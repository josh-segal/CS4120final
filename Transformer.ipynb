{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import utils as utils\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Version Info\n",
    "print(\"Tensforflow Version : \" ,tf.__version__)\n",
    "print(\"Transformers Version : \" ,transformers.__version__)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# make a data folder\n",
    "!mkdir -p data\n",
    "\n",
    "# download the data\n",
    "out_path = tf.keras.utils.get_file(origin=\"https://archive.ics.uci.edu/static/public/331/sentiment+labelled+sentences.zip\",extract=True,cache_dir=\"data\")\n",
    "print(\"\\n\",out_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('text_entailment_dataset/train.csv')\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "df = df.sample(frac=1, random_state=42)  # Shuffle with fixed seed for reproducibility\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_df, validation_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "# Write the training and validation DataFrames to separate CSV files\n",
    "train_df.to_csv('text_entailment_dataset/train_data.csv', index=False)\n",
    "validation_df.to_csv('text_entailment_dataset/validation_data.csv', index=False)\n",
    "\n",
    "train_dataset = df = pd.read_csv('text_entailment_dataset/train_data.csv')\n",
    "validation_dataset = df = pd.read_csv('text_entailment_dataset/validation_data.csv')\n",
    "test_dataset = df = pd.read_csv('text_entailment_dataset/test_data.csv')\n",
    "\n",
    "train_dataset.head()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "train_dataset.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "validation_dataset.head()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "validation_dataset.shape\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "test_dataset.head()\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "test_dataset.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# define a max length constant\n",
    "MAX_LENGTH = 64"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "bert = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "print(tokenizer)\n",
    "print(bert)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset[[\"premise\"]] = train_dataset[[\"premise\"]].astype(str)\n",
    "train_dataset[\"premise\"] = train_dataset[\"premise\"].apply(utils.change_lower)\n",
    "train_dataset[\"premise\"] = train_dataset[\"premise\"].apply(utils.clean_data)\n",
    "train_dataset[\"premise\"] = train_dataset[\"premise\"].apply(utils.remover)\n",
    "\n",
    "train_dataset[[\"hypothesis\"]] = train_dataset[[\"hypothesis\"]].astype(str)\n",
    "train_dataset[\"hypothesis\"] = train_dataset[\"hypothesis\"].apply(utils.change_lower)\n",
    "train_dataset[\"hypothesis\"] = train_dataset[\"hypothesis\"].apply(utils.clean_data)\n",
    "train_dataset[\"hypothesis\"] = train_dataset[\"hypothesis\"].apply(utils.remover)\n",
    "\n",
    "validation_dataset[[\"premise\"]] = validation_dataset[[\"premise\"]].astype(str)\n",
    "validation_dataset[\"premise\"] = validation_dataset[\"premise\"].apply(utils.change_lower)\n",
    "validation_dataset[\"premise\"] = validation_dataset[\"premise\"].apply(utils.clean_data)\n",
    "validation_dataset[\"premise\"] = validation_dataset[\"premise\"].apply(utils.remover)\n",
    "\n",
    "validation_dataset[[\"hypothesis\"]] = validation_dataset[[\"hypothesis\"]].astype(str)\n",
    "validation_dataset[\"hypothesis\"] = validation_dataset[\"hypothesis\"].apply(utils.change_lower)\n",
    "validation_dataset[\"hypothesis\"] = validation_dataset[\"hypothesis\"].apply(utils.clean_data)\n",
    "validation_dataset[\"hypothesis\"] = validation_dataset[\"hypothesis\"].apply(utils.remover)\n",
    "\n",
    "test_dataset[[\"premise\"]] = test_dataset[[\"premise\"]].astype(str)\n",
    "test_dataset[\"premise\"] = test_dataset[\"premise\"].apply(utils.change_lower)\n",
    "test_dataset[\"premise\"] = test_dataset[\"premise\"].apply(utils.clean_data)\n",
    "test_dataset[\"premise\"] = test_dataset[\"premise\"].apply(utils.remover)\n",
    "\n",
    "test_dataset[[\"hypothesis\"]] = test_dataset[[\"hypothesis\"]].astype(str)\n",
    "test_dataset[\"hypothesis\"] = test_dataset[\"hypothesis\"].apply(utils.change_lower)\n",
    "test_dataset[\"hypothesis\"] = test_dataset[\"hypothesis\"].apply(utils.clean_data)\n",
    "test_dataset[\"hypothesis\"] = test_dataset[\"hypothesis\"].apply(utils.remover)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = train_dataset['premise'] + train_dataset['hypothesis']\n",
    "X_Val = validation_dataset['premise'] + validation_dataset['hypothesis']\n",
    "X_test = test_dataset['premise'] + test_dataset['hypothesis']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# define a batch size for our experiments\n",
    "BATCH_SIZE = 64\n",
    "# define a percentage of the data to use for training\n",
    "\n",
    "train_dataset = df = pd.read_csv('text_entailment_dataset/train_data.csv')\n",
    "validation_dataset = df = pd.read_csv('text_entailment_dataset/validation_data.csv')\n",
    "test_dataset = df = pd.read_csv('text_entailment_dataset/test_data.csv')\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "train_sentences = [train_dataset.loc[s][0] + train_dataset.loc[s][1] for s in range(len(train_dataset))]\n",
    "train_labels = [train_dataset.loc[l][2] for l in range(len(train_dataset))]\n",
    "\n",
    "validation_sentences = [validation_dataset.loc[s][0] + validation_dataset.loc[s][1] for s in range(len(validation_dataset))]\n",
    "validation_labels = [validation_dataset.loc[l][2] for l in range(len(validation_dataset))]\n",
    "\n",
    "test_sentences = [test_dataset.loc[s][0] + test_dataset.loc[s][1] for s in range(len(test_dataset))]\n",
    "\n",
    "print(\"LENGTHS // Train sentences: \" + str(len(train_sentences)) + \". Train labels: \" + str(len(train_labels)))\n",
    "print(\"LENGTHS // Test sentences: \" + str(len(validation_sentences)) + \". Test labels: \" + str(len(validation_labels)))\n",
    "print(\"LENGTHS // Test sentences: \" + str(len(test_sentences)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "train_labels = train_dataset[\"label\"]\n",
    "validation_labels = validation_dataset[\"label\"]\n",
    "\n",
    "# Convert to one-hot encoded format\n",
    "num_classes = len(set(train_labels))  # Calculate the number of classes\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "validation_labels = to_categorical(validation_labels, num_classes=num_classes)\n",
    "\n",
    "print(\"train label shape:\", train_labels.shape)\n",
    "print(\"val label shape:\", validation_labels.shape)\n",
    "\n",
    "steps_per_epoch = len(train_labels) // BATCH_SIZE\n",
    "validation_steps = len(validation_labels) // BATCH_SIZE\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "#Implementing KMeans clustering for better labels\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Use a tfidf vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(train_sentences)\n",
    "\n",
    "# Choosing 3 clusters\n",
    "k = 3\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=0, n_init=\"auto\").fit(X)\n",
    "\n",
    "# Get cluster assignments for the training data\n",
    "train_cluster_labels = kmeans.labels_\n",
    "train_labels = to_categorical(train_cluster_labels, num_classes=num_classes)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# data generator for the model\n",
    "def data_generator(sentences: np.array,labels: np.array,batch_size: int) -> (dict,tf.Tensor):\n",
    "    i = 0\n",
    "    start_idx = -1 * batch_size\n",
    "    end_idx = 0\n",
    "\n",
    "    while True:\n",
    "        start_idx += batch_size\n",
    "        end_idx += batch_size\n",
    "        # TODO: append batch_size number of sentences and labels to batch_x and batch_y\n",
    "        # Make sure that you don't re-use sentences and labels that you've already put into batches!\n",
    "\n",
    "        if end_idx > len(sentences):\n",
    "            end_idx = batch_size\n",
    "            start_idx = 0\n",
    "\n",
    "        batch_y = labels[start_idx:end_idx]\n",
    "\n",
    "        # TODO: tokenize the batch_x, padding to MAX_LENGTH, and truncating to MAX_LENGTH\n",
    "        batch_x = tokenizer(sentences[start_idx:end_idx], return_tensors=\"tf\", max_length=MAX_LENGTH, truncation=\"longest_first\", padding=\"max_length\")\n",
    "\n",
    "        # debugging prints (make sure that these are commented out when you actually train your model)\n",
    "        # should be (batch_size, MAX_LENGTH)\n",
    "        # print(batch_x['input_ids'].shape)\n",
    "\n",
    "        # convert our ys into the appropriate tensor\n",
    "        batch_y = tf.convert_to_tensor(batch_y)\n",
    "\n",
    "        # debugging prints (make sure that these are commented out when you actually train your model)\n",
    "        # should be (batch_size,)\n",
    "        # print(batch_y.shape)\n",
    "        yield dict(batch_x), batch_y\n",
    "\n",
    "train_data = data_generator(train_sentences,train_labels,BATCH_SIZE)\n",
    "val_data = data_generator(validation_sentences,validation_labels,BATCH_SIZE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO: Take a look at the contents of tmp_batch_x and tmp_batch_y and report the shapes of the `input_ids`\n",
    "# and the y label tensor.\n",
    "# make sure that the shapes are what you expect them to be\n",
    "# (take a look at the comments in the data_generator code)\n",
    "\n",
    "tmp_batch_x,tmp_batch_y = next(train_data)\n",
    "val_batch_x, val_batch_y = next(val_data)\n",
    "\n",
    "print(tmp_batch_x[\"input_ids\"].shape)\n",
    "print(tmp_batch_y.shape)\n",
    "#print(tmp_batch_y)\n",
    "\n",
    "print(val_batch_x[\"input_ids\"].shape)\n",
    "print(val_batch_y.shape)\n",
    "#print(val_batch_y)\n",
    "print(train_cluster_labels)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.callbacks import History\n",
    "from transformers import TFDistilBertModel\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "# Define custom metrics functions\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    f1 = 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n",
    "    return f1\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "strategy = tf.distribute.MirroredStrategy()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "#Get the number of GPUs needed\n",
    "print(\"Total GPUs: \", strategy.num_replicas_in_sync)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "#Prints the GPUs on your machine (if it's nvidia)\n",
    "!nvidia-smi"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "#This will be our steps per epoch\n",
    "print(len(train_sentences)//BATCH_SIZE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "with strategy.scope() as scope:\n",
    "\n",
    "    bert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased',output_attentions = False,return_dict=False)\n",
    "    # we do not need attention outputs\n",
    "    # we want to return tuples since they are easier to access\n",
    "\n",
    "    bert_model.trainable = False\n",
    "    # setting trainable to false ensures\n",
    "    # we do not update its weights\n",
    "\n",
    "    # Define the learning rate schedule parameters\n",
    "    initial_learning_rate = 0.001\n",
    "    decay_rate = 0.95\n",
    "    decay_steps = 1000\n",
    "\n",
    "    # Create an exponential decay learning rate schedule\n",
    "    lr_schedule = ExponentialDecay(\n",
    "        initial_learning_rate,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=decay_rate,\n",
    "        staircase=True  # Optional: Whether to apply decay in a staircase manner\n",
    "    )\n",
    "\n",
    "    optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    model_ = tf.keras.Sequential([\n",
    "        bert_model,\n",
    "        tf.keras.layers.Lambda(lambda x: x[0][:,0,:]), # https://keras.io/api/layers/core_layers/lambda/\n",
    "        tf.keras.layers.Dense(64,activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32,activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10,activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(3,activation=\"softmax\") # we have 3 classes\n",
    "    ])\n",
    "\n",
    "    # Define a checkpoint callback to save the best model\n",
    "    checkpoint = ModelCheckpoint('distilbert_trained_model.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "\n",
    "    model_.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy', precision, recall, f1])\n",
    "\n",
    "    # Use the first batch of training data we got to instantiate -- needed for loading weights\n",
    "    model_(tmp_batch_x) \n",
    "    \n",
    "    #Load model if needed\n",
    "    #model_.load_weights('transformer_weights.h5')\n",
    "    # Define a callback to collect metrics history\n",
    "    history = History()\n",
    "\n",
    "    model_.fit(\n",
    "        train_data,\n",
    "        epochs=2,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=val_data,\n",
    "        validation_steps=validation_steps,\n",
    "        validation_batch_size=BATCH_SIZE,\n",
    "        callbacks=[history, checkpoint]\n",
    "    )\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "#save our weights -- CANNOT SAVE MODEL BECAUSE OF LAMBDA LAYER\n",
    "model_.save_weights('transformer_weights.h5')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Access the metrics history\n",
    "print(history.history.keys())  # To see what metrics are available"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Access the metrics history\n",
    "epochs = list(range(1, len(history.history['accuracy']) + 1))  # Assuming all metrics have the same length\n",
    "precision = np.array(history.history['precision'])\n",
    "recall = np.array(history.history['recall'])\n",
    "f1 = np.array(history.history['f1'])\n",
    "accuracy = np.array(history.history['accuracy'])\n",
    "loss = np.array(history.history['loss'])\n",
    "val_accuracy = np.array(history.history['val_accuracy'])\n",
    "val_loss = np.array(history.history['val_loss'])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Plot all four metrics on one graph\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.plot(epochs, val_accuracy, label='Validation Accuracy')\n",
    "plt.plot(epochs, loss, label='Training Loss')\n",
    "plt.plot(epochs, accuracy, label='Training Accuracy')\n",
    "\n",
    "plt.title('Metrics across Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xticks(epochs)\n",
    "plt.legend()\n",
    "plt.savefig(\"Transformer_BERT_training_val_loss_acc(1).pdf\")  # Save the plot before showing\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Plot all four metrics on one graph\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, precision, label='Precision')\n",
    "plt.plot(epochs, recall, label='Recall')\n",
    "plt.plot(epochs, f1, label='F1 Score')\n",
    "plt.plot(epochs, accuracy, label='Accuracy')\n",
    "\n",
    "plt.title('Metrics across Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xticks(epochs)\n",
    "plt.legend()\n",
    "plt.savefig(\"Transformer_BERT_training_PRFA(1).pdf\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
