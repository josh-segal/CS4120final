{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# !pip install datasets\n",
    "# !pip install evaluate\n",
    "# !pip install tokenizers\n",
    "# !pip install transformers\n",
    "# !pip install bs4\n",
    "# !pip install lxml"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E5eWlFMrgojZ",
    "outputId": "3c4706a2-652c-4d64-9a0a-a94f8ed55712",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:38:28.361549Z",
     "start_time": "2024-04-10T00:38:15.649587Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67eu0djHdb4N",
    "outputId": "fd234abb-2c3f-45c2-bfc0-14b5970b2495",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:38:28.369154Z",
     "start_time": "2024-04-10T00:38:28.363098Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/joshuasegal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/Users/joshuasegal/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/joshuasegal/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/joshuasegal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "# dataset_path = 'dataset'\n",
    "# papers_path = 'papers'\n",
    "# presentations_path = 'presentations'\n",
    "#\n",
    "# utils.move_xml_files(dataset_path, papers_path, presentations_path)\n",
    "\n",
    "\n",
    "# source_folder = \"data/paper_slides_data/raw_data/dataset\"\n",
    "# papers_folder = \"data/paper_slides_data/raw_data/papers\"\n",
    "# presentations_folder = \"data/paper_slides_data/raw_data/presentations\"\n",
    "#\n",
    "# utils.organize_xml_folders(source_folder, papers_folder, presentations_folder)"
   ],
   "metadata": {
    "id": "S2bstsijdb4O",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:38:28.377348Z",
     "start_time": "2024-04-10T00:38:28.370316Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/paper_slides_data/raw_data/dataset'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 12\u001B[0m\n\u001B[1;32m      9\u001B[0m papers_folder \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata/paper_slides_data/raw_data/papers\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     10\u001B[0m presentations_folder \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata/paper_slides_data/raw_data/presentations\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 12\u001B[0m utils\u001B[38;5;241m.\u001B[39morganize_xml_folders(source_folder, papers_folder, presentations_folder)\n",
      "File \u001B[0;32m~/Coding/Jupyter/NLP/final/notebooks/../utils.py:198\u001B[0m, in \u001B[0;36morganize_xml_folders\u001B[0;34m(source_folder, papers_folder, presentations_folder)\u001B[0m\n\u001B[1;32m    195\u001B[0m os\u001B[38;5;241m.\u001B[39mmakedirs(presentations_folder, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# Iterate through each folder in the source folder\u001B[39;00m\n\u001B[0;32m--> 198\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, folder_name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28msorted\u001B[39m(os\u001B[38;5;241m.\u001B[39mlistdir(source_folder))):\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;66;03m# Create the full path to the current folder\u001B[39;00m\n\u001B[1;32m    200\u001B[0m     folder_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(source_folder, folder_name)\n\u001B[1;32m    202\u001B[0m     \u001B[38;5;66;03m# Check if it's a directory\u001B[39;00m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data/paper_slides_data/raw_data/dataset'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the paths\n",
    "presentation_dir = \"../data/paper_slides_data/sample_data/presentations\"\n",
    "paper_dir = \"../data/paper_slides_data/sample_data/papers\"\n",
    "\n",
    "sample_xml_pres_filename = \"slide.clean_tika.xml\"\n",
    "sample_xml_paper_filename = \"Paper_BRM.tei.xml\"\n",
    "\n",
    "# Join the paths\n",
    "sample_xml_pres_path = os.path.join(presentation_dir, sample_xml_pres_filename)\n",
    "sample_xml_paper_path = os.path.join(paper_dir, sample_xml_paper_filename)\n",
    "\n",
    "# Read files\n",
    "sample_xml_pres = utils.read_file(sample_xml_pres_path)\n",
    "sample_xml_paper = utils.read_file(sample_xml_paper_path)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vvKeerpSdb4P",
    "outputId": "c5566859-b849-49c0-a03f-53012d93c89c",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:38:28.387989Z",
     "start_time": "2024-04-10T00:38:28.378404Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "sample_pres_text = utils.parse_presentation_xml(sample_xml_pres)\n",
    "print(len(sample_pres_text))\n",
    "print(sample_pres_text[:3])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "0ANc_UhWdb4P",
    "outputId": "8c40584a-da10-4fdc-d5f5-0e7a2d55c4cc",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:38:28.397030Z",
     "start_time": "2024-04-10T00:38:28.389096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "['Noam Nisan, Michael Schapira, Gregory Valiant, and Aviv Zohar', 'Motivation Equilibrium is the basic object of study in game theory. Question: How is an equilibrium reached? In a truly satisfactory answer each players rule of behavior is simple and locally rational repeated best-response repeated better-response regret-minimization', 'Motivation Repeated best-response is often employed in practice e.g., Internet routing We ask: When is such locallyrational behavior really rational?']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "sample_paper_text = utils.parse_paper_xml(sample_xml_paper)\n",
    "print(len(sample_paper_text))\n",
    "print(sample_paper_text[:3])"
   ],
   "metadata": {
    "id": "A2NuAWphdb4P",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:38:28.413436Z",
     "start_time": "2024-04-10T00:38:28.398220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385\n",
      "['The basic object of study in game theory and in economics is the equilibrium: a \"stable\" state from which none of the players wish to deviate.', 'Equilibrium is a static concept that often abstracts away the question of how it is reached.', 'Once we start looking at dynamics, or at algorithms for finding equilibria, we cannot escape questions of the form \"How is an equilibrium reached?\".']\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "sample_paper_title = utils.parse_title(sample_xml_paper)\n",
    "print(sample_paper_title)\n",
    "sample_pres_title = utils.parse_title(sample_xml_pres)\n",
    "print(sample_pres_title)"
   ],
   "metadata": {
    "id": "q1RE2aBldb4P",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:38:28.418156Z",
     "start_time": "2024-04-10T00:38:28.414456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best-Response Mechanisms\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "sample_pres_preprocessed = utils.preprocess_text(sample_pres_text)"
   ],
   "metadata": {
    "id": "7S4Gkn9Sdb4P",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:38:28.433630Z",
     "start_time": "2024-04-10T00:38:28.418668Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "sample_paper_preprocessed = utils.preprocess_text(sample_paper_text)"
   ],
   "metadata": {
    "id": "IfPoEVgfdb4P",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:38:28.485274Z",
     "start_time": "2024-04-10T00:38:28.434640Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "print(sample_pres_preprocessed[:3])\n",
    "print(sample_paper_preprocessed[:3])"
   ],
   "metadata": {
    "id": "qnzkDNmEdb4P",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:38:28.491659Z",
     "start_time": "2024-04-10T00:38:28.487341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['noam nisan  michael schapira  gregori valiant  aviv zohar'], ['motiv equilibrium basic object studi game theori ', 'question  equilibrium reach ', 'truli satisfactori answer player rule behavior simpl local ration repeat bestrespons repeat betterrespons regretminim'], ['motiv repeat bestrespons often employ practic eg  internet rout ask  locallyr behavior realli ration ']]\n",
      "[['basic object studi game theori econom equilibrium   stabl  state none player wish deviat '], ['equilibrium static concept often abstract away question reach '], ['start look dynam  algorithm find equilibria  escap question form  equilibrium reach ', ' ']]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print(len(sample_paper_preprocessed))\n",
    "print(len(sample_pres_preprocessed))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def process_folder(folder_path, parse_func, preprocess_func):\n",
    "    data_list = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, 'r') as file:\n",
    "            file_content = file.read()\n",
    "            parsed_data = parse_func(file_content)\n",
    "            preprocessed_data = preprocess_func(parsed_data)\n",
    "            data_list.append(preprocessed_data)\n",
    "    return data_list\n",
    "\n",
    "def combine_data(papers_folder, presentations_folder):\n",
    "    papers_data = process_folder(papers_folder, utils.parse_paper_xml, utils.preprocess_text)\n",
    "    presentations_data = process_folder(presentations_folder, utils.parse_presentation_xml, utils.preprocess_text)\n",
    "\n",
    "    combined_data = {\"papers\": papers_data,\n",
    "                     \"presentations\": presentations_data}\n",
    "    return combined_data\n",
    "\n",
    "# Example usage:\n",
    "# Define the folders relative to the current directory\n",
    "papers_folder = \"../data/paper_slides_data/raw_data/papers\"\n",
    "presentations_folder = \"../data/paper_slides_data/raw_data/presentations\"\n",
    "\n",
    "# Join the paths\n",
    "papers_folder_path = os.path.join(os.getcwd(), papers_folder)\n",
    "presentations_folder_path = os.path.join(os.getcwd(), presentations_folder)\n",
    "\n",
    "combined_data = combine_data(papers_folder_path, presentations_folder_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Zip presentations and papers together\n",
    "zipped_data = zip(combined_data[\"presentations\"][:3], combined_data[\"papers\"][:3])\n",
    "\n",
    "# Print the zipped data\n",
    "for i, (presentation, paper) in enumerate(zipped_data, start=1):\n",
    "    print(\"preso sentences\", len(presentation))\n",
    "    print(f\"Pair {i}: \\n Presentation - {presentation[:10]}\")\n",
    "    print(\"\")\n",
    "    print(\"paper sentences\", len(paper))\n",
    "    print(f\"Paper - {paper[:10]}\")\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def find_most_similar_sentence(query_sentence, sentences):\n",
    "    # Combine query sentence with the list of sentences\n",
    "    all_sentences = [query_sentence] + sentences\n",
    "\n",
    "    # Initialize TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Compute TF-IDF vectors for all sentences\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_sentences)\n",
    "\n",
    "    # Calculate cosine similarity between query sentence and all sentences\n",
    "    similarity_scores = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])[0]\n",
    "\n",
    "    # Find the index of the most similar sentence\n",
    "    most_similar_index = similarity_scores.argmax()\n",
    "\n",
    "    # Return the most similar sentence and its similarity score\n",
    "    most_similar_sentence = sentences[most_similar_index]\n",
    "    similarity_score = similarity_scores[most_similar_index]\n",
    "\n",
    "    return most_similar_sentence, similarity_score\n",
    "\n",
    "presentation_paper_pairs = []\n",
    "for presentation, paper in zip(combined_data[\"presentations\"], combined_data[\"papers\"]):\n",
    "    presentation_flat = [sentence for sublist in presentation for sentence in sublist]\n",
    "    paper_flat = [sentence for sublist in paper for sentence in sublist]\n",
    "    presentation_sentence_pairs = []\n",
    "    for sentence in presentation_flat:\n",
    "        most_similar_sentence, similarity_score = find_most_similar_sentence(sentence, paper_flat)\n",
    "        presentation_sentence_pairs.append([sentence, most_similar_sentence, similarity_score])\n",
    "        sorted_presentation_sentence_pairs = sorted(presentation_sentence_pairs, key=lambda x: x[2], reverse=True)\n",
    "    presentation_paper_pairs.append(sorted_presentation_sentence_pairs)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1192\n",
      "[[['thank ', '3 thank adam paul suggest featur class ', 0.4072465115358739], ['futur work debug tool develop run older newer version file system compar result older version file system repair simpl repair  copi data file system complex repair  recreat en file system tree micro repair ', 'compar two system use treetotre grammar ', 0.19439958985854655], ['hard work alreadi done us 30 differ disk base file system linux 26 file system use ', 'compar two system use treetotre grammar ', 0.1722803126553838], ['subsist  singl instanc store variant singl instanc store selecv merg data block block address si export virtual disk fse manag map  free space info ', ' x n singl substitut site x 1      x n ', 0.16731210441726532], ['corrupon data singl fs due bug  bit flip  storag stack corrupt data block merg n1 data block merg corrupt data block fix next read corrupon data block insid disk singl copi data differ code path differ ondisk structur envyf layer fs 2 fs n applicaon vf layer vdisk 1 vdisk 2 vdisk n read cach chash layer free space manag su b si st', 'system train use mira  crammer singer  2003  chiang et al  2009  tune set 3000 sentenc newswir nist mt evalu data gale develop data  disjoint train data ', 0.16542628092646108], ['summari result robust tradion file system vulner corrupon envyfs3 toler almost mistak one fs perform desktop workload  envyfs3 compar perform io intens workload  regular operaon  envyfs3  subsist accept perform memori pressur  envyfs3  subsist larg overhead', 'fuzzi treetotre extract perform use analog constraint ', 0.15955357723581923], ['ext3 jf reiserf envyf envyfssi experiment setup amd opteron 22 ghz processor 2gb ram 80 gb hitachi deskstar 7200rpm sata disk linux 2612 4gb disk par  file system openssh benchmark perform evaluaon el ap se im e  ec n  file system cpu intens openssh 45 copi  untar make perform envyfs3 compar singl file system', 'compar two system use treetotre grammar ', 0.15729718385706948], ['file 1  36 imprecis vf specificaon  cont  inod number allocaon inod number return system call child file system issu differ inod number possibl soluon  forc file system use algorithm ', 'compar two system use treetotre grammar ', 0.15076470862887847], ['result robust tradion file system handl corrupon   4   envyfs3 toler 989  singl file system mistak perform desktop workload  envyfs3 compar perform io intens workload  normal mode  envyfs3  subsist accept perform memori pressur  envyfs3  subsist larg overhead poten debug tool fs develop pinpoint sourc failsil bug ext3', 'fuzzi treetotre extract perform use analog constraint ', 0.14456574538252354], ['impracc  requir wide scale chang file system specificaon take year get accept leverag exisng specificaon ', 'phrase pair  accept cross previous accept phrase pair  otherwis  reject ', 0.14040213889578346], ['ext3  jf  reiserf threevers fs other work without modificaon', 'system use glue rule  chiang  2005   allow decod  work bottomup  stop build hierarch structur instead concaten partial translat without reorder ', 0.1304876577812984], ['disk b b b envyf layer block driver b reliabl evaluaon  fault injecon corrupon  bug fs  storag stack type disk block superblock  inod  block bitmap  file data  perform differ file op mount  stat  creat  unlink  read  report user visibl result result applic subsist except corruphon data block ex 3 jf r ei se rf pseudo devic driver vf b b b b typeawar fault injechon  prabhakaran05 ', ' 2006   systemat studi  find  sentenc treetotre constraint block rule extract  major due parser error ', 0.12930654664913963], ['base nversion program  avizienis77  nf server  rodrigues01   databas  vandiver07   secur  cox06  nversion file system envyf  simpl solwar layer store data n child file system operaon perform children reli simpl sowar layer challeng  reduc overhead retain reliabl subsist  novel singl instanc store envyf layer c h ild 1 c h ild 2 c h ild n disk driver disk si layer applicaon', ' use simpl heurist ', 0.12775813799810576], ['bug inevit file system challeng  cope ', 'paper  explor reason treetotre translat challeng  sourc syntax target syntax might use togeth ', 0.1263549004267543], ['fs 1 disk handl data block corrupon ', 'system train use mira  crammer singer  2003  chiang et al  2009  tune set 3000 sentenc newswir nist mt evalu data gale develop data  disjoint train data ', 0.1213794003491521], ['file system today world modern file system complex ten thousand line code  eg  xf 45k loc  storag stack also gevng deeper hypervisor  network  logic volum manag need handl gamut failur memori allocaon  disk fault  bit flip  system crash preserv integr metadata user data', 'compar two system use treetotre grammar ', 0.12124125784812764], ['file system bug bug report linux 26 seri bugzilla ext3  64  jf  17  reiserf  38 fs corrupon caus perman data loss fs bug broadli classifi two categori failstop  system immedi crash soluon  nook  swi 04   curio  david08  failsil  accident corrupt ondisk state mani bug uncov  prabhakaran05  gunawi08  yang04  yang06b ', 'compar two system use treetotre grammar ', 0.12023030497900813], ['persist store disk envyf write n file system n data block merg 1 data block content hash store persist metadata block merg inter fs block intra fs envyf layer fs 1 fs 2 fs n applicaon vf layer vdisk 1 disk vdisk 2 vdisk n read cach chash layer free space manag su b si st', ' 2006   systemat studi  find  sentenc treetotre constraint block rule extract  major due parser error ', 0.11341818702634786], ['pain process high cost develop  long delay lucki ', 'tabl 3 show score develop set test set  3000 2000 sentenc  respect  newswir drawn nist mt evalu data gale develop data disjoint tune data ', 0.11082652805708078], ['outlin introducon build reliabl file system reduc overhead subsist evaluahon reliabl perform conclus', 'first  tabl 4 show system use treetotre grammar use glue rule much less perform match substitut ', 0.11021190794156072], ['robust envyf recov child file system mistak ', 'compar two system use treetotre grammar ', 0.10630150838620037], ['poten bug isolaon ext3 envyfs3 ti e unlink corrupt inod  ext3_lookup  bug  ext3_unlink unmount  panic  ti e unlink corrupt inod  ext3_lookup  bug  ext3 inod match other op issu typic use  problem noce panic envyfs3  problem noce first child file system return wrong result', 'address problem  liu et al ', 0.10294383384990072], ['ext3 p h ra rs al se 1  ta   se 2  c h  ad ad lin k ge td ir en tr ie cr ea lin k kd ir n e sy lin k w ri te tr u n ca te rm ir u n lin k u n se 3  f sy n c  u u n inod dir bmap imap indirect data super jsuper gdesc data loss na mount op fail crash addion operaon fail  inod corrupon lead data loss unlink  system crash unmount e', 'system train use mira  crammer singer  2003  chiang et al  2009  tune set 3000 sentenc newswir nist mt evalu data gale develop data  disjoint train data ', 0.10216717704381487], ['jf p h ra rs al se 1 se 2 ad ad lin k ge td ir en tr ie cr ea lin k kd ir n e sy lin k w ri te tr u n ca te rm ir u n lin k u n se 3 u u n inod dir bmap imap intern data super jsuper jdata aggrinod imapdesc imapcntl normal data loss na mount op fail data corrupt crash readonli depend j', 'system train use mira  crammer singer  2003  chiang et al  2009  tune set 3000 sentenc newswir nist mt evalu data gale develop data  disjoint train data ', 0.10041516112377183], ['ext3 p h ra rs al se 1  ta   se 2  c h  ad ad lin k ge td ir en tr ie cr ea lin k kd ir n e sy lin k w ri te tr u n ca te rm ir u n lin k u n se 3  f sy n c  u u n inod dir bmap imap indirect data super jsuper gdesc normal data loss na mount op fail data corrupt crash readonli e depend e', 'system train use mira  crammer singer  2003  chiang et al  2009  tune set 3000 sentenc newswir nist mt evalu data gale develop data  disjoint train data ', 0.09982133665360324], ['advanc system lab  adsl  univers wisconsinmadison hxp  wwwcswisceduadsl', 'compar two system use treetotre grammar ', 0.09890399596880589], ['ext3 p h ra rs al se 1  ta   se 2  c h  ad ad lin k ge td ir en tr ie cr ea lin k kd ir n e sy lin k w ri te tr u n ca te rm ir u n lin k u n se 3  f sy n c  u u n inod dir bmap imap indirect data super jsuper gdesc result matrix normal data loss na mount op fail data corrupt crash readonli e depend e', 'system train use mira  crammer singer  2003  chiang et al  2009  tune set 3000 sentenc newswir nist mt evalu data gale develop data  disjoint train data ', 0.09874732093632363], ['outlin introducon build reliabl file system reduc overhead subsist evaluaon conclus', 'system use glue rule  chiang  2005   allow decod  work bottomup  stop build hierarch structur instead concaten partial translat without reorder ', 0.09623949163995657], ['outlin introducon build reliabl file system reduc overhead subsist evaluaon conclus', 'system use glue rule  chiang  2005   allow decod  work bottomup  stop build hierarch structur instead concaten partial translat without reorder ', 0.09623949163995657], ['outlin introducon build reliabl file system reduc overhead subsist evaluaon conclus', 'system use glue rule  chiang  2005   allow decod  work bottomup  stop build hierarch structur instead concaten partial translat without reorder ', 0.09623949163995657], ['ext3 p h ra rs al se 1  ta   se 2  c h  ad ad lin k ge td ir en tr ie cr ea lin k kd ir n e sy lin k w ri te tr u n ca te rm ir u n lin k u n se 3  f sy n c  u u n inod dir bmap imap indirect data super jsuper gdesc data loss na readonli ext3 detect corrupon rmdir  unlink creat  mkdir  symlink caus ext3 reus inod  resulng data loss e', 'system train use mira  crammer singer  2003  chiang et al  2009  tune set 3000 sentenc newswir nist mt evalu data gale develop data  disjoint train data ', 0.09117121523215979], ['conclus bugsmistak inevit solwar must cope  hope avoid envyf  nversion approach tolerang fs bug built use exisng specificaon file system subsist  singl instanc store decreas overhead retain reliabl', ' x n singl substitut site x 1      x n ', 0.08826140051690917], ['ye  leverag vf  issu vf precis nversion purpos need handl case specificaon precis eg  order directori entri  inod number allocaon', 'case may want soften match constraint ', 0.0859458206328542], ['nversion layer  envyf  insert beneath vf simpl design avoid bug exampl  read file alloc n data buffer read data block disk compar  data  return code  file posion return  data  return code issu  alloc memori read operaon extra copi alloc buffer applicaon comparison overhead compar wrapper inod map tabl applicaon vf layer ex t3 jf r ei se rf envyf layer read  file  1 block  read  file  1 block  read   read   read   f f f po  x po  x po  x err  err  err  disk err  err  tolerang filesystem mistak envyf', 'tabl 3 show score develop set test set  3000 2000 sentenc  respect  newswir drawn nist mt evalu data gale develop data disjoint tune data ', 0.08220469191772113], ['nversion system develop process  1 produc specificaon solwar 2 implemenng n version solwar 3 creang nversion layer execut differ version determin consensu result', 'heurist produc set nest phrase  repres singl restructur tree ', 0.0787081493851897], ['envyfs3 p h ra rs al se 1 se 2 ad ad lin k ge td ir en tr ie cr ea lin k kd ir n e sy lin k w ri te tr u n ca te rm ir u n lin k u n se 3 u u n inod dir bmap imap intern data super jsuper jdata aggrinod imapdesc imapcntl normal na crash kernel panic envyfs3 e r j envyf', 'system baselin  featur describ section 3 ad ', 0.07316268627035209], ['imprecis vf specificaon order directori entri issu  specifi return order cant blindli compar entri soluon  read entri directori  dir  test case  fse match entri fse return major result fs x fs fs z envyf layer file 1 file 2 file 3 dir  test file 2 file 3 file 1 dir  test dir  test file 1 file 2 file 3 readdir  test entri file 3 file 1 file 2 file 1 file 2 file 3 file 1 file 2 file 3 dir  test', 'use exact treetotre extract  got much smaller grammar  decreas accuraci chineseenglish test set  signific chang ', 0.07256469784456349], ['ext3 p h ra rs al se 1  ta   se 2  c h  ad ad lin k ge td ir en tr ie cr ea lin k kd ir n e sy lin k w ri te tr u n ca te rm ir u n lin k u n se 3  f sy n c  u u n inod dir bmap imap indirect data super jsuper gdesc data loss na mount ext3 store mani superblock copi   handl superblock corrupon e', 'system baselin  featur describ section 3 ad ', 0.0699145045205699], ['kernel panic ext3 p h ra rs al se 1  ta   se 2  c h  ad ad lin k ge td ir en tr ie cr ea lin k kd ir n e sy lin k w ri te tr u n ca te rm ir u n lin k u n se 3  f sy n c  u u n normal na inod dir bmap imap indirect data super jsuper gdesc envyfs3 work everi scenario 61809 tolerang filesystem mistak envyf 25 envyfs3 e r j envyf', 'system baselin  featur describ section 3 ad ', 0.06841953686149892], ['postmark10k postmark100k postmark100k  ext3 jf reiserf envyf envyfssi io intens mimic busi mail server workload transacon  creat  delet  read  append  postmark configuraon 2500 file file size  4kb 40kb ', 'size parallel text use shown tabl 2 ', 0.06640289752536471], ['read file envyf soluon  applicaon buffer fs tcplike checksum data comparison compar  checksum  return code  file posion read data un  l major compar wrapper inod map tabl applicaon vf layer ex t3 jf r ei se rf envyf layer read  file  1 block  read  file  1 block  read   read   f f f po  x po  x err  err  err  fs 1  fs 2  fs n  checksum disk err  err  read   po  x', 'compar two system use treetotre grammar ', 0.06594656207675069], ['part 1 part 2 part n disk 1 disk 2 disk n disk case singl instanc storag  si  ideal  one disk per fs praccal  one disk fs overhead effec storag space  1n n me io  readwrit  challeng  maintain divers minim overhead envyf layer fs 1 fs 2 fs n applicaon vf layer disk req ', 'figur 2  observ flat structur chines ip prevent exact treetotre extract extract rule contain part ip  exampl ', 0.06441783035750781], ['soluon  issu inod number envyf layer fs x fs fs z envyf layer dir  test dir  test dir  test file 1  10 file 1 65 file 1 10 file 2 15 file 3 16 file 2 04 file 3 44 file 1 36 file 1  inod map tabl file 3 99 file 1 65 file 2 43 inod number inod map tabl persist store', 'use exact treetotre extract  got much smaller grammar  decreas accuraci chineseenglish test set  signific chang ', 0.051568575275052854], ['tolerang filesystem mistak envyf lakshmi n bairavasundaram netapp  inc swaminathan sundararaman andrea c arpacidusseau remzi h arpacidusseau univers wisconsin madison', 'statist translat model use synchron contextfre grammar  scfg  relat formal tri captur recurs structur languag wide adopt last year ', 0.0], ['virt  fs 1 fs 3 fs 2 ', 'statist translat model use synchron contextfre grammar  scfg  relat formal tri captur recurs structur languag wide adopt last year ', 0.0], ['', 'statist translat model use synchron contextfre grammar  scfg  relat formal tri captur recurs structur languag wide adopt last year ', 0.0], ['queue', 'statist translat model use synchron contextfre grammar  scfg  relat formal tri captur recurs structur languag wide adopt last year ', 0.0], ['transacon  10k 100k postmark benchmark el ap se im e  ec n  envyfs3  8x  subsist  4x envyfs3  17x  subsist  115 ', 'statist translat model use synchron contextfre grammar  scfg  relat formal tri captur recurs structur languag wide adopt last year ', 0.0]], [['tupl contain data deriv relat   later appear relat  c ', 'type data set opinion sentenc relat certain topic ', 0.3085385265337465], ['topic motiv conceptu model predic languag evalu', 'topic model  gener idea use unigram languag model  ie  multinomi word distribut  model topic ', 0.26645501003214156], ['data curat set finegrain data multipl sourc integr  queri  updat manipul evolv schema instanc multipl histori includ manipul queri multipl valu attribut user express confid doubt exampl set intellig  profil person interest militari  oper risk assess escienc  bioinformat databas 3', 'order identifi multipl topic text  would fit mixtur model involv multipl multinomi distribut text data tri figur set paramet multipl word distribut maxim likelihood text data ', 0.2626441507027373], ['know sourc    data came ', 'know equat 11', 0.26239265046257554], ['idea  new predic  new  fullfeatur proven queri languag normal relat algebra oper front face new predic enabl select project base proven', 'defin new problem opinion integr ', 0.25847366983729525], ['summari mmp differ data structur orthogon proven data ', 'paper  use weblog data  method appli kind data contain opinion free text ', 0.2555169168418848], ['process method use deriv data  improv chang ', 'paper  use weblog data  method appli kind data contain opinion free text ', 0.24405299747413722], ['select  r  tupl path  sourc name  x   tupl r least one data valu deriv relat   relat  b ', 'type data set opinion sentenc relat certain topic ', 0.24004892501512853], ['select  r  data valu tupl path  valu relat    path  valu relat   b  ', 'quantifi repres ordinari opinion sentenc  comput  support valu  extract ordinari opinion sentenc ', 0.22746088585768268], ['curat data trustworthi ', 'paper  use weblog data  method appli kind data contain opinion free text ', 0.2062181676556631], ['key conceptu model featur relat data multivalu attribut multilay multiproven oper queri  dml  ddl data confid languag  dcl  distinct proven dataset  attribut  entiti  valu delet data proven retain  insert connect prior delet multipl histori data', 'paper  use weblog data  method appli kind data contain opinion free text ', 0.20416890869810003], ['exampl queri tupl relat r deriv sourc  x ', 'howev  larg scale inform sourc  quit challeng user integr digest opinion differ sourc ', 0.20035594907380583], ['access  track proven  keep manag user hand  transit layer implement  perform  full access proven map map', 'expert opinion rel easi user access opinion search websit cnet ', 0.19604917418140722], ['motiv conceptu model predic languag evalu', 'topic model  gener idea use unigram languag model  ie  multinomi word distribut  model topic ', 0.1958308732904328], ['motiv conceptu model predic languag evalu', 'topic model  gener idea use unigram languag model  ie  multinomi word distribut  model topic ', 0.1958308732904328], ['motiv conceptu model predic languag evalu', 'topic model  gener idea use unigram languag model  ie  multinomi word distribut  model topic ', 0.1958308732904328], ['access  track proven  keep manag user hand  transit layer implement  perform  full access proven map map focu paper', 'expert opinion rel easi user access opinion search websit cnet ', 0.1900613659210114], ['access  track proven  keep manag user hand  transit layer implement  perform  full access proven map map focu paper', 'expert opinion rel easi user access opinion search websit cnet ', 0.1900613659210114], ['select  r  data valu tupl path  valu relat   valu relat   c   tupl deriv tupl insert least timestamp  4   7 ', 'quantifi repres ordinari opinion sentenc  comput  support valu  extract ordinari opinion sentenc ', 0.18373108117049072], ['conceptu model structur', 'sinc expert review well written  keep origin form leverag structur organ ordinari opinion extract text ', 0.18253221396874292], ['predic languag 2 aqualset    aqual    aqual   andor   aqualset  cqualset    cqual    cqual   andor   cqualset  squalset    squal    squal   andor   squalset  aqual   action   constant   action  queri  user   constant   time  ccmp   constant  cqual   dataset  ccmp   constant   valu  ccmp   constant   expir squal   name  ccmp   constant  compon   tupl  attribut  valu ccmp           18', 'cluster  get partit p   p1    p l  l  p c c constant paramet defin averag number sentenc cluster ', 0.18124497942096626], ['start point  proven graph', 'could start larg σj  say 5000   ie  start perfectli align opinion model  gradual decay em iter equat 7  stop decay σ j weight prior µ j threshold δ  say 05  ', 0.17844860530086995], ['current model fall short  2 proven store string annot data  queri proven must pars string use particular system proven store one gener time  queri must written recurs  trace proven multipl prior queri', 'achiev use repres opinion queri retriev sentenc r ', 0.17768168310615107], ['overview research conceptu model logic model exist platform  user view data  proven  simpl  familiar languag  data prov ', 'paper  use weblog data  method appli kind data contain opinion free text ', 0.17604079745577958], ['overview research conceptu model logic model exist platform  user view data  proven  simpl  familiar languag  data prov ', 'paper  use weblog data  method appli kind data contain opinion free text ', 0.17604079745577958], ['overview research conceptu model logic model exist platform  user view data  proven  simpl  familiar languag  data prov ', 'paper  use weblog data  method appli kind data contain opinion free text ', 0.17604079745577958], ['oper delet data provenanc ', 'paper  use weblog data  method appli kind data contain opinion free text ', 0.1734642775717208], ['simpl languag select data base proven ', 'intuit  prior defin base expert review segment would tend make correspond languag model similar empir word distribut review segment  thu languag model would tend attract opinion sentenc c similar expert review segment ', 0.17235577028413485], ['languag extract proven ', 'sinc ordinari opinion tend redund primarili interest extract repres opinion  support use assess repres extract opinion ', 0.1629701224274203], ['select  r  tupl path  oper action   insert time    4  time   7  ', 'last year  mei other propos mixtur model model facet opinion time  11  ', 0.15758578413838115], ['name id bob 8  9 sue 7 trust peopl deriv ', ' support13  cisco own trademark name  iphon  sinc 2000  acquir infogear technolog corp  origin regist name ', 0.15677650236815685], ['mmp trio proven select languag compar', 'one repres sentenc p select similar sentenc cluster centroid  ie ', 0.14523266919534952], ['implement feasibl identifi proven graph search oper  start point queri specifi input relat predic specifi tupl  attribut  valu encod predic graphql pattern tupl attribut select output least one relev proven graph select graphql', 'first select 5 review aspect 14 method identifi similar supplementari opinion  5 aspect  mix one similar opinion sever supplementari opinion  user suppos select one sentenc share similar opinion review aspect ', 0.14403820897693073], ['work progress conceptu model formal subset algebra structur compar express compar queri complex closur properti proof intermodel map logic model openend access via queri languag implement feasibl perform tradeoff studi 25', 'achiev use repres opinion queri retriev sentenc r ', 0.13534979008281803], ['simpl proven queri goal  enabl select data proven approach  predic languag describ characterist proven path select project oper declar  procedur', 'one repres sentenc p select similar sentenc cluster centroid  ie ', 0.13330386517192921], ['trust order deriv ', 'order appli kind model integr problem  assum review segment correspond unigram languag model would captur opinion align review segment ', 0.1324799192801085], ['current model fall short1 proven limit singl histori singl granular  mostli  queri dml   mostli  model store proven schema data annot store extra attribut creat clutter  requir special care prevent corrupt queri 5', 'achiev use repres opinion queri retriev sentenc r ', 0.1183258863100576], ['conceptu model predic languag data select project base proven david w archer loi l delcambr depart comput scienc portland state univers', 'map estim comput use essenti em algorithm present slightli differ updat formula compon languag model ', 0.11127405999326433], ['predic languag 1 selectionpred   tupl  predicatequalifi   data valu tupl  predicatequalifi   valu attribut  list  tupl  predicatequalifi  projectionpred   attribut  predicatequalifi   data valu attribut  predicatequalifi  predicatequalifi   path   pathqualifi    path   pathqualifi    andor   predicatequalifi  pathqualifi    compon     cqualset    oper   aqualset    sourc   squalset    pathqualifi    pathqualifi   beforeandor   pathqualifi   must agre compon type specifi selectionpred projectionpred', 'need two type data set evalu ', 0.0749176093746606], ['proven represent b c 1 5 8 tupl id b c  ac  r  r   r  c r  proven represent c lineag trio green 1 8   c        c   2a  ac 2a2  ac e 1 9   b  c    c     c    b  c   2c  ac  bc 2c2  ac  bc f 3 9  b  c    b    b  c   2b  bc 2b2  bc note  edg may includ queri  dml  ddl  dcl  order oper also evid ra rc rb sd se sf 28', 'note randomli ', 0.06724557715326761], ['simpl nonfirst normal relat ye ye ye ye ddl  dml  queri  confirmdoubt ye ye logic model conceptu model 27', 'topic model  gener idea use unigram languag model  ie  multinomi word distribut  model topic ', 0.06309365730153015], ['backup materi', 'web 20 applic becom increasingli popular  peopl express opinion web variou way custom review  forum  discuss group  weblog ', 0.0], ['multigener proven ', 'web 20 applic becom increasingli popular  peopl express opinion web variou way custom review  forum  discuss group  weblog ', 0.0], ['multigranular proven ', 'web 20 applic becom increasingli popular  peopl express opinion web variou way custom review  forum  discuss group  weblog ', 0.0], ['multihistori proven ', 'web 20 applic becom increasingli popular  peopl express opinion web variou way custom review  forum  discuss group  weblog ', 0.0], ['reinsert connect ', 'web 20 applic becom increasingli popular  peopl express opinion web variou way custom review  forum  discuss group  weblog ', 0.0]], [['wwwopensolarisorgosprojectcrossbow 6 pseudo mac instanc  manag physic nic  per vnic stat  reus exist manag tool  link speed deriv configur bandwidth limit  highavail creat vnic link aggreg combin vnic ipmp group dedic pervnic hardwar kernel resourc data path passthrough  bump stack standard base endtoend network virtual  vlan tag prioriti flow control  pfc  assign vnic extend hardwar lane switch crossbow virtual nic  vnic ', 'link assign fresh  ', 0.17609483571567527], ['wwwopensolarisorgosprojectcrossbow 7 crossbow virtual switch virtual switch creat implicitli time  2 vnic creat data link mac layer provid packet switch semant equival ethernet switch  data path vnic creat top data link  connect vnic physic network  per vlan broadcast domain  isol vlan vnic creat etherstub creat virtual switch independ hardwar', 'sideeffect permit object creat within librari method  provid escap ', 0.1650499834249432], ['wwwopensolarisorgosprojectcrossbow 10 physic wire wphysic machin client router virtual wire wvirtual network machin host 1 host 2 port 6 20003 port 9 20001 port 3 10003 port 1 10001 port 2 10002 switch 3 switch 1 client router  virtual router  vnic6 20003 vnic9 20001 vnic3 10003 vnic1 10001 vnic2 10002 etherstub 3 etherstub 1 host 1 host 2', 'use help port java program dpj languag write safe parallel program  16  ', 0.14269442254123854], ['wwwopensolarisorgosprojectcrossbow 12 crossbow flow crossbow flow base follow attribut  servic  protocol  remoteloc port   transport  tcp  udp  sctp  iscsi  etc   ip address ip subnet  dscp label follow properti set flow  bandwidth limit  prioriti  cpu  flowadm createflow l bge0 protocoltcp  local_port443 p maxbw50m http1  flowadm setflowprop l bge0 p maxbw100m http1', 'analysi track flow method  manner similar intraprocedur pointer analysi ', 0.1351222372085743], ['wwwopensolarisorgosprojectcrossbow 9 virtual nic  virtual switch usag  dladm createvn l bge1 vnic1  dladm createvn l bge1 random p maxbw100m p cpus456 vnic2  dladm createetherstub vswitch1  dladm showetherstub link vswitch1  dladm createvn l vswitch1 p maxbw1000m vnic3  dladm showvnic link mactyp macvalu bandwidth cpu vnic1 bge1 factori 012345  vnic2 bge1 random 256789 max100m 456 vnic3 vswitch1 random 434701 max1000m  dladm createvn l ixgbe0 v 1055 p maxbw500m p cpus12 vnic9', 'link assign fresh  ', 0.10828929729251476], ['wwwopensolarisorgosprojectcrossbow 8 crossbow virtual switch exampl nonglob zone ng0 nonglob zone ng1 virtual machin vnic0 vnic1 vnic2 vnic3 bge0 ip filter nat virtual switch global zone solari host', 'exampl ', 0.10683751369083988], ['wwwopensolarisorgosprojectcrossbow 2 key issu network virtual fair polici base resourc share virtual environ  bandwidth  nic hardwar resourc includ rxtx descriptor  process cpu overhead due virtual  latenc  throughput manag  isol distribut applic  network fabric configur secur  new threat l2 network solv problem ', ' problem ', 0.10123738917236401], ['wwwopensolarisorgosprojectcrossbow 3 crossbow  solari network stack 8 year develop work achiev  scalabl across multicor cpu multi10gig bandwidth  virtual  qo  highavail design  exploit advanc nic featur key enabl  server network consolid  open network  cloud comput', 'rountev system design work incomplet program  26  ', 0.09942121334666966], ['wwwopensolarisorgosprojectcrossbow 5 hardwar lane dynam poll partit nic hardwar  rxtx ring  dma   kernel queuesthread  cpu allow creation hardwar lane assign vnic  flow use dynam poll rxtx ring schedul rate packet arriv transmiss per lane basi effect dynam poll mpstat  older driver  intr ithr csw icsw migr smtx srw syscl usr sy wt idl 10818 8607 4558 1547 161 1797 289 19112 17 69 0 12 mpstat  gldv3 base driver  intr ithr csw icsw migr smtx srw syscl usr sy wt idl 2823 1489 875 151 93 261 1 19825 15 57 0 27 75  fewer interrupt 85  fewer mutex 85  fewer ctx switch 15  cpu free', 'assign data line 15 permit rule  1  ', 0.08655706496813262], ['wwwopensolarisorgosprojectcrossbow 13 join us  beer  crossbow solari network bof  tonight 10301130pm  dover  b   present ben rockwood  joyent   vwire demo deepdiv discuss opensolari project commun  http  wwwopensolarisorgosprojectcrossbow  crossbowdiscuss  opensolarisorg  networkingdiscuss  opensolarisorg', 'let us recal first problem encount simpl puriti system  discuss 23  show method pure definit 1 requir two guarante ', 0.073955292720883], ['wwwopensolarisorgosprojectcrossbow 11 virtual network machin virtual network machin  vnm  zone virtual machin associ set network function  rout  firewal  load balanc  etc  vnm dedic vnic   configur link speed  cpu multipl vnm run singl host  connect virtual privat network  etherstub  physic network use simul  consolid  test  etc', 'link assign fresh  ', 0.07066718130317236], ['wwwopensolarisorgosprojectcrossbow 4 crossbow hardwar lane groundup design multicor multi10gig linear scalabl use hardwar lane  dedic resourc network virtual qo design stack effici due dynam poll packet chain  physic machinephys nic hardwar lane c l f e r virtual nic hardwar ringsdma kernel thread queue virtual nic kernel thread queue squeue hardwar ringsdma kernel thread queue virtual machinezon virtual machinezon applic switch vlan separ hardwar ringsdma', 'sinc determin use static type inform  may actual method invok  due dynam dispatch  ', 0.05962685912097255], ['nicola droux  senior staff engin solari kernel network  sun microsystem inc nicolasdroux  suncom crossbow virtual wire  network box novemb 5th  2009 usenix lisa 09  baltimor  md sunay tripathi  nicola droux  kai belgai  shrikrishna khare', 'start consid simpl puriti system surprisingli effect practic  crucial  employ modularli checkabl annot ', 0.0], [' switch  l3l4 devic  host', 'start consid simpl puriti system surprisingli effect practic  crucial  employ modularli checkabl annot ', 0.0], ['nicola droux nicolasdroux  suncom solari kernel network crossbow virtual wire  network box', 'start consid simpl puriti system surprisingli effect practic  crucial  employ modularli checkabl annot ', 0.0]]]\n"
     ]
    }
   ],
   "source": [
    "print(len(presentation_paper_pairs))\n",
    "print(presentation_paper_pairs[:3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "average_similarity = []\n",
    "for sentence_pairs in presentation_paper_pairs:\n",
    "    similarity_score_sum = sum(pair[2] for pair in sentence_pairs)\n",
    "    similarity_score_average = similarity_score_sum / len(sentence_pairs)\n",
    "    average_similarity.append(similarity_score_average)\n",
    "\n",
    "print(average_similarity[:5])\n",
    "\n",
    "print(sum(average for average in average_similarity) / len(average_similarity))\n"
   ],
   "metadata": {
    "id": "j8AdV2bqdb4Q",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:38:28.710189Z",
     "start_time": "2024-04-10T00:38:28.611339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10473271582810344, 0.1626123030226938, 0.08837021936706536, 0.08777198569090229, 0.15362456899990776]\n",
      "0.12297329954399107\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presentation sentences for pair 1 : ['thank ', 'futur work debug tool develop run older newer version file system compar result older version file system repair simpl repair  copi data file system complex repair  recreat en file system tree micro repair ', 'hard work alreadi done us 30 differ disk base file system linux 26 file system use ', 'subsist  singl instanc store variant singl instanc store selecv merg data block block address si export virtual disk fse manag map  free space info ', 'corrupon data singl fs due bug  bit flip  storag stack corrupt data block merg n1 data block merg corrupt data block fix next read corrupon data block insid disk singl copi data differ code path differ ondisk structur envyf layer fs 2 fs n applicaon vf layer vdisk 1 vdisk 2 vdisk n read cach chash layer free space manag su b si st', 'summari result robust tradion file system vulner corrupon envyfs3 toler almost mistak one fs perform desktop workload  envyfs3 compar perform io intens workload  regular operaon  envyfs3  subsist accept perform memori pressur  envyfs3  subsist larg overhead', 'ext3 jf reiserf envyf envyfssi experiment setup amd opteron 22 ghz processor 2gb ram 80 gb hitachi deskstar 7200rpm sata disk linux 2612 4gb disk par  file system openssh benchmark perform evaluaon el ap se im e  ec n  file system cpu intens openssh 45 copi  untar make perform envyfs3 compar singl file system', 'file 1  36 imprecis vf specificaon  cont  inod number allocaon inod number return system call child file system issu differ inod number possibl soluon  forc file system use algorithm ', 'result robust tradion file system handl corrupon   4   envyfs3 toler 989  singl file system mistak perform desktop workload  envyfs3 compar perform io intens workload  normal mode  envyfs3  subsist accept perform memori pressur  envyfs3  subsist larg overhead poten debug tool fs develop pinpoint sourc failsil bug ext3', 'impracc  requir wide scale chang file system specificaon take year get accept leverag exisng specificaon ', 'ext3  jf  reiserf threevers fs other work without modificaon', 'disk b b b envyf layer block driver b reliabl evaluaon  fault injecon corrupon  bug fs  storag stack type disk block superblock  inod  block bitmap  file data  perform differ file op mount  stat  creat  unlink  read  report user visibl result result applic subsist except corruphon data block ex 3 jf r ei se rf pseudo devic driver vf b b b b typeawar fault injechon  prabhakaran05 ', 'base nversion program  avizienis77  nf server  rodrigues01   databas  vandiver07   secur  cox06  nversion file system envyf  simpl solwar layer store data n child file system operaon perform children reli simpl sowar layer challeng  reduc overhead retain reliabl subsist  novel singl instanc store envyf layer c h ild 1 c h ild 2 c h ild n disk driver disk si layer applicaon', 'bug inevit file system challeng  cope ', 'fs 1 disk handl data block corrupon ', 'file system today world modern file system complex ten thousand line code  eg  xf 45k loc  storag stack also gevng deeper hypervisor  network  logic volum manag need handl gamut failur memori allocaon  disk fault  bit flip  system crash preserv integr metadata user data', 'file system bug bug report linux 26 seri bugzilla ext3  64  jf  17  reiserf  38 fs corrupon caus perman data loss fs bug broadli classifi two categori failstop  system immedi crash soluon  nook  swi 04   curio  david08  failsil  accident corrupt ondisk state mani bug uncov  prabhakaran05  gunawi08  yang04  yang06b ', 'persist store disk envyf write n file system n data block merg 1 data block content hash store persist metadata block merg inter fs block intra fs envyf layer fs 1 fs 2 fs n applicaon vf layer vdisk 1 disk vdisk 2 vdisk n read cach chash layer free space manag su b si st', 'pain process high cost develop  long delay lucki ', 'outlin introducon build reliabl file system reduc overhead subsist evaluahon reliabl perform conclus', 'robust envyf recov child file system mistak ', 'poten bug isolaon ext3 envyfs3 ti e unlink corrupt inod  ext3_lookup  bug  ext3_unlink unmount  panic  ti e unlink corrupt inod  ext3_lookup  bug  ext3 inod match other op issu typic use  problem noce panic envyfs3  problem noce first child file system return wrong result', 'ext3 p h ra rs al se 1  ta   se 2  c h  ad ad lin k ge td ir en tr ie cr ea lin k kd ir n e sy lin k w ri te tr u n ca te rm ir u n lin k u n se 3  f sy n c  u u n inod dir bmap imap indirect data super jsuper gdesc data loss na mount op fail crash addion operaon fail  inod corrupon lead data loss unlink  system crash unmount e', 'jf p h ra rs al se 1 se 2 ad ad lin k ge td ir en tr ie cr ea lin k kd ir n e sy lin k w ri te tr u n ca te rm ir u n lin k u n se 3 u u n inod dir bmap imap intern data super jsuper jdata aggrinod imapdesc imapcntl normal data loss na mount op fail data corrupt crash readonli depend j', 'ext3 p h ra rs al se 1  ta   se 2  c h  ad ad lin k ge td ir en tr ie cr ea lin k kd ir n e sy lin k w ri te tr u n ca te rm ir u n lin k u n se 3  f sy n c  u u n inod dir bmap imap indirect data super jsuper gdesc normal data loss na mount op fail data corrupt crash readonli e depend e', 'advanc system lab  adsl  univers wisconsinmadison hxp  wwwcswisceduadsl', 'ext3 p h ra rs al se 1  ta   se 2  c h  ad ad lin k ge td ir en tr ie cr ea lin k kd ir n e sy lin k w ri te tr u n ca te rm ir u n lin k u n se 3  f sy n c  u u n inod dir bmap imap indirect data super jsuper gdesc result matrix normal data loss na mount op fail data corrupt crash readonli e depend e', 'outlin introducon build reliabl file system reduc overhead subsist evaluaon conclus', 'outlin introducon build reliabl file system reduc overhead subsist evaluaon conclus', 'outlin introducon build reliabl file system reduc overhead subsist evaluaon conclus', 'ext3 p h ra rs al se 1  ta   se 2  c h  ad ad lin k ge td ir en tr ie cr ea lin k kd ir n e sy lin k w ri te tr u n ca te rm ir u n lin k u n se 3  f sy n c  u u n inod dir bmap imap indirect data super jsuper gdesc data loss na readonli ext3 detect corrupon rmdir  unlink creat  mkdir  symlink caus ext3 reus inod  resulng data loss e', 'conclus bugsmistak inevit solwar must cope  hope avoid envyf  nversion approach tolerang fs bug built use exisng specificaon file system subsist  singl instanc store decreas overhead retain reliabl', 'ye  leverag vf  issu vf precis nversion purpos need handl case specificaon precis eg  order directori entri  inod number allocaon', 'nversion layer  envyf  insert beneath vf simpl design avoid bug exampl  read file alloc n data buffer read data block disk compar  data  return code  file posion return  data  return code issu  alloc memori read operaon extra copi alloc buffer applicaon comparison overhead compar wrapper inod map tabl applicaon vf layer ex t3 jf r ei se rf envyf layer read  file  1 block  read  file  1 block  read   read   read   f f f po  x po  x po  x err  err  err  disk err  err  tolerang filesystem mistak envyf', 'nversion system develop process  1 produc specificaon solwar 2 implemenng n version solwar 3 creang nversion layer execut differ version determin consensu result', 'envyfs3 p h ra rs al se 1 se 2 ad ad lin k ge td ir en tr ie cr ea lin k kd ir n e sy lin k w ri te tr u n ca te rm ir u n lin k u n se 3 u u n inod dir bmap imap intern data super jsuper jdata aggrinod imapdesc imapcntl normal na crash kernel panic envyfs3 e r j envyf', 'imprecis vf specificaon order directori entri issu  specifi return order cant blindli compar entri soluon  read entri directori  dir  test case  fse match entri fse return major result fs x fs fs z envyf layer file 1 file 2 file 3 dir  test file 2 file 3 file 1 dir  test dir  test file 1 file 2 file 3 readdir  test entri file 3 file 1 file 2 file 1 file 2 file 3 file 1 file 2 file 3 dir  test', 'ext3 p h ra rs al se 1  ta   se 2  c h  ad ad lin k ge td ir en tr ie cr ea lin k kd ir n e sy lin k w ri te tr u n ca te rm ir u n lin k u n se 3  f sy n c  u u n inod dir bmap imap indirect data super jsuper gdesc data loss na mount ext3 store mani superblock copi   handl superblock corrupon e', 'kernel panic ext3 p h ra rs al se 1  ta   se 2  c h  ad ad lin k ge td ir en tr ie cr ea lin k kd ir n e sy lin k w ri te tr u n ca te rm ir u n lin k u n se 3  f sy n c  u u n normal na inod dir bmap imap indirect data super jsuper gdesc envyfs3 work everi scenario 61809 tolerang filesystem mistak envyf 25 envyfs3 e r j envyf', 'postmark10k postmark100k postmark100k  ext3 jf reiserf envyf envyfssi io intens mimic busi mail server workload transacon  creat  delet  read  append  postmark configuraon 2500 file file size  4kb 40kb ', 'read file envyf soluon  applicaon buffer fs tcplike checksum data comparison compar  checksum  return code  file posion read data un  l major compar wrapper inod map tabl applicaon vf layer ex t3 jf r ei se rf envyf layer read  file  1 block  read  file  1 block  read   read   f f f po  x po  x err  err  err  fs 1  fs 2  fs n  checksum disk err  err  read   po  x', 'part 1 part 2 part n disk 1 disk 2 disk n disk case singl instanc storag  si  ideal  one disk per fs praccal  one disk fs overhead effec storag space  1n n me io  readwrit  challeng  maintain divers minim overhead envyf layer fs 1 fs 2 fs n applicaon vf layer disk req ', 'soluon  issu inod number envyf layer fs x fs fs z envyf layer dir  test dir  test dir  test file 1  10 file 1 65 file 1 10 file 2 15 file 3 16 file 2 04 file 3 44 file 1 36 file 1  inod map tabl file 3 99 file 1 65 file 2 43 inod number inod map tabl persist store', 'tolerang filesystem mistak envyf lakshmi n bairavasundaram netapp  inc swaminathan sundararaman andrea c arpacidusseau remzi h arpacidusseau univers wisconsin madison', 'virt  fs 1 fs 3 fs 2 ', '', 'queue', 'transacon  10k 100k postmark benchmark el ap se im e  ec n  envyfs3  8x  subsist  4x envyfs3  17x  subsist  115 ']\n",
      "\n",
      "Paper sentences for pair 1 : ['3 thank adam paul suggest featur class ', 'compar two system use treetotre grammar ', 'compar two system use treetotre grammar ', ' x n singl substitut site x 1      x n ', 'system train use mira  crammer singer  2003  chiang et al  2009  tune set 3000 sentenc newswir nist mt evalu data gale develop data  disjoint train data ', 'fuzzi treetotre extract perform use analog constraint ', 'compar two system use treetotre grammar ', 'compar two system use treetotre grammar ', 'fuzzi treetotre extract perform use analog constraint ', 'phrase pair  accept cross previous accept phrase pair  otherwis  reject ', 'system use glue rule  chiang  2005   allow decod  work bottomup  stop build hierarch structur instead concaten partial translat without reorder ', ' 2006   systemat studi  find  sentenc treetotre constraint block rule extract  major due parser error ', ' use simpl heurist ', 'paper  explor reason treetotre translat challeng  sourc syntax target syntax might use togeth ', 'system train use mira  crammer singer  2003  chiang et al  2009  tune set 3000 sentenc newswir nist mt evalu data gale develop data  disjoint train data ', 'compar two system use treetotre grammar ', 'compar two system use treetotre grammar ', ' 2006   systemat studi  find  sentenc treetotre constraint block rule extract  major due parser error ', 'tabl 3 show score develop set test set  3000 2000 sentenc  respect  newswir drawn nist mt evalu data gale develop data disjoint tune data ', 'first  tabl 4 show system use treetotre grammar use glue rule much less perform match substitut ', 'compar two system use treetotre grammar ', 'address problem  liu et al ', 'system train use mira  crammer singer  2003  chiang et al  2009  tune set 3000 sentenc newswir nist mt evalu data gale develop data  disjoint train data ', 'system train use mira  crammer singer  2003  chiang et al  2009  tune set 3000 sentenc newswir nist mt evalu data gale develop data  disjoint train data ', 'system train use mira  crammer singer  2003  chiang et al  2009  tune set 3000 sentenc newswir nist mt evalu data gale develop data  disjoint train data ', 'compar two system use treetotre grammar ', 'system train use mira  crammer singer  2003  chiang et al  2009  tune set 3000 sentenc newswir nist mt evalu data gale develop data  disjoint train data ', 'system use glue rule  chiang  2005   allow decod  work bottomup  stop build hierarch structur instead concaten partial translat without reorder ', 'system use glue rule  chiang  2005   allow decod  work bottomup  stop build hierarch structur instead concaten partial translat without reorder ', 'system use glue rule  chiang  2005   allow decod  work bottomup  stop build hierarch structur instead concaten partial translat without reorder ', 'system train use mira  crammer singer  2003  chiang et al  2009  tune set 3000 sentenc newswir nist mt evalu data gale develop data  disjoint train data ', ' x n singl substitut site x 1      x n ', 'case may want soften match constraint ', 'tabl 3 show score develop set test set  3000 2000 sentenc  respect  newswir drawn nist mt evalu data gale develop data disjoint tune data ', 'heurist produc set nest phrase  repres singl restructur tree ', 'system baselin  featur describ section 3 ad ', 'use exact treetotre extract  got much smaller grammar  decreas accuraci chineseenglish test set  signific chang ', 'system baselin  featur describ section 3 ad ', 'system baselin  featur describ section 3 ad ', 'size parallel text use shown tabl 2 ', 'compar two system use treetotre grammar ', 'figur 2  observ flat structur chines ip prevent exact treetotre extract extract rule contain part ip  exampl ', 'use exact treetotre extract  got much smaller grammar  decreas accuraci chineseenglish test set  signific chang ', 'statist translat model use synchron contextfre grammar  scfg  relat formal tri captur recurs structur languag wide adopt last year ', 'statist translat model use synchron contextfre grammar  scfg  relat formal tri captur recurs structur languag wide adopt last year ', 'statist translat model use synchron contextfre grammar  scfg  relat formal tri captur recurs structur languag wide adopt last year ', 'statist translat model use synchron contextfre grammar  scfg  relat formal tri captur recurs structur languag wide adopt last year ', 'statist translat model use synchron contextfre grammar  scfg  relat formal tri captur recurs structur languag wide adopt last year ']\n",
      "\n",
      "Presentation sentences for pair 2 : ['tupl contain data deriv relat   later appear relat  c ', 'topic motiv conceptu model predic languag evalu', 'data curat set finegrain data multipl sourc integr  queri  updat manipul evolv schema instanc multipl histori includ manipul queri multipl valu attribut user express confid doubt exampl set intellig  profil person interest militari  oper risk assess escienc  bioinformat databas 3', 'know sourc    data came ', 'idea  new predic  new  fullfeatur proven queri languag normal relat algebra oper front face new predic enabl select project base proven', 'summari mmp differ data structur orthogon proven data ', 'process method use deriv data  improv chang ', 'select  r  tupl path  sourc name  x   tupl r least one data valu deriv relat   relat  b ', 'select  r  data valu tupl path  valu relat    path  valu relat   b  ', 'curat data trustworthi ', 'key conceptu model featur relat data multivalu attribut multilay multiproven oper queri  dml  ddl data confid languag  dcl  distinct proven dataset  attribut  entiti  valu delet data proven retain  insert connect prior delet multipl histori data', 'exampl queri tupl relat r deriv sourc  x ', 'access  track proven  keep manag user hand  transit layer implement  perform  full access proven map map', 'motiv conceptu model predic languag evalu', 'motiv conceptu model predic languag evalu', 'motiv conceptu model predic languag evalu', 'access  track proven  keep manag user hand  transit layer implement  perform  full access proven map map focu paper', 'access  track proven  keep manag user hand  transit layer implement  perform  full access proven map map focu paper', 'select  r  data valu tupl path  valu relat   valu relat   c   tupl deriv tupl insert least timestamp  4   7 ', 'conceptu model structur', 'predic languag 2 aqualset    aqual    aqual   andor   aqualset  cqualset    cqual    cqual   andor   cqualset  squalset    squal    squal   andor   squalset  aqual   action   constant   action  queri  user   constant   time  ccmp   constant  cqual   dataset  ccmp   constant   valu  ccmp   constant   expir squal   name  ccmp   constant  compon   tupl  attribut  valu ccmp           18', 'start point  proven graph', 'current model fall short  2 proven store string annot data  queri proven must pars string use particular system proven store one gener time  queri must written recurs  trace proven multipl prior queri', 'overview research conceptu model logic model exist platform  user view data  proven  simpl  familiar languag  data prov ', 'overview research conceptu model logic model exist platform  user view data  proven  simpl  familiar languag  data prov ', 'overview research conceptu model logic model exist platform  user view data  proven  simpl  familiar languag  data prov ', 'oper delet data provenanc ', 'simpl languag select data base proven ', 'languag extract proven ', 'select  r  tupl path  oper action   insert time    4  time   7  ', 'name id bob 8  9 sue 7 trust peopl deriv ', 'mmp trio proven select languag compar', 'implement feasibl identifi proven graph search oper  start point queri specifi input relat predic specifi tupl  attribut  valu encod predic graphql pattern tupl attribut select output least one relev proven graph select graphql', 'work progress conceptu model formal subset algebra structur compar express compar queri complex closur properti proof intermodel map logic model openend access via queri languag implement feasibl perform tradeoff studi 25', 'simpl proven queri goal  enabl select data proven approach  predic languag describ characterist proven path select project oper declar  procedur', 'trust order deriv ', 'current model fall short1 proven limit singl histori singl granular  mostli  queri dml   mostli  model store proven schema data annot store extra attribut creat clutter  requir special care prevent corrupt queri 5', 'conceptu model predic languag data select project base proven david w archer loi l delcambr depart comput scienc portland state univers', 'predic languag 1 selectionpred   tupl  predicatequalifi   data valu tupl  predicatequalifi   valu attribut  list  tupl  predicatequalifi  projectionpred   attribut  predicatequalifi   data valu attribut  predicatequalifi  predicatequalifi   path   pathqualifi    path   pathqualifi    andor   predicatequalifi  pathqualifi    compon     cqualset    oper   aqualset    sourc   squalset    pathqualifi    pathqualifi   beforeandor   pathqualifi   must agre compon type specifi selectionpred projectionpred', 'proven represent b c 1 5 8 tupl id b c  ac  r  r   r  c r  proven represent c lineag trio green 1 8   c        c   2a  ac 2a2  ac e 1 9   b  c    c     c    b  c   2c  ac  bc 2c2  ac  bc f 3 9  b  c    b    b  c   2b  bc 2b2  bc note  edg may includ queri  dml  ddl  dcl  order oper also evid ra rc rb sd se sf 28', 'simpl nonfirst normal relat ye ye ye ye ddl  dml  queri  confirmdoubt ye ye logic model conceptu model 27', 'backup materi', 'multigener proven ', 'multigranular proven ', 'multihistori proven ', 'reinsert connect ']\n",
      "\n",
      "Paper sentences for pair 2 : ['type data set opinion sentenc relat certain topic ', 'topic model  gener idea use unigram languag model  ie  multinomi word distribut  model topic ', 'order identifi multipl topic text  would fit mixtur model involv multipl multinomi distribut text data tri figur set paramet multipl word distribut maxim likelihood text data ', 'know equat 11', 'defin new problem opinion integr ', 'paper  use weblog data  method appli kind data contain opinion free text ', 'paper  use weblog data  method appli kind data contain opinion free text ', 'type data set opinion sentenc relat certain topic ', 'quantifi repres ordinari opinion sentenc  comput  support valu  extract ordinari opinion sentenc ', 'paper  use weblog data  method appli kind data contain opinion free text ', 'paper  use weblog data  method appli kind data contain opinion free text ', 'howev  larg scale inform sourc  quit challeng user integr digest opinion differ sourc ', 'expert opinion rel easi user access opinion search websit cnet ', 'topic model  gener idea use unigram languag model  ie  multinomi word distribut  model topic ', 'topic model  gener idea use unigram languag model  ie  multinomi word distribut  model topic ', 'topic model  gener idea use unigram languag model  ie  multinomi word distribut  model topic ', 'expert opinion rel easi user access opinion search websit cnet ', 'expert opinion rel easi user access opinion search websit cnet ', 'quantifi repres ordinari opinion sentenc  comput  support valu  extract ordinari opinion sentenc ', 'sinc expert review well written  keep origin form leverag structur organ ordinari opinion extract text ', 'cluster  get partit p   p1    p l  l  p c c constant paramet defin averag number sentenc cluster ', 'could start larg σj  say 5000   ie  start perfectli align opinion model  gradual decay em iter equat 7  stop decay σ j weight prior µ j threshold δ  say 05  ', 'achiev use repres opinion queri retriev sentenc r ', 'paper  use weblog data  method appli kind data contain opinion free text ', 'paper  use weblog data  method appli kind data contain opinion free text ', 'paper  use weblog data  method appli kind data contain opinion free text ', 'paper  use weblog data  method appli kind data contain opinion free text ', 'intuit  prior defin base expert review segment would tend make correspond languag model similar empir word distribut review segment  thu languag model would tend attract opinion sentenc c similar expert review segment ', 'sinc ordinari opinion tend redund primarili interest extract repres opinion  support use assess repres extract opinion ', 'last year  mei other propos mixtur model model facet opinion time  11  ', ' support13  cisco own trademark name  iphon  sinc 2000  acquir infogear technolog corp  origin regist name ', 'one repres sentenc p select similar sentenc cluster centroid  ie ', 'first select 5 review aspect 14 method identifi similar supplementari opinion  5 aspect  mix one similar opinion sever supplementari opinion  user suppos select one sentenc share similar opinion review aspect ', 'achiev use repres opinion queri retriev sentenc r ', 'one repres sentenc p select similar sentenc cluster centroid  ie ', 'order appli kind model integr problem  assum review segment correspond unigram languag model would captur opinion align review segment ', 'achiev use repres opinion queri retriev sentenc r ', 'map estim comput use essenti em algorithm present slightli differ updat formula compon languag model ', 'need two type data set evalu ', 'note randomli ', 'topic model  gener idea use unigram languag model  ie  multinomi word distribut  model topic ', 'web 20 applic becom increasingli popular  peopl express opinion web variou way custom review  forum  discuss group  weblog ', 'web 20 applic becom increasingli popular  peopl express opinion web variou way custom review  forum  discuss group  weblog ', 'web 20 applic becom increasingli popular  peopl express opinion web variou way custom review  forum  discuss group  weblog ', 'web 20 applic becom increasingli popular  peopl express opinion web variou way custom review  forum  discuss group  weblog ', 'web 20 applic becom increasingli popular  peopl express opinion web variou way custom review  forum  discuss group  weblog ']\n",
      "\n",
      "Presentation sentences for pair 3 : ['wwwopensolarisorgosprojectcrossbow 6 pseudo mac instanc  manag physic nic  per vnic stat  reus exist manag tool  link speed deriv configur bandwidth limit  highavail creat vnic link aggreg combin vnic ipmp group dedic pervnic hardwar kernel resourc data path passthrough  bump stack standard base endtoend network virtual  vlan tag prioriti flow control  pfc  assign vnic extend hardwar lane switch crossbow virtual nic  vnic ', 'wwwopensolarisorgosprojectcrossbow 7 crossbow virtual switch virtual switch creat implicitli time  2 vnic creat data link mac layer provid packet switch semant equival ethernet switch  data path vnic creat top data link  connect vnic physic network  per vlan broadcast domain  isol vlan vnic creat etherstub creat virtual switch independ hardwar', 'wwwopensolarisorgosprojectcrossbow 10 physic wire wphysic machin client router virtual wire wvirtual network machin host 1 host 2 port 6 20003 port 9 20001 port 3 10003 port 1 10001 port 2 10002 switch 3 switch 1 client router  virtual router  vnic6 20003 vnic9 20001 vnic3 10003 vnic1 10001 vnic2 10002 etherstub 3 etherstub 1 host 1 host 2', 'wwwopensolarisorgosprojectcrossbow 12 crossbow flow crossbow flow base follow attribut  servic  protocol  remoteloc port   transport  tcp  udp  sctp  iscsi  etc   ip address ip subnet  dscp label follow properti set flow  bandwidth limit  prioriti  cpu  flowadm createflow l bge0 protocoltcp  local_port443 p maxbw50m http1  flowadm setflowprop l bge0 p maxbw100m http1', 'wwwopensolarisorgosprojectcrossbow 9 virtual nic  virtual switch usag  dladm createvn l bge1 vnic1  dladm createvn l bge1 random p maxbw100m p cpus456 vnic2  dladm createetherstub vswitch1  dladm showetherstub link vswitch1  dladm createvn l vswitch1 p maxbw1000m vnic3  dladm showvnic link mactyp macvalu bandwidth cpu vnic1 bge1 factori 012345  vnic2 bge1 random 256789 max100m 456 vnic3 vswitch1 random 434701 max1000m  dladm createvn l ixgbe0 v 1055 p maxbw500m p cpus12 vnic9', 'wwwopensolarisorgosprojectcrossbow 8 crossbow virtual switch exampl nonglob zone ng0 nonglob zone ng1 virtual machin vnic0 vnic1 vnic2 vnic3 bge0 ip filter nat virtual switch global zone solari host', 'wwwopensolarisorgosprojectcrossbow 2 key issu network virtual fair polici base resourc share virtual environ  bandwidth  nic hardwar resourc includ rxtx descriptor  process cpu overhead due virtual  latenc  throughput manag  isol distribut applic  network fabric configur secur  new threat l2 network solv problem ', 'wwwopensolarisorgosprojectcrossbow 3 crossbow  solari network stack 8 year develop work achiev  scalabl across multicor cpu multi10gig bandwidth  virtual  qo  highavail design  exploit advanc nic featur key enabl  server network consolid  open network  cloud comput', 'wwwopensolarisorgosprojectcrossbow 5 hardwar lane dynam poll partit nic hardwar  rxtx ring  dma   kernel queuesthread  cpu allow creation hardwar lane assign vnic  flow use dynam poll rxtx ring schedul rate packet arriv transmiss per lane basi effect dynam poll mpstat  older driver  intr ithr csw icsw migr smtx srw syscl usr sy wt idl 10818 8607 4558 1547 161 1797 289 19112 17 69 0 12 mpstat  gldv3 base driver  intr ithr csw icsw migr smtx srw syscl usr sy wt idl 2823 1489 875 151 93 261 1 19825 15 57 0 27 75  fewer interrupt 85  fewer mutex 85  fewer ctx switch 15  cpu free', 'wwwopensolarisorgosprojectcrossbow 13 join us  beer  crossbow solari network bof  tonight 10301130pm  dover  b   present ben rockwood  joyent   vwire demo deepdiv discuss opensolari project commun  http  wwwopensolarisorgosprojectcrossbow  crossbowdiscuss  opensolarisorg  networkingdiscuss  opensolarisorg', 'wwwopensolarisorgosprojectcrossbow 11 virtual network machin virtual network machin  vnm  zone virtual machin associ set network function  rout  firewal  load balanc  etc  vnm dedic vnic   configur link speed  cpu multipl vnm run singl host  connect virtual privat network  etherstub  physic network use simul  consolid  test  etc', 'wwwopensolarisorgosprojectcrossbow 4 crossbow hardwar lane groundup design multicor multi10gig linear scalabl use hardwar lane  dedic resourc network virtual qo design stack effici due dynam poll packet chain  physic machinephys nic hardwar lane c l f e r virtual nic hardwar ringsdma kernel thread queue virtual nic kernel thread queue squeue hardwar ringsdma kernel thread queue virtual machinezon virtual machinezon applic switch vlan separ hardwar ringsdma', 'nicola droux  senior staff engin solari kernel network  sun microsystem inc nicolasdroux  suncom crossbow virtual wire  network box novemb 5th  2009 usenix lisa 09  baltimor  md sunay tripathi  nicola droux  kai belgai  shrikrishna khare', ' switch  l3l4 devic  host', 'nicola droux nicolasdroux  suncom solari kernel network crossbow virtual wire  network box']\n",
      "\n",
      "Paper sentences for pair 3 : ['link assign fresh  ', 'sideeffect permit object creat within librari method  provid escap ', 'use help port java program dpj languag write safe parallel program  16  ', 'analysi track flow method  manner similar intraprocedur pointer analysi ', 'link assign fresh  ', 'exampl ', ' problem ', 'rountev system design work incomplet program  26  ', 'assign data line 15 permit rule  1  ', 'let us recal first problem encount simpl puriti system  discuss 23  show method pure definit 1 requir two guarante ', 'link assign fresh  ', 'sinc determin use static type inform  may actual method invok  due dynam dispatch  ', 'start consid simpl puriti system surprisingli effect practic  crucial  employ modularli checkabl annot ', 'start consid simpl puriti system surprisingli effect practic  crucial  employ modularli checkabl annot ', 'start consid simpl puriti system surprisingli effect practic  crucial  employ modularli checkabl annot ']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "presentation_sentences_list = []\n",
    "paper_sentences_list = []\n",
    "\n",
    "for pair in presentation_paper_pairs:\n",
    "    presentation_sentences = [sentences[0] for sentences in pair]\n",
    "    paper_sentences = [sublist[1] for sublist in pair]\n",
    "    presentation_sentences_list.append(presentation_sentences)\n",
    "    paper_sentences_list.append(paper_sentences)\n",
    "\n",
    "# Print the separated lists for each pair\n",
    "for i in range(3):\n",
    "    print(\"Presentation sentences for pair\", i+1, \":\", presentation_sentences_list[i])\n",
    "    print()\n",
    "    print(\"Paper sentences for pair\", i+1, \":\", paper_sentences_list[i])\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(presentation_sentences_list[5]))\n",
    "print(len(presentation_sentences_list[5]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at best_model.h5",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m load_model(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbest_model.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/keras/saving/saving_api.py:212\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001B[0m\n\u001B[1;32m    204\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m saving_lib\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[1;32m    205\u001B[0m         filepath,\n\u001B[1;32m    206\u001B[0m         custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects,\n\u001B[1;32m    207\u001B[0m         \u001B[38;5;28mcompile\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcompile\u001B[39m,\n\u001B[1;32m    208\u001B[0m         safe_mode\u001B[38;5;241m=\u001B[39msafe_mode,\n\u001B[1;32m    209\u001B[0m     )\n\u001B[1;32m    211\u001B[0m \u001B[38;5;66;03m# Legacy case.\u001B[39;00m\n\u001B[0;32m--> 212\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m legacy_sm_saving_lib\u001B[38;5;241m.\u001B[39mload_model(\n\u001B[1;32m    213\u001B[0m     filepath, custom_objects\u001B[38;5;241m=\u001B[39mcustom_objects, \u001B[38;5;28mcompile\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcompile\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    214\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/keras/saving/legacy/save.py:230\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(filepath, custom_objects, compile, options)\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(filepath_str, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39mexists(filepath_str):\n\u001B[0;32m--> 230\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(\n\u001B[1;32m    231\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo file or directory found at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilepath_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    232\u001B[0m         )\n\u001B[1;32m    234\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mgfile\u001B[38;5;241m.\u001B[39misdir(filepath_str):\n\u001B[1;32m    235\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m saved_model_load\u001B[38;5;241m.\u001B[39mload(\n\u001B[1;32m    236\u001B[0m             filepath_str, \u001B[38;5;28mcompile\u001B[39m, options\n\u001B[1;32m    237\u001B[0m         )\n",
      "\u001B[0;31mOSError\u001B[0m: No file or directory found at best_model.h5"
     ]
    }
   ],
   "source": [
    "model = load_model(\"best_model.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(presentation_sentences_list[0])\n",
    "print(paper_sentences_list[0][0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TODO: tokenize and vectorize input data\n",
    "import pickle\n",
    "\n",
    "models_dir = '../models/'\n",
    "\n",
    "# Load the tokenizer object\n",
    "with open(os.path.join(models_dir, 'tokenizer.pkl'), 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Tokenize inference sentences using the loaded tokenizer\n",
    "inference_premise_sequences = tokenizer.texts_to_sequences(presentation_sentences_list[0])\n",
    "inference_hypothesis_sequences = tokenizer.texts_to_sequences(paper_sentences_list[0])\n",
    "\n",
    "# Pad the sequences to the same maximum sequence length\n",
    "inference_premise_sequences = pad_sequences(inference_premise_sequences, maxlen=45, padding='post')\n",
    "inference_hypothesis_sequences = pad_sequences(inference_hypothesis_sequences, maxlen=45, padding='post')\n",
    "\n",
    "# Print the size of inference sequences\n",
    "print(\"Size of Premise Inference Sequences:\", len(inference_premise_sequences))\n",
    "print(\"Size of Hypothesis Inference Sequences:\", len(inference_hypothesis_sequences))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "probabilities = model.predict([inference_premise_sequences, inference_hypothesis_sequences])\n",
    "print(probabilities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(probabilities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "predicted_classes = np.argmax(probabilities, axis=1)\n",
    "\n",
    "# Step 3: Class Labels\n",
    "class_labels = [\"Entailment\", \"Neutral\", \"Contradictory\"]  # Replace with your actual class labels\n",
    "predicted_labels = [class_labels[idx] for idx in predicted_classes]\n",
    "\n",
    "# Print the predicted labels\n",
    "print(\"Predicted Labels:\", predicted_labels)"
   ],
   "metadata": {
    "id": "f6Ik2bemdb4Q",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:38:28.715504Z",
     "start_time": "2024-04-10T00:38:28.711288Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Count the occurrences of each label\n",
    "label_counts = {label: predicted_labels.count(label) for label in set(predicted_labels)}\n",
    "\n",
    "# Calculate the total count of all labels\n",
    "total_count = sum(label_counts.values())\n",
    "\n",
    "# Calculate the proportion of each label\n",
    "label_proportions = {label: count / total_count for label, count in label_counts.items()}\n",
    "\n",
    "# Define weights for each label\n",
    "label_weights = {\n",
    "    'Contradictory': 0,\n",
    "    'Neutral': 0.5,\n",
    "    'Entailment': 1\n",
    "}\n",
    "\n",
    "# Calculate the weighted sum of counts for all labels\n",
    "weighted_sum = sum(label_counts[label] * label_weights[label] for label in label_counts)\n",
    "\n",
    "# Normalize the weighted sum to range from 0 to 1\n",
    "normalized_weighted_sum = weighted_sum / (total_count * max(label_weights.values()))\n",
    "\n",
    "# Print the normalized weighted sum\n",
    "print(\"Normalized Weighted Sum of Label Counts:\", normalized_weighted_sum)\n",
    "\n",
    "# Print the label proportions\n",
    "print(\"Label Proportions:\", label_proportions)\n"
   ],
   "metadata": {
    "id": "BVLIYEZ7db4Q",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:38:28.822426Z",
     "start_time": "2024-04-10T00:38:28.734952Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the thresholds\n",
    "thresholds = {\n",
    "    'BAD': 0.33,\n",
    "    'GOOD': 0.66,\n",
    "    'GREAT': 1.0\n",
    "}\n",
    "\n",
    "# Determine the category based on the normalized weighted sum\n",
    "category = None\n",
    "for label, threshold in thresholds.items():\n",
    "    if normalized_weighted_sum <= threshold:\n",
    "        category = label\n",
    "        break\n",
    "\n",
    "# Print the category\n",
    "print(\"This presentation was a\", category, \"representation of this paper.\")\n"
   ],
   "metadata": {
    "id": "-p0GWz-uBhbU",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:38:28.826097Z",
     "start_time": "2024-04-10T00:38:28.823430Z"
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
