<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:33+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cross-domain Collaboration Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 12-16, 2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tang</surname></persName>
							<email>jietang@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University ‡ IBM TJ Watson Research Center</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University ‡ IBM TJ Watson Research Center</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimeng</forename><surname>Sun</surname></persName>
							<email>jimeng@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University ‡ IBM TJ Watson Research Center</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Su</surname></persName>
							<email>suhang@sse.buaa.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University ‡ IBM TJ Watson Research Center</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Cross-domain Collaboration Recommendation</title>
					</analytic>
					<monogr>
						<title level="j" type="main">KDD</title>
						<meeting> <address><addrLine>Beijing, China</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="volume">12</biblScope>
							<date type="published">August 12-16, 2012</date>
						</imprint>
					</monogr>
					<note>Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. 978-1-4503-1462-6 /12/08 ...$10.00.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H33 [Information Search and Retrieval]: Text Mining; J4 [Social Behavioral Sciences]: Miscellaneous General Terms Algorithms</term>
					<term>Experimentation Keywords Collaboration recommendation</term>
					<term>Social network</term>
					<term>Social influence</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Interdisciplinary collaborations have generated huge impact to society. However, it is often hard for researchers to establish such cross-domain collaborations. What are the patterns of cross-domain collaborations? How do those collaborations form? Can we predict this type of collaborations? Cross-domain collaborations exhibit very different patterns compared to traditional collaborations in the same domain: 1) sparse connection: cross-domain collaborations are rare; 2) complementary expertise: cross-domain collaborators often have different expertise and interest; 3) topic skewness: cross-domain collaboration topics are focused on a subset of topics. All these patterns violate fundamental assumptions of traditional recommendation systems. In this paper, we analyze the cross-domain collaboration data from research publications and confirm the above patterns. We propose the Cross-domain Topic Learning (CTL) model to address these challenges. For handling sparse connections, CTL consolidates the existing cross-domain collaborations through topic layers instead of at author layers, which alleviates the sparseness issue. For handling complementary expertise, CTL models topic distributions from source and target domains separately, as well as the correlation across domains. For handling topic skewness, CTL only models relevant topics to the cross-domain collaboration. We compare CTL with several baseline approaches on large publication datasets from different domains. CTL outperforms base-lines significantly on multiple recommendation metrics. Beyond accurate recommendation performance, CTL is also insensitive to parameter tuning as confirmed in the sensitivity analysis.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Social network analysis focuses on modeling interactions between people. Researchers have studied various issues in social networks, such as network properties <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11]</ref> and generation processes <ref type="bibr" target="#b17">[18]</ref>, link predictions <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b31">32]</ref> and recommendations <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b16">17]</ref>. Despite all the existing research in social networks, little has been done on analyzing collaborations across two different domains.</p><p>Interdisciplinary collaborations have generated huge impact to society. For example, collaborations between biology and computer science revolutionized the field of bioinformatics. Because of these cross-domain collaborations, originally extremely expensive tasks such DNA sequencing have become scalable and affordable to a much broader population. Now medicine and data mining are working together in the field of medical informatics, which is a big growth area that is expected to have huge impact on medicine <ref type="bibr" target="#b23">[24]</ref>. Indeed, cross-domain collaboration has become increasingly important. <ref type="figure" target="#fig_0">Figure 1</ref> shows the increasing trend of cross-domain collaborations over the past fifteen years across different domains in a publication database (Cf. § 4 for details). In most of the cases, there exists a clear increasing trend of the cross-domain collaborations.</p><p>However, it is often hard for researchers to establish such crossdomain collaborations. What are the patterns of cross-domain collaborations? How do those collaborations form? Can we predict this type of collaborations? Cross-domain collaborations often exhibit very different challenges compared to traditional collaborations in the same domain:</p><p>First, sparse connection, cross-domain collaborations are rare compared to traditional collaborations within a domain, partly because it is difficult for an outsider to find the right collaborator in the field that one does not know. This also makes it challenging to directly use a supervised learning approach due to the lack of training samples.</p><p>Second, complementary expertise, cross-domain collaborators often have different expertise and interest; For example, data mining researchers can easily identify who they want to work with in the data mining field, because the topics are known to them. However, for a cardiologist who wants to apply data mining techniques to predict heart failures, it will be difficult for her to find the right collaborators in data mining. Because these two fields (cardiology and data mining) are completely different with different terminology and problems. It is very difficult for one from cardiology to identify the right topics in data mining to look for collaborators.</p><p>Third, topic skewness, not all topics are relevant for crossdomain collaborations. In fact, in our study, only less than 9% of all possible topics pairs across domains have collaborations. Therefore, for the task of cross-domain collaboration recommendation, we should focus on better modeling those topics with high probability of having cross-domain collaborations. Despite of the above challenges, once such cross-domain collaboration is successfully formed, its impact is usually tremendous. In our study, cross-domain collaborations constitute a small portion of all possible collaborations as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. The trends of cross-domain collaboration in many cases are growing. Newly formed cross-domain collaborations are significant in all cases, which confirmed the potential need for cross-domain collaborations.</p><p>Based on these observations, we propose the Cross-domain Topic Learning (CTL) method that addresses all three challenges including sparse connection, complementary expertise and topic skewness. CTL is a generative topic model that differentiates relevant topics to cross-domain collaboration from other topics.</p><p>We compare CTL with several baseline approaches on large publication data sets of different domains. CTL outperforms others significantly on recommendation metrics. Beyond accurate recommendation performance, CTL is also insensitive to parameter tuning as confirmed in the sensitivity analysis. Finally, we integrate CTL into a large-scale web application for recommending cross-domain research collaborators, which further demonstrates the scalability of CTL in handling real-time queries.</p><p>The rest of this paper is organized as follows: Section 2 formulates the cross-domain recommendation problem formally; Section 3 presents our proposed methods on cross-domain recommendation; Section 4 describes the experiments; Section 5 presents the related work; then we conclude in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">PROBLEM DEFINITION</head><p>We present required definitions and formulate the problem of cross-domain collaboration recommendation. Without loss of generality, we assume there are two domains, the source domain and the target domain. Our goal is to recommend potential collaborators in the target domain for a specific user from the source domain. Definition 1. Source/Target domain. The source (or target) domain can be represented as a social network G = (V, E, X), where V is a set of |V | = N users and E ⊆ V × V is a set of undirected (collaborative) relationships between users, X is an N × d attribute matrix in which every row corresponds to a vector of attribute values of a user. We use xj to denote the j th attribute.</p><p>We use superscript S and T to differentiate the source domain and the target. If there is no ambiguity, we will omit S for the source domain and use superscript for the target, for brevity. Suppose each user vi is associated with d attributes. For example, in the research collaboration network, each user is associated with a set of publication papers or a set of words appearing in those papers. Given this, we have the following definition:</p><p>Definition 2. Domain-specific topic models. A topic model θi of a user vi is a multinomial distribution of attributes {P (xj|θi)}j. Then a domain is considered as a mixture of multiple user-specific topic models. The assumption behind is that attributes associated with the user are sampled following a distribution corresponding to each topic, i.e., P (x|θi).</p><p>Such a definition is usually used in the LDA/PLSI style topic models <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b14">15]</ref>. According to the above definition, attributes with the highest probability associated with each topic would suggest the semantics represented by the topic. For example, a "Data Mining" topic discovered from the publication data can be represented by keywords "clustering", "learning", "classification", etc.</p><p>The input of our problem consists of a source domain G S and a target domain G T , each associated with topic models. Please note that the source domain and the target domain can be overlapping, i.e., V S ∩ V T 񮽙 = ∅. Given this, we can precisely define the following problem: Problem 1. Cross-domain collaboration recommendation. Given (1) a source domain G S and a target domain G T , (2) topic models θ and θ associated with users in the two domains respectively, the goal is to rank and recommend potential collaborators in the target domain for a specific user vq from the source domain.</p><p>The fundamental challenge of this problem is how to capture the collaboration patterns across different domains. Within the same domain, homophily is often considered as the driven force for the formation of collaborative relationships, which suggests that people with the similar interest (topic model θ) tend to collaborate with each other. However, in the cross-domain setting, the problem is very different. Technically, it is challenging to extract and discriminate topics in the two domains. In particular, given a specific user and her topic distribution from the source domain, on which topics and with whom should she collaborate in the target domains?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">CROSS-DOMAIN TOPIC LEARNING</head><p>We begin by considering some baseline solutions and then propose our cross-domain topic learning approach. A simple approach to the problem is to construct a collaboration graph connecting users between source and target domains and then use a random walk with restart algorithm <ref type="bibr" target="#b27">[28]</ref> to rank collaborators in the target</p><formula xml:id="formula_0">Source domain Target domain v 1 v 2 v N v q v' 1 v' 2 v' N' ... G S G T ... (a) Author matching v 1 v 2 v N v q v' 1 v' 2 v' N'</formula><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G S G T</head><p>... ... domain. We call this method Author Matching. The details of the algorithm are described in Section 3.1.</p><formula xml:id="formula_1">G S G T ...</formula><p>The problem with Author Matching is the sparse connections between authors across two domains. To alleviate this problem, the second model is to consolidate the correlation between the underlying topics. Suppose each domain has T different topics and each user has a distribution over the topics. We can augment the collaboration graph with two topic layers (as shown in <ref type="figure" target="#fig_1">Figure 2</ref>(b)). The links between the two topic layers indicate the alignment between topics, which implicitly represents the complementary expertise between users. Based on this representation, a random walk with restart algorithm can be again applied to the graph to rank (both topic and user) nodes in the target domain. We call this method Topic Matching, and details are described in Section 3.2.</p><p>Topic matching improves the cross domain connections through a subset of topic pairs from source domain to target domain. However, not all topic pairs are relevant for collaboration (topic skewness). Therefore, blindly computing all topics from source and target domains are not necessary for collaboration recommendation and often lead to sub optimal results. One challenge here is how to differentiate relevant "collaboration" topics from other topics. We further design a Cross-domain Topic Learning (CTL) algorithm to address this challenge in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Author Matching</head><p>Based on the historic cross-domain collaborations, we create a collaboration graph, as shown in <ref type="figure" target="#fig_1">Figure 2</ref>(a). The problem is to rank relevant nodes in the target domain G T for a given query node vq in the source domain G S . Measuring the relatedness of two nodes in the graph can be achieved using the Random Walks with Restarts (RWR) theory <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b27">28]</ref>. Starting from node vq, a RWR is performed by following a link to another node according to the weight of the link at each step. 1 Also, in every step, there is a probability τ to return the node vq. The relatedness score of node vi wrt node vq is defined as the stationary probability ri that the random walk will finally arrive node vi, i.e.,</p><formula xml:id="formula_2">r (t+1) = (1 − τ )S · r (t) + τ q (1)</formula><p>where r (t) is a vector with each element r t i denoting the probability that the random walk at step t arrives at node vi; q is a vector of zero with the element corresponding to the starting node vq set to 1, i.e., qv q = 1; S defines the transition probability of the random <ref type="bibr" target="#b0">1</ref> In the author matching method, we use a uniform weight, i.e., weights of links of a node v to its neighbors are defined as 1</p><formula xml:id="formula_3">N B(v)</formula><p>, where N B(v) is the number of neighbors of node v. In §3.2, we will introduce how to define the weight based on topic model. walk, with element Sij denoting the random walking probability from node vi to node vj.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Topic Matching</head><p>The author matching method only considers the network structure information, but ignores the content (topic) information. How do people collaborate across different domains? And what are the hottest topics on which people from different domains tend to collaborate?</p><p>Recently, probabilistic topic models have been successfully applied to multiple text mining tasks to extract topics from text <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b26">27]</ref>. We employ an Author-Conference-Topic (ACT) model <ref type="bibr" target="#b30">[31]</ref>, which utilizes the topic distribution to represent the interdependencies among authors, papers, and publication venues. <ref type="bibr" target="#b1">2</ref> The model simulates the process when people collaborate on a work, e.g., writing a scientific paper, using a series of probabilistic steps. In essence, for each object it estimates a mixture of topic distributions which represent the probability of the object associated with every topic. Such as for each author v, we have a set of probabilities {P (zi|v)}i or {θvz i }i, respectively denoting how likely author v is interested in topic zi. Similarly, we have {P (xj|z)}j or {φzx j }j, the probability of attribute xj (e.g., a keyword) given topic z. We use Gibbs sampling to learn the probabilities. The interested reader can refer to <ref type="bibr" target="#b30">[31]</ref> for more details.</p><p>Combining topic model into random walk. We now discuss how to combine the topic model into the random walk framework. First, we apply the ACT model to the source and the target domains respectively and obtain two sets of topic distributions. Then we estimate the alignment between topics of these two domains. We calculate the alignment according to the historic cross-domain collaborations. Specifically, the strength of the alignment between topic zi from the source domain and topic z j from the target domain is estimated by:</p><formula xml:id="formula_4">S z i z j = 1 κ (v,v )∈E ST [P (zi|v) + P (z j |v )] (2)</formula><p>where κ is a normalization factor; (v, v ) ∈ E ST indicates a crossdomain collaboration between v and v . We augment the graph generated in the author matching method with topic nodes {z} and {z } extracted from the two domains. <ref type="figure" target="#fig_1">Figure 2</ref>(b) shows the graphical structure, which suggests that a random walk can be performed from a user v to a topic z and from Input: a source domain G S and a target domain G T Output: estimated parameters θ,θ ,φ, ϑ, and λ Initialize an ACT model in G S by learning from documents written by authors only from G S ; Similarly, initialize an ACT model for target domain G T ;</p><formula xml:id="formula_5">foreach collaborated document d do foreach word x di ∈ d do Toss a coin s di according to bernoulli(s di ) ∼ beta(γt, γ),</formula><p>where beta(.) is a Beta distribution, and γt and γ are two parameters; if s di = 0 then Randomly select a pair (v, v ) from d's authors, where v is an author from G S and v from G T ; Draw a topic z di ∼ multi(ϑ vv ) from the topic mixture ϑ vv specific to (v, v ); The link weight between user node v and topic node z is defined as the probability P (z|v) obtained from the ACT model. Then the relatedness of the query node to a target topic z is defined by a similar formula as that in Eq. 1 and analogously we can define the relatedness between the query node and user nodes in the target domain.</p><formula xml:id="formula_6">end if s di = 1 then Randomly select a user v; Draw a topic z di ∼ multi(θv) from the topic model of user v; end end Draw a word x di ∼ multi(φz di ) from z di -specific</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Cross-domain Topic Learning (CTL)</head><p>The topic matching method does not discriminate the "collaboration" topics from those topics existing in only one domain. As a result, the "irrelevant" topics (irrelevant to collaboration) may hurt the collaboration recommendation performance. We develop a new topic modeling approach called Cross-domain Topic Learning (CTL) to model topics of the source domain and the target domain simultaneously.</p><p>Model description. The basic idea here is to use two correlated generative processes to model the source and the target domains together. The first process is to model documents written by authors from single domain (either source or target). The second process is to model collaborated documents. For each word in a collaborated document, we use a Bernoulli distribution to determine whether it is generated from a "collaboration" topic or a topic-specific to one domain only. <ref type="figure" target="#fig_2">Figure 3</ref> shows the graphical structure of the  <ref type="bibr">(v, v )</ref> is an author pair randomly sampled to be responsible for word x; s is a binary variable indicating whether the current word inherits the topic from a single domain (s = 1) or by a cross-domain collaboration s = 0; θ and θ are topic models from the source domain and the target domain, respectively; ϑ vv is a collaboration topic model specific to author pair (v, v ); α is the Dirichlet hyperparameter; λ is a parameter for sampling the binary variable s; γ and γt are Beta parameters to generate λ. <ref type="table" target="#tab_1">Table 1</ref> summarizes the notations used in the CTL model.</p><p>Formally, the generative process is described in Algorithm 1: first, documents of the two domains G S and G T are partitioned into three clusters: documents written by authors only from the source domain, documents written by authors only from the target domain, and documents collaborated by authors from both domains. Then CTL respectively extracts topics of authors from the first two document clusters (without cross-domain collaborations) according to the distributionp(θv|α) and p(θ v |α), where α is the Dirichlet prior. For simplicity, we use the same prior α for both source and target domains.</p><p>Second, CTL models the cross domain collaboration documents. For each word x di in document d, a coin s is tossed according to p(s|d) ∼ beta(γt, γ), where beta(.) is a Beta distribution. When s = 1, a single user v (or v ) is chosen according to a uniform distribution, then the word x di is sampled from a selected topic z di specific to the user v, according to θv (therefore, this is not a cross-domain collaboration). When s = 0, a pair of cross-domain collaborators (v, v ) are selected, and a new multinomial distribution ϑ vv is constructed by combining θv and θ v (therefore, crossdomain collaboration is formed). More specifically, we first expand the source and target topic spaces to be of the same dimension. For example, if source domain has 10 topics and target domain 5 topics, the expanded topic space will have 15 topics (10 from source domain and 5 from target domain). The expanded source topic distributioñ θv =&lt; θv, 0, . . . , 0 &gt;, where we set 0 on the target topics. Similarly, we define the expanded target topic distribution to be˜θbe˜ be˜θ v =&lt; 0, . . . , 0, θ v &gt;. The new distribution ϑ vv is then defined as˜θvas˜ as˜θv + ˜ θ v , a simple mixture of the two expanded multinomials of θv and θ v <ref type="bibr" target="#b4">[5]</ref>. Finally the word x di is sampled from a collaboration topic z di according to the new distribution ϑ vv . target domain (zero probability on topics from the other domain). Then, CTL smoothes topics distributions across the two domains. Users from the source domain will also have a probability over topics extracted from the target domain, and vice versa. After training the CTL model, we also obtain a set of "collaboration topics" between the two domains, i.e., topics with the highest posterior probabilities P (z|s = 0, ·) (or P (z|s = 0, ·) &gt; ) in the collaborated documents. (Here, · indicates all the other parameters we should consider when calculating the probability.) For example in right hand side of <ref type="figure">Figure 4</ref>, the box indicates those collaboration topics.</p><p>Model inference. We use Gibbs sampling to estimate unknown parameters {θ, θ , ϑ, φ, λ} in the CTL model. In particular, we evaluate (a) the posterior distribution on z (or z) for each word in the document written by authors only from a single domain and then use the results to infer θ (or θ); (b) the posterior distribution on s, and then use the sampling results of z and z according to s to update ϑ, θ and θ . Finally, λ and φ can be inferred from the obtained topic models. More specifically, we begin with the joint probability of all documents in the two domains, and then using the chain rule, we obtain the posterior probability of sampling the topic for each word. For (a) we use the same sampling algorithm as that for the LDA model (or the ACT model) (cf. <ref type="bibr" target="#b12">[13]</ref> or <ref type="bibr" target="#b30">[31]</ref>), i.e. with the posterior probability:</p><formula xml:id="formula_7">P (z di |z −di , x, ·) = n −di vz di + α z (n −di vz + α) × m −di z di x di + β x (m −di z di x + β)<label>(3)</label></formula><p>where nvz is the number of times that topic z has been sampled from the multinomial distribution specific to a randomly selected author v; mzx is the number of times that word x has been generated by topic z; the number n −di with the superscript −di denotes a quantity, excluding the current instance. We use a similar process for both domains. For parameter estimation in (b), we consider a two-step Gibbs sampling. We first sample the coin s according to the posterior probability: (Detailed derivation is given in Appendix.)</p><formula xml:id="formula_8">P (s di = 0|s −di , z,·) = n −di ds 0 + γt n −di ds 0 + n −di ds 1 + γt + γ × n −di vv z di + (nvz di + n v z di ) + α z (n −di vv z + (nvz di + n v z di ) + α)<label>(4)</label></formula><p>where n ds 0 is the number of times that s = 0 has been sampled in document d; (v, v ) is the selected user pair to be responsible for x di ; n vv z is the number of times that topic z has been sampled from user pair (v, v ). P (s di = 1|·) can be analogously defined as the above equation. The only difference is to replace the sum of the two terms (nvz di + n v z di ) with the number by a selected single user v (or v ).</p><p>The posterior probability of topic z is defined as:</p><formula xml:id="formula_9">P (z di |s di = 0, x, z −di ,·) = m −di z di x di + mz di x di + m z di x di + β x (m −di z di x + mz di x + m z di x + β) × n −di vv z di + (nvz di + n v z di ) + α z (n −di vv z + (nvz + n v z ) + α)<label>(5)</label></formula><p>where m −di zx is the number of times that word x has been generated by topic z in the collaborated documents; mzx and m zx respectively represents the number of times that word x has been generated by topic z in the source domain and that in the target domain.</p><p>During the parameter estimation, the algorithm keeps track of a V × T (user by topic) count matrix for both domains, a D × 2 (collaborated document by coin), a 2 × T (coin by topic) count matrices, and a AP × T (user pair by topic) count matrix (AP is the number of user pairs). Given these matrices, we can estimate the probabilities of θ, θ , ϑ, φ, and λ.</p><p>Cross-domain recommendation via random walk. We combine the learned "collaboration" topics by CTL into the collaboration graph (Cf. <ref type="figure" target="#fig_1">Figure 2(c)</ref>). In principle, there could be a link between any user node and topic node (the difference is the link weight). To control the density of the constructed network, we define a parameter and add links between users and topics only when P (z|s = 0, ·) &gt; . A smaller results in a more dense network. Random walk with restart is then performed on the topic augmented graph to calculate the relatedness between users from the target domain and the query user node in an analogous way as done in Eq. 1. Finally we rank users in the target domain according to the estimated relatedness scores and recommend users with the highest relatedness. One advantage of the CTL model is that it is able to recommend "related" collaboration topics based on the relatedness scores between the query node and the topic nodes. In topic matching, we could also consider recommending topics based on the relatedness scores; however, the recommended topics might be irrelevant to collaboration. In CTL, the recommended topics directly reflect existing collaborations across the two domains.</p><p>The CTL model can be also generalized to multiple domains. The basic idea is to use a multinomial distribution to replace the Bernoulli distribution. The multinomial represents collaboration topics among multiple domains, between two specific domains, or those in single domain. Based on the learned topics, we can construct a topic-centered network (similar to <ref type="figure" target="#fig_1">Figure 2(c)</ref>). Then the random walk with restart can be performed on the network to estimate the relatedness scores of users from different domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTAL RESULTS</head><p>In this section, we evaluate the proposed methods on large publication datasets of different domains. All data sets and codes are publicly available 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>Data sets. The data set is extracted from Arnetminer.org <ref type="bibr" target="#b30">[31]</ref>, an academic search system, which contains 1,436,990 authors and 1,932,442 publications. The data we used in our experiments spans from 1990 to 2005. We consider the following five sub-domains:</p><p>• Data Mining: We use papers of the following data mining conferences: KDD, SDM, ICDM, WSDM and PKDD as ground truth, which result in a network with 6,282 authors and 22,862 co-author relationships.</p><p>• Medical Informatics: We include the following journals: Journal of the American Medical Informatics Association, Journal of Biomedical Informatics, Artificial Intelligence in Medicine, IEEE Trans. Med. Imaging and IEEE Transactions on Information and Technology in Biomedicine, from which we obtain a network of 9,150 authors and 31,851 coauthor relationships.</p><p>• Theory: We include the following conferences, i.e., STOC, FOCS and SODA, from which we get 5,449 authors and 27,712 co-author relationships.</p><p>• Visualization: We include the following conferences and journals, CVPR, ICCV, VAST, TVCG, IEEE Visualization and Information Visualization. The obtained coauthor network is comprised of 5,268 authors and 19,261 co-author relationships.</p><p>• Database: We include the following conferences, i.e., SIG-MOD, VLDB and ICDE. From those conferences, we extract 7,590 authors and 37,592 co-author relationships.</p><p>Based on the above five sub domains, we create four crossdomain test cases: Data Mining to Theory, Medical Informatics to Database, Medical Informatics to Data Mining, and Visualization to Data Mining.</p><p>Comparison methods. We compare the following methods for collaboration recommendation:</p><p>Content Similarity (Content): It calculates similarity between authors based on papers published by them. Specifically, we construct feature vector wq and w v of words used in papers published by query author q and target author v , respectively. Those feature vectors are normalized by TFIDF <ref type="bibr" target="#b0">[1]</ref>. The similarity score is the Cosine similarity between wq and w v Sim(vq, v ) = wq · w v wqw v</p><p>Collaborative Filtering (CF): It leverages the existing collaborations to make the recommendation. The basic idea is that if a query author q has the same or similar collaborators as a person x within the same domain, q is then likely to have the same crossdomain collaborators as x. We employ a memory-based collaborative filtering algorithm <ref type="bibr" target="#b7">[8]</ref>, in which recommendations are made for a query user q using the following formula:</p><formula xml:id="formula_11">CF _score(q, v ) = x∈V S I(x, v )r(q, x)<label>(7)</label></formula><p>where r(q, x) is the similarity between authors in the source domain, e.g., Cosine similarity based on collaboration connections; the indicator variable I(x, v ) is 1 if the author x has a crossdomain collaboration with v and 0 otherwise. Hybrid: It considers a linear combination of the scores obtained by the Content and the CF methods, specifically,</p><formula xml:id="formula_12">Hybrid(vq, v ) = µCF _score(vq, v )+(1−µ)Sim(vq, v ) (8)</formula><p>where µ is a balance parameter. We empirically set it as 0.5.</p><p>Katz: It is the best link predictor in <ref type="bibr" target="#b19">[20]</ref>. It sums over all possible paths between the query user and a candidate user, and then use the summation score to rank all candidates.</p><p>Author Matching: (Cf. §3.1) It makes recommendation by performing the random walk with restart on the collaboration graph.</p><p>Topic Matching: (Cf. §3.2) It makes recommendation by combining the extracted topics into random walking algorithm.</p><p>CTL: (Cf. §3.</p><p>3) It is the proposed method, which considers topic skewness and extracts relevant topics to cross-domain collaboration. The relevant topics are then integrated into the random walk framework for recommendation. <ref type="bibr" target="#b3">4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation metrics.</head><p>To quantitatively evaluate the proposed methods, in each test case, we use historic collaboration data (data before 2001) for training and the last four years <ref type="bibr">(2001)</ref><ref type="bibr">(2002)</ref><ref type="bibr">(2003)</ref><ref type="bibr">(2004)</ref><ref type="bibr">(2005)</ref> for validation. In evaluation, we consider those candidates who already have cross-domain collaborations and then our task is to predict if they will maintain the collaborations or expand new cross-domain collaborations. If the system recommends a cross-domain collaboration and later the collaboration has been built, then we say the system made a correct recommendation; otherwise we say the system made a wrong recommendation. Based on this, we evaluate the recommendation performance in terms of P@10 (Precision for the top 10 recommended results), P@20, R@100 (Recall for the top 100 results), MAP (Mean Average Precision), and Average Reciprocal Hit-Rank (ARHR) <ref type="bibr" target="#b8">[9]</ref>.</p><p>All codes are implemented in C++, and all the experiments are conducted on an x64 server with E7520 1.87GHz Intel Xeon CPU and 128G RAM. The operation system is Microsoft Windows Sever 2008 R2 Enterprise. For training the ACT and the CTL models, it takes about 12 hours and 15 hours respectively on the entire data set (1,436,990 authors and 1,932,442 publications). Recognizing the computation complexity of LDA style models, we are currently looking into developing more efficient computation mechanism to speed up the process. <ref type="table" target="#tab_2">Table 2</ref> lists the performance of cross-domain collaboration recommendation by the comparison methods on the four different test cases. The proposed CTL method clearly outperforms the baseline methods (+2.2-30% in terms of MAP). Content only considers the content information, which leads to a bad performance. The two methods (Hybrid and Topic Matching), combining the content and the network information, improve the recommendation performance compared to the simple baselines such as Content, CF and Author Matching. Moreover, Topic Matching considers the topic information extracted from the two domains, and thus performs better than the Hybrid method adopting a simple combination. CTL differentiates "collaboration topics" from those irrelevant topics and obtains significant improvement over both Hybrid and Topic Matching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Recommendation Performance Analysis</head><p>Cross-domain topics analysis. How many topics are enough for the cross-domain recommendation? We perform an analysis by varying the number of cross-domain topics in the proposed CTL method. <ref type="figure" target="#fig_5">Figure 5(a)</ref> shows its MAP performance with the num- ber of cross-domain topics varied. We see, when the number is small (&lt; 80), increasing the number often obtains a performance improvement. The trend becomes stable when the number is up to 150. This demonstrates the stability of the CTL method with respect to the number of topics.</p><p>Hyperparameter analysis. We use α as the example to analyze how hyperparameter influences the performance of the CTL method. <ref type="figure" target="#fig_5">Figure 5(b)</ref> shows the performance of CTL with the parameter α varied (all the other hyperparameters fixed and the number of topics is set as T = 120). We see although the performance changes when varying the value of α, the largest difference is less than 0.03 This confirms CTL method is not sensitive to the particular choice of α.</p><p>Restart parameter analysis. We study how the parameter τ influences the process of random walk with restart. <ref type="figure" target="#fig_5">Figure 5</ref>(c) plots the performance of the CTL method on the four test cases with the parameter τ varied. In general, the recommendation performance is not sensitive to the restart parameter τ . By a careful investigation, we find that a small τ makes the random walk diffuse too quickly thus can hurt the precision, while a large τ limits the diffusion process and thus can result in a lower recall.</p><p>Convergence analysis. We further investigate the convergence of the random walk with restart algorithm. (within 5 iterations). This fast convergence on CTL model enable real time query support that is crucial in the deployed system we will discuss next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>New Collaboration Prediction</head><p>The collaboration network is dynamic in nature, with collaborative relationships created over time. In general, there are two types of collaborative behaviors, maintaining existing collaborations and building new collaborations. Can we predict who will create a new collaboration in the future? This is a more difficult task. We conduct an experiment to evaluate the performance of the proposed method for new collaboration prediction. In particular, we still use the publication data before 2001 for training and the data between <ref type="bibr">[2001]</ref><ref type="bibr">[2002]</ref><ref type="bibr">[2003]</ref><ref type="bibr">[2004]</ref><ref type="bibr">[2005]</ref> for test, and in the evaluation, we only consider new collaborations in the test data. <ref type="figure">Figure 6</ref> shows the performance of new collaboration prediction by the six comparison algorithms. On average, the performance of all algorithms drops a bit, but all algorithms have similar behaviors as that in <ref type="table" target="#tab_2">Table 2</ref>. In particular, it is exciting to see that CTL can still maintain about 0.3 in terms of MAP which is significantly higher than the baseline methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Prototype System</head><p>We have developed and deployed a web application for crossdomain recommendation based on the proposed CTL method 5 . The system trained a CTL model offline using all the publication data (about 1,932,442 publication papers) in Arnetminer.org. When a user wants to find cross-domain collaborators, he first inputs his profile (including organization and research interest) or use an existing author profile via the Arnetminer system, which includes more than 1 million researcher profiles. Then the user inputs the target domain (by keywords) in which he wants to find collaborations. The system performs the random walk with restart algorithm (Cf. §3.3) online against the CTL model to rank potential topics/collaborators in the target domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">RELATED WORK</head><p>Collaboration recommendation plays an important role in many fields and has attracted a lot of research interest. Chen et al. <ref type="bibr" target="#b6">[7]</ref> have developed a system called CollabSeer for discovering potential collaborators for a given author based on the structure of the coauthor network and the user's research interests. This is the most relevant paper to our work. However, it does not consider the cross-domain problem. <ref type="bibr">Konstas et al. [17]</ref> investigated how social relationships can help recommendation. They developed a track recommendation system by considering both social annotation and friendship inherent in the social graph established among users, items and tags. <ref type="bibr">Kautz et al.</ref> [16] introduced a system called ReferralWeb which attempts to combine social networks for collaborative filtering. There are a large body of research on collaborative filtering. For example <ref type="bibr" target="#b1">[2]</ref> introduced a system called Fab by combining content-based filtering and collaborative filtering. Shi et al. <ref type="bibr" target="#b25">[26]</ref> proposed a large scale machine learning system for recommending heterogeneous content in social networks and Sculley et al. <ref type="bibr" target="#b24">[25]</ref> presented a method to rank which combines regression and ranking. <ref type="bibr">Yuan et al. [35]</ref> aimed to fuse heterogeneous social relationships for recommendation using factorization and regularization technologies. <ref type="bibr">Wang and Blei [34]</ref> developed an algorithm to recommend scientific articles to users of an online community by combining traditional collaborative filtering and probabilistic topic modeling. However, most existing works only consider the recommendation problem within one single domain, but do not consider the cross-domain recommendation problem. In addition, we propose a novel cross-domain topic learning method, which supports recommending collaboration topics as well.</p><p>Our work is also related to expert finding <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b35">36]</ref> and expertise matching <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b32">33]</ref>. Mimno et al. <ref type="bibr" target="#b22">[23]</ref> and <ref type="bibr">Tang et al. [33]</ref> studied the problem of paper-reviewer recommendation, a subtask of expert finding. The proposed algorithms can be leveraged for collaboration recommendations. However, expert finding and expertise matching are in nature different from the problem of collaboration recommendation. The idea of differentiating irrelevant topics has been also studied in previous work such as the queryoriented topic model (qLDA) proposed in <ref type="bibr" target="#b28">[29]</ref>, which tries to identify relevant topics to queries in multi-document summarization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION</head><p>In this paper, we study the problem of cross-domain collaboration recommendation. We precisely define the problem and present three models for ranking and recommending potential collaborators. A cross-domain topic modeling approach has been proposed to learn and differentiate collaboration topics from other topics. Experimental results in a coauthor network demonstrate the effectiveness and efficiency of the proposed approach.</p><p>As for the future work, it is intriguing to connect cross-domain collaborative relationships with social theories. For example, how cross-domain relationships correlate with strong/weak ties <ref type="bibr" target="#b11">[12]</ref> and how such correlation can help spread knowledge from one domain to another domain. It would be also interesting to apply the proposed method to other networks, e.g., software development.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">APPENDIX</head><p>According to the generative process, we could integrate out the multinomial (Bernoulli) distributions θ, θ , ϑ, λ, φ, because the model only uses conjugate priors <ref type="bibr" target="#b9">[10]</ref>. We use Eq. 4 as the example to explain its derivation. First we write the joint probability: </p><p>We now derive the first fraction of Eq. 10. As we assume that si is generated from a Bernoulli distribution λ whose Beta parameters are γ, γt, then we can get p(s|λ) = d λ n ds 0 d · (1 − λ d ) n ds 1 , where n ds 0 is the number of times that s = 0 has been sampled in document d and n ds 1 represents the number of times that s = 1 has been sampled in d. Because Beta is the conjugate prior of Bernoulli, we could solve the Bernoulli-Beta integral using Gibbs sampling. Specifically, P (s|λ)P (λ|γ, γt)dλ </p><p>To yield the first fraction of Eq. 10, we apply the above equation twice and obtain the following equation:</p><p>P <ref type="formula">(</ref> </p><p>Here, we use the identity Γ(x + 1) = xΓ(x); the superscript −di denotes a quantity, excluding the current instance. The second fraction of Eq. 10 can be derived analogously. Specifically, as P ((v, v )|A) is a uniform distribution, P (z|(v, v , s, ϑ) and P (ϑ|α) are conjugate pair of Multinomial-Dirichlet, we can obtain <ref type="bibr" target="#b13">[14]</ref>: (13)</p><p>where σ(A d ) is the total number of cross-domain user pairs generated from authors of document d (for a specific document, the number will be a constant); ∆(α) = Γ(α) T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Γ(T α)</head><p>; n vv z denotes the number of times that topic z has been sampled by user pair (v, v ); nvz and n v z are two numbers obtained when combining the two distributions θv and θ v ; please note that though we write it as the sum of the two numbers, in practice, when sampling a specific topic, we will only consider one of them. This is because, for example, if a topic z is from the source domain, the number n v z will be 0. Accordingly, the second fraction of Eq. 10 can be written as: </p><formula xml:id="formula_16">+ (nvz di + n v z di ) + α z (n −di vv z + (nvz di + n v z di ) + α)<label>(14)</label></formula><p>Finally, by combining Eqs. 12 and 14, we obtain Eq. 4.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 : The comparison of existing collaboration and new collaboration trends over years. DM -Data Mining domain; MI - Medical Informatics domain; TH -Theory domain; VIS -Visualization domain; DB -Database domain. The trends of cross-domain collaborations in all but one case are growing (The exception between DM and VIS remain roughly constant over time). Newly formed cross-domain collaborations are significantly in all cases.</head><label>1</label><figDesc>Figure 1: The comparison of existing collaboration and new collaboration trends over years. DM -Data Mining domain; MIMedical Informatics domain; TH -Theory domain; VIS -Visualization domain; DB -Database domain. The trends of cross-domain collaborations in all but one case are growing (The exception between DM and VIS remain roughly constant over time). Newly formed cross-domain collaborations are significantly in all cases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 : Graphical representation of the three recommendation models: author matching, topic matching, and CTL.</head><label>2</label><figDesc>Figure 2: Graphical representation of the three recommendation models: author matching, topic matching, and CTL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Graphical representation of CTL model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 illustrates an example of CTL learning.Figure 4 : Intuitive explanation of the CTL learning. is a pa- rameter to select collaboration topics.</head><label>44</label><figDesc>Figure 4: Intuitive explanation of the CTL learning. is a parameter to select collaboration topics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 (Figure 6 : Performance on new collaboration prediction of all algorithms.</head><label>56</label><figDesc>Figure 6: Performance on new collaboration prediction of all algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 : Parameter analysis. (a) Performance of cross-domain topic learning model by varying the number of topics T ; (b) Performance of cross-domain topic learning (CTL) is stable when varying α parameter; (c) Performance of CTL is stable when varying the restart parameter τ in the random walk process on the four test cases; (d) Convergence analysis of different models on the test case of Visualization-Data Mining.</head><label>5</label><figDesc>Figure 5: Parameter analysis. (a) Performance of cross-domain topic learning model by varying the number of topics T ; (b) Performance of cross-domain topic learning (CTL) is stable when varying α parameter; (c) Performance of CTL is stable when varying the restart parameter τ in the random walk process on the four test cases; (d) Convergence analysis of different models on the test case of Visualization-Data Mining.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>P</head><label></label><figDesc>(x, x , z, z , s, v, v |α, γ, γt, β, A) ∝ P (s|λ)P (λ|γ, γt)dλ P (v|A)P (z|v, s, θ)P (θ|α)dθ P (v |A )P (z |v , s, θ )P (θ |α)dθ P (x|z, φ)P (φ|β)dφ P ((v, v )|A)P (z|(v, v ), s, ϑ)P (ϑ|α)dϑ (9) The conditional of si is obtained by dividing the joint distribu- tion of all variables by the joint with all variables but si (denoted by s−i) and canceling factors that do not depend on s−i. p(si = 0|s−i, z, .) = P (x, x , z, z , s, v, v |α, γ, γt, β, A) P (x, x , z, z , s−i, v, v |α, γ, γt, β, A) = P (s|λ)P (λ|γ, γt)dλ P (s−i|λ)P (λ|γ, γt)dλ · P ((v, v )|A)P (z|(v, v ), s, ϑ)P (ϑ|α)dϑ P ((v, v )|A)P (z|(v, v ), s−i, ϑ)P (ϑ|α)dϑ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>− λ d ) n ds 1 +γ−1 dλ d = d B(n ds 0 + γt, n ds 1 + γ) B(γt, γ) = d Γ(n ds 0 + γt)Γ(n ds 1 + γ)Γ(γt + γ) Γ(n ds 0 + n ds 1 + γt + γ)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>with n d = {nvz + n v z + n vv z } T z=1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>+n vz +n v z +α)]−1) = n −di vv z di</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>1 z' 2 z' 3</head><label></label><figDesc></figDesc><table>Topics 
Topics 

z 1 

... 

z T 

z' ... 

z' T 

Source domain 
Target domain 

z 2 

z 3 

(b) Topic matching 

Topics 

z 1 

... 

z K 

Source domain 
Target domain 

v 1 

v 2 

v N 

v q 

v' 1 

v' 2 

v' N' 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 : Notations in the CTL model.</head><label>1</label><figDesc></figDesc><table>SYMBOL DESCRIPTION 
T 
number of topics 
d 
a collaborated document 
A d 
a set of authors of document d 
x di 
the ith attribute (word) in document d 
z di 
the topic assigned to attribute x di 
s di 
if x di is a word from a single domain or a cross domain 
θv 
multinomial distribution over topics specific to author v 
ϑ vv 
multinomial distribution over topics specific to author 
pair (v,v ) 
φz 
multinomial distribution over words specific to topic z 
α, β 
Dirichlet priors to multinomial distributions θ, θ and φ 
λ 
parameter for sampling the binary variable s 
γ, γt 
Beta parameters to generate λ 

CTL model. (For simplicity, we omit the modeling part for single 
domain and focus on the modeling of the collaborated documents.) 
CTL models each cross-domain collaborated document using topic 
models of authors from the source domain and the target domain. 
Let us briefly introduce notations. A d is a set of authors of doc-
ument d; v is an author and </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Recommendation performance by different methods 
on the four cross-domain test cases (%). Content− Content 

Similarity; CF− Collaborative Filtering; Author− Author Matching; 
Topic− Topic Matching. 
Cross 
domain 
ALG P@10 P@20 MAP R@100 
ARHR 
-10 

ARHR 
-20 

Data 
Mining (S) 
to 
Theory (T) 

Content 10.3 
10.2 10.9 
31.4 
4.9 
2.1 
CF 
15.6 
13.3 23.1 
26.2 
4.9 
2.8 
Hybrid 17.4 
19.1 20.0 
29.5 
5.0 
2.4 
Author 27.2 
22.3 25.7 
32.4 
10.1 
6.4 
Topic 
28.0 
26.0 32.4 
33.5 
13.4 
7.1 
Katz 
30.4 
29.8 31.6 
27.4 
11.2 
5.9 
CTL 
37.7 
36.4 40.6 
35.6 
14.3 
7.5 

Medical 
Info. (S) 
to 
Database (T) 

Content 10.1 
10.9 12.5 
45.9 
3.6 
2.1 
CF 
18.3 
20.2 21.4 
47.6 
5.3 
3.9 
Hybrid 25.0 
26.5 28.4 
59.1 
6.4 
4.2 
Author 26.2 
29.6 32.2 
54.8 
10.5 
5.4 
Topic 
29.4 
26.3 34.7 
59.3 
11.5 
5.2 
Katz 
27.5 
28.3 30.7 
57.2 
10.5 
5.0 
CTL 
32.5 
30.0 36.9 
59.8 
11.4 
5.4 

Medical 
Info. (S) 
to 
Data 
Mining (T) 

Content 5.8 
5.7 
9.5 
19.8 
1.9 
0.9 
CF 
13.7 
17.8 18.9 
34.3 
2.7 
1.3 
Hybrid 18.0 
19.0 19.8 
36.7 
3.4 
1.3 
Author 20.1 
23.8 29.3 
64.4 
5.3 
2.1 
Topic 
26.0 
25.0 33.9 
48.1 
10.7 
5.6 
Katz 
21.2 
23.8 32.4 
48.1 
10.2 
4.8 
CTL 
30.0 
24.0 35.6 
49.6 
12.2 
6.0 

Visual. (S) 
to 
Data 
Mining (T) 

Content 9.6 
11.8 13.2 
18.9 
3.1 
1.8 
CF 
14.0 
20.8 26.4 
29.4 
6.9 
4.3 
Hybrid 16.0 
20.0 27.6 
30.1 
6.3 
4.4 
Author 22.0 
25.2 27.7 
31.1 
11.9 
6.7 
Topic 
26.3 
25.0 32.3 
31.4 
13.2 
8.8 
Katz 
23.0 
25.1 29.3 
30.2 
10.4 
5.4 
CTL 
28.3 
26.0 32.8 
36.3 
14.0 
9.1 

</table></figure>

			<note place="foot" n="2"> The ACT model can be considered as an extension of LDA [4], but considers the collaborative relationships between users and the difference of various objects (e.g., author, paper, and conference/journal).</note>

			<note place="foot" n="3"> http://arnetminer.org/collaboration</note>

			<note place="foot" n="4"> As for the hyperparameters α, αt, and β, following LDA [4], we empirically take fixed values (i.e., α = αq = 50/T , and β = 0.01). γ and γt are defined to represent our preference for crossdomain collaborations (i.e., γq = 3.0 and γ = 0.1). We did try different settings and found that the estimated topic models are not very sensitive to the hyperparameters.</note>

			<note place="foot" n="5"> http://arnetminer.org/collaborator</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<title level="m">Modern Information Retrieval</title>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fab: content-based, collaborative recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Balabanovi´cbalabanovi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shoham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="66" to="72" />
			<date type="published" when="1997-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Formal models for expert finding in enterprise corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR&apos;06</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="43" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Latent dirichlet allocation. JMLR</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Applying discrete pca in data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Buntine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jakulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI&apos;04</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="59" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Graph mining: Laws, generators, and algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Collabseer: a search engine for collaboration discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JCDL&apos;11</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="231" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Google news personalization: Scalable online collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Datar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rajaram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;07</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Item-based top-n recommendation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Deshpande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="143" to="177" />
			<date type="published" when="2004-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Rao-blackwellised particle filtering for dynamic bayesian networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI&apos;00</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="176" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On power-law relationships of the internet topology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM&apos;99</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="251" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The strength of weak ties</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Granovetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Sociology</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1360" to="1380" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Finding scientific topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PNAS&apos;04</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="5228" to="5235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Parameter estimation for text analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heinrich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<pubPlace>Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Leipzig</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Probabilistic latent semantic indexing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR&apos;99</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Referral web: Combining social networks and collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Selman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="63" to="65" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On social networks and collaborative recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Konstas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stathopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Jose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR&apos;09</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="195" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Sampling from large graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;06</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="631" to="636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Predicting positive and negative links in online social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;10</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="641" to="650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The link-prediction problem for social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liben-Nowell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JASIST</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1019" to="1031" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">New perspectives and methods in link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lichtenwalter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Lussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;10</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="243" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Random walks on graphs: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lovasz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Combinatorics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Expertise modeling for matching papers with reviewers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mimno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;07</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="500" to="509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Microarray analysis and tumor classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Quackenbush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New England Journal of Medicine</title>
		<imprint>
			<biblScope unit="volume">354</biblScope>
			<biblScope unit="page" from="2463" to="2472" />
			<date type="published" when="2006-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Combined regression and ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;10</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="979" to="988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A large scale machine learning system for recommending heterogeneous content in social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR&apos;11</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1337" to="1338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Probabilistic author-topic models for information discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Smyth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;04</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="306" to="315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Neighborhood formation and anomaly detection in bipartite graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM&apos;05</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="418" to="425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Multi-topic based query-oriented summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM&apos;09</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1147" to="1158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Topic level expertise search over heterogeneous networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning Journal</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="211" to="237" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Arnetminer: Extraction and mining of academic social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;08</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="990" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Relational learning via latent social dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;09</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="817" to="826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">On optimization of expertise matching with various constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="83" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Collaborative topic modeling for recommending scientific articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;11</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Factorization vs. regularization: fusing heterogeneous social relationships in top-n recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys&apos;11</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="245" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Expert finding in a social network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DASFAA&apos;07</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1066" to="1069" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
