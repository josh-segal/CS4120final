<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Cross-Collection Mixture Model for Comparative Text Mining</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atulya</forename><surname>Velivelli</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bei</forename><surname>Yu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of Electrical and Computer Engineering</orgName>
								<orgName type="department" key="dep3">Graduate School of Library and Information Science</orgName>
								<orgName type="institution" key="instit1">University of Illinois at Urbana Champaign</orgName>
								<orgName type="institution" key="instit2">University of Illinois at Urbana</orgName>
								<address>
									<settlement>Champaign</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Illinois at Urbana</orgName>
								<address>
									<settlement>Champaign</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Cross-Collection Mixture Model for Comparative Text Mining</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H33 [Informa- tion Search and Retrieval]: Text Mining General Terms: Algorithms Keywords: Comparative text mining</term>
					<term>mixture models</term>
					<term>clus- tering</term>
				</keywords>
			</textClass>
			<abstract>
				<p>In this paper, we define and study a novel text mining problem, which we refer to as Comparative Text Mining (CTM). Given a set of comparable text collections, the task of comparative text mining is to discover any latent common themes across all collections as well as summarize the similarity and differences of these collections along each common theme. This general problem subsumes many interesting applications, including business intelligence and opinion summarization. We propose a generative probabilistic mixture model for comparative text mining. The model simultaneously performs cross-collection clustering and within-collection clustering, and can be applied to an arbitrary set of comparable text collections. The model can be estimated efficiently using the Expectation-Maximization (EM) algorithm. We evaluate the model on two different text data sets (i.e., a news article data set and a laptop review data set), and compare it with a baseline clustering method also based on a mixture model. Experiment results show that the model is quite effective in discovering the latent common themes across collections and performs significantly better than our baseline mixture model.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Text mining is concerned with extracting knowledge and patterns from text <ref type="bibr" target="#b3">[5,</ref><ref type="bibr" target="#b4">6]</ref>. While there has been much research in text mining, most existing research is focused on one single collection of text. The goals are often to extract basic semantic units such as named entities, to extract relations between information units, or to extract topic themes.</p><p>In this paper, we study a novel problem of text mining referred to as Comparative Text Mining (CTM). Given a set of comparable text collections, the task of comparative text mining is to discover any latent common themes across all collections as well as summarize the similarity and differences of these collections along each common theme. Specifically, the task involves: (1) discovering the different common themes across all the collections; (2) for each discovered theme, characterize what is in common among all the collections and what is unique to each collection. The need for comparative text mining exists in many different applications, including business intelligence, summarizing reviews of similar products, and comparing different opinions about a common topic in general.</p><p>In this paper, we study the CTM problem and propose a generative probabilistic mixture model for CTM. The model simultaneously performs cross-collection clustering and withincollection clustering, and can be applied to an arbitrary set of comparable text collections. The mixture model is based on component multinomial distribution models, each characterizing a different theme. The common themes and collection-specific themes are explicitly modeled. The proposed model can be estimated efficiently using the ExpectationMaximization (EM) algorithm.</p><p>We evaluate the model on two different text data sets (i.e., a news article data set and a laptop review data set), and compare it with a baseline clustering method also based on a mixture model. Experiment results show that the model is quite effective in discovering the latent common themes across collections and performs significantly better than our baseline mixture model. The rest of the paper is organized as follows. In Section 2, we briefly introduce the problem of CTM. We then present a baseline simple mixture model and a new cross-collection mixture model in Section 3 and Section 4. We discuss the experiment results in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">COMPARATIVE TEXT MINING</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">A motivating example</head><p>With the popularity of e-commerce, online customer evaluations are becoming widely provided by online stores and third-party websites. Pioneers like amazon.com and epinions.com have accumulated large amounts of customer input including reviews, comments, recommendations and advice, etc. For example, the number of reviews in epinions.com is more than one million <ref type="bibr">[4]</ref>. Given a product, there could be up to hundreds of reviews, which is impossible for the readers to go through. It is thus desirable to summarize a collection of reviews for a certain type of products in order to provide the readers the most salient feedbacks from the peers. For review summarization, the most important task is to identify different semantic aspects of a product that the reviewers mentioned and to group the opinions according to these aspects to show similarities and differences in the opinions.</p><p>For example, suppose we have reviews of three different brands of laptops (Dell, IBM, and Apple), and we want to summarize the reviews. A useful summary would be a tabular representation of the opinions as shown in <ref type="table" target="#tab_0">Table 1</ref>, in which each row represents one aspect (subtopic) and different columns correspond to different opinions. It is, of course, very difficult, if not impossible to produce such a table completely automatically. However, we can achieve a less ambitious goal -identifying the semantic aspects and identifying the common and specific characteristics of each product in an unsupervised way. This is a concrete example of comparative text mining.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The general problem</head><p>The example above is only one of the many possible applications of comparative text mining. In general, the task of comparative text mining involves: (1) discovering the common themes across all the collections; (2) for each discovered theme, characterize what is in common among all the collections and what is unique to each collection. It is very hard to precisely define what a theme is, but it corresponds roughly to a topic or subtopic. The granularity of themes is application-specific. CTM is a fundamental task in exploratory text analysis. In addition to opinion comparison and summarization, it has many other applications, such as business intelligence (comparing different companies), customer relationship management (comparing different groups of customers), and semantic integration of text (comparing component text collections).</p><p>CTM is challenging in several ways: (1) It is a completely unsupervised learning task; no training data is available. (It is for the same reason that CTM can be very useful for many different purposes -it makes minimum assumptions about the collections and in principle we can compare any arbitrary partition of text.) (2) We need to identify themes across different collections, which is more challenging than identifying topic themes in one single collection. (3) The task involves a discrimination component -for each discovered theme, we also want to identify the unique information specific to each collection. Such a discrimination task is difficult given that we do not have training data. In a way, CTM goes beyond the regular one-collection text mining by requiring an "alignment" of multiple collections based on common themes.</p><p>Since no training data is available, in general, we must rely on unsupervised learning methods, such as clustering, to perform CTM. In this paper, we study how to use probabilistic mixture models to perform CTM. Below we first describe a simple mixture model for clustering, which represents a straightforward application of an existing text mining method, and then present a more sophisticated mixture model specifically designed for CTM. A naive solution to CTM is to treat the multiple collections as one single collection and perform clustering. Our hope is that some clusters would represent the common themes across the collections, while some others would represent themes specific to one collection (see <ref type="figure" target="#fig_0">Figure 1)</ref>. We now present a simple multinomial mixture model for clustering an arbitrary collection of documents, in which we assume there are k latent common themes in all collections, and each is characterized by a multinomial word distribution (also called a unigram language model). A document is regarded as a sample of a mixture model with these theme models as components. We fit such a mixture model to the union of all the text collections we have, and the obtained component multinomial models can be used to analyze the common themes and differences among the collections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">CLUSTERING WITH A SIMPLE MIXTURE MODEL</head><formula xml:id="formula_0">¢ ¡ ¤ £ ¦ ¥ ¦ § ¤ ¨© ¤ ¤ ¤ θ ¤ ¤ θ! " $ # &amp; % &amp; ' ( % 0 ) θ1 2 4 3 2 6 5 2 ! 7 ¤ ¤ 8 θ 5 " $ # 9 % &amp; ' ( % 0 @ θA</formula><p>Formally, let C = {C1, C2, ..., Cm} be m comparable collections of documents. Let θ1, ..., θ k be k theme unigram language models and θB be the background model for all the collections. A document d is regarded as a sample of the following mixture model (based on word generation).</p><formula xml:id="formula_1">p d (w) = λBp(w|θB) + (1 − λB) k B j=1 [π d,j p(w|θj )]</formula><p>where w is a word, π d,j is a document-specific mixing weight for the j-th aspect theme, and C k j=1 π d,j = 1. λB is the mixing weight of the background model θB. The log-likelihood of all the collections C is</p><formula xml:id="formula_2">log p(C|Λ) = m B i=1 B d∈C i B w∈V [c(w, d) × log(λBp(w|θB) + (1 − λB) k B j=1 (π d,j p(w|θj)))]</formula><p>where V is the set of all the words (i.e., vocabulary), c(w, d) is the count of word w in document d, and</p><formula xml:id="formula_3">Λ = ({θj , π d,j } k j=1</formula><p>is the set of all the theme model parameters. The purpose of using a background model is to "force" clustering to be done based on more discriminative words, leading to more informative and more discriminative component models. We control this effect through θB.</p><p>The model can be estimated using any estimator. For example, the Expectation-Maximization (EM) algorithm <ref type="bibr" target="#b2">[3]</ref> can be used to compute a maximum likelihood estimate with the following updating formulas:</p><formula xml:id="formula_4">p(z d,w = j) = π (n) d,j p (n) (w|θ j ) k j 񮽙 =1 π (n) d,j 񮽙 p (n) (w|θ j 񮽙 ) p(z d,w = B) = λ B p(w|θ B ) λ B p(w|θ B ) + (1 − λ B ) k j=1 π (n) d,j p (n) (w|θ j ) π (n+1) d,j = w∈V c(w, d)p(z d,w = j) j 񮽙 w∈V c(w, d)p(z d,w = j 񮽙 ) p (n+1) (w|θ j ) = m i=1 d∈C i c(w, d)(1 − p(z d,w = B))p(z d,w = j) w 񮽙 ∈V m i=1 d∈C i c(w 񮽙 , d)(1 − p(z d,w 񮽙 = B))p(z d,w 񮽙 = j)</formula><p>This mixture model is closely related to the probabilistic latent semantic indexing model (PLSI) proposed in <ref type="bibr" target="#b5">[7]</ref> and treats CTM as a single-collection text mining problem. However, such a simple model is inadequate for CTM for two reasons: (1) We have completely ignored the structure of collections. As a result, we may have clusters that represent only some, not all of the collections. (2) There is no easy way to identify which theme cluster represents the common information across collections and which represents specific information to a particular collection. Below we present a more sophisticated coordinated mixture model, which is specifically designed for CTM and addresses these two deficiencies.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CLUSTERING WITH A CROSS-COLLECTION MIXTURE MODEL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>񮽙񮽙񮽙񮽙񮽙񮽙񮽙</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The model</head><p>Our main idea for improving the simple mixture model for comparative text mining is to explicitly distinguish common theme clusters that characterize common information across all collections from special theme clusters that characterize collection-specific information. Thus we now consider k latent common themes as well as a potentially different set of k collection-specific themes for each collection (illustrated in <ref type="figure" target="#fig_1">Figure 2</ref>). These component models directly correspond to all the information we are interested in discovering. The sampling distribution of a word in document d (from collection Ci) is now collection-specific. Specifically, it involves the background model (θB), k common theme models (θ1, ..., θ k ), and k collection-specific theme models (θ1,i, ..., θ k,i ), which are to capture the unique information about the k themes in collection Ci. That is,</p><formula xml:id="formula_5">p d (w|C i ) = (1 − λ B ) k ¡ j=1 [π d,j (λ C p(w|θ j ) + (1 − λ C )p(w|θ j,i ))] +λ B p(w|θ B )</formula><p>where λB is the weight on the background model θB and λC is the weight on the common theme model θj (as opposed to the collection-specific theme model θj,i). Intuitively, when we "generate" a word, we first decide whether to use the background model θB according to λB; the larger λB is, the more likely we will use θB. If we decide not to use θB, then we need to decide which theme to use; this is controlled by π d,j , the probability of using theme j when generating words in d. Finally, once we decide which theme to use, we still need to decide whether we should use the common theme model or the collection-specific theme model, and this is controlled by λC, the probability of using the common model. The weighting parameters λB and λC are intentionally to be set by the user, and their interpretation is as follows. λB reflects our knowledge about how noisy the collections are. If we believe the text is verbose, then λB should be set to a larger value. In our experiments, a value of 0.9 − 0.95 often works well. λC indicates our emphasis on the commonality, as opposed to the speciality in comparative text mining. A larger λC would allow us to learn a richer common theme model, whereas a smaller one would learn a weaker common theme model, but stronger special models. The optimal value depends on the specific applications.</p><p>According to this generative model, the log-likelihood of the whole set of collections is</p><formula xml:id="formula_6">log p(C) = m B i=1 B d∈C i B w∈V [c(w, d) log[λBp(w|θB) +(1 − λB) k B j=1 π d,j (λCp(w|θj) + (1 − λC )p(w|θj,i))]]</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Parameter estimation</head><p>We estimate the background model θB using all the available text in the m text collections. That is,</p><formula xml:id="formula_7">ˆ p(w|θB) = C m i=1 C d∈C i c(w, d) C m i=1 C d∈C i C w 񮽙 ∈V c(w 񮽙 , d)</formula><p>Since λB and λC are set manually, this leaves us with the following parameters to estimate: (1) the common theme models, θ = {θ1, ..., θ k }; (2) the special theme models for each collection Ci, θC i = {θ1,i, ..., θ k,i }; and (3) the theme mixing weights for each document d:</p><formula xml:id="formula_8">π d = {π d,1 , ..., π d,k }. p(z d,C i ,w = j) = π (n) d,j (λC p (n) (w|θj ) + (1 − λC )p (n) (w|θj,i)) k j 񮽙 =1 π (n) d,j 񮽙 (λC p (n) (w|θ j 񮽙 ) + (1 − λC )p (n) (w|θ j 񮽙 ,i )) p(z d,C i ,w = B) = λB p(w|θB) λB p(w|θB) + (1 − λB ) k j=1 π (n) d,j (λC p (n) (w|θj ) + (1 − λC )p (n) (w|θj,i)) p(z d,C i ,j,w = C) = λC p (n) (w|θj ) λC p (n) (w|θj ) + (1 − λC )p (n) (w|θj,i) π (n+1) d,j = w∈V c(w, d)p(z d,C i ,w = j) j 񮽙 w∈V c(w, d)p(z d,C i ,w = j 񮽙 ) p (n+1) (w|θj) = m i=1 d∈C i c(w, d)(1 − p(z d,C i ,w = B))p(z d,C i ,w = j)p(z d,C i ,j,w = C) w 񮽙 ∈V m i=1 d∈C i c(w 񮽙 , d)(1 − p(z d,C i ,w 񮽙 = B))p(z d,C i ,w 񮽙 = j)p(z d,C i ,j,w 񮽙 = C) p (n+1) (w|θj,i) = m i=1 d∈C i c(w, d)(1 − p(z d,C i ,w = B))p(z d,C i ,w = j)(1 − p(z d,C i ,j,w = C)) w 񮽙 ∈V m i=1 d∈C i c(w 񮽙 , d)(1 − p(z d,C i ,w 񮽙 = B))p(z d,C i ,w 񮽙 = j)(1 − p(z d,C i ,j,w 񮽙 = C))</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3: EM updating formulas for the cross-collection mixture model</head><p>As in the simple mixture model, we can also use the EM algorithm to compute a maximum likelihood estimate. The updating formulas are shown in <ref type="figure">Figure 3</ref>. Each EM iteration involves scanning all the text once, so the algorithm is quite scalable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Using the model</head><p>Once the model is estimated, we will have k collectionspecific models for each of the m collections and k common theme models across all collections. Each of these models is a word distribution or unigram language model. The high probability words can characterize the theme/cluster extracted. Such words can often be used directly as a summary or indirectly (e.g., through a hidden Markov model) to extract relevant sentences to form a summary of the corresponding theme. The extracted word distributions can also be used in many other ways, e.g., to classify other text documents or to link the related passages in the text collections so that a user can navigate the information space for comparative analysis.</p><p>We can input our bias for CTM through setting λB and λC manually. Specifically, λB allows us to input our knowledge about the noise (stop words) in the data -if we know the text data is verbose, then we should set λB to a high value, whereas if the data is concise and mostly content-bearing keywords, then we need to set λB to a smaller value. Similarly, λC allows us to input a trade-off between extracting common theme models (setting λC to a higher value) vs. extracting collection-specific models (setting λC to a smaller value). Such biases cannot be learned by the maximum likelihood estimator. Indeed, maximizing the data likelihood is only a means to achieve our ultimate goal, which is why we want to regularize our model in a meaningful way so that we can impose certain preferences while maximizing the data likelihood. The flexibility and control provided by λB and λC make it possible for a user to control the focus of the results of comparative text mining.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EXPERIMENTS AND RESULT ANALYSIS</head><p>We evaluated the Simple Mixture model (SimpMix) and the Cross-Collection Mixture model (CCMix) on two domains -war news and laptop reviews.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">War news</head><p>The War news data consists of news excerpts on two comparable events: (1) Iraq war and (2) Afghanistan war, both of which occurred in the last two years. The Iraq war news excerpts were a combination of 30 articles from the CNN and BBC web sites over the last one year span. The Afghanistan war data consists of 26 news articles downloaded from the CNN and BBC web sites for one year starting from Nov. 2001. Our goal is to compare these two wars and find out their common and specific characteristics.</p><p>The results of using either the simple mixture model or the cross-collection mixture model are shown in <ref type="table" target="#tab_2">Table 2</ref>, where the top words of each theme model are listed along with their probabilities. We set λB = 0.95 for SimpMix and set λ b = 0.9, λC = 0.25 for CCMix; in both cases, the number of clusters is fixed to 5. Variations of these parameters are discussed later.</p><p>We see that although there are some interesting themes in the results of SimpMix (e.g., cluster3 and cluster4 appear to be about American and British inquiry into the presence of weapons in Iraq, respectively, while cluster2 suggests the presence of British soldier in Basra, a town in southern Iraq), they are all about Iraq war. We do not see any obvious theme common to both Iraq war and Afghanistan war. This is expected given that SimpMix pools all documents together without exploiting the collection structure.</p><p>In contrast, the results of CCMix explicitly suggest the common themes and the corresponding collection-specific themes. For example, cluster3 clearly suggests that in both wars, there has been loss of lives. Furthermore, the top words in the corresponding Iraq theme include names of some key defense people that are involved in the Iraq war (e.g., "Hoon" is the last name of the british defense secretary and "Sanchez" is the last name of the U.S General in Iraq). In comparison, the top words in the corresponding Afghanistan theme includes the name of the U.S Defense secretary who had an important role in the Afghan war.</p><p>Cluster4 and cluster5 are also meaningful themes. The common theme captured in Cluster4 is the Monday briefings by an official spokesman of a political administration during both wars; the corresponding special themes indicate the difference in the topics discussed in the briefings (e.g., weapon inquiry for Iraq war and Bin Laden for Afghanistan war). The common theme of Cluster5 is about the diplomatic role played by the United Nations (UN). The corresponding special themes again suggest the difference between the two wars. The Iraq theme indicates the role of UN in sending weapon inspectors to Iraq; the Afghanistan theme refers to Northern Alliance that received aid from the UN and came to power in Afghanistan after the defeat of Taliban.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Laptop customer reviews</head><p>This data set was constructed to test our models for comparing opinions of customers on different laptops. We manually downloaded the following 3 review sets from epinions.com <ref type="bibr">[4]</ref>, filtering out the misplaced ones: Apple iBook (M8598LL/A) Mac Notebook (34 reviews), Dell Inspiron 8200 (8TWORH) PC Notebook (22 reviews), IBM ThinkPad T20 2647 (264744U) PC Notebook (42 reviews).</p><p>The results on this data set are generally similar to those on war news. Due to the limit of space, we only show the CCMix results in <ref type="table" target="#tab_3">Table 3</ref>, which are obtained by setting λC =.7 and λB=.96 and fixing the number of clusters to 8. Here we again see many very interesting common themes; indeed, the top two words in the common themes can provide a very good summary of the themes (e.g., "sound and speakers" for cluster1, "battery hours" for cluster5, and "Microsoft Office" for cluster8). However, the special themes, although suggesting some differences among the three laptops, are much harder to interpret. This may be because there is a great deal of variation in product-specific opinions in the data, which makes the data extremely sparse for learning a coherent collection-specific theme for each of the eight themes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Parameter tuning</head><p>When we vary λB and λC in CCMix, the results are generally different. Specifically, when λB is set to a small value, non-informative stop words tend to show up in common themes. A reasonable value for λB is generally higher than 0.9 -in that case, the model automatically eliminates the non-informative words from the theme clusters, allowing for more discriminative clustering. Indeed, in all our experiments, we have intentionally retained all the stop words, and the model is clearly able to filter out non-informative words, though in some cases, they still show up as top words in the common themes of the news data. They can be "eliminated" by using an even higher λB, but then we may end up having insufficient information to learn a common theme reliably. λC affects the vocabulary allocation between the common and collection-specific themes. In the news data experiments, when we change λC to a value above 0.4, the collection-specific terms would dominate the common theme models. In the laptop data experiments, when λC is less than 0.7, we lose many content keywords of the common themes to the corresponding collection-specific themes. Both λB and λC are intentionally left for a user to tune so that we can incorporate application-specific bias into the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">RELATED WORK</head><p>The most related work to our work is the coupled clustering method presented in <ref type="bibr" target="#b6">[8]</ref>, which appears to be one of the very few studies considering the clustering problem in multiple collections. They extend the information bottleneck approach to discover common clusters across different collections. Comparative text mining goes beyond this by analyzing both the similarities and collection-specific differences. We also use a completely different approach based on probabilistic mixture models. Another related work is <ref type="bibr" target="#b8">[10]</ref>, where cross-training is used for learning classifiers from multiple document sets. Our work differs from it in that we perform unsupervised learning. The aspect models studied in <ref type="bibr" target="#b5">[7,</ref><ref type="bibr" target="#b1">2]</ref> are also related to our work but they are closer to our baseline model and are not designed for comparing multiple collections. There are many studies in document clustering <ref type="bibr" target="#b0">[1]</ref>. Again, the difference lies in that they consider only one collection and thus are similar to the baseline model.</p><p>Our work is also related to document summarization, especially multiple document summarization (e.g., <ref type="bibr" target="#b7">[9,</ref><ref type="bibr" target="#b10">12]</ref>). Indeed, we can the results of CTM as a special form of summary of multiple text collections. However, an important difference is that while a summary intends to retain the explicit information in text (to maintain fidelity), CTM aims at extracting non-obvious implicit patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSIONS AND FUTURE WORK</head><p>In this paper, we define and study a novel text mining problem referred to as comparative text mining. It is con- cerned with discovering any latent common themes across a set of comparable collections of text as well as summarizing the similarities and differences of these collections along each theme. We propose a generative cross-collection mixture model for performing comparative text mining. The model simultaneously performs cross-collection clustering and withincollection clustering, and can be applied to an arbitrary set of comparable text collections. We define the model and present the EM algorithm that can estimate the model efficiently. We evaluate the model on two different text data sets (i.e., a news article data set and a laptop review data set), and compare it with a baseline clustering method based on a simple mixture model. Experiment results show that the cross-collection mixture model is quite effective in discovering the latent common themes across collections and performs significantly better than the baseline simple mixture model. The proposed model has many obvious applications in opinion summarization and business intelligence. It also has many other less obvious applications in the general area of text mining and semantic integration of text. For example, our model can be used to compare the course web pages from the major computer science department web sites to discover core computer science topics. It can also be used to compare literature collections in different communities to support concept switching <ref type="bibr" target="#b9">[11]</ref>.</p><p>The work reported in this paper is just an initial step toward a promising new direction. There are many interesting future research directions. First, it may be interesting to explore how we can further improve the CCMix model and its estimation. One interesting direction is to explore the Maximum A Posterior (MAP) estimator, which would allow us to incorporate more prior knowledge in a principled way. For example, a user may already have certain thematic aspects in mind. With MAP estimation, we can easily add that bias to the component models. Second, we can generalize our model to model semi-structured data to perform more general comparative data mining. One way to achieve this goal is to introduce additional random variables in each component model so that we can model any structured data. Finally, it would be very interesting to explore how we could exploit the learned theme models to provide additional help to a user who wants to perform comparative analysis. For example, the learned common theme models can be used to construct a hidden Markov model (HMM) to identify the parts in the text collections about the common themes, and to connect them through automatically generated hyperlinks. This would allow a user to easily navigate through the common themes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The Simple Mixture Model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The Cross-Collection Mixture Model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 : A tabular summary</head><label>1</label><figDesc></figDesc><table>Subtopics 
Dell 
IBM Apple 
Battery life long enough short 
short 
Memory 
good 
bad 
good 
Speed 
slow 
fast 
fast 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 θ 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 θ 񮽙񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 θ 񮽙</head><label>񮽙</label><figDesc></figDesc><table>񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 
񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 
񮽙 񮽙 񮽙 񮽙 񮽙 
θ 񮽙 񮽙 񮽙 

񮽙 񮽙 
񮽙 񮽙 
񮽙 񮽙 

񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 
񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 
񮽙 񮽙 񮽙 񮽙 񮽙 
θ 񮽙 񮽙 񮽙 

񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 
񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 
񮽙 񮽙 񮽙 񮽙 񮽙 
θ 񮽙 񮽙 񮽙 

񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 
񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 
񮽙 񮽙 񮽙 񮽙 񮽙 
θ 񮽙 񮽙 񮽙 

񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 
񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 
񮽙 񮽙 񮽙 񮽙 񮽙 
θ 񮽙 񮽙 񮽙 

񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 
񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 񮽙 
񮽙 񮽙 񮽙 񮽙 񮽙 
θ 񮽙 񮽙 񮽙 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 : War news results using SimpMix model (top) vs. CCMix model (bottom)</head><label>2</label><figDesc></figDesc><table>Cluster1 
Cluster2 
Cluster3 
Cluster4 
Cluster5 
Common 
will 0.019 
british 0.017 
weapons 0.022 
inquiry 0.052 
countries 0.026 
theme 
let 0.012 
soldiers 0.015 
kay 0.021 
intelligence 0.036 
contracts 0.023 
words 
united 0.012 
baghdad 0.015 
rumsfeld 0.017 
dossier 0.024 
allawi 0.012 
god 0.011 
air 0.011 
commission 0.014 
hutton 0.021 
hoon 0.012 
inspectors 0.011 
basra 0.011 
group 0.014 
claim 0.019 
russian 0.010 
your 0.010 
mosque 0.010 
senate 0.011 
wmd 0.019 
international 0.010 
nation 0.010 
southern 0.01 
survey 0.010 
mps 0.018 
russia 0.009 
n 0.010 
fired 0.010 
paper 0.010 
committee 0.017 
reconstruction 0.009 

Cluster1 
Cluster2 
Cluster3 
Cluster4 
Cluster5 

Common 
us 0.042 
mr 0.029 
killed 0.036 
monday 0.036 
united 0.042 
theme 
nation 0.030 
marines 0.025 
month 0.032 
official 0.032 
nations 0.04 
words 
will 0.024 
dead 0.023 
deaths 0.023 
i 0.029 
with 0.03 
action 0.022 
general 0.022 
one 0.023 
would 0.028 
is 0.025 
re 0.022 
defense 0.019 
died 0.022 
where 0.025 
it 0.024 
border 0.019 
key 0.018 
been 0.022 
do 0.025 
they 0.023 
its 0.017 
since 0.018 
drive 0.018 
spokesman 0.022 
diplomatic 0.023 
ve 0.016 
first 0.016 
according 0.015 
political 0.021 
blair 0.022 

Iraq 
god 0.022 
iraq 0.022 
troops 0.016 
intelligence 0.049 
n 0.03 
theme 
saddam 0.016 
us 0.021 
hoon 0.015 
weapons 0.034 
weapons 0.024 
words 
baghdad 0.013 
baghdad 0.017 
sanchez 0.012 
inquiry 0.028 
inspectors 0.023 
your 0.012 
nato 0.015 
billion 0.01 
commission 0.017 
council 0.016 
live 0.01 
iraqi 0.013 
spokeswoman 0.008 
independent 0.016 
declaration 0.015 

Afghan 
paper 0.021 
story 0.028 
taleban 0.026 
bin 0.031 
northern 0.040 
theme 
afghan 0.019 
full 0.026 
rumsfeld 0.020 
laden 0.031 
alliance 0.040 
words 
meeting 0.014 
saturday 0.016 
hotel 0.012 
steinberg 0.027 
kabul 0.030 
euro 0.012 
e 0.015 
front 0.011 
taliban 0.023 
taleban 0.025 
highway 0.012 
rabbani 0.012 
dropped 0.010 
chat 0.019 
aid 0.020 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 3 : Laptop review results using CCMix model</head><label>3</label><figDesc></figDesc><table>Cluster1 
Cluster2 
Cluster3 
Cluster4 
Cluster5 
Cluster6 
Cluster7 
Cluster8 

C 
sound 0.035 
port 0.023 
ram 0.105 
m 0.027 
battery 0.129 
t 0.039 
cd 0.095 
office 0.037 
O 
speakers 0.035 
jack 0.021 
mb 0.037 
trackpad 0.018 
hours 0.080 
modem 0.017 
drive 0.076 
microsoft 0.021 
M 
playback 0.034 
ports 0.018 
memory 0.034 
chip 0.013 
life 0.060 
internet 0.017 
rw 0.055 
little 0.018 
M 
feel 0.019 
will 0.018 
256mb 0.027 
improved 0.012 
5 0.038 
later 0.014 
dvd 0.049 
basic 0.015 
O 
pros 0.017 
your 0.017 
128mb 0.021 
volume 0.012 
end 0.016 
configuration 0.014 
combo 0.025 
6 0.014 
N 
cons 0.017 
warm 0.013 
tech 0.020 
did 0.011 
3 0.016 
free 0.013 
drives 0.023 
under 0.013 
market 0.017 
keep 0.012 
128 0.020 
latch 0.011 
high 0.015 
vga 0.012 
rom 0.020 
mhz 0.012 
size 0.014 
down 0.012 
support 0.018 
make 0.010 
processor 0.014 
were 0.012 
floppy 0.017 
word 0.011 

D 
rests 0.026 
banias 0.019 
options 0.039 
inspiron 0.061 
dells 0.032 
fans 0.019 
apoint 0.017 
0 0.046 
E 
palm 0.022 
svga 0.014 
sodimm 0.025 
pentium 0.052 
ran 0.017 
shipping 0.017 
blah 0.015 
angle 0.018 
L 
9000 0.020 
record 0.014 
eraser 0.021 
8200 0.03 
prong 0.015 
2nd 0.016 
hook 0.011 
portion 0.0154 
L 
smart 0.018 
supposedly 0.013 
crucial 0.018 
toshiba 0.027 
requiring 0.014 
tracking 0.015 
tug 0.011 
usb 0.0153 
reader 0.018 
rebate 0.013 
sdram 0.018 
440 0.026 
second 0.011 
spoke 0.015 
2499 0.011 
specials 0.014 

A 
magazine 0.011 
osx 0.040 
macos 0.019 
macos0.016 
g4 0.016 
iphoto 0.031 
airport 0.075 
appleworks 0.060 
P 
ipod 0.010 
quartz 0.015 
personal 0.018 
netscape 0.013 
interlaced 0.016 
itunes 0.027 
burn 0.035 
word 0.021 
P 
strong 0.01 
instance 0.014 
shield 0.016 
apache 0.009 
mac 0.016 
import 0.021 
4x 0.018 
result 0.016 
L 
icon 0.009 
underneath 0.012 
airport 0.016 
ie5 0.008 
imac 0.014 
book 0.018 
reads 0.014 
spreadsheet 0.013 
E 
choppy 0.008 
cooling 0.012 
installation 0.015 
ll 0.008 
powermac 0.012 
quicktime 0.016 
schools 0.013 
excel 0.012 

I 
technology 0.023 
rj 0.033 
exchange 0.023 
company 0.021 
thinkpad 0.077 
thinkpads 0.020 
t20 0.04 
list 0.015 
B 
outdated 0.020 
chik 0.018 
hassle 0.016 
570 0.017 
ibm 0.047 
connector 0.018 
ultrabay 0.030 
factor 0.013 
M 
surprisingly 0.018 
dsl 0.017 
disc 0.015 
turn 0.017 
covers 0.029 
connectors 0.018 
tells 0.021 
months 0.013 
trackpoint 0.014 
45 0.015 
t23 0.012 
buttons 0.015 
lightest 0.028 
bluetoot 0.018 
device 0.021 
cap 0.013 
recommend 0.013 
pacbell 0.012 
cdrw 0.015 
numlock 0.012 
3000 0.027 
sturdy 0.011 
number 0.020 
helpdesk 0.0128 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Distributional clustering of words for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGIR</title>
		<meeting>ACM SIGIR</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Latent Dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Royal Statist. Soc. B</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Knowledge discovery in textual databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Untangling text data mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL&apos;99</title>
		<meeting>ACL&apos;99</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Probabilistic latent semantic indexing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGIR&apos;99</title>
		<meeting>ACM SIGIR&apos;99</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Coupled clustering: a method for detecting structural correspondence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Marx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Buhmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="747" to="780" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Towards multidocument summarization by reformulation: Progress and prospects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Klavans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Hatzivassiloglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI-99</title>
		<meeting>AAAI-99</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cross-training: Learning probabilistic mappings between topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sarawagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Godbole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGKDD</title>
		<meeting>ACM SIGKDD</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The interspace: Concept navigation across distributed communities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Schatz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="54" to="62" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generic summarization and keyphrase extraction using mutual reinforcement principle and sentence clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM SIGIR</title>
		<meeting>ACM SIGIR</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
