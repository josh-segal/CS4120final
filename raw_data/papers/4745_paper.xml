<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Distributed Computation of the Mode</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 18-21, 2008</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Kuhn</surname></persName>
							<email>kuhn@inf.ethz.ch</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Locher</surname></persName>
							<email>lochert@tik.ee.ethz.ch</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Schmid</surname></persName>
							<email>schmiste@in.tum.de</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute of Theoretical Computer Science</orgName>
								<orgName type="department" key="dep2">Institut für Informatik Technische</orgName>
								<orgName type="laboratory">Computer Engineering and Networks Laboratory (TIK) ETH</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<postCode>8092, 8092</postCode>
									<settlement>Zurich, Zurich, Zurich</settlement>
									<country>Switzerland, Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Universität München</orgName>
								<address>
									<postCode>85748</postCode>
									<settlement>Garching</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Distributed Computation of the Mode</title>
					</analytic>
					<monogr>
						<title level="m">PODC&apos;08</title>
						<meeting> <address><addrLine>Toronto, Ontario, Canada</addrLine></address>
						</meeting>
						<imprint>
							<date type="published">August 18-21, 2008</date>
						</imprint>
					</monogr>
					<note>Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. 978-1-59593-989-0/08/08 ...$5.00.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>F22 [Analysis of Algorithms and Problem Complex- ity]: Nonnumerical Algorithms and Problemscomputations on discrete structures</term>
					<term>G22 [Discrete Mathematics]: Graph Theorygraph al- gorithms</term>
					<term>G22 [Discrete Mathematics]: Graph Theorynetwork problems General Terms Algorithms, Theory Keywords Aggregation, Distributed Algorithms, Mode, Most Frequent Element</term>
				</keywords>
			</textClass>
			<abstract>
				<p>This paper studies the problem of computing the most frequent element (the mode) by means of a distributed algorithm where the elements are located at the nodes of a network. Let k denote the number of distinct elements and further let m i be the number of occurrences of the element e i in the ordered list of occurrences m 1 &gt; m 2 ≥ ... ≥ m k. We give a deterministic distributed algorithm with time complexity O(D+k) where D denotes the diameter of the graph, which is essentially tight. As our main contribution, a Monte Carlo algorithm is presented which computes the mode in O(D + F 2 /m 2 1 · log k) time with high probability, where the frequency moment F is dened as F = P k i=1 m i. This algorithm is substantially faster than the deterministic algorithm for various relevant frequency distributions. Moreover , we provide a lower bound of Ω(D + F 5 /(m 5 1 B)), where B is the maximum message size, that captures the eect of the frequency distribution on the time complexity to compute the mode.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>A fundamental requirement of decentralized systems such as, e.g., wireless sensor networks or peer-to-peer networks, is that statistical data about these systems can be acquired in a distributed fashion. A network component may want to analyze relevant data which has been accumulated in the network in order to learn about the state of the system. For example, a participant in a peer-to-peer network might be interested in the most popular les or in the total number of available les. All queries must be performed eciently as nodes may have limited resources such as a small energy supply in the case of sensor networks, or because the size of the network may forbid any operation that requires a single entity to communicate repeatedly with a large number of other entities in the system.</p><p>Fortunately, many aggregation functions can be computed in the network itself. Distributive (max, min, count, sum) and algebraic (plus, minus, average, variance) aggregation functions can be computed as follows <ref type="bibr" target="#b15">[15]</ref>: In a rst step, a spanning tree is constructed on which the aggregations are performed. The root sends a message along the spanning tree, asking the leaves to start the aggregation. The inner nodes of the spanning tree wait until all their children have sent their values, and subsequently forward the aggregated value to their respective parent. The time complexity of these operations is <ref type="bibr">O(D)</ref> where D denotes the diameter of the spanning tree. Even order statistics and percentiles can be computed eciently by using a k-selection algorithm <ref type="bibr" target="#b10">[10]</ref>, which computes the k th smallest element in the network.</p><p>Although a wide range of queries can be computed by combining these aggregation functions, there are essential queries that cannot be answered using any of these functions, e.g., How many disjoint elements are there in the network? or Which element occurs most often among all elements?. While it has been shown that the number of disjoint elements can be approximated eciently <ref type="bibr" target="#b6">[6]</ref>, less is known about the complexity of nding the mode, i.e., the element which occurs most often, in a distributed fashion. An algorithm to compute the mode distributively is a useful tool for popularity analyses in large networks.</p><p>This paper presents a deterministic algorithm which computes the mode in time <ref type="bibr">O(D + k)</ref> for general distributions, where D is the network diameter and k is the total number of distinct elements; this is essentially tight up to logarithmic factors. Our main result however is a distributed Monte Carlo algorithm to nd the mode in general graphs. This algorithm is especially suited for skewed distributions which naturally arise in various contexts. For example, the frequencies of terms on webpages, les in le-sharing networks etc., are distributed according to a power law <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b17">17]</ref>. We point out that the time complexity of our algorithm is fairly low for such distributions, but our bound on the time complexity is more general and holds for all distributions. Most of our results are expressed in terms of the frequency moments F = P k i=1 m i , where m i denotes the number of occurrences of the element ei in the ordered list of occurrences, i.e., m1 &gt; m2 ≥ . . . ≥ m k . <ref type="bibr" target="#b0">1</ref> The proposed algorithm nds the mode in O(D +F 2 /m 2 1 ·log k) time with probability at least 1 − 1/k c for a constant c ≥ 1. Moreover, we show that it is generally hard to compute the mode for arbitrary distributions by proving a lower bound of Ω(D+F5/(m <ref type="bibr" target="#b5">5</ref> 1 B)), where B is the maximum message size.</p><p>The remainder of this paper is organized as follows. In the subsequent section (Section 2), related work is reviewed. The model used in this work is introduced in Section 3. Our deterministic and randomized algorithms are both discussed in Section 4, together with their respective analyses. In Section 5, the aforementioned lower bound is proven. As an example for skewed distributions, we give the time complexity of the randomized algorithm in the case where the frequencies of the elements follow power laws in Section 6. Finally, the paper concludes in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>As mentioned before, while certain aggregation functions such as the sum, minimum or maximum etc. can be computed eciently both in distributed and non-distributed settings, other functions are more dicult. In a recent paper by <ref type="bibr">Kuhn et al.</ref> [10] a randomized algorithm for the kselection problem, where the goal is to nd the k th smallest element, is presented. In a graph of diameter D consisting of n nodes, where each node holds a single element, the time complexity is O(D log D n) with high probability, which matches the lower bound of Ω(D log D n) also derived in this work. Thus, nding the median is asymptotically more difcult than computing distributive and algebraic functions.</p><p>Flajolet et al. <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b8">8]</ref> have studied the problem of determining the number of distinct elements in a multiset. In their probabilistic LogLog algorithm, all elements are hashed into suciently long binary strings in such a way that all bits closely resemble random, independent and uniformly distributed bits. As the number of elements that hash to a value with a prex of x 0-bits is k/2 x in expectation, where k denotes the number of distinct elements, the basic idea of the algorithm is that the length of the longest prex consisting of 0-bits can be used as an approximation for log 2 k. By repeating this step m times and by correcting a systematic bias in the asymptotic limit, the resulting estimate is asymptotically unbiased and the standard error is approximately 1.30/ √ m. A simple reduction from the set disjointness problem shows that the bit complexity to nd the true value k is at least Ω(k) <ref type="bibr" target="#b14">[14]</ref>. This implies that, while nding the exact number of distinct elements is in general hard, an accurate estimate can be computed eciently. The problem of nding the mode, the most frequent element in a list for random access machines has been studied by Munro et al. <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b13">13]</ref>. In <ref type="bibr" target="#b5">[5]</ref>, they give an algorithm which needs n log n/m + o(n log n/m) + O(n) comparisons in the worst-case, where n is the total number of elements in the list and m is the frequency of the mode. This is asymptotically optimal up to lower order terms. Farzan et al. <ref type="bibr" target="#b7">[7]</ref> investigate a cache-oblivious model, i.e., a random access memory model with a memory hierarchy where the cache sizes are unknown. The paper presents an optimal randomized algorithm and a near-optimal deterministic algorithm to compute the mode which minimize the number of cache misses.</p><p>Alon et al. <ref type="bibr" target="#b0">[1]</ref> have studied the space complexity of approximating the frequency moments F = P k i=1 m i in a streaming model (i.e., only one linear pass through the input is done). Note that the frequency moment F∞ = lim →∞ (F ) 1// = max 1≤i≤k m i is the number of occurrences of the mode. In particular, in this work the lower bound technique used in <ref type="bibr" target="#b11">[11]</ref> is adapted to show that for any xed k ≥ 6 and γ &lt; 1/2, given an input sequence I of at most n elements taken from the set N = {1, 2, ..., n}, any randomized algorithm that outputs a number Z k such that</p><formula xml:id="formula_0">P[|Z k − F k | &gt; 0.1F k ]</formula><p>&lt; γ uses at leastΩ(n 1−5/k ) memory bits. This implies a lower bound of Ω(n) on the bit complexity to compute the frequency of the mode. It also follows that computing the mode itself requires Ω(n) bits, as the frequency of the mode can be computed trivially in O(D) time once the mode is known.</p><p>While preparing the camera-ready version, we found a paper by Charikar, Chen, and Farach-Colton studying the space complexity of nding frequent elements in a streaming model <ref type="bibr" target="#b2">[3]</ref>. Using a dierent algorithm but somewhat similar techniques, they give an algorithm with a space complexity of O ` (k+F2/m 2 k )·log n ´ that nds k elements with frequency at least (1 − ε)m k with high probability, where m k is the frequency of the k th -most frequent element. Together with some of the ideas of this paper, the techniques of <ref type="bibr" target="#b2">[3]</ref> can be adapted for the distributed scenario yielding an alternative distributed algorithm with the same time complexity as the algorithm introduced in this paper. Similarly, the techniques of this paper could also be used to solve the problem of <ref type="bibr" target="#b2">[3]</ref> with the same space complexity. We provide a deterministic algorithm which is essentially asymptotically optimal for arbitrary frequency distributions. Furthermore, we derive general upper and lower bounds on the time complexity taking the frequency distribution of the elements into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">MODEL</head><p>We are given a connected graph G = (V, E) of diameter D with node set V and edge set E. The diameter of a graph is dened as the length of the longest shortest path between any two nodes. Each node v ∈ V stores one or more elements e i . There are K possible elements, i.e., each element e i is chosen from an alphabet A, where |A| = K. For simplicity, we will assume that the alphabet is the set {1, ..., K}, henceforth denoted by <ref type="bibr">[K]</ref>; this also implies that the elements can be ordered. Each element e i ∈ A can appear multiple times, and we dene m i to be the frequency of the element e i , where m 1 &gt; m 2 ≥ ... ≥ m k . We assume that the frequencies mi are chosen from the set <ref type="bibr">[M ]</ref>. Let k denote the total number of distinct elements, and let m = P k i=1 m i be the total number of elements. This paper will often refer to the following denition. Definition 3.1. (Frequency Moments) The th frequency moment F of a multiset containing m i elements of type ei ∈ <ref type="bibr">[K]</ref> is dened as F = P k i=1 m i . Observe that F0 = k is the number of distinct elements in the multiset, and F 1 = m is the total number of elements. For the sake of simplicity, when describing the algorithm we will assume that the nodes know the frequency moments F0 and F2 as well as the frequency m1 of the mode. Estimates of these quantities can be obtained eciently in parallel to the computation of the mode, as we will show in Section 4.3.</p><p>The nodes compute the mode by exchanging messages. Two nodes can directly send a message to each other if and only if they are connected by an edge in G. We consider a classic synchronous message passing model as, e.g., described in <ref type="bibr" target="#b15">[15]</ref>. Our algorithms are described in terms of synchronous rounds. In every round, each node can receive a message from all adjacent nodes, perform some local computations, and send messages to all adjacent nodes. The time complexity of an algorithm is the number of rounds needed until every node terminates. Note that all our results also hold if we allow asynchronous communication since every synchronous algorithm can be reformulated as an asynchronous algorithm of the same time complexity <ref type="bibr" target="#b15">[15]</ref>. We restrict the size of each message to B ∈ O(log K + log M + log n) bits. The main obstacle for computations in the described model is edge congestion that is caused by the bound on the size of the messages. In fact, with arbitrarily large messages, a single convergecast a simple ooding-echo operationwould suce to accumulate all elements at a single node, which could subsequently solve any problem locally.</p><p>Finally, in this paper it is assumed that a breadth-rst search spanning tree rooted at the node initiating the algorithm has been pre-computed. As computing such a tree only takes 2D time and all our time bounds are at least linear in D, this assumption is not critical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">ALGORITHMS</head><p>First, the deterministic algorithm to compute the mode is presented, together with the proof of the lower bound for arbitrary frequency distributions. In the second subsection, the randomized algorithm ALG mode whose running time crucially depends on the frequency distribution is described and analyzed. Finally, it is proven that ALG mode has the same time complexity when a small quasi-random family of hash functions is used, which permits the use of small messages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Deterministic Algorithm</head><p>There is a straightforward deterministic algorithm to nd the mode executed on the pre-computed spanning tree. We assume that there is a total order on all the elements, i.e., e 1 &gt; . . . &gt; e k . The algorithm starts at the leaves of the tree which send element-frequency pairs ei, mi to their parents in increasing order starting with the smallest element that they possess. Any inner node v stores these pairs received from its children and sums up the frequencies for each distinct element. Node v forwards e i , m i , where m i is the accumulated frequency of ei in the subtree rooted at v, to its parent as soon as v has received at least one pair ej, mj from each of its children such that e j ≥ e i . Any node v sends e i , m i to its parent at time t ≤ h + i where h is the height of the subtree rooted at v. This claim clearly holds for the leaves as each leaf can send the i th smallest element e i at latest at time i. Inductively, a node v thus receives at least the i th smallest element after h+i−1 time, after which it can forward the element including the accumulated frequency to its parent. Observe that there is no congestion, as node v has already sent all smaller element-frequency pairs in earlier rounds. Thus, the algorithm terminates after at most O(D +k) steps. Note that this algorithm does not only compute the mode and its frequency m 1 , but also the frequencies of all other elements.</p><p>Similarly to the lower bound for the number of distinct elements, a lower bound for the mode problem follows by reduction from the well-known set disjointness problem. It has been shown that two entities each holding a set of elements of cardinality k/2 must exchange Ω(k) bits in order to determine whether the two sets are disjoint, even using randomization <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b11">11,</ref><ref type="bibr" target="#b16">16]</ref>. This bit complexity implies a time lower bound of Ω(k/B), as by denition each message can contain at most B bits. Since there are distributions where determining if the sets are disjoint requires Ω(k/B) time and computing the mode for these distributions solves the disjointness problem, 2 it follows that computing the mode also requires Ω(k/B) time. As D is also a natural lower bound in the distributed model, the time lower bound for the mode problem is</p><formula xml:id="formula_1">Ω(D + k/B).</formula><p>Although this simple deterministic algorithm is optimal up to a factor B, it is worth investigating other algorithms which take the distribution of the elements into account. In particular, the skewness of the distribution can reasonably be expected to aect the eciency of an algorithm to compute the mode. In the following, we present a randomized algorithm whose time complexity is considerably lower for various distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Randomized Algorithm</head><p>In this section the randomized algorithm ALG mode is introduced, followed by a thorough analysis of its time complexity. In order to compute the mode, ALG mode makes extensive use of hash functions. Our analysis is organized in two parts. First, we assume that the hash functions are chosen independently and uniformly from the set of all possible hash functions mapping the elements e i ∈ <ref type="bibr">[K]</ref> to a hash value in the required range R. We require the size of the range R to be only 2; however, selecting any of these 2 K possible hash functions at random still entails a large communications overhead as choosing one hash function requires the communication of K bits. Therefore, we subsequently show that ALG mode still works if a random hash function is selected from a much smaller set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Algorithm</head><p>We rst summarize the basic mechanism underlying the algorithm ALG mode . Each node in the graph stores a local counter c(e i ), which is initially 0, for each of its t elements e1, . . . , et. The algorithm uses hash functions that map each element randomly to one of two bins with equal probability. All nodes use the same hash function to compute and subsequently forward the number of its elements that mapped to the rst and the second bin. Each counter c(e i ) is incremented by the number of elements that have been mapped Algorithm 1 countElementsInBins(h) at node v with mul-</p><formula xml:id="formula_2">tiset e 1 , . . . , e t : 1: c0 = |{ei : h(ei) = −1}| 2: c1 = |{ei : h(ei) = +1}| 3: if Γ(v) = ∅ then 4:</formula><p>send c 0 , c 1 to p(v) 5: else <ref type="bibr">6:</ref> for all vj ∈ Γ(v) in parallel do <ref type="bibr" target="#b7">7</ref>:</p><formula xml:id="formula_3">c (j) 0 , c (j) 1 = countElementsInBins(h) 8: send c 0 , c 1 + P j∈Γ(v) c (j) 0 , c (j) 1 to p(v)</formula><p>to the same bin as element ei. The idea is to determine the mode by repeating this procedure using dierent hash functions. Since the mode is likely to end up in the larger bin more often than the other elements, the counter c(e 1 ) will grow faster than the counters of the other elements. After a rst phase, which reduces the set of candidates for the mode, the frequency of each remaining candidate is computed separately in a second phase. The time complexity is bounded by the time required to nd a small set of candidates and by the time to check these candidates.</p><p>We will now study each step of the algorithm in greater detail. The root node, i.e., the node interested in computing the mode, selects r 1 hash functions h 1 , . . . , h r 1 where hi : A → {−1, +1}, i.e., each hash function maps every element to one of the two bins. The parameter r1 will be determined later in the analysis of the algorithm. In the following, we will represent the two bins as a tuple c 0 , c 1 , where c i denotes the number of elements that have been mapped to bin i ∈ {0, 1}. All nodes then accumulate the mappings by means of a ooding-echo procedure on the spanning tree using the function countElementsInBins parameterized by the hash function: Once the leaves have received information about the hash function, their elements e1, . . . , et are hashed and added to the two bins, i.e., c0 is set to the number of elements that mapped to the rst bin and c 1 is set to the number of the remaining elements. This tuple is sent to the parent node, which accumulates the tuples from all its children and adds its own tuple. The resulting tuple is forwarded recursively up to the root. Let p(v) and Γ(v) denote the parent and the set of children of node v in the spanning tree, respectively. The sum of two tuples c 0 , c 1 and c 0 , c 1 is dened as c 0 , c 1 , where c i = c i + c i for i ∈ {0, 1}. This subroutine is summarized in Algorithm 1.</p><p>Once the root has computed the nal tuple c0, c1, this tuple is distributed down the spanning tree. Any node that receives this distribute message forwards it to its children and updates its local counters according to the following rule: For all elements ei that mapped to the larger of the two bins, its counter c(e i ) is increased by |c 0 − c 1 |. These steps can be carried out in parallel for all r 1 hash functions, i.e., the root can issue one of the r 1 procedure calls in each communication round. Once the r1 results have been obtained and the tuples have all been distributed, Phase (1) of the algorithm is completed.</p><p>In the second phase, the r 2 elementsthe parameter r 2 will also be specied laterwith the largest counters are accumulated at the root using the procedure getPotentialModes. In this procedure, the nodes always forward the element e i , including c(e i ), if its counter is the largest among all those whose element has not been sent yet. Moreover, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Analysis</head><p>In Phase (1), ALG mode executes r1 iterations, where a randomly chosen hash function hi ∈ {h1, h2, ..., hr 1 } assigns all the elements e i ∈ A to one of the two bins in each iteration, i.e., h 1 , ..., h r 1 : A → {−1, +1}. First, we need to prove a bound on the number r 1 of required hash functions to substantially reduce the set of candidates.</p><p>Throughout the rest of this section, we will make use of the following helper lemma. <ref type="bibr">Lemma</ref>  </p><formula xml:id="formula_4">P h Y ≥ λ p F2[Y ] i ≤ e −λ 2 /2 . Proof. It holds that P h Y ≥ λ p F 2 [Y ] i ≤ γ&gt;0 E[e γY ] e γλ √ F 2 [Y ] = Q k i=1 E[e γY i ] e γλ √ F 2 [Y ] ≤ Q k i=1 e γy i +e −γy i 2 e γλ √ F 2 [Y ] = Q k i=1 cosh(γyi) e γλ √ F 2 [Y ] ≤ Q k i=1 e γ 2 y 2 i /2 e γλ √ F 2 [Y ] = e γ 2 P k i=1 y 2 i /2 e γλ √ F 2 [Y ] ≤ e −λ 2 /2 since (e x + e −x )/2 = cosh(x) ≤ e x 2 /2 and by setting γ = λ/ p F 2 [Y ]. Note that F 2 [Y ] = Var(Y ).</formula><p>The goal of Phase <ref type="formula" target="#formula_13">(1)</ref> is to reduce the set of elements that could potentially be the mode to a small set of size r 2 . The following lemma bounds the number r1 of hash functions required to ensure that the counter of the mode is larger than the counter of a large fraction of all elements.</p><p>Lemma 4.2. If r 1 ∈ O(F 2 /m 2 1 log(k/ε)) then ∀e i : m i &lt; m 1 /2 it holds that c(e i ) &lt; c(e 1 ) with probability at least 1−ε.</p><p>Proof. First, we focus only on the events where the mode e1 and the element e with the maximum frequency among all elements whose frequency is less than half of the frequency e 1 of the mode are put into dierent bins. All other elements are added randomly to one of the bins, and this procedure is repeated r1 times. Alternatively, we can say that there are (k − 2)r1 elements α1, . . . , α (k−2)r 1 that are placed randomly into the two bins. It holds that</p><formula xml:id="formula_5">P r 1 (k−2) i=1 α 2 i &lt; r 1 · F 2 .</formula><p>Before the elements α 1 , . . . , α r 1 (k−2) are put into the bins, it holds that c(e 1 ) &gt; c(e ) + r 1 · m 1 /2. In order to ensure that c(e 1 ) &gt; c(e ) after all elements have been placed in one of the bins, the probability that the other elements compensate this imbalance of at least r1 · m1/2 must be small. Let the Bernoulli variable Z i indicate into which bin the element α i is placed. In particular, in case Z i = −1, the element is put into the bin where the mode is, and if Zi = 1, the element is placed into the other bin. By setting r1 = 8F2/m 2 1 ln(2k/ε) and applying Lemma 4.1 we get that</p><formula xml:id="formula_6">P 2 4 (k−2)r 1 X i=1 αiZi ≥ r1 · m1/2 3 5 &lt; e − r 2 1 ( m 1 2 ) 2 2 P(k−2)r 1 i=1 α 2 i &lt; e − r 1 m 2 1 8F 2 = ε 2k .</formula><p>In order to ensure that the elements e 1 and e are often placed into dierent bins, the number of rounds is increased to r1 = 32F2/m 2 1 ln(2k/ε). Let the random variable U denote the number of times that the two elements are placed into the same bin. Using a simple Cherno bound we get that the probability that 32F 2 /m 2 1 ln(2k//) rounds do not suce to bound the probability of failure to ε/(2k), because e1 and e are put into dierent bins less than 8F2/m 2 1 ln(2k/ε) times, is itself bounded by</p><formula xml:id="formula_7">P[U &gt; 24F2/m 2 1 ln(2k/ε)] &lt; e −F 2 /m 2 1 ln(2k/ε) &lt; ε/(2k).</formula><p>Thus, the probability that c(e 1 ) &gt; c(e ) is at least 1 − ε/k. Let Υ = {e i : m i &lt; m 1 /2} denote the set of all elements for which we want to prove that their counters are lower than the counter of the mode. The probability that any element e * in this set has a counter larger than the mode is</p><formula xml:id="formula_8">P[∃e * ∈ Υ : c(e * ) &gt; c(e 1 )] &lt; P e∈Υ P[c(e) &gt; c(e 1 )] &lt; k · (ε/k) = ε, which concludes the proof.</formula><p>Note that technically we cannot determine r 1 unless we know F 2 , m 1 , and k. In the following section, we show that these quantities can all be estimated eciently. Using this bound on the number of hash functions, we are now in the position to prove the following theorem. Theorem 4.3. The time complexity of ALG mode to compute the mode with probability at least 1 − ε on an arbitrary</p><formula xml:id="formula_9">graph G of diameter D is O " D + F 2 m 2 1 log k ε « .</formula><p>Proof. In Phase (1) of the algorithm, r 1 hash functions are applied to all elements and the sum of elements hashed to each bin is accumulated at the root using a simple oodingecho procedure. It is important to see that all these hash functions can be handled in parallel as opposed to computing the resulting bin sizes for each hash function sequentially, i.e., the number of communication rounds required is bounded by <ref type="bibr">O(D + r1)</ref> and not O(D · r1). Each result is distributed back down the tree in order to allow each node to updates its counters for all its stored elements, which requires O(D) time. Hence, the time complexity of the rst phase is bounded by O(D + r 1 ).</p><p>In Phase (2), the r2 elements with the largest counters are accumulated at the root, and the element with the highest number of occurrences out of this set is returned as the mode. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Estimators for F2, m1, and k</head><p>In order to estimate F 2 , the algorithm described by Alon et al. <ref type="bibr" target="#b0">[1]</ref> can be used, which employs a set of four-wise independent hash functions mapping elements to either −1 or 1. A set H of hash functions is called four-wise independent if for any four elements e 1 , . . . , e 4 , the values h(e i ) of a randomly chosen hash function h from the set are statistically independent. Hence, for any elements e 1 , . . . , e 4 and any choice c1 . . . , c4 ∈ {−1, 1} there are |H|/16 hash functions h ∈ H for which it holds that h(ei) = ci for all i = {1 . . . , 4}. It is shown that, by using s := 32 lg(1/ε ) λ 2 of these hash functions h1, . . . , hs, where each function hj is used to compute</p><formula xml:id="formula_10">X j := P k i=1 h j (e i ) · m i</formula><p>, these values X j can be used to compute an estimatê F2 which deviates from F2 by at most λF2 with probability 1 − ε . The transition from the streaming model to our model is straightforward: The values X j can be computed by usig two counters c −1 and c +1 that sum up the values that map to −1 and +1 (just like in our algorithm), as it holds that</p><formula xml:id="formula_11">Xj = P k i=1 h j (ei) · mi = c+1 − c−1.</formula><p>Since λ is a constant, we can aggregate all counters and thus all values X j for all hash functions j ∈ {1, . . . , s} at the node that wishes to approximate F 2 in O(D + log(1/ε )) time and compute the estimatê F2 locally. As mentioned in Section 2, there is a probabilistic algorithm to estimate k = F 0 eciently <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b8">8]</ref>. The algorithm uses hash functions that map elements to bit strings. The key idea is that the length of the longest prex consisting of 0-bits can be used as an approximation for log 2 k. Several runs of this procedure using randomly chosen hash functions are used in order to bound the variance. In the distributed version of this algorithm, the lengths of the longest prex of 0-bits for each hash function are accumulated and then used to compute an estimatê k, which also takes O(D) time. 3 Thus, estimatorsˆF2estimatorsˆ estimatorsˆF2 andˆkandˆ andˆk for both F2 and k can be computed in parallel to the computation of the mode. Since the variances are bounded, we can in fact compute estimates for which it holds thatˆFthatˆ thatˆF 2 ≥ F 2 andˆkandˆ andˆk ≥ k with a certain probability 1 − ε by modifying the original estimates. Given the estimatorsˆF2estimatorsˆ estimatorsˆF2 andˆkandˆ andˆk, an estimatorˆm1estimatorˆ estimatorˆm1 for m1 can be obtained as follows. We know that after r1 = 32F2/m 2 1 log(2k/ε) time, the rst phase of the algorithm may terminate. After each distribution of c 0 , c 1 , h i we determine the frequency of any element e i whose counter is currently the largest in O(D) time and use this frequency as the new estimator forˆm1forˆ forˆm1, if this frequency is greater than any frequency encountered before. Aggregation rounds are performed iteratively as long as 32ˆF32ˆ 32ˆF 2 / ˆ m 2 1 log 2 ˆ k/ε &lt; T , where T denotes the number of aggregation rounds executed so far. Once this inequality does no longer hold, we can conclude that the algorithm must have executed enough aggregation rounds, asˆm asˆ asˆm 1 ≤ m 1 . The algorithm does not run much longer than needed, sincê</p><formula xml:id="formula_12">m 1 ≥ m 1 /2 after 32ˆF32ˆ 32ˆF 2 / ˆ m 2 1 log(2 ˆ k/ε) ≥ r 1 rounds.</formula><p>Note that, since all algorithms exhibit a certain error probability, the number of rounds r 1 of the rst phase must be increased slightly by a small constant factor to ensure that the mode is still computed correctly with probability at least 1 − ε. We dispense with the analysis of the exact factor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Selecting Hash Functions</head><p>ALG mode makes extensive use of hash functions. In Section 4.2, we assumed that the hash functions can be chosen uniformly at random from the set of all 2 K possible hash functions. However, in order to select one of these hash functions at random, K bits have to be communicated, which is not allowed in our model where we restrict message sizes to at most O(log K + log M + log n) bits. In the following, we show that our algorithm still works if a random hash function is chosen from a much smaller set.</p><p>We rst need a few denitions. Let S ⊆ [K] × [M ] be a subset of all possible element-frequency pairs and let h : <ref type="bibr">[K]</ref> → {−1, +1} be a hash function. We dene the imbalance λS(h) of h with respect to S as</p><formula xml:id="formula_13">λS(h) = P (e i ,m i )∈S h(e i ) · m i p F2[S] ,<label>(1)</label></formula><p>where F2 <ref type="bibr">[S]</ref> is the second frequency moment of the set S.</p><p>We call a hash function h λ-good with respect to a set</p><formula xml:id="formula_14">S ∈ [K] × [M ] if |λ S (h)| ≤ λ.</formula><p>Let H be a family of hash functions h : [K] → {−1, 1}. Further, let H e,e ⊆ H be the set of hash functions h for which h(e) = h(e ). We call H a quasi-random hash family with parameters δ, ε ∈ (0, 1) if the following conditions hold.</p><formula xml:id="formula_15">Let 1 = p 2 ln(5(2 + δ)K 2 /ε)/δ. (I) 2-independence: For all e, e ∈ [K], ˛ ˛ H e,e ˛ ˛ ≥ (1 − δ) · ˛ ˛ H ˛ ˛ /2.</formula><p>3 It has been pointed out that the somewhat ideal properties of the hash functions assumed in the original work are not required and that by slightly modifying the algorithm it suces to use a set of linear hash functions <ref type="bibr" target="#b0">[1]</ref>.</p><p>(II) Exponentially small imbalance: For all e, e ∈ [K],</p><formula xml:id="formula_16">S ⊆ ` [K] \ {e, e } ´ × [M ]</formula><p>, and all integers ≤ 1 , the number of hash functions h ∈ H e,e that are not δ-good with respect to S is at most (2 + δ) · e −(δ) 2 /2 .</p><p>(III) Independence of imbalance sign: For all e, e ∈</p><formula xml:id="formula_17">[K], S ⊆ ([K] \ {e, e }) × [M ]</formula><p>, and all integers ≤ 1, let Λ e,e ,S () be the set of hash functions h ∈ H e,e that are not (δ − 1)-good but that are δ-good with respect to S. We have</p><formula xml:id="formula_18">˛ ˛ ˛ ˛ ˛ ˘ h ∈ Λ e,e ,S () ˛ ˛ λ S (h) · h(e) &lt; 0 ¯˛ ˛ − ˛ ˛ ˘ h ∈ Λ e,e ,S () ˛ ˛ λ S (h) · h(e) &gt; 0 ¯˛ ˛ ˛ ˛ ˛ ≤ δ · " e −δ 2 (−1) 2 /2 − e −δ 2 2 /2 " · |H e,e |.</formula><p>Note that the family of all 2 K hash functions clearly is a quasi-random family for all δ and ε (cf. Lemma 4.1). However, we will show that there are exponentially smaller quasi-random hash families and that our algorithm achieves the same bounds if the hash functions h1, . . . , hr 1 are chosen uniformly from any quasi-random family H with appropriate values of δ and ε. We proceed as follows: We rst show that choosing O(F 2 /m 2 1 · log(k/ε)) hash functions from a quasi-random family results in a time complexity of O(D + F2/m 2 1 · log(k/ε)) rounds if the algorithm is allowed to err with probability at most ε. Subsequently, we prove that quasi-random hash families of size O(poly(K, M )) exist, allowing to run ALG mode with messages of size O(log M + log K + log n).</p><p>Assume that we are given a set</p><formula xml:id="formula_19">S ⊆ [K] × [M ] of elements e 1 , . . . , e k ∈ [K] with frequencies m 1 ≥ . . . ≥ m k ∈ [M ]</formula><p>and a quasi-random hash family H. The hash functions h 1 , . . . , h r 1 in ALG mode are chosen independently and uniformly at random from H. Let ei be an element that occurs less than half as often as the mode, i.e., mi &lt; m1/2. As above, let H e 1 ,e i ⊆ H be the set of hash functions h for which h(e 1 ) = h(e i ). As in Section 4.2 for random hash functions, we again need to choose the number of rounds r1 such that c(e1) &gt; c(ei) with suciently large probability. Let Se i = S \ {(e1, m1), (ei, mi)} and let H e i = H e 1 ,e i ∩ {h 1 , . . . , h r 1 } be the set of chosen hash functions h for which h(e 1 ) = h(e i ). The dierence ∆ e i between c(e 1 ) and c(e i ) after r 1 rounds can be computed as</p><formula xml:id="formula_20">∆ e i = |H e i | · (m 1 − m i ) + N e i ,<label>(2)</label></formula><p>where</p><formula xml:id="formula_21">N e i = X h∈H e i h(e 1 )· X (e,m)∈Se i h(e)·m = X h∈H e i h(e 1 )·λ Se i (h)· p F 2 [S e i ].</formula><p>Thus, we have to show that </p><formula xml:id="formula_22">N e i &gt; −|H e i |(m 1 − m i ) &gt; −|H e i | ·</formula><formula xml:id="formula_23">S e i (h) &gt; c1 · ˛ ˛ He i ˛ ˛ 3 5 &lt; c −|H e i | 2 .</formula><p>Proof. For simplicity, assume that 1/δ ∈ Z such that every integer λ = δ for some integer . Then by using Condition (II) of the quasi-randomness denition, we obtain that for every λ ∈ N, the number of hash functions h ∈ H e 1 ,e i that is not λ-good is at most (2 + δ) · |H e 1 ,e i | · e −λ 2 /2 . The probability that we want to bound is maximized if for all λ ∈ N we have that</p><formula xml:id="formula_24">β λ = ˛ ˛ ˘ h ∈ H e 1 ,e i ˛ ˛ h is not λ-good ¯˛ ˛ ˛ ˛ He 1 ,e i ˛ ˛ = ( (2 + δ) · e −λ 2 /2 if λ ≥ p 2 ln(2 + δ) 1</formula><p>otherwise.</p><p>Let H = He 1 ,e i \ Λ∞ and t = ˛ ˛ H ˛ ˛ , and let</p><formula xml:id="formula_25">p := P 2 4 X h∈H λ 2 Se i (h) &gt; c 1 · t 3 5</formula><p>We have</p><formula xml:id="formula_26">p ≤ P 2 4 X h∈H˚|λ h∈H˚h∈H˚|λ Se i (h)| ˇ 2 &gt; c 1 · t 3 5 &lt; γ&gt;0 E » e γ P h∈H l |λ S e i (h)| m 2 - e γc 1 t = Q h∈H E » e γ l |λ S e i (h)| m 2 - e γc 1 t ≤ P ∞ λ=1 (β λ − β λ−1 ) · e γλ 2 e γc 1 ! t ≤ 0 @ (2 + δ) · P ∞ λ=1 " e −(λ−1) 2 /2 − e −λ 2 /2 " · e γλ 2 e γc 1 1 A t = 0 @ (2 + δ) · P ∞ λ=1 e λ 2 (γ−1/2) · " e λ−1/2 − 1 " e γc 1 1 A t .</formula><p>There are constants c 1 and γ such that the above expression is at most c −t 2 for a constant c 2 &gt; 1. The claim now follows because for a hash function h that is chosen uniformly at random from He 1 ,e i , P ˆ h ∈ Λ∞˜≤ Λ∞˜Λ∞˜≤ ε/(5K 2 ) and therefore</p><formula xml:id="formula_27">t = Ω(|H e i |) with probability e −Θ(|H e 1 ,e i |) .</formula><p>We can now bound the value of Ne i with high probability.</p><formula xml:id="formula_28">Lemma 4.5. If δ &lt; 1/(8c · K · ln 3/2 (K/ε)) and |He i | ≥ c · F 2 [S e i ]/m 2 1 · ln(k/ε) for a suciently large constant c ≥ 1, we get P h Ne i ≤ − m1 2 · |He i | i &lt; ε k . Proof. Note that K ≥ k &gt; F2[Se i ]/m 2 1 .</formula><p>In order to simplify the analysis, we dene˜λdene˜ dene˜λ Se i (h) = δ( − 1) for every</p><formula xml:id="formula_29">h ∈ Λ + () and˜λand˜ and˜λ S e i (h) = −δ( − 1) for every h ∈ Λ − (). Instead of N e i ,</formula><note type="other">we now consider the random variable˜N variable˜ variable˜N e</note><formula xml:id="formula_30">i = X h∈H e i h(e 1 ) · ˜ λ Se i (h) · p F 2 [S e i ]<label>(3)</label></formula><p>and get</p><formula xml:id="formula_31">Ne i &gt; ˜ Ne i − δ · ˛ ˛ He i ˛ ˛ · p F2[Se i ],</formula><p>since we change no λ Se i (h)-value by more than δ. We set d() = ˛ ˛ |Λ − ()| − |Λ + ()| to the dierence between the sizes of two symmetric sets of the described partition of H e 1 ,e i . Since H is a quasi-random family, we have d() ≤ δ(e −δ 2 (−1) 2 /2 − e −δ 2 2 /2 )|H e 1 ,e i | (independence of imbalance sign). For each 1 ≤ ≤ 1, remove d() hash functions from the larger of the two sets Λ + () and Λ − () and add them to a set Λ . We then have</p><formula xml:id="formula_32">|Λ + ()| = |Λ − ()| for 1 ≤ ≤ 1 . Let H 1 = S 1 =1 Λ + () ∪ Λ − () be the hash func- tions in some Λ + () or Λ − () and let H 2 = H e 1 ,e i \(H 1 ∪Λ ∞ )</formula><p>be the set of hash functions from the sets Λ . We dene</p><formula xml:id="formula_33">X e i = X h∈H 1 ∩H e i h(e 1 ) · ˜ λ Se i (h) Ye i = X h∈H 2 ∩H e i h(e1) · ˜ λS e i (h) Z e i = X h∈Λ∞∩He i h(e 1 ) · λ Se i (h) ,</formula><p>and then have˜Nhave˜ Together with Lemma 4.4 and because λS e i (h)/ ˜ λS e i (h) ≥ 1 for every h ∈ H1, we obtain that for every constant c2 &gt; 1, there is a constant c 1 &gt; 0 such that</p><formula xml:id="formula_34">have˜N e i = (X e i + Y e i + Z e i ) · p F 2 [S e i ]. Because |Λ + ()| = |Λ − ()| for 1 ≤ ≤ 1 , for every hash function h ∈ H1, there is a corresponding hash function h ∈ H1 such that˜λSthat˜ that˜λS e i (h) = − ˜ λS e i (h</formula><formula xml:id="formula_35">P h X e i &lt; −α · p c 1 · |H e i | i &lt; e −α 2 /2 + c −|H e i | 2 .</formula><p>Choosing α = p 2 ln(5k/ε) and an appropriate constant c 2 (note that |H e i | ≥ c ln(k/ε)), we have</p><formula xml:id="formula_36">P " X e i &lt; − s 2 · c 1 · ln " 5k ε « · |H e i | # &lt; 2ε 5k .<label>(4)</label></formula><p>In order to bound the value of Y e i , remember that</p><formula xml:id="formula_37">|Λ | = d() ≤ δ(e −δ 2 (−1) 2 /2 − e −δ 2 2 /2 )|H e 1 ,e i |.</formula><p>Hence, the probability that we choose at least one hash function h from H2 with |λ</p><formula xml:id="formula_38">Se i (h)| &gt; λ is at most |H e i | · δ · e −λ 2 /2 . Hence, there is a constant c 3 &gt; 0 such that P " max h∈H 2 ∩H e i ˛ ˛ λ S e i (h) ˛ ˛ &gt; c 3 · s ln " k + |H e i | ε « # ≤ ε 5k .</formula><p>(5) Let us now consider the size of the set H 2 . By Condition (III) of the quasi-randomness denition, we have</p><formula xml:id="formula_39">|H 2 | ≤ δ · e · |H e 1 ,e i |.</formula><note type="other">The probability for choosing a hash function h ∈ H 2 is therefore at most δe. Using Cherno and E ˆ |H e</note><formula xml:id="formula_40">i ∩ H2|˜≤ H2|˜H2|˜≤ e/ p ln(K/ε), we conclude that there is a constant c4 &gt; 0 such that P " ˛ ˛ He i ∩ H2 ˛ ˛ &gt; c4 · s ln " |H e 1 | ε « # ≤ ε 5k .<label>(6)</label></formula><p>Combining Inequalities <ref type="formula">(5)</ref> and <ref type="formula" target="#formula_40">(6)</ref>, we obtain</p><formula xml:id="formula_41">P » Ye i &lt; −c3c4 · ln " k ε «- ≤ 2ε 5k .<label>(7)</label></formula><p>Finally, by the denition of 1, we have that</p><formula xml:id="formula_42">P ˆ Ze i &lt; 0 ˜ ≤ P ˆ |Λ∞| &gt; 0 ˜ ≤ 2(1 + δ) · |H e i | · e −δ 2 2 1 /2 ≤ ε 5k . (8) Let ν := δ · |He i | + s c 1 · ln " k ε « · |He i | + c3c4 · ln " k ε « !</formula><p>for some constant c 1 . Combining Inequalities (3), (4), <ref type="formula" target="#formula_41">(7)</ref>, and <ref type="formula">(8)</ref>, we get that</p><formula xml:id="formula_43">P h N e i &lt; −ν · p F 2 [S e i ] i &lt; ε k (9) for a constant c 1 &gt; 0. Using 1 ≤ F 2 [S e i ]/m 2 1 ≤ k ≤ K, we obtain δ · |He i | · p F2[Se i ] &lt; p F 2 [S e i ] · |H e i | 8cK ln 3/2 (K/ε) ≤ m 2 1 · |H e i | 8c p F 2 [S e i ] ln 3/2 (K/ε) &lt; m 1 8 · |H e i |.</formula><p>For the second term in the sum of Inequality (9), we have s</p><formula xml:id="formula_44">c 1 · ln " k ε « · |He i | · F2[Se i ] ≤ p c · c 1 · F 2 [S e i ] ln(k/ε) m 1 ≤ m 1 8 · |H e i |</formula><p>if c is chosen suciently large. Finally, the third term of Inequality <ref type="formula">(9)</ref> can be bounded by</p><formula xml:id="formula_45">c3c4 · ln " k ε « · p F2[Se i ] ≤ m1 8 · |He i | (10) with p F2[Se i ] ≥ m1</formula><p>and c large enough. Combining Inequalities (9) (10) completes the proof.</p><p>Next, an upper bound on the time complexity of ALG mode is derived if the hash functions are chosen from a quasirandom family. The following theorem shows that we obtain the same asymptotic running time as with hash functions that are chosen uniformly from all possible hash functions. Theorem 4.6. If the hash functions are chosen from a quasi-random family H with parameters δ &lt; 1/(8c · K · ln 3/2 (log(K/ε)) and ε ∈ (0, 1), ALG mode needs O(D + F 2 /m 2 1 log(k/ε)) rounds to compute the mode with probability at least 1 − ε.</p><p>Proof. We need to show that when using r 1 = O(D + F 2 /m 2 1 log(k/ε)) hash functions, the counters c(e i ) of all elements ei with multiplicity mi &lt; m1/2 are smaller than the counter c(e1) of the mode with probability at least 1−ε. This follows almost immediately from Equation <ref type="formula" target="#formula_20">(2)</ref> and Lemma 4.5. It only remains to show that |H e i | = Ω(r 1 ) with high probability. This follows immediately from Condition (I) (2-independence) in the quasi-randomness denition by using a Cherno bound.</p><p>Since we only allow messages of size O(log K + log M + log n), ALG mode is ecient only when applied to a quasirandom family H of size polynomial in K, M , and n. In the following, using the probabilistic method we show that indeed, small quasi-random hash families exist. We prove that if we choose suciently many random hash functions, they form a quasi-random family with positive (in fact high) probability.</p><p>Theorem 4.7. For all parameters δ ∈ (0, 1) and ε ∈ (0, 1), there is a quasi-random hash family H of size |H| = O((K + M + log(1/δ) + log log(1/ε))/δ 6 ).</p><p>Proof. Let H = ˘ h 1 , . . . , h q ¯ be q hash functions that are chosen independently and uniformly at random from the set of all 2 K possible hash functions h : [K] → {0, 1}. We need that H is a quasi-random family with parameters δ and ε with positive probability. Let us now examine the three conditions of the quasi-randomness denition.</p><p>2-independence: </p><formula xml:id="formula_46">For</formula><formula xml:id="formula_47">˜ &lt; K 2 · 2 K · 2 M · 1 · e −δ 2 2e −δ 2 2 1 /2 (1−δ)q/16 .</formula><p>Independence of imbalance sign:</p><p>We assume that H satises Conditions (I) and (II). Let </p><formula xml:id="formula_48">e, e ∈ [K], S ⊆ ` [K]\{e, e } ´ ×[</formula><formula xml:id="formula_49">P ˆ Y &gt; δ · Φ · q ˜ = P » Y &gt; δ β · |Λ| - &lt; 2e −δ 2 |Λ|/(4β 2 ) = 2e −δ 2 Φ·q/(4β) .</formula><p>Based on the assumption that H satises Condition (II), we have</p><formula xml:id="formula_50">β Φ ≤ (2 + δ)e −δ 2 (−1) 2 /2 ` e −δ 2 (−1) 2 /2 − e −δ 2 2 /2 ´ 2 = 2 + δ ` 1 − e −δ 2 (−1/2) ´ 2 · e −δ 2 (−1) 2 /2 .</formula><p>The bound on β/Φ is largest if = 1. We then get β/Φ ≤ (2 + δ)/(δ 2 /2 − δ 4 /4) 2 . Hence, we obtain</p><formula xml:id="formula_51">P ˆ H does not satisfy Condition (III) ˜ &lt; K 2 · 2 K · 2 M · 1 · 2e − δ 2 4 · " δ 2 2 − δ 4 4 « 2 ·q .</formula><p>If we choose</p><formula xml:id="formula_52">q ≥ C δ 6 · K + M + log p ln(K/ε) δ !!</formula><p>for a suciently large constant C, the right-hand sides of the inequalities become less than 1/3 and it is therefore possible to satisfy Conditions (I)-(III). This concludes the proof. 1 · log(k/ε)) rounds for a given error probability ε, and that there indeed exist suciently small sets of hash functions yielding the desired message size.</p><p>Remark: A natural generalization of our models presented so far is to allow weighted elements, i.e., each element ei ∈ A has a corresponding weight wi. The task of nding the mode would then translate into nding the element which maximizes the product of the frequency and weight, i.e., the mode is denes as the element ei maximizing wimi. It is easy to see that our algorithms can be generalized to the case of weighted elements as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">LOWER BOUND</head><p>In this section, we show that for every m1, F5 ∈ N with F5 ≥ m 5 1 , there is a graph G with diameter D and a frequency distribution with maximum frequency m 1 and a 5 th frequency moment F 5 such that nding the mode requires Ω(D + F 5 /(B · m 5 1 )) rounds. Here B denotes the number of bits that can be transmitted in a single message.</p><p>To prove our lower bound, we use a reduction from the set disjointness problem, a well-known problem from communication complexity theory <ref type="bibr" target="#b11">[11]</ref>. Assume that two nodes u 1 and u2 have sets of elements S1 and S2 with |S1| = |S2| = such that |S1 ∩ S2| ∈ {0, 1}. In <ref type="bibr" target="#b16">[16]</ref>, Razborov showed that in order to distinguish between the case where S 1 and S 2 are disjoint and the case where they intersect in exactly one element, u 1 and u 2 have to exchange Ω() bits even if we allow them to err with probability ε ≤ ε0 for a constant ε0. In order to derive a lower bound on the space complexity for approximating the frequency moments F of a distribution in a streaming model, Alon et al. extended Razborov's lower bound to a scenario with more than two nodes <ref type="bibr" target="#b0">[1]</ref> to distinguish between the case where the sets are pairwise disjoint and the case where they intersect in exactly one element is Ω(/d 3 ). This also holds for randomized algorithms with error probability ε &lt; 1/2.</p><p>We prove the lower bound for computing the mode in two steps. We rst look at a special type of frequency distributions where the frequencies m 2 , . . . , m k are equal up to a factor of 2 and then generalize the result to arbitrary frequency distributions. In the following, we will assume that all the nodes know about the frequency distribution are bounds There is a total of m1 + k − 1 elements (element e1 occurs m1 times, all other k − 1 elements occur only once). We distribute these elements among the m 1 leaf nodes such that every leaf node receives e 1 exactly once and (k − 1)/m 1 of the other elements. Let S i be the set of elements of leaf node ui. For i = j, we have Si ∩ Sj = {e1}. we can apply Theorem 5.1 to show that the total number of bits the nodes u 1 , . . . , u d have to communicate in order to nd e 1 is Ω(k /m 1 /m 3 1 ) = Ω(k /m 4 1 ). This is due to the fact that any algorithm ALG which computes e1 can be used to solve the problem of Theorem 5.1 as follows. If ALG terminates without returning a value e 1 , we know that the sets S 1 , . . . , S d are pairwise disjoint. If ALG returns a value e 1 , we can test whether e 1 indeed is in all sets S i be exchanging a logarithmic number of additional bits. Note that we have 1 + (k − 1)/m1 ≥ m 4 1 (corresponding to the condition ≥ d 4 in Theorem 5.1) because we assumed that   The inequality follows because we assume that F5 = m 5 1 + k − 1 ≥ 2m 5 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">POWER LAW DISTRIBUTIONS</head><p>An interesting and widely studied distribution is the power-law distribution p(x) ∝ x −α for some constant α &gt; 0 <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b17">17]</ref>, that is, by normalization, m i = 1/i α . Let m = P k i=1 m i . It holds that n ∈ Θ(k 1−α ) for α &lt; 1, m ∈ Θ(log k) for α = 1 and m ∈ Θ(1) for α &gt; 1. For ALG mode , we hence obtain the following upper bounds on the running time T :</p><p>T ∈ 8 &gt; &lt; &gt; :</p><formula xml:id="formula_53">O ` D + k 1−2α · (log k + log (1/ε)) ´ , if α &lt; 1/2 O ` D + log k · (log k + log (1/ε)) ´ if α = 1/2 O ` D + log k + log (1/ε) ´ , if α &gt; 1/2.</formula><p>We observe an interesting threshold phenomenon. If α &lt; 1/2, our randomized algorithm needs polynomial time whereas for α ≥ 1/2, the mode can be determined in polylogarithmic time. Our lower bound on the time T needed to nd the mode becomes Ω ` D + k 1−5α /(B log k) ´ if α &lt; 1/5.</p><p>For α ≥ 1/5, we do not obtain a non-trivial lower bound. Hence, indeed, there seems to exist a value α 0 ≥ 1/5 such that the time complexity of every algorithm is polynomial in k if α &lt; α0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSIONS</head><p>This paper has shown that the mode can be computed deterministically in time <ref type="bibr">O(D+k)</ref> in arbitrary graphs and that there are distributions for which this is tight up to a logarithmic factor. In an eort to exploit properties of the actual frequency distribution, we presented a randomized Monte Carlo type algorithm which nds the mode with high probability in time O(D + F2/m 2 1 · log k). We did not prove that this is tight; however, the lower bound of Ω(D + F 5 /(m <ref type="bibr" target="#b5">5</ref> 1 B)) rounds shows that the general dependence of the upper bound on the skewness of the distribution is correct. We believe that at least up to polylogarithmic factors the upper bound is the correct bound for all distributions. An improvement of the lower bound would most likely also solve an open problem from <ref type="bibr" target="#b0">[1]</ref>: It is shown that in a streaming model, F 0 , F1, and F2 can be approximated in polylogarithmic space, whereas polynomial space is needed to approximate F for ≥ 6. It is conjectured in <ref type="bibr" target="#b0">[1]</ref> that approximating F 3 , F 4 , and F 5 also requires polynomial time.</p><p>We formulated all our results for a message passing model where communication is constricted by congestion on edgesnote that we do not bound congestion at nodesand by the adjacency relationships of the underlying network graph. However, our general approach directly applies to all distributed models (e.g. gossiping <ref type="bibr" target="#b3">[4]</ref>) where aggregation can be studied. The time complexity of our algorithm is then equal to the time complexity of computing O(F2/m 2 1 · log k) independent basic aggregation functions such as computing the sum or the maximum of all elements.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Algorithm 2 ALG mode 1: mode = ∅, freq = −∞ 2: Phase (1): 3: for i = 1, . . . , r 1 in parallel do 4: c 0 , c 1 = countElementsInBins(h i ) 5: distribute(c0, c1, hi) 6: Phase (2): 7: e 1 , . . . , e r 2 = getPotentialModes(r 2 ) 8: for i = 1, . . . , r 2 in parallel do, freq = m i 12: return mode an element is only forwarded, if its counter is among the r2 largest counters ever forwarded to the parent node.</head><label>Algorithm</label><figDesc></figDesc><table>9: 
mi = getFrequency(ei) 
10: 

if mi &gt; freq then 

11: 
mode = e i Once 
these elements arrive at the root, the root issues a request to 
count the individual frequencies for all those elements and 
the element with the largest frequency is returned as the 
mode. The entire algorithm is depicted in Algorithm 2. 
We will now specify the parameters and analyze the time 
complexity of ALG mode . 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>4 .1. For i = 1, . . . , k, let Yi be independent ran- dom variables with Y i = ( yi, with P = 1/2 −y i , with P = 1/2 If Y = P k i=1 Yi and F2[Y ] = P k i=1 y 2 i is the second frequency moment of a set with frequencies y 1 , . . . , y k , then we have that</head><label>4</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>The procedure getPotentialModes performs this op- eration in O(D + r 2 ) time, as the i th largest value arrives at the root after at most D + i rounds of communication. Naturally, the frequency of r 2 elements can also be deter- mined in O(D + r 2 ) time, and thus the entire phase requires O(D + r 2 ) time. The parameter r2 has to be large enough to ensure that the mode is in fact in this set of elements with high prob- ability. Let ¯ Υ = {e i : m i ≥ m 1 /2} be the complement of Υ. According to Lemma 4.2, if r 1 = 32F 2 /m 2¯ Υ m 2 i ≤ F2, implying that | ¯ Υ| ≤ 4F 2 /m 2 1 . Thus, by setting r 2 = 4F 2 /m 2 1 , both phases complete after O(D + F 2 /m 2</head><label></label><figDesc></figDesc><table>1 ln(2k/ε), 
then the mode is in ¯ 
Υ with probability at least 1 − ε. We 
have that | ¯ 
Υ|(m1/2) 2 ≤ 
P 

e i ∈ 1 log(k/ε)) rounds and the mode 
is found with probability 1 − ε. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>m 1 /2 with suciently high probability.2 /ε)/δ. We partition the hash functions h ∈ He 1 ,e i according to the value of h(e1)λS i (h). For in- tegers 1 ≤ ≤ 1 , let Λ + () be the set of hash func- tions h ∈ H e 1 ,e i for which h(e 1 )λ S i (h) ∈ (δ( − 1), δ] and let Λ − () be the set hash functions h ∈ H e 1 ,e i for which h(e1)λS i (h) ∈ [−δ, −δ( − 1)). Further let Λ∞ be the set of hash functions h ∈ He 1 ,e i for which ˛ ˛ λS i (h) ˛ ˛ &gt; δ1. In order to lower bound the value of N e i , we need the following lemma. Lemma 4.4. For every constant c 2 &gt; 1, there is a con- stant c 1 &gt; 0, such that P 2 4 X h∈H e i \Λ ∞ λ 2</head><label></label><figDesc></figDesc><table>We need 
to start with some additional denitions. Recall that 1 = 

p 
2 ln(5(2 + δ)K </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>two elements e and e from´ × [M ], and ≤ 1 . Further, let X be the fraction of hash functions h ∈ H e,e that are not δ- good with respect to S. By2 2 /2 ˜ &lt; e −δ 2 2e −δ 2 2 /2 |H e,e |/8 . Note that being in H e,e and being δ-good with respect to S are independent. With a union bound, we get P ˆ H does not satisfy Condition (II)</head><label></label><figDesc></figDesc><table>[K], we have P 
ˆ |H e,e | &lt; 

(1 − δ) · |H/2 
˜ &lt; e −δ 2 q/4 by Cherno's inequality. By using 

a union bound, we therefore get that 

P 
ˆ H does not satisfy Condition (I) 
˜ &lt; K 2 · e −δ 2 q/4 . (11) 

Exponentially small imbalance: 

We assume that H satises Condition (1). Let e, e ∈ [K], 
S ⊆ 
` 
[K] \ {e, e } 
Lemma 4.1 and by Cherno's 

inequality, P 
ˆ X &gt; (2 + δ)e −δ </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>M ], and ≤ 1 . Let Λ be the set of hash functions h ∈ H for which |λS(h)| ∈ (δ( − 1), δ]. Further let Λ + ⊆ Λ be the hash functions h for which h(e) · λ S (h) &gt; 0 and let Λ − = Λ \ Λ + . We need to bound the value of Y = ˛ ˛ |Λ + | − |Λ − | ˛ ˛ . Because the value of h(e) is independent of λS(h), for γ ∈ (0, 1), we get P ˆ Y &gt; γ · |Λ|˜&lt; |Λ|˜|Λ|˜&lt; 2e −γ 2 |Λ|/4 by using Cherno's inequal- ity. We dene Φ = e −δ 2 (−1) 2 /2 − e −δ 2 2 /2 and assume that |Λ| = β · Φ · q. We then have</head><label></label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Theorems 4 .6 and 4.7 conclude our analysis of ALG mode : We have shown that ALG mode needs no more than O(D + F2/m 2</head><label>4</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>. Assume that there are d nodes u1, . . . , u d with sets S1, . . . , S d with |S1| = . . . = |S d | = such that either the sets are pairwise disjoint or there is an element e such that S i ∩ S j = {e} for all 1 ≤ i &lt; j ≤ d. The following theorem is proven in [1].4 , the total number of bits that the nodes u 1 , . . . , u d have to communicate in order</head><label></label><figDesc></figDesc><table>Theorem 5.1. [1] For every ≥ d </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Theorem 5.2. Let m 1 , F 5 ∈ N such that F 5 ≥ m 5 1 . There is a frequency distribution m 1 &gt; m 2 ≥ m 3 ≥ . . . ≥ m k with F 5 = P k i=1 m 5 i such that for every D &gt; 1, there is a graph G with diameter D on which nding the mode needs Ω " D + F5 m 5 1 · B « rounds where B is the number of bits that can be sent in a single message. Proof. We set m2 = m3 = . . . = m k = 1, which implies that F5 = P k i=1 m 5 i = m 5 1 + k − 1. Let k be the maximal integer k ≥ k such that m 1 divides k − 1.1 ≥ m 5 1 and thus k &gt; m 5 1 − m 1 + 1. Let G be a star graph with m 1 + 1 nodes, i.e., G consists of an inner node of degree m 1 and m 1 leaves u 1 , . . . , u m 1 .</head><label></label><figDesc></figDesc><table>m + 
1 and m − 
i for i = 2 such that it is guaranteed 
that m + 
1 /2 ≤ m 1 ≤ m + 
1 and that m − 
i ≤ m i ≤ 2m − 
i &lt; m + 
1 /2. 
We require that an algorithm works for all distributions sat-
isfying the given bounds and for all assignments of elements 
to nodes. We rst look at the case where the bound m − 
i is 
the same for all i. 

We assume that 
the algorithm knows that the elements e k +1 , . . . , e k need 
not be considered. It then remains to solve the problem for 
the frequency distribution m1, . . . , m k . Note that nding 
the mode for this distribution can be at most as hard as 
nding the mode for the frequency distribution m 1 , . . . , m k 
because additional information cannot make the problem 
harder. We can further assume that F5 ≥ 2m 5 
1 since oth-
erwise the statement of the theorem becomes trivial. This 
implies that k − </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>From G, we obtain a graph with diameter D on which the lower bound becomes Ω(D + k /(m 5 1 B)) by replacing each edge in G by a path of length D/2. We get a lower bound of Ω(D + F 5 /(m 5 1 B)) because</head><label></label><figDesc></figDesc><table>). Hence, since one of the leaf nodes 
has to send at least Ω(k/m 5 
1 ) bits, the number of rounds is 
at least Ω(k/(m 5 
1 B)). 
</table></figure>

			<note place="foot" n="1"> If m1 = m2, the algorithm simply nds any element that occurs at least as often as all others.</note>

			<note place="foot" n="2"> If the frequency of the mode is 2, then this element must appear in both sets and thus the sets are not disjoint.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The Space Complexity of Approximating the Frequency Moments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 28th Annual ACM Symposium on Theory of Computing (STOC)</title>
		<meeting>28th Annual ACM Symposium on Theory of Computing (STOC)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Web Caching and Zipf-like Distributions: Evidence and Implications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Breslau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 18th Annual IEEE Conference on Computer Communications (INFOCOM)</title>
		<meeting>18th Annual IEEE Conference on Computer Communications (INFOCOM)</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Finding frequent items in data streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Charikar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Farach-Colton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">312</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">315</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Gossip-Basid Computation of Aggregate Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G D</forename><surname>Kempe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dobra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 44th</title>
		<meeting>44th</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<title level="m">Annual IEEE Symposium on Foundations of Computer Science (FOCS)</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Determining the Mode</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dobkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Munro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">255263</biblScope>
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">LogLog Counting of Large Cardinalities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Flajolet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 11th Annual European Symposium on Algorithms (ESA)</title>
		<meeting>11th Annual European Symposium on Algorithms (ESA)</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cache-Oblivious Comparison-Based Algorithms on Multisets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farzan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ferragina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Franceschini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Munro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th Annual European Sympoisum on Algorithms (ESA)</title>
		<meeting>13th Annual European Sympoisum on Algorithms (ESA)</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Probabilistic Counting Algorithms for Data Base Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Flajolet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">N</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">182209</biblScope>
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The Probabilistic Communication Complexity of Set Intersection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kalyanasundaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schnitger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Discrete Mathematics (SIDMA)</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">545557</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Tight Bounds for Distributed Selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Locher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wattenhofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 19th ACM Symposium on Parallelism in Algorithms and Architectures (SPAA)</title>
		<meeting>19th ACM Symposium on Parallelism in Algorithms and Architectures (SPAA)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kushilevitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nisan</surname></persName>
		</author>
		<title level="m">Communication Complexity</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Brief History of Generative Models for Power Law and Lognormal Distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitzenmacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internet Mathematics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">226251</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Sorting and Searching in Multisets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Munro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Spira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal of Computing (SICOMP)</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">18</biblScope>
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A Note on Ecient Aggregate Queries in Sensor Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Patt-Shamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">370</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page">254264</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peleg</surname></persName>
		</author>
		<title level="m">Distributed Computing: A Locality-Sensitive Approach. SIAM</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On the Distributional Complexity of Disjointness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Razborov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">385390</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On a Class of Skew Distribution Functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page">425440</biblScope>
			<date type="published" when="1955" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
