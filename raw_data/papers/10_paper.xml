<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:26+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Simple Coreference Resolution with Rich Syntactic and Semantic Features</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2009-08">August 2009. 2009</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
							<email>aria42@cs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Division UC Berkeley</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
							<email>klein@cs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Division UC Berkeley</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Simple Coreference Resolution with Rich Syntactic and Semantic Features</title>
					</analytic>
					<monogr>
						<title level="j" type="main">ACL and AFNLP</title>
						<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing <address><addrLine>Singapore</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="page" from="6" to="7"/>
							<date type="published" when="2009-08">August 2009. 2009</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Coreference systems are driven by syntactic, semantic , and discourse constraints. We present a simple approach which completely modularizes these three aspects. In contrast to much current work, which focuses on learning and on the discourse component, our system is deterministic and is driven entirely by syntactic and semantic compatibility as learned from a large, unlabeled corpus. Despite its simplicity and discourse naivete, our system substantially outperforms all unsupervised systems and most supervised ones. Primary contributions include (1) the presentation of a simple-to-reproduce, high-performing baseline and (2) the demonstration that most remaining errors can be attributed to syntactic and semantic factors external to the coreference phenomenon (and perhaps best addressed by non-coreference systems).</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The resolution of entity reference is influenced by a variety of constraints. Syntactic constraints like the binding theory, the i-within-i filter, and appositive constructions restrict reference by configuration. Semantic constraints like selectional compatibility (e.g. a spokesperson can announce things) and subsumption (e.g. Microsoft is a company) rule out many possible referents. Finally, discourse phenomena such as salience and centering theory are assumed to heavily influence reference preferences. As these varied factors have given rise to a multitude of weak features, recent work has focused on how best to learn to combine them using models over reference structures <ref type="bibr" target="#b4">(Culotta et al., 2007;</ref><ref type="bibr" target="#b5">Denis and Baldridge, 2007;</ref><ref type="bibr" target="#b14">Klenner and Ailloud, 2007)</ref>.</p><p>In this work, we break from the standard view. Instead, we consider a vastly more modular system in which coreference is predicted from a deterministic function of a few rich features. In particular, we assume a three-step process. First, a selfcontained syntactic module carefully represents syntactic structures using an augmented parser and extracts syntactic paths from mentions to potential antecedents. Some of these paths can be ruled in or out by deterministic but conservative syntactic constraints. Importantly, the bulk of the work in the syntactic module is in making sure the parses are correctly constructed and used, and this module's most important training data is a treebank. Second, a self-contained semantic module evaluates the semantic compatibility of headwords and individual names. These decisions are made from compatibility lists extracted from unlabeled data sources such as newswire and web data. Finally, of the antecedents which remain after rich syntactic and semantic filtering, reference is chosen to minimize tree distance.</p><p>This procedure is trivial where most systems are rich, and so does not need any supervised coreference data. However, it is rich in important ways which we argue are marginalized in recent coreference work. Interestingly, error analysis from our final system shows that its failures are far more often due to syntactic failures (e.g. parsing mistakes) and semantic failures (e.g. missing knowledge) than failure to model discourse phenomena or appropriately weigh conflicting evidence.</p><p>One contribution of this paper is the exploration of strong modularity, including the result that our system beats all unsupervised systems and approaches the state of the art in supervised ones. Another contribution is the error analysis result that, even with substantial syntactic and semantic richness, the path to greatest improvement appears to be to further improve the syntactic and semantic modules. Finally, we offer our approach as a very strong, yet easy to implement, baseline. We make no claim that learning to reconcile disparate features in a joint model offers no benefit, only that it must not be pursued to the exclusion of rich, nonreference analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Coreference Resolution</head><p>In coreference resolution, we are given a document which consists of a set of mentions; each mention is a phrase in the document (typically an NP) and we are asked to cluster mentions according to the underlying referent entity. There are three basic mention types: proper (Barack Obama), nominal (president), and pronominal (he). 1 For comparison to previous work, we evaluate in the setting where mention boundaries are given at test time; however our system can easily annotate reference on all noun phrase nodes in a parse tree (see Section 3.1.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Sets</head><p>In this work we use the following data sets:</p><p>Development: (see Section 3)</p><p>• ACE2004-ROTH-DEV: Dev set split of the ACE 2004 training set utilized in <ref type="bibr" target="#b1">Bengston and Roth (2008)</ref>. The ACE data also annotates pre-nominal mentions which we map onto nominals. 68 documents and 4,536 mentions.</p><p>Testing: (see Section 4)</p><p>• ACE2004-CULOTTA-TEST: Test set split of the ACE 2004 training set utilized in <ref type="bibr" target="#b4">Culotta et al. (2007)</ref> and <ref type="bibr" target="#b1">Bengston and Roth (2008)</ref>.</p><p>Consists of 107 documents. 2</p><p>• ACE2004-NWIRE: ACE 2004 Newswire set to compare against <ref type="bibr" target="#b20">Poon and Domingos (2008)</ref>.</p><p>Consists of 128 documents and 11,413 mentions; intersects with the other ACE data sets.</p><p>• MUC-6-TEST: MUC6 formal evaluation set consisting of 30 documents and 2,068 mentions.</p><p>Unlabeled: (see Section 3.2)</p><p>• BLIPP: 1.8 million sentences of newswire parsed with the Charniak (2000) parser. No labeled coreference data; used for mining semantic information.</p><p>• WIKI: 25k articles of English Wikipedia abstracts parsed by the <ref type="bibr" target="#b13">Klein and Manning (2003)</ref> parser. <ref type="bibr">3</ref> No labeled coreference data; used for mining semantic information.</p><p>1 Other mention types exist and are annotated (such as prenominal), which are treated as nominals in this work. <ref type="bibr">2</ref> The evaluation set was not made available to nonparticipants.</p><p>3 Wikipedia abstracts consist of roughly the first paragraph of the corresponding article</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Evaluation</head><p>We will present evaluations on multiple coreference resolution metrics, as no single one is clearly superior:</p><p>• Pairwise F1: precision, recall, and F1 over all pairs of mentions in the same entity cluster. Note that this over-penalizes the merger or separation of clusters quadratically in the size of the cluster.</p><p>• b 3 (Amit and Baldwin, 1998): For each mention, form the intersection between the predicted cluster and the true cluster for that mention. The precision is the ratio of the intersection and the true cluster sizes and recall the ratio of the intersection to the predicted sizes; F1 is given by the harmonic mean over precision and recall from all mentions.</p><p>• MUC ( <ref type="bibr">Vilain et al., 1995)</ref>: For each true cluster, compute the number of predicted clusters which need to be merged to cover the true cluster. Divide this quantity by true cluster size minus one. Recall is given by the same procedure with predicated and true clusters reversed. 4</p><p>• CEAF ( <ref type="bibr" target="#b16">Luo, 2005</ref>): For a similarity function between predicted and true clusters, CEAF scores the best match between true and predicted clusters using this function. We use the φ 3 similarity function from <ref type="bibr" target="#b16">Luo (2005)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System Description</head><p>In this section we develop our system and report developmental results on ACE2004-ROTH-DEV (see Section 2.1); we report pairwise F1 <ref type="figure">fig- ures</ref> here, but report on many more evaluation metrics in Section 4. At a high level, our system resembles a pairwise coreference model ( <ref type="bibr" target="#b22">Soon et al., 1999;</ref><ref type="bibr" target="#b17">Ng and Cardie, 2002;</ref><ref type="bibr" target="#b1">Bengston and Roth, 2008)</ref>; for each mention m i , we select either a single-best antecedent amongst the previous mentions m 1 , . . . , m i−1 , or the NULL mention to indicate the underlying entity has not yet been evoked. Mentions are linearly ordered according to the position of the mention head with ties being broken by the larger node coming first.</p><p>While much research ( <ref type="bibr" target="#b17">Ng and Cardie, 2002;</ref><ref type="bibr">Cu- lotta et al., 2007;</ref><ref type="bibr" target="#b9">Haghighi and Klein, 2007;</ref><ref type="bibr" target="#b20">Poon and Domingos, 2008;</ref><ref type="bibr" target="#b6">Finkel and Manning, 2008)</ref> has explored how to reconcile pairwise decisions to form coherent clusters, we simply take the transitive closure of our pairwise decision (as in <ref type="bibr" target="#b17">Ng and Cardie (2002)</ref> and <ref type="bibr" target="#b1">Bengston and Roth (2008)</ref>) which can and does cause system errors. In contrast to most recent research, our pairwise decisions are not made with a learned model which outputs a probability or confidence, but instead for each mention m i , we select an antecedent amongst m 1 , . . . , m i−1 or the NULL mention as follows:</p><p>• Syntactic Constraint: Based on syntactic configurations, either force or disallow coreference between the mention and an antecedent. Propagate this constraint (see <ref type="figure" target="#fig_0">Fig- ure 4</ref>).</p><p>• Semantic/Syntactic Filter: Filter the remaining possible antecedents based upon compatibility with the mention (see <ref type="figure">Fig- ure</ref> 2).</p><p>• Selection: Select the 'closest' mention from the set of remaining possible antecedents (see <ref type="figure">Figure 1</ref>) or the NULL antecedent if empty.</p><p>Initially, there is no syntactic constraint (improved in Section 3.1.3), the antecedent compatibility filter allows proper and nominal mentions to corefer only with mentions that have the same head (improved in Section 3.2), and pronouns have no compatibility constraints (improved in Section 3.1.2). Mention heads are determined by parsing the given mention span with the Stanford parser <ref type="bibr" target="#b13">(Klein and Manning, 2003)</ref> and using the Collins head rules <ref type="bibr" target="#b3">(Collins, 1999)</ref>; <ref type="bibr" target="#b20">Poon and Domingos (2008)</ref> showed that using syntactic heads strongly outperformed a simple rightmost headword rule. The mention type is determined by the head POS tag: proper if the head tag is NNP or NNPS, pronoun if the head tag is PRP, PRP$, WP, or WP$, and nominal otherwise.</p><p>For the selection phase, we order mentions m 1 , . . . , m i−1 according to the position of the head word and select the closest mention that remains after constraint and filtering are applied. This choice reflects the intuition of <ref type="bibr" target="#b8">Grosz et al. (1995)</ref> that speakers only use pronominal mentions when there are not intervening compatible <ref type="figure">Figure 1</ref>: Example sentence where closest tree distance between mentions outperforms raw distance. For clarity, each mention NP is labeled with the underlying entity id. mentions. This system yields a rather low 48.9 pairwise F1 (see BASE-FLAT in <ref type="table" target="#tab_2">Table 2</ref>). There are many, primarily recall, errors made choosing antecedents for all mention types which we will address by adding syntactic and semantic constraints.</p><formula xml:id="formula_0">S h h h h h h h @ @ @ @ @ @ @ NP#1    3 3 3 NP NNP Nintendo PP   IN of NP#2 NNP America VP     VBD announced NP#3 r r r ¨ ¨ ¨ NP#1 PRP$ its NP   JJ new NN console</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Adding Syntactic Information</head><p>In this section, we enrich the syntactic representation and information in our system to improve results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Syntactic Salience</head><p>We first focus on fixing the pronoun antecedent choices. A common error arose from the use of mention head distance as a poor proxy for discourse salience. For instance consider the example in <ref type="figure">Figure 1</ref>, the mention America is closest to its in flat mention distance, but syntactically Nintendo of America holds a more prominent syntactic position relative to the pronoun which, as <ref type="bibr" target="#b11">Hobbs (1977)</ref> argues, is key to discourse salience.</p><p>Mapping Mentions to Parse Nodes: In order to use the syntactic position of mentions to determine anaphoricity, we must associate each mention in the document with a parse tree node. We parse all document sentences with the Stanford parser, and then for each evaluation mention, we find the largest-span NP which has the previously determined mention head as its head. <ref type="bibr">5</ref> Often, this results in a different, typically larger, mention span than annotated in the data. Now that each mention is situated in a parse tree, we utilize the length of the shortest tree path between mentions as our notion of distance. In  <ref type="figure">Figure 2</ref>: Example of a coreference decision fixed by agreement constraints (see Section 3.1.2). The pronoun them is closest to the site mention, but has an incompatible number feature with it. The closest (in tree distance, see Section 3.1.1) compatible mention is The Israelis, which is correct particular, this fixes examples such as those in <ref type="figure">Figure 1</ref> where the true antecedent has many embedded mentions between itself and the pronoun. This change by itself yields 51.7 pairwise F1 (see BASE-TREE in <ref type="table" target="#tab_2">Table 2</ref>), which is small overall, but reduces pairwise pronoun antecedent selection error from 51.3% to 42.5%.</p><formula xml:id="formula_1">S hh hh hh hh h @ @ @ @ @ @ @ @ @ NP-ORG#1 r r r ¨ ¨ ¨</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Agreement Constraints</head><p>We now refine our compatibility filtering to incorporate simple agreement constraints between coreferent mentions. Since we currently allow proper and nominal mentions to corefer only with matching head mentions, agreement is only a concern for pronouns. Traditional linguistic theory stipulates that coreferent mentions must agree in number, person, gender, and entity type (e.g. animacy). Here, we implement person, number and entity type agreement. <ref type="bibr">6</ref> A number feature is assigned to each mention deterministically based on the head and its POS tag. For entity type, we use NER labels. Ideally, we would like to have information about the entity type of each referential NP, however this information is not easily obtainable. Instead, we opt to utilize the Stanford NER tagger ( <ref type="bibr" target="#b7">Finkel et al., 2005</ref>) over the sentences in a document and annotate each NP with the NER label assigned to that mention head. For each mention, when its NP is assigned an NER label we allow it to only be compatible with that NER label. <ref type="bibr">7</ref> For pronouns, we deterministically assign a set of compatible NER values (e.g. personal pronouns can only be a PER-6 Gender agreement, while important for general coreference resolution, did not contribute to the errors in our largely newswire data sets. <ref type="bibr">7</ref> Or allow it to be compatible with all NER labels if the NER tagger doesn't predict a label. gore <ref type="table">president  florida  state  bush governor lebanese territory  nation  people  arafat  leader  inc.  company  aol  company  nation country  assad  president   Table 1</ref>: Most common recall (missed-link) errors amongst non-pronoun mention heads on our development set. Detecting compatibility requires semantic knowledge which we obtain from a large corpus (see Section 3.2). SON, but its can be an ORGANIZATION or LOCA-TION). Since the NER tagger typically does not label non-proper NP heads, we have no NER compatibility information for nominals.</p><formula xml:id="formula_2">S ` ` ` ` NP#1 NNP Wal-Mart VP h h h h ( ( ( ( VBZ says S h h h h ( ( ( (</formula><p>We incorporate agreement constraints by filtering the set of possible antecedents to those which have compatible number and NER types with the target mention. This yields 53.4 pairwise F1, and reduces pronoun antecedent errors to 42.5% from 34.4%. An example of the type of error fixed by these agreement constraints is given by <ref type="figure">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Syntactic Configuration Constraints</head><p>Our system has so far focused only on improving pronoun anaphora resolution. However, a plurality of the errors made by our system are amongst nonpronominal mentions. <ref type="bibr">8</ref> We take the approach that in order to align a non-pronominal mention to an antecedent without an identical head, we require evidence that the mentions are compatible.</p><p>Judging compatibility of mentions generally requires semantic knowledge, to which we return later. However, some syntactic configurations</p><formula xml:id="formula_3">NP#1 h h h h h h h h ( ( ( ( ( ( ( ( NP P P P P P NN#1 painter NNP Pablo NNP Picasso , , NP#1``NP#1`NP#1`` ` ` ` ` subject of the [exhibition] 2 NP-PERS#1 hh hh hh hh h J J ( ( ( ( ( ( ( ( ( NP P P P P NP-APPOS#1 NN painter NP-PERS b b b " " " NNP Pablo NNP Picasso , , NP-APPOS#1``APPOS#1`APPOS#1`` ` ` ` ` subject of the [exhibition]2 (a)<label>(b)</label></formula><p>Figure 3: NP structure annotation: In (a) we have the raw parse from the <ref type="bibr" target="#b13">Klein and Manning (2003)</ref> parser with the mentions annotated by entity. In (b), we demonstrate the annotation we have added. NER labels are added to all NP according to the NER label given to the head (see Section 3.1.1). Appositive NPs are also annotated. Hashes indicate forced coreferent nodes guarantee coreference. The one exploited most in coreference work <ref type="bibr" target="#b22">(Soon et al., 1999;</ref><ref type="bibr" target="#b17">Ng and Cardie, 2002;</ref><ref type="bibr" target="#b15">Luo et al., 2004;</ref><ref type="bibr" target="#b4">Culotta et al., 2007;</ref><ref type="bibr" target="#b20">Poon and Domingos, 2008;</ref><ref type="bibr" target="#b1">Bengston and Roth, 2008</ref>) is the appositive construction. Here, we represent apposition as a syntactic feature of an NP indicating that it is coreferent with its parent NP (e.g. it is an exception to the i-within-i constraint that parent and child NPs cannot be coreferent).</p><p>We deterministically mark a node as NP-APPOS (see <ref type="figure">Figure 3)</ref> when it is the third child in of a parent NP whose expansion begins with (NP , NP), and there is not a conjunction in the expansion (to avoid marking elements in a list as appositive).</p><p>Role Appositives: During development, we discovered many errors which involved a variant of appositives which we call 'role appositives' (see painter in <ref type="figure">Figure 3</ref>), where an NP modifying the head NP describes the role of that entity (typically a person entity). There are several challenges to correctly labeling these role NPs as being appositives. First, the NPs produced by Treebank parsers are flat and do not have the required internal structure (see <ref type="figure">Figure 3(a)</ref>). While fully solving this problem is difficult, we can heuristically fix many instances of the problem by placing an NP around maximum length sequences of NNP tags or NN (and JJ) tags within an NP; note that this will fail for many constructions such as U.S. President Barack Obama, which is analyzed as a flat sequence of proper nouns. Once this internal NP structure has been added, whether the NP immediately to the left of the head NP is an appositive depends on the entity type. For instance, Rabbi Ashi is an apposition but Iranian army is not. Again, a full solution would require its own model, here we mark as appositions any NPs immediately to the left of a head child NP where the head child NP is identified as a person by the NER tagger. <ref type="bibr">9</ref> We incorporate NP appositive annotation as a constraint during filtering. Any mention which corresponds to an appositive node has its set of possible antecedents limited to its parent. Along with the appositive constraint, we implement the i-within-i constraint that any non-appositive NP cannot be be coreferent with its parent; this constraint is then propagated to any node its parent is forced to agree with. The order in which these constraints are applied is important, as illustrated by the example in <ref type="figure" target="#fig_0">Figure 4</ref>: First the list of possible antecedents for the appositive NP is constrained to only its parent. Now that all appositives have been constrained, we apply the i-withini constraint, which prevents its from having the NP headed by brand in the set of possible antecedents, and by propagation, also removes the NP headed by Gitano. This leaves the NP Wal-Mart as the closest compatible mention.</p><p>Adding these syntactic constraints to our system yields 55.4 F1, a fairly substantial improvement, but many recall errors remain between mentions with differing heads. Resolving such cases will require external semantic information, which we will automatically acquire (see Section 3.2).</p><p>Predicate Nominatives: Another syntactic constraint exploited in <ref type="bibr" target="#b20">Poon and Domingos (2008)</ref> is the predicate nominative construction, where the object of a copular verb (forms of the verb be) is constrained to corefer with its subject (e.g. Microsoft is a company in Redmond). While much less frequent than appositive configurations (there are only 17 predicate nominatives in our devel- opment set), predicate nominatives are another highly reliable coreference pattern which we will leverage in Section 3.2 to mine semantic knowledge. As with appositives, we annotate object predicate-nominative NPs and constrain coreference as before. This yields a minor improvement to 55.5 F1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Semantic Knowledge</head><p>While appositives and related syntactic constructions can resolve some cases of non-pronominal reference, most cases require semantic knowledge about the various entities as well as the verbs used in conjunction with those entities to disambiguate references ( <ref type="bibr" target="#b12">Kehler et al., 2008)</ref>. However, given a semantically compatible mention head pair, say AOL and company, one might expect to observe a reliable appositive or predicative-nominative construction involving these mentions somewhere in a large corpus. In fact, the Wikipedia page for AOL 10 has a predicate-nominative construction which supports the compatibility of this head pair: AOL LLC (formerly America Online) is an American global Internet services and media company operated by Time Warner.</p><p>In order to harvest compatible head pairs, we utilize our BLIPP and WIKI data sets (see Section 2), and for each noun (proper or common) and pronoun, we assign a maximal NP mention node for each nominal head as in Section 3.1.1; we then annotate appositive and predicate-nominative NPs as in Section 3.1.3. For any NP which is annotated as an appositive or predicate-nominative, we extract the head pair of that node and its constrained antecedent. <ref type="bibr">10</ref> http://en.wikipedia.org/wiki/AOL</p><p>The resulting set of compatible head words, while large, covers a little more than half of the examples given in <ref type="table">Table 1</ref>. The problem is that these highly-reliable syntactic configurations are too sparse and cannot capture all the entity information present. For instance, the first sentence of Wikipedia abstract for Al Gore is:</p><p>Albert Arnold "Al" Gore, Jr. is an American environmental activist who served as the 45th Vice President of the United States from 1993 to 2001 under President Bill Clinton.</p><p>The required lexical pattern X who served as Y is a general appositive-like pattern that almost surely indicates coreference. Rather than opt to manually create a set of these coreference patterns as in Hearst (1992), we instead opt to automatically extract these patterns from large corpora as in <ref type="bibr" target="#b21">Snow et al. (2004)</ref> and <ref type="bibr" target="#b19">Phillips and Riloff (2007)</ref>. We take a simple bootstrapping technique: given a set of mention pairs extracted from appositives and predicate-nominative configurations, we extract counts over tree fragments between nodes which have occurred in this set of head pairs (see <ref type="figure" target="#fig_1">Figure 5)</ref>; the tree fragments are formed by annotating the internal nodes in the tree path with the head word and POS along with the subcategorization. We limit the paths extracted in this way in several ways: paths are only allowed to go between adjacent sentences and have a length of at most 10. We then filter the set of paths to those which occur more than a hundred times and with at least 10 distinct seed head word pairs.</p><p>The vast majority of the extracted fragments are variants of traditional appositives and predicatenominatives with some of the structure of the NPs  specified. However there are some tree fragments which correspond to the novel coreference patterns (see <ref type="figure" target="#fig_1">Figure 5</ref>) of parenthetical alias as well as conjunctions of roles in NPs.</p><p>We apply our extracted tree fragments to our BLIPP and WIKI data sets and extract a set of compatible word pairs which match these fragments; these words pairs will be used to relax the semantic compatibility filter (see the start of the section); mentions are compatible with prior mentions with the same head or with a semantically compatible head word. This yields 58.5 pairwise F1 (see SEM-COMPAT in <ref type="table" target="#tab_2">Table 2</ref>) as well as similar improvements across other metrics.</p><p>By and large the word pairs extracted in this way are correct (in particular we now have coverage for over two-thirds of the head pair recall errors from <ref type="table">Table 1</ref>.) There are however wordpairs which introduce errors. In particular citystate constructions (e.g. Los Angeles, California) appears to be an appositive and incorrectly allows our system to have angeles as an antecedent for california. Another common error is that the % symbol is made compatible with a wide variety of common nouns in the financial domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>We present formal experimental results here (see <ref type="table" target="#tab_2">Table 2</ref>). We first evaluate our model on the ACE2004-CULOTTA-TEST dataset used in the state-of-the-art systems from <ref type="bibr" target="#b4">Culotta et al. (2007)</ref> and <ref type="bibr" target="#b1">Bengston and Roth (2008)</ref>. Both of these systems were supervised systems discriminatively trained to maximize b 3 and used features from many different structured resources including WordNet, as well as domain-specific features ( <ref type="bibr" target="#b4">Culotta et al., 2007</ref>). Our best b 3 result of 79.0 is broadly in the range of these results. We should note that in our work we use neither the gold mention types (we do not model pre-nominals separately) nor do we use the gold NER tags which <ref type="bibr" target="#b1">Bengston and Roth (2008)</ref> does. Across metrics, the syntactic constraints and semantic compatibility components contribute most to the overall final result.</p><p>On the MUC6-TEST dataset, our system outper-  <ref type="table">Table 3</ref>: Errors for each type of antecedent decision made by the system. Each row is a mention type and the column the predicted mention type antecedent. The majority of errors are made in the NOMINAL category.</p><formula xml:id="formula_4">P R O P E R N O M I N A L P R O N O U N N U L L T O T A</formula><p>forms both <ref type="bibr" target="#b20">Poon and Domingos (2008)</ref> (an unsupervised Markov Logic Network system which uses explicit constraints) and Finkel and Manning (2008) (a supervised system which uses ILP inference to reconcile the predictions of a pairwise classifier) on all comparable measures. 11 Similarly, on the ACE2004-NWIRE dataset, we also outperform the state-of-the-art unsupervised system of <ref type="bibr" target="#b20">Poon and Domingos (2008)</ref>. Overall, we conclude that our system outperforms state-of-the-art unsupervised systems 12 and is in the range of the state-of-the art systems of <ref type="bibr">Cu- lotta et al. (2007)</ref> and <ref type="bibr" target="#b1">Bengston and Roth (2008)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Error Analysis</head><p>There are several general trends to the errors made by our system. <ref type="table">Table 3</ref> shows the number of pairwise errors made on MUC6-TEST dataset by mention type; note these errors are not equally weighted in the final evaluations because of the transitive closure taken at the end. The most errors are made on nominal mentions with pronouns coming in a distant second. In particular, we most frequently say a nominal is NULL when it has an antecedent; this is typically due to not having the necessary semantic knowledge to link a nominal to a prior expression.</p><p>In order to get a more thorough view of the cause of pairwise errors, we examined 20 random errors made in aligning each mention type to an antecedent. We categorized the errors as follows:</p><p>• SEM. COMPAT: Missing information about the compatibility of two words e.g. pay and wage. For pronouns, this is used to mean that we incorrectly aligned a pronoun to a mention with which it is not semantically compatible (e.g. he aligned to board).</p><p>• SYN. COMPAT: Error in assigning linguistic features of nouns for compatibility with pronouns (e.g. disallowing they to refer to team).</p><p>• HEAD: Errors involving the assumption that mentions with the same head are always compatible. Includes modifier and specificity errors such as allowing Lebanon and Southern Lebanon to corefer. This also includes errors of definiteness in nominals (e.g. the people in the room and Chinese people). Typically, these errors involve a combination of missing syntactic and semantic information.</p><p>• INTERNAL NP: Errors involving lack of internal NP structure to mark role appositives (see Section 3.1.3).</p><p>• PRAG. / DISC.: Errors where discourse salience or pragmatics are needed to disambiguate mention antecedents.</p><p>• PROCESS ERROR: Errors which involved a tokenization, parse, or NER error.</p><p>The result of this error analysis is given in Table 4; note that a single error may be attributed to more than one cause. Despite our efforts in Section 3 to add syntactic and semantic information to our system, the largest source of error is still a combination of missing semantic information or annotated syntactic structure rather than the lack of discourse or salience modeling.</p><p>Our error analysis suggests that in order to improve the state-of-the-art in coreference resolution, future research should consider richer syntactic and semantic information than typically used in current systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Our approach is not intended as an argument against the more complex, discourse-focused approaches that typify recent work. Instead, we note that rich syntactic and semantic processing vastly reduces the need to rely on discourse effects or evidence reconciliation for reference resolution. Indeed, we suspect that further improving the syntactic and semantic modules in our system may produce greater error reductions than any other  <ref type="table">Table 4</ref>: Error analysis on ACE2004-CULOTTA-TEST data by mention type. The dominant errors are in either semantic or syntactic compatibility of mentions rather than discourse phenomena. See Section 5.</p><p>route forward. Of course, a system which is rich in all axes will find some advantage over any simplified approach. Nonetheless, our coreference system, despite being relatively simple and having no tunable parameters or complexity beyond the non-reference complexity of its component modules, manages to outperform state-of-the-art unsupervised coreference resolution and be broadly comparable to state-of-the-art supervised systems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Example of interaction between the appositive and i-within-i constraint. The i-withini constraint disallows coreference between parent and child NPs unless the child is an appositive. Hashed numbers indicate ground truth but are not in the actual trees.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Example paths extracted via semantic compatibility mining (see Section 3.2) along with example instantiations. In both examples the left child NP is coreferent with the rightmost NP. Each category in the interior of the tree path is annotated with the head word as well as its subcategorization. The examples given here collapse multiple instances of extracted paths.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>PP   IN as NP#2   a shrine SBAR   IN because PP   &amp; &amp; TO to NP#1 PRP them S</head><label></label><figDesc></figDesc><table>The Israelis 
VP hh hh hh hh hh h 

3 
3 
3 
3 
3 

@ 
@ 
@ 
@ 
@ 
@ 
@ 
@ 
@ 
@ 
@ 

VBP 

regard 

NP#2 

r r r 
¨ 
¨ 
¨ 

NP 

the site 

¡ 
¡ 
2 
2 
2 
2 
2 
2 

r r r 
¨ 
¨ 
¨ 

it is sacred 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Experimental Results (See Section 4): When comparisons between systems are presented, the 
largest result is bolded. The CEAF measure has equal values for precision, recall, and F1. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Mention Type SEM. COMPAT SYN. COMPAT HEAD INTENAL NP PRAG / DISC. PROCESS ERROR OTHER</head><label>Mention</label><figDesc></figDesc><table>Comment 

NOMINAL 

7 
-
5 
6 
2 
2 
1 
2 general appos. patterns 

PRONOUN 

6 
3 
-
6 
3 
3 
3 
2 cataphora 

PROPER 

6 
-
3 
4 
4 
4 
1 

</table></figure>

			<note place="foot" n="4"> The MUC measure is problematic when the system predicts many more clusters than actually exist (Luo, 2005; Finkel and Manning, 2008); also, singleton clusters do not contribute to evaluation.</note>

			<note place="foot" n="5"> If there is no NP headed by a given mention head, we add an NP over just that word.</note>

			<note place="foot" n="8"> There are over twice as many nominal mentions in our development data as pronouns.</note>

			<note place="foot" n="9"> Arguably, we could also consider right modifying NPs (e.g., [Microsoft [Company]1]1) to be role appositive, but we do not do so here.</note>

			<note place="foot" n="11"> Klenner and Ailloud (2007) took essentially the same approach but did so on non-comparable data. 12 Poon and Domingos (2008) outperformed Haghighi and Klein (2007). Unfortunately, we cannot compare against Ng (2008) since we do not have access to the version of the ACE data used in their evaluation.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Algorithms for scoring coreference chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Amit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MUC7</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Understanding the value of features for corefernce resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Bengston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Maximum entropy inspired parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Chapter of the Association of Computational Linguistics (NAACL)</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Head-driven statistical models for natural language parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Collins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">First-order probabilistic models for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Culotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Global, Joint Determination of Anaphoricity and Coreference Resolution using Integer Programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Denis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Enforcing transitivity in coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association of Computational Linguists (ACL)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Incorporating non-local information into information extraction systems by gibbs sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Centering: A framework for modelling the local coherence of discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><forename type="middle">J</forename><surname>Grosz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Weinstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unsupervised coreference resolution in a nonparametric bayesian model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics. Association for Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association of Computational Linguistics. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatic acquisition of hyponyms from large text corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marti</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Natural Language Learning (COLING)</title>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Resolving pronoun references</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Hobbs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lingua</title>
		<imprint>
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Coherence and coreference revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Kehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Kertz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannah</forename><surname>Rohde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Elman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Accurate unlexicalized parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association of Computational Linguists (ACL)</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Optimization in coreference resolution is not needed: A nearly-optimal algorithm with intensional constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Klenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etienne</forename><surname>Ailloud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recent Advances in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Mention-Synchronous Coreference Resolution Algorithm Based on the Bell Tree</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abe</forename><surname>Ittycheriah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyan</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanda</forename><surname>Kambhatla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association of Computational Linguists</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">On coreference resolution performance metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing</title>
		<meeting>the conference on Human Language Technology and Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Improving Machine Learning Approaches to Coreference Resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association of Computational Linguists</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unsupervised models of coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Exploiting roleidentifying nouns and expressions for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recent Advances in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>RANLP</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Joint unsupervised coreference resolution with Markov Logic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2008 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning syntactic patterns for automatic hypernym discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">A machine learning approach to coreference resolution of noun phrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Soon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C Y</forename><surname>Lim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Dennis Connolly, and Lynette Hirschman. 1995. A modeltheoretic coreference scoring scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Vilain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Aberdeen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MUC-6</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
