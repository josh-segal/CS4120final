<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Local Context in Non-linear Deformation Models for Handwritten Character Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Keysers</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Lehrstuhl für Informatik VI -Computer Science Department</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<postCode>D-52056</postCode>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Gollan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Lehrstuhl für Informatik VI -Computer Science Department</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<postCode>D-52056</postCode>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Lehrstuhl für Informatik VI -Computer Science Department</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<postCode>D-52056</postCode>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Local Context in Non-linear Deformation Models for Handwritten Character Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We evaluate different two-dimensional non-linear deformation models for handwritten character recognition. Starting from a true two-dimensional model, we derive pseudo-two-dimensional and zero-order deformation models. Experiments show that it is most important to include suitable representations of the local image context of each pixel to increase performance. With these methods, we achieve very competitive results across five different tasks, in particular 0.5% error rate on the MNIST task.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In many object recognition tasks it is important to use suitable models of image transformation to obtain good results. The recognition of handwritten digits is a prototypical task in this context, as different writing styles lead to strongly varying appearances of the images, but at the same time the reference model for each class is well-defined. In this paper we show that two-dimensional non-linear deformation models in combination with suitable representations of the local image context of each pixel are an effective means to obtain excellent results for this task. We use five different databases and a comparison to other approaches shows that the proposed methods generalize very well.</p><p>We describe deformation models of different order: Two-dimensional (2D) hidden Markov models (HMMs) take into account the connections between the displacements of pixels in both directions of the image plane. They have been introduced in several publications, e.g. <ref type="bibr" target="#b0">[1]</ref>. Pseudo-two-dimensional (P2D) HMMs relax the constraints in one of the dimensions, thus reducing the computational effort considerably <ref type="bibr" target="#b1">[2]</ref>. If we further relax the constraints on the deformation grid such that the pixel displacements are independent of each other, we arrive at a zeroorder model that we call image distortion model (IDM). This simple model has been introduced in the literature several times with different names, e.g. <ref type="bibr" target="#b2">[3]</ref>. Finally, the P2DHMM can be extended to allow additional distortions.</p><p>The experiments show that the important aspect for these models is the use of local context information at the pixel £ This work was partially funded by the DFG (Deutsche Forschungsgemeinschaft) under contract NE-572/6. level. Using this context information in the form of the image gradient and local image parts, the performance can be improved significantly, leading to state-of-the-art results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Classifier and deformation models</head><p>Since we investigate the influence of different deformation models on the classification accuracy, we use a simple classification setup, i.e. the well-known nearest neighbor (NN) classifier. On most databases, the 3-NN classifier was used, as other groups report good results for this choice.</p><p>The deformation models result in distance measures that are used in the NN classifier, where the test image</p><formula xml:id="formula_0">¤ ¦ ¥ ¨ § © ¥ " ! # % $ &amp; $ % $ ' ( ) 1 0 2 ¥ " ! &amp; $ &amp; $ % $ 3 3 4</formula><p>is explained by a suitable deformation of the reference image</p><formula xml:id="formula_1">5 ¥ 6 § 8 7 &amp; 9 A @ # C B D ¥ ! # % $ &amp; $ &amp; $ &amp; C E F G " ¥ H ! &amp; $ % $ &amp; $ 3 P I</formula><p>. Here, the image pixels take</p><formula xml:id="formula_2">Q - dimensional values © P 79 % @ S R U TV X W .</formula><p>We now want to determine an image deformation mapping </p><formula xml:id="formula_3">Y B a ` ' b c P c G d ` ' b c c f e h g Y i 1 0 e q p r Y B C G s</formula><formula xml:id="formula_4">d f e g h  Y B ` ' b c P c G` i b c P c e C  ¥ i   k j e d Y B m l i G s n l 0 e</formula><p>On the other hand, relative cost functions depend on the relative displacement of neighboring pixels:</p><formula xml:id="formula_5">d p o g % q  Y B ` ' b c P c G` i b c P c f e C  ¥   r j oY B ) l Y B ) s c u t v ! e G # l G # s c w C B x s l B ) y s c G # l Y G # z s c t v ! e C e</formula><p>Here, j e and j o determine the model structure as mentioned above. The distance measure is determined by minimizing the costs over the possible deformation mappings:</p><formula xml:id="formula_6">Y ¤ u 5 e ¥ ¡ £ ¢ ¥ ¤ t 9 % v x w y 1 y @ &amp; v u w y 1 y ¦    ¤  5 Y B `  b c P c C G`  b c P ce t ¨ § d  Y B `  b c P c G`  b c ce ©</formula><p>where § is the deformation cost weight and</p><formula xml:id="formula_7">d ¥ d o t d e</formula><p>is the sum of relative and absolute deformation costs. Additionally, the border constraints</p><formula xml:id="formula_8">B c " ¥ ! # B ` " ¥ E F C G # c ¥ ! # C B x b ¥ I</formula><p>are applied. To soften these constraints the images can be extended by e.g. 3 pixels at the borders.</p><p>Two-dimensional HMM. The 2DHMM is an extension to two dimensions of the (0,1,2)-or (loop, jump, skip)-HMM that is frequently used e.g. in speech recognition. It results from using the relative cost function j oY</p><formula xml:id="formula_9">9 @ 9 @ e ¥ ¡ Y  9   y  @   y  9   z  @  e " ! ! # otherwise</formula><p>This cost function ensures monotonicity (no backward steps) and continuity (no large jumps) of the displacement grid. Here, instead of using the cost value 0, we can also use a function depending on the relative displacements. In addition, we may also use an absolute cost function j eY</p><formula xml:id="formula_10">$ 9 @ e ¥ ¡ £ % Y  9   @  e &amp; ! ( ' # otherwise (1)</formula><p>with a warp range</p><formula xml:id="formula_11">' (e.g. ' ¥ 0 )</formula><p>), which restricts the absolute global deformation. The minimization of this true 2D model is NP-complete <ref type="bibr" target="#b3">[4]</ref>, and therefore approximation algorithms are used as e.g. dynamic programming with beamsearch <ref type="bibr" target="#b0">[1]</ref>, or simulated annealing.</p><p>Pseudo-two-dimensional HMM. The P2DHMM <ref type="bibr" target="#b1">[2]</ref> is obtained from the 2DHMM by neglecting the dependencies between pixels of neighboring image columns, using: This model is computationally equivalent to a onedimensional HMM and therefore the minimization process can be solved in polynomial time. Nevertheless, the computational effort can be substantial and methods like beam search can be used to speed up the minimization.</p><p>Image Distortion Model. The IDM is a zero-order model, i.e. local dependencies in the displacement grid are neglected. Consequentially, it results from using no relative cost function (i.e. </p><note type="other">f g f f h i q p s r ¥ t v u w $ x y s p  r R     $ x f   Figure 2. Example P2DHMDM mapping.</note><p>IDM. It results from the P2DHMM when we allow additional distortions from the columns that are matched by an additional pixel, where these distortions are independent of each other. <ref type="figure">Figure 2</ref> shows an example mapping allowed under the restrictions of the P2DHMDM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Using local image context</head><p>Using the above models, experiments on the USPS corpus (Section 4) showed that only a comparatively small improvement from 5.6% to 4.0% was possible when using the pixel values directly. Furthermore, the improvements depended strongly on the choice and weight of the deformation cost function for the allowed relative displacements. An analysis showed that some wanted deformations but also unwanted deformations changing the class membership of the images were modeled. This behavior can be restricted by including the local image context of each pixel in an appropriate way, with the result that pixel values are vectors.</p><p>Derivatives as context. One straight forward way to include the local image context is to use derivatives of the image values with respect to the image coordinates as computed by the horizontal and vertical Sobel filter. These values have the additional advantage of invariance with respect to the absolute image brightness. Now the question arises of how to weight the importance of the context information with respect to the image gray values. <ref type="figure" target="#fig_3">Figure 3</ref> shows the error rate on the USPS corpus (using the P2DHMM) with respect to the relative weight of the gradient image (a relative weight of 1 means that only the gradient information is used). From the graph it is clear that best results are obtained when using only the gradient information. The additional use of the second derivative lead to only small improvements in first experiments.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Databases and results</head><p>All results presented here were obtained using 3  3 sub images of the horizontal and vertical gradient images only, i.e. 18-dimensional vectors as pixel values, as these settings showed the overall best performance among those investigated. <ref type="figure" target="#fig_5">Figure 4</ref> shows the process of the feature extraction: The horizontal and vertical gradient images are calculated using the Sobel filter, then the local 3 . To speed up the classification process, a preselection of the e.g. 500 best fitting references based on the Euclidean distance was performed in some of the experiments <ref type="bibr" target="#b4">[5]</ref>. The software used for the experiments is available for download <ref type="bibr" target="#b0">1</ref> .</p><p>An overview of the used corpora is shown in <ref type="table" target="#tab_1">Table 1</ref>. For each database some example images are shown along with the sizes of training and test sets and the sizes of the images. Reference results are shown in <ref type="table" target="#tab_2">Table 2</ref> along with the results obtained using the methods presented in this paper. It can be observed that the results are state-of-the-art and even improve on the best published error rates for three of the five corpora. In the following paragraphs we shortly summarize special results for each of the databases used.</p><p>USPS. On the US postal service database, the P2DHMDM gave the best results. Some experiments were 1 http://www-i6.informatik.rwth-aachen.de/¦ gollan/w2d.html performed for training of prototypes with the presented models. <ref type="figure" target="#fig_6">Figure 5</ref> shows the mean images for all ten classes and the prototypes learned using the deformation model. The error rates show that the P2DHMDM performs better using the learned prototypes and interestingly using only one prototype per class, the error rate is as low as 4.9%. The learned prototypes appear much less blurred than the means, as the variation is compensated by the non-linear deformation model. On the other hand the corresponding mean images perform better if no deformation is used.</p><p>UCI. On the University of California, Irvine, optical digits corpus, a scaling to 16  16 pixels using spline interpolation was performed. Here, the IDM performed as good as the more complex P2DHMDM.</p><p>MCEDAR. On the Modified CEDAR (Center of Excellence for Document Analysis and Recognition) task, again the images were scaled to 16  16 pixels using splines. Here, the P2DHMDM performed slightly better than the IDM.</p><p>MNIST. On the Modified National Institute of Standards and Technology task, due to the good results of the IDM on the other databases and the lower complexity, only the IDM   <ref type="bibr" target="#b11">[12]</ref> and 56 reported in <ref type="bibr" target="#b12">[13]</ref>. ETL6A. The Electrotechnical Laboratory, National Institute of Advanced Industrial Science and Technology, Japan, 6A sub corpus contains Latin uppercase letters of 26 classes that were scaled down to 16  16 pixels. The proposed deformation models, which are similar to the methods used in <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>, also obtained very good results, here.</p><p>Comparison of different models. Due to space limitations, we cannot give a complete list of reference results for the different models here. A detailed discussion can be found in <ref type="bibr" target="#b4">[5]</ref>. In the experiments, some general results could be observed. For all of the models, the performance increased significantly with the use of local image context. This increase was greater for the simpler models, leading to the conclusion that the context information can compensate for the neglected restrictions. One of the reasons for the fact that the more complex models did not outperform the simpler models is the following: Due to the computational complexity of the minimization, approximation methods had to be applied and for the more complex models usually a smaller number of images was preselected using the Euclidean distance to reduce the computational effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We presented different non-linear deformation models and introduced the P2DHMDM as an extension. The most important aspect when applying these methods is the inclusion of local image context information, for which we propose the gradient and small sub images. Using the context information, very good results can be achieved even with simple deformation models. The experiments gave new best results on three of the five databases used and were very competitive on the remaining two. The excellent overall results show the general applicability of the methods, which is also true for medical images <ref type="bibr" target="#b16">[17]</ref>. Aspects to be addressed in future work include other methods of context extraction, as e.g. PCA, the use of more prototypes per class and the extension to the recognition of continuous script.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>tween neighboring columns is neglected, and all pixels from one column are mapped onto the same target column. Again, we can use a function depending on the relative dis- placements and an absolute warp range as in Eq. (1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>)in computation time. Pseudo-two-dimensional HM distortion model.Figure 1 . IDM mappings, cp. Eq. ( 1 ).</head><label>11</label><figDesc>Figure 1. IDM mappings, cp. Eq. (1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Sub images as context.</head><label></label><figDesc>A second way to include the local image context is to use local sub images that are ex- tracted around the regarded pixel, e.g. of size 3  3 pixels. If these contexts are extracted from the gradient images, the value of an image pixel is a vector of dimension</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 . USPS error vs. gradient weight.</head><label>3</label><figDesc>Figure 3. USPS error vs. gradient weight.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc> 3 context is extracted in the gradient images and the values are stacked onto each other to form the pixel-level feature vector. All experiments were performed using a ¥ -NN classifier with ¥ R § ! # </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Extraction of local image context.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 . USPS prototypes / error rates [%].</head><label>5</label><figDesc>Figure 5. USPS prototypes / error rates [%].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table>Corpus and image sizes and example images. 
name 
example images 
size 
# train # test 

USPS 

! 

¡ 

 

! 

¢ 

7 291 
2 007 

UCI 

 
 
 

3 823 
1 797 

MCEDAR 

 
 
 

11 000 
2 711 

MNIST 

) 
 
 
) 
%  

60 000 10 000 

ETL6A 

 
  


¤ £ 

 

 

15 600 13 000 

2 

2.5 

3 

3.5 

4 

4.5 

5 

5.5 

6 

6.5 

7 

0 
0.2 
0.4 
0.6 
0.8 
1 

error rate [%] 

relative weight of image gradients vs. image gray values 

USPS error rate 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 . Error rates for the different corpora.</head><label>2</label><figDesc></figDesc><table>method 
ER[%] 
USPS 
Euclidean distance, 1-NN 
5.6 
2DHMM, 1-NN 
this work 
2.7 
extended tangent distance 
[3] 
2.4 
IDM, 1-NN 
this work 
2.4 
extended support vectors 
[6] 
2.2 
local features + tangent distance 
[7] 
2.0 
P2DHMDM, 3-NN 
this work 
1.9 
UCI 
Euclidean distance, 1-NN 
2.0 
PCA mixture 
[8] 
1.5 
P2DHMDM / IDM, 1-NN 
this work 
0.8 
MCEDAR 
factor analysis 
[9] 
4.7 
probabilistic PCA 
[10] 
4.6 
IDM, 3-NN 
this work 
3.5 
P2DHMDM, 3-NN 
this work 
3.3 
MNIST 
deslant, Euclidean distance, 

-NN 
[11] 
2.4 
extended tangent distance 
[3] 
1.0 
distortions, neural net, boosting 
[11] 
0.7 
shape context matching, 3-NN 
[12] 
0.6 
invariant support vector machine 
[13] 
0.6 
IDM, 3-NN 
this work 
0.5 
distortions+, neural net 
[14] 
0.4 
ETL6A 
Euclidean distance, 1-NN 
4.5 
piece-wise linear 2D-HMM 
[15] 
0.9 
Eigen-deformations 
[16] 
0.5 
IDM, 3-NN 
this work 
0.5 

was tested. It resulted in 54 errors as compared to the 63 
errors reported in </table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A monotonic and continuous twodimensional warping based on dynamic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Uchida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sakoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICPR</title>
		<meeting>ICPR<address><addrLine>Brisbane, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-08" />
			<biblScope unit="page" from="521" to="524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Keyword Spotting in Poorly Printed Documents using Pseudo 2-D Hidden Markov Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Agazzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. PAMI</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="842" to="848" />
			<date type="published" when="1994-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Experiments with an Extended Tangent Distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dahmen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Theiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICPR</title>
		<meeting>ICPR<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-09" />
			<biblScope unit="page" from="38" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Elastic Image Matching is NPcomplete</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Unger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recog. Lett</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="445" to="453" />
			<date type="published" when="2003-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Nichtlineare Verformungsmodelle für die Bilderkennung (in German). Diploma thesis, Lehrstuhl für Informatik VI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gollan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003-09" />
			<pubPlace>Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>RWTH Aachen University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Practical SMO Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krzyzak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICPR</title>
		<meeting>ICPR<address><addrLine>Quebec City, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Combination of Tangent Vectors and Local Representations for Handwritten Digit Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Paredes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Workshop Stat. Pattern Recognition</title>
		<meeting><address><addrLine>Windsor, Ontario, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-08" />
			<biblScope unit="page" from="538" to="547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A Numeral Character Recognition using the PCA Mixture Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y</forename><surname>Bang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recog. Lett</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="103" to="111" />
			<date type="published" when="2002-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Modeling the Manifolds of Images of Handwritten Digits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Revow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="74" />
			<date type="published" when="1997-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Probabilistic Principal Component Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tipping</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Royal Stat. Soc. (B)</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="611" to="622" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Gradient-Based Learning Applied to Document Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Shape Context: A New Descriptor for Shape Matching and Object Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 13</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="831" to="837" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Training Invariant Support Vector Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Decoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="161" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Simard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IC-DAR</title>
		<meeting>IC-DAR<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-08" />
			<biblScope unit="page" from="958" to="962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Handwritten character recognition using elastic matching based on a class-dependent deformation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Uchida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sakoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICDAR</title>
		<meeting>ICDAR<address><addrLine>Edinburgh, Scotland, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-08" />
			<biblScope unit="page" from="163" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Eigen-Deformations for Elastic Matching based Handwritten Character Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Uchida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sakoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2031" to="2040" />
			<date type="published" when="2003-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Classification of Medical Images using Non-linear Distortion Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gollan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bildverarbeitung für die Medizin</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-03" />
			<biblScope unit="page" from="366" to="370" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
