<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Neural Network Classifier for Junk E-Mail</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2004-05-07">May 7th, 2004</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Stuart</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sung-Hyuk</forename><surname>Cha</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Tappert</surname></persName>
						</author>
						<title level="a" type="main">A Neural Network Classifier for Junk E-Mail</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of Student/Faculty Research Day</title>
						<meeting>Student/Faculty Research Day						</meeting>
						<imprint>
							<date type="published" when="2004-05-07">May 7th, 2004</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Most e-mail readers spend a non-trivial amount of time regularly deleting junk e-mail (spam) messages , even as an expanding volume of such e-mail occupies server storage space and consumes network bandwidth. An ongoing challenge, therefore, rests within the development and refinement of automatic clas-sifiers that can distinguish legitimate e-mail from spam. A few published studies have examined spam detectors using Naïve Bayesian approaches and large feature sets of binary attributes that determine the existence of common keywords in spam, and many commercial applications also use Naïve Bayesian techniques. Spammers recognize these attempts to thwart their messages and have developed tactics to circumvent these filters, but these evasive tactics are themselves patterns that human readers can often identify quickly. This preliminary study tests an alternative approach using a neural network (NN) classifier on a corpus of e-mail messages from one user. The feature set uses descriptive characteristics of words and messages similar to those that a human reader would use to identify spam. The results of this study are compared to previous spam detectors that have used Naïve Bayesian classifiers.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The volume of junk e-mail (spam) transmitted by the Internet has arguably reached epidemic proportions. While the inconvenience of spam is not new -public comments about unwanted e-mail messages identified the problem as early as 1975 -the volume of unsolicited commercial e-mail was relatively limited until the mid-1990s <ref type="bibr" target="#b2">[3]</ref>. Spam volume was estimated to be merely 8% of network e-mail traffic in 2001 but has ballooned to about 40% of e-mail today. One research firm has predicted that the cost of fighting spam across the U.S. will approach $10 billion in 2003 <ref type="bibr" target="#b11">[12]</ref>.</p><p>Most e-mail readers must spend a non-trivial amount of time regularly deleting spam messages, even as an expanding volume of junk e-mail occupies server storage space and consumes network bandwidth. An ongoing challenge, therefore, rests within the development and refinement of automatic classifiers that can distinguish legitimate e-mail from spam.</p><p>Many commercial and open-source products exist to accommodate the growing need for spam classifiers, and a variety of techniques have been developed and applied toward the problem, both at the network and user levels. The simplest and most common approaches are to use filters that screen messages based upon the presence of common words or phrases common to junk e-mail. Other simplistic approaches include blacklisting (automatic rejection of messages received from the addresses of known spammers) and whitelisting (automatic acceptance of message received from known and trusted correspondents). In practice, effective spam filtering uses a combination of these three techniques. The primary flaw in the first two approaches is that it relies upon complacence by the spammers by assuming that they are not likely to change (or forge) their identities or to alter the style and vocabulary of their sales pitches. Whitelisting risks the possibility that the recipient will miss legitimate e-mail from a known or expected correspondent with a heretofore unknown address, such as correspondence from a long-lost friend, or a purchase confirmation pertaining to a transaction with an online retailer.</p><p>A variety of text classifiers have been investigated that categorize documents topically or thematically, including probabilistic, decision tree, rule-based, example-based ("lazy learner"), linear discriminant analysis, regression, support vector machine, and neural network approaches <ref type="bibr" target="#b9">[10]</ref>. A prototype system has also been designed to recognize hostile messages ("flames") within online communications <ref type="bibr" target="#b10">[11]</ref>. However, the body of published academic work specific to spam filtering and classification is limited. This may seem surprising given the obvious need for effective, automated classifiers, but it suggests two likely reasons for the low volume of published material. First, the effectiveness of any given anti-spam technique can be seriously compromised by the public revelation of the technique since spammers are aggressive and adaptable. Second, recent variations of Naïve Bayesian classifiers have demonstrated high degrees of success. In general, these classifiers identify attributes (usually keywords or phrases common to spam) that are assigned probabilities by the classifier. The product of</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.2</head><p>the probabilities of each attribute within a message is compared to a predefined threshold, and the messages with products exceeding the threshold are classified as spam.</p><p>Sahami, et al. <ref type="bibr" target="#b8">[9]</ref> proposed a Naïve Bayesian approach that examined manually-categorized messages for a set of common words, phrases ("be over 21", "only $", etc.), and non-textual characteristics (such as the time of initial transmission or the existence of attachments) deemed common to junk e-mail. Androutsopoulos, et al. <ref type="bibr" target="#b0">[1]</ref> used an edited, 1 encrypted, and manually-categorized corpus of messages with a lemmatizer and a stop-list, using words-attributes. Both approaches used binary attributes, where X n = 1 if a property is represented and X n = 0 if it is not. In each case, the selected words were the result of hand-crafted, manually-derived selections. In addition to these approaches, several applied solutions exist that claim high success rates (as high as 99.5%) with Naïve Bayesian classifiers <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref> that use comprehensive hash tables comprised of hundreds of thousands of tokens and their corresponding probability values, essentially creating attribute sets of indefinite size. <ref type="bibr" target="#b1">2</ref> While these Naïve Bayesian approaches generally perform effectively, they suffer from two intrinsic problems. The first is that they rely upon a consistent vocabulary by the spammers. New words that become more frequently used must be identified as they appear in waves of new spam, and, in the case of hash tables, any new word must be assigned an initial arbitrary probability value when it is created. Spammers use this flaw to their advantage, peppering spam with strings of random characters to slip the junk messages under the classification thresholds. The second problem is one of context. Binary word-attributes, and even phrase-attributes, do not identify the common patterns in spam that humans can easily and readily identify, such as unusual spellings, images and hyperlinks, and patterns typically hidden from the recipient, such as HTML comments.</p><p>In summary, Naïve Bayesian classifiers are indeed naïve, and require substantial calculations for each e-mail classification. A human reader, by contrast, requires relatively little calculation to deduce if a given e-mail is a legitimate message or spam. While spammers send messages that vary widely in composition, subject, and style, they typically include identifiable tactics that are designed to garner attention or to circumvent filters and classifiers and that are rarely used in traditional private correspondence. These evasive tactics are themselves patterns that human readers can often identify quickly.</p><p>In this paper we apply a neural network (NN) approach to the classification of spam using attributes comprised from descriptive characteristics of the evasive patterns that spammers employ, rather than the context or frequency of keywords in the messages. This approach produces similar results but with fewer attributes than the Naïve Bayesian strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>This project used a corpus of 1654 e-mails received by one of the authors over a period of several months. None of the e-mails contained embedded attachments.</p><p>Each e-mail message was saved as a text file, and then parsed to identify each header element (such as Received: or Subject:) to distinguish them from the body of the message. Every substring within the subject header and the message body that was delimited by white space was considered to be a token, and an alphabetic word was defined as a token delimited by white space that contains only English alphabetic characters (A-Z, az) or apostrophes. The tokens were evaluated to create a set of 17 hand-crafted features from each e-mail message <ref type="table" target="#tab_0">(Table 1</ref>).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.3</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>16</head><p>Binary feature indicating whether a color of any text within the body message was set to white: 1 = yes, 0 = no</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>17</head><p>Number of URLs within hyperlinks that contain any numeric digits or any of three special characters ("&amp;", "%" or "@") in the domain or subdomain(s) of the link The e-mails were manually categorized into 800 legitimate e-mails and 854 junk e-mails. Half of each category was randomly selected to comprise a training set (n = 827) and the remaining e-mails were used as a testing set. All feature values were scaled (normalized) to range from 0 to 1.</p><p>The training data were used to train a three-layer, backpropagation neural network with the number of hidden nodes ranging from 4 to 14 and the number of epochs from 100 to 500. After training, the e-mail messages of the testing set were classified to obtain generalization accuracy results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>The relative success of spam filtering techniques is determined by classic measures of precision and recall on the testing subsets of legitimate e-mail and junk e-mail. Spam precision (SP) is defined as the percentage of messages classified as spam that actually are spam. Likewise, legitimate precision (LP) is the percentage of messages classified as legitimate that are indeed legitimate. Spam recall (SR) is defined as the proportion of the number of correctly-classified spam messages to the number of messages originally categorized as spam. Similarly, legitimate recall (LR) is the proportion of correctly-classified legitimate messages to the number of messages originally categorized as legitimate. Thus, we define the counts:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.4</head><p>n SS = the number of spam messages correctly classified as spam. n SL = the number of spam messages incorrectly classified as legitimate n LL = the number of legitimate messages correctly classified as legitimate n LS = the number of legitimate messages incorrectly classified as spam and the precision and recall formulas: <ref type="table" target="#tab_1">Table 2</ref> gives the results on the testing set by hidden node count and training epochs. The trial with 12 hidden nodes and 500 epochs (highlighted in the table) produced the lowest number of misclassifications, with 35 of the 427 spam messages (8.20%) classified as legitimate (nSL), and 32 of the 400 legitimate messages (8.00%) classified as spam (nLS), for a total of 67 misclassifications. Of the 35 misclassified spam messages, 30 were short in length -only a few lines, including HTML tagssome as brief as "save up to 27% on gas" followed by a hyperlink. Among the remaining five messages: one had many "comments" without comment delimiters, thus creating nonsense HTML tags that some browsers ignore (but some do not -a risk this spammer was willing to take); two were written almost entirely in ASCII 5.5 escape codes; one followed four image files with English words in jumbled, meaningless sentences; and one creatively used an off-white color for fonts to disguise the random characters appended to the end of the e-mail.</p><formula xml:id="formula_0">LS SS SS n n n SP precision Spam + = ) ( (1) SL LL LL n n n LP precision Legitimate + = ) ( (2) SL SS SS n n n SR recall Spam + = ) ( (3) LS LL LL n n n LR recall Legitimate + = ) ( (4)</formula><p>The 32 legitimate messages were misclassified due mostly to characteristics that are unusual for personal email. Twenty-two affected the features normally triggered by spam: six were from a known correspondent that prefers to write in white typeface on a colored background, ten were responses or forwards that quoted HTML that triggered several features, five were commercial e-mail from known vendors (with many hyperlinks and linkable images), and one was ranked as "low" priority from a known correspondent. The remaining ten messages were less obvious: four included special characters or vowel-less words in the subject header, three had several words with multiple occurrences of rare English characters (feature 2), and three had an unusual number of hyperlinks (due, in part, to links in signature lines).</p><p>The NN accuracy of this study is similar to that of the Naïve Bayesian classifiers described in <ref type="bibr" target="#b0">[1]</ref> and <ref type="bibr" target="#b8">[9]</ref>, and <ref type="table" target="#tab_2">Table 3</ref> presents a comparison. For comparison purposes we also ran a small experiment with spam blacklist databases. While some databases are part of commercial programs, most require manual entry of IP addresses one at a time, apparently designed primarily for mail server administrators who are trying to determine whether their legitimate e-mails are being incorrectly tagged as spam. To test how accurately legitimate and spam e-mails are tagged by the blacklist databases, we manually entered the IP addresses of the e-mail messages that were incorrectly tagged by the NN classifier (32 legitimate and 35 spam e-mails) into a site that sends IP addresses to 173 working spam blacklists and returns the number of hits <ref type="bibr" target="#b3">[4]</ref>. We entered both the first (original) IP address of each message and also, when present, a second IP address (a possible mail server or ISP). While it is likely that the second IP column includes bulk e-mail servers of spammers, it is also likely that it includes non-spamming ISPs or Web portals that route junk e-mail messages but presumably do not participate intentionally in spamming. Because we considered single-list hits to be anomalies since they aren't confirmed by any other blacklists on the site, we counted only hit counts greater than one as spam that would have been blacklisted. The blacklisting results are presented in <ref type="table" target="#tab_3">Table 4</ref>. While the percentages of legitimate e-mails considered spam by the blacklists are lower than the percentages of spam correctly identified as spam, it is surprising to see that over half were incorrectly screened using our "at least two blacklists" criterion. Even though we tested the blacklist databases with potentially difficult e-mails, the ones incorrectly classified by the NN classifier, the poor blacklisting results indicate that the blacklisting strategy, at least for these databases, is inadequate. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>Although the NN technique is accurate and useful, its spam precision performance is not high enough for it to be used without supervision. For this technique to be more useful, the feature set would require additional members or modifications. It should be noted, however, that the NN required fewer features to achieve results similar to the Naïve Bayesian approaches, indicating that descriptive qualities of words and messages, similar to those used by human readers, can be used effectively to distinguish spam by a classifier. As suggested in previous work <ref type="bibr" target="#b8">[9]</ref>, a combination of keywords and descriptive characteristics may provide more accurate classification. A neural network classifier using these descriptive features, however, may not degrade over time as rapidly as classifiers that rely upon a relatively static vocabulary from spammers. Strategies that apply a combination of techniques, such as a NN with a whitelist, would likely yield better results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>7 Binary</head><label>7</label><figDesc>feature indicating whether a priority header appeared within the message headers (X-Priority and/or X-MSMail-priority) or whether the priority had been set to any level besides normal or medium: yes = 1, no = 0 8 Binary feature indicating whether a content-type header appeared within the message headers or whether the content type of the message has been set to "text/html": yes = 1, no = 0 Features From the Message Body 9 Proportion (fraction) of alphabetic words with no vowels and at least seven characters 10 Proportion of alphabetic words that contained at least two of the following letters in upper or lower case: J, K, Q, X, Z 11 Proportion of alphabetic words that were at least 15 characters long 12 Binary feature indicating whether the white-space-delimited strings "From:" and "To:" were both present: 1 = yes, 0 = no 13 Number of HTML opening comment tags 14 Number of hyperlinks ("href=") 15 Number of clickable images represented in the HTML</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 . Features extracted from each e-mail.</head><label>1</label><figDesc></figDesc><table>Feature 
Features From the Message Subject Header 
1 
Number of alphabetic words that did not contain any vowels 

2 
Number of alphabetic words that contained at least two of the following 
letters (upper or lower case): J, K, Q, X, Z 
3 
Number of alphabetic words that were at least 15 characters long 

4 

Number of tokens that contained non-English characters, special charac-
ters such as punctuation, or numeric digits at the beginning or middle of 
the token. 
5 
Number of words with all alphabetic characters in upper case 

6 
Binary feature indicating occurrence of a character (including spaces) that 
is repeated at least three times in succession: yes = 1, no = 0 
Features From the Priority and Content-Type Headers 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 . Classification results on the testing set (n = 827).</head><label>2</label><figDesc></figDesc><table>Spam 
Legitimate 
Hidden 
Nodes 

Training 
Epochs 
Precision 
(%) 

Recall 
(%) 

Precision 
(%) 

Recall 
(%) 

300 
91.81 
86.65 
86.56 
91.75 

400 
90.95 
89.46 
88.94 
90.50 
8 

500 
93.73 
87.59 
87.62 
93.75 

300 
92.11 
90.16 
89.73 
91.75 

400 
91.09 
86.18 
86.05 
91.00 
10 

500 
92.48 
86.42 
86.45 
92.50 

300 
93.52 
87.82 
87.79 
93.50 

400 
91.73 
88.29 
87.98 
91.50 
12 

500 
92.45 
91.80 
91.32 
92.00 

300 
91.58 
84.07 
84.37 
91.75 

400 
92.04 
86.65 
86.59 
92.00 
14 

500 
91.28 
88.29 
87.92 
91.00 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 . Comparison results for NN and Naïve Bayesian classifiers.</head><label>3</label><figDesc></figDesc><table>Classifier 
Num 
Feat 

Num 
Msgs 

Spam 
(%) 

SP 
(%) 

SR 
(%) 

LP 
(%) 

LR 
(%) 

NN 
(12 nodes, 500 epochs) 
17 
827 
51.6 
92.5 
91.8 
91.3 
92.0 

Naïve Bayesian from [9] 3 
Words 
500 
1789 
88.2 
97.1 
94.3 
87.7 
93.4 
Words+Phrases 
500 
1789 
88.2 
97.6 
94.3 
87.8 
94.7 
Words+Phrases+Non-textual 
500 
1789 
88.2 
100.0 
98.3 
96.2 
100.0 

Naïve Bayesian from [1] 4 
Bare 
50 
1099 
43.8 
95.1 
84.0 
N/A 
N/A 
Stop-List 
50 
1099 
43.8 
96.8 
84.2 
N/A 
N/A 
Lemmatized 
100 
1099 
43.8 
98.3 
78.1 
N/A 
N/A 
Lemmatized + Stop List 
100 
1099 
43.8 
98.0 
79.6 
N/A 
N/A 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 4 . Blacklisting results for the e-mails incorrectly tagged by the NN classifier.</head><label>4</label><figDesc></figDesc><table>Blacklisting (% Considered Spam) 

Classification 
First IP Address 
(Original Address) 

Second IP Address 
(E-mail Server/ISP) 

Either First or Second 
IP Address 

n LS 

(32 E-mails) 
53.1 
25.0 
53.1 

n SL 

(35 E-mails) 
40.0 
60.0 
97.1 

</table></figure>

			<note place="foot" n="1"> The corpus utilized by [1] removed all HTML tags and attachments, and all header fields other than &quot;Subject:&quot; were removed for privacy reasons. 2 A token is a &quot;word&quot; separated by some predetermined delimiter (spaces, punctuation, HTML tags, etc.), and therefore a given token many not necessarily correspond to an actual word of written text. Examples from [5] include &quot;qvp0045&quot;, &quot;freeyankeedom&quot;, &quot;unsecured&quot;, and &quot;7c266675&quot;, among others. In [6], Graham argues that performance may be improved by providing separate case-sensitive entries for words in a hash table (such as &quot;FREE!!!&quot; and &quot;Free!!!&quot;), potentially magnifying the size of the probability table. The selection of delimiters and the effectiveness of scanning HTML tags for tokens are currently subjects of debate.</note>

			<note place="foot" n="3"> Sahami, et. al. [9] used three feature sets in their approach. The first used keywords, the second considered additional key phrases, and the last included non-textual attributes. In each case the most prevalent 500 attributes within the corpus were selected. 4 Androutsopoulos, et. al. [1] used a corpus from a moderated mailing list in a &quot;bare&quot; form and with three forms of alterations: a lemmatized version (which changed parts of speech, such as changing &quot;earned&quot; to &quot;earn&quot;), a version edited with a stop-list (which removed frequently used words), and a version using both the lemmatizer and a stop-list. The authors did not provide statistics for legitimate precision (LP) or legitimate recall (LR).</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An Experimental Comparison of Naive Bayesian and Keyword-Based Anti-Spam Filtering with Personal E-mail Messages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I;</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koutsias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">V</forename><surname>Chandrinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Spyropoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23 rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 23 rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Athens, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Burton</surname></persName>
		</author>
		<ptr target="http://spamprobe.sourceforge.net/paper.html" />
		<title level="m">SpamProbe -Bayesian Spam Filtering Tweaks</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">17</biblScope>
		</imprint>
	</monogr>
	<note>last accessed November</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Cranor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Lamacchia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Spam! Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="74" to="83" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Against a List of All Known DNS-based Spam Databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">P</forename><surname>Declude</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lookup</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A Plan for Spam</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Graham</surname></persName>
		</author>
		<ptr target="http://www.paulgraham.com/spam.html" />
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">17</biblScope>
		</imprint>
	</monogr>
	<note>last accessed November</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Better Bayesian Filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Graham</surname></persName>
		</author>
		<ptr target="http://spamconference.org/proceedings2003.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Spam Conference</title>
		<meeting>the 2003 Spam Conference<address><addrLine>Cambridge, Massachusetts</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Statistical Spam Filter Works for Me</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hauser</surname></persName>
		</author>
		<ptr target="http://www.sofbot.com/article/Statistical_spam_filter.html" />
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">17</biblScope>
		</imprint>
	</monogr>
	<note>last accessed November</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">S</forename><surname>Hauser</surname></persName>
		</author>
		<ptr target="http://www.sofbot.com/article/Spam_review.html" />
	</analytic>
	<monogr>
		<title level="j">Statistical Spam Filter Review</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>last accessed November</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Bayesian Approach to Filtering Junk E-mail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sahami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<idno>WS-98-05</idno>
	</analytic>
	<monogr>
		<title level="m">Learning for Text Categorization-Papers from the AAAI Workshop</title>
		<meeting><address><addrLine>Madison, Wisconsin</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="55" to="62" />
		</imprint>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning in Automatic Text Categorization. ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Smokey: Automatic Recognition of Hostile Messages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Spertus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14 th National Conference on AI and the 9 th Conference on Innovative Applications of AI</title>
		<meeting>the 14 th National Conference on AI and the 9 th Conference on Innovative Applications of AI<address><addrLine>Providence, Rhode Island</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="1058" to="1065" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Ending Spam&apos;s Free Ride</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">netWorker</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="18" to="24" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
