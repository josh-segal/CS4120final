<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T17:06+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Mean Field Inference in Dependency Networks: An Empirical Study</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Lowd</surname></persName>
							<email>lowd@cs.uoregon.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Information Science</orgName>
								<orgName type="institution">University of Oregon Eugene</orgName>
								<address>
									<postCode>97403</postCode>
									<region>OR</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Shamaei</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Information Science</orgName>
								<orgName type="institution">University of Oregon Eugene</orgName>
								<address>
									<postCode>97403</postCode>
									<region>OR</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Mean Field Inference in Dependency Networks: An Empirical Study</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Dependency networks are a compelling alternative to Bayesian networks for learning joint probability distributions from data and using them to compute probabilities. A dependency network consists of a set of conditional probability distributions, each representing the probability of a single variable given its Markov blanket. Running Gibbs sampling with these conditional distributions produces a joint distribution that can be used to answer queries, but suffers from the traditional slowness of sampling-based inference. In this paper , we observe that the mean field update equation can be applied to dependency networks, even though the conditional probability distributions may be inconsistent with each other. In experiments with learning and inference on 12 datasets, we demonstrate that mean field inference in dependency networks offers similar accuracy to Gibbs sampling but with orders of magnitude improvements in speed. Compared to Bayesian networks learned on the same data, dependency networks offer higher accuracy at greater amounts of evidence. Furthermore, mean field inference is consistently more accurate in dependency networks than in Bayesian networks learned on the same data.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>In many domains, including recommender systems, fault diagnosis, and medicine, we wish to learn a joint probability distribution from data and use it to compute the probabilities of various events. The learning and inference tasks are often treated separately, but it is their combination that determines the overall accuracy of a system. A standard approach is to learn a probabilistic graphical model, such as a Bayesian or Markov network, and answer queries using an approximate inference algorithm, such as mean field inference or Gibbs sampling <ref type="bibr">(Gilks, Richardson, and Spiegelhal- ter 1996)</ref>. These methods have been largely successful, but have several limitations. For Bayesian networks, the need to avoid cycles significantly restricts the set of probability distributions that can be compactly represented. Undirected models such as Markov networks are somewhat more flexible, but suffer from computationally expensive weight learning and structure learning.</p><p>Dependency networks are an often overlooked alternative that combine some of the best qualities of Bayesian Copyright c 2011, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. and Markov networks. Like Bayesian networks, dependency networks can be learned efficiently from data. Like Markov networks, they can represent many symmetric and cyclical dependencies more compactly than a Bayesian network. For these reasons, dependency networks have been successfully applied to tasks such as collaborative filtering <ref type="bibr">(Heck- erman et al. 2000)</ref> and part-of-speech tagging ( <ref type="bibr" target="#b21">Toutanova et al. 2003)</ref>. A relational extension of dependency networks has also been successfully applied to domains such as fraud detection <ref type="bibr" target="#b18">(Neville and Jensen 2007)</ref> and entity resolution ( <ref type="bibr" target="#b17">Natarajan et al. 2010</ref>).</p><p>However, dependency networks are traditionally limited to a single inference algorithm -Gibbs sampling -which may be slow to run and may produce different results depending on the order in which variables are sampled. This arises from the fact that the conditional probability distributions which comprise a dependency network are often inconsistent with each other, leading to a poorly-specified joint probability distribution. This disadvantage has led dependency networks to be largely ignored in favor of Bayesian and Markov networks, which have clearer semantics.</p><p>In this paper, we show that an approximate version of the mean field inference algorithm can be applied to dependency networks, in spite of the fact that the conditional distributions in a dependency network may be inconsistent. We find that mean field inference typically converges much faster than Gibbs sampling and offers similar accuracy.</p><p>We then compare the speed and accuracy of learning and inference in dependency networks to Bayesian networks, by learning and evaluating both models on 12 publicly available datasets. We find that learning times are similar, but dependency networks have consistently better test set pseudolikelihood. In our queries, mean field runs faster in dependency networks than in Bayesian networks while producing consistently more accurate results. When we run Gibbs sampling in both models, their relative accuracy depends on the amount of evidence. On queries with more evidence, dependency networks are more accurate; with less evidence, Bayesian networks are more accurate. However, the differences in probabilities are typically very small. This means that dependency networks are a good choice for many applications, especially when queries will involve a large amount of evidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bayesian Networks</head><p>Let X be a set of random variables {X 1 , X 2 , . . . , X n }. A Bayesian network (BN) <ref type="bibr" target="#b19">(Pearl 1988</ref>) represents a probability distribution over X , P (X ), using a directed, acyclic graph and a set of conditional probability distributions (CPDs). The graph contains one node for each variable X i . Each CPD P (X i |Π i ) specifies the probability of a single variable (X i ) given its parents in the graph (Π i ). The product of these CPDs gives the full joint probability distribution:</p><formula xml:id="formula_0">P (X = x) = i P (X i = x i |Π i = π i )<label>(1)</label></formula><p>Bayesian networks and other graphical models can be defined over both discrete and continuous variables. For this paper, we restrict our attention to discrete variables, although many of the methods can be naturally applied to the continuous and hybrid cases as well.</p><p>The Markov blanket of a variable X i , denoted MB(X i ), is the set of variables that render X i independent from all other variables in the domain. In a Bayesian network, this set consists of X i 's parents in the graph, X i 's children, and all variables that have a child in common with X i . These independencies, and others, are entailed by the CPD factorization from Equation 1.</p><p>The simplest form for a CPD is a full table that specifies the distribution of the child variable, X i , given each configuration of its parent variables, Π i . However, this representation is exponential in the number of parent variables, effectively limiting the maximum number of parents to a small number.</p><p>A more efficient and flexible alternative is to represent conditional probabilities with probabilistic decision trees <ref type="bibr" target="#b2">(Chickering, Heckerman, and Meek 1997)</ref>. A decision tree is a directed, rooted tree, in which each leaf contains a distribution over the target variable X i . Each interior node is labeled with one of X i 's parents, X j ∈ Π i , and each outgoing arc from this node is labeled with one or more values of the parent variable, x j ∈ Val(X j ). The distribution at a leaf gives the conditional probability of X i given the configurations of parent variables specified along the path from the leaf to the root of the tree.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BN Inference</head><p>To answer queries, we use the BN to compute marginal and conditional probabilities. Since exact inference in a BN is #P-complete (Roth 1996), approximation algorithms are typically necessary. Popular approximate inference algorithms include Markov chain Monte Carlo methods, such as Gibbs sampling; variational approximations such as mean field (MF); and loopy belief propagation (BP).</p><p>Gibbs sampling proceeds by initializing the query variables randomly and then resampling each in turn, according to its conditional probability given its Markov blanket. Evidence variables remain fixed to their set values. The probability of a particular query is computed as the fraction of the samples that match the query. For positive distributions (i.e., all configurations have non-zero probability), Gibbs sampling is guaranteed to eventually converge to the correct distribution. However, this can take a very long time, and convergence can be difficult to detect.</p><p>Sampling methods can often be improved by using Rao-Blackwellization, in which some of the variables are marginalized analytically. One way to apply RaoBlackwellization to Gibbs sampling is to add fractional counts to the different states that could result from resampling the current variable, based on their relative probabilities. Then the variable is randomly assigned a single value, as in regular Gibbs sampling. These fractional counts can lead to a significant reduction in variance.</p><p>Belief propagation (BP) is an exact inference algorithm for tree-structured Bayesian and Markov networks. Loopy belief propagation is the application of the belief propagation algorithm to graphs with cycles (Murphy, Weiss, and Jordan 1999). We use the flooding message propagation scheme in our experiments, which sends messages from variables to CPDs and then CPDs to variables in each iteration, as described by <ref type="bibr" target="#b12">Kschischang et al. (2001)</ref>.</p><p>We defer a full description of mean field inference to the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BN Learning</head><p>The objective of parameter learning is to select a set of model parameters (CPD probabilities) that maximize a particular objective function on the training data. For Bayesian networks, the most common objective function is loglikelihood, penalized by a prior distribution on each conditional distribution. We used the Beta(1,1) distribution as the prior in all of our experiments, which is equivalent to Laplace smoothing. In this case, parameter estimation can be done in closed form from the sufficient statistics of the training data.</p><p>In structure learning, the objective is to find the structure that maximize an objective function such as the Bayesian score <ref type="bibr" target="#b10">(Heckerman, Geiger, and Chickering 1995)</ref>. Finding the optimal structure is NP-hard <ref type="bibr" target="#b3">(Chickering, Heckerman, and Meek 2004</ref>), but greedy search typically works well in practice. A common approach is to do hill climbing with random restarts, where the search operators include adding, deleting, and reversing arcs. For decision tree CPDs, the search operators consist of adding a split to a tree CPD, which replaces a decision tree leaf node with a new interior node that has leaves as its children <ref type="bibr" target="#b2">(Chickering, Heckerman, and Meek 1997)</ref>. Operations that would lead to a cycle in the BN are excluded from the search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dependency Networks</head><p>A dependency network (DN) <ref type="bibr" target="#b9">(Heckerman et al. 2000)</ref> consists of a set of conditional probability distributions P i (X i |MB(X i )), each defining the probability of a single variable given its Markov blanket. These conditional distributions may or may not be consistent with each other. The graph of a DN is directed, with a node for each variable in the domain. For each variable X i , there are edges from the nodes representing variables in X i 's Markov blanket to the node representing X i .</p><p>Unlike a BN, the product of all CPDs gives the pseudolikelihood of an instance, P * , not its probability:</p><formula xml:id="formula_1">P * (X ) = i P i (X i |MB(X i ))<label>(2)</label></formula><p>Pseudo-likelihood <ref type="bibr" target="#b1">(Besag 1975</ref>) is a consistent estimator commonly used for learning the parameters of Markov networks, since its local approach to normalization avoids the intractability of partition function. However, pseudolikelihood learning tends to produce models that handle long-range dependencies poorly. The joint distribution of a DN is defined as the stationary distribution of a Gibbs sampler run by using its CPDs for the required Markov blanket distributions, P i (X i |MB(X i )). <ref type="bibr" target="#b9">Heckerman et al. (2000)</ref> also describe a second method for computing probabilities in which the probability of each variable is computed in turn using the Gibbs sampler, conditioned on the states of previous variables. This reduces the variance when computing rare joint probabilities with sampling, and is theoretically equivalent. <ref type="bibr" target="#b21">Toutanova et al. (2003)</ref> adapt the Viterbi algorithm to perform MAP inference in a chain-structured DN. To our knowledge, no other inference algorithms have ever been applied to DNs.</p><p>A dependency network can be constructed from any Bayesian or Markov network by constructing a conditional probability distribution for each variable given its Markov blanket. A DN can also be learned from data by the same methods used to learn a BN with tree-structured CPDs, except without enforcing acyclicity. This makes DN learning trivial to parallelize with a separate process for each variable.</p><p>However, when learned from data, the resulting CPDs may be inconsistent with each other. Heckerman et al. refer to this as a "general dependency network." Given a particular sampling order, a Gibbs sampler will still have a unique stationary distribution when the distribution is positive (all probabilities are non-zero). However, the stationary distribution may depend on the ordering chosen. Furthermore, the joint distribution determined by the Gibbs sampler may be inconsistent with the conditional probabilities asserted by the CPDs. When learned from data, DNs tend to roughly approximate consistency, since each CPD is approximating the same empirical distribution of the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean Field Inference in Dependency Networks</head><p>Mean field inference (MF) approximates an intractable distribution P with a fully factorized distribution Q:</p><formula xml:id="formula_2">Q(X ) = i Q(X i )<label>(3)</label></formula><p>Q is selected to be as close as possible to the desired distribution P , where distance 1 is measured as the Kullback-Leibler (KL) divergence between Q and P :</p><formula xml:id="formula_3">KL(Q P ) = X Q(X) log Q(X) P (X)<label>(4)</label></formula><formula xml:id="formula_4">= E X∼Q log Q(X) P (X)<label>(5)</label></formula><p>By deriving the fixed point equations for MF, it can be shown that every local optimum of the KL divergence satisfies the following equation for every marginal in the Q distribution:</p><formula xml:id="formula_5">Q(X i ) = 1 Z i exp E X \{Xi}∼Q [log P (X i |X \ {X i })]<label>(6)</label></formula><p>where Z i is a normalizing constant. This can be interpreted as setting Q(X i ) to match the expectation of X i in log space, where the expectation is computed according to the distribution of the remaining variables in Q. By using this equation to iteratively update each Q(X i ) marginal in turn, the KL divergence can be shown to decrease in each iteration until a local minimum is reached. A common ordering for the Q updates is to use a queue, so that after Q(X i ) is updated, the neighbors of X i are added to the end of the queue if not already in it. This continues until convergence.</p><p>These updates were derived by <ref type="bibr" target="#b8">Haft et al. (1999)</ref>. They additionally observed that, since these equations only depend on P through the conditional distributions P (X i |X \ {X i }) (or more specifically, P (X i |MB(X i )), since the Markov blanket renders all other variables independent), they could be used to define MF update equations for any representation. However, Haft et al. did not apply these equations to dependency networks where the conditional distributions could be inconsistent.</p><p>Algorithm 1 contains pseudo-code for mean field inference in dependency networks. It is similar to Algorithm 11.7 from <ref type="bibr" target="#b11">Koller and Friedman (2009)</ref>, but with three modifications. The main change is line 8, which uses the conditional distributions P i (X i |MB(X i )) to perform the update from Equation 6. This makes the algorithm applicable to dependency networks, whether or not their conditional distributions are consistent. The algorithm also features a maximum number of iterations, MaxIters, so that the algorithm will halt early if convergence is slow. In our experiments, we set this to 50 times the number of non-evidence variables. Mean field almost always converged in fewer iterations. When we increased the maximum number of iterations, it always converged. The second modification is to set a convergence threshold, , on the distance between the old and new marginals. In our experiments, we used a Euclidean distance of 0.0001 as the threshold. Algorithm 1 can be made equivalent to the standard mean field inference algorithm on a Bayesian or Markov network by setting to zero, NumIters to infinity, and each P i to the Markov blanket distribution of X i given its neighbors in the Bayesian or Markov network.</p><p>In a consistent DN, MF will always converge to a local minimum of the KL divergence, as in any other graphical model. With inconsistent CPDs and determinism, it is easy to produce oscillations. Given two binary variables A and Algorithm 1 Mean field inference for dependency networks 1: Q ← Q 0 2: Iters ← 0 3: Unprocessed ← X 4: while Unprocessed = ∅ and Iters &lt; MaxIters do</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Choose X i from Unprocessed 6:</p><formula xml:id="formula_6">Q old (X i ) ← Q(X i ) 7:</formula><p>for x i ∈ V al(X i ) do 8:</p><formula xml:id="formula_7">Q(x i ) ← exp{E MB(Xi)∼Q [log P i (X i |MB(X i )]} 9:</formula><p>end for 10:</p><p>Normalize Q(X i ) to sum to one <ref type="bibr">11:</ref> if Q old (X i ) − Q(X i ) &gt; then</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>12:</head><p>Unprocessed ← Unprocessed ∪ MB(X i )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>13:</head><p>end if</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>14:</head><p>Unprocessed ← Unprocessed -X i</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>15:</head><p>Iters ← Iters +1 16: end while B, let P (A|B) = 1 when A = B and P (B|A) = 1 when B = A. MF run in this DN will oscillate forever unless initialized to the fixed point Q(A) = Q(B) = 0.5. With positive CPDs, where no probabilities are 1 or 0, it remains unknown if convergence is always guaranteed. MF converged in our experiments, but we do not know if this is always the case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>In our experiments, we sought to evaluate the relative effectiveness of different learning and inference schemes on realworld data. We were particularly interested in how MF compares to the standard approach of Gibbs sampling in DNs, both in speed and accuracy. Furthermore, since BNs are an alternative to DNs, we felt it was important to benchmark our results against standard BN learning and inference methods. If BNs can produce more accurate answers than DNs in less time, then the case for using DNs is relatively weak.</p><p>We ran our experiments on 12 publicly available datasets collected and prepared by <ref type="bibr" target="#b5">Davis and Domingos (2010)</ref> and also used by <ref type="bibr" target="#b14">Lowd and Davis (2010)</ref> for evaluating Markov network structure learning algorithms. We excluded the EachMovie dataset, since it is no longer publicly available. All variables are binary-valued. The datasets vary widely in size and number of variables. See <ref type="table" target="#tab_0">Table 1</ref> for a summary, and <ref type="bibr" target="#b5">Davis and Domingos (2010)</ref> for more details on their origin. Datasets are listed in increasing order by number of variables.</p><p>We learned DNs and BNs with tree CPDs using the WinMine toolkit <ref type="bibr" target="#b4">(Chickering 2002)</ref>, which is based on the algorithms of <ref type="bibr" target="#b2">Chickering et al. (1997)</ref> and <ref type="bibr" target="#b9">Heckerman et al. (2000)</ref>. <ref type="bibr">2</ref> WinMine uses a structure prior that penalizes models based on the number of parameters: where s is the number of parameters in the model. To avoid overfitting, we tuned the κ parameter on the tune set. We evaluated on test data. We ran inference using a Rao-Blackwellized Gibbs sampler, with 100 burn-in iterations and 1000 sampling iterations. We experimented with running the Gibbs sampler for ten times as long, but found that additional iterations produced little benefit on most of our datasets. We also ran mean field and belief propagation. All inference algorithms were implemented in the open-source Libra Toolkit. <ref type="bibr">3</ref> We use DN.Gibbs and DN.MF to refer to Gibbs sampling and mean field in a learned dependency network, respectively; and BN.Gibbs, BN.MF, and BN.BP to refer to Gibbs sampling, mean field, and belief propagation in a learned Bayesian network, respectively.</p><formula xml:id="formula_8">P (S) ∝ κ s<label>(7)</label></formula><p>All inference algorithms are evaluated using test set conditional marginal log-likelihood (CMLL), a common evaluation metric <ref type="bibr" target="#b13">(Lee, Ganapathi, and Koller 2007;</ref><ref type="bibr" target="#b5">Davis and Domingos 2010)</ref>. The CMLL represents the expected log loss of the query variable marginals, given the evidence variables:</p><formula xml:id="formula_9">CM LL(X = x) = 1 |X Q | Xi∈X Q log P (X i = x i |X E = x e ) (8)</formula><p>where X Q is the set of query variables, X E is the set of evidence variables, and x e denotes the configuration of the evidence variables in the example. Unlike Davis and Domingos (2010), we randomly select a separate set of query and evidence variables for each instance in the test set. The fraction of evidence variables ranges from 10% to 90% of the total variables in the domain, by 10% increments. All other variables are used as query variables. In order to reduce the variance among results with different amounts of evidence, the evidence variables in each query at 10% evidence are a subset of those at 20% evidence, which are a subset of those at 30% evidence, and so on. This makes our queries at different levels of evidence more similar, while remaining unbiased. <ref type="table" target="#tab_2">Table 2</ref>: Learning time (in seconds), complexity (number of parameters), test set pseudo-log-likelihood (PLL), and test set log-likelihood (LL) of learned models. Reported error range is one standard deviation of the mean. Standard errors of less than 0.0005 are reported as 0.000. When differences in PLL or LL are statistically significant, the better result is in bold.  For pseudo-log-likelihood, DNs are significantly better on 10 out of 12 datasets according to a paired t-test (p &lt; 0.05). MSWeb is the only dataset where BNs perform better. The better pseudo-likelihood of DNs in this experiment is the consequence of the fact that DNs effectively optimize pseudo-likelihood while learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dependency</head><p>We used Algorithm 1 from Heckerman et. al <ref type="bibr" target="#b9">(Heckerman et al. 2000</ref>) to approximate the log-likelihood in dependency networks. Since this is a very slow sampling-based algorithm, we used only 40% of the test data. Log-likelihood for the BNs was computed exactly on the same subset. DNs are significantly better on 3 datasets and BNs are significantly better on 4, according to a paired t-test (p &lt; 0.05). We expected BNs to do better, since they are directly optimizing log-likelihood, but DNs were surprisingly competitive.</p><p>We then ran multiple inference algorithms on all data sets to evaluate the accuracy of the different models and algorithms in answering conditional queries. <ref type="figure">Figure 1</ref> shows the per-variable CMLL for each data set, averaged over all amounts of evidence (10% to 90%). With the exception of BN.MF, all algorithms have very similar accuracies. BN.BP, BN.Gibbs, and DN.Gibbs tend to be slightly more accurate than DN.MF. On every dataset, DN.MF is more accurate than BN.MF. Whether DN.Gibbs is more accurate than BN.Gibbs depends on the dataset. Overall, the accuracy of DN.MF is superior to BN.MF and comparable to other inference algorithms. <ref type="figure">Figure 2</ref> depicts the average inference time for each data set, averaged over all amounts of evidence. For inference time, the MF methods are the fastest, often 1-2 orders of magnitude faster than the other methods. In addition, DN.MF is faster than BN.MF in 10 data sets out of 12.</p><p>To tease apart the differences between DNs and BNs, we looked at wins and losses by amount of evidence.  <ref type="table" target="#tab_2">Table 2</ref>), since PLL conditions on the most evidence possible: all other variables. Since Gibbs sampling is an anytime algorithm, we can force it to match the speed of mean field. <ref type="table" target="#tab_6">Table 4</ref>    probabilities inferred by DN.MF and all other methods. We chose root mean squared difference as our metric, since it penalizes large differences more than small differences. For 10 out of 12 datasets, the root mean squared difference between DN.MF and the other methods was less than 0.005. Between DN.MF and BN.Gibbs, the root mean squared difference was less than 0.001 on half of the datasets. Between DN.MF and DN.Gibbs, the root mean squared difference was less than 0.0005 on 9 datasets. This supports the hypothesis that all methods produce similar results. In particular, MF and Gibbs sampling give very similar probabilities in dependency networks. Source code and additional results are available in the online appendix at http://ix.cs.uoregon.edu/ ∼ lowd/dnmf.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>Mean field inference in DNs offers similar accuracy to Gibbs sampling but in significantly less time. It is also consistently more accurate than running mean field inference in a BN learned on the same data. When we compare to other BN inference algorithms as well, we find that DNs are more accurate when more evidence is available. Therefore, although BNs remain a good choice for many applications of statistical learning and inference, DNs are a compelling alternative.</p><p>In future work, we intend to apply mean field to relational dependency networks <ref type="bibr" target="#b18">(Neville and Jensen 2007)</ref>. In relational domains such as social network analysis, networks are typically cyclical and large-scale, making dependency networks with mean field inference a natural choice over directed models or Gibbs sampling.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: Per-variable CMLL for each dataset, averaged over all amounts of evidence. Shorter bars are better.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 : Data Set Characteristics</head><label>1</label><figDesc></figDesc><table>Data Set 
Train 
Tune 
Test Num. 
Set 
Set 
Set 
Vars. 
Size 
Size 
Size 
NLTCS 
16,181 
2,157 
3,236 
16 
MSNBC 
291,326 38,843 58,265 
17 
KDDCup 2000 
180,092 19,907 34,955 
64 
Plants 
17,412 
2,321 
3,482 
69 
Audio 
15,000 
2,000 
3,000 
100 
Jester 
9,000 
1,000 
4,116 
100 
Netflix 
15,000 
2,000 
3,000 
100 
MSWeb 
29,441 
3,270 
5,000 
294 
Book 
8,700 
1,159 
1,739 
500 
WebKB 
2,803 
558 
838 
839 
Reuters-52 
6,532 
1,028 
1,540 
889 
20 Newsgroups 
11,293 
3,764 
3,764 
910 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 summarizes</head><label>2</label><figDesc>the BN and DN models learned on each dataset. Learning DNs is faster than learning BNs in 7 out of 12 datasets. Therefore, DN learning time is at least comparable to BNs.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Number and fraction of datasets on which 
DN.Gibbs and DN.MF are more accurate than BN.Gibbs 
and BN.BP, respectively. 

DN.G 
DN.MF 
Evidence vs. BN.G Percent vs. BN.BP Percent 
10% 
3 
25% 
1 
8% 
20% 
1 
8% 
1 
8% 
30% 
1 
8% 
1 
8% 
40% 
3 
25% 
3 
25% 
50% 
5 
42% 
5 
42% 
60% 
7 
58% 
8 
67% 
70% 
10 
83% 
9 
75% 
80% 
10 
83% 
10 
83% 
90% 
11 
92% 
11 
92% 
Total 
51 
47% 
39 
36% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 compares</head><label>3</label><figDesc></figDesc><table>DN.Gibbs to BN.Gibbs and DN.MF to BN.BP, 
respectively. We chose to compare DN.MF to BN.BP here 
because BN.MF is consistently less accurate, and BN.BP is 
also an iterative message-passing algorithm. Many of these 
wins and losses are by very small amounts, but the trends are 
still informative. At greater amounts of evidence, DNs are 
increasingly accurate relative to BNs. This can be explained 
by the fact that DNs are optimizing a conditional measure 
when learned, while BNs are optimizing the overall likeli-
hood. This is also consistent with DNs having better PLL 
values than BNs (see </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head></head><label></label><figDesc>shows the results of running Gibbs sampling in either DNs or BNs with the same amount of time required by DN.MF to converge. In most cases Gibbs sampling is less accurate, since DN.MF converges much faster than Gibbs. In total, DN.MF wins 85% of the time compared to DN.Gibbs and 79% of the time compared to BN.</figDesc><table>Gibbs. 
Finally, we measured the difference between the marginal 

!"#$% 

&amp;%!'$ 
())$*+,-... 

/01234 
5*678 

!93:07; 
&lt;9439= 

&amp;%&gt;9? 
'88@ 

&gt;9?(' 
A9*39=4BC-

-.,!9D4E=8*+4 

B.FG 

B.FC 

B.FH 

B.FI 

B.F-

B.FJ 

. 

5K9=1E9,$&amp;"" 

)!F&amp;L 
'!F&amp;L 
)!FM7??4 
'!FM7??4 
'!F'/ 

)131,%93 

$&amp;"" 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Number and fraction of datasets in which DN.MF 
is more accurate than DN.Gibbs and BN.Gibbs when run for 
the same amount of time. 

DN.Gibbs 
BN.Gibbs 
Evidence MF Wins Percent MF Wins Percent 
10% 
9 
75% 
7 
58% 
20% 
10 
83% 
6 
50% 
30% 
10 
83% 
6 
50% 
40% 
9 
75% 
10 
83% 
50% 
10 
83% 
10 
83% 
60% 
10 
83% 
11 
92% 
70% 
11 
92% 
11 
92% 
80% 
11 
92% 
12 
100% 
90% 
12 
100% 
12 
100% 
Total 
92 
85% 
85 
79% 

</table></figure>

			<note place="foot" n="1"> We use the term &quot;distance&quot; informally. KL divergence is not symmetric, and therefore not a metric.</note>

			<note place="foot" n="2"> We also experimented with BNs with table CPDs, but found their performance to be similar to BNs with tree CPDs. For brevity, we only present the tree CPD results in this paper.</note>

			<note place="foot" n="3"> The Libra Toolkit is available from http://libra.cs.uoregon.edu</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Jesse Davis, Chloé Kiddon, and Aniruddh Nath for feedback on earlier drafts of this paper, and Christopher Meek for helpful discussions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<idno>27.1 4018 -0.032 ± 0.000 -0.034 ± 0.001 12.3 577 -0.033 ± 0.000 -0.034 ± 0.001</idno>
		<title level="m">KDDCup</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Statistical analysis of non-lattice data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>References Besag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Statistician</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="179" to="195" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Bayesian approach to learning Bayesian networks with local structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chickering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the Thirteenth Conference on Uncertainty in Artificial Intelligence<address><addrLine>Providence, RI</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="80" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Largesample learning of Bayesian networks is NP-hard</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chickering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1287" to="1330" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The WinMine toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Chickering</surname></persName>
		</author>
		<idno>MSR-TR-2002-103</idno>
		<imprint>
			<date type="published" when="2002" />
			<pubPlace>Microsoft, Redmond, WA</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Bottom-up learning of Markov network structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Domingos</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the TwentySeventh International Conference on Machine Learning</title>
		<meeting>the TwentySeventh International Conference on Machine Learning<address><addrLine>Haifa, Israel</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Gilks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Spiegelhalter</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Markov Chain Monte Carlo in Practice</title>
		<imprint>
			<publisher>Chapman and Hall</publisher>
			<pubPlace>London, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Modelindependent mean field theory as a local method for approximate propagation of information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Haft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computation in Neural Systems</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="93" to="105" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dependency networks for inference, collaborative filtering, and data visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Chickering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rounthwaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kadie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="49" to="75" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning Bayesian networks: The combination of knowledge and statistical data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Chickering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="197" to="243" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Probabilistic Graphical Models: Principles and Techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Factor graphs and the sum-product algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Kschischang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-A</forename><surname>Loeliger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="498" to="519" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient structure learning of Markov networks using L1-regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-I</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ganapathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="817" to="824" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning Markov network structure with decision trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lowd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davis</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th IEEE International Conference on Data Mining (ICDM)</title>
		<meeting>the 10th IEEE International Conference on Data Mining (ICDM)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Australia</forename><surname>Sydney</surname></persName>
		</author>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Loopy belief propagation for approximate inference: An empirical study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence</title>
		<editor>Morgan Kaufmann</editor>
		<meeting>the Fifteenth Conference on Uncertainty in Artificial Intelligence<address><addrLine>Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Boosting relational dependency networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kersting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shavlik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twentieth International Conference on Inductive Logic Programming</title>
		<meeting>the Twentieth International Conference on Inductive Logic Programming<address><addrLine>Firenze, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Relational dependency networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Neville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jensen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On the hardness of approximate reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="273" to="302" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Feature-rich part-of-speech tagging with a cyclic dependency network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the 2003 Human Language Technology Conference and North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="173" to="180" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
