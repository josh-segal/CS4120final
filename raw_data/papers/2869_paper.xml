<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Prototype-Driven Grammar Induction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
							<email>aria42@cs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Division</orgName>
								<orgName type="department" key="dep2">Computer Science Division</orgName>
								<orgName type="institution" key="instit1">University of California Berkeley</orgName>
								<orgName type="institution" key="instit2">University of California Berkeley</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
							<email>klein@cs.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Division</orgName>
								<orgName type="department" key="dep2">Computer Science Division</orgName>
								<orgName type="institution" key="instit1">University of California Berkeley</orgName>
								<orgName type="institution" key="instit2">University of California Berkeley</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Prototype-Driven Grammar Induction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We investigate prototype-driven learning for primarily unsupervised grammar induction. Prior knowledge is specified declaratively, by providing a few canonical examples of each target phrase type. This sparse prototype information is then propagated across a corpus using distributional similarity features, which augment an otherwise standard PCFG model. We show that distributional features are effective at distinguishing bracket labels, but not determining bracket locations. To improve the quality of the induced trees, we combine our PCFG induction with the CCM model of Klein and Manning (2002), which has complementary stengths: it identifies brackets but does not label them. Using only a handful of prototypes, we show substantial improvements over naive PCFG induction for English and Chinese grammar induction.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>There has been a great deal of work on unsupervised grammar induction, with motivations ranging from scientific interest in language acquisition to engineering interest in parser construction <ref type="bibr" target="#b1">(Carroll and Charniak, 1992;</ref><ref type="bibr" target="#b3">Clark, 2001)</ref>. Recent work has successfully induced unlabeled grammatical structure, but has not successfully learned labeled tree structure ( <ref type="bibr" target="#b8">Klein and Manning, 2002;</ref><ref type="bibr" target="#b9">Klein and Manning, 2004;</ref><ref type="bibr">Smith and Eis- ner, 2004</ref>) .</p><p>In this paper, our goal is to build a system capable of producing labeled parses in a target grammar with as little total effort as possible. We investigate a prototype-driven approach to grammar induction, in which one supplies canonical examples of each target concept. For example, we might specify that we are interested in trees which use the symbol NP and then list several examples of prototypical NPs (determiner noun, pronouns, etc., see <ref type="figure">figure 1</ref> for a sample prototype list). This prototype information is similar to specifying an annotation scheme, which even human annotators must be provided before they can begin the construction of a treebank. In principle, prototypedriven learning is just a kind of semi-supervised learning. However, in practice, the information we provide is on the order of dozens of total seed instances, instead of a handful of fully parsed trees, and is of a different nature.</p><p>The prototype-driven approach has three strengths. First, since we provide a set of target symbols, we can evaluate induced trees using standard labeled parsing metrics, rather than the far more forgiving unlabeled metrics described in, for example, <ref type="bibr" target="#b9">Klein and Manning (2004)</ref>. Second, knowledge is declaratively specified in an interpretable way (see <ref type="figure">figure 1</ref>). If a user of the system is unhappy with its systematic behavior, they can alter it by altering the prototype information (see section 7.1 for examples). Third, and related to the first two, one does not confuse the ability of the system to learn a consistent grammar with its ability to learn the grammar a user has in mind.</p><p>In this paper, we present a series of experiments in the induction of labeled context-free trees using a combination of unlabeled data and sparse prototypes. We first affirm the well-known result that simple, unconstrained PCFG induction produces grammars of poor quality as measured against treebank structures. We then augment a PCFG with prototype features, and show that these features, when propagated to non-prototype sequences using distributional similarity, are effective at learning bracket labels on fixed unlabeled trees, but are still not enough to learn good tree structures without bracketing information. Finally, we intersect the feature-augmented PCFG with the CCM model of <ref type="bibr" target="#b8">Klein and Manning (2002)</ref>, a highquality bracketing model. The intersected model is able to learn trees with higher unlabeled F 1 than those in <ref type="bibr" target="#b9">Klein and Manning (2004)</ref>. More importantly, its trees are labeled and can be evaluated according to labeled metrics. Against the English Penn Treebank, our final trees achieve a labeled F 1 of 65.1 on short sentences, a 51.7% error reduction over naive PCFG induction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Experimental Setup</head><p>The majority of our experiments induced tree structures from the WSJ section of the English Penn treebank <ref type="bibr" target="#b13">(Marcus et al., 1994)</ref>, though see section 7.4 for an experiment on Chinese. To facilitate comparison with previous work, we extracted WSJ-10, the 7,422 sentences which contain 10 or fewer words after the removal of punctuation and null elements according to the scheme detailed in <ref type="bibr" target="#b10">Klein (2005)</ref>. We learned models on all or part of this data and compared their predictions to the manually annotated treebank trees for the sentences on which the model was trained. As in previous work, we begin with the part-of-speech (POS) tag sequences for each sentence rather than lexical sequences <ref type="bibr" target="#b1">(Carroll and Charniak, 1992;</ref><ref type="bibr" target="#b8">Klein and Manning, 2002)</ref>. Following <ref type="bibr" target="#b9">Klein and Manning (2004)</ref>, we report unlabeled bracket precision, recall, and F 1 . Note that according to their metric, brackets of size 1 are omitted from the evaluation. Unlike that work, all of our induction methods produce trees labeled with symbols which are identified with treebank categories. Therefore, we also report labeled precision, recall, and F 1 , still ignoring brackets of size 1. <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments in PCFG induction</head><p>As an initial experiment, we used the insideoutside algorithm to induce a PCFG in the straightforward way <ref type="bibr" target="#b11">(Lari and Young, 1990;</ref><ref type="bibr">Man- ning and Schütze, 1999</ref>). For all the experiments in this paper, we considered binary PCFGs over the nonterminals and terminals occuring in WSJ-10. The PCFG rules were of the following forms:</p><p>• X → Y Z, for nonterminal types X, Y, and Z, with Y = X or Z = X • X → t Y , X → Y t, for each terminal t • X → t t , for terminals t and t For a given sentence S, our CFG generates labeled trees T over S. <ref type="bibr">2</ref> Each tree consists of binary productions X(i, j) → α over constituent spans <ref type="bibr">(i, j)</ref>, where α is a pair of non-terminal and/or terminal symbols in the grammar. The generative probability of a tree T for S is:</p><formula xml:id="formula_0">P CF G (T, S) = X(i,j)→α∈T P (α|X)</formula><p>In the inside-outside algorithm, we iteratively compute posterior expectations over production occurences at each training span, then use those expectations to re-estimate production probabilities. This process is guaranteed to converge to a local extremum of the data likelihood, but initial production probability estimates greatly influence the final grammar <ref type="bibr" target="#b1">(Carroll and Charniak, 1992</ref>). In particular, uniform initial estimates are an (unstable) fixed point. The classic approach is to add a small amount of random noise to the initial probabilities in order to break the symmetry between grammar symbols.</p><p>We randomly initialized 5 grammars using treebank non-terminals and trained each to convergence on the first 2000 sentences of WSJ-10. Viterbi parses were extracted for each of these 2000 sentences according to each grammar. Of course, the parses' symbols have nothing to anchor them to our intended treebank symbols. That is, an NP in one of these grammars may correspond to the target symbol VP, or may not correspond well to any target symbol. To evaluate these learned grammars, we must map the models' phrase types to target phrase types. For each grammar, we followed the common approach of greedily mapping model symbols to target symbols in the way which maximizes the labeled F 1 . Note that this can, and does, result in mapping multiple model symbols to the most frequent target symbols. This experiment, labeled PCFG × NONE in <ref type="figure" target="#fig_1">figure 4</ref>, resulted in an average labeled F 1 of 26.3 and an unlabeled F 1 of 45.7. The unlabeled F 1 is better than randomly choosing a tree (34.7), but not better than always choosing a right branching structure (61.7). <ref type="bibr" target="#b8">Klein and Manning (2002)</ref> suggest that the task of labeling constituents is significantly easier than identifying them. Perhaps it is too much to ask a PCFG induction algorithm to perform both of these tasks simultaneously. Along the lines of <ref type="bibr" target="#b14">Pereira and Schabes (1992)</ref>, we reran the insideoutside algorithm, but this time placed zero mass on all trees which did not respect the bracketing of the gold trees. This constraint does not fully  <ref type="figure">Figure 1</ref>: English phrase type prototype list manually specified (The entire supervision for our system). The second part of the table is additional prototypes discussed in section 7.1.</p><p>eliminate the structural uncertainty since we are inducing binary trees and the gold trees are flatter than binary in many cases. This approach of course achieved the upper bound on unlabeled F 1 , because of the gold bracket constraints. However, it only resulted in an average labeled F 1 of 52.6 (experiment PCFG × GOLD in <ref type="figure" target="#fig_1">figure 4</ref>). While this labeled score is an improvement over the PCFG × NONE experiment, it is still relatively disappointing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Encoding Prior Knowledge with Prototypes</head><p>Clearly, we need to do something more than adding structural bias (e.g. bracketing information) if we are to learn a PCFG in which the symbols have the meaning and behaviour we intend. How might we encode information about our prior knowledge or intentions? Providing labeled trees is clearly an option. This approach tells the learner how symbols should recursively relate to each other. Another option is to provide fully linearized yields as prototypes. We take this approach here, manually creating a list of POS sequences typical of the 7 most frequent categories in the Penn Treebank (see <ref type="figure">figure 1</ref>). <ref type="bibr">3</ref> Our grammar is limited to these 7 phrase types plus an additional type which has no prototypes and is unconstrained. <ref type="bibr">4</ref> This list grounds each sym-3 A possible objection to this approach is the introduction of improper reasearcher bias via specifying prototypes. See section 7.3 for an experiment utilizing an automatically generated prototype list with comparable results. <ref type="bibr">4</ref> In our experiments we found that adding prototypes for more categories did not improve performance and took more bol in terms of an observable portion of the data, rather than attempting to relate unknown symbols to other unknown symbols.</p><p>Broadly, we would like to learn a grammar which explains the observed data (EM's objective) but also meets our prior expectations or requirements of the target grammar. How might we use such a list to constrain the learning of a PCFG with the inside-outside algorithm? We might require that all occurences of a prototype sequence, say DT NN, be constituents of the corresponding type (NP). However, human-elicited prototypes are not likely to have the property that, when they occur, they are (nearly) always constituents. For example, DT NN is a perfectly reasonable example of a noun phrase, but is not a constituent when it is part of a longer DT NN NN constituent. Therefore, when summing over trees with the inside-outside algorithm, we could require a weaker property: whenever a prototype sequence is a constituent it must be given the label specified in the prototype file. <ref type="bibr">5</ref> This constraint is enough to break the symmetry between the model labels, and therefore requires neither random initialization for training, nor post-hoc mapping of labels for evaluation. Adding prototypes in this way and keeping the gold bracket constraint gave 59.9 labeled F 1 . The labeled F 1 measure is again an improvement over naive PCFG induction, but is perhaps less than we might expect given that the model has been given bracketing information and has prototypes as a form of supervision to direct it.</p><p>In response to a prototype, however, we may wish to conclude something stronger than a constraint on that particular POS sequence. We might hope that sequences which are similar to a prototype in some sense are generally given the same label as that prototype. For example, DT NN is a noun phrase prototype, the sequence DT JJ NN is another good candidate for being a noun phrase. This kind of propagation of constraints requires that we have a good way of defining and detecting similarity between POS sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Phrasal Distributional Similarity</head><p>A central linguistic argument for constituent types is substitutability: phrases of the same type appear time. We note that we still evaluate against all phrase types regardless of whether or not they are modeled by our grammar. <ref type="bibr">5</ref> Even this property is likely too strong: prototypes may have multiple possible labels, for example DT NN may also be a QP in the English treebank.  <ref type="figure">Figure 2</ref>: Yields along with most similar prototypes and phrase types, guessed according to <ref type="bibr">(3)</ref>.</p><p>in similar contexts and are mutually substitutable <ref type="bibr" target="#b6">(Harris, 1954;</ref><ref type="bibr" target="#b15">Radford, 1988)</ref>. For instance, DT JJ NN and DT NN occur in similar contexts, and are indeed both common NPs. This idea has been repeatedly and successfully operationalized using various kinds of distributional clustering, where we define a similarity measure between two items on the basis of their immediate left and right contexts <ref type="bibr" target="#b16">(Schütze, 1995;</ref><ref type="bibr" target="#b2">Clark, 2000;</ref><ref type="bibr">Klein and Man- ning, 2002</ref>). As in Clark <ref type="formula" target="#formula_1">(2001)</ref>, we characterize the distribution of a sequence by the distribution of POS tags occurring to the left and right of that sequence in a corpus. Each occurence of a POS sequence α falls in a context x α y, where x and y are the adjacent tags. The distribution over contexts x − y for a given α is called its signature, and is denoted by σ(α). Note that σ(α) is composed of context counts from all occurences, constitiuent and distituent, of α. Let σ c (α) denote the context distribution for α where the context counts are taken only from constituent occurences of α. For each phrase type in our grammar, X, define σ c (X) to be the context distribution obtained from the counts of all constituent occurences of type X:</p><formula xml:id="formula_1">σ c (X) = E p(α|X) σ c (α)<label>(1)</label></formula><p>where p(α|X) is the distribution of yield types for phrase type X. We compare context distributions using the skewed KL divergence:</p><formula xml:id="formula_2">D SKL (p, q) = D KL (pγp + (1 − γ)q)</formula><p>where γ controls how much of the source distributions is mixed in with the target distribution. A reasonable baseline rule for classifying the phrase type of a POS yield is to assign it to the phrase from which it has minimal divergence:</p><formula xml:id="formula_3">type(α) = arg min X D SKL (σ c (α), σ c (X)) (2)</formula><p>However, this rule is not always accurate, and, moreover, we do not have access to σ c (α) or σ c (X). We chose to approximate σ c (X) using the prototype yields for X as samples from p(α|X). Letting proto(X) denote the (few) prototype yields for phrase type X, we define˜σdefine˜ define˜σ(X):</p><formula xml:id="formula_4">˜ σ(X) = 1 |proto(X)| α∈proto(X) σ(α)</formula><p>Note˜σNote˜ Note˜σ(X) is an approximation to (1) in several ways. We have replaced an expectation over p(α|X) with a uniform weighting of proto(X), and we have replaced σ c (α) with σ(α) for each term in that expectation. Because of this, we will rely only on high confidence guesses, and allow yields to be given a NONE type if their divergence from each˜σeach˜ each˜σ(X) exceeds a fixed threshold t. This gives the following alternative to (2):</p><formula xml:id="formula_5">type(α) = (3) NONE, if min X D SKL (σ(α), ˜ σ(X)) &lt; t arg min X D SKL (σ(α), ˜ σ(X)), otherwise</formula><p>We built a distributional model implementing the rule in (3) by constructing σ(α) from context counts in the WSJ portion of the Penn Treebank as well as the BLIPP corpus. Each˜σEach˜ Each˜σ(X) was approximated by a uniform mixture of σ(α) for each of X's prototypes α listed in <ref type="figure">figure 1</ref>.</p><p>This method of classifying constituents is very precise if the threshold is chosen conservatively enough. For instance, using a threshold of t = 0.75 and γ = 0.1, this rule correctly classifies the majority label of a constituent-type with 83% precision, and has a recall of 23% over constituent types. <ref type="figure">Figure 2</ref> illustrates some sample yields, the prototype sequence to which it is least divergent, and the output of rule (3).</p><p>We incorporated this distributional information into our PCFG induction scheme by adding a prototype feature over each span (i, j) indicating the output of (3) for the yield α in that span. Associated with each sentence S is a feature map F specifying, for each (i, j), a prototype feature p ij . These features are generated using an augmented CFG model, CFG+, given by: 6</p><formula xml:id="formula_6">P CF G + (T, F ) = X(i,j)→α∈T P (p ij |X)P (α|X) = X(i,j)→α∈T φ CF G + (X → α, p ij ) 6</formula><p>Technically, all features in F must be generated for each assignment to T , which means that there should be terms in this equation for the prototype features on distituent spans. However, we fixed the prototype distribution to be uniform for distituent spans so that the equation is correct up to a constant depending on F . where φ CF G + (X → α, p ij ) is the local factor for placing X → α on a span with prototype feature p ij . An example is given in <ref type="figure" target="#fig_0">figure 3</ref>.</p><formula xml:id="formula_7">P (S|ROOT) ¯ ROOT S  P (NP VP|S) P (P = NONE|S)       $ $ $ $ $ $ P (NN</formula><p>For our experiments, we fixed P (p ij |X) to be:</p><formula xml:id="formula_8">P (p ij |X) = 0.60, if p ij = X uniform, otherwise</formula><p>Modifying the model in this way, and keeping the gold bracketing information, gave 71.1 labeled F 1 (see experiment PROTO × GOLD in <ref type="figure" target="#fig_1">figure 4</ref>), a 40.3% error reduction over naive PCFG induction in the presence of gold bracketing information. We note that the our labeled F 1 is upper-bounded by 86.0 due to unary chains and more-than-binary configurations in the treebank that cannot be obtained from our binary grammar. We conclude that in the presence of gold bracket information, we can achieve high labeled accuracy by using a CFG augmented with distributional prototype features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Constituent Context Model</head><p>So far, we have shown that, given perfect perfect bracketing information, distributional prototype features allow us to learn tree structures with fairly accurate labels. However, such bracketing information is not available in the unsupervised case.</p><p>Perhaps we don't actually need bracketing constraints in the presence of prototypes and distributional similarity features. However this experiment, labeled PROTO × NONE in <ref type="figure" target="#fig_1">figure 4</ref>, gave only 53.1 labeled F 1 (61.1 unlabeled), suggesting that some amount of bracketing constraint is necessary to achieve high performance.</p><p>Fortunately, there are unsupervised systems which can induce unlabeled bracketings with reasonably high accuracy. One such model is the constituent-context model (CCM) of <ref type="bibr" target="#b8">Klein and Manning (2002)</ref>, a generative distributional model. For a given sentence S, the CCM generates a bracket matrix, B, which for each span (i, j), indicates whether or not it is a constituent (B ij = c) or a distituent (B ij = d). In addition, it generates a feature map F , which for each span (i, j) in S specifies a pair of features, F ij = (y ij , c ij ), where y ij is the POS yield of the span, and c ij is the context of the span, i.e identity of the conjoined left and right POS tags:</p><formula xml:id="formula_9">P CCM (B, F ) = P (B) (i,j) P (y ij |B ij )P (c ij |B ij )</formula><p>The distribution P (B) only places mass on bracketings which correspond to binary trees. We can efficiently compute P CCM (B, F ) (up to a constant) depending on F using local factors φ CCM (y ij , c ij ) which decomposes over constituent spans: 7</p><formula xml:id="formula_10">P CCM (B, F ) ∝ (i,j):B ij =c P (y ij |c)P (c ij |c) P (y ij |d)P (c ij |d) = (i,j):B ij =c φ CCM (y ij , c ij )</formula><p>The CCM by itself yields an unlabeled F 1 of 71.9 on WSJ-10, which is reasonably high, but does not produce labeled trees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Intersecting CCM and PCFG</head><p>The CCM and PCFG models provide complementary views of syntactic structure. The CCM explicitly learns the non-recursive contextual and yield properties of constituents and distituents. The PCFG model, on the other hand, does not explicitly model properties of distituents but instead focuses on modeling the hierarchical and recursive properties of natural language syntax. One would hope that modeling both of these aspects simultaneously would improve the overall quality of our induced grammar.</p><p>We therefore combine the CCM with our featureaugmented PCFG, denoted by PROTO in experiment names. When we run EM on either of the models alone, at each iteration and for each training example, we calculate posteriors over that model's latent variables. For CCM, the latent variable is a bracketing matrix B (equivalent to an unlabeled binary tree), while for the CFG+ the latent variable is a labeled tree T . While these latent variables aren't exactly the same, there is a close relationship between them. A bracketing matrix constrains possible labeled trees, and a given labeled tree determines a bracketing matrix. One way to combine these models is to encourage both models to prefer latent variables which are compatible with each other.</p><p>Similar to the approach of <ref type="bibr" target="#b9">Klein and Manning (2004)</ref> on a different model pair, we intersect CCM and CFG+ by multiplying their scores for any labeled tree. For each possible labeled tree over a sentence S, our generative model for a labeled tree T is given as follows:</p><formula xml:id="formula_11">P (T, F, F ) = (4) P CF G + (T, F )P CCM (B(T ), F )</formula><p>where B(T ) corresponds to the bracketing matrix determined by T . The EM algorithm for the product model will maximize:</p><formula xml:id="formula_12">P (S,F, F ) = T ∈T (S) P CCM (B, F )P CF G + (T, F ) = B P CCM (B, F ) T ∈T (B,S) P CF G + (T, F )</formula><p>where T (S) is the set of labeled trees consistent with the sentence S and T (B, S) is the set of labeled trees consistent with the bracketing matrix B and the sentence S. Notice that this quantity increases as the CCM and CFG+ models place probability mass on compatible latent structures, giving an intuitive justification for the success of this approach.</p><p>We can compute posterior expectations over (B, T ) in the combined model (4) using a variant of the inside-outside algorithm. The local factor for a binary rule r = X → Y Z, over span (i, j), with CCM features F ij = (y ij , c ij ) and prototype feature p ij , is given by the product of local factors for the CCM and CFG+ models:</p><formula xml:id="formula_13">φ(r, (i, j)) = φ CCM (y ij , c ij )φ CF G + (r, p ij )</formula><p>From these local factors, the inside-outside algorithm produces expected counts for each binary rule, r, over each span (i, j) and split point k, denoted by P <ref type="figure">(r, (i, j)</ref>, k|S, F, F ). These posteriors are sufficient to re-estimate all of our model parameters.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CCM as a Bracketer</head><p>We tested the product model described in section 5 on WSJ-10 under the same conditions as in section 3. Our initial experiment utilizes no protoype information, random initialization, and greedy remapping of its labels. This experiment, PCFG × CCM in <ref type="figure" target="#fig_1">figure 4</ref>, gave 35.3 labeled F 1 , compared to the 51.6 labeled F 1 with gold bracketing information (PCFG × GOLD in <ref type="figure" target="#fig_1">figure 4</ref>). Next we added the manually specified prototypes in <ref type="figure">figure 1</ref>, and constrained the model to give these yields their labels if chosen as constituents. This experiment gave 48.9 labeled F 1 (73.3 unlabeled). The error reduction is 21.0% labeled (5.3% unlabeled) over PCFG × CCM.</p><p>We then experimented with adding distributional prototype features as discussed in section 3.2 using a threshold of 0.75 and γ = 0.1. This experiment, PROTO × CCM in figure 4, gave 62.2 labeled F 1 (76.5 unlabeled). The error reduction is 26.0% labeled (12.0% unlabeled) over the experiment using prototypes without the similarity features. The overall error reduction from PCFG × CCM is 41.6% (16.7%) in labeled (unlabeled) F 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Error Analysis</head><p>The most common type of error by our PROTO × CCM system was due to the binary grammar restriction. For instance common NPs, such as DT JJ NN, analyzed as [ NP DT <ref type="bibr">[ NP JJ NN]</ref> ], which proposes additional N constituents compared to the flatter treebank analysis. This discrepancy greatly, and perhaps unfairly, damages NP precision (see <ref type="figure">figure 6</ref>). However, this is error is unavoidable given our grammar restriction.  <ref type="bibr" target="#b0">(Abney, 1987)</ref>. Another type of error also reported by <ref type="bibr" target="#b8">Klein and Manning (2002)</ref> is MD VB groupings in infinitival VPs also sometimes argued by linguists <ref type="bibr" target="#b5">(Halliday, 2004</ref>). More seriously, prepositional phrases are almost always attached "high" to the verb for longer NPs.</p><formula xml:id="formula_14">S      $ $ $ $ $ NP NNP France VP       $ $ $ $ $ $ MD can VP hh hh hh h @ @ @ @ @ @ @ VB boast NP     $ $ $ $ $ NP     3 3 3 3 NP    3 3 3 DT the NN lion POS 's NN share PP     IN of NP r r r ¨ ¨ ¨ JJ high-priced NNS bottles S hh hh hh hh h @ @ @ @ @ @ @ @ @ NNP France VP hh hh hh hh @ @ @ @ @ @ @ @ VP      $ $ $ $ $ VP   &amp; &amp; MD can VB boast NP     3 3 3 3 NP l l D D DT the NN lion PP   &amp; &amp; POS 's NN share PP     IN of NP r r r ¨ ¨ ¨ JJ high-priced NNS bottles S hh hh hh hh h @ @ @ @ @ @ @ @ @ NNP France VP hh hh hh hh h h @ @ @ @ @ @ @ @ @ @ VP     MD can VP      $ $ $ $ $ VB boast NP     NP  </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Augmenting Prototypes</head><p>One of the advantages of the prototype driven approach, over a fully unsupervised approach, is the ability to refine or add to the annotation specification if we are not happy with the output of our system. We demonstrate this flexibility by augmenting the prototypes in <ref type="figure">figure 1</ref> with two new categories NP-POS and VP-INF, meant to model possessive noun phrases and infinitival verb phrases, which tend to have slightly different distributional properties from normal NPs and VPs. These new sub-categories are used during training and then stripped in post-processing. This prototype list gave 65.1 labeled F 1 (78.2 unlabeled). This experiment is labeled BEST in <ref type="figure" target="#fig_1">figure 4</ref>. Looking at the CFG-learned rules in <ref type="figure" target="#fig_4">figure 7</ref>, we see that the basic structure of the treebank grammar is captured.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Parsing with only the PCFG</head><p>In order to judge how well the PCFG component of our model did in isolation, we experimented with training our <ref type="bibr">BEST</ref>   . This demonstrates that while our PCFG performance degrades without the CCM, it can be used on its own with reasonable accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Automatically Generated Prototypes</head><p>There are two types of bias which enter into the creation of prototypes lists. One of them is the bias to choose examples which reflect the annotation semantics we wish our model to have. The second is the iterative change of prototypes in order to maximize F 1 . Whereas the first is appropriate, indeed the point, the latter is not. In order to guard against the second type of bias, we experimented with automatically extracted generated prototype lists which would not be possible without labeled data. For each phrase type category, we extracted the three most common yield associated with that category that differed in either first or last POS tag. Repeating our PROTO × CCM experiment with this list yielded 60.9 labeled F 1 (76.5 unlabeled), comparable to the performance of our manual prototype list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Chinese Grammar Induction</head><p>In order to demonstrate that our system is somewhat language independent, we tested our model on CTB-10, the 2,437 sentences of the Chinese Treebank <ref type="bibr" target="#b7">(Ircs, 2002</ref>) of length at most 10 after punctuation is stripped. Since the authors have no expertise in Chinese, we automatically extracted prototypes in the same way described in section 7.3. Since we did not have access to a large auxiliary POS tagged Chinese corpus, our distributional model was built only from the treebank text, and the distributional similarities are presumably degraded relative to the English. Our PCFG × CCM experiment gave 18.0 labeled F 1 (43.4 unlabeled). The PROTO × CCM model gave 39.0 labeled F 1 (53.2 unlabeled). Presumably with access to more POS tagged data, and the expertise of a Chinese speaker, our system would see increased performance. It is worth noting that our unlabeled F 1 of 53.2 is the best reported from a primarily unsupervised system, with the next highest figure being 46.7 reported by <ref type="bibr" target="#b9">Klein and Manning (2004)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We have shown that distributional prototype features can allow one to specify a target labeling scheme in a compact and declarative way. These features give substantial error reduction in labeled F 1 measure for English and Chinese grammar induction. They also achieve the best reported unlabeled F 1 measure. 8 Another positive property of this approach is that it tries to reconcile the success of distributional clustering approaches to grammar induction <ref type="bibr" target="#b3">(Clark, 2001;</ref><ref type="bibr">Klein and Man- ning, 2002</ref>), with the CFG tree models in the supervised literature <ref type="bibr" target="#b4">(Collins, 1999</ref>). Most importantly, this is the first work, to the authors' knowl-</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Illustration of PCFG augmented with prototype similarity features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: English grammar induction results. The upper bound on labeled recall is due to unary chains.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Examples of corrections from adding VP-INF and NP-POS prototype categories. The tree in (a) is the Treebank parse, (b) is the parse with PROTO × CCM model, and c) is the parse with the BEST model (added prototype categories), which fixes the possesive NP and infinitival VP problems, but not the PP attachment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 (</head><label>5</label><figDesc>b) demonstrates three other errors. Pos- sessive NPs are analyzed as [ NP NN [ PP POS NN ] ], with the POS element treated as a preposition and the possessed NP as its complement. While labeling the POS NN as a PP is clearly incorrect, placing a constituent over these elements is not unreasonable and in fact has been proposed by some linguists</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Top PCFG Rules learned by BEST model ment gave 65.1 labeled F 1 (76.8 unlabeled). This demonstrates that while our PCFG performance degrades without the CCM, it can be used on its own with reasonable accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head></head><label></label><figDesc>model with the CCM com- ponent, but dropping it at test time. This experi-</figDesc><table>Label 
Prec. Rec. F 1 
S 
79.3 80.0 79.7 
NP 
49.0 74.4 59.1 
VP 
80.4 73.3 76.7 
PP 
45.6 78.6 57.8 
QP 
36.2 78.8 49.6 
ADJP 
29.4 33.3 31.2 
ADVP 25.0 12.2 16.4 

Figure 6: Precision, recall, and F 1 for individual 
phrase types in the BEST model 

Rule 
Probability Rule 
Probability 

S → NP VP 

0.51 

VP → VBZ NP 

0.20 

S → PRP VP 

0.13 

VP → VBD NP 

0.15 

S → NNP VP 

0.06 

VP → VBP NP 

0.09 

S → NNS VP 

0.05 

VP → VB NP 

0.08 

NP → DT NN 

0.12 

ROOT → S 

0.95 

NP → NP PP 

0.09 

ROOT → NP 

0.05 

NP → NNP NNP 

0.09 

NP → JJ NN 

0.07 

PP → IN NP 

0.37 

QP → CD CD 

0.35 

PP → CC NP 

0.06 

QP → CD NN 

0.30 

PP → TO VP 

0.05 

QP → QP PP 

0.10 

PP → TO QP 

0.04 

QP → QP NNS 

0.05 
ADJP → RB VBN 0.37 

ADVP → RB RB 

0.25 

ADJP → RB JJ 

0.31 
ADVP → ADJP PRP 0.15 

ADJP → RBR JJ 

0.09 

ADVP → RB CD 

0.10 

</table></figure>

			<note place="foot" n="1"> In cases where multiple gold labels exist in the gold trees, precision and recall were calculated as in Collins (1999). 2 Restricting our CFG to a binary branching grammar results in an upper bound of 88.1% on unlabeled F1.</note>

			<note place="foot" n="7"> Klein (2005) gives a full presentation.</note>

			<note place="foot" n="8"> The next highest results being 77.1 and 46.7 for English and Chinese respectively from Klein and Manning (2004). edge, which has learned CFGs in an unsupervised or semi-supervised setting and can parse natural language language text with any reasonable accuracy.</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The English Noun Phrase in its Sentential Aspect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Abney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
	<note>Ph.D. thesis, MIT</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Two experiments on learning probabilistic dependency grammars from corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Glenn</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<idno>CS-92-16</idno>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Inducing syntactic categories by context distribution clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
		<meeting><address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="91" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">The unsupervised induction of stochastic context-free grammars using distributional clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Clark</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note>In CoNLL</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The Unsupervised learning of Natural Language Structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
		<respStmt>
			<orgName>University of Rochester</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">An introduction to functional grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Halliday</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Edward Arnold</publisher>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Distributional Structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zellig</forename><surname>Harris</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1954" />
			<publisher>University of Chicago Press</publisher>
			<pubPlace>Chicago</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Building a large-scale annotated chinese corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nianwen Xue Ircs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A generative constituent-context model for improved grammar induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Corpus-based induction of syntactic structure: Models of dependency and constituency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The unsupervised learning of Natural Language Structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The estimation of stochastic context-free grammars using the insideoutside algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karim</forename><surname>Lari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech and Language</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="35" to="56" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schütze</surname></persName>
		</author>
		<title level="m">Foundations of Statistical Natural Language Processing</title>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of english: The penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Marcinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Insideoutside reestimation from partially bracketed corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">N</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schabes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="128" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Transformational Grammar. Cambridge University Press</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Radford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Distributional part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Guiding unsupervised grammar induction using contrastive estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Working notes of the IJCAI workshop on Grammatical Inference Applications</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
