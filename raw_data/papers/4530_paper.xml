<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PARALLEL AND DISTRIBUTED AUDIO CONCEALMENT USING NONLOCAL SPARSE REPRESENTATIONS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Lane Department of Comp. Sci. and Elec. Engr. West</orgName>
								<orgName type="institution">Virginia University</orgName>
								<address>
									<postCode>26506-6109</postCode>
									<settlement>Morgantown</settlement>
									<region>WV</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">PARALLEL AND DISTRIBUTED AUDIO CONCEALMENT USING NONLOCAL SPARSE REPRESENTATIONS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a new class of parallel and distributed audio con-cealment (PDAC) algorithms which recover lost audio packets at the receiver to fight against channel impairment. The main contribution of this work is the proposal of using nonlocal sparse representations to characterize the prior constraint of undamaged audio. When combined with observation constraint, we obtain an alternating projection based audio concealment algorithm which recovers missing data in a parallel and distributed fashion. We also present two extensions of PDAC for more challenging situations: expectation-maximization PDAC (EM-PDAC) to handle consecutive packet loss and filter-bank PDAC (FB-PDAC) to repair complex music signals. Excellent preliminary experimental results are reported for a wide range of audio materials and loss conditions.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Audio concealment refers to the problem of repairing the lost packets due to channel impairments. Channel impairments could arise from fading in a cellular network or network congestion in a packet switch network. The impact of lost packets on subjective quality of audio signals is dramatic <ref type="bibr">[1]</ref>, <ref type="bibr">[2]</ref>. Error concealment has found to be a useful technique in multimedia communication applications. In particular, as voice over internet protocol (VoIP) and audio streaming becomes more popular, packet loss recovery for audio signals is expected to receive more attention in the future. There are two classes of concealment techniques: sendera) b) based and receiver-based <ref type="bibr">[1]</ref>. Our focus here is receiver-based approaches which attempt to recover the data in the lost packet by exploiting the inherent redundancy of audio source itself (refer to <ref type="figure" target="#fig_0">Fig. 1</ref>). Existing approaches toward packet loss recovery mainly include time-scale modification <ref type="bibr" target="#b0">[3]</ref>, adaptive packetization <ref type="bibr" target="#b1">[4]</ref> and model-based schemes <ref type="bibr" target="#b2">[5]</ref>, <ref type="bibr">[2]</ref>. Interested readers are referred to two survey articles <ref type="bibr">[1]</ref>, <ref type="bibr" target="#b3">[6]</ref> for more information. However, we note that most current schemes sequentially recover the lost packet -i.e., concealment starts from the two ends of a missing frame and recover lost data on a sample-by-sample basis (refer to <ref type="figure" target="#fig_0">Fig. 1a</ref>).</p><p>The drawback of such sequential approach is error propagation. That is, recovery at the boundary of missing frame is likely to be more accurate than that at the center. The problem of error propagation is rooted in the locality or Markovian assumption made about the audio source for the purpose of overcoming the curse of dimensionality <ref type="bibr" target="#b4">[7]</ref>. However, such assumption is often questionable especially for speech (e.g., pitch-related) and audio signals which often demonstrate strong non-local dependency. The above observations motivate us to come up with a new class of algorithms that recover the missing data in a parallel and distributed fashion. As shown in <ref type="figure" target="#fig_0">Fig. 1b</ref>, a lost frame x of length q is conceived to be a subframe of several longer frames {x 1, ..., x k } of length p &gt; q. Therefore, the problem of estimating x can be transformed into k parallel and distributed concealment problems which can be solved independently. Apparently, the overlapping among x i's introduces redundancy or diversity to the solution, which distinguishes ours from previous attacks.</p><p>The objective of this work is to demonstrate the benefit of diversity to error concealment problem and suggest its connection to the influential paradigm in cognitive science called parallel distributed processing (PDP) <ref type="bibr">[?]</ref>. Since human observers will ultimately judge the quality of recovered audio, there is a compelling need to develop biologically-inspired PDP algorithms which better match the mechanism of human auditory system. The rest of the paper is organized as follows. In Section 2, we introduce nonlocal sparse representation in the frame space which is the foundation for developing parallel and distributed concealment. Basic algorithm and its two extensions are presented next in Section 3. Preliminary experimental results are reported in Section 4 to justify the effectiveness of the proposed approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">NONLOCAL SPARSE REPRESENTATION IN THE FRAME SPACE</head><p>Let S = {s 1, s2, ..., sN } denote a sequence of audio samples. To overcome the curse of dimensionality, we consider a frame-based representation of audio as shown in <ref type="figure" target="#fig_1">Fig. 2</ref>. In speech coding, one often apply linear prediction analysis to each frame of samples and represent them by parametric autoregressive (AR) models <ref type="bibr" target="#b6">[9]</ref>.</p><p>Here we are interested in a nonparametric approach of modeling audio signals in the frame space R p -specifically, we want to develop a new representation based on the observation that all frames of length p (point clouds in R p ) form a nonlinear manifold whose dimensionality is much smaller than p.</p><p>In the seminal work of nonlinear dimensionality reduction by locally linear embedding (LLE) <ref type="bibr" target="#b7">[10]</ref>, the local geometry of a manifold is characterized by linear coefficients that reconstruct each data point from its neighbors in the frame space, i.e.,</p><formula xml:id="formula_0">x 0 = q 񮽙 i=1 wixi,<label>(1)</label></formula><p>where x0 is the data point (frame of interest) and N (x0) = {xi} q i=1 denotes its local neighborhood. Note that the locality in the frame space is NOT equivalent to that in the time domain where audio is sampled. Two audio frames would have small distance in the frame space (i.e., neighboring points in R p ) but are far away from each other (e.g., separated by a pitch period). Therefore, the subtle difference between linear prediction model in Eq.</p><p>(1) and classical AR model lies on the choice of neighborhood x i's (nonlocal vs. local in the time domain).</p><p>The key motivation behind nonlocal sparse representation lies in the question of how to exploit the manifold constraint shown in <ref type="figure" target="#fig_1">Fig. 2</ref>. Counter-intuitively, the solution is to increase the dimensionality. For example, any single point x0 in R p does not realize the local subspace constraint; instead multiple points in the local neighborhood of x 0 reflect the manifold constraint -the point cloud could have a lower dimensionality than p. In other words, if we pack all points in the neighborhood of x 0 (including x0) into a 2D array X sized p × Q (Q = q + 1), the manifold constraint of the signal can be exploited by standard 2D linear transforms (e.g., FFT and DCT).</p><p>What do we buy from such increased dimensionality (2D instead of 1D)? We argue it is the improved sparsity of signal representation. Better sparsity is a direct consequence of nonlinearity because the nonlocal information of x i (i.e., how it is related to x0) is implicitly coded into the new dimension (intuitively we can think of it as the phase axis). Therefore, even if a linear and nonadaptive 2D transform is used, the derived audio representation is nonlinear and adaptive due to the embedded nonlocal (phase) information. Such joint time-phase (local-nonlocal) processing is an important departure from the current practice of pursuing adaptive yet still local representation for audio signals.</p><p>One critical issue remaining to be addressed is the size of local neighborhood in the frame space -the sparsity is not guaranteed unless sufficient number of points can be found surrounding x0. Fortunately, such condition is approximately satisfied for signals acquired from the real world such as audio. In our framebased representation, two frames x and y are declared adjacent if y = T [x] + w where w denotes an additive noise term and T is the translation operator. Although the above definition of local neighborhood can be further extended by incorporating timereversal and time-scale modification into T (it is essentially the transformation operator of an ergodic process <ref type="bibr" target="#b8">[11]</ref>), we only use translation in our current implementation for its simplicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">PARALLEL AND DISTRIBUTED AUDIO CONCEALMENT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Baseline Algorithm Description</head><p>Sparsity constraint in the frame space offers a powerful prior constraint for undamaged audio. Similar to image recovery <ref type="bibr" target="#b9">[12]</ref>, we can define two constraint sets for the targetˆStargetˆ targetˆS: observation constraint specified by correctly-received audio packets and prior constraint specified by the sparsity prior in the frame space (i.e., ˆ S belongs to a low-dimensional manifold). Note that packed audio frames X ∈ R p×q are indeed 2D array, which imply that tools developed for image recovery are also applicable here. However, we note that such borrowing is motivated by the need of exploiting nonlocal dependency in audio, which differs from the locality motivation in image recovery. The convexity of observation and prior constraint sets are easy to justify (refer to <ref type="bibr" target="#b9">[12]</ref>); and the recovery of missing data can be solved by alternating projections (see <ref type="figure" target="#fig_2">Fig. 3a</ref>). The basic PDAC algorithm is summarized as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1. Parallel and Distributed Audio Concealment (PDAC) Algorithm</head><p>• Initialization: ˆ S 0 = S; • Data recovery: recover the missing data inˆSinˆ inˆS k by alternating projections -prior (sparsity) constraint: apply transform-domain thresholding to each 2D array X formed around x0 and take the average of overlapped samples as the projection resultsˆSresultsˆ resultsˆS k+1 ;</p><p>-observation constraint: for those packets which are not lost, replace their corresponding data inˆSinˆ inˆS k+1 by those inˆSinˆ inˆS 0 ;</p><p>We making two additional comments about the enforcement of sparsity constraint in the above algorithm. First, transformdomain thresholding refers to the standard concatenation of forward transform, hard thresholding and inverse transform. The choice of transform is flexible -we have found FFT and DCT achieve comparable performance. However, we note that the 2D <ref type="figure">Fig. 4</ref>. Flow-chart of FB-PDAC algorithm.</p><p>basis used in our algorithm is not adaptive at all -temporal adaptation is due to the clustering in the frame space. Second, averaging overlapped frames is an ad-hoc strategy for transforming the overcomplete expansion of audio back to a complete version. It is possible to develop more sophisticated fusion strategy using Bayesian theory (but outside the scope of this work).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. PDAC Algorithm Extensions</head><p>In our baseline algorithm, the impact of missing frame on data clustering in the frame space is ignored. However, such issue is important because the sparsity (dimensionality of manifold) is directly determined by the clustering results. Fortunately, such missing data problem can be solved by the classical expectation maximization (EM) algorithm -i.e., we can alternate the process of recovering missing data and determining local neighborhood N (x 0) in R p . Intuitively, improved estimation of missing data will lead to a better definition of N (x0) and vice versa (refer to <ref type="figure" target="#fig_2">Fig. 3b)</ref>. Therefore, we can extend PDAC algorithm by adding an outer loop responsible for clustering refinement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2. EM-PDAC Algorithm</head><p>• Initialization: ˆ S 0 = S; • Outer loop (EM-like iteration) -neighborhood refinement: find N (x0) for every frame x0 centered at a missing sample inˆSinˆ inˆS k ;</p><p>-data recovery (inner loop): recover the missing data inˆS inˆ inˆS k by Algorithm 1.</p><p>Another challenging issue arises as audio sampling rate gets higher. For example, empirical studies have shown that music signals sampled at 44.1KHz are less aperiodic and therefore more difficult to conceal than speech signals sampled at 8KHz. Higher sampling rate also implies more demanding computational power in real-time applications. Those observations motivate us to extend the basic PDAC algorithm by incorporating a multi-rate filter-bank (FB) architecture <ref type="bibr" target="#b10">[13]</ref> as shown in <ref type="figure">Fig. 4</ref>. Despite the simplicity of FB-PDAC, we have found that it improves the concealment performance (due to improved waveform similarity at lower resolutions) and speeds up the computation (due to reduced frame length and search window size).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTAL RESULTS</head><p>In this section, we use experimental results to justify the effectiveness of the proposed algorithms. Two pieces of audio files are used as the test data: one is normal human speech sampled at 8KHz and the other is a pop music sampled at 44.1KHz. The benchmark used in our comparison include a simplified implementation of LP-based packet loss concealment (LP-PLC) <ref type="bibr">[2]</ref> (without excitation generator but with a higher-order LP and take the average of LP results from both forward and backward directions) and our own implementation of waveform similarity overlap-add (WS-OLA) <ref type="bibr" target="#b0">[3]</ref>. LP-LPC and WS-OLA can be viewed as the representatives of parametric and nonparametric modeling of audio signals. The objective measurement of concealment performance is the signal-to-noise (SNR) of the lost packet (we assume packet loss is isolated due to interleaving). Although no subjective testing is performed yet, it is reasonable to assume improved SNR performance will correlate to higher perceptual quality. In our first experiment, we test our PDAC algorithm on human speech signal. The size of lost packet is 10ms (L = 80 samples) and we set the length of frame to be p = 4L+1 samples. <ref type="figure" target="#fig_3">Fig. 5</ref> includes the comparison of the error signals produced by three different concealment techniques: LP-PLC, WS-OLA and PDAC. Our algorithm achieves the highest SNR performance among three. To better illustrate the behavior of PDAC, we show the evolution of MSE as the iteration proceeds in <ref type="figure" target="#fig_4">Fig. 6</ref>. It can be observed that 1) PDAC converges rapidly (little improvement after the first five iterations); 2) DCT and FFT achieve comparable performance (FFT gives SN R = 15.03dB at the convergence, DCT achieves SN R = 13.58dB).</p><p>In our second experiment, we want to demonstrate the gain of EM-PDAC over PDAC due to refined data clustering. The same testing condition and parameter setting are used. <ref type="figure" target="#fig_5">Fig. 7</ref> includes the comparison between MSE profiles for PDAC and EM-PDAC algorithms (both use FFT as the sparsifying transform). It can be observed that 1) SNR first converges and then improves again when the outer loop variable increases (neighborhood N (x 0) is updated); 2) EM-PDAC achieves over 1dB gain over PDAC. Such findings support the benefits of refining data clustering though at the price of higher computational complexity.</p><p>Finally, we report the performance of PDCA on concealing music signals. Such type of signal is less regular than human speech and demonstrates weaker periodicity. At the same test-  ing condition (L = 80), both LP-PLC and WS-OLA give poor SNR results (&lt; 1dB). <ref type="figure" target="#fig_6">Fig. 8</ref> shows the SNR performance of FB-PDAC at different decimation ratios (k = 1, 2, 4, 8). The gain of FB-PDAC with k = 8 over PB-PDAC is about 2.5dB. Preliminary subjective testing also justifies that such moderate SNR increase does correlate to the improvement of perceptual quality. We will report more comprehensive results on subjective testing at the conference. Currently it takes about one minute to run our nonoptimized MATLAB implementation of FB-PDAC on a Pentium-IV machine (2.4G processer, 512M memory). However, we note that data clustering -computational bottleneck in our algorithmcan be efficiently implemented by associative memory <ref type="bibr" target="#b11">[14]</ref>. Moreover, the class of PDAC algorithms might admit fast hardware implementation on VLSI chips due to their parallel nature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">REFERENCES</head><p>[1] C. Perkins, O. Hodson, and V. Hardman, "A survey of packet loss recovery techniques for streaming audio," IEEE Net- </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Receiver-based concealment: a) sequential recovery; b) parallel recovery.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Nonlinear manifold constraint of audio signals: overlapped frames of length p correspond to points in the frame space R p .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. a) alternating projections in PDAC; b) EM-PDAC (PDAC is contained as the inner-loop).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Top-left: damaged signal; top-right: error signal of LP-PLC (SN R = 5.97dB); bottom-left: error signal of WS-OLA (SN R = 8.38dB); bottom-right: error signal of PDAC (SN R = 13.58dB).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. MSE profile of PDAC algorithm when FFT (dotted) and DCT (solid) are used as the sparsifying transforms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. SNR(dB) profile of EM-PDAC algorithm (note that SNR improves again after 13th iteration where outer loop proceeds).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. SNR(dB) profile of FB-PDAC algorithm (note that it degenerates to PDAC when k = 1).</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A new technique for audio packet loss concealment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sanneck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stenger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Younes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Girod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings IEEE Globalcom</title>
		<meeting>IEEE Globalcom</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="48" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Concealment of lost speech packets using adaptive packetization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sanneck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICMCS</title>
		<meeting>of ICMCS</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Model-based multirate representation of speech signals and its application to recovery of missing speech packets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-S</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Speech and Audio Processing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="220" to="231" />
			<date type="published" when="1997-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A survey of errorconcealment schemes for real-time audio and video transmissions over the internet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISMSE</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Feature selection: Evaluation, application, and small sample performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zongker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="153" to="158" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Group</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Discrete-Time Processing of Speech Signals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Proakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hansen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>MacMillan</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Nonlinear Dimensionality Reduction by Locally Linear Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5500</biblScope>
			<biblScope unit="page" from="2323" to="2326" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Ergodic theory and information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Billingsley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1965" />
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Nonlinear approximation based image recovery using adaptive sparse reconstructions and iterated denoising-part ii: adaptive algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">G</forename><surname>Guleryuz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="555" to="571" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Multirate Systems and Filter Banks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vaidyanathan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Prentice Hall</publisher>
			<pubPlace>New Jersey; Englewood Cliffs</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Neural networks and physical systems with emergent collective computational abilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Hopfield</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="page" from="457" to="464" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
