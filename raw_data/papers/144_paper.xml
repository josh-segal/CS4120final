<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:31+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TLC: Transmission Line Caches</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradford</forename><forename type="middle">M</forename><surname>Beckmann</surname></persName>
							<email>beckmann@cs.wisc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Sciences Department</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Sciences Department</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">TLC: Transmission Line Caches</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>It is widely accepted that the disproportionate scaling of transistor and conventional on-chip interconnect performance presents a major barrier to future high performance systems. Previous research has focused on wire-centric designs that use parallelism, locality, and on-chip wiring bandwidth to compensate for long wire latency. An alternative approach to this problem is to exploit newly-emerging on-chip transmission line technology to reduce communication latency. Compared to conventional RC wires, transmission lines can reduce delay by up to a factor of 30 for global wires, while eliminating the need for repeaters. However, this latency reduction comes at the cost of a comparable reduction in bandwidth. In this paper, we investigate using transmission lines to access large level-2 on-chip caches. We propose a family of Transmission Line Cache (TLC) designs that represent different points in the latency/bandwidth spectrum. Compared to the recently-proposed Dynamic Non-Uniform Cache Architecture (DNUCA) design, the base TLC design reduces the required cache area by 18% and reduces the interconnection network&apos;s dynamic power consumption by an average of 61%. The optimized TLC designs attain similar performance using fewer transmission lines but with some additional complexity. Simulation results using full-system simulation show that TLC provides more consistent performance than the DNUCA design across a wide variety of workloads. TLC caches are logically simpler than DNUCA designs, but require greater circuit and manufacturing complexity.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The disproportionate scaling of VLSI interconnect and transistor performance has been recognized as a key challenge for future high performance systems <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b36">35]</ref>. This problem manifests itself most strongly in global wires that communicate across a large fraction of a chip. For example, sending a signal across a 2 cm die required only one to two clock cycles at the beginning of this decade <ref type="bibr" target="#b13">[13]</ref>, but will take over 25 cycles by its end for aggressively clocked processors <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b18">18]</ref>.</p><p>The problem of slow global wires has prompted substantial microarchitectural research to reduce their impact on system performance <ref type="bibr" target="#b31">[30,</ref><ref type="bibr" target="#b32">31]</ref>. For example, <ref type="bibr">Kim et al.</ref> recently proposed a novel design for large on-chip level-2 caches, which are increasingly performance critical due to longer memory latencies, more pressing power constraints, and limited off-chip bandwidth <ref type="bibr" target="#b25">[24]</ref>. Their Dynamic Non-Uniform Cache Architecture (DNUCA) is a physical organization that exploits the fact that closer cache banks can be accessed more rapidly than more distant banks. DNUCA achieves impressive performance improvements over other alternatives, but introduces significant logical complexity, along with power and area inefficiencies.</p><p>An emerging alternative approach to the slow global wire problem is to use on-chip transmission lines <ref type="bibr" target="#b8">[8]</ref>. Transmission lines exhibit much lower latencies than conventional wires since their signalling speed is dominated by a relatively short inductive-capacitance (LC) delay rather than a series of a relatively large resistive-capacitance (RC) delays <ref type="bibr" target="#b0">1</ref> . The speed of the incident wave across a transmission line is analogous to the speed of a ripple moving across water in a bathtub, while the latency across conventional RC wires is analogous to changing the water level of the bathtub.</p><p>Despite their substantial speed advantage-up to a factor of 30 by the end of the decade-transmission lines will not replace most conventional on-chip wires because they sacrifice significant bandwidth. Transmission lines require very wide, thick wires and dielectric spacing to operate in the LC range, which are only available in the uppermost layers of a chip's interconnection metal stack. These extremely sparse metal layers are best utilized for This work was supported by the National Science Foundation (CDA-9623632, EIA-9971256, EIA-0205286, and CCR-0324878), a Wisconsin Romnes Fellowship (Wood), and donations from Intel Corporation and Sun Microsystems, Inc. Dr. Wood has a significant financial interest in Sun Microsystems, Inc.</p><p>1. In other words, the latency of a transmission line to the first order is determined by the speed of light in the dielectric surrounding the interconnect instead of the time to change the charge across the wire's capacitance. the few long distance communication links whose latency can have a significant impact on overall system performance.</p><p>In this paper, we explore using transmission lines for communication between the storage banks of large onchip caches and their central controllers. We refer to these caches as Transmission Line Cache (TLC) designs. By using long on-chip transmission lines, TLC achieves the following advantages over DNUCA:</p><p>• TLC provides consistent high performance for a wide variety of workloads with different sized memory footprints because its entire storage is accessible within 16 cycles using low contention point-to-point links.</p><p>• TLC's simple logical design eases logical verification and integration with dynamic instruction schedulers.</p><p>• By eliminating repeaters and communicating through on-chip transmission lines that can be routed over the cache banks, TLC consumes 18% less substrate area than DNUCA and allows for more efficient layout.</p><p>• TLC reduces the power consumed within the communication network of a large on-chip cache. However TLC does have the following disadvantages compared to DNUCA:</p><p>• TLC's transmission line drivers and receivers require a greater circuit verification effort to ensure proper signalling in the noisy environments of future integrated circuits.</p><p>• TLC demands significantly more metal layers resulting in a higher per wafer manufacturing cost than the DNUCA design, which uses conventional interconnect.</p><p>The rest of the paper is organized as follows. Section 2 reviews the global wire problem and how the DNUCA design addresses it. Section 3 discusses on-chip transmission lines and the technology assumptions we made for this study. Section 4 describes the family of TLC designs. Section 5 and Section 6 describe the methodology and results of our simulation experiments that compare the performance of TLC and DNUCA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Wire Delay and Caches</head><p>As previously mentioned, the delay of conventional interconnect relative to transistors is increasing as integrated circuits move to smaller geometries. Global wires (&gt; 1 mm) are particularly vulnerable because the RC delay of conventional interconnect grows quadratically with distance <ref type="bibr" target="#b43">[42]</ref>. To keep wire delay linear with distance, designers insert repeaters to break long wires into multiple shorter segments. However, increasing wire density and operational frequencies dictate an increasing number of repeaters.</p><p>Overall, the use of repeaters for global communication leads to three key problems <ref type="bibr" target="#b17">[17]</ref>:</p><p>• Repeaters require a substantial amount of area for their large transistors.</p><p>• Repeaters necessitate disciplined floorplanning to allocate the necessary substrate area at the proper locations.</p><p>• Repeaters need many via cuts from the upper metal layers down to the substrate, which congest the interconnection layers below and reduce the overall wire bandwidth.</p><p>Furthermore, more localized (&lt; 1 mm) wire delay is also a significant factor in the design of on-chip caches. For instance, current level-2 caches are divided into multiple smaller banks to optimize the individual bank's area/delay tradeoff <ref type="bibr" target="#b26">[25]</ref>. While partitioning a cache into banks mitigates the impact of localized wire delay, the global wire delay to access the appropriate banks becomes the dominant factor as chips move to smaller geometries. Kim et al. <ref type="bibr" target="#b25">[24]</ref> showed that-for a 16 MB L2 cache in the 45 nm generation-the delay to reach individual banks ranged from 3 to 47 cycles. Clearly, a conventional cache with uniformly slow access time would have unacceptable latency and bandwidth. <ref type="bibr">Kim et al. address</ref> this problem by defining a family of Non-Uniform Cache Architecture (NUCA) designs. Similar to <ref type="figure" target="#fig_1">Figure 1</ref>, all practical NUCA designs assume a 2D array of cache banks accessed via a 2D switch interconnect implemented using conventional RC-delay wires. The dedicated communication channels between the cache banks reserve the necessary substrate area for the data link's repeaters. The static, or SNUCA, designs use loworder address bits to determine which cache blocks map to each bank. The dynamic, or DNUCA, designs exploit locality by migrating frequently accessed blocks to the cache banks closest to the controller. Dynamic placement reduces the average access time, but introduces significant additional design complexity, power consumption, and bandwidth demand.</p><p>The DNUCA design is a very large (+30-way) setassociative cache, with banks grouped into different bank sets where a given block address may reside. A reference that hits in the closest two banks of a bank set, a close hit, takes the minimum time, but a miss may require a search of all the remaining banks in the bank set. DNUCA uses a partial tag structure to avoid this worst case for most accesses. The partial tag structure stores the six least significant bits of all tags and is accessed in parallel with the closest two banks of the bank set. If a request misses in the closest banks, the partial tag comparison indicates which other banks need to be searched. In some cases, the partial tag check indicates that no other banks need be search, a so-called fast miss. Partial tags improve performance directly, by reducing searches, and indirectly, by reducing interconnect link contention.</p><p>While partial tags provide many benefits, keeping them consistent with the cache contents introduces significant complexity. In particular, the partial tags must be updated when blocks migrate to closer banks. Due to contention in the mesh network, blocks are not guaranteed to move from one bank to the other in a fixed time. Thus a complex synchronization mechanism is required to ensure that blocks are not missed during a search. While these complications are certainly manageable, they represent a significant additional design and verification effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">On-chip Transmission Lines</head><p>Printed-circuit board and other off-chip wire technologies are commonly designed to behave as transmission lines <ref type="bibr" target="#b10">[10]</ref>. Conversely, although on-chip transmission lines using non-conventional technology have been explored for over 20 years <ref type="bibr" target="#b39">[38]</ref>, on-chip wires using CMOS technology are normally designed to operate as lossy RC lines <ref type="bibr" target="#b42">[41]</ref>. But with improving fabrication technology, on-chip transmission lines are starting to emerge in CMOS circuits. For example, several current high performance chips use transmission lines for the long global wires (~ 0.75 cm) used for clock distribution <ref type="bibr" target="#b30">[29,</ref><ref type="bibr" target="#b41">40,</ref><ref type="bibr" target="#b44">43]</ref>. Longer (&gt; 1 cm) transmission lines operating in the 7.5-10 GHz frequency range have been shown to work on CMOS test chips using very wide wires <ref type="bibr" target="#b8">[8]</ref> or low operating temperatures <ref type="bibr" target="#b11">[11]</ref>. With the introduction of lower-k dielectrics <ref type="bibr" target="#b7">[7]</ref> and increasing on-chip frequencies <ref type="bibr" target="#b18">[18]</ref>, more practical on-chip transmission lines will be available before the end of the decade.</p><p>In this paper, we explore on-chip transmission line communication. Specifically, we investigate using singleended voltage-mode signalling, where standard voltage signals propagate across a single point-to-point link. To reduce reflection noise across these relatively low loss transmission lines, we assumed source-terminated drivers with digitally-tuned resistance <ref type="bibr" target="#b10">[10]</ref>. Receivers use a large input impedance termination for full wave reflection of the received signal. Single-ended voltage-mode signalling best fits the low utilization of on-chip interconnection networks.</p><p>The physical transmission line is a single long wire that is routed directly from the driver to the receiver without repeaters. Because of the length of transmission lines, thicker and wider metal tracks are required to maintain low wire resistance. Additionally, thicker intermetal dielectrics are necessary to control wire capacitance on these long fat wires so that they can operate as transmission lines. These transmission lines must be laid out in stripline fashion with a reference plane both above and below the transmission line metal layer to provide low resistance return paths for inductive induced currents <ref type="bibr" target="#b33">[32]</ref>. While transmission line dimensions are much larger than the dimensions proposed for future conventional interconnect, they are actually very similar to the upper metal layers of previous high performance processors <ref type="bibr" target="#b6">[6]</ref> and current silicon microwave chips <ref type="bibr" target="#b34">[33]</ref> At these large wire dimensions, the "skin effect" significantly increases the signals' susceptibility to noise. The skin effect phenomenon arises because at high frequencies, magnetic repulsion forces current towards the perimeter of the conductor, thereby reducing the wire's effective cross section. Thus higher frequency signals encounter effective resistances greater than the wire's DC resistance. This effect is compounded by the fact that a digital pulse is composed of many sinusoidal signals of different frequencies. Because the different components of a digital pulse encounter different effective resistances, the receiver sees a signal that is rounded and stretched out. Noise is a significant issue when receiving these attenuated signals.</p><p>To reduce the noise susceptibility, we propose using alternating power and ground shielding <ref type="bibr" target="#b23">[22]</ref> lines between each transmission line, in addition to the reference planes above and below the signal layer. Laying out the lines in this manner not only provides several individual low-resistive return paths, but also isolates each line from most capacitive and inductive cross-coupling noise.</p><p>Adding metal layers for reference planes will add significant manufacturing cost to the chip compared to con-  <ref type="formula">11 0 0 1 1 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1   00 00 11 11 0 0 1 1 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1   00 00 11 11 0 0 1 1 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1   00 00 11 11 0 0 1 1 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1   00 00 11 11 0 0 1 1 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1   00 00 11 11 0 0 1 1 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1 00 00 11 11 0 0 1 1</ref> 00 00 00 11 11 11 0 0 0 1 1 1 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 11 11 11 0 0 0 1 1 1 00 00 00 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>. 16 MB DNUCA Block Diagram</head><p>ventional CMOS technology. However, the International Technology Roadmap for Semiconductors already projects, for the year 2010, integrating four reference planes into high performance chips to provide inductive shielding and decoupling capacitance <ref type="bibr" target="#b14">[14]</ref>. Only time will tell if the benefits of transmission lines will justify their cost, but the history of silicon processing shows us that many complex and expensive enhancements have been adopted, including copper wires <ref type="bibr" target="#b13">[13]</ref> and SOI devices <ref type="bibr" target="#b9">[9]</ref>. We believe on-chip transmission lines could be the next manufacturing enhancement that drives system performance into the next decade.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Transmission Line Cache Designs</head><p>One interesting opportunity for on-chip transmission lines is as a low latency interface between the cache's storage and its controller. We targeted our Transmission Line Cache designs for the 45 nm technology generation <ref type="bibr" target="#b14">[14]</ref>, with an aggressive CPU core operating frequency of 10 GHz <ref type="bibr" target="#b18">[18]</ref>. At this design point, the tremendous speed advantage of transmission lines will not only provide improved cache performance, but will also permit trading off some performance for a simpler design consuming less area and power. We analyze a 16MB TLC to allow direct comparison with the 16 MB DNUCA design using the same technology assumptions <ref type="bibr" target="#b25">[24]</ref>.</p><p>TLC exploits the tremendous speed and layout benefits of transmission lines to decouple the cache storage from the cache controller. Because transmission lines can quickly communicate across long distances without using repeaters, the large storage area of the cache can consume the less valuable real estate on the edges of the chip, while the cache controller can be moved to the center of the chip where it can be quickly accessed by the processor core. This design is less feasible using conventional global wires because of their intermediate repeater requirement discussed previously. Conversely, the on-chip transmission lines used by TLC don't require repeaters and can be routed over other logic without congesting intermediate wiring tracks and the substrate area below. <ref type="figure" target="#fig_3">Figure 2</ref> shows the high-level floorplan for the base TLC design. This cache is composed of 32-512 KB banks where half the banks line one edge of the die and the other half line the opposite edge. The space between the banks would be consumed by the processor core and L1 caches. On each edge, the banks are stacked in two columns of eight. Each pair of adjacent banks share two eight-byte wide unidirectional transmission line links to the L2 cache controller, creating a high bandwidth, low latency interface between the controller and the storage banks.</p><p>Because the individual transmission lines vary in length, we adjust their width to maintain appropriate resistance and capacitance, as shown in <ref type="figure" target="#fig_2">Figure 3</ref> and <ref type="table">Table 1</ref>. The width of the transmission lines used in TLC determine the size of a cache controller. The cache controller must be tall enough so that all the transmission line links can connect with it. The cache controller must be wide enough so that the each link has a direct connection to the center of the controller where the cache request originates. The TLC cache controller uses conventional wires to communicate between the transmission lines located on its edges and the controller logic located at its center. These conventional wires add up to three additional delay cycles to the TLC access times.</p><p>As mentioned in the previous section, transmission lines are increasingly sensitive to noise corruption. To further compensate for skew due to discontinuities across the transmission lines, we enforce extremely conservative setup and hold times of at least 40% of the entire clock cycle for the TLC signals. Remaining faults on the transmission lines could be repaired using end-to-end ECC checks. For instance, the IBM Power 4 already performs ECC checks when accessing the on-chip L2 cache <ref type="bibr" target="#b38">[37]</ref>. End-to-end ECC simply means generating and checking the codes in the central controller. We believe that these measures are enough to ensure that single-ended voltage-mode transmission lines will perform correctly in the noisy environments of future chips. If one desires extra reliability, there are other techniques to increase noise immunity such as Optimized Transmission Line Caches. The high bandwidth interface of the base TLC design comes at considerable cost in wire area. We anticipate that extra metal layers will be required to implement the transmission lines needed by the base TLC design. As a cheaper alternative, we consider optimized TLC designs that require fewer transmission lines, perhaps permitting their integration into the existing uppermost metal layers. <ref type="figure">Figure 4</ref> introduces the top level floorplan of these designs and <ref type="table" target="#tab_0">Table 2</ref> summarizes the parameters of our entire family of TLC designs.</p><p>The Optimized TLC designs (TLCopt) are able to reduce the number of required wires through three methods:</p><p>• Storing the 64-byte cache block across multiple banks to reduce the amount of data needed to be transferred between the cache controller and an individual bank per cache request.</p><p>• Doubling the cache bank size from 512KB to 1MB thus reducing the number of banks the cache controller interfaces with by half.</p><p>• Supplying each bank with only enough address information to access the correct set and perform a 6-bit partial tag <ref type="bibr" target="#b21">[21]</ref> comparison. The full tag comparison is performed later at the cache controller.</p><p>In these designs, each bank is responsible for storing only a portion of the most significant bits of the cache tag along with the lower 6-bits of the tag. The bank uses this 6-bit partial tag to do a quick comparison, determining if a request hits. Because all banks holding a block store the same lower 6-bit partial tag, all tag comparisons among them will have the same result. When the banks respond to a load request, they send its higher order tag bits along with the data to the cache controller which performs the full tag comparison. In the infrequent case of multiple partial tag matches, the banks respond with the high order tag bits of all matching entries. The controller determines which set entry, if any, actually matches, and then request the specific block. Because all our TLC designs are exclusive write-back caches, store requests are simply written to the cache without requiring any tag comparisons.</p><p>As an additional benefit of using fewer transmission lines, the TLCopt designs require smaller cache controllers. This is because the TLC cache controller's height is </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Methodology</head><p>Our evaluation methodology can be broken down into two separate parts. First, we designed and simulated the physical on-chip transmission lines used by TLC. Second, we evaluated the performance and estimated the dynamic power consumption of TLC as it compares to DNUCA using a full-system simulator.</p><p>Physical Evaluation. The goal of our physical evaluation was to first investigate the usage of on-chip transmission lines in future technology and then to evaluate their performance. We started by using Linpar <ref type="bibr" target="#b12">[12]</ref>, a 2-dimensional field-solver program, to extract the inductance, resistance and capacitance characteristics of on-chip transmission lines. Once we had RLC matrices describing the transmission lines, we simulated 10 GHz pulses travelling across the lines using HSPICE. Specifically, we modeled the transmission line's frequency dependent attenuation with HSPICE's W element transmission line model. We simulated four signal wires with shielding wires separating each of them under worst case signalling conditions. We took the output waveforms to determine the latency of the transmission lines, as well as ensured the received signals had an amplitude of at least 75% of V dd and a pulse width of at least 40% of the processor cycle time.</p><p>We used the tool ECACTI <ref type="bibr" target="#b0">[1]</ref> to determine the access latency and layout of the cache banks. Our models for delay <ref type="bibr" target="#b3">[3]</ref>, gate capacitance <ref type="bibr" target="#b17">[17]</ref>, and transistor sizes <ref type="bibr" target="#b35">[34]</ref> allowed us to estimate the size and power of future interconnect as well as the switches used in NUCA <ref type="bibr" target="#b24">[23,</ref><ref type="bibr" target="#b40">39]</ref>.</p><p>Performance Evaluation. We evaluated the system performance of each cache design using a dynamically scheduled SPARC V9 uniprocessor. To simulate our target system, we used the full system simulator Simics <ref type="bibr" target="#b27">[26]</ref> extended with a detailed processor <ref type="bibr" target="#b28">[27]</ref> and memory system timing model. Our detailed memory timing simulator for DNUCA and TLC included modelling contention within the links, switches and banks in each design. <ref type="table" target="#tab_1">Table 3</ref> summarizes our simulation parameters.</p><p>We evaluated all cache designs using 12 different benchmarks: four SPECint 2000 benchmarks (bzip, gcc, mcf, and perl), four SPECfp 2000 benchmarks (equake, lucas, swim, and applu) <ref type="bibr" target="#b37">[36]</ref>, and four commercial benchmarks described in <ref type="table" target="#tab_3">Table 5</ref>  <ref type="bibr" target="#b1">[2]</ref>. We warmed up the caches, as shown in Column 3 of <ref type="table" target="#tab_2">Table 4</ref>, then evaluated each design over the amount of work indicated in Column 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation Results</head><p>This section evaluates the impact of TLC on a future high performance microprocessor. Section 6.1 shows that the base TLC design provides comparable overall performance to DNUCA while providing more predictable behavior and consuming less area and power within the interconnect. Section 6.2 evaluates the link utilization of all the TLC designs and shows that the TLCopt designs can attain similar performance to the base TLC design, while using significantly fewer wires.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">TLC vs. DNUCA</head><p>Overall Performance. <ref type="figure" target="#fig_5">Figure 5</ref> compares the normalized execution time of the DNUCA and base TLC designs using the statically partitioned SNUCA2 cache design as a baseline <ref type="bibr" target="#b25">[24]</ref>. SNUCA2 is the static NUCA design using a two-dimensional grid interconnect. Except for some of the SPECFP benchmarks, both TLC and DNUCA significantly improve overall system performance compared to SNUCA2. The lack of performance impact TLC and DNUCA have on the SPECfp benchmarks, lucas, swim, and applu, is due to the extremely high L2 miss rates of these benchmarks, as shown in Columns 3 and 4 of Table 6 <ref type="bibr" target="#b15">[15]</ref>. DNUCA is particularly hurt by the low temporal locality and high miss rates of the swim and applu benchmarks. DNUCA inserts all data blocks brought in from memory into the furthest banks from the cache controller and then promotes the blocks to its closer, quickly accessible banks every time the block is accessed. This promotion policy relies on the expectation that most cache requests will be for a small set of frequently accessed blocks. However, in benchmarks where most requests miss in the cache, this policy fails to improve cache access times. This behavior is shown by the low ratio of DNUCA block promotions to block insertions for these two SPECfp benchmarks, Column 6 of <ref type="table" target="#tab_4">Table 6</ref>.</p><p>The fourth SPECfp benchmark, equake, is particularly interesting. Equake uses a finite element method on sparse matrices to simulate seismic waves propagating in a * 4-way set associative, with LRU replacement    <ref type="bibr" target="#b5">[5]</ref> to generate web requests. We use a repository of 80,000 files (totaling ~2 GB). These files are fetched by 400 clients. Java Server Workload: SPECjbb (Sjbb). SPECjbb2000 is a server-side java benchmark that models a 3-tier system, focusing on the middleware server business logic. We use Sun's HotSpot 1.4.0 Server JVM. Our experiments use 24 threads and 24 warehouses (a data size of ~500MB per warehouse).</p><p>Online Transaction Processing (OLTP): DB2 with a TPC-C-like workload. The TPC-C benchmark models the database activity of a wholesale supplier, with many concurrent users performing transactions. Our OLTP workload is based on the TPC-C v3.0 benchmark using IBM's DB2 v7.2 EEE database management system. We use an 5GB database with 25000 warehouses stored on eight raw disks and an additional dedicated database log disk. We reduced the number of districts per warehouse, items per warehouse, and customers per district to allow for concurrency provided by a larger number of warehouses. There are 16 simulated users.</p><p>large basin <ref type="bibr" target="#b4">[4]</ref>. Like the other three SPECfp benchmarks, equake streams through a lot of data, but Equake also has a large data set that it frequently accesses. DNUCA's frequency replacement policy separates the two groups of data within its highly associative sets, so that the streaming data does not evict the frequently accessed data. On the other hand, TLC's LRU replacement policy is unable to disambiguate between the two data sets leading to a higher miss rate and lower performance for this benchmark.</p><p>Figure 5 also shows DNUCA and TLC perform very well for the SPECint and commercial workloads that have much lower miss rates. While DNUCA significantly improves performance for these workloads which have a high percentage of hits to the closest banks of cache, TLC significantly improves the performance of workloads like mcf which has a large memory footprint <ref type="bibr" target="#b15">[15]</ref>. Overall, TLC moves the cache storage away from the processor core, while providing comparable performance improvement to DNUCA over the set of benchmarks.</p><p>Performance Predictability. TLC exhibits more predictable performance than DNUCA because it provides a more consistent response latency for L2 cache accesses. Therefore an instruction scheduler can rely on TLC's predictable latency for scheduling dynamic operations, thus simplifying its circuits. Additionally, schedulers performing speculative memory scheduling on L2 accesses will encounter significantly fewer replays using TLC.</p><p>TLC's statically partitioned banks and high bandwidth interface enable TLC to provide more consistent lookup latency than DNUCA. <ref type="figure" target="#fig_6">Figure 6</ref> plots the mean cache lookup latency for the two cache designs over all twelve benchmarks. As expected, TLC encounters more bank contention due to its fewer banks and longer bank access latencies, while DNUCA encounters more contention in the routing network to and from the banks. The key observation is that TLC offers a more consistent mean lookup latency of around 13 cycles for all the benchmarks, while the mean lookup latency of DNUCA varies tremendously among benchmarks.</p><p>Columns 7 and 8 of <ref type="table" target="#tab_4">Table 6</ref> compare the predictability of lookup latency for the TLC and DNUCA designs.  Column 7 shows that 10% or less of TLC lookup latencies are mispredicted for all but mcf. Column 8 shows that at least 40% of DNUCA lookups are mispredicted, for twothirds of the benchmarks. Because TLC has a predictable lookup latency and a high fraction of non-delayed requests, TLC can be easily integrated into a dynamic instruction scheduler, while the wide variation of access times for DNUCA significantly complicates dynamic instruction scheduling.</p><p>Furthermore, as pipelines become deeper with a greater distance between when the instruction issue and execution stages, we believe aggressive dynamic schedulers will perform speculative memory scheduling on L2 accesses. Speculative memory scheduling is a technique performed by current high performance microprocessors to improve the load-to-use latency between instructions. Rather than waiting for a cache "hit" signal, some processors with predictable cache lookup latencies <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b20">20]</ref> will either predict a load hits in the cache and speculatively issue the load's dependent instructions or predict that the load misses and issue other independent instructions instead. Speculative memory scheduling reduces load-touse latency by allowing dependent instructions to meet their source data at the execution units as soon as possible, while not wasting valuable issue bandwidth in the scheduler. However, when the scheduler mispredicts that a load will hit in the cache, the speculatively issued dependent instructions must be replayed.</p><p>Speculative memory scheduling on L2 accesses is significantly more difficult due to their difficult to predict access latencies. One solution is to access the L2 cache tags early to provide a hint of when the data will arrive. For example, Itanium 2 <ref type="bibr" target="#b29">[28]</ref> uses a centralized tag structure to provide early hit or miss indication for its 256KB L2 cache.</p><p>However, due to increasing wire delays, a centralized cache tag structure for future large on-chip caches may be impractical. For instance the tag array for a 16 MB cache is nearly 1 MB, accessing such a large tag array will add several cycles of unnecessary latency to many cache lookups. Instead, we believe future large caches will use a more distributed design and be partitioned into banks of tag and data arrays. These more distributed caches, like the NUCA caches, will have much lower mean access times than a centralized cache of similar size. However, the wide variance in their access times will only add to the nondeterminism of their accesses. On the other hand, TLC has very predictable lookup latency and therefore could be easily integrated into future aggressive schedulers.</p><p>Area. Although TLC requires additional metal layers, it significantly reduces substrate area and hence overall die size. <ref type="table" target="#tab_5">Table 7</ref> breaks down the substrate area requirements of DNUCA and TLC. <ref type="table" target="#tab_5">Table 7</ref> shows that the latency benefit of DNUCA's smaller banks comes at an increased cost in bank area (Column 2) and an even greater increased cost in routing channel area (Column 3). Column 4 shows that the DNUCA partial tag structure adds a relatively small amount to the total cache area. On the other hand, TLC's large dense banks and lack of repeaters in the communication network saves storage and channel area, though its cache controller area is much larger due to its interface with the wide transmission line wires. Overall, TLC reduces substrate area by 18% compared to DNUCA.</p><p>Power. Current low-power, low-voltage drivers <ref type="bibr" target="#b19">[19]</ref> for off-chip transmission lines consume too much static   λ λ power to be implemented for low utilized on-chip signals.</p><p>Instead, TLC uses a more traditional single-ended voltagemode driver with active high signalling. These drivers not only save power as compared to their contemporary lowvoltage counterparts, but actually allow TLC to consume less power than a cache using conventional RC interconnect. The rest of this section breaks down both the TLC and DNUCA interconnection networks' static and dynamic power consumption to show how TLC can save power compared to DNUCA.</p><p>While determining the exact static power consumption is difficult early in the design process, it is well understood that static power is dominated by transistor leakage current which is directly dependent on transistor width <ref type="bibr" target="#b35">[34]</ref>. By removing intermediate switches, latches, and repeaters, as well as not requiring a partial tag array, TLC significantly reduces the transistor demand of the cache communication network. As shown in <ref type="table" target="#tab_6">Table 8</ref>, we estimate an over 50 fold reduction of transistors for TLC in comparison to DNUCA. <ref type="table" target="#tab_6">Table 8</ref> also indicates the total transistor gate width would be reduced by over an order of magnitude. Therefore the TLC communication network will save leakage power versus the DNUCA network.</p><p>Dynamic power dissipation is dependent on the signalling strategy of the interconnect. Signalling across conventional RC interconnect using repeaters relies on charging and discharging the capacitance of each wire segment from one voltage value to another. Therefore for conventional signalling, dynamic power equals the power required to change the voltage, V, across the wire's total capacitance, C, for a given frequency, f, and data activity factor, <ref type="bibr" target="#b35">[34]</ref>:</p><p>In voltage-mode transmission line signalling, the dynamic power consumed is the power required to create the incident wave. At the driver, the transmission line looks like a resistor equal to the characteristic impedance of the line. Therefore the power supplied by the driver is determined by voltage across its internal resistance, R D , in series with the transmission line's characteristic impedance, Z 0 , for the duration of the signal pulse, t b , <ref type="bibr" target="#b10">[10]</ref>:</p><p>Comparing the dynamic power dissipation of matched voltage-mode transmission lines (R D = Z 0 ) to that of conventional wires, one sees that when , transmission lines will consume less dynamic power than conventional interconnect. As cycle times continue to decrease, this relationship will hold for long global links beyond ~1 cm in length. <ref type="table" target="#tab_7">Table 9</ref> compares the dynamic power components of the two cache designs. While the total amount of dynamic power is relatively small for both designs, TLC does reduce dynamic power dissipation within the communication network by utilizing on-chip transmission lines. TLC also significantly reduces the number of banks accessed per cache request leading to a greater reduction in dynamic power consumption as compared to DNUCA. </p><formula xml:id="formula_0">α Conventional Signalling Dynamic Power α C V 2 f × × × = Transmission Line Dynamic Power α t × b V 2 R D Z 0 + ( ) -------------------------- × f × = t b 2 Z 0 × ( ) ⁄ C &lt;</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">The Family of TLC designs</head><p>This section evaluates link utilization for the family of TLC designs and shows that similar performance to the base TLC design can be achieved using significantly fewer wires. Link utilization is the percentage of cycles where the transmission lines actually communicate data. <ref type="figure" target="#fig_7">Figure 7</ref> plots the average link utilization for each TLC design across the spectrum of benchmarks. One should first notice that the base TLC link utilization never exceeds 2% for any benchmark and for most benchmarks it hovers below 1%. This extremely low utilization shows that the base TLC design has more bandwidth than necessary. As expected, the TLCopt designs have an increasing degree of link utilization consistent with their reduction in transmission line wires. However, even the utilization of the TLCopt 350 design remains relatively low, never surpassing 13%. <ref type="figure">Figure 8</ref> shows that this increase in link and bank contention for the TLCopt designs does not translate into a significant performance degradation compared to the base TLC design. For some benchmarks, the TLCopt designs achieve slight improvements in execution time due to their slightly lower cache access latencies <ref type="table" target="#tab_0">(Table 2)</ref>. Overall multiple partial tag matches in the TLCopt designs occurred in approximately 1% of the cache lookups, thus the increased messages sent between the cache controller and the banks has little effect on performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We have proposed an alternative family of cache designs using emerging on-chip transmission line technology. On-chip transmission lines offer a significant latency advantage to conventional global interconnect for communicating distances greater than a few millimeters. However, due to their power and bandwidth characteristics, onchip data transmission lines will be practically limited to long (&gt; 1cm) performance critical signals.</p><p>TLC is one such application of on-chip transmission lines. Our TLC designs perform comparably to the previous DNUCA strategy, while saving area and power. Furthermore, they provide a spectrum of reduced logical complexity solutions, but require significant circuit and manufacturing cost. To combat the increased wire demand of the base TLC design, we introduced three optimized TLC designs that consume less wires and perform comparably for most benchmarks. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1</head><label>1</label><figDesc>Figure 1. 16 MB DNUCA Block Diagram</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 also</head><label>3</label><figDesc>compares the dimensions of the transmission lines used in TLC with the dimensions of the conventional RC wires used in the DNUCA communication network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Base TLC Top Level Floorplan</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 . Cross-sectional comparison ( 45 nm technology)Figure 4 .</head><label>3454</label><figDesc>Figure 3. Cross-sectional comparison (45 nm technology)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Normalized Execution Time</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Mean Cache Lookup Latency (Cycles)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7</head><label>7</label><figDesc>Figure 7. TLC Average Link Utilizaiton</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 2 . Design Parameters</head><label>2</label><figDesc></figDesc><table>Design 
Banks 

Banks/ 
Block 

Bank 
Size 

Transmission 
Lines per Bank 
Pair 

Total 
Transmission 
Lines Used 

Uncontended 
Latency 

Bank 
Access 
Time 

TLC 

TLC 
32 
1 
512 KB 
128 
2048 
10 -16 cycles 
8 cycles 

TLCopt 1000 
16 
2 
1 MB 
126 
1008 
12 -13 
10 

TLCopt 500 
16 
4 
1 MB 
64 
512 
12 
10 

TLCopt 350 
16 
8 
1 MB 
44 
352 
12 
10 

NUCA 

SNUCA2 
32 
1 
512 KB 
n/a 
n/a 
9 -32 
8 

DNUCA 
256 
1 
64 KB 
n/a 
n/a 
3 -47 
3 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 3 . Simulation Setup</head><label>3</label><figDesc></figDesc><table>Memory System 
Dynamically Scheduled Processor 

split L1 I &amp; D caches 
64 KBytes, 2-way, 

3cycles 

reorder buffer / 

scheduler 

128 / 64 entries 

unified L2 cache 
16 MBytes, DNUCA 

or TLC* 

pipeline width 
4-wide fetch &amp; issue 

cache block size 
64 Bytes 
pipeline stages 
30 

memory latency 
300 cycles 
direct branch predictor 
3.5 kBytes YAGS 

memory size 
4 GBytes of DRAM 
indirect branch 

predictor 

256 entries (cascaded) 

outstanding memory requests 
8 
return address stack 
64 entries 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 4 . Evaluation Methodology</head><label>4</label><figDesc></figDesc><table>Benchmark 
Fast Forward 
Warm-up 
Executed 

SPECint 2000 
1 -5 Billion instr. 
500 Million instr. 
500 Million instr. 

SPECfp 2000 
500 Mill -3 Bill instr. 
1 Billion instr. 
500 Million instr. 

Apache 
500000 transactions 
2000 transactions 
2000 transactions 

Zeus 
500000 transactions 
2000 transactions 
2000 transactions 

SPECjbb 
1000000 transactions 
15000 transactions 
10000 transactions 

OLTP 
100000 transactions 
300 transactions 
250 transactions 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 5 . Commercial Workload Description</head><label>5</label><figDesc></figDesc><table>Static Web Servers (Apache &amp; Zeus): We use Apache 2.0.36 and Zeus 4.2 for SPARC/Solaris 9, configured to 
use pthread locks and minimal logging as the web server. We use SURGE </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 6 . Benchmark Characteristics</head><label>6</label><figDesc></figDesc><table>Bench 

Total L2 
Requests 

TLC 
L2 misses 
/ 1K instr. 

DNUCA 
L2 misses 
/ 1K instr. 

DNUCA 
close 
hit% 

DNUCA 
promotes / 
inserts 

TLC 
predictable 
lookup % 

DNUCA 
predictable 
lookup % 

bzip 
4.8 x 10 6 
0.051 
0.052 
81% 
64 
92% 
56% 

gcc 
3.8 x 10 7 
0.068 
0.070 
99 
610 
99 
62 

mcf 
5.5 x 10 7 
0.019 
0.019 
48 
12000 
82 
24 

perl 
2.6 x 10 6 
0.028 
0.028 
97 
9.7 
96 
90 

equake 
6.2 x 10 6 
6.8 
5.2 
16 
0.55 
90 
38 

swim 
2.4 x 10 7 
40 
38 
0.7 
0.15 
98 
39 

applu 
9.0 x 10 6 
16 
16 
1.0 
0.06 
98 
38 

lucas 
7.8 x 10 6 
13 
12 
7.2 
0.15 
99 
49 

apache 
1.5 x 10 7 
4.8 
3.8 
67 
3.7 
98 
61 

zeus 
1.4 x 10 7 
6.4 
4.8 
60 
2.5 
97 
57 

Sjbb 
7.1 x10 6 
2.3 
2.3 
58 
1.9 
93 
59 

oltp 
3.3 x 10 6 
0.93 
0.79 
89 
13 
98 
77 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 7 .</head><label>7</label><figDesc></figDesc><table>Consumed Substrate Area 

Cache 
Design 

Storage 
Area 

Channel 
Area 

Con-
troller 
Area 

Total 
Area 

DNUCA 
92 mm 2 
17 mm 2 
1.1 mm 2 110 mm 2 

TLC 
77 
3.1 
10 
91 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 8 .</head><label>8</label><figDesc></figDesc><table>Cache Communication Network 
Characteristics 

Cache 
Design 
Total Transistors 

Total Transistor 
Gate Width 

DNUCA 
1.2 x 10 7 
440 million 

TLC 
1.9 x 10 5 
20 million 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="true"><head>Table 9 . Dynamic Components</head><label>9</label><figDesc></figDesc><table>Benchmark 

DNUCA Banks 
Accessed/Request 

TLC Banks 
Accessed/Request 

DNUCA Network 
Dynamic Power 

TLC Network 
Dynamic Power 

bzip 
2.3 banks 
1 bank 
150 mW 
56 mW 

gcc 
2.0 
1 
150 
100 

mcf 
2.6 
1 
350 
150 

perl 
2.0 
1 
63 
36 

equake 
2.5 
1 
87 
23 

swim 
2.5 
1 
190 
56 

applu 
2.5 
1 
110 
34 

lucas 
2.5 
1 
57 
17 

apache 
2.4 
1 
200 
67 

zeus 
2.4 
1 
170 
53 

Sjbb 
2.4 
1 
130 
43 

oltp 
2.1 
1 
220 
90 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Peter Hsu for inspiring this work and giving us helpful feedback. We thank Doug Burger, Steve Keckler, Changkyu Kim and the Texas CART group for help with the DNUCA comparison. We thank Virtutech AB, the Wisconsin Condor group, and the Wisconsin Computer Systems Lab for their help and support. We thank Alaa Alameldeen, Brian Fields, Mark Hill, Mike Marty, Carl Mauer, Kevin Moore, Min Xu, the Wisconsin Computer Architecture Affiliates, and the anonymous reviewers for their comments on this work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The Effect of Technology Scaling on Microarchitectural Structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Keckler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<idno>TR-00-02</idno>
		<imprint>
			<date type="published" when="2001-05" />
		</imprint>
		<respStmt>
			<orgName>Department of Computer Sciences, University of Texas at Austin</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Simulating a $2M</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Alameldeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M K</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Mauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Sorin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Commercial Server on a $2K PC. IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="50" to="57" />
			<date type="published" when="2003-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Speed and Power Scaling of SRAMs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">S</forename><surname>Amrutur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Horowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="175" to="185" />
			<date type="published" when="2000-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Large-scale simulation of elastic wave propagation in heterogeneous media on parallel computers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bielak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ghattas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Kallivokas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>O&amp;apos;hallaron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Shewchuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Methods in Applied Mechanics and Engineering</title>
		<imprint>
			<biblScope unit="page" from="85" to="102" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generating Representative Web Workloads for Network and Server Performance Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Crovella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1998 ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems</title>
		<meeting>the 1998 ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems</meeting>
		<imprint>
			<date type="published" when="1998-06" />
			<biblScope unit="page" from="151" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A 300-MHz 64-b Quad-Issue CMOS RISC Microprocessor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Benschneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1203" to="1214" />
			<date type="published" when="1995-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fast Films</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Spectrum</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="36" to="40" />
			<date type="published" when="2003-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Near Speedof-Light Signaling Over On-Chip Electrical Interconnects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Talwalkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="834" to="838" />
			<date type="published" when="2003-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Design Considerations of SOI Digital CMOS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Chaung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE 1998 International SOI Conference</title>
		<meeting>the IEEE 1998 International SOI Conference</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="5" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Poulton</surname></persName>
		</author>
		<title level="m">Digital Systems Engineering</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Electrical Characteristics of Interconnections for HighPerformance Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Deutsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998-02" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="315" to="355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Matrix Parameters for Multiconductor Transmission Lines: Software and User&apos;s Manual. Artech House</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Djordjevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Bazdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>Harrington</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">T R</forename><surname>For Semiconductors</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Itrs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Edition. Semiconductor Industry Association</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">T R</forename><surname>For Semiconductors</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Itrs</surname></persName>
		</author>
		<ptr target="http://public.itrs.net/Files/2002Update/2002Update.pdf" />
	</analytic>
	<monogr>
		<title level="j">Update. Semiconductor Industry Association</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">SPEC CPU2000: Measuring CPU Performance in the New Millennium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Henning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="28" to="35" />
			<date type="published" when="2000-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The microarchitecture of the Pentium 4 processor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Upton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boggs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Carmean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kyker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Roussel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intel Technology Journal</title>
		<imprint>
			<date type="published" when="2001-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The Future of Wires</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Horowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="490" to="504" />
			<date type="published" when="2001-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The Optimal Logic Depth Per Pipeline Stage is 6 to 8 Inverter Delays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Hrishikesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">P</forename><surname>Jouppi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Keckler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shivakumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th Annual International Symposium on Computer Architecture</title>
		<meeting>the 29th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="2002-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">LVDS Provides Higher Bit Rates, Lower Power, and Improved Noise Performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kempainen</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The Alpha 21264 Microprocessor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Kessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="24" to="36" />
			<date type="published" when="1999-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Inexpensive Implementations of Set-Associativity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Kessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jooss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lebeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th</title>
		<meeting>the 16th</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<title level="m">Annual International Symposium on Computer Architecture</title>
		<imprint>
			<date type="published" when="1989-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A Novel VLSI Layout Fabric for Deep SubMicron Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Khatri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conference</title>
		<imprint>
			<date type="published" when="1999-06" />
			<biblScope unit="page" from="491" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Personal Communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An Adaptive, Non-Uniform Cache Structure for Wire-Dominated On-Chip Caches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Keckler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</title>
		<meeting>the 10th International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)</meeting>
		<imprint>
			<date type="published" when="2002-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Implementation of a ThirdGeneration 1.1-GHz 64-bit Microprocessor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">K</forename><surname>Konstadinidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of SolidState Circuits</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1461" to="1469" />
			<date type="published" when="2002-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Simics: A Full System Simulation Platform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Magnusson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="50" to="58" />
			<date type="published" when="2002-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Full System Timing-First Simulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Mauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems</title>
		<meeting>the 2002 ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems</meeting>
		<imprint>
			<date type="published" when="2002-06" />
			<biblScope unit="page" from="108" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Itanium 2 Processor Microarchitecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mcnairy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Soltis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="44" to="55" />
			<date type="published" when="2003-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Clock Distribution Networks with On-Chip Transmission Lines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minzuno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Anjo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sumi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fukaishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wakabayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mogami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Horiuchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yamashina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE 2000 International Interconnect Technology Conference</title>
		<meeting>the IEEE 2000 International Interconnect Technology Conference</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="3" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A Design Space Evaluation of Grid Processor Architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nagarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sankaralingam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Keckler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 34th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2001-12" />
			<biblScope unit="page" from="40" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Complexity-Effective Superscalar Processors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palacharla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th Annual International Symposium on Computer Architecture</title>
		<meeting>the 24th Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<date type="published" when="1997-06" />
			<biblScope unit="page" from="206" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Inductance on Silicon for Sub-micron CMOS VLSI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Priore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1993 Symposium on VLSI Circuits</title>
		<meeting>the 1993 Symposium on VLSI Circuits</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="17" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Ultra High Speed SiGe NPN for Advanced BiCMOS Technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Racanelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Electron Devices Meeting</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note>pages 15.3.1-15.3.4</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">BACPAC -Berkeley Advanced Chip Performance Calculator website</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sylvester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
		<ptr target="http://www-device.eecs.berkeley.edu/dennis/bacpac/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Getting to the Bottom of Deep Submicron II: a Global Wiring Paradigm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sylvester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1999 International Symposium on Physical Design</title>
		<meeting>the 1999 International Symposium on Physical Design</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="193" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Systems Performance Evaluation Cooperation</title>
		<ptr target="http://www.spec.org" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Tendler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dodson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fields</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sinharoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">POWER4 System Microarchitecture. IBM Server Group Whitepaper</title>
		<imprint>
			<date type="published" when="2001-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">JSP -A Research Signal Processor in Josephson Technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">F</forename><surname>Tsui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="243" to="252" />
			<date type="published" when="1980-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Orion: A PowerPerformance Simulator for Interconnection Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-S</forename><surname>Peh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 35th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2002-11" />
			<biblScope unit="page" from="294" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The Circuit and Physical Design of the POWER4 Microprocessor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Warnock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="51" />
			<date type="published" when="2002-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Principles of CMOS VLSI Design: A Systems Perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Weste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Eshragian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982" />
			<publisher>Addison-Wesley Publishing Co</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Delay Models and Speed Improvement Techniques for RC Tree Interconnections Among Small-Geometry CMOS Inverters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-C</forename><surname>Shiau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Solid-State Circuits</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1247" to="1256" />
			<date type="published" when="1990-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The Design and Analysis of the Clock Distribution Network for a 1.2 GHz Alpha Microprocessor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xanthopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K G</forename><surname>Atul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gangwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">K</forename><surname>Prewitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE 2001 International Solid-State Circuits Conference</title>
		<meeting>the IEEE 2001 International Solid-State Circuits Conference</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="402" to="403" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
