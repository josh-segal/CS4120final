<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Toward Integrating Word Sense and Entity Disambiguation into Statistical Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
							<email>marine@cs.ust.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Center HKUST Department of Computer Science</orgName>
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihai</forename><surname>Shen</surname></persName>
							<email>shenyh@cs.ust.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Center HKUST Department of Computer Science</orgName>
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofeng</forename><surname>Yu</surname></persName>
							<email>xfyu@cs.ust.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Center HKUST Department of Computer Science</orgName>
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Human Language Technology Center HKUST Department of Computer Science</orgName>
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Toward Integrating Word Sense and Entity Disambiguation into Statistical Machine Translation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We describe a machine translation approach being designed at HKUST to integrate semantic processing into statistical machine translation, beginning with entity and word sense disambiguation. We show how integrating the semantic modules consistently improves translation quality across several data sets. We report results on five different IWSLT 2006 speech translation tasks, representing HKUST&apos;s first participation in the IWSLT spoken language translation evaluation campaign. We translated both read and spontaneous speech transcriptions from Chinese to English, achieving reasonable performance despite the fact that our system is essentially text-based and therefore not designed and tuned to tackle the challenges of speech translation. We also find that the system achieves reasonable results on a wide range of languages, by evaluating on read speech transcriptions from Arabic, Italian, and Japanese into English.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The role and usefulness of semantic processing for Statistical Machine Translation (SMT) has recently been much debated. In previous work, we reported surprisingly disappointing results when using the predictions of a Senseval word sense disambiguation (WSD) system in conjunction with SMT using an IBM-style model <ref type="bibr">(Carpuat and Wu, 2005b)</ref>. Nevertheless, error analysis leaves little doubt that the performance of SMT systems still suffers from inaccurate lexical choice. Other empirical studies have shown that SMT systems perform much more poorly than dedicated WSD models, both supervised and unsupervised, on Senseval WSD tasks <ref type="bibr">(Carpuat and Wu, 2005a</ref>)-also suggesting that WSD still has a role to play in improving SMT.</p><p>In this paper, we describe ongoing work on an approach being designed at HKUST to investigate the effect of semantic handling on current SMT models, using dedicated word sense and entity disambiguation modules. In particular, we propose a new architecture for integrating WSD into SMT architectures, and show that this additional semantic handling consistently improves translation quality across several data sets.</p><p>We then turn to the IWSLT 2006 tasks, describing the experimental set-up and evaluation results. This represents a first participation by HKUST in the IWSLT spoken language translation evaluation campaign. For this first participation, we focused on building a baseline system for Chinese to English translation that could be easily ported to different language pairs. We therefore chose to translate additional input languages from different language families. We submitted translations of read and spontaneous speech in the Chinese to English task, as well as read speech translations from Arabic, Italian and Japanese into English. Despite the fact that the system is essentially text-based, and therefore is not designed and tuned to tackle the challenges of speech translation, the system achieves reasonable performance, yielding a BLEU score of 15.45 and a ME-TEOR score of 44.56 for Chinese to English translation, our main language pair of interest. Results on other language pairs suggest that the system can achieve reasonable results with little modification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Machine translation engine</head><p>The core MT engine as used in the experiments here is an off-the-shelf phrase-based statistical machine translation model. This is a useful engine since the approach has been shown to achieve competitive translation quality and is commonly used. Many state-of-the-art systems employ phrase-based approaches (e.g., <ref type="bibr" target="#b31">Zens et al. (2005)</ref>, <ref type="bibr" target="#b13">Koehn et al. (2005)</ref>, <ref type="bibr" target="#b20">Sadat et al. (2005)</ref>). All phrase-based models make use of a phrasal bilexicon, but essentially differ in the bilexicon extraction and parameter estimation strategies, and the phrase reordering method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Decoder</head><p>For the experiments here, we used the Pharaoh decoder <ref type="bibr" target="#b15">(Koehn, 2004)</ref>, which implements a heuristic beam search for phrase based translation. While the phrase reordering model used in Pharaoh is weaker than in other proposed models, Pharaoh was chosen for the advantages of being freely available and widely used, and therefore constitutes an appropriate point of reference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Phrasal bilexicon</head><p>The core phrasal bilexicon is derived from the intersection of bidirectional IBM Model 4 alignments, obtained with GIZA++ ( <ref type="bibr" target="#b18">Och and Ney, 2002</ref>). The intersection is augmented using growing heuristics proposed by <ref type="bibr" target="#b18">Och and Ney (2002)</ref> in order to improve recall. Following <ref type="bibr" target="#b14">Koehn (2003)</ref>, each entry in the phrasal bilexicon is scored using phrase translation conditional probabilities for both translation directions, as well as lexical weights which combine word translation probabilities according to the word alignment observed within the phrase pair during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Language model</head><p>The language model is a standard trigram model with Kneser-Ney smoothing trained using the SRI language modeling toolkit <ref type="bibr" target="#b23">(Stolcke, 2002</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Word sense disambiguation for translation lexical choice</head><p>We now present a new architecture integrating a stateof-the-art WSD model into phrase-based SMT, and show that WSD produces small but consistent gains across several test sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">WSD classifiers</head><p>The model consists of an ensemble of four voting models combined by majority vote. The first voting model is a na¨ıvena¨ıve Bayes model, since <ref type="bibr" target="#b29">Yarowsky and Florian (2002)</ref> found this model to be the most accurate classifier in a comparative study on a subset of Senseval-2 English lexical sample data.</p><p>The second voting model is a maximum entropy model <ref type="bibr" target="#b11">(Jaynes, 1979)</ref>, since <ref type="bibr" target="#b12">Klein and Manning (2002)</ref> found that this model yielded higher accuracy than na¨ıvena¨ıve Bayes in a subsequent comparison of WSD performance.</p><p>The third voting model is a boosting model <ref type="bibr" target="#b10">(Freund and Schapire, 1997)</ref>, since has consistently turned in very competitive scores on related tasks such as named entity classification, as described in Section 4.1.1. We also use the Adaboost.MH algorithm for WSD, just like for NER.</p><p>The fourth voting model is a model based on Kernel PCA ( ). Kernel Principal Component Analysis (KPCA) is a nonlinear kernel method for extracting nonlinear principal components from vector sets where, conceptually, the n-dimensional input vectors are nonlinearly mapped from their original space R n to a high-dimensional feature space F where linear PCA is performed, yielding a transform by which the input vectors can be mapped nonlinearly to a new set of vectors ( <ref type="bibr" target="#b22">Schölkopf et al., 1998</ref>). WSD can be performed by a Nearest Neighbor Classifier in the high-dimensional KPCA feature space. We have showed that KPCAbased WSD models achieve close accuracies to the best individual WSD models, while having a significantly different bias ).</p><p>All these classifiers have the ability to handle large numbers of sparse features, many of which may be irrelevant. Moreover, the maximum entropy and boosting models are known to be well suited to handling features that are highly interdependent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">WSD features</head><p>The WSD classifier employs much richer features than IBM-style statistical MT systems. The feature set consists of position-sensitive, syntactic, and local collocational features, since these features yielded the best results when combined in a na¨ıvena¨ıve Bayes model on several Senseval-2 lexical sample tasks ( <ref type="bibr" target="#b29">Yarowsky and Florian, 2002</ref>).</p><p>All these WSD models were extensively evaluated on a wide range of monolingual and multilingual lexi-  cal sample disambiguation tasks both on Senseval-2 and Senseval-3 data (e.g., , , Su et al. <ref type="formula">(2004)</ref>). <ref type="table" target="#tab_0">Table 1</ref> shows that our method of integrating a state-ofthe-art WSD model into phrase-based SMT produces small but consistent gains across all Chinese-English development test sets. The main difference between this approach and our earlier experiments <ref type="bibr">(Carpuat and Wu, 2005b</ref>) lies in the fact that we focus on repurposing the WSD system for SMT. Rather than using a generic Senseval WSD model, both the WSD training and the WSD predictions are integrated into the SMT framework. Specifically:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Repurposing the WSD models for SMT</head><p>• Instead of using a Senseval system, we redefine the WSD task to be as close as possible to the translation disambiguation task faced by the SMT system.</p><p>• Instead of using predefined senses drawn from manually constructed sense inventories such as HowNet <ref type="bibr" target="#b9">(Dong, 1998)</ref>, our WSD for SMT system directly disambiguates between all translation candidates seen during SMT training.</p><p>• Instead of learning from manually annotated training data, our WSD system is trained on the same corpora as the SMT system.</p><p>Thus, in a given SMT input sentence, for every word that was seen in the training data, we have a WSD model and a context-dependent distribution over the possible translation candidates of the word. This distribution is used to augment the baseline bilexicon. With Pharaoh, we use the provided XML markup scheme to specifiy translation candidates and their corresponding probabilities. At decoding time, these externally generated translation candidates are considered as if they were additional bilexicon entries, and are used to build translation hypotheses that compete with other translation hypotheses build from within the traditional SMT phrasal translation lexicon.</p><p>Analysis shows that the WSD translation probabilities give better rankings and are more discriminative than the baseline translation probabilities, yielding improved translations as can be seen in <ref type="table" target="#tab_1">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Named-entity translation</head><p>Recognizing, disambiguating, and translating entities is a special case of word sense disambiguation for translation lexical choice, where the words or phrases in question are entities of various sorts. Translating names correctly is particularly important to translation quality and usefulness, but does present some distinct challenges from regular phrase translation. First, the vast majority of names are rare and often never seen in training, and, with the exception of names of well-known persons or other entities, are typically not recorded in lexicons. Second, whether a phrase is a named-entity (NE) depends on context and is therefore ambiguous. Third, names have specific translation patterns. For instance, the translation of a person name usually cannot be inferred from the translation of each of its components.</p><p>The first step in handling NE translation consists in identifying NE boundaries and their type. In this system, we are focusing on identifying the PERSON, LO-CATION and ORGANIZATION entity types. For the purpose of translation, identifying NE boundaries is not sufficient, since the type of a NE affects the translation patterns: for instance, many location and person names can typically be transliterated, while some components of organization names should be translated with a standard bilexicon instead. After identifying NE boundaries and types, a rulebased translation approach based on name gazetteers and transliteration schemes is used to obtain one or more translations for each identified NE.</p><p>The decoder integrates the NE translation candidates as additional translation candidates for the NE phrase, using the Pharaoh XML markup scheme for translation input, as for the integration of the WSD predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Identifying named entities</head><p>The named-entity recognition (NER) system is based on a multilingual NER system initially developped for several European languages, and subsequently adapted to Chinese.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">NER classifiers</head><p>As NER can be framed as a classification task, we use an ensemble of three relatively high performing machine learning classifiers:</p><p>Boosting: The main idea behind boosting algorithms is that a set of many weak classifiers can be effectively combined to yield a single strong classifier. Each weak classifier is trained sequentially, increasingly focusing more heavily on the instances that the previous classifiers found difficult to classify. Our system uses AdaBoost.MH <ref type="bibr" target="#b10">(Freund and Schapire, 1997</ref>), an n-ary classification variant of the original binary AdaBoost algorithm. As demonstrated by <ref type="bibr" target="#b26">Wu et al. (2002)</ref> and <ref type="bibr">Car- reras et al. (2002)</ref>, boosting can be used to build language independent NER models that perform exceptionally well.</p><p>Support Vector Machines: Support Vector Machines (SVMs) have gained a considerable following in recent years ( <ref type="bibr" target="#b1">Boser et al., 1992</ref>). Sassano and Utsuro (2000) and <ref type="bibr" target="#b16">McNamee and Mayfield (2002)</ref> have demonstrated that SVMs show promise when applied to named entity recognition, though performance appears quite sensitive to parameter choices.</p><p>Transformation-based learning: Transformationbased learning (TBL) is a rule-based machine learning algorithm that was first introduced by <ref type="bibr" target="#b2">Brill (1995)</ref> and used for part-of-speech tagging. The central idea of transformation-based learning is to learn an ordered list of rules which progressively improve upon the current state of the training set. An initial assignment is made based on simple statistics, and then rules are greedily learned to correct the mistakes, until no net improvement can be made. Our system uses the fnTBL toolkit <ref type="bibr" target="#b17">(Ngai and Florian, 2001</ref>), which implements several optimizations in rule learning to drastically speed up the time needed for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">NER features</head><p>We use a set of primary features which can be easily obtained across languages, and require little linguistic analysis.</p><p>For European languages, features are defined as follows:</p><p>• Lexical (words and lemmas) and syntactic (partof-speech) information within a window of 2 words surrounding the current word</p><p>• Prefixes and suffixes of up to a length of 4 characters from the current word</p><p>• Capitalization: whether the word starts with a capital letter and/or the entire word is capitalized</p><p>• A small set of conjunctions of POS tags and words within a window of 2 words of the current word</p><p>• Previous history: the chunk tags (gold standard during training; assigned for evaluation) of the previous two words.</p><p>• Gazetteer features: whether the current word is within a NE occuring in a given gazetteer.</p><p>For Chinese, the feature set must be adapted to tackle several additional challenges. First, unlike European  <ref type="bibr" target="#b30">Yu et al., 2006</ref>) and for several European languages at CoNLL 2002 ( <ref type="bibr" target="#b26">Wu et al., 2002</ref>) and 2003 ( <ref type="bibr" target="#b27">Wu et al., 2003</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">IWSLT experimental set-up and results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Data description</head><p>Training and evaluation data are drawn from the multilingual Basic Travel Expression Corpus (BTEC*), which contains relatively short sentences used in simple conversations in the travel domain, and their translations in several languages.</p><p>We participated in the open track of the evaluation campaign, where we were allowed to use only the BTEC* data given for each translation task, plus any other external resources. The training and evaluation data statistics are given in <ref type="table" target="#tab_2">Table 3</ref> and 4 respectively. The ChineseEnglish and Japanese-English tasks were provided with twice as many training bisentences as the Arabic-English and Italian-English tasks. Taking advantage of the fact that BTEC* is a multilingual parallel corpus, all training sets share the same English side. Similarly, the evaluation test sets are composed of Arabic, Chinese, Italian and Japanese sentences that can all translate to the same English sentence.</p><p>All training data was clean text, representing a mismatch to the test data used in the evaluation, which was noisy output from automatic speech recognition. In addition to recognition errors, automatic speech transcriptions do not contain punctuation, and use digits to represent numbers. Performance could be improved by eliminating the mismatch between training and test data.</p><p>For each Chinese sentence, we are given correct speech transcriptions as well as automatic read speech transcriptions and automatic spontaneous speech transcriptions. For the other languages, we only translated the correct and the read speech transcriptions. For this first IWSLT participation, we did not take advantage of the availability of n-best lists, and only made use of the 1-best transcription, as if the input were text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Language-specific data preprocessing</head><p>For all language pairs, sentence pairs containing multiple segments are split and re-aligned to provide cleaner parallel training data. After this common processing step, each language followed a minimal language-specific tokenization scheme.</p><p>English: The English was simply tokenized and case-normalized in the same manner for all languages.</p><p>Chinese: The Chinese side of the parallel corpora was word segmented using the LDC segmenter.</p><p>Arabic: In contrast with the 4 other languages considered, Arabic is a morphologically rich language and requires more sophisticated processing. The Arabic text is first converted to the Buckwalter romanization scheme. Tokenization and lemmatization are performed using the ASVMT Arabic morphological analysis toolkit <ref type="bibr">(Diab, 2005</ref>). An Arabic word is typically formed of a stem, and possibly affixes and clitics. Affixes are inflectional markers for tense, gender and/or number, while the clitics include some prepositions, conjunctions, determiners, etc. Tokenization, which consists of separating those  <ref type="table">Table 6</ref>: Examples of Chinese translations for different input conditions: correct speech transcription (text), read speech transcription (read), and spontaneous speech transcription (spontaneous).</p><formula xml:id="formula_0">Example 1 Input (text): ïå ÷ Š ` ( å, " 0@ ™ e } Output:</formula><p>Could you please write down the address in Japan, please. Input (read):</p><p>ïå ÷î¨(÷î¨÷î¨( å, " 0@ ™ e }</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output:</head><p>Could you please write down the address in Japan, please. Input (spontaneous):</p><formula xml:id="formula_1">ïå ÷ ž Ù º " 0@ ™ † } Output:</formula><p>May handle, deal with the address of the please. syntactic units, is the first step of processing in ASVMT. This is followed by lemmatization which, in ASVMT, refers to a normalization step where the tokens coming from stems that were modified when agglutinated are converted back to their original form. Italian: We preprocessed the Italian corpus just like the English corpus: it was simply tokenized, using the same rules as for English, and case-normalized. This is obviously not optimal, as Italian presents more morphological inflexions than English, as suggested by the larger vocabulary size on the Italian side of the training data than on the English side <ref type="table" target="#tab_2">(Table 3)</ref>.</p><p>Japanese: We used the provided word segmentation and did not perform any additional processing. <ref type="table" target="#tab_4">Table 5</ref> shows the evaluation of translation quality for the Chinese-English translation task, using the most common automatic evaluation metrics: BLEU <ref type="bibr" target="#b19">(Papineni et al., 2002</ref>), NIST <ref type="bibr" target="#b8">(Doddington, 2002</ref>), METEOR <ref type="bibr">(Baner- jee and Lavie, 2005)</ref>, as well as word error rate (WER) and position-independent word error rate (PER) <ref type="bibr">(Till- mann et al., 1997</ref>). The HKUST system achieves reasonable performance, with evaluation scores situated in the middle range, compared to all systems evaluated on the open track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Chinese-English task</head><p>As expected, translation quality degrades for all evaluation metrics when moving from correct transcriptions to read and spontaneous speech. <ref type="table">Table 6</ref> shows how differences in the accuracy of speech transcription affects the final translation quality. In the first example, the spontaneous speech transcription contains a sequence of four incorrect characters ("ž Ù º" instead of the correct "Š ` ( å,"), which makes the translation meaningless. In contrast, the read speech translation contains only one error: the speech recognizer confuses the more formal word "¨" with the correct word  "`". However, they both translate to the same English word ("you") yielding an acceptable sentence translation despite the speech recognizer error. The second set of sentences gives an example of a less common case, where the spontaneous speech translation is better than the read speech translation. The read speech transcription wrongly recognizes the word "Z" ("evening") as "©?", which is meaningless and cannot be translated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Other language pairs</head><p>Translation results for the other language pairs are reported in <ref type="table" target="#tab_5">Table 7</ref>. Despite the smaller amount of training data available, translating from Italian yields the best performance, since Italian is closer to English than the three other input languages considered. <ref type="table" target="#tab_6">Table 8</ref> shows sentence translations obtained for all the input languages for a common reference translation. In these examples, the translation from Italian is usually the best of the four, as shown by the evaluation scores. Japanese translations seem to be the hardest for the system, with many input words that are not or incorrectly translated, despite a phrasal bilexicon learned on twice as much data as the Italian phrasal bilexicon. In Chinese, the phrasal lexicon coverage seems better on these sentences, but our phrase-based model fails to accurately capture differences in syntax: in the third example, the Chinese system translates most words correctly but fails to correctly disambiguate the use of the Chinese verb in assertion vs. interrogation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We have described the design of an approach at HKUST to integrating semantic processing into statistical machine translation, with specific modules for word sense and entity disambiguation and translation, and showed how repurposing the semantic analysis modules for the translation task yields improvements in translation quality. We discussed results obtained on four different languages in the IWSLT 2006 speech translation tasks, in HKUST's first participation in the IWSLT evaluation campaign. On the Chinese to English translation task, the system achieved reasonable performance as measured by a set of automatic evaluation metrics. We also reported results on the Arabic, Italian and Japanese read speech translation tasks, showing that the system is easily portable to other language pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">References</head><p>Satanjeev Banerjee and Alon Lavie. METEOR: An automatic metric for MT evaluation with improved correlation with human judgement. In Pro-</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>ZA¹ åM Å{ {° Output: You must check in by ten o'clock in the evening. Input (read): ¨ ©?A¹ åM Å{ {° Output: You must check in at ten before. Input (spontaneous): ¨ ZA¹ åM Å{ {° Output: You must check in by ten o'clock in the evening.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 : Evaluation results: integrating the WSD trans- lation predictions improves BLEU and NIST scores across 4 different Chinese-English test sets.</head><label>1</label><figDesc></figDesc><table>Test Set 
Experiment 
BLEU NIST 
DevTest 1 Baseline 
40.76 7.9388 
+ WSD for SMT 41.28 7.9814 
DevTest 2 Baseline 
39.81 8.1533 
+ WSD for SMT 39.85 8.1753 
DevTest 3 Baseline 
49.26 9.1172 
+ WSD for SMT 49.81 9.1522 
DevTest 4 Baseline 
16.13 5.7258 
+ WSD for SMT 16.27 5.7569 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Translation examples with and without WSD 
for SMT 
Example 1 
Input 
© ÜU } 

Ref. 
May I see the menu ? 
Baseline Let me see the menu ? 
+ WSD 
May I see the menu ? 
Example 2 
Input 
ý Š "  §M Ù 

Ref. 
Would you show me to my seat ? 
Baseline Can you change my seat finger for me ? 
+ WSD 
Can you direct me to my seat ? 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 : IWSLT-06 Training data statistics computed for the 4 language pairs</head><label>3</label><figDesc></figDesc><table>Training Data Statistics 
Chinese-English Arabic-English 
Italian-English 
Japanese-English 
Number of bisentences 
39953 
19972 
19972 
39953 
Vocabulary size (input lang) 
11178 
25152 
17917 
12535 
Vocabulary size (English) 
18992 
13337 
13337 
18992 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 4 : IWSLT-06 Evaluation test data statistics computed for the correct speech transcriptions (text) and the read speech transcriptions (read)</head><label>4</label><figDesc></figDesc><table>Test Data Statistics 
Chinese-English Arabic-English 
Italian-English 
Japanese-English 
Number of sentences 
500 
500 
500 
500 
Vocabulary size (text) 
1328 
1950 
1467 
1330 
Vocabulary size (read) 
1361 
1890 
1552 
1383 
unknown words (text) 
150 
727 
399 
154 
unknown words (read) 
124 
763 
340 
105 

languages, Chinese lacks capitalization information which 
plays a very important role in identifying named enti-
ties. Second, there is no space between words in Chi-
nese, so ambiguous segmentation interacts with NER 
decisions. Consequently, segmentation errors will af-
fect the NER performance, and vice versa. Third, unlike 
European languages, Chinese allows an open vocabu-
lary for proper names of persons, eliminating another 
major source of explicit clues used by European lan-
guage NER models. Based on these observations, we 
use character-level features instead of word-level fea-
tures; this prevents committing to a given word segmen-
tation, which might be incorrect at NE boundaries. 
Several versions of this NER system were exten-
sively evaluated on NER shared tasks for Chinese at 
SIGHAN 2006 (</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 : Evaluation results on the Chinese-English translation task, on correct speech transcriptions (text), read speech transcriptions (read) and spontaneous speech (transcriptions) Evaluation Metric</head><label>5</label><figDesc></figDesc><table>HKUST 
Result 
(text) 

Result Range 
(text) 

HKUST 
Result 
(read) 

Result Range 
(read) 

HKUST Result 
(spontaneous) 

Result Range 
(spontaneous) 

BLEU 
18.04 
12.84-24.23 
15.45 
10.37-21.11 
14.41 
03.44-18.98 
NIST 
5.3615 
4.0658-6.4004 
4.7769 
3.6384-5.5858 
4.6365 
2.7374-5.1513 
METEOR 
49.15 
41.64-51.82 
44.56 
37.29-45.96 
42.38 
31.78-41.98 
WER 
68.99 
74.42-65.06 
71.16 
77.64-69.10 
71.87 
87.12-70.60 
PER 
54.87 
58.21-49.80 
58.20 
61.62-54.73 
59.11 
74.30-57.05 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 7 : Evaluation results on the Arabic, Italian and Japanese translation tasks, for both correct speech transcriptions (text), and read speech trancriptions (read).</head><label>7</label><figDesc></figDesc><table>Evaluation 
Metric 

Arabic 
(text) 

Arabic 
(read) 

Italian 
(text) 

Italian 
(read) 

Japanese 
(text) 

Japanese 
(read) 
BLEU 
16.63 
14.77 
29.64 
23.74 
15.60 
15.23 
NIST 
3.8863 
3.3318 
7.1816 
6.0956 
0.1560 
0.1523 
METEOR 
42.88 
39.20 
62.39 
54.03 
45.79 
42.83 
WER 
67.57 
69.16 
58.08 
63.07 
72.48 
72.39 
PER 
56.47 
59.48 
43.40 
49.38 
57.86 
58.18 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table>Translations of test sentences from Arabic (ar), 
Chinese (zh), Italian (it) and Japanese (jp) into English 
Input Translation 
Ref. 
It is about twenty kilometers away from here. 
ar 
On in about twenty kilometers from here. 
zh 
About twenty kilometers from here. 
it 
It's about twenty kilometers far from here. 
jp 
About two -kilometers from here. 

Ref. 
This wine is from France. It's very famous. 
ar 
This wine from France and is very popular. 
zh 
This is very famous French made wine. 
it 
This wine comes from France is very popu-
lar. 
jp 
This is 's very famous. 

Ref. 
Yes. We also have blue, red, yellow and pink. 
ar 
Yes, we have a red and my. 
zh 
Do you have any blue red yellow and pink. 
it 
Yes, we have red yellow blue and pink. 
jp 
Yes, we have red green yellow pink. 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<title level="m">of Workshop on Intrinsic and Extrinsic Evaluation Measures for MT and/or Summarization at the 43th Annual Meeting of the Association of Computational Linguistics (ACL-2005)</title>
		<meeting><address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A training algorithm for optimal margin classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><forename type="middle">E</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Computational Learning Theory</title>
		<editor>David Haussler</editor>
		<meeting>the 4th Workshop on Computational Learning Theory<address><addrLine>San Malteo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="144" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Transformation-based error-driven learning and natural language processing: a case study in part of speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="543" to="565" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Evaluating the word sense disambiguation performance of statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second International Joint Conference on Natural Language Processing (IJCNLP)</title>
		<meeting><address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-10" />
			<biblScope unit="page" from="122" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Word sense disambiguation vs. statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">43rd Annual Meeting of the Association for Computational Linguistics (ACL-2005)</title>
		<meeting><address><addrLine>Ann Arbor</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06" />
			<biblScope unit="page" from="387" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Augmenting ensemble classification for word sense disambiguation with a Kernel PCA model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third International Workshop on Evaluating Word Sense Disambiguation Systems (Senseval-3)</title>
		<meeting><address><addrLine>Barcelona</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Named entity extraction using AdaBoost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lluís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Padró</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Natural Language Learning (CoNLL-2002), at COLING-2002</title>
		<meeting><address><addrLine>Taipei</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-09" />
			<biblScope unit="page" from="171" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Documentation for the Arabic SVM Toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mona</forename><surname>Diab</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Automatic evaluation of machine translation quality using n-gram co-occurrence statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Doddington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Language Technology conference (HLT-2002)</title>
		<meeting>the Human Language Technology conference (HLT-2002)<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Knowledge description: what, how and who?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Zhen Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Symposium on Electronic Dictionary</title>
		<meeting>International Symposium on Electronic Dictionary<address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A decision-theoretic generalization of on-line learning and an application to boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="119" to="139" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Where do we stand on maximum entropy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaynes</forename><surname>Edwin Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Maximum Entropy Formalism</title>
		<editor>Raphael D. Levine and Myron Tribus</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1979" />
			<biblScope unit="page" from="15" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Conditional structure versus conditional estimation in NLP models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-2002, Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>EMNLP-2002, Conference on Empirical Methods in Natural Language Processing<address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002-07" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Edinburgh system description for the 2005 IWSLT speech translation evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amittai</forename><surname>Axelrod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><forename type="middle">Birch</forename><surname>Mayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callisonburch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miles</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Talbot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IWSLT-2005</title>
		<meeting>IWSLT-2005<address><addrLine>Pittsburgh, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Noun-Phrase Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
		<respStmt>
			<orgName>University of Southern California</orgName>
		</respStmt>
	</monogr>
<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Pharaoh: a beam search decoder forphrase-based statistical machine translation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th Conference of the Association for Machine Translation in the Americas (AMTA)</title>
		<meeting><address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Entity extraction without language specific resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2002</title>
		<meeting>CoNLL-2002<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="183" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Transformation-based learning in the fast lane</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Ngai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT/NAACL-2001</title>
		<meeting>HLT/NAACL-2001<address><addrLine>Pittsburgh, PA</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Discriminative training and maximum entropy models for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Portage: A phrase-based machine translation system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatiha</forename><surname>Sadat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Howard</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akakpo</forename><surname>Agagbo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Tikuisis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Worskhop on Building and Using Parallel Texts</title>
		<meeting>the ACL Worskhop on Building and Using Parallel Texts<address><addrLine>Ann Arbor, MI</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2005-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Named entity chunking techniques in supervised learning for Japanese named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manabu</forename><surname>Sassano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takehito</forename><surname>Utsuro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">19th International Conference on Computational Linguistics (COLING-2000)</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="705" to="711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Nonlinear component analysis as a kernel eigenvalue problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus-Rober</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">SRILM -an extensible language modeling toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Spoken Language Processing</title>
		<meeting>the International Conference on Spoken Language Processing<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Semi-supervised training of a Kernel PCA-based model for word sense disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">20th International Conference on Computational Linguistics (COLING-2004)</title>
		<meeting><address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Accelerated DP-based search for statistical translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Tillmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Zubiaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hassan</forename><surname>Sawaf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Eurospeech&apos;97</title>
		<meeting>Eurospeech&apos;97<address><addrLine>Rhodes, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="2667" to="2670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Boosting for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Ngai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeppe</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongsheng</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Natural Language Learning (CoNLL-2002), at COLING-2002</title>
		<meeting><address><addrLine>Taipei</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-09" />
			<biblScope unit="page" from="195" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A stacked, voted, stacked model for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Ngai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">at Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics (HLT/NAACL-2003)</title>
		<meeting><address><addrLine>Edmonton, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-05" />
		</imprint>
	</monogr>
	<note>Computational Natural Language Learning</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A Kernel PCA method for superior word sense disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">42nd Annual Meeting of the Association for Computational Linguistics (ACL-2004)</title>
		<meeting><address><addrLine>Barcelona</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Evaluating sense disambiguation across diverse parameter spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="293" to="310" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Boosting for Chinese namedentity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofeng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth SIGHAN Workshop of the Special Interest Group for Chinese Language Processing (SIGHAN5) at COLING/ACL</title>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The RWTH phrase-based statistical machine translation system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasa</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahram</forename><surname>Khadivi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeny</forename><surname>Matusov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IWSLT-2005</title>
		<meeting>IWSLT-2005<address><addrLine>Pittsburgh, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
