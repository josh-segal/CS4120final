<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:52+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Modeling Intra-class Variation for Nonideal Iris Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Lane Dept. of Computer Science and Electrical Engineering</orgName>
								<orgName type="institution">West Virginia University</orgName>
								<address>
									<postCode>26506-6109</postCode>
									<settlement>Morgantown</settlement>
									<region>WV</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Modeling Intra-class Variation for Nonideal Iris Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Intra-class variation is fundamental to the FNMR performance of iris recognition systems. In this paper, we perform a systematic study of modeling intra-class variation for nonideal iris images captured under less-controlled environments. We present global geometric calibration techniques for compensating distortion associated with off-angle acquisition and local geometric calibration techniques for compensating distortion due to inaccurate segmentation or pupil dilation. Geometric calibration facilitates both the localization and recognition of iris and more importantly, it offers a new approach of trading FNMR with FMR. We use experimental results to demonstrate the effectiveness of the proposed calibration techniques on both ideal and non-ideal iris databases.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Inter-class and intra-class variations are at the heart of any pattern recognition problem. They jointly determine the receiver operating characteristics (ROC) performance measured by false matching rate (FMR) and false non-matching rate (FNMR). Inter-class variation is largely determined by the "randomness" of a pattern itself -for example, since the iris pattern appears to be more random than the fingerprint pattern, iris recognition can easily achieve an extremely low FMR <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>. However, the con side of randomness is large intra-class variation and accordingly high FNMR.</p><p>For iris images, intra-class variation is caused by various uncertainty factors (e.g., eyelid/eyelash occlusion, pupil dilation/constriction, reflection of lights). Although it is possible to use quality control at the system level to alleviate the problem to some extent (e.g., in <ref type="bibr" target="#b5">[6]</ref> an iris image is suggested to be rejected if the eye is overly blurred or occluded), such strategy is often bad for the ergonomics of biometric systems. Moreover, there is increasing evidence that less-controlled iris acquisition might be inevitable in practice. For instance, it is not always feasible to capture the iris images at the front angle and the level position due to varying height, head tilting and gaze direction. Such class of "nonideal iris images" raise new challenges to the existing iris recognition systems since none of them can handle geometric distortion caused by off-angle acquisition (refer to <ref type="figure" target="#fig_0">Fig. 1</ref>).</p><p>This work was partially supported by NSF Center for Identification Technology Research.</p><p>In this paper, we present geometric calibration techniques for reducing intraclass variation. Given a pair of nonideal images, we first globally calibrate them by geometric transformations (rotation and scaling) to recover the circular shape of pupil. To the best of our knowledge, this is the first study on compensating geometric distortion of off-angle images in the open literature. After standard iris localization, unwrapping into polar coordinate and enhancement, we propose to locally calibrate enhanced images by constrained-form deformation techniques before matching. Local calibration is shown to dramatically reduce intra-class variation at the cost of slightly increased inter-class variation. Due to global and local calibration, we can even directly match two enhanced images without any spatial or frequency filtering (for feature extraction) and still obtain good recognition performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Nonideal Iris Acquisition</head><p>Due to the small physical size of human iris, its acquisition is not as easy as other biometrics such as face and fingerprint. Even under a controlled environment, the acquired images are seldom perfect -various uncertainty factors could give rise to severe intra-class variation, which makes the matching difficult. We structure those factors into two categories: sensor-related and subjectrelated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Sensor-related</head><p>The first assumption we make is that the camera is sufficiently close to the subject such that iris region with enough spatial resolution is acquired. Empirical studies have shown that it is desirable to have the resolution of above 100dpi for iris recognition. In addition to camera distance, the angle of camera is the other dominating factor in the acquisition. When the camera is located at an off-angle position, nearly-circular structure of human pupil would become elliptic (refer to <ref type="figure" target="#fig_0">Fig. 1</ref>). Most existing iris recognition algorithms can not handle such nonideal (off-angle) images.</p><p>There are two different off-angle scenarios under our investigation. In the first case, the camera and the eyes are at the same height and the following scaling transformation relates the front-angle image to its off-angle counterpart:</p><p>x y</p><formula xml:id="formula_0">= cosθ 0 0 1 x y .<label>(1)</label></formula><p>It simply compresses the horizontal direction -for instance, a circle in f (x, y) becomes an ellipse in f (x , y ) whose long and short axes are parallel to vertical and horizontal directions. In the second case, the camera and the eyes are not in the same horizontal plane and the projection of iris onto imaging plane becomes slightly complicated. Instead of an ellipse at the straight position, we observe a rotated ellipse with the angle being determined by the tilting of the camera. In addition to geometric distortions, sensor also introduces photometric distortions such as out-of-focus, reflection and shading. We usually assume that iris images are acquired with good focus; but in practice manual adjustment of the focus is only possible when images are captured by well-trained personnel. Reflection of light source often gives rise to bright spots in iris images, which need to be treated as occlusions. Another potential reflection source is the contact lens, though such issue has been largely ignored in the literature of iris recognition so far. Shading could also affect the intensity values of iris images especially during off-angle acquisition, which often makes robust detection of limbus boundary more difficult.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Subject-related</head><p>The fundamental cause of subject-related uncertainty factors is motion. For iris recognition, three levels of motion could interfere with the acquisition: head movement, eye movement and pupil motion. Head movement can often be avoided by verbal commands; but even when the head remains still, its varying height and tilting position could give rise to different projections. Eye movement consists of eye open/close and saccadic eyeball movement. Both eyelid and eyelashes could render occlusions; gaze direction interacts with camera angle, which makes captured iris images seldom ideal except when the camera is extremely close to eye (e.g., CASIA database).</p><p>There are two kinds of pupillary motion: hippus and light reflex. Hippus refers to spasmodic, rhythmical dilation and constriction of the pupil that are independent of illumination, convergence, or psychic stimuli. The oscillation frequency of hippus is around 0.5Hz and its origin remains elusive. Light reflex refers to pupillary dilation and constriction in response to the change in the amount of light entering the eye. It is known that the diameter of human pupil can change as much as nine times <ref type="bibr">(1 − 9mm)</ref>. Such dramatic variation leads to complex elastic deformation of iridal tissues, which can only be partially handled by the existing normalization technique.</p><p>One might argue that quality control at the system level can solve all the problems caused by uncertainty factors. However, it is our opinion that a robust iris recognition algorithm with modest computational cost will be more effective than redoing the acquisition. Note that in the real world, it is nontrivial to take all those uncertainty factors into account and even more frustrating for human operators to figure out what is wrong with an innocent-looking image. Therefore, the main objective of this paper is to present geometric calibration techniques for improving the robustness of iris recognition algorithms (the issue of photometric distortion is outside the scope of this work).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Geometric Calibration</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Global Calibration</head><p>Global calibration of nonideal iris images refers to the compensation of geometric distortion caused by off-angle cameras. The key motivation behind global calibration is to make the shape of pupil in an iris image as circular as possible. Although slightly non-circular pupils exist, they won't cause us any problem as long as we perform the calibration to both the enrolled and inquiry iris images. Therefore, we suggest that the pursuit of circular shape is an effective strategy for globally calibrating iris images even if both the enrolled and inquiry image are off-angle.</p><p>Detecting the pupil boundary in an off-angle image can use standard LeastSquare (LS) based ellipse fitting techniques such as <ref type="bibr" target="#b2">[3]</ref>. However, the accuracy of ellipse fitting degrades in the presence of outliers. Though it is often suggested that RANSAC can lead to improved robustness, we argue that it is more efficient to exploit our a priori knowledge about the outlier than the power of randomness. For example, outliers to ellipse detection in iris images are mainly attributed to light reflection and eyelashes. Light reflection often shows up as small round balls with high-intensity values, which can be masked during ellipse detection. Eyelashes have similar intensity values to pupil but highly different morphological attributes. Therefore, morphological filtering operations can effectively suppress the interference from eyelashes.</p><p>Ellipse fitting returns five parameters: the horizontal and vertical coordinates of pupil center (c x , c y ), the length of long and short axes (r x , r y ), and the orientation of the ellipse φ. Our global calibration consists of two steps: 1) rotate the image around (c x , c y ) by −φ to restore the straight position of ellipse; 2) apply the inverse of scaling transformation defined by Eq. (1) to restore the circular shape of pupil. The parameter in scaling transformation is given by cosθ = rx ry (assume r x , r y correspond to the short and long axes respectively). One tricky issue in the practical implementation is the periodicity of orientation parameter φ. Since <ref type="bibr" target="#b2">[3]</ref> does not put any constraint on the range of φ (e.g., φ and φ + π generates exactly the same ellipse), we need to further resolve the ambiguity among the set {φ + kπ 2 , k ∈ Z}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Local Calibration</head><p>After global calibration, we assume the compensated images are first unwrapped into polar coordinate based on the estimated parameters of inner(pupil) and outer(limbus) boundaries. Iris localization problem has been well studied in the literature (e.g., the coarse-to-fine integro-differential operator suggested by Daugman in <ref type="bibr" target="#b1">[2]</ref>). The detection of non-iris structures (eyelid, eyelashes and reflections) has also been studied in <ref type="bibr" target="#b0">[1]</ref> and <ref type="bibr" target="#b4">[5]</ref>. However, two major challenges remain. First, it has been experimentally found in <ref type="bibr" target="#b6">[7]</ref> that excessive pupil dilation often gives rise to large intra-class variation. Unwrapping into polar coordinate partially alleviates the problem due to normalization along the radial axis; but it is cannot completely account for nonlinear elastic deformation of iridal tissues when dilation ratio is large. Second and more importantly, pupil dilation often interacts with erroneous estimate of inner and outer boundaries (due to poor contrast or eyelash occlusion), which gives rise to inaccurate alignment along the radial axis. We propose to compensate the remaining geometric distortions by local calibration techniques.</p><p>Our local calibration is decomposed of two steps. In the first step, enhanced image is structured into eight nonoverlapping blocks along the angular coordinate and block matching is applied to linearly compensate translational displacement (e.g., due to head tilting). In the second step, nonlinear elastic deformation is approximated by Horn's optical flow field (v 1 , v 2 ) <ref type="bibr" target="#b3">[4]</ref>. Specifically, Horn's method targets at the minimization of</p><formula xml:id="formula_1">E = E 2 of + α 2 E 2 s .<label>(2)</label></formula><p>where E of is the error of optical flow equation, E 2 s = ||∇v 1 || 2 +||∇v 2 || 2 measures the smoothness of optical flow field. By selecting a fairly large regularization parameter α (suggested value is 200), we enforce the optical flow model to only accommodate small and localized deformation. <ref type="figure" target="#fig_1">Fig. 2</ref> shows an example of deformed sampling lattice after local calibration.</p><p>Although local calibration effectively reduces intra-class variation, its impact on inter-class variation can not be ignored. If iris patterns were truly random, our calibration should have no effect because of the constraints enforced above. Neither linear shifting nor regularized optical flow can deform a random pattern into another. However, in practice iris patterns are still characterized by notable structures such as flower, jewelry, shake and stream. Therefore, the impact of local calibration on inter-class variation is structure-dependent. For structures with less discriminating capability (e.g., stream), its optimal recognition performance is fundamentally worse than other's (e.g., flower). As we will see next, the proposed local calibration technique is also often more effective on high-texture iris images than low-texture ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>We have incorporated the proposed calibration techniques into the well-known Daugman's algorithm as shown in <ref type="figure">Fig. 3</ref>. In our current implementation, we have search for the largest bounding boxes for upper and lower eyelid respectively based on an approximate estimate of locations. <ref type="figure" target="#fig_1">Fig. 2b)</ref> shows several examples of different occlusion scenarios. In this section, we report our experimental results with both ideal (front-angle) and non-ideal (off-angle) iris databases. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Ideal Iris Database</head><p>For ideal database such as CASIA, no global calibration is needed. Therefore, we first demonstrate how local calibration facilitates iris recognition -an iris code can be obtained by simply thresholding the enhanced image. <ref type="figure" target="#fig_1">Fig. 2b)</ref> shows the distribution of Hamming distance (HD) for the whole 108 images (1620 intraclass and 1600 inter-class comparisons). It can be observed that without any sophisticated feature extraction technique, our plain iriscode already achieves reasonably good separation of intra-class and inter-class distributions. Empirical studies show that among the 2% intra-class comparisons whose HD is above 0.4, about 80% occur with two difficult subjects (No. 41 and 101, one example is shown as the bottom image in <ref type="figure">Fig. 3b</ref>) whose iris contain little texture and is severely occluded.</p><p>To further illustrate the impact of iris type on recognition performance, we manually pick out 30 subjects with high-texture (e.g., the middle image in in <ref type="figure">Fig. 3b</ref>) and low-texture (e.g., the top image in in <ref type="figure">Fig. 3b</ref>) iris respectively. The HD distributions for these two classes are shown in <ref type="figure">Fig. 4</ref>. For high-texture iris images, the separation of intra-class and inter-class distributions is nearly optimal regardless of the occlusion (on the average, 20% pixels are occluded in CASIA database). Low-texture iris is more challenging especially when occlusion also occurs. How to improve the performance for low-texture iris is left for our future study. We have also tested the proposed local calibration technique with our own implementation of Daugman's algorithm. The distributions of HD before and after calibration are shown in <ref type="figure">Fig. 5</ref>. It can be observed that local calibration effectively reduces intra-class variation at the price of slightly increased inter-class variation. Though more extensive experiments are required to evaluate the impact on ROC performance, it seems that local calibration at least suggests a new way of trading FNMR with FMR -i.e., in order to satisfy the accuracy require- ments imposed by biometric applications, we might want to slightly sacrifice the FMR (since it is extremely low) in order to lower FNMR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Nonideal Iris Database</head><p>We have also collected a database of nonideal images for about 100 people in collaboration with the Eye Institute (EI) of West Virginia University in the past year. For each eye of a person, two images are acquired at the front and offangle respectively; the total number of images in EI database is around 800. Although the off-angles are preset to be 15 o and 30 o , we have found that those parameters cannot be directly used for global calibration due to varying gaze and head positions. We have also found that acquiring well-focused iris images is not easy for people without sufficient experience on operating cameras (e.g., auto-focus does not work properly for iris acquisition). Out-of-focus images can still be used for testing global calibration and iris localization techniques; but not for iris matching. Therefore, we can only perform our experiments with nonideal iris recognition on a small set of images (8 subjects) that are reasonably focused.</p><p>Experimental results have shown that ellipse-fitting based calibration works very well. By manually inspecting 80 calibrated images randomly selected from the database, we do not observe any error -pupils all appear circular after the calibration, which implies that nonideal iris recognition is transformed back to the ideal case. For the small set of focused iris images after global calibration, we have compared the results of modified Daugman's algorithm with and without local calibration. <ref type="figure">Fig. 6</ref> shows the distributions of HD for 48 intra-class and 128 inter-class comparisons, from which we can again see the effectiveness of local calibration. .</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Examples of nonideal iris images: a) off-angle but the same level; b) off-angle and different level; c) calibrated image of a); d) calibrated image of b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. An example of deformed mesh obtained by local calibration (left) and HD distributions of simply thresholding enhanced images (right)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .Fig. 4 .</head><label>34</label><figDesc>Fig. 3. a) The diagram of the proposed iris recognition system; b) examples of ROIs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>Fig. 5. HD distributions of modified Daugman's algorithm without (left) and with (right) local calibration for CASIA database</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A fast and robust iris localization method based on texture segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE on Biometric Technology for Human Identification</title>
		<meeting>SPIE on Biometric Technology for Human Identification</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">How iris recognition works?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Daugman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Circuits Syst. Video Tech</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="21" to="30" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Direct least-squares fitting of ellipses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Fitzgibbon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pilu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="476" to="480" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Determining optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schunck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="185" to="203" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Accurate iris segmentation based on novel re.ection and eyelash detection model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Sym. on Intell. Multimedia, Video and Speech Proc</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Personal identi.cation based on iris texture analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1519" to="1533" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">E.cient iris recognition by characterizing key local variations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="739" to="750" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Iris recognition: an emerging technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wildes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. of IEEE</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="1348" to="1363" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
