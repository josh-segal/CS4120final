<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:32+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Social Influence Analysis in Large-scale Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tang</surname></persName>
							<email>jietang@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimeng</forename><surname>Sun</surname></persName>
							<email>jimeng@us.ibm.com</email>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">IBM TJ Watson Research Center</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Wang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zi</forename><surname>Yang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Social Influence Analysis in Large-scale Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H33 [Information Search and Retrieval]: Text Mining; H28 [Database Management]: Database Applications General Terms Algorithms</term>
					<term>Experimentation Keywords Social Influence Analysis</term>
					<term>Topical Affinity Propagation</term>
					<term>Large-scale Network</term>
					<term>Social Networks</term>
				</keywords>
			</textClass>
			<abstract>
				<p>In large social networks, nodes (users, entities) are influenced by others for various reasons. For example, the colleagues have strong influence on one&apos;s work, while the friends have strong influence on one&apos;s daily life. How to differentiate the social influences from different angles(topics)? How to quantify the strength of those social influences? How to estimate the model on real large networks? To address these fundamental questions, we propose Topical Affinity Propagation (TAP) to model the topic-level social influence on large networks. In particular, TAP can take results of any topic modeling and the existing network structure to perform topic-level influence propagation. With the help of the influence analysis, we present several important applications on real data sets such as 1) what are the representative nodes on a given topic? 2) how to identify the social influences of neighboring nodes on a particular node? To scale to real large networks, TAP is designed with efficient distributed learning algorithms that is implemented and tested under the Map-Reduce framework. We further present the common characteristics of distributed learning algorithms for Map-Reduce. Finally, we demonstrate the effectiveness and efficiency of TAP on real large data sets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>With the emergence and rapid proliferation of social applications and media, such as instant messaging (e.g., IRC, AIM, MSN, Jabber, Skype), sharing sites (e.g., Flickr, Picassa, YouTube, Plaxo), Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. blogs (e.g., Blogger, WordPress, LiveJournal), wikis (e.g., Wikipedia, PBWiki), microblogs (e.g., Twitter, Jaiku), social networks (e.g., MySpace, Facebook, Ning), collaboration networks (e.g., DBLP) to mention a few, there is little doubt that social influence is becoming a prevalent, complex and subtle force that governs the dynamics of all social networks. Therefore, there is a clear need for methods and techniques to analyze and quantify the social influences.</p><p>Social network analysis often focus on macro-level models such as degree distributions, diameter, clustering coefficient, communities, small world effect, preferential attachment, etc; work in this area includes <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">23]</ref>. Recently, social influence study has started to attract more attention due to many important applications. However, most of the works on this area present qualitative findings about social influences <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b15">16]</ref>. In this paper, we focus on measuring the strength of topic-level social influence quantitatively. With the proposed social influence analysis, many important questions can be answered such as 1) what are the representative nodes on a given topic? 2) how to identify topic-level experts and their social influence to a particular node? 3) how to quickly connect to a particular node through strong social ties?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Motivating Application</head><p>Several theories in sociology <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b15">16]</ref> show that the effect of the social influence from different angles (topics) may be different. For example, in research community, such influences are well-known. Most researchers are influenced by others in terms of collaboration and citations. The most important information in the research community are 1) co-author networks, which capture the social dynamics of the community, 2) their publications, which imply the topic distribution (interests) of the authors. The key question is how to quantify the influence among researchers by leveraging these two pieces.</p><p>In <ref type="figure" target="#fig_2">Figure 1</ref>, the left figure illustrates the input: a co-author network of 7 researchers, and the topic distribution of each researcher. For example, George has the same probability (.5) on both topics, "data mining" and "database"; The right figure shows the output of our social influence analysis: two social influence graphs, one for each topic, where the arrows indicate the direction and strength. We see, Ada is the key person on "data mining", while Eve is the key person on "database". Thus, the goal is how to effectively and efficiently obtain the social influence graphs for real large networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Challenges and Contributions</head><p>The challenges of computing social influence graphs are the following:</p><p>• Multi-aspect. Social influences are associated with different topics. E.g., A can have high influence to B on a particular topic, but B may have a higher influence to A on another topic. It is important to be able to differentiate those influences from multiple aspects.  • Node-specific. Social influences are not a global measure of importance of nodes, but an importance measure on links between nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Social influence anlaysis</head><p>• Scalability. Real social networks are getting bigger with thousands or millions of nodes. It is important to develop the method that can scale well to real large data sets.</p><p>To address the above challenges, we propose Topical Affinity Propagation (TAP) to model the topic-level social influence on large networks. In particular, TAP takes 1) the results of any topic modeling such as a predefined topic ontology or topic clusters based on pLSI <ref type="bibr" target="#b14">[15]</ref> and LDA <ref type="bibr" target="#b2">[3]</ref> and 2) the existing network structure to perform topic-level influence propagation. More formally, given a social network G = (V, E) and a topic model on the nodes V , we compute topic-level social influence graphs G z = (V z , E z ) for all topic 1 ≤ z ≤ T . The key features of TAP are the following:</p><p>• TAP provides topical influence graphs that quantitatively measure the influence on a fine-grain level;</p><p>• The influence graphs from TAP can be used to support other applications such as finding representative nodes or constructing the influential subgraphs;</p><p>• An efficient distributed learning algorithm is developed for TAP based on the Map-Reduce framework in order to scale to real large networks.</p><p>The rest of the paper is organized as follows: Section 2 formally formulates the problem; Section 3 explains the proposed approach. Section 4 presents experimental results that validate the computational efficiency of our methodology. Finally, Section 5 discusses related work and Section 6 concludes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">OVERVIEW</head><p>In this section, we present the problem formulation and the intuition of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Formulation</head><p>The goal of social influence analysis is to derive the topic-level social influences based on the input network and topic distribution on each node. First we introduce some terminology, and then define the social influence analysis problem.</p><p>Topic distribution: In social networks, a user usually has interests on multiple topics. Formally, each node v ∈ V is associated with a vector θv ∈ R T of T -dimensional topic distribution ( z θ vz = 1). Each element θ vz is the probability(importance) of the node on topic z.</p><p>Topic-based social influences: Social influence from node s to t denoted as µst is a numerical weight associated with the edge est. In most cases, the social influence score is asymmetric, i.e., µ st = µ ts . Furthermore, the social influence from node s to t will vary on different topics.</p><p>Thus based on the above concepts, we can define the tasks of topic-based social influence analysis. Given a social network G = (V, E) and a topic distribution for each node, the goal is to find the topic-level influence scores on each edge. Problem 1. Given 1) a network G = (V, E), where V is the set of nodes (users, entities) and E is the set of directed/undirected edges, 2) T -dimensional topic distribution θ v ∈ R T for all node v in V , how to find the topic-level influence network G z = (V z , E z ) for all topics 1 ≤ z ≤ T ? Here Vz is a subset of nodes that are related to topic z and Ez is the set of pair-wise weighted influence relations over V z , each edge is the form of a triplet (v s , v t , µ z st ) (or shortly (e st , µ z st )), where the edge is from node v s to node v t with the weight µ z st . Our formulation of topic-based social influence analysis is quite different from existing works on social network analysis. For social influence analysis, <ref type="bibr" target="#b1">[2]</ref> and <ref type="bibr" target="#b20">[21]</ref> propose methods to qualitatively measure the existence of influence.</p><p>[6] studies the correlation between social similarity and influence. The existing methods mainly focus on qualitative identification of the existence of influence, but do not provide a quantitative measure of the influential strength.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Our Approach</head><p>The social influence analysis problem poses a unique set of challenges:</p><p>First, how to leverage both node-specific topic distribution and network structure to quantify social influence? In another word, a user's influence on others not only depends on their own topic distribution, but also relies on what kinds of social relationships they have with others. The goal is to design a unified approach to utilize both the local attributes (topic distribution) and the global structure (network information) for social influence analysis.</p><p>Second, how to scale the proposed analysis to a real large social network? For example, the academic community of Computer Science has more than 1 million researchers and more than 10 million coauthor relations; Facebook has more than 50 millions users and hundreds of millions of different social ties. How to efficiently identify the topic-based influential strength for each social tie is really a challenging problem.</p><p>Next we discuss the data input and the main intuition of the proposed method. Data Input:</p><p>Two inputs are required to our social influence analysis: 1) networks and 2) topic distribution on all nodes.</p><p>The first input is the network backbone obtained by any social networks, such as online social networks like Facebook and MySpace.</p><p>The second input is the topic distribution for all nodes. In general, the topic information can be obtained in many different ways. For example, in a social network, one can use the predefined categories as the topic information, or use user-assigned tags as the topic information. In addition, we can use statistical topic modeling <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b17">18]</ref> to automatically extract topics from the social networking data. In this paper, we use the topic modeling approach to initialize the topic distribution of each node. Topical Affinity Propagation (TAP):</p><p>Based on the input network and topic distribution on the nodes, we formalize the social influence problem in a topical factor graph model and propose a topical affinity propagation on the factor graph to automatically identify the topic-specific social influence.</p><p>Our main idea is to leverage an affinity propagation at the topiclevel for social influence identification. The approach is based on the theory of factor graph <ref type="bibr" target="#b16">[17]</ref>, in which the observation data are cohesive on both local attributes and relationships. In our setting, the node corresponds to the observation data in the factor graph and the social relationship corresponds to edge between the observation data in the graph. Finally, we propose two different propagation rules: one based on message passing on graphical models, the other one is a parallel update rule that is suitable for Map-Reduce framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">TOPICAL AFFINITY PROPAGATION</head><p>The goal of topic-based social influence analysis is to capture the following information: nodes' topic distributions, similarity between nodes, and network structure. In addition, the approach has to be able to scale up to a large scale network. Following this thread, we first propose a Topical Factor Graph (TFG) model to incorporate all the information into a unified probabilistic model. Second, we propose Topical Affinity Propagation (TAP) for model learning. Third, we discuss how to do distributed learning in the Map-Reduce framework. Finally, we illustrate several applications based on the results of social influence analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Topical Factor Graph (TFG) Model</head><p>Now we formally define the proposed TFG model. Variables The TFG model has the following components: a set of observed variables {vi} N i=1 and a set of hidden vectors {yi} N i=1 , which corresponds to the N nodes in the input network. Notations are summarized in table 1.</p><p>The hidden vector y i ∈ {1, . . . , N } T models the topic-level influences from other nodes to node v i . Each element y z i , taking the value from the set {1, . . . , N }, represents the node that has the highest probability to influence node vi on topic z.</p><p>For example, <ref type="figure">Figure 2</ref> shows a simple example of an TFG. The observed data consists of four nodes {v 1 , . . . , v 4 }, which have cor- responding hidden vectors Y = {y 1 , . . . , y 4 }. The edges between the hidden nodes indicate the four social relationships in the original network (aka the edges of the input network). Feature Functions There are three kinds of feature functions:</p><p>• Node feature function g(v i , y i , z) is a feature function defined on node v i specific to topic z.</p><p>• Edge feature function f (y i , y j , z) is a feature function defined on the edge of the input network specific to topic z.</p><p>• Global feature function h(y 1 , . . . , y N , k, z) is a feature function defined on all nodes of the input network w.r.t. topic z.</p><p>Basically, node feature function g describes local information on nodes, edge feature function f describes dependencies between nodes via the edge on the graph model, and global feature function captures constraints defined on the network.</p><p>In this work, we define the node feature function g as:</p><formula xml:id="formula_0">g(vi, y i , z) =      w z iy z i j∈N B(i) (w z ij +w z ji ) y z i = i j∈N B(i) w z ji j∈N B(i) (w z ij +w z ji ) y z i = i (1)</formula><p>where N B(i) represents the indices of the neighboring nodes of node v i ; w z ij = θ z j α ij reflects the topical similarity or interaction strength between v i and v j , with θ z j denoting the importance of node-j to topic z, and αij denoting the weight of the edge eij. αij can be defined by different ways. For example, in a coauthor network, α ij can be defined as the number of papers coauthored by v i and v j . The above definition of the node feature function has the following intuition: if node vi has a high similarity/weight with node vy i , then vy i may have a high influence on node vi; or if node v i is trusted by other users, i.e. other users take him as an high influential node on them, then it must also "trust" himself highly (taking himself as a most influential user on him).</p><p>As for the edge feature function, we define a binary feature function, i.e., f (y i , y j , z) = 1 if and only if there is an edge eij between node v i and node v j , otherwise 0. We also define a global edge feature function h on all nodes, i.e.:</p><formula xml:id="formula_1">h(y 1 , . . . , y N , k, z) = 0 if y z k = k and y z i = k for all i = k 1 otherwise.<label>(2)</label></formula><p>Intuitively, h(·) constrains the model to bias towards the "true" representative nodes, More specially, a representative node on topic z must be the representative of itself on topic z, i.e., y z k = k. And it must be a representative of at least another node v i , i.e.,</p><formula xml:id="formula_2">∃y z i = k, i = k. y 1 v 1 g(v 1 ,y 1 ,z) y 2 v 2 y 3 v 3 y 4 v 4 f (y 1 ,y 3 ,z)</formula><p>f (y 2 , y 4 , z)</p><formula xml:id="formula_3">y 1 1 =2 y 1 2 =1 Observation data: nodes TFG model f (y 1 ,y 2 ,z) f (y 2 ,y 3 ,z) g(v 2 ,y 2 ,z) g(v 3 ,y 3 ,z) g(v 4 ,y 4 ,z) #Topic: T=2 y 2 1 =4 y 2 2 =1 y 3 1 =2 y 3 2 =1 y 4 1 =4 y 4 2 =2 h (y 1 , y 2 , …, y N , k, z)</formula><p>Figure 2: Graphical representation of the topical factor graph model. {v 1 , . . . , v 4 } are observable nodes in the social network; {y 1 , . . . , y 4 } are hidden vectors defined on all nodes, with each element representing which node has the highest probability to influence the corresponding node; g(.) represents a feature function defined on a node, f (.) represents a feature function defined on an edge; and h(.) represents a global feature function defined for each node, i.e. k ∈ {1, . . . , N }.</p><p>Joint Distribution Next, a factor graph model is constructed based on this formulation. Typically, we hope that a model can best fit (reconstruct) the observation data, which is usually represented by maximizing the likelihood of the observation. Thus we can define the objective likelihood function as:</p><formula xml:id="formula_4">P (v, Y) = 1 Z N k=1 T z=1 h(y 1 , . . . , y N , k, z) N i=1 T z=1 g(v i , y i , z) e kl ∈E T z=1 f (y k , y l , z)<label>(3)</label></formula><p>where v = <ref type="bibr">[v1, . . . , vN ]</ref> and Y = [y 1 , . . . , y N ] corresponds to all observed and hidden variables, respectively; g and f are the node and edge feature functions; h is the global feature function; Z is a normalizing factor. The factor graph in <ref type="figure">Figure 2</ref> describes this factorization. Each black box corresponds to a term in the factorization, and it is connected to the variables on which the term depends.</p><p>Based on this formulation, the task of social influence is cast as identifying which node has the highest probability to influence another node on a specific topic along with the edge. That is, to maximize the likelihood function P (v, Y). One parameter configuration is shown in <ref type="figure">Figure 2</ref>. On topic 1, both node v 1 and node v 3 are strongly influenced by node v 2 , while node v 2 is mainly influenced by node v4. On topic 2, the situation is different. Almost all nodes are influenced by node v1, where node v4 is indirectly influenced by node v 1 via the node v 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Basic TAP Learning</head><p>Baseline: Sum-Product To train the TFG model, we can take Eq. 3 as the objective function to find the parameter configuration that maximizes the objective function. While it is intractable to find the exact solution to Eq. 3, approximate inference algorithms such as sum-product algorithm <ref type="bibr" target="#b16">[17]</ref>, can be used to infer the variables y.</p><p>In sum-product algorithm, messages are passed between nodes and functions. Message passing is initiated at the leaves. Each node v i remains idle until messages have arrived on all but one of the edges incident on the node v i . Once these messages have arrived, node vi is able to compute a message to be sent onto the one remaining edge to its neighbor. After sending out a message, node v i returns to the idle state, waiting for a "return message" to arrive from the edge. Once this message has arrived, the node is able to compute and send messages to each of neighborhood nodes. This process runs iteratively until convergence.</p><p>However, traditional sum-product algorithm cannot be directly applied for multiple topics. We first consider a basic extension of the sum-product algorithm: topical sum-product. The algorithm iteratively updates a vector of messages m between variable nodes and factor (i.e. feature function) nodes. Hence, two update rules can be defined respectively for a topic-specific message sent from variable node to factor node and for a topic-specific message sent from factor node to variable node.</p><formula xml:id="formula_5">m y→f (y, z) = f ∼y\f m f →y (y, z) z =z f ∼y\f m f →y (y, z ) (τ z z ) m f →y (y, z) = ∼{y}   f (Y, z) y ∼f \y m y →f (y , z)   + z =z τ z z ∼{y}   f (Y, z ) y ∼f \y m y →f (y , z )   (4)</formula><p>where</p><p>• f ∼ y\f represents f is a neighbor node of variable y on the factor graph except factor f ;</p><p>• Y is a subset of hidden variables that feature function f is defined on; for example, a feature f (yi, yj) is defined on edge eij, then we have Y = {yi, yj}; ∼ {y} represents all variables in Y except y;</p><p>• the sum ∼{y} actually corresponds to a marginal function for y on topic z;</p><p>• and coefficient τ represents the correlation between topics, which can be defined in many different ways. In this work we, for simplicity, assume that topics are independent. That is, τ zz = 1 when z = z and τ zz = 0 when z = z . In the following, we will propose two new learning algorithms, which are also based this independent assumption.</p><p>New Learning Algorithm However, the sum-product algorithm requires that each node need wait for all(-but-one) message to arrive, thus the algorithm can only run in a sequential mode. This results in a high complexity of O(N 4 × T ) in each iteration. To deal with this problem, we propose an affinity propagation algorithm, which converts the message passing rules into equivalent update rules passing message directly between nodes rather than on the factor graph. The algorithm is summarized in Algorithm 1.</p><p>In the algorithm, we first use logarithm to transform sum-product into max-sum, and introduce two sets of variables {r z ij } T z=1 and {a z ij } T z=1 for each edge e ij . The new update rules for the variables are as follows: (Derivation is omitted for brevity.)</p><formula xml:id="formula_6">r z ij = b z ij − max k∈N B(j) {b z ik + a z ik }<label>(5)</label></formula><formula xml:id="formula_7">a z jj = max k∈N B(j) min {r z kj , 0}<label>(6)</label></formula><formula xml:id="formula_8">a z ij = min(max {r z jj , 0}, − min {r z jj , 0} − max k∈N B(j)\{i} min {r z kj , 0}), i ∈ N B(j)<label>(7)</label></formula><p>where N B(j) denotes the neighboring nodes of node j, r z ij is the influence message sent from node i to node j and a z ij is the influence message sent from node j to node i, initiated by 0, and b z ij is the logarithm of the normalized feature function</p><formula xml:id="formula_9">b z ij = log g(v i , y i , z)| y z i =j k∈N B(i)∪{i} g(v i , y i , z)| y z i =k (8)</formula><p>The introduced variables r and a have the following nice explanation. Message a z ij reflects, from the perspective of node v j , how likely node v j thinks he/she influences on node v i with respect to topic z, while message r z ij reflects, from the perspective of node vi, how likely node vi agrees that node vj influence on him/her with respect to topic z. Finally, we can define the social influence score based on the two variables r and a using a sigmoid function:</p><formula xml:id="formula_10">µ z st = 1 1 + e −(r z ts +a z ts )<label>(9)</label></formula><p>The score µ z st actually reflects the maximum of P (v, Y, z) for y z t = s, thus the maximization of P (v, Y, z) can be obtained by</p><formula xml:id="formula_11">y z t = arg max s∈N B(t)∪{t} µ z st<label>(10)</label></formula><p>Input: G = (V, E) and topic distributions {θ v } v∈V Output: topic-level social influence graphs {Gz = (Vz, Ez)} T z=1</p><p>Calculate the node feature function g(v i , y i , z); Finally, according to the obtained influence scores {µ z st } and the topic distribution {θ v }, we can easily generate the topic-level social influence graphs. Specifically, for each topic z, we first filter out irrelevant nodes, i.e., nodes that have a lower probability than a predefined threshold. An alternative way is to keep only a fixed number (e.g., 1,000) of nodes for each topic-based social influence graph. (This filtering process can be also taken as a preprocessing step of our approach, which is the way we conducted our experiments.) Then, for a pair of nodes <ref type="bibr">(vs, vt)</ref> that has an edge in the original network G, we create two directed edges between the two nodes and respectively assign the social influence scores µ z st and µ z ts . Finally, we obtain a directed social influence graph G z for the topic z.</p><p>The new algorithm reduces the complexity of each iteration from O(N 4 × T ) in the sum-product algorithm to O(M × T ). More importantly, the new update rules can be easily parallelized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Distributed TAP Learning</head><p>As a social network may contain millions of users and hundreds of millions of social ties between users, it is impractical to learn a TFG from such a huge data using a single machine. To address this challenge, we deploy the learning task on a distributed system under the map-reduce programming model <ref type="bibr" target="#b8">[9]</ref>.</p><p>Map-Reduce is a programming model for distributed processing of large data sets. In the map stage, each machine (called a process node) receives a subset of data as input and produces a set of intermediate key/value pairs. In the reduce stage, each process node merges all intermediate values associated with the same intermediate key and outputs the final computation results. Users specify a map function that processes a key/value pair to generate a set of intermediate key/value pairs, and a reduce function that merges all intermediate values associated with the same intermediate key.</p><p>In our affinity propagation process, we first partition the large social network graph into subgraphs and distribute each subgraph to a process node. In each subgraph, there are two kinds of nodes: internal nodes and marginal nodes. Internal nodes are those all of whose neighbors are inside the very subgraph; marginal nodes have neighbors in other subgraphs. For every subgraph G, all internal nodes and edges between them construct the closed graph ¯ G. The marginal nodes can be viewed as "the supporting information" for updating the rules. For easy explanation, we consider the distributed learning algorithm on a single topic and thus the map stage and the reduce stage can be defined as follows.</p><p>In the map stage, each process node scans the closed graph ¯ G of the assigned subgraph G. Note that every edge eij has two values a z ij and r ij . Thus, the map function is defined as for every key/value pair e ij /a ij , it issues an intermediate key/value pair e i * /(b ij + a ij ); and for key/value pair e ij /r ij , it issues an intermediate key/value pair e * j/rij.</p><p>In the reduce stage, each process node collects all values associated with an intermediate key e i * to generate new r i * according to <ref type="bibr">Eq. (5)</ref>, and all intermediate values associated with the same key e * j to generate new a * j according to Eqs. (6) and <ref type="bibr" target="#b6">(7)</ref>. Thus, the one time map-reduce process corresponds to one iteration in our affinity propagation algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Model Application</head><p>The social influence graphs by TAP can help with many applications. Here we illustrate one application on expert identification, i.e., to identify representative nodes from social networks on a specific topic.</p><p>Here we present 3 methods for expert identification: 1) PageRank+LanguageModeling (PR), 2) PageRank with global Influence (PRI) and 3) PageRank with topic-based influence (TPRI). Baseline: PR One baseline method is to combine the language model and PageRank <ref type="bibr" target="#b23">[24]</ref>. Language model is to estimate the relevance of a candidate with the query and PageRank is to estimate the authority of the candidate. There are different combination methods. The simplest combination method is to multiply or sum the PageRank ranking score and the language model relevance score. Proposed 1: PRI In PRI, we replace the transition probability in PageRank with the influence score. Thus we have</p><formula xml:id="formula_12">r[v] = β 1 |V | + (1 − β) v :v →v r[v ]p(v|v )<label>(11)</label></formula><p>In traditional PageRank algorithm, p(v|v ) is simply the value of one divides the number of outlinks of node v . Here, we consider the influence score. Specifically we define</p><formula xml:id="formula_13">p(v|v ) = z µ z v v v j :v →v j z µ z v v j</formula><p>Proposed 2: TPRI In the second extension, we introduce, for each node v, a vector of ranking scores r <ref type="bibr">[v, z]</ref>, each of which is specific to topic z. Random walk is performed along with the coauthor relationship between authors within the same topic. Thus the topicbased ranking score is defined as:</p><formula xml:id="formula_14">r[v, z] = β 1 |V | p(z k |v) + (1 − β) v :v →v r[v , z]p(v|v , z)<label>(12)</label></formula><p>where p(z|v) is the probability of topic z generated by node v and it is obtained from the topic model; p(v|v , z) represents the probability of node v influencing node v on topic z; we define it as</p><formula xml:id="formula_15">p(v|v , z) = µ z v v v j :v →v j µ z v v j</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTAL RESULTS</head><p>In this section, we present various experiments to evaluate the efficiency and effectiveness of the proposed approach. All data sets, codes, and tools to visualize the generated influence graphs are publicly available at http://arnetminer.org/lab-datasets/soinf/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Data Sets</head><p>We perform our experiments on three real-world data sets: two homogeneous networks and one heterogeneous network. The homogeneous networks are academic coauthor network (shortly Coauthor) and paper citation network (shortly Citation). Both are extracted from academic search system Arnetminer 1 . The coauthor data set consists of 640,134 authors and 1,554,643 coauthor relations, while the citation data set contains 2,329,760 papers and 12,710,347 citations between these papers. Topic distributions of authors and papers are discovered using a statistical topic modeling approach, Author-Conference-Topic (ACT) model <ref type="bibr" target="#b24">[25]</ref>. The ACT approach automatically extracts 200 topics and assigns an authorspecific topic distribution to each author and a paper-specific topic distribution to each paper.</p><p>The other heterogeneous network is a film-director-actor-writer network (shortly Film), which is crawled from Wikipedia under the category of "English-language films" 2 . In total, there are 18,518 films, 7,211 directors, 10,128 actors, and 9,784 writers. There are 142,426 relationships between the heterogeneous nodes in the dataset. The relationship types include: film-director, film-actor, film-writer, and other relationships between actors, directors, and writers. The first three types of relationships are extracted from the "infobox" on the films' Wiki pages. All the other types of people relationships are created as follows: if one people (including actors, directors, and writers) appears on another people's page, then a directed relationship is created between them. Topic distributions of the heterogeneous network is initialized using the category information defined on the Wikipedia page. More specifically, we take 10 categories with the highest occurring times as the topics. The 10 categories are: "American film actors", "American television actors", "Black and white films", "Drama films", "Comedy films", "British films", "American film directors", "Independent films", "American screenwriters", and "American stage actors". As for the topic distribution of each node in the Film network, we first calculate how likely a node v i belong to a category (topic) z, i.e. p(v i |z), according to 1</p><formula xml:id="formula_16">|V z |</formula><p>, where |V z | is the number of nodes in the category (topic) z. Thus, for each node, we will obtain a set {p(v i |z)} T z=1 of likelihood for each node. Then we calculate the topic distribution {p(z|vi)} T z=1 according to the Bayesian rule p(z|vi) ∝ p(z)p(vi|z), where p(z) is the probability of the category (topic).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Evaluation Measures</head><p>For quantitatively evaluate our method, we consider three performance metrics:</p><p>• CPU time. It is the execution elapsed time of the computation. This determines how efficient our method is.</p><p>• Case study. We use several case studies to demonstrate how effective our method can identify the topic-based social influence graphs.</p><p>• Application improvement. We apply the identified topicbased social influence to help expert finding, an important application in social network. This will demonstrate how the quantitative measurement of the social influence can benefit the other social networking application.</p><p>The basic learning algorithm is implemented using MATLAB 2007b and all experiments with it are performed on a Server running Windows 2003 with two Dual-Core Intel Xeon processors (3.0 GHz) and 8GB memory. The distributed learning algorithm is implemented under the Map-Reduce programming model using the Hadoop platform <ref type="bibr" target="#b2">3</ref> . We perform the distributed train on 6 computer nodes (24 CPU cores) with AMD processors (2.3GHz) and 48GB memory in total. We set the maximum number of iterations as 100 and the threshold for the change of r and a to 1e − 3. The algorithm can quickly converge after 7-10 iterations in most of the times. In all experiments, for generating each of the topic-based social influence graphs, we only keep 1,000 nodes that have the highest probabilities p(v|z).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Scalability Performance</head><p>We evaluate the efficiency of our approach on the three data sets. We also compare our approach with the sum-product algorithm. <ref type="table" target="#tab_2">Table 2</ref> lists the CPU time required on the three data sets with the following observations: Sum-Product vs TAP The new TAP approach is much faster than the traditional sum-product algorithm, which even cannot complete on the citation data set. Basic vs Distributed TAP The distributed TAP can typically achieve a significant reduction of the CPU time on the large-scale network. For example, on the citation data set, we obtain a speedup 15X. While on a moderate scaled network (the coauthor data set), the speedup of the distributed TAP is limited, only 3.6. On a relative smaller network (the Film data set), the distributed learning underperforms the basic TAP learning algorithm, which is due to the communication overhead of the Map-Reduce framework. Distributed Scalability We further conduct a scalability experiment with our distributed TAP. We evaluate the speedup of the distributed learning algorithm on the 6 computer nodes using the citation data set with different sizes. It can be seen from <ref type="figure">Figure 3</ref> (a) that when the size of the data set increase to nearly one million edges, the distributed learning starts to show a good parallel efficiency (speedup&gt;3). This confirms that distributed TAP like many distributed learning algorithms is good on large-scale data sets.  Using our large citation data set, we also perform speedup experiments on a Hadoop platform using 1, 2, 4, 6 computer nodes (since we did not have access to a large number of computer nodes). The speedup, shown in 3 (b), show reasonable parallel efficiency, with a &gt; 4× speedup using 6 computer nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Qualitative Case Study</head><p>Now we demonstrate the effectiveness of TAP of representative nodes identification on the Coauthor and Citation data sets. <ref type="table" target="#tab_5">Table 4</ref> shows representative nodes (authors and papers) found by our algorithm on different topics from the coauthor data set and the citation data set. The representative score of each node is the probability of the node influencing the other nodes on this topic. The probability is calculated by</p><formula xml:id="formula_17">j∈N B(i)∪{i} µ ij N i=1</formula><p>j∈N B(i)∪{j} µ ij . We can see some interesting results. For example, some papers (e.g., "FaCT and iFaCT") that do have have a high citation number might be selected as the representative nodes. This is because our algorithm can identify the influences between papers, thus can differentiate the citations of the theoretical background of a paper and an odd citation in the reference. <ref type="table">Table 5</ref> shows four representative authors and researchers who are mostly influenced by them. <ref type="table">Table 6</ref> shows two representative papers and papers that are mostly influence by the two papers. Some other method e.g., the similarity-based baseline method using cosine metric, can be also used to estimate the influence according to the similarity score. Such a method was previously used for analyzing the social influence in online communities <ref type="bibr" target="#b5">[6]</ref>. Comparing with the similarity-based baseline method, our method has several distinct advantages: First, such a method can only measure the similarity between nodes, but cannot tell which node has a stronger influence on the other one. Second, the method cannot tell which nodes have the highest influences in the network, which our approach naturally has the capacity to do this. This provides many immediate applications, for example, expert finding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Quantitative Case Study</head><p>Now we conduct quantitatively evaluation of the effectiveness of the topic-based social influence analysis through case study. Recall the goal of expert finding is to identify persons with some expertise or experience on a specific topic (query) q. We define the baseline  method as the combination <ref type="bibr" target="#b23">[24]</ref> of the language model P (q|v) and PageRank r <ref type="bibr">[v]</ref>.</p><p>We use an academic data set used in <ref type="bibr" target="#b23">[24]</ref> [25] for the experiments. Specifically, the data set contains 14, 134 authors, 10, 716 papers, and 1, 434 conferences. Four-grade scores (3, 2, 1, and 0) are manually labeled to represent definite expertise, expertise, marginal expertise, and no expertise. Using this data, we create a coauthor network. The topic model for each author is still obtained using the statistical topic modeling approach <ref type="bibr" target="#b24">[25]</ref>. With the topic models, we apply the proposed TAP approach to the coauthor network to identify the topic-based influences.</p><p>With the learned topic-based influence scores, we define two extensions to the PageRank method: PageRank with Influence (PRI) and PageRank with topic-based influence (TPRI). Details of the extension is described in Section 3.4. For expert finding, we can further combine the extended PageRank model with the relevance model, for example the language model by P (q|v)r <ref type="bibr">[v]</ref> or a topicbased relevance model by z p(q|z)p(z|v)r <ref type="bibr">[v, z]</ref>, where r[v] and r <ref type="bibr">[v, z]</ref> are obtained respectively from PRI and TPRI; p(q|z), p(z|v) can be obtained from the statistical topic model <ref type="bibr" target="#b23">[24]</ref>.</p><p>We evaluate the performance of different methods in terms of Precision@5 (P@5), P@10, P@20, R-precision (R-Pre), and mean average precision (MAP) <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b6">7]</ref>. <ref type="figure">Figure 7</ref> shows the result of expert finding with different approaches. We see that the topic-based social influences discovered by the TAP approach can indeed improve the accuracy of expert finding, which confirms the effectiveness of the proposed approach for topic-based social influence analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Social Network and Influence</head><p>Much effort has been made for social network analysis and a large number of work has been done. For example, methods are proposed for identifying cohesive subgraphs within a network where cohesive subgraphs are defined as "subsets of actors among whom there are relatively strong, direct, intense, frequent, or positive ties" <ref type="bibr" target="#b25">[26]</ref>. Quite a few metrics have been defined to characterize a social network, such as betweenness, closeness, centrality, centralization, etc. A common application of the social network analysis is Web community discovery. For example, Flake et al. <ref type="bibr" target="#b11">[12]</ref> propose a method based on maximum flow/minmum cut to identify Web communities. As for social influence analysis, <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b20">21]</ref> propose methods to qualitatively measure the existence of influence. <ref type="bibr" target="#b5">[6]</ref> studies the correlation between social similarity and influence. Other similar  <ref type="table">Table 5</ref>: Example of influence analysis from the coauthor data set. There are two representative authors and example list of researchers who are mostly influenced by them on topic "data mining", and their corresponding influenced order on topic "database" and "machine learning".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Topic: Data Mining</head><p>Topic: Databasework can be referred to <ref type="bibr" target="#b9">[10]</ref>. To the best of our knowledge, no previous work has been conducted for quantitatively measuring the topic-level social influence on large-scale networks. For the networking data, graphical probabilistic models are often employed to describe the dependencies between observation data. Markov random field <ref type="bibr" target="#b21">[22]</ref>, factor graph <ref type="bibr" target="#b16">[17]</ref>, Restricted Boltzmann Machine(RBM) <ref type="bibr" target="#b26">[27]</ref>, and many others are widely used graphical models. One relevant work is <ref type="bibr" target="#b12">[13]</ref>, which proposes an affinity propagation algorithm for clustering by passing messages between data points. The algorithm tries to identify exemplars among data points and forms clusters of data points around these exemplars.</p><p>In this paper, we propose a Topical Factor Graph (TFG) model, for quantitatively analyzing the topic-based social influences. Compared with the existing work, the TFG can incorporate the correlation between topics. We propose a very efficient algorithm for learning the TFG model. In particular, a distributed learning algorithm has been implemented under the Map-reduce programming model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Large-scale Mining</head><p>As data grows, data mining and machine learning applications also start to embrace the Map-Reduce paradigm, e.g., news personalization with Map-Reduce EM algorithm <ref type="bibr" target="#b7">[8]</ref>, Map-Reduce of several machine learning algorithms on multicore architecture <ref type="bibr" target="#b4">[5]</ref>.</p><p>Recently Papadimitriou and Sun <ref type="bibr" target="#b19">[20]</ref> illustrates a mining framework on Map-Reduce along with a case-study using co-clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION AND FUTURE WORK</head><p>In this paper, we study a novel problem of topic-based social influence analysis. We propose a Topical Affinity Propagation (TAP) approach to describe the problem using a graphical probabilistic model. To deal with the efficient problem, we present a new algorithm for training the TFG model. A distributed learning algorithm has been implemented under the Map-reduce programming model. Experimental results on three different types of data sets demonstrate that the proposed approach can effectively discover the topicbased social influences. The distributed learning algorithm also has a good scalability performance. We apply the proposed approach to expert finding. Experiments show that the discovered topic-based influences by the proposed approach can improve the performance of expert finding.</p><p>The general problem of network influence analysis represents an new and interesting research direction in social network mining. There are many potential future directions of this work. One interesting issue is to extend the TFG model so that it can learn topic distributions and social influences together. Another issue is to design the TAP approach for (semi-)supervised learning. Users may provide feedbacks to the analysis system. How to make use of the <ref type="table">Table 6</ref>: Example of influence analysis results on topic "data mining" from the citation data set. There are two representative papers and example paper lists that are mostly influenced by them. useful supervised information to improve the analysis quality is an interesting problem. Another potential issue is to apply the proposed approach to other applications (e.g., community discovery) to further validate its effectiveness. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">*ACKNOWLEDGMENTS</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>KDD' 09 ,</head><label>09</label><figDesc>June 28-July 1, 2009, Paris, France. Copyright 2009 ACM 978-1-60558-495-9/09/06 ...$5.00.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Social influence analysis illustration using the co-author network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>The work is supported by the Natural Science Foundation of China (No. 60703059), Chinese National Key Foundation Research (No. 2007CB310803), National High-tech R&amp;D Program (No. 2009AA01Z138), and Chinese Young Faculty Research Fund (No. 20070003093).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 : Notations. SYMBOL DESCRIPTION N number of nodes in the social network M number of edges in the social network T number of topics V the set of nodes in the social network E the set of edges v i a single node y z i node-v i 's representative on topic z y i thethe social influence of node vs on node vt w.r.t. topic z</head><label>1</label><figDesc></figDesc><table>hidden vector of representatives for all topics on node v i 
θ z 

i 

the probability for topic z to be generated by the node v i 
e st 
an edge connecting node v s and node v t 
w z 

st 

the similarity weight of the edge est w.r.t. topic z 
µ z 

st 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>= (Vz, Ez) for every topic z according</head><label></label><figDesc></figDesc><table>1.1 
Calculate b z 
ij according to Eq. 8; 
1.2 
Initialize all {r z 
ij } ← 0; 
1.3 
repeat 
1.4 
foreach edge-topic pair (eij , z) do 
1.5 
Update r z 
ij according to Eq. 5; 
1.6 
end 
1.7 
foreach node-topic pair (vj , z) do 
1.8 
Update a z 
jj according to Eq. 6; 
1.9 
end 
1.10 
foreach edge-topic pair (eij , z) do 
1.11 
Update a z 
ij according to Eq. 7; 
1.12 
end 
1.13 
until convergence; 
1.14 
foreach node v t do 
1.15 
foreach neighboring node s ∈ N B(t) ∪ {t} do 
1.16 
Compute µ z 
st according to Eq. 9; 
1.17 
end 
1.18 
end 
1.19 
Generate Gz to {µ z 
st }; 
1.20 

Algorithm 1: The new TAP learning algorithm. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 2 : Scalability performance of different methods on real data sets. &gt;10hr means that the algorithm did not terminate when the algorithm runs more than 10 hours.</head><label>2</label><figDesc></figDesc><table>Methods 
Citation Coauthor Film 
Sum-Product 
N/A 
&gt;10hr 
1.8 hr 
Basic TAP Learning 
&gt;10hr 
369s 
57s 
Distributed TAP Learning 39.33m 
104s 
148s 

0 
170K 
540K 
1M 
1.7M 
0 

1 

2 

3 

4 

5 

6 

7 

1 
2 
3 
4 
5 
6 
1 

1.5 

2 

2.5 

3 

3.5 

4 

4.5 

5 

5.5 

6 

Perfect 
Our method 

(a) Dataset size vs. speedup 
(b) #Computer nodes vs. speedup 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 : Speedup results.</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Performance of expert finding with different ap-
proaches. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="true"><head>Table 4 : Representative nodes discovered by our algorithm on the Coauthor data set and the Citation data set.</head><label>4</label><figDesc></figDesc><table>Dataset 
Topic 
Representative Nodes 

Author 

Data Mining 
Heikki Mannila, Philip S. Yu, Dimitrios Gunopulos, Jiawei Han, Christos Faloutsos, Bing Liu, Vipin Kumar, Tom M. Mitchell, 
Wei Wang, Qiang Yang, Xindong Wu, Jeffrey Xu Yu, Osmar R. Zaiane 
Machine Learning 
Pat Langley, Alex Waibel, Trevor Darrell, C. Lee Giles, Terrence J. Sejnowski, Samy Bengio, Daphne Koller, Luc De Raedt, 
Vasant Honavar, Floriana Esposito, Bernhard Scholkopf 
Database System 
Gerhard Weikum, John Mylopoulos, Michael Stonebraker, Barbara Pernici, Philip S. Yu, Sharad Mehrotra, Wei Sun, V. S. Sub-
rahmanian, Alejandro P. Buchmann, Kian-Lee Tan, Jiawei Han 
Information Retrieval 
Gerard Salton, W. Bruce Croft, Ricardo A. Baeza-Yates, James Allan, Yi Zhang, Mounia Lalmas, Zheng Chen, Ophir Frieder, 
Alan F. Smeaton, Rong Jin 
Web Services 
Yan Wang, Liang-jie Zhang, Schahram Dustdar, Jian Yang, Fabio Casati, Wei Xu, Zakaria Maamar, Ying Li, Xin Zhang, Boualem 
Benatallah, Boualem Benatallah 
Semantic Web 
Wolfgang Nejdl, Daniel Schwabe, Steffen Staab, Mark A. Musen, Andrew Tomkins, Juliana Freire, Carole A. Goble, James A. 
Hendler, Rudi Studer, Enrico Motta 
Bayesian Network 
Daphne Koller, Paul R. Cohen, Floriana Esposito, Henri Prade, Michael I. Jordan, Didier Dubois, David Heckerman, Philippe 
Smets 

Citation 

Data Mining 
Fast Algorithms for Mining Association Rules in Large Databases, Using Segmented Right-Deep Trees for the Execution of 
Pipelined Hash Joins, Web Usage Mining: Discovery and Applications of Usage Patterns from Web Data, Discovery of Multiple-
Level Association Rules from Large Databases, Interleaving a Join Sequence with Semijoins in Distributed Query Processing 
Machine Learning 
Object Recognition with Gradient-Based Learning, Correctness of Local Probability Propagation in Graphical Models with Loops, 
A Learning Theorem for Networks at Detailed Stochastic Equilibrium, The Power of Amnesia: Learning Probabilistic Automata 
with Variable Memory Length, A Unifying Review of Linear Gaussian Models 
Database System 
Mediators in the Architecture of Future Information Systems, Database Techniques for the World-Wide Web: A Survey, The 
R*-Tree: An Efficient and Robust Access Method for Points and Rectangles, Fast Algorithms for Mining Association Rules in 
Large Databases 
Web Services 
The Web Service Modeling Framework WSMF, Interval Timed Coloured Petri Nets and their Analysis, The design and imple-
mentation of real-time schedulers in RED-linux, The Self-Serv Environment for Web Services Composition 
Web Mining 
Web Usage Mining: Discovery and Applications of Usage Patterns from Web Data, Fast Algorithms for Mining Association Rules 
in Large Databases, The OO-Binary Relationship Model: A Truly Object Oriented Conceptual Model, Distributions of Surfers' 
Paths Through the World Wide Web: Empirical Characterizations, Improving Fault Tolerance and Supporting Partial Writes in 
Structured Coterie Protocols for Replicated Objects 
Semantic Web 
FaCT and iFaCT, The GRAIL concept modelling language for medical terminology, Semantic Integration of Semistructured and 
Structured Data Sources, Description of the RACER System and its Applications, DL-Lite: Practical Reasoning for Rich Dls 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Fast Algorithms for Mining Association Rules in Large Databases Web Usage Mining: Discovery and Applications of Usage Patterns from Web Data Mining Large Itemsets for Association Rules A New Framework For Itemset Generation Efficient Mining of Partial Periodic Patterns in Time Series Database A New Method for Similarity Indexing of Market Basket Data A General Incremental Technique for Maintaining Discovered Association Rules Mining Web Site?s Clusters from Link Topology and Site Hierarchy Predictive Algorithms for Browser Support of Habitual User Activities on the Web A Fine Grained Heuristic to Capture Web Navigation Patterns A Road Map to More Effective Web Personalization: Integrating Domain Knowledge with Web Usage Mining</head><label>Fast</label><figDesc></figDesc><table></table></figure>

			<note place="foot" n="1"> http://arnetminer.org 2 http://en.wikipedia.org/wiki/Category: English-language_films</note>

			<note place="foot" n="3"> http://hadoop.apache.org/</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Statistical mechanics of complex networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Barabasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reviews of Modern Physics</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Influence and correlation in social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anagnostopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mahdian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD&apos;08)</title>
		<meeting>eeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD&apos;08)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="7" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Retrieval evaluation with incomplete information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR&apos;04</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Map-Reduce for machine learning on multicore</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-T</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-A</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Bradski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Olukotun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Neural Information Processing Systems (NIPS&apos;06)</title>
		<meeting>the 18th Neural Information Processing Systems (NIPS&apos;06)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Feedback effects between similarity and social influence in online communities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cosley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huttenlocher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD&apos;08)</title>
		<meeting>eeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD&apos;08)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="160" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Overview of the trec-2005 enterprise track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>De Vries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TREC 2005 Conference Notebook</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="199" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Google news personalization: Scalable online collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Datar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rajaram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 16th international conference on World Wide Web (WWW&apos;07)</title>
		<meeting>eeding of the 16th international conference on World Wide Web (WWW&apos;07)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Mapreduce: Simplified data processing on large clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th conference on Symposium on Opearting Systems Design &amp; Implementation (OSDI&apos;04)</title>
		<meeting>the 6th conference on Symposium on Opearting Systems Design &amp; Implementation (OSDI&apos;04)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="10" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Extraction and classification of dense communities in the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dourisboure</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Geraci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pellegrini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;07</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="461" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On power-law relationships of the internet topology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGCOMM</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="251" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Efficient identification of web communities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Flake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining (KDD&apos;00)</title>
		<meeting>the sixth ACM SIGKDD international conference on Knowledge discovery and data mining (KDD&apos;00)</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="150" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Mixture modeling by affinity propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dueck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 18th Neural Information Processing Systems (NIPS&apos;06)</title>
		<meeting>the 18th Neural Information Processing Systems (NIPS&apos;06)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="379" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The strength of weak ties</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Granovetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Sociology</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1360" to="1380" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Probabilistic latent semantic indexing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Research and Development in Information Retrieval (SIGIR&apos;99)</title>
		<meeting>the 22nd International Conference on Research and Development in Information Retrieval (SIGIR&apos;99)</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="50" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The Strength of Strong ties: the importance of philos in networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krackhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Networks and Organizations</title>
		<editor>Book of Nitin Nohria and Robert G. Eccles</editor>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Harvard Business School Press</publisher>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Factor graphs and the sum-product algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Kschischang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Member</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Loeliger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="498" to="519" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Topic modeling with network regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International World Wide Web Conference (WWW&apos;08)</title>
		<meeting>the 17th International World Wide Web Conference (WWW&apos;08)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The structure and function of complex networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Reviews</title>
		<imprint>
			<biblScope unit="page">45</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Disco: Distributed co-clustering with map-reduce</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Papadimitriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Data Mining (ICDM&apos;08)</title>
		<meeting>IEEE International Conference on Data Mining (ICDM&apos;08)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Yes, there is a correlation: -from social networks to personal behavior on the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Singla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of the 17th international conference on World Wide Web (WWW&apos;08)</title>
		<meeting>eeding of the 17th international conference on World Wide Web (WWW&apos;08)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="655" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Information processing in dynamical systems: foundations of harmony theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Smolensky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<biblScope unit="page" from="194" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Exploring complex networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Strogatz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">410</biblScope>
			<biblScope unit="page" from="268" to="276" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A topic modeling approach and its integration into the random walk framework for academic search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Data Mining (ICDM&apos;08)</title>
		<meeting>IEEE International Conference on Data Mining (ICDM&apos;08)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1055" to="1060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Arnetminer: Extraction and mining of academic social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (SIGKDD&apos;08)</title>
		<meeting>the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (SIGKDD&apos;08)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="990" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wasserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Faust</surname></persName>
		</author>
		<title level="m">Social Network Analysis: Methods and Applications</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A new learning algorithm for mean field boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Artificial Neural Network (ICANN&apos;01)</title>
		<meeting>International Conference on Artificial Neural Network (ICANN&apos;01)</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="351" to="357" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
