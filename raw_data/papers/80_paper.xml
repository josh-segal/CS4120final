<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:29+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Landmarks, Critical Paths and Abstractions: What&apos;s the Difference Anyway?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malte</forename><surname>Helmert</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Technion Faculty of Industrial Engineering and Management</orgName>
								<orgName type="institution">Albert-Ludwigs-Universität Freiburg Institut für Informatik Georges-Köhler-Allee</orgName>
								<address>
									<postCode>52 79110, 32000</postCode>
									<settlement>Freiburg, Haifa</settlement>
									<country>Germany, Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carmel</forename><surname>Domshlak</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Technion Faculty of Industrial Engineering and Management</orgName>
								<orgName type="institution">Albert-Ludwigs-Universität Freiburg Institut für Informatik Georges-Köhler-Allee</orgName>
								<address>
									<postCode>52 79110, 32000</postCode>
									<settlement>Freiburg, Haifa</settlement>
									<country>Germany, Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Landmarks, Critical Paths and Abstractions: What&apos;s the Difference Anyway?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Current heuristic estimators for classical domain-independent planning are usually based on one of four ideas: delete relax-ations, critical paths, abstractions, and, most recently, landmarks. Previously, these different ideas for deriving heuristic functions were largely unconnected. We prove that admissible heuristics based on these ideas are in fact very closely related. Exploiting this relationship, we introduce a new admissible heuristic called the landmark cut heuristic, which compares favourably with the state of the art in terms of heuristic accuracy and overall performance.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Heuristic search, either in the space of world states reached through progression or in the space of subgoals reached through regression, is a common and successful approach to classical planning. For example, at the recent 6th International Planning Competition <ref type="bibr">(IPC-2008)</ref>, the three bestperforming satisficing planners and two of the three bestperforming optimal planners in the sequential planning tracks followed this paradigm. <ref type="bibr">1</ref> Apart from the choice of search algorithm, the main feature that distinguishes heuristic planners is their heuristic estimator. Most current heuristic functions are based on one of the following four ideas:</p><p>1. delete relaxations: e. g., h + , h max , h add , h FF , h pmax , h sa 2. critical paths: the h m heuristic family 3. abstractions: pattern databases, merge-and-shrink abstractions, and structural patterns 4. landmarks: LAMA's h LM , and the admissible landmark heuristics h L and h LA We discuss these heuristics in detail and provide literature references later. For now, we remark that these four ideas have been developed in relative isolation. Indeed, apart from <ref type="bibr" target="#b7">Haslum and Geffner's (2000)</ref> result that h max is a special case of the h m family (h max = h 1 ), we are not aware of any published formal connections.</p><p>In this paper, we prove further results that relate the quality of heuristics from the above four families. We limit our Copyright c 2009, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. <ref type="bibr">1</ref> See http://ipc.informatik.uni-freiburg.de.</p><p>attention to admissible heuristics because it is hard to define a notion of "heuristic quality" for inadmissible heuristics that is independent of the search algorithm being used. Admissible heuristics, in contrast, have a clear notion of dominance: if h 1 (s) ≥ h 2 (s) for all states s, then h 1 is superior or equal to h 2 in terms of heuristic quality, with provable consequences for the performance of optimal search algorithms. In the theoretical part of this paper, we establish several such dominance results:</p><p>• Landmark heuristics dominate additive h max heuristics.</p><p>• Additive h max heuristics dominate landmark heuristics.</p><p>• Additive critical path heuristics with m ≥ 2 strictly dominate landmark heuristics and additive h max heuristics.</p><p>• Merge-and-shrink abstractions strictly dominate landmark heuristics and additive h max heuristics.</p><p>• Pattern database abstractions are incomparable with landmark heuristics and additive h max heuristics. These statements are informal summaries, and some restrictions apply. In particular, the results for landmark heuristics only apply to relaxation-based landmarks which are verifiable by a relaxed planning graph criterion. (All landmark heuristics considered in the literature fall into this class.) On the positive side, all results are constructive, showing how to compute a dominating heuristic in polynomial time.</p><p>As a result of our dominance proofs, we obtain a new admissible heuristic called the landmark cut heuristic h LM-cut , which can alternatively be viewed as a landmark heuristic, a cost partitioning scheme for additive h max , or an approximation to the (intractable) optimal relaxation heuristic h + . We experimentally demonstrate that h LM-cut gives excellent approximations to h + and compares favourably to other admissible heuristics in terms of accuracy. Moreover, we show an optimal planner based on the landmark cut heuristic to be highly competitive with the state of the art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preliminaries</head><p>STRIPS planning. For the theoretical results of this paper, we use the propositional STRIPS formalism augmented with non-negative actions costs (e. g., <ref type="bibr" target="#b18">Keyder and Geffner, 2008)</ref>. Some of the heuristics we discuss were originally introduced for the more general SAS + formalism <ref type="bibr" target="#b0">(Bäckström and Nebel 1995)</ref>, to which our results apply equally. Definition 1 (planning task) A planning task is a 4-tuple Π = V, O, I, G, where • V is a finite set of propositional state variables, • O is a finite set of operators, each with associated preconditions pre(o) ⊆ V , add effects add(o) ⊆ V , delete effects del(o) ⊆ V and cost cost(o) ∈ R + 0 , • I ⊆ V is the initial state, and • G ⊆ V is the set of goals.</p><p>State variables of planning tasks are also called propositions or facts. A state in our formalism is a subset of facts, representing the propositions which are currently true. States can alternatively be defined as assignments to state variables, but set notation is more convenient for the purposes of this paper. Applying an operator o in s results in state (s\del(o))∪add(o), which we denote as s <ref type="bibr">[o]</ref>. The notation is only defined if o is applicable in s, i. e., if pre(o) ⊆ s.</p><p>Applying a sequence o 1 , . . . , o n of operators to a state is defined inductively as</p><formula xml:id="formula_0">s[] := s and s[o 1 , . . . , o n+1 ] := (s[o 1 , . . . , o n ])[o n+1 ].</formula><p>A plan for a state s (s-plan, or plan when s is clear from context) is an operator sequence π such that s <ref type="bibr">[π]</ref> is defined and satisfies all goals (i. e.,</p><formula xml:id="formula_1">G ⊆ s[π]). The cost of plan π is cost(π) := n i=1 cost(o i ).</formula><p>The objective of optimal planning is to find an I-plan of minimal cost (called an optimal I-plan) or prove that no plan exists.</p><p>Heuristics. Heuristic functions or heuristics are a key ingredient of heuristic search planners. A heuristic is a function h : 2 V → R + 0 ∪ {∞} with the intuition that h(s) estimates the cost of an s-plan. The perfect heuristic h * maps each state to the cost of an optimal s-plan (infinite if no splan exists). A heuristic h is admissible if h(s) ≤ h * (s) for all states s. All common heuristic search algorithms for optimal planning require admissible heuristics. If h(s) ≥ h (s) for all states s, we say that h dominates h .</p><p>Cost partitioning. If h 1 , . . . , h k are admissible heuristics, then their pointwise maximum is an admissible heuristic dominating each individual heuristic. Under certain conditions, their pointwise sum, which dominates the maximum, is also admissible. Many recent advances in the accuracy of admissible planning heuristics are due to better, more finegrained methods for finding admissible additive heuristics. <ref type="bibr" target="#b16">Katz and Domshlak (2008a)</ref> introduced a very general criterion for admissible additive combinations. Let Π, Π 1 , . . . , Π k be planning tasks which are identical except for the operator costs. Let cost : O → R + 0 denote the operator cost function for Π and cost i : O → R + 0 denote the operator cost functions for</p><formula xml:id="formula_2">Π i . If k i=1 cost i (o) ≤ cost(o)</formula><p>for all operators o ∈ O, then the sum of arbitrary admissible heuristics for Π i is an admissible heuristic for Π. We call such a separation of Π into planning tasks Π 1 , . . . , Π k with smaller operator costs a cost partitioning of Π.</p><p>Cost partitioning offers a very flexible way of additively combining different heuristic estimates in an admissible way. In particular, it subsumes earlier additivity criteria for pattern database heuristics by <ref type="bibr" target="#b5">Edelkamp (2001)</ref> and for general admissible heuristics by <ref type="bibr" target="#b9">Haslum et al. (2005)</ref>.</p><p>Of course, different cost partitionings for the same component heuristics lead to overall heuristics of different quality, and the question of how to automatically derive a good cost partitioning has attracted considerable interest. At least theoretically, this question has recently been fully resolved for abstraction heuristics <ref type="bibr" target="#b16">(Katz and Domshlak 2008a)</ref> and landmark heuristics <ref type="bibr" target="#b15">(Karpas and Domshlak 2009)</ref> with the development of algorithms that compute an optimal cost partitioning for a given state and component heuristic set in polynomial time. Practically, it is still an interesting question how to reduce the time requirements of these optimal partitioning algorithms or come up with approximate results quickly. For relaxation heuristics and critical path heuristics, the question of optimal cost partitioning remains open. Suboptimal algorithms have been presented by <ref type="bibr" target="#b9">Haslum et al. (2005)</ref> and by <ref type="bibr" target="#b4">Coles et al. (2008)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Planning Heuristics</head><p>We now formally introduce the heuristic functions we consider in our analysis.</p><p>Relaxation heuristics. Relaxation heuristics estimate the cost of reaching a goal state by considering a relaxed task Π + derived from the actual planning task Π by ignoring all delete effects of operators, i. e., replacing each operator o by a new operator o + with the same preconditions, add effects and cost as o and del(o + ) = ∅. (Notation: if S is an operator set, S + denotes the set</p><formula xml:id="formula_3">{ o + | o ∈ S }.)</formula><p>The idealized h + heuristic (Hoffmann and Nebel 2001) uses the cost of an optimal s-plan in Π + as the heuristic estimate for state s. This is an admissible heuristic that is often very informative <ref type="bibr" target="#b14">(Hoffmann 2005;</ref><ref type="bibr" target="#b10">Helmert and Mattmüller 2008;</ref><ref type="bibr" target="#b1">Betz 2009</ref>), but NP-hard to compute <ref type="bibr">(By- lander 1994)</ref>. Due to its computational complexity, the h + heuristic has not been used in a domain-independent planning system. Instead, inadmissible estimates of h + such as the additive heuristic <ref type="bibr" target="#b2">(Bonet and Geffner 2001)</ref>, FF heuristic ( <ref type="bibr" target="#b13">Hoffmann and Nebel 2001)</ref>, pairwise max heuristic ( <ref type="bibr" target="#b19">Mirkis and Domshlak 2007)</ref> or set-additive heuristic <ref type="bibr" target="#b18">(Keyder and Geffner 2008)</ref> are commonly used. Inadmissible estimates of h + cannot be admissible heuristics (consider the case Π = Π + ), and hence we do not discuss them further.</p><p>Instead, we focus on the max heuristic h max <ref type="bibr" target="#b2">(Bonet and Geffner 2001)</ref>, which provides an admissible estimate for h + . The h max value of a state s of planning task V, O, I, G is defined in terms of proposition costs The max heuristic is often not very informative, but this weakness can be overcome to a large extent by using suitable cost partitioning (e. g., <ref type="bibr" target="#b4">Coles et al., 2008)</ref>. In this case, all component heuristics are copies of the h max heuristic with different cost functions. We will call such heuristics additive h max heuristics. Note that all additive h max heuristics are admissible heuristics for Π + and hence dominated by h + .</p><p>Critical path heuristics. The h m heuristics (Haslum and Geffner 2000) estimate goal distances by computing lowerbound estimates on the cost of achieving sets of facts of cardinality m, where m ∈ N 1 is a parameter. Roughly speaking, the underlying simplifying assumption is that a set of facts is reachable with cost K iff all its m-subsets are reachable with cost K. Computing h m (s) requires polynomial time for fixed m, but exponential time in m.</p><p>We call the h m family critical path heuristics because their heuristic estimate is based on the length of the most expensive branch in a tree-shaped plan (not unlike a partialorder plan) for the simplified problem. All h m heuristics are admissible. In typical planning benchmarks, the h m heuristics have unbounded relative error ( <ref type="bibr" target="#b10">Helmert and Mattmüller 2008)</ref>, but as with h max = h 1 this weakness can be overcome by suitable cost partitioning. For all m ≥ 2, h m dominates h m−1 and is incomparable with h + .</p><p>Abstraction heuristics. Abstraction heuristics map each state s of Π to an abstract state α(s) through a homomorphism function α. The heuristic value h α (s) is then the distance from α(s) to the nearest abstract goal state in the transition system induced by α on the transition system of Π. This always leads to an admissible heuristic because each plan for Π has a corresponding abstract plan with the same cost. The real cost can be underestimated because α is generally not injective and hence not every abstract plan corresponds to a plan for Π.</p><p>Different abstraction mappings lead to heuristics of different quality. Examples include pattern databases <ref type="bibr" target="#b5">(Edelkamp 2001;</ref><ref type="bibr" target="#b9">Haslum, Bonet, and Geffner 2005;</ref><ref type="bibr" target="#b8">Haslum et al. 2007)</ref>, merge-and-shrink abstractions <ref type="bibr" target="#b12">(Helmert, Haslum, and Hoffmann 2007)</ref> and structural patterns <ref type="bibr" target="#b17">(Katz and Domshlak 2008b)</ref>. <ref type="bibr" target="#b16">Katz and Domshlak (2008a)</ref> showed that optimal cost partitions for an ensemble of abstraction heuristics can be computed in polynomial time. However, finding an abstraction mapping that is compactly representable and leads to an informative heuristic remains difficult.</p><p>Landmark heuristics. A fact landmark for a state s is a fact that is true at some point in every s-plan. The first planning algorithm exploiting fact landmarks was presented by <ref type="bibr" target="#b20">Porteous et al. (2001)</ref>. The first (inadmissible) landmarkbased heuristic is due to <ref type="bibr" target="#b21">Richter et al. (2008)</ref>, and several admissible landmark heuristics have recently been defined by <ref type="bibr" target="#b15">Karpas and Domshlak (2009)</ref>. The latter papers use extended notions of landmarks which are subsumed by disjunctive action landmarks: sets of actions of which at least one is part of every s-plan. Since this is the most general and (for this paper) useful notion of landmarks, we simply refer to disjunctive action landmarks for a state s as s-landmarks.</p><p>Deciding whether an operator set L ⊆ O is an s-landmark in a planning task Π is PSPACE-hard (Porteous, Sebastia, and  and therefore existing landmark heuristics employ a sufficient criterion based on relaxed planning graphs. This criterion is equivalent to testing whether L + is an s-landmark in the delete relaxation Π + . For this reason, the existing landmark heuristics assign the same heuristic value to states of Π and Π + , and therefore they are relaxation heuristics in the sense that they are dominated by h + (if they are admissible). We only consider relaxation-based landmarks in this paper, but more general landmarks are certainly conceivable, for example based on reachability criteria for higher-order critical path heuristics.</p><p>The elementary landmark heuristic for planning task Π and operator subset L assigns the estimate min o∈L cost(o) to a state s if L + is an s-landmark of Π + and 0 otherwise. This is clearly admissible: if L + is an s-landmark, one of its elements must be contained in every plan for Π + and hence at least the cost of the cheapest operator in L must be paid. The admissible heuristics of Karpas and Domshlak can be understood as cost partitionings over sets of elementary landmark heuristics. This is a slightly idealized view because their search algorithm does not actually test for each search state whether an operator set is a landmark but rather uses a more efficiently computable sufficient criterion that loses some heuristic accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Landmarks vs. h max vs. Abstractions</head><p>We now present the main theorems relating admissible landmark heuristics to additive h max heuristics and abstraction heuristics. All our results take on the form of per-state compilations: given a state s, a planning task Π and an additive ensemble of heuristics h 1 , . . . , h k from a given class (e. g., elementary landmark heuristics), we show how to compute an additive ensemble of heuristics from another class (e. g., merge-and-shrink abstraction heuristics)</p><formula xml:id="formula_4">h 1 , . . . , h m with m i=1 h i (s) ≥ k i=1 h i (s).</formula><p>We only discuss the case k = 1, which suffices: general results follow by compiling the component heuristics individually. Our algorithms are polynomial in Π, which prevents some trivial compilations. (For example, exponential-size abstractions can always represent the perfect heuristic h * , which dominates everything.) Throughout this section, Π = V, O, I, G is the given planning task and we assume that the heuristic value is to be computed for the state I.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>From Landmarks to Abstractions</head><p>We first consider compilations from elementary landmark heuristics to abstraction heuristics, namely to pattern databases and merge-and-shrink abstractions. The converse compilations are clearly not possible in general because, unlike elementary landmark heuristics, neither of these abstraction heuristics are bounded by h + . For pattern database heuristics, we prove a negative result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 1 (Landmarks to pattern databases)</head><p>There is no polynomial-time compilation of elementary landmark heuristics into pattern database heuristics.</p><p>Proof sketch: Consider the planning task family (Π n ) n∈N1 where Π n has state variables {v 1 , . . . , v n , g}, initial state ∅, goal {g} and an operator set containing, for each i ∈ {1, . . . , n}, one "setup operator" of cost 1 that achieves {v i } with no preconditions and one "goal operator" of cost 0 that achieves the goal {g} with precondition {v i }.</p><p>The set of all setup operators forms an I-landmark in Π n , and we get h(I) = 1 for the associated elementary landmark heuristic. However, all pattern database heuristics h for Π n that project away at least one state variable yield h (I) = 0, and the polynomial-time requirement demands that some variables need to be projected away for large n.</p><p>The weakness of pattern databases exploited in our proof is that their capabilities for representing "disjunctive resources" like the facts v i are very limited. We remark that this does not apply to symbolic pattern databases <ref type="bibr" target="#b6">(Edelkamp 2002)</ref>, which have exponentially more compact representations than traditional pattern databases on some planning tasks. Merge-and-shrink abstractions <ref type="bibr" target="#b12">(Helmert, Haslum, and Hoffmann 2007)</ref> are another class of abstraction heuristics that do not share this weakness. Indeed, they are powerful enough to completely capture landmark heuristics. Theorem 2 (Landmarks to merge-and-shrink abstractions) Elementary landmark heuristics can be compiled into merge-and-shrink heuristics in polynomial time.</p><p>Proof sketch: We are given the elementary landmark heuristic h for the operator subset L. Let V be the set of facts that can be reached from I in Π + without using the operators L + . The set V can be computed in polynomial time by a standard relaxed exploration. Now consider the abstraction heuristic h induced by</p><formula xml:id="formula_5">α(s) = ˜ s 1 if s ⊆ V ˜ s 2 if s ⊆ V</formula><p>(where the abstract state space consists of only two states).</p><p>We must show that α can be computed as a merge-andshrink abstraction in polynomial time. But this is easy to see: we can use a linear merge strategy with an arbitrary variable order and shrink all intermediate abstract transition graphs to two abstract states, one corresponding to all states where the state variables not in V that were considered so far in the heuristic construction all have value 0, and the other corresponding to all other states. Now let us compare h (I) to h(I). If L + is not an Ilandmark of Π + , then h(I) = 0 and hence clearly h (I) ≥ h(I). So consider the case where L + is an I-landmark of Π + . This implies that G ⊆ V , and hence s * ⊆ V for all goal states s * , which shows that α(s * ) = ˜ s 2 for all goal state. Therefore, ˜ s 2 is the only abstract goal state. Moreover, α(I) = ˜ s 1 , as clearly I ⊆ V . All abstract plans must therefore perform a transition from˜sfrom˜ from˜s 1 tõ s 2 , and h (I) is the minimal cost of all such transitions.</p><p>Assume that there is a state transition in Π from a state s 1 ⊆ V (i. e., a state with α(s 1 ) = ˜ s 1 ) to a state s 2 ⊆ V (i. e., a state with α(s 2 ) = ˜ s 2 ) by an operator o / ∈ L. Then the relaxation of o is applicable in state s 1 in Π + and leads to a state s 2 ⊆ V , which contradicts the definition of V . Hence, all abstract transitions from˜sfrom˜ from˜s 1 tõ s 2 are induced by some operator from L and thus have cost at least min o∈L cost(o). Because all abstract solutions must contain such a transition, we get h (I) ≥ min o∈L cost(o) = h(I).</p><p>This concludes our comparison of landmark heuristics and abstraction heuristics: landmark heuristics are strictly less powerful than merge-and-shrink abstractions and incomparable to pattern database heuristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>From Landmarks to h max and Back</head><p>We now move away from abstraction heuristics and consider the relationship between landmark heuristics and the max heuristic. Our first result has a simple proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 3 (Landmarks to h max )</head><p>Elementary landmark heuristics can be compiled into additive h max heuristics in polynomial time. Proof sketch: We are given the elementary landmark heuristic h for the operator subset L. We directly compile h to the h max heuristic for the same planning task (i. e., we do not perform additional cost partitioning). Again, let L + be the relaxed operators induced by L.</p><p>As in the proof of Theorem 2, if L + is not an I-landmark of Π + , then clearly h max (I) ≥ 0 = h(I). If L + is an I-landmark of Π + , then Π + is not solvable without using some operator in L + , which means that h max (I) would be infinite if the operators in L did not exist. This implies that if h max (I) = ∞, then the cost computation for h max (I) must make use of at least one of the operators in L, and hence h max (I) ≥ min o∈L cost(o) = h(I).</p><p>Extending this result to arbitrary cost partitionings, we observe that additive h max heuristics are at least as powerful as admissible landmark heuristics. We now show (maybe somewhat more surprisingly) that the converse is also true under a small additional condition. Theorem 4 (h max to landmarks) For states with finite h max value, the h max heuristic can be compiled into additive elementary landmark heuristics in polynomial time.</p><p>Proof sketch: If h max (I) = 0, there is nothing to prove. Otherwise, we show how to find a cost partitioning cost = cost 1 + cost 2 for Π with two heuristics h 1 and h 2 such that</p><formula xml:id="formula_6">• h max (I) ≤ h 1 (I) + h 2 (I),</formula><p>• h 1 is an elementary landmark heuristic with cost function cost 1 , and • h 2 is the h max heuristic with cost function cost 2 . The reduction is then applied recursively to h 2 if h 2 (I) &gt; 0. As we show later, the set of zero cost operators is strictly larger for cost 2 than for cost, so that the process terminates in polynomially many (at most |O|) steps. We now describe how to find the landmark that defines heuristic h 1 and how to perform the cost partitioning of cost into cost 1 and cost 2 .</p><p>Without loss of generality, we assume that there exists at least one fact in I, at least one fact in G, and that each operator has at least one precondition. (If necessary, add a "dummy fact" d to I, G and all preconditions.) We first determine the h max cost values of all facts V and then compute a modified planning task Π obtained from Π + by two transformations. First, we turn the goal set and all operator preconditions into singleton sets by keeping only one fact with maximal h max cost among the set elements. This is a further relaxation of Π + because we drop goals and operator preconditions while leaving all else identical. Because we keep the h max cost maximizers in each condition, h max (I) is not changed by this transformation. In the second transformation step, we replace each operator o with pre(o) = {p} and add(o) = {a 1 , . . . , a k } with k operators o 1 , . . . , o k with pre(o i ) = {p} and add(o i ) = {a i } for i ∈ {1, . . . , k}. That is, operators are split up according to their add effects. Again, it is easy to verify that this transformation does not affect the h max value.</p><p>The resulting planning task, which we call Π , has a singleton goal set and all operators have exactly one precondition, exactly one add effect, and no delete effects. Based on Π , we define a directed weighted graph G Π whose vertices are the facts of Π and which has an arc from u to v with weight w iff Π has an operator with precondition u, add effect v and cost w. (Parallel arcs are possible for multiple operators with identical precondition and effect.) We call this graph a justification graph for Π because, even though it describes a planning task much simpler than Π, it retains enough information to justify the h max costs of Π. The h max cost of a fact v is the length of a shortest path in the justification graph from some fact in I to v.</p><p>A cut in the justification graph is a set of arcs of G Π such that all paths from some fact in I to the goal fact g traverse at least one such arc. Cuts in the justification graph are guaranteed to exist: for example, the set of all arcs clearly forms a cut. (We cannot have g ∈ I because h max (I) &gt; 0.) Cuts in the justification graph correspond to I-landmarks of Π : without the operators of Π that define the cut, Π cannot be solved. Due to the construction of Π as a further relaxation of Π + , this implies that the operators L + that induce the cut form a landmark of Π + .</p><p>Given a cut, we can compile h max into an elementary landmark heuristic h 1 that represents the cut and a remaining h max heuristic h 2 that represents everything else. In detail, we choose as h 1 the elementary landmark heuristic for the landmark L that corresponds to the cut, and associate with it the cost function cost 1 that assigns cost c min := min o∈L cost(o) to all operators o ∈ L and cost 0 to all other operators. The heuristic h 2 is the h max heuristic with cost function cost 2 := cost − cost 1 . To complete the proof, we need to find a cut that guarantees (a) c min &gt; 0 and (b) h 1 (I) + h 2 (I) ≥ h max (I). Condition (a) ensures that cost 2 has more zero-cost actions than cost and hence the partitioning process eventually terminates. Condition (b) ensures that we obtain a heuristic value at least as large as the initial h max (I) estimate.</p><p>To find a suitable cut, we partition the facts of Π into three sets:</p><p>• the goal zone V * , consisting of all facts from which the goal fact g can be reached in G Π through a path of cost 0. The goal zone is disjoint from I because otherwise we would have h max (I) = 0.</p><p>• the before-goal zone V 0 , consisting of all facts that can be reached from I in G Π without ever entering V * , and • the beyond-goal zone, consisting of everything else.</p><p>As our cut, we choose the set of all arcs from facts in V 0 to facts in V * . Let L be the set of operators inducing the cut. We now show that this satisfies conditions (a) and (b) above.</p><p>For (a), assume that c min = 0, i. e., cost(o) = 0 for some o ∈ L. Then there is an arc of weight 0 from some v 0 ∈ V 0 to some v * ∈ V * . But this violates the definition of the goal zone V * , because then there would be a 0-cost path from v 0 to the goal fact g and v 0 should be included in V * . This is a contradiction, and we can conclude that c min &gt; 0. For (b), we know that L + is an I-landmark of Π + and hence h 1 (I) = min o∈L cost 1 (o) = c min . It remains to be shown that h 2 (I) ≥ h max (I)−c min . In words, we must show that reducing the cost of the operators in L by c min does not decrease the h max value of the task by more than c min . To see this, observe that we can require that every "reasonable" path in the justification graph from I to the goal fact only passes from V 0 to V * (and hence uses an operator from L) once: as soon as the goal zone is reached, the goal fact can be reached free of cost, and thus, once the goal zone is reached, it should not be left again. Hence, reducing the costs of the operators in L by c min cannot reduce the goal distances in the justification graph by more than c min . Since the goal distances correspond to the h max costs of Π and Π is a relaxation of Π + in terms of h max value, we can conclude that the cost reduction only reduces the h max value of Π by at most c min . This concludes the proof.</p><p>We remark that the restriction of the theorem to states with finite h max values is necessary because elementary landmark heuristic values -and hence their admissible additive combinations -are always finite. However, in practical applications of the compilation algorithm this restriction is not problematic because infinite h max estimates can be detected in the first compilation step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion of the Compilation Results</head><p>Our compilation results are summarized in <ref type="figure" target="#fig_1">Fig. 1</ref>. <ref type="bibr">2</ref> There are two results we consider quite surprising, namely the equivalence of additive h max and additive landmarks, and the fact that these heuristics are strictly dominated by merge-andshrink heuristics. Besides being an academic curiosity, do these results have any further implications for the study of admissible planning heuristics?</p><p>For the compilation of additive h max /landmarks to mergeand-shrink heuristics, we do not see any immediate application. The reduction in Theorem 2 appears too costly to use for every state of a search, and also it typically leads to a heuristic estimate that is no larger than for the original landmark heuristic. Still, it is worth noting that our results imply that the scaling behaviour of abstraction heuristics can be at least as good as that of landmark heuristics -opposite to recent experimental evidence (cf. the scaling experiments by <ref type="bibr" target="#b15">Karpas and Domshlak, 2009)</ref>. This suggests that there is scope for improving the current methods for generating merge-and-shrink abstractions. However, we have no immediate insights on how such improvements could be obtained.</p><p>Regarding the equivalence of additive h max and admissible landmark heuristics, however, there are some immediate consequences of our result which we consider to be of interest. Firstly, we get some insights into the problem of computing optimal additive h max heuristics, about which very little was known previously (cf. the discussion of <ref type="bibr" target="#b16">Katz and Domshlak, 2008a</ref>). We now know that this problem is equivalent to finding an optimal admissible landmark heuristic, for which we can at least provide a brute force algorithm: generate all possible disjunctive fact landmark heuristics, then compute an optimal cost decomposition. Since there are exponentially many possible disjunctive fact landmarks, this is an exponential algorithm and hence not practical, but this is still an improvement over the previous situation where no algorithm for optimal additive h max was known.</p><p>Secondly, the reduction used in Theorem 4 can actually be used in practice to improve the heuristic estimates of a given additive h max heuristic. The computation of a single cut can be performed in O(Π), the same asymptotic time it takes to compute a single h max estimate. The overall runtime of the procedure is then bounded by O(|O| · Π), no worse than the time required for computing h 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Landmark Cut Heuristic</head><p>One way to make use of the reduction from additive h max to landmarks is to apply it to the simplest possible additive h max heuristic, namely to standard h max without any cost decomposition. This results in a heuristic that estimates goal distances by repeatedly computing landmarks that constitute cuts in justification graphs, until the generated landmarks have eroded so much cost from the original h max heuristic that no further cuts of nonzero cost can be found. We have implemented the resulting heuristic, which we call the landmark cut heuristic h LM-cut , and performed two experiments with it. In the first experiment, we focus on heuristic accuracy, without regard for computation time. In the second experiment, we consider the use of the heuristic within an A * -based optimal planning algorithm.</p><p>Our planner implementation is built on the implementation of merge-and-shrink abstractions by . We evaluate on all IPC benchmark domains supported by that system.</p><p>All experiments were conducted on Linux computers with 3 GHz Intel E8400 CPUs using a 30 minute timeout. We set  <ref type="bibr">(20)</ref> 47.00 2.00 n/a 47.00 47.00 47.00 Logistics-2000 <ref type="bibr">(26)</ref> 35.12 5.85 31.42 33.81 35.00 35.12 Miconic-STRIPS <ref type="bibr">(150)</ref> 50.47 2.99 5.11 32.00 50.47 50.47 Pathways <ref type="bibr">(5)</ref> 15.60 5.80 5.80 9.00 7.60 15.60 PSR-Small <ref type="bibr">(50)</ref> 3.14 1.46 2.78 2.46 3.14 3.14 TPP <ref type="bibr">(18)</ref> 32.17 6.39 n/a n/a 17.61 32.17 Depot <ref type="bibr">(10)</ref> 20.90 4.70 14.80 17.40 17.50 20.50 Driverlog <ref type="bibr">(14)</ref> 15.50 4.71 10.71 12.00 13.43 15.00 Grid <ref type="bibr">(2)</ref> 15.00 10.50 10.50 11.50 11.50 14.00 <ref type="bibr">Logistics-1998 (10)</ref> 27  a 1.5 GB memory limit except for runs with the Gamer planner, which for technical reasons required 2 GB of memory. Accuracy. To evaluate its accuracy, we compare the landmark cut heuristic to other heuristics from the same class, i. e., based on h max or landmarks. In detail, we compare to • plain h max <ref type="bibr" target="#b2">(Bonet and Geffner 2001)</ref>, • the original additive h max heuristic <ref type="bibr" target="#b9">(Haslum, Bonet, and Geffner 2005)</ref>, abbreviated as HBG, • the recent ADHG decomposition for additive h max ( <ref type="bibr" target="#b4">Coles et al. 2008</ref>), abbreviated as CFLS, and • the admissible landmark heuristic h LA ( <ref type="bibr" target="#b15">Karpas and Domshlak 2009)</ref>. None of these heuristics take delete effects into account, so they are all bounded by h + . The objective of our experiment is to determine how closely each of them approximates h + . For this purpose, we compute the initial state heuristic values for all of our benchmark tasks where we were able to compute the corresponding value for h + . 3 <ref type="table" target="#tab_2">Table 1</ref> shows the results of the experiment. We see that h LM-cut is a significantly more accurate approximation to h + than the other approaches. The average additive error compared to h + across all instances is 0.28, implying that for  In summary, the experiment shows that the h LM-cut heuristic provides excellent heuristic estimates. While we only compare heuristic estimates to h + -based heuristics, we remark that such heuristics define the state of the art of admissible planning heuristic accuracy. In particular, <ref type="bibr" target="#b15">Karpas and Domshlak (2009)</ref> report that h LA is much more informative than current merge-and-shrink abstractions on large IPC benchmarks. Our results suggest that the landmark cut heuristic is even more informative.</p><p>Optimal Planning. To evaluate the usefulness of the landmark cut heuristic for optimal planning algorithms, we compare our A * implementation to four other heuristics: h LA , h m&amp;s (merge-and-shrink abstractions of size 10,000), h max , and h 0 (i. e., blind search). All these heuristics were implemented within an otherwise identical planning system except that for h LA we replaced A * with LM-A * , which performs better for this heuristic. (We also ran experiments with merge-and-shrink abstractions of size 100,000, which performed worse overall than the h m&amp;s results reported here.)</p><p>Additionally, we report results for the winner and runnerup of IPC-2008, Gamer and HSP * F . Note that the h 0 heuristic corresponds to the baseline planner used at IPC-2008, which narrowly outperformed Gamer at the competition.   <ref type="table" target="#tab_4">Table 2</ref> shows the number of planning tasks solved by each planner. The two dominating approaches are A * with h LM-cut and LM-A * with h LA , both of which solve more than 400 tasks, while the next best planner, Gamer, solves 312. To put these numbers in perspective, the margin between the two best planners and Gamer is about twice as large as the margin between Gamer and blind search. For 16 of the 22 domains, h LM-cut is one of the top performers, and in the other cases it usually gets close. The only clear exceptions are Gripper, where A * with imperfect heuristics cannot be competitive with BDD-based planners like Gamer for reasons discussed by <ref type="bibr" target="#b11">Helmert and Röger (2008)</ref>, and FreeCell.</p><formula xml:id="formula_7">h LM-cut h LA h max Inst. h * h Exp.</formula><p>Comparing h LM-cut to h LA , we see that h LM-cut solves significantly more tasks than h LA (450 vs. 422). Moreover, it solves more tasks than h LA in 12 domains, while being worse in only one (FreeCell).</p><p>To provide some insights about why h LM-cut outperforms h LA , Tab. 3 presents detailed experimental data for three domains, chosen as representatives of the three domain classes distinguished in the first experiment: Blocks (perfect h + estimates), Satellite (average errors between 0 and 1) and Openstacks (average errors greater than 1). We report results for h LM-cut , h LA and, as a baseline, h max .</p><p>We first discuss the Openstacks results; note that this is the domain where h LM-cut approximates h + worst among all domains in the first experiment. <ref type="table" target="#tab_6">Table 3</ref> shows that this leads to more expansions than h LA (by a factor of 2.0-2.4) and consequently longer planning time (by a factor of 3.2-4.6). Still, both heuristics solve the same set of tasks. The best performer in this domain is h max , due to its comparatively fast heuristic computations and despite requiring many more node evaluations than h LM-cut and h LA .</p><p>In Blocks and Satellite, h LM-cut requires much more time per node, but ends up faster overall due to better heuristic guidance, in particular for large instances. The same behaviour can be observed in many of the other domains.</p><p>The gap in heuristic quality between h LM-cut and h LA in Blocks is huge: h LM-cut solves eight additional tasks and requires a factor of 43-48 fewer expansions on the two largest commonly solved tasks. At first glance, this appears surprising: according to Tab. 1, both heuristics always obtain perfect h + estimates in this domain. The reason for the discrepancy is that h LM-cut recomputes all relevant information for every search state, while h LA relies on expensive precomputations performed only for the initial state. Therefore, the quality of h LA deteriorates as search moves away from the initial state. We remark that this strong reliance on the initial state is not unique to h LA : it is shared by all current abstraction heuristics and additive h max partitioning algorithms.</p><p>Concluding our discussion of the second experiment, we think it is fair to say that the landmark cut heuristic advances the state of the art in optimal sequential planning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>The main motivation for this work was the lack of formal results that connect different kinds of admissible planning heuristics. We have contributed towards changing this by providing several compilation results for delete relaxations, critical paths, abstractions and landmarks. It turns out that these concepts are much more closely related than was previously known. However, open questions remain. In particular, we still do not know how hard it is to find an optimal cost decomposition for h max , although we have made some progress towards answering this question. We also do not know if abstraction heuristics are powerful enough to capture the h m heuristics for larger values of m.</p><p>Theoretical results of the kind presented in this paper are occasionally criticized for not being of practical relevance. We believe these results to be highly relevant because they open new avenues towards finding better planning heuristics, combining the strengths of previously disconnected concepts. We have explored one such avenue: the landmark cut heuristic, based on our compilation from additive h max to landmark heuristics, is highly informative and leads to a very strong optimal planning algorithm. Other avenues remain to be explored. Our results show that abstraction heuristics are theoretically more powerful than relaxation heuristics, yet the best-performing heuristics in use today are relaxation heuristics. Trying to leverage the power of abstraction heuristics in a way that makes them consistently competitive with good relaxation heuristics remains an important open problem.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>c s (v), with h max (s) = max v∈G c s (v). The proposition costs are defined as the maximal solution to the recur- sive equations cost s (v) = 0 for v ∈ s and c s (v) = min o∈O with v∈add(o) (cost(o) + max p∈pre(o) c s (p)) for v / ∈ s. (Empty minima are defined as ∞ here, empty maxima as 0.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Summary of compilation results. Arrows indicate that heuristics in one class can be compiled into dominating heuristics in the other class in polynomial time. Dotted lines indicate that such compilations are not possible in either direction. Additive merge-and-shrink heuristics cannot be compiled into additive h m heuristics in polynomial time; the converse question is open.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Comparison of heuristic accuracy of relaxation 
heuristics. Domains are annotated with the number of in-
stances considered, and the following columns show the av-
erage h values for the initial states of these instances. En-
tries n/a indicate running out of memory or time on some in-
stances. Best approximations to h + are highlighted in bold. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Domain h LM-cut h LA h m&amp;s h max h 0 Gamer HSP *</head><label>h</label><figDesc></figDesc><table>F 

Airport (50) 
38 
24 
16 
20 17 
11 
15 
Blocks (35) 
28 
20 
18 
18 18 
30 
30 
Depot (22) 
7 
7 
7 
4 
4 
4 
4 
Driverlog (20) 
14 
14 
12 
8 
7 
11 
9 
FreeCell (80) 
15 
28 
15 
15 14 
11 
20 
Grid (5) 
2 
2 
2 
2 
1 
2 
0 
Gripper (20) 
6 
6 
7 
7 
7 
20 
6 
Logistics-2000 (28) 
20 
20 
16 
10 10 
20 
16 
Logistics-1998 (35) 
6 
5 
4 
2 
2 
6Total 
450 422 
314 294 273 
321 
279 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Comparison of solved tasks. Number of tasks in 
each domain is shown in parentheses (11 unsolvable Mys-
tery tasks omitted). Best results are highlighted in bold. 

at least 72% of the tasks we obtain the perfect h + estimate. 
The next best heuristic, h LA , has an error of 1.94, almost 
7 times the value for h LM-cut . Considering relative error, 
h LM-cut outperforms h LA by a factor of 3.8. Looking at indi-
vidual domains, there are eight cases where all h LM-cut esti-
mates are perfect (upper part of the table), eight cases where 
the average additive error is at most 1 (middle part) and six 
cases where it is larger (bottom part). Compared to the other 
heuristics, the estimates of h LM-cut are best in all domains ex-
cept FreeCell and Openstacks, where h LA is more accurate. 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Detailed results (15 smallest Blocks tasks omitted). 
For each solved task, we report the optimal plan length h  *  
and, for each heuristic, the initial state estimate, number of 
node expansions, and search time (in seconds). Best results 
are highlighted in bold. 

</table></figure>

			<note place="foot" n="2"> For space reasons, we do not provide a proof for one of the results shown in the figure, namely that pattern database heuristics cannot be compiled to general additive h m heuristics. The proof is quite simple and exploits the fact that h m is bounded by O(N m ) in uniform-cost domains, where N is the set of atoms of the task.</note>

			<note place="foot" n="3"> It is likely that in cases where we cannot determine h + , the heuristic errors are larger for all five heuristics, so the absolute errors reported are not necessarily indicative of large instances. The h + values were computed through domain-specific techniques (Betz 2009) and heuristic search in the delete relaxation.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was partly supported by the German Research Foundation (DFG) as part of SFB/TR 14 "Automatic Verification and Analysis of Complex Systems" (AVACS). Carmel Domshlak was partly supported by ISF grant 670/70.</p></div>
			</div>

			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Complexity results for SAS + planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bäckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nebel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="625" to="655" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Betz</surname></persName>
		</author>
		<title level="m">Komplexität und Berechnung der h + -Heuristik. Diplomarbeit</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>Albert-Ludwigs-Universität Freiburg</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Planning as heuristic search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bonet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Geffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIJ</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="33" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The computational complexity of propositional STRIPS planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bylander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIJ</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="165" to="204" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Additivedisjunctive heuristics for optimal planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICAPS</title>
		<meeting>ICAPS</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="44" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Planning with pattern databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Edelkamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECP</title>
		<meeting>ECP</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Symbolic pattern databases in heuristic search planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Edelkamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AIPS</title>
		<meeting>AIPS</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="274" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Admissible heuristics for optimal planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haslum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Geffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AIPS</title>
		<meeting>AIPS</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="140" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Domain-independent construction of pattern database heuristics for cost-optimal planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haslum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Botea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Helmert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bonet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Koenig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1007" to="1012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">New admissible heuristics for domain-independent planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haslum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bonet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Geffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI 2005</title>
		<meeting>AAAI 2005</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1163" to="1168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Accuracy of admissible heuristic functions in selected planning domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Helmert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mattmüller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="938" to="943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">How good is almost perfect?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Helmert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Röger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="944" to="949" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Flexible abstraction heuristics for optimal sequential planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Helmert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haslum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICAPS</title>
		<meeting>ICAPS</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="176" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The FF planning system: Fast plan generation through heuristic search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nebel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAIR</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="253" to="302" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Where &apos;ignoring delete lists&apos; works: Local search topology in planning benchmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAIR</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="685" to="758" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Cost-optimal planning with landmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Karpas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Domshlak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Optimal additive composition of abstraction-based admissible heuristics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Domshlak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICAPS</title>
		<meeting>ICAPS</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="174" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Structural patterns heuristics via fork decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Domshlak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICAPS</title>
		<meeting>ICAPS</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="182" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Heuristics for planning with action costs revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Keyder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Geffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECAI</title>
		<meeting>ECAI</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="588" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Cost-sharing approximations for h +</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mirkis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Domshlak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICAPS</title>
		<meeting>ICAPS</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="240" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On the extraction, ordering, and usage of landmarks in planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Porteous</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sebastia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECP</title>
		<meeting>ECP</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="37" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Landmarks revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Helmert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Westphal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="975" to="982" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
