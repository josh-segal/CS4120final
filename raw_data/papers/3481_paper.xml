<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Self-Repairing Peer-to-Peer System Resilient to Dynamic Adversarial Churn</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Kuhn</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Computer Engineering and Networks Laboratory ETH</orgName>
								<address>
									<postCode>8092</postCode>
									<settlement>Zurich, Zurich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Schmid</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Computer Engineering and Networks Laboratory ETH</orgName>
								<address>
									<postCode>8092</postCode>
									<settlement>Zurich, Zurich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Wattenhofer</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Computer Engineering and Networks Laboratory ETH</orgName>
								<address>
									<postCode>8092</postCode>
									<settlement>Zurich, Zurich</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Self-Repairing Peer-to-Peer System Resilient to Dynamic Adversarial Churn</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a dynamic distributed hash table where peers may join and leave at any time. Our system tolerates a powerful adversary which has complete visibility of the entire state of the system and can continuously add and remove peers. Our system provides worst-case fault-tolerance, maintaining desirable properties such as a low peer degree and a low network diameter.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Storing and handling data in an efficient way lie at the heart of any data-driven computing system. Compared to a traditional client/server approach, decentralized peer-to-peer (P2P) systems have the advantage to be more reliable, available, and efficient. P2P systems are based on common desktop machines ("peers"), distributed over a large-scale network such as the Internet. These peers share data (as well as the management of the data) that is conventionally stored on a central server. Usually, peers are under control of individual users who turn their machines on or off at any time. Such peers join and leave the P2P system at high rates ("churn"), a problem that is not existent in orthodox distributed systems. In other words, a P2P system consists of unreliable components only. Nevertheless, the P2P system should provide a reliable and efficient service.</p><p>Most P2P systems in the literature are analyzed against an adversary who can crash a functionally bounded number of random peers. After crashing a few peers the system is given sufficient time to recover again. The scheme described in this paper significantly differs from this in two major aspects. First, we assume that joins and leaves occur in a worst-case manner. We think of an adversary which can remove and add a bounded number of peers. The adversary cannot be fooled by any kind of randomness. It can choose which peers to crash and how peers join. 1 Note that we use the term "adversary" to model worst-case behavior. We do not consider Byzantine faults. Second, the adversary does not have to wait until the system is recovered before it crashes the next batch of peers. Instead, the adversary can constantly crash peers while the system is trying to stay alive. Indeed, our system is never fully repaired but always fully functional. In particular, our system is resilient against an adversary which continuously attacks the "weakest part" of the system. Such an adversary could for example insert a crawler into the P2P system, learn the topology of the system, and then repeatedly crash selected peers, in an attempt to partition the P2P network. Our system counters such an adversary by continuously moving the remaining or newly joining peers towards the sparse areas.</p><p>Clearly, we cannot allow our adversary to have unbounded capabilities. In particular, in any constant time interval, the adversary can at most add and/or remove O(log n) peers, n being the total number of peers currently in the system. This model covers an adversary which repeatedly takes down machines by a distributed denial of service attack, however only a logarithmic number of machines at each point in time. Our algorithm relies on messages being delivered timely, in at most constant time between any pair of operational peers. In distributed computing such a system is called synchronous. Note that if nodes are synchronized locally, our algorithm also runs in an asynchronous environment. In this case, the propagation delay of the slowest message defines the notion of time which is needed for the adversarial model. The basic structure of our P2P system is a hypercube. Each peer is part of a distinct hypercube node; each hypercube node consists of Θ(log n) peers. Peers have connections to other peers of their hypercube node and to peers of the neighboring hypercube nodes. In the case of joins or leaves, some of the peers have to change to another hypercube node such that up to constant factors, all hypercube nodes own the same number of peers at all times. If the total number of peers grows or shrinks above or below a certain threshold, the dimension of the hypercube is increased or decreased by one, respectively.</p><p>The balancing of peers among the hypercube nodes can be seen as a dynamic token distribution problem <ref type="bibr" target="#b0">[1]</ref> on the hypercube. Each node of a graph (hypercube) has a certain number of tokens, the goal is to distribute the tokens along the edges of the graph such that all nodes end up with the same or almost the same number of tokens. While tokens are moved around, an adversary constantly inserts and deletes tokens. Our P2P system builds on two basic components: i) an algorithm which performs the described dynamic token distribution and ii) an information aggregation algorithm which is used to estimate the number of peers in the system and to adapt the dimension accordingly.</p><p>Based on the described structure, we get a fully scalable, efficient P2P system which tolerates O(log n) worst-case joins and/or crashes per constant time interval. As in other P2P systems, peers have O(log n) neighbors, and the usual operations (e.g. search) take time O(log n). In our view a main contribution of the paper, however, is to propose and study a model which allows for dynamic adversarial churn. We believe that our basic algorithms (dynamic token distribution and information aggregation) can be applied to other P2P topologies, such as butterflies, skip graphs, chordal rings, etc. It can even be used for P2P systems that go beyond distributed hash tables (DHT).</p><p>The paper is organized as follows. In Section 2 we discuss relevant related work. Section 3 gives a short description of the model. A detailed discussion of our P2P system is given in Sections 4 and 5. Section 6 concludes our work.  <ref type="bibr" target="#b11">[12]</ref>). Due to the nature of P2P systems, fault-tolerance has been a prime issue from the beginning. The systems usually tolerate a large number of random faults. However after crashing a few peers the systems are given sufficient time to recover again. From an experimental point of view, churn has been studied in <ref type="bibr" target="#b12">[13]</ref>, where practical design tradeoffs in the implementation of existing P2P networks are considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Resilience to worst-case failures has been studied by Fiat, Saia et al. in <ref type="bibr" target="#b13">[14]</ref> <ref type="bibr" target="#b14">[15]</ref>. They propose a system where, w.h.p., (1 − ε)-fractions of peers and data survive the adversarial deletion of up to half of all nodes. In contrast to our work the failure model is static. Moreover, if the total number of peers changes by a constant factor, the whole structure has to be rebuilt from scratch.</p><p>Scalability and resilience to worst-case joins and leaves has been addressed by <ref type="bibr">Abraham et al.</ref> in <ref type="bibr" target="#b15">[16]</ref>. The focus lies on maintaining a balanced network rather than on fault-tolerance in the presence of concurrent faults. In contrast to our paper, whenever a join or leave happens, the network has some time to adapt.</p><p>The only paper which explicitly treats arbitrarily concurrent worst-case joins and leaves is by Li et al. <ref type="bibr" target="#b16">[17]</ref>. In contrast to our work, Li et al. consider a completely asynchronous model where messages can be arbitrarily delayed. The stronger communication model is compensated by a weaker failure model. It is assumed that peers do not crash. Leaving peers execute an appropriate "exit" protocol and do not leave before the system allows this; crashes are not allowed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>We consider the synchronous message passing model. In each round, each peer can send a message to all its neighbors. Additionally, we have an adversary A(J, L, λ) which may perform J arbitrary joins and and L arbitrary leaves (crashes) in each interval of λ rounds.</p><p>We assume that a joining peer π 1 contacts an arbitrary peer π 2 which already belongs to the system; π 2 then triggers the necessary actions for π 1 's integration.</p><p>A peer may be contacted by several joining peers simultaneously. In contrast to other systems where peers have to do some finalizing operations before leaving, we consider the more general case where peers depart or crash without notice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Algorithm</head><p>In this section, we describe the maintenance algorithm which maintains the simulated hypercube in the presence of an adversary which constantly adds and removes peers. The goal of the maintenance algorithm is twofold. It guarantees that each node always contains at least one peer which stores the node's data. Further, it adapts the hypercube dimension to the total number of peers in the system. This is achieved by two basic components. First, we present a dynamic token distribution algorithm for the hypercube. Second, we describe an information aggregation scheme which allows the nodes to simultaneously change the dimension of the hypercube.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dynamic Token Distribution</head><p>The problem of distributing peers uniformly throughout a hypercube is a special instance of a token distribution problem, first introduced by Peleg and Upfal <ref type="bibr" target="#b0">[1]</ref>. The problem has its origins in the area of load balancing, where the workload is modelled by a number of tokens or jobs of unit size; the main objective is to distribute the total load equally among the processors. Such load balancing problems arise in a number of parallel and distributed applications including job scheduling in operating systems, packet routing, large-scale differential equations and parallel finite element methods. More applications can be found in <ref type="bibr" target="#b17">[18]</ref>.</p><p>Formally, the goal of a token distribution algorithm is to minimize the maximum difference of tokens at any two nodes, denoted by the discrepancy φ. This problem has been studied intensively; however, most of the research is about the static variant of the problem, where given an arbitrary initial token distribution, the goal is to redistribute these tokens uniformly. In the dynamic variant on the other hand, the load is dynamic, that is, tokens may arrive and depart during the execution of the token distribution algorithm. In our case, peers may join and leave the simulated hypercube at arbitrary times, so the emphasis lies on the dynamic token distribution problem on a d-dimensional hypercube topology.</p><p>We use two variants of the token distribution problem: In the fractional token distribution, tokens are arbitrarily divisible, whereas in the integer token distribution tokens can only move as a whole. In our case, tokens represent peers and are inherently integer. However, it turns out that the study of the fractional model is useful for the analysis of the integer model.</p><p>We use a token distribution algorithm which is based on the dimension exchange method <ref type="bibr" target="#b18">[19]</ref> <ref type="bibr" target="#b19">[20]</ref>. Basically, the algorithm cycles continuously over the d dimensions of the hypercube. In step s, where i = s mod d, every node u := β 0 ...β i ...β d−1 having a tokens balances its tokens with its adjacent node in dimension i, v := β 0 ...β i ...β d−1 , having b tokens, such that both nodes end up with a+b 2 tokens in the fractional token distribution. On the other hand, if the tokens are integer, one node is assigned a+b 2 tokens and the other one gets a+b 2 tokens. It has been pointed out in <ref type="bibr" target="#b18">[19]</ref> that the described algorithm yields a perfect discrepancy φ = 0 after d steps for the static fractional token distribution. In <ref type="bibr" target="#b19">[20]</ref>, it has been shown that in the worst case, φ = d after d steps in the static integer token distribution. We can show that if the decision to which node to assign a+b 2 and to which node to assign a+b 2 tokens is made randomly, the final discrepancy is constant in expectation. However, we do not make use of this because it has no influence on our asymptotic results.</p><p>In the following, the dynamic integer token distribution problem is studied, where a "token adversary" A(J, L, 1) adds at most J and removes at most L tokens at the beginning of each step. In particular, we will show that if the initial distribution is perfect, i.e., φ = 0, our algorithm maintains the invariant φ ≤ 2J + 2L + d at every moment of time.</p><p>For the dynamic fractional token distribution, the tokens inserted and deleted at different times can be treated independently and be superposed. Therefore, the following lemma holds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 1. For the dynamic fractional token distribution, the number of tokens at a node depends only on the token insertions and deletions of the last d steps and on the total number of tokens in the system.</head><p>Proof. Assume that a total amount of T tokens are distributed in two different ways on the d-dimensional hypercube. According to <ref type="bibr" target="#b18">[19]</ref>, each node has exactly T 2 d tokens after d steps in the absence of an adversary. On the other hand, the token insertions and removals of the adversary that happen in-between can be treated as an independent superposition, as the corresponding operations are all linear.</p><p>We can now bound the discrepancy of the integer token distribution algorithm by comparing it with the fractional problem.</p><p>Lemma 2. Let v be a node of the hypercube. Let τ v (t) and τ v,f (t) denote the number of tokens at v for the integer and fractional token distribution algorithms at time t, respectively. We have ∀t :</p><formula xml:id="formula_0">|τ v (t) − τ v,f (t)| ≤ d 2 .</formula><p>Proof. For t = 0, we have τ v (t) = τ v,f (t). For symmetry reasons, it is sufficient to show the upper bound τ v (t) ≤ τ v,f (t) + d 2 . We first prove by induction that τ v (t) ≤ τ v,f (t) + t 2 at time t. For the induction step, we consider two neighbors u and v which exchange tokens. We have</p><formula xml:id="formula_1">τ v (t + 1) ≤ τ v (t) + τ u (t) 2 ≤ τ v,f (t) + t 2 + τ u,f (t) + t 2 2 6 ≤ τ v,f (t) + t 2 + τ u,f (t) + t 2 2 + 1 2 ≤ τ v,f (t + 1) + t + 1 2 .</formula><p>The second inequality follows from the induction hypothesis and the fact that τ v (t) and τ u (t) are integers. Note that adding or removing tokens has no influence on the difference between τ v and τ v,f because it modifies τ v and τ v,f in the same way. So far, we have seen that the number of integer tokens can deviate from the number of fractional tokens by at most d 2 after the first d steps. In order to show that this holds for all times t, we consider a fractional token distribution problemˆτproblemˆ problemˆτ v,f for whichˆτwhichˆ whichˆτ v,f (t − d) = τ v (t − d). Using the above argument, we have τ v (t−d) ≤ ˆ τ v,f (t) and by Lemma 1, we getˆτgetˆ getˆτ v,f (t) = τ v,f (t). This concludes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 3. In the presence of an adversary A(J, L, 1), it always holds that the integer discrepancy φ ≤ 2J + 2L + d.</head><p>Proof. We show that the fractional discrepancy φ f is bounded by 2J + 2L. Since Lemma 2 implies that for the integer discrepancy φ i it holds that φ i − φ f ≤ d, the claim follows. Let J t ≤ J and L t ≤ L be the insertions and deletions that happen at the beginning of step t. First, we consider the case of joins only, i.e., L t = 0. Assume that all J t tokens are inserted at node v = β 0 ...β i ...β d−1 where i := t mod d. In the upcoming paragraph, all indices are implicitly modulo d. In step t, according to the token distribution algorithm, v keeps J t /2 tokens and sends J t /2 to node u = β 0 ...β i ...β d−1 . In step t + 1, J t /4 are sent to nodes β 0 ...β i β i+1 ...β d−1 and β 0 ...β i β i+1 ...β d−1 , and so on. Thus, after step t + d − 1, every node in the d-dimensional hypercube has the same share of J t 2 d tokens from that insertion. We conclude that a node can have at most all insertions of this step, half of the insertions of the last step, a quarter of all insertions two steps ago and so on:</p><formula xml:id="formula_2">J t + J t−1 2 + J t−2 4 + ... + J t−(d−1) 2 d−1 &lt; 2J + J t−d 2 d + J t−(d+1) 2 d + J t−(d+2) 2 d + ...</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>shared by all nodes</head><p>Since J t−i ≤ J for i = 0, 1, 2, . . ., we have φ f ≤ 2J. For the case of only token deletions, the same argument can be applied, yielding a discrepancy of at most 2L. Finally, if there are both insertions and deletions which do not cancel out each other, we have φ f ≤ 2J + 2L.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Information Aggregation</head><p>When the total number of peers in the d-dimensional hypercube system exceeds a certain threshold, all nodes β 0 . . .  <ref type="bibr" target="#b22">[22]</ref>[23], we present an algorithm which provides the same estimated number of peers in the system to all nodes in every step allowing all nodes to split or merge synchronously, that is, in the same step. The description is again made in terms of tokens rather than peers.</p><p>Assume that in order to compute the total number of tokens in a d-dimensional hypercube, each node v = β 0 ...  </p><formula xml:id="formula_3">Γ v [k + 1] = Γ u [k + 1] = Γ v [k] + Γ u [k].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Simulated Hypercube</head><p>Based on the components presented in the previous sections, both the topology and the maintenance algorithm are now described in detail. In particular, we show that, given an adversary A(d + 1, d + 1, 6) which inserts and removes at most d + 1 peers in any time interval of 6 rounds, 1) the out-degree of every peer is bounded by Θ(log 2 n) where n is the total number of peers in the system, 2) the network diameter is bounded by Θ(log n), and 3) every node of the simulated hypercube has always at least one peer which stores its data items, so no data item will ever be lost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Topology</head><p>We start with a description of the overlay topology. As already mentioned, the peers are organized to simulate a d-dimensional hypercube, where the hypercube's nodes are represented by a group of peers. A data item with identifier id is stored at the node whose identifier matches the first d bits of the hash-value of id . The peers of each node v are divided into a core C v of at most 2d+3 peers and a periphery P v consisting of the remaining peers; all peers within the same node are completely connected (intra-connections). Moreover, every peer is connected to all core peers of the neighboring nodes (inter-connections). <ref type="figure">Figure 1</ref> shows an example for d = 2. <ref type="figure">Fig. 1</ref>. A simulated 2-dimensional hypercube with four nodes, each consisting of a core and a periphery. All peers within the same node are completely connected to each other, and additionally, all peers of a node are connected to all core peers of the neighboring nodes. Only the core peers store data items, while the peripheral peers may move between the nodes to balance biased adversarial changes.</p><p>The data items belonging to node v are replicated on all core peers, while the peripheral peers are used for the balancing between the nodes according to the peer distribution algorithm and do not store any data items. The partition into core and periphery has the advantage that the peers which move between nodes do not have to replace the data of the old node by the data of the new nodes in most cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">6-Round (Maintenance) Algorithm</head><p>The 6-round (maintenance) algorithm maintains the simulated hypercube topology described in the previous section given an adversary A <ref type="figure">(d + 1, d + 1, 6</ref>). In particular, it ensures that 1) every node has at least one core peer all the times and hence no data is lost; 2) each node always has between 3d + 10 and 45d + 86 peers; 3) only peripheral peers are moved between nodes, thus the unnecessary copying of data is avoided.</p><p>In the following, we refer to a complete execution of all six rounds of the maintenance algorithm as a phase. Basically, the 6-round algorithm balances the peers across one dimension in every phase according to the token distribution algorithm as described in Section 4.1; additionally, the total number of peers in the system is computed with respect to an earlier state of the system by the information aggregation algorithm of Section 4.2 to expand or shrink the hypercube if the total number of peers exceeds or falls below a certain threshold. In our system, we use the lower threshold LT := 8d+16 and the upper threshold UT := 40d + 80 for the total number of peers per node on average. <ref type="bibr" target="#b1">2</ref> While peers may join and leave the system at arbitrary times, the 6-round algorithm considers the (accumulated) changes only once per phase. That is, a snapshot of the system is made in round 1; rounds 2 -6 then ignore the changes that might have happened in the meantime and depend solely on the snapshot at the beginning of the phase. Round 1: Each node v makes the snapshot of the currently active peers. For this, each peer in v sends a packet with its own ID and the (potentially empty) ID set of its joiners to all adjacent peers within v. Round 2: Based on the snapshot, the core peers of a node v know the total number of peers in the node and send this information to the neighboring core with which they have to balance in this phase (cf. Section 4.1). The cores also exchange the new estimated total number of peers in their domains with the corresponding adjacent cores (cf. Section 4.2). Finally, each peer informs its joiners about the snapshot. Round 3: Given the snapshot, every peer within a node v can compute the new periphery (snapshot minus old core). This round also prepares the transfer for the peer distribution algorithm across dimension i: The smaller of the two nodes determines the peripheral peers that have to move and sends these IDs to the neighboring core. Round 4: In this round, the peer distribution algorithm is continued: The core which received the IDs of the new peers sends this information to the periphery. Additionally, it informs the new peers about the neighboring cores, etc.</p><p>The dimension reduction is prepared if necessary: If the estimated total number of peers in the system is beyond the threshold, the core peers of a node which will be reduced send their data items plus the identifiers of all their peripheral peers (with respect to the situation after the transfer) to the core of their adjacent node in the largest dimension. Round 5: This round finishes the peer distribution, establishes the new peripheries, and prepares the building of a new core. If the hypercube has to grow in this phase, the nodes start to split, and vice versa if the hypercube is going to shrink.</p><p>Given the number of transferred peers, all peers can now compute the new peripheries. Moreover, they can compute the new core: It consists of the peers of the old core which have still been alive in Round 1, plus the 2d + 3 − |C| smallest IDs in the new periphery, where C is the set of the old core peers which have still been alive in Round 1. The old core then informs all its neighboring nodes (i.e., their old cores) about the new core.</p><p>If the hypercube has to grow in this phase, the smallest 2d+3 peers in the new periphery of the node that has to be split become the new core of the expanded node, and half of the remaining peripheral peers build its periphery. Moreover, the necessary data items are sent to the core of the expanded node, and the neighboring (old) cores are informed about the IDs of the expanded core.</p><p>If the hypercube is about to shrink, all old cores in the lower half of the hypercube (the surviving sub-cube) inform their periphery about the peers arriving from the expanded node and the peers in the expanded node about the new core and its periphery. The data items are copied to the peers as necessary. Round 6: In this round, the new cores are finally built: The old core forwards the information about the new neighboring cores to the peers joining the core.</p><p>Moreover, if the hypercube has been reduced, every peer can now compute the new periphery. If the hypercube has grown, the old core forwards the expanded cores of its neighbors to all peers in its expanded node.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We presented a first distributed hash table which provably tolerates continuous worst-case membership changes while maintaining crucial features such as efficient routing. We believe that our approach opens several exciting P2P research challenges. For example: How well do classic P2P proposals perform when studied with a dynamic failure model or what is the adversary/efficiency tradeoff when studying dynamic models?</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>A</head><label></label><figDesc>plethora of different overlay networks with various interesting technical proper- ties have been proposed over the last years (e.g. [2][3][4][5][6][7][8][9][10][11]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>β d−1 have to split into two new nodes β 0 . . . β d−1 0 and β 0 . . . β d−1 1, yielding a (d + 1)-dimensional hypercube. Analo- gously, if the number of peers falls beyond a certain threshold, nodes β 0 . . . β d−2 0 and β 0 . . . β d−2 1 have to merge their peers into a single node β 0 . . . β d−2 , yield- ing a (d − 1)-dimensional hypercube. Based on ideas also used in [21]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>β d−1 maintains an array Γ v [0...d], where Γ v [i] for i ∈ [0, d] stores the estimated number of tokens in the sub-cube consisting of the nodes sharing v's prefix β 0 ...β d−1−i . Further, assume that at the beginning of each step, an adversary inserts and removes an arbitrary number of tokens at arbitrary nodes. Each node v = β 0 ...β d−1−i ...β d−1 then calculates the new array Γ v [0...d]. For this, v sends Γ v [i] to its adjacent node u = β 0 ...β d−1−i ...β d−1 , for i ∈ [0, d−1]. Then, Γ v [0] is set to the new number of tokens at v which is the only node with prefix β 0 ...β d−1 . For i ∈ [1, d], the new estimated number of tokens in the prefix domain β 0 ...β d−1−(i+1) is given by the total number of tokens in the domain β 0 ...β d−1−i plus the total number of tokens in domain β 0 ...β d−1−i provided by node u, that is, Γ v [i + 1] := Γ v [i] + Γ u [i]. Lemma 4. Consider two arbitrary nodes v 1 and v 2 of the d-dimensional hyper- cube. Our algorithm guarantees that Γ v1 [d] = Γ v2 [d] at all times t. Moreover, it holds that this value is the correct total number of tokens in the system at time t − d.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Proof.</head><label></label><figDesc>We prove by induction that at time t + k, all nodes sharing the prefix β 0 ...β d−1−k for k ∈ [0, d] store the same value Γ v [k] which represents the correct state of that sub-domain in step t. k = 0: There is only one node having the prefix β 0 ...β d−1 , so the claim trivially holds. k → k+1: By the induction hypothesis, all nodes v with prefix β 0 ...β d−1−(k+1) β d−1−k share the same value Γ v [k] which corresponds to the state of the system k steps earlier, and the same holds for all nodes u with prefix β 0 ...β d−1−(k+1) β d−1−k . In step k + 1, all these nodes having the same prefix β 0 ...β d−1−(k+1) obviously store the same value</figDesc></figure>

			<note place="foot" n="1"> We assume that a joining peer knows a peer which already belongs to the system. This is known as the bootstrap problem.</note>

			<note place="foot" n="2"> Note that since we consider the threshold on average, and since these values are provided with a delay of d phases in a d-dimensional hypercube (see Lemma 4), the number of peers at an individual node may lie outside [LT , UT ].</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The Token Distribution Problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peleg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Upfal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. on Computing</title>
		<imprint>
			<biblScope unit="volume">287</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="229" to="243" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">P-Grid: A Self-Organizing Access Structure for P2P Information Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Aberer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 9th Int. Conference on Cooperative Information Systems (CoopIS)</title>
		<meeting>9th Int. Conference on Cooperative Information Systems (CoopIS)</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="179" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">LAND: Stretch (1 + ε) Locality-Aware Networks for DHTs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Dobzinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Malkhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 15th Ann. ACM-SIAM Symp. on Discrete Algorithms (SODA)</title>
		<meeting>15th Ann. ACM-SIAM Symp. on Discrete Algorithms (SODA)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="550" to="559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Skip Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Aspnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 14th Ann. ACM-SIAM Symp. on Discrete Algorithms (SODA)</title>
		<meeting>14th Ann. ACM-SIAM Symp. on Discrete Algorithms (SODA)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="384" to="393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The Hyperring: A Low-Congestion Deterministic Data Structure for Distributed Environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Awerbuch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ch</forename><surname>Scheideler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 15th Ann. ACM-SIAM Symp. on Discrete Algorithms (SODA)</title>
		<meeting>15th Ann. ACM-SIAM Symp. on Discrete Algorithms (SODA)</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">SkipNet: A Scalable Overlay Network with Practical Locality Properties</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Harvey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saroiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Theimer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wolman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th USENIX Symp. on Internet Technologies and Systems (USITS)</title>
		<meeting>4th USENIX Symp. on Internet Technologies and Systems (USITS)</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">OceanStore: An Architecture for Global-scale Persistent Storage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bindel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Eaton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Geels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gummadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kubiatowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rhea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Weatherspoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Weimer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wells</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ch</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM ASPLOS</title>
		<meeting>of ACM ASPLOS</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Viceroy: A Scalable and Dynamic Emulation of the Butterfly</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Malkhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ratajczak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 21st Ann. Symp. on Principles of Distributed Computing (PODC)</title>
		<meeting>21st Ann. Symp. on Principles of Distributed Computing (PODC)</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="183" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Accessing Nearby Copies of Replicated Objects in a Distributed Environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Plaxton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rajaraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Richa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 9th Ann. ACM Symp. on Parallel Algorithms and Architectures (SPAA</title>
		<meeting>9th Ann. ACM Symp. on Parallel Algorithms and Architectures (SPAA</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="311" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Scalable Content Addressable Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Handley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Karp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ratnasamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACM SIGCOMM</title>
		<meeting>of ACM SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Chord: A Scalable Peer-to-peer Lookup Service for Internet Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kaashoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Karger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIG-COMM Conference</title>
		<meeting>ACM SIG-COMM Conference</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Tapestry: A Resilient Global-scale Overlay for Service Deployment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kubiatowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stribling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal on Selected Areas in Communications</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Handling Churn in a DHT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Geels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kubiatovicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rhea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Roscoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. USENIX Ann. Technical Conference</title>
		<meeting>USENIX Ann. Technical Conference</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Censorship Resistant Peer-to-Peer Content Addressable Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fiat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Saia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th Symp. on Discrete Algorithms</title>
		<meeting>13th Symp. on Discrete Algorithms</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dynamically Fault-Tolerant Content Addressable Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gribble</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fiat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Saia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saroiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st Int. Workshop on Peer-to-Peer Systems (IPTPS)</title>
		<meeting>1st Int. Workshop on Peer-to-Peer Systems (IPTPS)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Generic Scheme for Building Overlay Networks in Adversarial Scenarios</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Awerbuch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bartal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Malkhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pavlov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 17th Int. Symp. on Parallel and Distributed Processing (IPDPS</title>
		<meeting>17th Int. Symp. on Parallel and Distributed essing (IPDPS</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Active and Concurrent Topology Maintenance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Plaxton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 18th Ann. Conference on Distributed Computing (DISC)</title>
		<meeting>18th Ann. Conference on Distributed Computing (DISC)</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Scheduling and Load Balancing in Parallel and Distributed Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kavi</forename><surname>Hurson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shirazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>IEEE Computer Science Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dynamic Load Balancing for Distributed Memory Multiprocessors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cybenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal on Parallel Distributed Computing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="279" to="301" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Load Balancing, Selection and Sorting on the Hypercube</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Plaxton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st</title>
		<meeting>1st</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Ann. ACM Symp. on Parallel Algorithms and Architectures</title>
		<imprint>
			<biblScope unit="issue">SPAA</biblScope>
			<biblScope unit="page" from="64" to="73" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Aggregating Information in Peer-to-Peer Systems for Improved Join and Leave</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Albrecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gähwiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wattenhofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th IEEE Int. Conference on Peer-to-Peer Computing (P2P)</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Astrolabe: A Robust and Scalable Technology for Distributed System Monitoring, Management, and Data Mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Birman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Renesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Vogels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computing Systems</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="164" to="206" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Willow: DHT, Aggregation, and Publish/Subscribe in One Protocol</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bozdog</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Renesse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd Int. Workshop on Peer-To-Peer Systems (IPTPS)</title>
		<meeting>3rd Int. Workshop on Peer-To-Peer Systems (IPTPS)</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
