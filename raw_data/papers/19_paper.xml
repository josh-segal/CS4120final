<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:27+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning spectral graph segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothée</forename><surname>Cour</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Gogin</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Shi</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer and Information Science</orgName>
								<orgName type="department" key="dep2">Computer Science Ecole Polytechnique</orgName>
								<orgName type="department" key="dep3">Computer and Information Science</orgName>
								<orgName type="institution">University of Pennsylvania Philadelphia</orgName>
								<address>
									<postCode>19104, 91128</postCode>
									<settlement>Palaiseau Cedex</settlement>
									<region>PA</region>
									<country key="FR">FRANCE</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Pennsylvania Philadelphia</orgName>
								<address>
									<postCode>19104</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning spectral graph segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present a general graph learning algorithm for spectral graph partitioning, that allows direct supervised learning of graph structures using hand labeled training examples. The learning algorithm is based on gradient descent in the space of all feasible graph weights. Computation of the gradient involves finding the derivatives of eigenvec-tors with respect to the graph weight matrix. We show the derivatives of eigenvectors exist and can be computed in an exact analytical form using the theory of implicit functions. Furthermore, we show for a simple case, the gradient converges exponentially fast. In the image segmentation domain, we demonstrate how to encode top-down high level object prior in a bottom-up shape detection process.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Image segmentation and data clustering are two fundamental operations in computer vision and machine learning. Let I = {x 1 , ..., x n } be a set of feature vectors representing n image pixels or data points. The image segmentation process partitions pixels into K disjoint groups. In a 2-way segmentation, we seek an output vector SEG(I) = {y 1 , ..., y n } ∈ {0, 1} n , such that a segmentation goodness measure is optimized. We defined segmentation as a mapping from x i to y i ∈ {0, 1} to purposely hint its potential connection to a supervised learning method we should propose. Our goal is to teach the image segmentation through a set of hand labeled training examples. Given a set of image/segmentation pairs {I i , SEG * (I i )}, the system will learn to adjust so that the computed segmentation SEG(I i ) is close to SEG * (I i ). With a supervised image segmentation, we are able to encode top-down object familiarity prior in a bottom-up distributed process. In this paper, we will demonstrate a system that can detect and segment rectangular shaped objects in a clutter image background by learning from examples.</p><p>To appreciate why learning image segmentation is difficult, we summarize below its basic principles. Segmentation algorithms are defined by the clustering criteria and computational process to optimize it. For example, in the Markov Random Field (MRF) formulation, the criteria is to maximize P (SEG(x)|x) = 1 Z exp( −f (y i , y j |x)), where f (y i , y j |x), called clique potential, specifies a local measure of grouping pixel i with j. While each f (y i , y j |x) can be easily corrupted, the global optimum of P (SEG(x)|x) must balance preferences on all pairs of f (y i , y j |x) and therefore is stable. Spectral graph partitioning, such as Normalized Cut (Ncut) <ref type="bibr" target="#b6">[6]</ref>[5], has been developed as a computationally efficient alternative to MRF. Image segmentation is mapped to a graph partitioning problem, where the graph consists of the pixels/data points as nodes, and the weighted graph edges W (i, j) serve as the equivalent of Clique Potential f (y i , y j |x). The global segmentation criterion Ncut seeks a balanced segmentation and grouping of the pixels. Computationally the solution is derived from the eigenvectors of W y = λDy, where D is the degree matrix. As in the MRF case, the eigenvectors are implicitly related to the input weight matrix W , and are quite insensitive to random perturbation of W .</p><p>While global decision process from local feature comparison brings a stable segmentation, it makes the learning segmentation a difficult task. Treating any segmentation learning algorithm as a black box, one must be able to back-trace error on the output of global segmentation to the input local clique potential or pair-wise weight matrix. Since the global decision is only implicitly related to the input, it is hard to explicitly assign a blame to a particular clique potential or weight matrix entry. To account for segmentation error on just one pixel, we would potentially need to adjust all possible pairs of clique potential or weight optimizes the graph weight W (I, Θ) by minimizing the KL-divergence between an equivalent random walk matrix P (I, Θ) and the target P * (I, Θ). (B) Our method directly optimize the error on the output Ncut segmentation vector X N cut [W (I, Θ)] by gradient descent in the space of all feasible graph weights using explicit computation of the derivatives of eigenvectors.</p><p>matrix entries! Meila-Shi <ref type="bibr" target="#b4">[4]</ref> first studied the problem of learning spectral graph cuts with supervised training data. Their proposed algorithm learned the graph weight W ij by minimizing the KL-divergence between an equivalent random walk matrix P ij and the target P * ij derived from the hand labeled segmentation. However the formulation provides no explicit constraints on the Ncut eigenvector itself. Bach-Jordan <ref type="bibr" target="#b0">[1]</ref> formulated a direct optimization of W with respect to its Ncut eigenvector. They transform the implicit relationship between W and Ncut eigenvector into an explicit one by making a differentiable approximation of eigenvector using power method. The resulting computation of derivatives of eigenvector is however complex and can be computationally unstable.</p><p>We present in this paper a direct method for learning spectral graph cut, based on efficient computation of derivatives of Ncut eigenvectors in exact analytical form. We show that there is an explicit computation that assigns the segmentation error to the input graph weight matrix. This capability allows us to design parameterized graphs that can encode and detect complex objects. The paper is organized as follows. We describe in Sec. 2 the structure of the graph we use for image and shape segmentation. Sec. 3 describes the learning algorithm and its convergence properties. We show our results in Sec. 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PROBLEM SETUP</head><p>We will demonstrate a learnable segmentation algorithm for detecting and segmenting desired object shape such as a rectangle in an image. The shape detection-segmentation process begins with edge detection. Each edge i is parametrized by (x i , y i , θ i ), its location and orientation. Denote F (I) = {e 1 , ..., e k |e i = (x i , y i , θ i )} the set of edges detected for image I, and F the complete set of possible edges detected in all images. The goal of the segmentation algorithm is to group the edges which form a rectangle, and separate them from background edge clutters, as shown in <ref type="figure" target="#fig_0">Fig. 11</ref>.</p><p>While a rectangle is a relatively simple shape, its aspect can be quite flexible with variable aspect ratio in x, y, and variable orientation. Assuming we have quantized the orientation into N angle angles, for an image size of N pixel × N pixel a brute force method would need to search over O(N 4 pixel N angle possible configurations (for a 100 × 100 image with 10 orientations quantization, we have 1 billion configurations!). One way to avoid this large scale search is to decompose the rectangles into simple local configurations (corners, lines, parallel lines), and combine them by checking their global consistency. This datadriven bottom-up process only needs to check roughly O(N edge ) = O(|F (I)|) local configurations (assuming a fixed neighborhood size). The global integration can be carried out in the grouping framework of graph partitioning such as Ncut, which has empirically a running time of O(N 1.5 edge ). Furthermore, the decomposition of a shape into local edge relationships also makes the detection more robust to image background clutter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">LOCAL SHAPE CONFIGURATIONS</head><p>We need to define functions on local configuration goodness, with the hope of discriminating rectangular object vs. background. Since we are using oriented edges, we can favor convex configurations and penalize concave or other impossible configurations, as illustrated in <ref type="figure">Fig. 2</ref>. The function that assesses the goodness of a particular configuration is denoted as clique potential: f (e 1 , . . . , e K ) is high only when (e 1 , . . . , e K ) form a familiar configuration. The problem of designing this clique potential can be quite complex in general. For example, consider the case of binary relationships: we need to find a potential function for all possible pairs of edges (e 1 , e 2 ): <ref type="figure">Figure 2</ref>: Different oriented edge configurations and associated clique potential. Left: three edges forming a convex object (likely to be found in rectangle shapes). Middle: concave configuration (unlikely in rectangular shapes). Right: impossible configuration (very unlikely to be found in any object). </p><formula xml:id="formula_0">invariance, f (x 1 , y 1 , θ 1 ; x 2 , y 2 , θ 2 ) = ¯ f (x 2 − x 1 , y 2 − y 1 , θ 1 , θ 2 ) and, f (z 1 , θ 1 ; z 2 , θ 2 ) = ¯ ¯ f ((z 2 − z 1 )e −iθ1 , θ 2 − θ 1 ). Right: summing up ternary affinities to obtain a binary affinity, f (e 1 , e 2 ) = i f 3 (e 1 , e 2 , e i ). f (e 1 , e 2 ) = f (x 1 , y 1 , θ 1 , x 2 , y 2 , θ 2 ).</formula><p>The function takes 4-dimensional inputs, and even in the simple case of 10x10 possible edge locations, with 4 orientations {π/2, 2π/2, 3π/2, 4π/2}, that makes 160,000 different values to design through learning. To make the learning problem more managable, we use the following parameterization that induces translational invariance:</p><formula xml:id="formula_1">f (x 1 , y 1 , θ 1 ; x 2 , y 2 , θ 2 ) = ¯ f (x 2 − x 1 , y 2 − y 1 , θ 1 , θ 2 ) (1)</formula><p>If in addition we also require invariance by rotation, the use of complex numbers comes in handy, with z = x+iy we obtain f (</p><formula xml:id="formula_2">z 1 , θ 1 ; z 2 , θ 2 ) = ¯ ¯ f ((z 2 −z 1 )e −iθ1 , θ 2 − θ 1 ). These invariance properties are illustrated in Fig. 3.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">GLOBAL SHAPE DETECTION FROM LOCAL CONFIGURATIONS</head><p>With local edge clique function we could eliminate wrong patterns of edges, retrieve the correct edge orientation when ambiguous, and enhance good configurations. However, there are many ambiguous cases in which local properties are insufficient to decide the foreground/background labeling. Think about a weak edge at object boundary, or a strong clutter edge in the background. A direct thresholding technique would fail here. Another example is provided by <ref type="figure">Fig. 4</ref>, where a local approach would favor the wrong edge orientation. As in the case of image segmentation, local grouping measures need to be aggregated to form a global segmentation decision. We will see in the next section how to formulate this precisely in graph framework, through Spectral Graph Partitioning.</p><p>Figure 4: Each edge has 2 hypothesized opposite polarities. We want to inhibit clutter edges and recover correct polarity. Left: local segmentation of edges produces the wrong polarity for one edge (barred), grouping it with clutter. Right: global aggregation of edge affinities yields a correct grouping and inhibits clutter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">SPECTRAL GRAPH PARTITIONING FORMULATION</head><p>Such local relationships between image features are well captured by the notion of graph G = V, W . The graph nodes V consist of the image edge features F = {e i }, and the graph edges are the relationships between the edge features with affinity matrix W ∈ R n×n defined by W ij = f (e i , e j ). Higherorder edge feature relationships can be translated into binary affinities by summing over cliques: W ij = i1=i,i2=j,i3,...,iK f (e i1 , ..., e iK ), as illustrated in <ref type="figure" target="#fig_1">Fig.  3</ref>. We denote V (I) the image edge features, F (I), detected in I; W (I) = W (V (I), V (I)), the subgraph affinity induced by image features in I.</p><p>Let us recall our goal: we want to partition the graph nodes V (I) into two groups, using an indicator vector X: X i = 1 if detected feature V (I) i belongs to foreground, and X i = −1 if it belongs to background. The segmentation process should ensure that edge features (nodes) grouped together have high mutual affinity, and nodes in different sets have low affinity. We will use the Normalized Cuts (Ncut) criterion for the segmentation process. Ncut criterion can be optimized by finding the second generalized eigenvector of (W (I), D(I)) (D(I) is the degree matrix of W (I)):</p><formula xml:id="formula_3">W (I)X(I) = λ 2 D(I)X(I)<label>(2)</label></formula><p>X(I) is then thresholded to determine the foreground/background labelling. Note that, the solution we obtain for X(I) is an implicit function of the weight matrix W (I), which is defined by the local </p><formula xml:id="formula_4">W (LN, F ) = W (RN, F ) = W (LN, N F ) = W (RN, N F ) = 1 2</formula><p>, making it impossible to distinguish between a Face and a Non-Face. The graph learning algorithm we propose does not suffer from this. clique potentials, f (e i , e j ). However, its computation is tractable and, as we shall see, we can apply perturbation theory to analyze their effect on the segmentation task. This last point is essential: it means that we can assign a blame to the local graph structure, by looking at the global segmentation result. Hence the system is not a black box anymore, we can train it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">LEARNING THE GRAPH STRUCTURE</head><p>As we have seen, the design of the clique potential is as crucial to the segmentation as it complex. In the Ncut formulation, whether we use a parameterization of the affinity matrix W (Θ) or a direct representation through its coefficients W ij , real image segmentation tasks will require a large number of parameters to be optimized. Hence the need for a principled algorithm to learn the clique potential.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">WHY ARE SIMPLE LEARNING SCHEMES INSUFFICIENT</head><p>One natural idea in learning the graph clique potential is simply to measure the coocurrence of image features accross a set of training images, in accordance to the Hebbian rule. This rule strengthens the weight W ij if feature i and feature j are strongly correlated, according to: W ij = I V (I) i V (I) j in our notation. Though intuitive, this rule is insufficient for our problem. <ref type="figure" target="#fig_2">Fig.  5</ref> illustrates a typical situation that the Hebbian rule is unable to handle, namely the XOR boolean function. More generally, the Hebbian rule cannot learn non-linearly separable functions. We have shown in <ref type="bibr" target="#b2">[2]</ref> 1 that our system does not have this limitation and it could learn XOR.</p><p>1 http://www.seas.upenn.edu/∼timothee/research.html</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">PRINCIPLE OF LEARNING</head><p>The Maximum Likelihood formulation (ML) tries to adjust the clique potential so that it maximally explains the data (the set of training images). However, this formulation doesn't take into account the graph inference procedure I → X(I), as a result, it can produce a probability distribution that cannot be inferenced efficiently. We use a different approach. We adjust the clique potential so that the output of the system gets closer to the desired segmentation. In the following, we assume we are given a set of images I with a target segmentation X * (I).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">COST FUNCTION FOR LEARNING</head><formula xml:id="formula_5">Definitions X p [W ], λ p are the p th largest eigenvec- tor, eigenvalue of W X = λD W X with X p [W ] = 1 and D W = diag(W 1). X p [W ]</formula><p>is uniquely defined up to polarity, which we disambiguate using a fixed vector Y and forcing sign(Y T X p [W ]) = +1. This is possible only when Y T X p [W ] 񮽙 = 0. We also require λ p be unique. To satisfy these constraints, we will restrict our attention to weight matrices W in a certain subset S 2,X * (I) n of symmetric matrices, where</p><formula xml:id="formula_6">S p,Y n = {W ∈ S n : W 1 &gt; 0, ker(W − λ p D W ) 񮽙 ⊂ Y ⊥ , λ p single}.</formula><p>Note that if W ∈ S n and W 1 &gt; 0, W has probability 1 of being in the feasible space. What's more, S 2,X * (I) n is open, which implies that any small perturbation of W is allowed. Define the one-target energy function:</p><formula xml:id="formula_7">E(W, I) = 1 2 X 2 [W (I)] − X * (I) 2 , for W ∈ S 2,X * (I) n<label>(3)</label></formula><p>The multi-target energy function is defined as</p><formula xml:id="formula_8">E(W ) = I E(W, I), for W ∈ ∩ I S 2,X * (I) n</formula><p>. This error energy function has the following property, which will be useful later on when we try to learn the graph network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prop. 3.1 (E(W, I) has no local minimum)</head><p>The single target energy function has all its local minima in S 2,X * n {W : λ 2 (W ) 񮽙 = −1} equal to the global minimum, 0.</p><p>The proof, in <ref type="bibr" target="#b2">[2]</ref>, shows that at a critical point, the error vector X 2 − X * (I) is in the kernel of a certain matrix of rank n-1. This shows in fact that X 2 − X * (I) is proportional to X 2 , which finally leads to X 2 = X * (I). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">GRADIENT DESCENT ALGORITHM</head><formula xml:id="formula_9">e i , e j ) = ¯ f (x 2 − x 1 , y 2 − y 1 , θ 1 , θ 2 )</formula><p>, which is a 4 dimensional lookup table.</p><p>The main difficulty is to study how the Ncut eigenvector, X 2 [W (Θ)], varies with the graph weight matrix W (Θ). We will write down a continuous-time PDE describing evolution of the error energy on X 2 [W (Θ)] with respect to Θ. We show that this PDE has an exact analytical form, and the resulting PDE converges. We have also proved the convergence rate is exponential for a simple case <ref type="bibr" target="#b2">[2]</ref>. This result shows that we can minimize the error energy over W or Θ by gradient descent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 3.2 (Derivative of Ncut eigenvector)</head><p>The map W → (X p , λ p ) is C ∞ over S p,Y n , and we can express the derivatives over any C 1 path W (t) as:</p><formula xml:id="formula_10">dX p [W (t)] dt = −(W − λ p D W ) † (W ′ − λ p D ′ W − dλ p dt D W )X p dλ p dt = X T p (W ′ − λ p D ′ W )X p X T p D W X p</formula><p>We obtain an analog theorem for the derivative of standard eigenvectors, by simply replacing D W with I n . The proof in <ref type="bibr" target="#b2">[2]</ref> uses the implicit function theorem to show</p><formula xml:id="formula_11">X p [W ] is C ∞ , then differentiates W X p = λ p D W X p to obtain (W − λ p D W )X ′ p + (W ′ − λ p D ′ W − λ ′ p D W )X p = 0. Computation of the partial derivatives ∂X2</formula><p>∂W alone requires O(n 3 ) time because of the pseudo-inverse term (W − λ p D W ) † in each gradient direction. We remove this bottleneck by first left-multiplying by ∂E ∂X2 . We in-</p><formula xml:id="formula_12">troduce Y = −(W − λ 2 D W ) † (X 2 − X * (I))</formula><p>, which we showed how to compute efficiently in <ref type="bibr" target="#b2">[2]</ref>, and obtain a O(n 2 ) gradient update rule:</p><formula xml:id="formula_13">∂E ∂W ij = X 2,i Y j + X 2,j Y i − λ 2 (X 2,i Y i + X 2,j Y j ) −λ ′ 2ij Y T D W X 2 with λ ′ 2ij = 2X 2,i X 2,j − λ 2 (X 2,i 2 + X 2,j 2 ) X T 2 D W X 2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">PROPERTIES OF THE LEARNING ALGORITHM</head><p>Empirically, we observe that E(W (t)) converges to 0 exponentially fast when W (t) follows the gradient path, even if the number of training examples grows as O(n). We will prove this fact in the case of a single target. The convergence of E(W (t)) however does not imply that of W (t). Indeed, one can construct functions for which gradient descent leads to limit cycle oscillations. The following proposition shows that this cannot happen here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prop. 3.3 (Exponential convergence of E(W, I))</head><p>The 1-target energy PDE ˙ W = − ∂E ∂W either converges to a global energy minimum W ∞ , or it escapes any compact K ⊂ S 2,X * n . In the first case, E(W (t)) → 0 exponentially.</p><p>Our proof in <ref type="bibr" target="#b2">[2]</ref> shows that ∂E ∂W ≥ b √ E, leading to the convergence of W (t), and then d dt E(W (t)) ≤ −b 2 E, which shows the exponential decay of E(W (t)).</p><p>Pathological non-convergence cases. As stated in the proposition, W (t) could potentially hit the boundary of S 2,X * n . This arises in 2 pathological cases: 1)</p><formula xml:id="formula_14">λ 2 (t) → 1 or λ 2 (t) − λ 3 (t) → 0, and 2) D W (t) (i, i) → 0 for some i. Note that X * (I) T X 2 [W (t)] → 0 can- not happen, because initially X * (I) T X 2 [W (t)] &gt; 0</formula><p>and E(W, I) decreases. There are ways to alleviate those problems through weight parameterization, but in practice they only occur when learning a lot of target vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">POINT SET CLUSTERING</head><p>In experiment 1, <ref type="figure" target="#fig_4">figure 6</ref>, we examine our spectral graph learning algorithm on simple 2D point set clustering examples. The graph weight matrix W ij = </p><formula xml:id="formula_15">exp(−σ x (x i − x j ) 2 ) + exp(−σ y (y i − y j ) 2 )</formula><p>has two parameters σ x , σ y which we aim to optimize. We update (σ x , σ y ) as follows:</p><formula xml:id="formula_16">∆σ x = −η(X − X * ) T ∂X ∂σ x (4) ∆σ y = −η(X − X * ) T ∂X ∂σ y (5)</formula><p>We use directly the derivatives given in Sec. 3.4 with the following expressions of W ′ :</p><formula xml:id="formula_17">∂w ij ∂σ x = −(x i − x j ) 2 e −σx(xi−xj ) 2 (6) ∂w ij ∂σ y = −(y i − y j ) 2 e −σy(yi−yj ) 2 (7)</formula><p>The experiments on simple clustering show a fast convergence of the gradient descent. We also tested the algorithm with radial distributed point sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">MULTISCALE IMAGE SEGMENTATION</head><p>In this experiment, we focus on an application of spectral learning in image segmentation. The aim is to provide a powerful tool to find the best scales of edge extraction in Ncut segmentation <ref type="bibr" target="#b3">[3]</ref>. Basically the idea of multiscale segmentation is to use several edge scales find a consistent segmentation of the image across scales. The simultaneous use of various scale levels is interesting for complex and big images which mixes textures with sharp and soft contours. In those images, meaningful boundaries may exist at weak contours or between textures that do not rise to edges. Using simultaneously several scales of edges enable to face this problem. The global affinity matrix is the sum of r-affinity matrices at different scales: the scales and to set up the weighting coefficients when more than two scales are required. Learning on σ coefficients enables to find the sensitivity to edge strength at a given scale.</p><formula xml:id="formula_18">W (I) i,j = k r=1 α r exp (−σ r ∆ (r) i,j (I))<label>(</label></formula><p>The update rules for α r , σ r are as following: <ref type="figure">Figure 9</ref>: The learned shift-invariant graph clique function ¯ f (x 2 − x 1 , y 2 − y 1 , θ 1 , θ 2 ) with θ 1 = 0, and θ 2 = π/2. Each 2D function corresponds to a fixed (θ 1 , θ 2 ) pair. The clique function learns to favor good continuation of the edges with (θ 1 = 0, θ 2 = 0), (θ 1 = π/2, θ 2 = π/2), and corner configurations (θ 1 = π/2, θ 2 = 0), (θ 1 = 0, θ 2 = π/2)</p><formula xml:id="formula_19">∆α r = −ηY ( ∂W ∂α r − λ ∂D ∂α r − ∂λ ∂α r D)X (9) ∆σ r = −ηY ( ∂W ∂σ r − λ ∂D ∂σ r − ∂λ ∂σ r D)X (10)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">SHAPE DETECTION</head><p>We first generate random rectangles in synthetic images of 100 by 100, see <ref type="figure" target="#fig_8">Fig. 8</ref>. The edges extracted, e i are specified by its quantized location (x i , y i ), orientation θ i , and polarity p i . Three graph weight clique potential functions are implemented:</p><formula xml:id="formula_20">1. unconstrained f (e 1 , e 2 ) = f (x 1 , y 1 , θ 1 , x 2 , y 2 , θ 2 ) 2. translational invariant f (e 1 , e 2 ) = ¯ f (x 2 − x 1 , y 2 − y 1 , θ 1 , θ 2 )</formula><p>3. translational invariant with ternary clique potential f (e 1 , e 2 ) = 1</p><formula xml:id="formula_21">N k g(x 1 − x k , y 1 − y k , x 2 − x k , y 2 − y k , θ 1 , θ 2 , θ k ).</formula><p>We apply the following graph learning algorithms to train segmentation algorithm to detect rectangles.   for each training set and the result displayed in <ref type="figure" target="#fig_0">fig.10</ref> have been averaged. We noticed a very low standard deviation on our training sets.</p><p>We see that the best results are achieved with the triplet clique method involving summation of ternary affinities over a third node. With only 20 training examples, an average of 75% of the noise was eliminated in the 2000 testing examples. We achieved the best result with a training data set of 500 squares. 15 iterations were enough to reach energy convergence and it took 4 minutes. This fast convergence can be explained by the averaging on a third node: when the affinity between two nodes is updated, all ternary affinities involving this pair are updated in a single pass. Also, ternary clique potentials carry out a stronger, more robust cue than binary affinities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">RECTANGLE DETECTION ON REAL IMAGES</head><p>This rectangle detection algorithm can be applied directly on real images, <ref type="figure" target="#fig_0">fig.12</ref>. We just have to adapt the filter parameters to have a good edge extraction. The amount of noise on real images turns out to be frequently below the one we used in the learning step, thus giving those encouraging results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Two alternative algorithms for learning spectral graph partitioning. (A) methods of Meila-Shi[4] optimizes the graph weight W (I, Θ) by minimizing the KL-divergence between an equivalent random walk matrix P (I, Θ) and the target P * (I, Θ). (B) Our method directly optimize the error on the output Ncut segmentation vector X N cut [W (I, Θ)] by gradient descent in the space of all feasible graph weights using explicit computation of the derivatives of eigenvectors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Properties of the clique potential/affinity matrix. Left and middle: translation and rotation invariance, f (x 1 , y 1 , θ 1 ; x 2 , y 2 , θ 2 ) = ¯ f (x 2 − x 1 , y 2 − y 1 , θ 1 , θ 2 ) and, f (z 1 , θ 1 ; z 2 , θ 2 ) = ¯ ¯ f ((z 2 − z 1 )e −iθ1 , θ 2 − θ 1 ). Right: summing up ternary affinities to obtain a binary affinity, f (e 1 , e 2 ) = i f 3 (e 1 , e 2 , e i ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The XOR function. Suppose we have a face detection graph with nodes: Left Nose (LN), Right Nose (RN), Face (F), and Non-Face(NF). The Hebbian learning rule, based on feature coocurrence, would find the following weights: W (LN, F ) = W (RN, F ) = W (LN, N F ) = W (RN, N F ) = 1 2 , making it impossible to distinguish between a Face and a Non-Face. The graph learning algorithm we propose does not suffer from this.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>We minimize the error energy over W by gradi- ent descent: ∆W = −η ∂E ∂W = −η ∂E ∂X2 ∂X2 ∂W . When W is parameterized by Θ, we have instead ∆Θ = −η ∂E ∂X2 ∂X2 ∂W ∂W ∂Θ . In the case of rectangle detection, the parameters Θ consist of all the values of the function f (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Learning point set clustering. W (i, j) = exp(−σx(x(i) − x(j)) 2 ) + exp(−σy(y(i) − y(j)) 2 ). A) 2D layout of the points. The first set is the cross set and the second is the star set. The resulting clustering can be identified by the red and black colors. B) Energy landscape of E(σx, σy), and gradient path taken by Eq.4, ( ˙ σx, ˙ σy) = −( ∂E ∂σx , ∂E ∂σy ). C) Target vector comparing with initial and final learned Ncut vector. The graph nodes are ordered according to their x-axis position (first row), and to their distance to origin (second row).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: A simple example of multiscale learning. The input image is 40 by 40 and 4 narrow scales are used. The best result (minimum of energy) with one scale is displayed as well as the result with all four scales set up with the same weight, and with the learned weight. The use of multiscale enable to segment correctly the inside of the G. The lowest energy is achieved after learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Figure 8: A: Training. Row 1: training input vector. Row 2: Ncut vector after learning. Row 3: target vector. B: Testing. Row 1: testing input vector, Row 2: Ncut vector after learning. For each edge, 2 polarities are hypothesized (only 1 is displayed in Row 1 of Training/Testing). Notice that after learning, not only clutter edges are suppressed but also the correct edge polarities are recovered.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>1 .</head><label>1</label><figDesc>Generate random rectangles with one noise- free and one noisy version per example. Generate a random affinity matrix W to start with 2. For each image I, extract edge features from the noisy image to compute subgraph V (I), and compute target X * (I) from the noise- free image 3. initialize E = 0; for each image I, (a) W (I) = W (V(I), V(I)), using one of the clique potential function f (e i , e j ) described above. (b) Compute X 2 (I), second generalized eigenvector of (W (I), D W (I) ) (c) Update W (I) with gradient update and propagate updating to each f (e i , e j ) (d) Update E := E + E I with the partial energy E I = 1 2 ||X 2 (I) − X * (I)|| 2 4. Go back to step 3 until E &lt; threshold</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8</head><label>8</label><figDesc>Fig.8 display the results of the training and testing using shift-invariant clique function ¯ f . Figure 4.2 shows the shift-invariant clique function learned on a pair of horizontal and vertical edges.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>4Figure 10 :</head><label>10</label><figDesc>Figure 10: Square shape detection and enhancement. For each simulation, the table indicates the percentage of remaining noise (100 is the initial amount of noise) on 2000 testing examples. These results have been obtained for different sizes of training set, according to three methods: 1-learning on full affinity matrix, 2-invariance by translation, 3-mean on third node with invariance by translation.</figDesc></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Left: edges detected, with arrows indicating orientation (2 opposite polarity hypothesis for each edge)</title>
	</analytic>
	<monogr>
		<title level="m">Examples of rectangle detection on real images</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
		</imprint>
	</monogr>
	<note>Right: segmentation of foreground edges. in red) versus background clutter edges (in dark</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A learnable spectral memory graph for recognition and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothee</forename><surname>Cour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Shi</surname></persName>
		</author>
		<idno>MS-CIS-04-12</idno>
	</analytic>
	<monogr>
		<title level="j">Philadelphia</title>
		<imprint>
			<date type="published" when="2004-06" />
		</imprint>
		<respStmt>
			<orgName>University of Pennsylvania CIS Technical Reports</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning to detect natural image boundaries using local brightness, color and texture cues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charless</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence(PAMI)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="530" to="549" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning segmentation with random walk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marina</forename><surname>Meila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On spectral clustering: Analysis and an algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Figure 12: Rectangle detection on real images. First column: image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence(PAMI)</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="888" to="905" />
		</imprint>
	</monogr>
	<note>Normalized cuts and image segmentation. second column: edges detected; third column: rectangle detection using the graph. Graph weights are learned with random rectangles in background noise</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
