<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Structural Patterns Heuristics via Fork Decomposition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Katz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Industrial Engineering &amp; Management Technion</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carmel</forename><surname>Domshlak</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Industrial Engineering &amp; Management Technion</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Structural Patterns Heuristics via Fork Decomposition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We consider a generalization of the PDB homomorphism abstractions to what is called &quot;structural patterns&quot;. The basic idea is in abstracting the problem in hand into provably tractable fragments of optimal planning, alleviating by that the constraint of PDBs to use projections of only low di-mensionality. We introduce a general framework for additive structural patterns based on decomposing the problem along its causal graph, suggest a concrete non-parametric instance of this framework called fork-decomposition, and formally show that the admissible heuristics induced by the latter abstractions provide state-of-the-art worst-case informativeness guarantees on several standard domains.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The difference between various algorithms for optimal planning as heuristic search is mainly in the admissible heuristic functions they define and use. Very often an admissible heuristic function for domain-independent planning is defined as the optimal cost of achieving the goals in an over-approximating abstraction of the planning problem in hand <ref type="bibr" target="#b21">(Pearl 1984;</ref><ref type="bibr" target="#b1">Bonet &amp; Geffner 2001)</ref>. Such an abstraction is obtained by relaxing certain constraints present in the specification of the problem, and the desire is to obtain a tractable (that is, solvable in polynomial time), yet informative abstract problem. The main question here is thus: What constraints should we relax to obtain such an effective over-approximating abstraction?</p><p>The abstract state space induced by a homomorphism abstraction is obtained by a systematic contracting groups of original problem states into abstract states. Most typically, such state-gluing is obtained by projecting the original problem onto a subset of its parameters, eliminating the constraints that fall outside the projection. Homomorphisms have been successfully explored in the scope of domainindependent pattern database (PDB) heuristics <ref type="bibr" target="#b5">(Edelkamp 2001;</ref><ref type="bibr" target="#b8">Haslum et al. 2007</ref>), inspired by the (similarly named) problem-specific heuristics for search problems such as (k 2 − 1)-puzzles, Rubik's Cube, etc. <ref type="bibr">(Culberson &amp; Scha- effer 1998)</ref>. A core property of the PDB heuristics is that the problem is projected onto a space of a small (up to logarithmic) dimensionality so that reachability analysis in that space could be done by exhaustive search. This constraint implies a scalability limitation of the PDB heuristics-as the problems of interest grow, limiting patterns to logarithmic dimensionality might make them less and less informative with respect to the original problems.</p><p>In this paper we consider a generalization of the PDB abstractions to what is called structural patterns. As it was recently suggested by <ref type="bibr" target="#b19">Katz and Domshlak (2007)</ref>, the basic idea behind structural patterns is simple and intuitive, and it corresponds to abstracting the original problem to provably tractable fragments of optimal planning. The key point is that, at least theoretically, moving to structural patterns alleviates the requirement for the abstractions to be of a low dimensionality. The contribution of this paper is precisely in showing that structural patterns are far from being of theoretical interest only. Specifically, we • Specify causal-graph structural patterns (CGSPs), a general framework for additive structural patterns that is based on decomposing the problem in hand along its causal graph.</p><p>• Introduce a concrete family of CGSPs, called fork decompositions, that is based on two novel fragments of tractable cost-optimal planning.</p><p>• Following the type of analysis suggested by <ref type="bibr" target="#b10">Helmert and Mattmüller (2008)</ref>, study the asymptotic performance ratio of the fork-decomposition admissible heuristics, and show that their worst-case informativeness on selected domains more than favorably competes with this of (even parametric) state-of-the-art admissible heuristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>From PDBs to Structural Patterns</head><p>Problems of classical planning correspond to reachability analysis in state models with deterministic actions and complete information; here we consider state models captured by the SAS + formalism <ref type="bibr" target="#b0">(Bäckström &amp; Nebel 1995)</ref>.</p><p>Definition 1 A SAS + problem instance is given by a quadruple Π = V, A, I, G, where:</p><p>• V = {v 1 , . . . , v n } is a set of state variables, each associated with a finite domain dom(v i ). The initial state I is a</p><formula xml:id="formula_0">A C D B E F G t c 2 c 1 c 3 p1 p2</formula><p>Figure 1: Logistics-style example adapted from Helmert (2006a). Deliver p 1 from C to G, and p 2 from F to E using the cars c 1 , c 2 , c 3 and truck t, and making sure that c 3 ends up at F . The cars may only use city roads (thin edges), the truck may only use the highway (thick edge).</p><p>complete assignment, and the goal G is a partial assignment to V .</p><p>• A is a finite set of actions, where each action a is a pair pre(a), eff(a) of partial assignments to V called preconditions and effects, respectively. Each action a ∈ A is associated with a non-negative real-valued cost C(a).</p><p>An action a is applicable in a state s ∈ dom(V ) iff s[v] = pre(a) <ref type="bibr">[v]</ref> whenever pre(a) <ref type="bibr">[v]</ref> is specified. Applying a changes the value of v to eff(a) <ref type="bibr">[v]</ref> if eff(a) <ref type="bibr">[v]</ref> is specified. In this work we focus on cost-optimal (also known as sequentially optimal) planning in which the task is to find a plan ρ ∈ A * for Π minimizing a∈ρ C(a). Across the paper we use a slight variation of a Logisticsstyle example of <ref type="bibr" target="#b14">Helmert (2006a)</ref>. This example is depicted in <ref type="figure">Figure 1</ref>, and in SAS + it has</p><formula xml:id="formula_1">V = {p1, p2, c1, c2, c3, t} dom(p1) = dom(p2) = {A, B, C, D, E, F, G, c1, c2, c3, t} dom(c1) = dom(c2) = {A, B, C, D} dom(c3) = {E, F, G} dom(t) = {D, E} I = {p1 = C, p2 = F, t = E, c1 = A, c2 = B, c3 = G} G = {p1 = G, p2 = E, c3 = F },</formula><p>and actions corresponding to all possible loads and unloads, as well as single-segment movements of the vehicles. For instance, if action a captures loading p 1 into c 1 at C, then pre(a) = {p 1 = C, c 1 = C}, and eff(a) = {p 1 = c 1 }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pattern Database Heuristics</head><p>Given a problem Π = V, A, I, G, for any partial assignment x to V , and any V ⊆ V , by x <ref type="bibr">[V ]</ref> we refer to the projection of x onto V . Considering homomorphism abstractions of Π, each variable subset V ⊆ V defines an over-approximating pattern abstraction Π <ref type="bibr">[V ]</ref> = V , A <ref type="bibr">[V ]</ref> , I <ref type="bibr">[V ]</ref> , G <ref type="bibr">[V ]</ref> that is obtained by projecting the initial state, the goal, and all the actions' preconditions and effects onto V (Edelkamp 2001). The idea behind the PDB heuristics is elegantly simple. First, we select a (relatively small) set of subsets V 1 , . . . , V m of V such that, for 1 ≤ i ≤ m, the size of V i is sufficiently small to perform exhaustive-search reachability analysis in Π <ref type="bibr">[Vi]</ref> . Let h <ref type="bibr">[Vi]</ref> (s) be the optimal cost of achieving the abstract goal G <ref type="bibr">[Vi]</ref> from the abstract state s <ref type="bibr">[Vi]</ref> . Since each Π <ref type="bibr">[Vi]</ref> is an overapproximating abstraction of Π, each h <ref type="bibr">[Vi]</ref> (·) is an admissible estimate of the true cost h * (·). Given that, if the set of abstract problems Π <ref type="bibr">[V1]</ref> , . . . , Π <ref type="bibr">[Vm]</ref> satisfy certain requirements of additivity <ref type="bibr" target="#b6">(Felner, Korf, &amp; Hanan 2004;</ref><ref type="bibr" target="#b5">Edelkamp 2001)</ref>, then PDB heuristic can be set to m i=1 h <ref type="bibr">[Vi]</ref> (s), and otherwise only to max m i=1 h <ref type="bibr">[Vi]</ref> (s). We now provide a syntactically slight, yet quite powerful generalization of the standard mechanism for constructing additive decompositions of planning problems along subsets of their state variables <ref type="bibr" target="#b6">(Felner, Korf, &amp; Hanan 2004;</ref><ref type="bibr" target="#b5">Edelkamp 2001</ref>).</p><p>Definition 2 Let Π = V, A, I, G be a SAS + problem, and let V = {V 1 , . . . , V m } be a set of some subsets of V . An <ref type="bibr">Vi]</ref> , and <ref type="bibr">[Vi]</ref> , eff(a) <ref type="bibr">[Vi]</ref> , then</p><formula xml:id="formula_2">additive decomposition of Π over V is a set of SAS + prob- lems Π = {Π 1 , . . . , Π m }, such that (1) For each Π i = V i , A i , I i , G i , we have (a) I i = I [Vi] , G i = G [</formula><formula xml:id="formula_3">(b) if a [Vi] def = pre(a)</formula><formula xml:id="formula_4">A i = {a [Vi] | a ∈ A ∧ eff(a) [Vi] = ∅}. (2) For each a ∈ A holds C(a) ≥ m i=1 C i (a [Vi] ).<label>(1)</label></formula><p>Definition 2 generalizes the idea of "all-or-nothing" action-cost partition from the literature on additive PDBs to arbitrary action-cost partitions-the original cost of each action is partitioned this or another way among the "representatives" of that action in the abstract problems, with Eq. 1 being the only constraint posed on this action-cost partition.</p><p>Proposition 1 For any SAS + problem Π over variables V , any set of V 's subsets V = {V 1 , . . . , V m }, and any additive decomposition of Π over V, we have h * (s) ≥ m i=1 h * i (s <ref type="bibr">[Vi]</ref> ) for all states s of Π. 1</p><p>Structural Patterns: Basic Idea PDB heuristics and their enhancements are successfully exploited these days in the planning research <ref type="bibr" target="#b5">(Edelkamp 2001;</ref><ref type="bibr" target="#b9">Haslum, Bonet, &amp; Geffner 2005;</ref><ref type="bibr" target="#b8">Haslum et al. 2007</ref>). However, the well-known Achilles heel of the PDB heuristics is that each pattern (that is, each selected variable subset V i ) is required to be small so that reachability analysis in Π <ref type="bibr">[Vi]</ref> could be done by exhaustive search. In short, computing h <ref type="bibr">[Vi]</ref> (s) in polynomial time requires satisfying</p><formula xml:id="formula_5">|V i | = O(log |V |) if |dom(v)| = O(1) for each v ∈ V i ,</formula><p>and satisfying |V i | = O(1), otherwise. In both cases, this constraint implies an inherent scalability limitation of the PDB heuristics. As the problems of interest grow, limiting patterns to logarithmic dimensionality will unavoidably make them less and less informative with respect to the original problems, and this unless the domain forces its problem instances to consist of small, loosely-coupled subproblems that can be captured well by individual patterns <ref type="bibr" target="#b10">(Helmert &amp; Mattmüller 2008)</ref>. However, as recently observed by <ref type="bibr" target="#b19">Katz and Domshlak (2007)</ref>, pattern databases are not necessarily the only way to proceed with homomorphism abstractions. In principle, given a SAS + problem Π = V, A, I, G, one can select a set of subsets V 1 , . . . , V m of V such that, for 1 ≤ i ≤ m, the reachability analysis in Π <ref type="bibr">[Vi]</ref> is tractable (not necessarily due to the size of but) due to the specific structure of Π <ref type="bibr">[Vi]</ref> . What is important here is that this requirement can be satisfied even if the size of each selected pattern V i is Θ(|V |). In any event, having specified the abstract problems Π <ref type="bibr">[V1]</ref> , . . . , Π <ref type="bibr">[Vm]</ref> as above, the heuristic estimate is then formulated similarly to the PDB heuristics: If the set of abstract problems</p><formula xml:id="formula_6">c₁ c₂ c₃ t p₁ p₂ A C D B E F G D E at A at B at C at D at E at F at G in c₂ in c₁ in t in c₃ (a) (b) (c)</formula><formula xml:id="formula_7">Π [V1] , . . . , Π [Vm] satisfy additiv- ity, then we set h(s) = m i=1 h [Vi] (s), otherwise we set h(s) = max m i=1 h [Vi] (s)</formula><p>. A priori, this generalization of the PDB idea to structural patterns is appealing as it allows using patterns of unlimited dimensionality. The pitfall, however, is that such structural patterns correspond to tractable fragments of cost-optimal planning, and the palette of such known fragments is extremely limited <ref type="bibr" target="#b0">(Bäckström &amp; Nebel 1995;</ref><ref type="bibr" target="#b2">Bylander 1994;</ref><ref type="bibr" target="#b17">Jonsson &amp; Bäckström 1998;</ref><ref type="bibr" target="#b18">Jonsson 2007;</ref><ref type="bibr" target="#b19">Katz &amp; Domshlak 2007)</ref>. Next, however, we show that this palette can still be extended, and this in the direction allowing us to materialize the idea of structural patterns heuristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Causal Graph Structural Patterns</head><p>The key role in what follows plays the causal graph structure that has already been exploited in complexity analysis of classical planning. The causal graph CG(Π) = (V, E) of a SAS + problem Π = V, A, I, G is a digraph over the nodes V . An arc (v, v ) belongs to CG(Π) iff v = v and there exists an action a ∈ A such that eff(a) <ref type="bibr">[v ]</ref>, and either pre(a) <ref type="bibr">[v]</ref> or eff(a) <ref type="bibr">[v]</ref> are specified. In what follows, for each v ∈ V , by pred(v) and succ(v) we refer to the sets of all immediate predecessors and successors of v in CG(Π).</p><p>Though less heavily, we also use here the structure of the problem's domain transition graphs <ref type="bibr" target="#b0">(Bäckström &amp; Nebel 1995)</ref>. The domain transition graph DTG(v, Π) of v in Π is an arc-labeled digraph over the nodes dom(v) such that an arc (ϑ, ϑ ) belongs to DTG(v, Π) iff there is an action a ∈ A with eff(a) <ref type="bibr">[v]</ref> = ϑ , and either pre(a) <ref type="bibr">[v]</ref> is unspecified or pre(a) <ref type="bibr">[v]</ref> = ϑ. In that case, the arc (ϑ, ϑ ) is labeled with pre(a) <ref type="bibr">[V \{v}]</ref> and C(a). <ref type="figure" target="#fig_0">Figure 2</ref> depicts the causal and (labels omitted) domain transition graphs for our running-example problem Π. We now proceed with exploiting this structure of the problems in devising structural pattern heuristics.</p><p>Though additive decomposition over subsets of variables is rather powerful, it is too general for our purposes because it does not account for any structural requirements one may have for the abstract problems. For instance, focusing on the causal graph, when we project the problem onto subsets of its variables, we leave all the causal-graph connections between the variables in each abstract problem untouched. In contrast, targeting tractable fragments of cost-optimal planning, here we aim at receiving abstract problems with causal graphs of specific structure. This leads us to introducing what we call causal graph structural patterns; the basic idea here is to abstract the given problem Π along a subgraph of its causal graph, obtaining an over-approximating abstraction that preserves the effects of the Π's actions to the largest extent possible.</p><p>Definition 3 Let Π = V, A, I, G be a SAS + problem, and G = (V G , E G ) be a subgraph of the causal graph CG(Π). A causal-graph structural pattern (CGSP) Π G = V G , A G , I G , G G is a SAS + problem defined as follows. <ref type="bibr">[v ]</ref>, and either <ref type="bibr">[v ]</ref> is specified and either eff(a) <ref type="bibr">[v]</ref> or pre(a) <ref type="bibr">[v]</ref> is specified, and each</p><formula xml:id="formula_8">1. I G = I [V G ] , G G = G [V G ] , 2. A G = a∈A A G (a), where each A G (a) = {a 1 , . . . , a l(a) }, l(a) ≤ |eff(a)|, is a set of actions over V G such that (a) for each a i ∈ A G (a), if eff(a i )</formula><formula xml:id="formula_9">eff(a i )[v] or pre(a i )[v] are specified, then (v, v ) ∈ E G . (b) for each (v, v ) ∈ E G , s.t. eff(a)</formula><formula xml:id="formula_10">a i ∈ A G (a), if eff(a i )[v ] is specified, then either eff(a i )[v] or pre(a i )[v] is specified as well. (c) for each s ∈ dom(V G ), if pre(a) [V G ] ⊆ s, then the action sequence ρ = a 1 · a 2 · . . . · a l(a) is applicable in s, and if applying ρ in s results in s ∈ dom(V G ), then s \ s = eff(a) [V G ] . (d) C(a) ≥ l(a) i=1 C G (a i ).</formula><p>For any SAS + problem Π = V, A, I, G, and any subgraph G = (V G , E G ) of the causal graph CG(Π), a CGSP Π G can always be (efficiently) constructed from Π, and it is ensured that CG(Π G ) = G. The latter is directly enforced by the construction constraints in Definition 3. To see the former, one possible construction of the action sets</p><formula xml:id="formula_11">A G (a) is as follows-if {v 1 , . . . , v k } is the subset of V G affected by a, then A G (a) = {a 1 , . . . , a k } with eff(a i )[v] = ( eff(a)[v], v = vi unspecified, otherwise pre(a i )[v] = 8 &gt; &gt; &gt; &gt; &gt; &lt; &gt; &gt; &gt; &gt; &gt; : eff(a)[v], v = vj ∧ j &lt; i ∧ (vj, vi) ∈ EG pre(a)[v], v = vj ∧ j &gt; i ∧ (vj, vi) ∈ EG pre(a)[v], v = vi pre(a)[v], v ∈ {v1, . . . , v k } ∧ (v, vi) ∈ EG unspecified, otherwise</formula><p>Now, given a SAS + problem Π and a subgraph G of CG(Π), if the structural pattern Π G can be solved costoptimally in polynomial time, we can use its solution as an admissible heuristic for Π. Moreover, given a set G = {G 1 , . . . , G m } of subgraphs of the causal graph CG(Π), these heuristic estimates induced by the structural patterns {Π G1 , . . . , Π Gm } are additive if holds a certain property given by Definition 4.</p><p>Definition 4 Let Π = V, A, I, G be a SAS + problem, and G = {G 1 , . . . , G m } be a set of subgraphs of the causal graph CG(Π). An additive CGSP decomposition of Π over G is a set of CGSPs Π = {Π G1 , . . . , Π Gm } such that, for each action a ∈ A, holds</p><formula xml:id="formula_12">C(a) ≥ m i=1 a ∈A G i (a) C Gi (a ).<label>(2)</label></formula><p>Proposition 2 (Admissibility) For any SAS + problem Π, any set of CG(Π)'s subgraphs G = {G 1 , . . . , G m }, and any additive CGSP decomposition of Π over G, we have</p><formula xml:id="formula_13">h * (s) ≥ m i=1 h * i (s [V G i ] ) for all states s of Π.</formula><p>Relying on Proposition 2, we can now decompose any given problem Π into a set of tractable CGSPs Π = {Π G1 , . . . , Π Gm }, solve all these CGSPs in polynomial time, and derive an admissible heuristic for Π. Note that (similarly to Definition 2) Definition 4 leaves the decision about the actual partition of the action costs rather open. In what follows we adopt the most straightforward, uniform action-cost partitioning in which the cost of each action a is equally split among all the non-redundant abstractions of a in Π. The choice of the action-cost partitioning, however, can sometimes be improved or even optimized; for further details see <ref type="bibr" target="#b20">(Katz &amp; Domshlak 2008</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fork-Decompositions</head><p>We now introduce certain concrete additive decompositions of SAS + planning problems along their causal graphs. In itself, these decompositions do not immediately lead to structural patterns abstractions, yet they provide an important building block on our way towards them.</p><formula xml:id="formula_14">Definition 5 Let Π = V, A, I, G be a SAS + problem. c₁ p₁ p₂ c₁ c₂ c₃ t p₁ CG(Π f c1 ) CG(Π if p1 )</formula><p>Figure 3: Causal graphs of a fork and an inverted fork structural patterns of the running example.</p><formula xml:id="formula_15">-F-decomposition Π F = {Π f v } v∈V , -I-decomposition Π I = {Π i v } v∈V , and -FI-decomposition Π FI = {Π f v , Π i v } v∈V are additive CGSP decompositions of Π over sets of sub- graphs G F = {G f v } v∈V , G I = {G i v } v∈V , and G FI = G F ∪ G I , respectively, where, for v ∈ V , V G f v = {v} ∪ succ(v), E G f v = u∈succ(v) {(v, u)} V G i v = {v} ∪ pred(v), E G i v = u∈pred(v) {(u, v)}</formula><p>Note that all three fork-decompositions in Definition 5 are entirely non-parametric in the sense of flexibility left by the general definition of CGSPs. Illustrating Definition 5, let us consider the (uniform) FI-decomposition of the problem Π from our running example, assuming all the actions in Π have the same unit cost. After eliminating from G FI all the singletons 2 , we get</p><formula xml:id="formula_16">G FI = {G f c1 , G f c2 , G f c3 , G f t , G i p1 , G i p2 }.</formula><p>Considering the action sets of the problems in Π FI , each original driving action is present in some three problems in Π FI , while each load/unload action is present in some five such problems. For instance, the action "drive-c 1 -from-Ato-D" is present in {Π f c1 , Π i p1 , Π i p2 }, and the action "load-</p><formula xml:id="formula_17">p 1 - into-c 1 -at-A" is present in {Π f c1 , Π f c2 , Π f c3 , Π f t , Π i p1 }.</formula><p>Since we assume a uniform partitioning of the action costs, the cost of each driving and load/unload action in each corresponding abstract problem is set to 1/3 and 1/5, respectively.</p><p>From Proposition 2 we have the sum of costs of solving the problems Π FI ,</p><formula xml:id="formula_18">h FI = v∈V h * Π f v + h * Π i v ,<label>(3)</label></formula><p>being an admissible estimate of h * . The question now is how good this estimate is. The optimal cost of solving our problem is 19. Taking as a basis for comparison the seminal (non-parametric) h max and h 2 heuristics <ref type="bibr" target="#b1">(Bonet &amp; Geffner 2001;</ref><ref type="bibr" target="#b7">Haslum &amp; Geffner 2000)</ref>, we have h max = 8 and h 2 = 13. At the same time, we have h FI = 15, and hence it appears that using h FI is at least promising. Unfortunately, despite the seeming simplicity of the problems in Π, turns out that fork-decompositions as they are do not fit the requirements of the structural patterns framework. On the one hand, the causal graphs of {Π f c1 , Π f c2 , Π f c3 , Π f t } and {Π i p1 , Π i p2 } form directed forks and inverted forks, respectively (see <ref type="figure">Figure 3)</ref>, and, in general, the number of variables in each such problem is Θ(n). On the other hand, <ref type="bibr" target="#b4">Domshlak and Dinitz (2001)</ref> show that even nonoptimal planning for SAS + problems with fork and inverted fork causal graphs is NP-complete. Moreover, even if the domain-transition graphs of all the state variables are strongly connected, optimal planning for forks and inverted forks remain NP-hard (see <ref type="bibr" target="#b12">Helmert (2003)</ref> and <ref type="formula" target="#formula_12">(2004)</ref> for the respective results). In the next section, however, we show that this is not the end of the story for forkdecompositions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Meeting CGSPs and Domain Abstractions</head><p>While hardness of optimal planning for problems with fork and inverted fork causal graphs put a shadow on relevance of fork-decompositions, closer look at the proofs of the corresponding hardness results of <ref type="bibr" target="#b4">Domshlak and Dinitz (2001)</ref> and <ref type="bibr" target="#b12">Helmert (2003;</ref><ref type="bibr" target="#b13">2004)</ref> reveals that these proofs in particular rely on root variables having large domains. It turns out that this is not incidental, and Propositions 3 and 4 below characterize some substantial islands of tractability within these structural fragments of SAS + .</p><p>Proposition 3 (Tractable Forks) Given a SAS + problem Π = V, A, I, G with a fork causal graph rooted at r, if (i) |dom(r)| = 2, or (ii) for all v ∈ V , |dom(v)| = O(1), then cost-optimal planning for Π is poly-time.</p><p>For the next proposition we use the notion of k-dependent actions-an action a is called k-dependent if it is preconditioned by ≤ k variables that are not affected by a <ref type="bibr" target="#b19">(Katz &amp; Domshlak 2007</ref>).</p><p>Proposition 4 (Tractable Inverted Forks) Given a SAS + problem Π = V, A, I, G with an inverted fork causal graph rooted at r ∈ V , if |dom(r)| = O(1) and all the actions A are 1-dependent, then cost-optimal planning for Π is poly-time.</p><p>Propositions 3 and 4 allow us to meet between the forkdecompositions and structural patterns. The basic idea is to further abstract each CGSP in fork-decomposition of Π by abstracting domains of its variables to meet the requirements of the tractable fragments. Such domain abstractions have been suggested for domain-independent planning by <ref type="bibr">Hoff- mann et al. (2006)</ref>, and recently successfully exploited in planning as heuristic search by <ref type="bibr" target="#b11">Helmert et al. (2007)</ref>.</p><p>Definition 6 Let Π = V, A, I, G be a SAS + problem, v ∈ V be a variable of Π, and Φ = {φ 1 , . . . , φ k } be a set of mappings from dom(v) to some sets</p><formula xml:id="formula_19">Γ 1 , . . . , Γ k . An ad- ditive domain decomposition of Π over Φ is a set of SAS + problems Π Φ = {Π 1 , . . . , Π k } such that (1) For each Π i = V i , A i , I i , G i , we have 3 (a) I i = φ i (I), G i = φ i (G), and (b) if φ i (a) def = φ i (pre(a)), φ i (eff(a)), then A i = {φ i (a) | a ∈ A ∧ φ i (eff(a)) ⊆ φ i (pre(a))}.</formula><p>(2) For each a ∈ A holds</p><formula xml:id="formula_20">C(a) ≥ k i=1 C i (φ i (a)).<label>(4)</label></formula><p>Proposition 5 For any SAS + problem Π over variables V , any variable v ∈ V , any domain abstractions</p><formula xml:id="formula_21">Φ = {φ i } k i=1</formula><p>of v, and any additive domain decomposition of Π over Φ,</p><formula xml:id="formula_22">we have h * (s) ≥ k i=1 h * i (φ i (s)</formula><p>) for all states s of Π. Targeting tractability of the causal graph structural patterns, we now connect between fork-decompositions and domain decompositions as in Definition 6. Given a FI-</p><formula xml:id="formula_23">decomposition Π FI = {Π f v , Π i v } v∈V of Π, we • For each Π f v ∈ Π, associate the root r of CG(Π f v ) with mappings Φ v = {φ v,1 , . . . , φ v,kv }, k v = O(poly(|Π|))</formula><p>, and all φ v,i : dom(r) → {0, 1}, and then additively de-</p><formula xml:id="formula_24">compose Π f v into Π f v = {Π f v,i } kv i=1 over Φ v .</formula><p>• For each Π i v ∈ Π, first, reformulate it in terms of 1-dependent actions only; such a reformulation can easily be done in time/space O(poly(|Π i v |)). Then, associate the root r of CG(Π i v ) with mappings</p><formula xml:id="formula_25">Φ v = {φ v,1 , . . . , φ v,k v }, k v = O(poly(|Π|))</formula><p>, and all φ v,i : <ref type="formula" target="#formula_4">(1)</ref>, and then ad-</p><formula xml:id="formula_26">dom(r) → {0, 1, . . . , b v,i }, b v,i = O</formula><formula xml:id="formula_27">ditively decompose Π i v into Π i v = {Π i v,i } k v i=1 over Φ v .</formula><p>From Propositions 2 and 5 we then have</p><formula xml:id="formula_28">h FI = v∈V   kv i=1 h * Π f v,i + k v i=1 h * Π i v,i   ,<label>(5)</label></formula><p>being an admissible estimate of h * for Π, and, from Propositions 3 and 4, h FI is also poly-time computable. The question is, however, how further abstracting our fork decompositions using domain abstractions as above affects the informativeness of the heuristic estimate. Below we show that the answer to this question can be somewhat surprising.</p><p>To illustrate a mixture of structural and domain abstractions as above, here as well we use our running Logisticsstyle example. To begin with an extreme setting of domain abstractions, first, let the domain abstractions for roots of both forks and inverted forks be to binary domains. Among multiple options for choosing the mapping sets {Φ v } and {Φ v }, here we use a simple choice of distinguishing between different values of each variable v on the basis of their distance from I <ref type="bibr">[v]</ref> in DTG(v, Π). Specifically, for each v ∈ V , we set Φ v = Φ v , and, for each value ϑ ∈ dom(v),</p><formula xml:id="formula_29">φ v,i (ϑ) = φ v,i (ϑ) = 0, d(I[v], ϑ) &lt; i 1, otherwise<label>(6)</label></formula><p>For example, the problem Π f c1 is decomposed (see <ref type="figure" target="#fig_0">Fig- ure 2b</ref>) into two problems, Π f c1,1 and Π f c1,2 , with the binary abstract domains of c 1 corresponding to the partitions {A}/{B, C, D} and {A, D}/{B, C} of dom(c 1 ), respectively. Now, given the decomposition of Π over forks and {Φ v , Φ v } v∈V as above, consider the problem Π i p1,1 , obtained from abstracting Π along the inverted fork of p 1 and then abstracting dom(p 1 ) using</p><formula xml:id="formula_30">φp 1 ,1(ϑ) = ( 0, ϑ ∈ {C} 1, ϑ ∈ {A, B, D, E, F, G, c1, c2, c3, t}</formula><p>It is not hard to verify that, from the original actions affecting p 1 , we are left in Π i p1,1 only with actions conditioned by c 1 and c 2 . If so, then no information is lost 4 if we 1. remove from Π i p1,1 both variables c 3 and t, and the actions changing (only) these variables, and 2. redistribute the (fractioned) cost of the removed actions between all other representatives of their originals in Π. The latter revision of the action cost partitioning can be obtained directly by replacing the cost-partitioning steps corresponding to Eqs. 2 and 4 by a single, joint action cost partitioning applied over the final abstractions</p><formula xml:id="formula_31">v∈V (Π f v ∪ Π i v ) and satisfying C(a) ≥ X v∈V 0 B @ kv X i=1 X a ∈A G f v (a) C f v,i (φv,i(a )) + k v X i=1 X a ∈A G i v (a) C i v,i (φ v,i (a )) 1 C A<label>(7)</label></formula><p>Overall, computing h FI as in Eq. 5 under "all binaryrange domain abstractions" provides us with h FI = 12 <ref type="bibr">7</ref> 15 , and knowing that the original costs are all integers we can safely adjust it to h FI = 13. Hence, even under the most severe domain abstractions as above, h FI does not fall from h 2 in our example problem.</p><p>Let us now slightly relax our domain abstractions for the roots of the inverted forks to be to the ternary range {0, 1, 2}. While mappings {Φ v } stay as before, {Φ v } are set to</p><formula xml:id="formula_32">∀ϑ ∈ dom(v) : φ v,i = 8 &gt; &lt; &gt; : 0, d(I[v], ϑ) &lt; 2i − 1 1, d(I[v], ϑ) = 2i − 1 2, d(I[v], ϑ) &gt; 2i − 1<label>(8)</label></formula><p>For example, the problem Π i p1 is now decomposed into Π i p1,1 , . . . , Π i p1,3 along the abstractions of dom(p 1 ). Applying now the same computation of h FI as in Eq. 5 over the new set of domain abstractions gives h FI = 15 1 2 , which, again, can be safely adjusted to h FI = 16. Note that this value is higher than h FI = 15 obtained using the (generally intractable) "pure" fork-decomposition as in Eq. 3. At first view, this outcome may seem counterintuitive as the domain abstractions are applied over the fork-decomposition, and one would expect a stronger abstraction to provide less precise estimates. This, however, is not necessarily the case. For instance, domain abstraction for the root of an inverted <ref type="table">Table 1</ref>: Performance ratios of multiple heuristics in selected planning domains; ratios for h + , h k , h PDB , h PDB add are by <ref type="bibr" target="#b10">Helmert and Mattmüller (2008)</ref>.</p><formula xml:id="formula_33">Domain h + h k h PDB h PDB add h F h I h FI GRIPPER 2/3 0 0 2/3 2/3 0 1/3 LOGISTICS 3/4 0 0 1/2 1/2 1/2 1/2 BLOCKSWORLD 1/4 0 0 0 0 0 0 MICONIC 6/7 0 0 1/2 5/6 1/2 1/2 SATELLITE 1/2 0 0 1/6 1/6 1/6 1/6</formula><p>LOGISTICS, BLOCKSWORLD, MICONIC-STRIPS, SATELLITE, MICONIC-SIMPLE-ADL, and SCHEDULE. (Familiarity with the domains is assumed; for an overview consult <ref type="bibr" target="#b15">Helmert, 2006b</ref>.) The h + estimate corresponds to the optimal cost of solving the well-known "ignore-deletes" abstraction of the original problem, and it is generally NP-hard to compute <ref type="bibr" target="#b2">(Bylander 1994)</ref>. The h k , k ∈ N + , family of heuristics is based on a relaxation where the cost of reaching a set of n satisfied atoms is approximated by the highest cost of reaching a subset of k satisfied atoms <ref type="bibr" target="#b1">(Bonet &amp; Geffner 2001)</ref>; computing h k is exponential only in k. The h PDB and h PDB add heuristics are regular (maximized over) and additive (summed-up) pattern database heuristics where the size of each pattern is assumed to be O(log(n)), and (importantly) the choice of the patterns is assumed to be optimal.</p><p>The results of Helmert and Mattmüller provide us with a baseline for evaluating our admissible heuristics h F , h I , and h FI corresponding to F-, I-, and FI-decompositions, respectively. At this point, the reader may rightfully wonder whether some of these three heuristics are not dominated by the others, and thus are redundant for our analysis. Proposition 6, however, shows that this is not the case-each of these three heuristics can be strictly more informative than the other two, depending on the problem instance and/or the state being evaluated.</p><p>Proposition 6 (Undominance) None of the heuristic functions h F , h I , and h FI (with and/or without domain abstractions) dominate each other. <ref type="table">Table 1</ref> presents now the asymptotic performance ratios of h F , h I , and h FI in GRIPPER, LOGISTICS, BLOCKSWORLD, MICONIC-STRIPS, and SATELLITE, 5 putting them in line with the corresponding results of Helmert and Mattmüller for h + , h k , h PDB , and h PDB add . We have also studied the ratios of max{h F , h I , h FI }, and in these five domains they appear to be identical to these of h F . 6 Taking a conservative position, the performance ratios for the fork-decomposition heuristics in <ref type="table">Table 1</ref> are "worst-case" in the sense that (i) here we neither optimize the action-cost partitioning (setting it to "uniform"), nor eliminate clearly redundant patterns, and <ref type="bibr">5</ref> We have not accomplished yet the analysis of MICONIC-SIMPLE-ADL and SCHEDULE; the action sets in these domains are much more heterogeneous, and thus more involved for analytic analysis of fork-decompositions. <ref type="bibr">6</ref> Note that "ratio of max" should not necessarily be identical to "max of ratios".</p><p>(ii) use domain abstractions to (up to) ternary-valued abstract domains only. Specifically, the domains of the inverted-fork roots are all abstracted using the "distance-from-initial-value" ternaryvalued domain decompositions as in Eq. 8, while the domains of the fork roots are all abstracted using the "leaveone-out" binary-valued domain decompositions as in Eq. 9.</p><formula xml:id="formula_34">∀ϑ i ∈ dom(v) : φ v,i (ϑ) = 0, ϑ = ϑ i 1, otherwise<label>(9)</label></formula><p>In a sketch, the results in <ref type="table">Table 1</ref> are obtained as follows. GRIPPER Assuming n &gt; 0 balls should be moved from one room to another, all the three heuristics h F , h I , h FI account for all the required pickup and drop actions, and only for O(1)-portion of move actions. On the other hand, the former actions are responsible for 2/3 of the optimal-plan length (= cost). Now, with the basic uniform action-cost partition, h F , h I , and h FI account for whole, O(1/n), and 1/2 of the total pickup/drop actions' cost, respectively, providing the ratios as in <ref type="table">Table 1</ref>. <ref type="bibr">7</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LOGISTICS</head><p>Optimal plan contains at least as much loads/unloads as move actions, and all the three heuristics h F , h I , h FI fully account for the former, providing a lower bound of 1/2. An instance on which all three heuristics achieve exactly 1/2 consists of two trucks t 1 , t 2 , no airplanes, one city, and n packages such that the initial and goal locations of all the packages and trucks are all pair-wise different.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BLOCKSWORLD Arguments similar to these of Helmert and</head><p>Mattmüller <ref type="formula" target="#formula_12">(2008)</ref> for h PDB add . MICONIC-STRIPS All the three heuristics fully account for all the loads/unloads. In addition, h F accounts for the full cost of all the moves to the passengers' initial locations, and for half of the cost of all other moves. This provides us with the lower bounds of 1/2 and 5/6, respectively. Tightness of 1/2 for h I and h FI is, e.g., on the instance consisting of n passengers, 2n+1 floors, and all the initial and goal locations being pair-wise different. Tightness of 5/6 for h F is, e.g., on the instance consisting of n passengers, n + 1 floors, the elevator and all the passengers are initially at floor n + 1, and each passenger i wishes to get to floor i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SATELLITE</head><p>The length of an optimal plan for a problem with n images to be taken and k satellites to be moved to some end-positions is ≤ 6n + k. All the three heuristics fully account for all the image-taking actions, and one satellite-moving action per satellite as above, providing a lower bound of 1 6 . Tightness of 1/6 for all three heuristics is on the following instance: Two satellites with instruments {i} l i=1 and {i} 2l i=l+1 , respectively, where l = n − √ n. Each pair of instruments {i, l + i} can take images in modes {m 0 , m i }. There is a set of directions {d j } n j=0 and a set of image objectives {o i } n i=1 such that, for 1 ≤ i ≤ l, o i = (d 0 , m i ), and, for l &lt; i ≤ n, o i = (d i , m 0 ). Finally, the calibration direction for each pair of instruments {i, l + i} is d i .</p><p>Overall, the results for fork-decomposition heuristics in <ref type="table">Table 1</ref> are very gratifying. First, note that the performance ratios for h k and h PDB are all 0. This is because every kelementary (for h k ) and log(n)-elementary (for h PDB ) subgoal set can be reached in the number of steps that only depends on k (respectively, log(n)), and not n, while h * (s n ) grows linearly in n in all the five domains. This leaves us with h PDB add being the only state-of-the-art (tractable and) admissible heuristic to compare with. <ref type="table">Table 1</ref> shows that the asymptotic performance ratio of max{h F , h I , h FI } is at least as good as this of h PDB add in all five domains, and it is superior to h PDB add in MICONIC-STRIPS, getting here quite close to h + . Comparing between h PDB add and fork-decomposition heuristics, it is crucial to recall that the ratios devised by Helmert and Mattmüller for h PDB add are with respect to optimal, manually-selected set of patterns. In contrast, forkdecomposition heuristics are completely non-parametric, and thus require no tuning of the pattern-selection process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary</head><p>We presented a generalization of the pattern-database projections, called structural patterns, that is based on abstracting the problem in hand to provably tractable fragments of optimal planning. The key motivation behind this generalization of PDBs is to alleviate the requirement for the patterns to be of a low dimensionality. We defined the notion of (additive) causal graph structural patterns (CGSPs), and studied their potential on a concrete CGSP framework based on decomposing the problem into a set of fork and inverted fork components of its causal graph, combined with abstracting the domains of certain variables within these individual components. We showed that the asymptotic performance ratios of the resulting heuristics on selected planning domains are at least as good, and sometimes transcends, these of the state-of-the-art admissible heuristics.</p><p>The basic principles of the structural patterns framework motivate further research in numerous directions, and in particular, in (1) discovering new islands of tractability of optimal planning, and (2) translating and/or abstracting the general planning problems into such islands. Likewise, currently we explore combining structural patterns (and, in particular, CGSPs) with PDB-style projection patterns, as well as with more flexible "merge-and-shrink" abstractions suggested in <ref type="bibr" target="#b11">(Helmert, Haslum, &amp; Hoffmann 2007)</ref>. Very roughly, the idea here is to "glue" and/or "duplicate" certain variables prior to projecting the problem in hand onto its tractable structural components. We believe that a successful such combination of techniques has a potential to improve the effectiveness of the heuristics, and in particular their domain-dependent asymptotic performance ratios.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: (a) Causal graph; (b) DTGs (labels omitted) of c 1 and c 2 (left), t (centre), and c 3 (right); (c) DTG of p 1 and p 2 .</figDesc></figure>

			<note place="foot" n="1"> Due to the lack of space, the proofs are given in the full TR.</note>

			<note place="foot" n="2"> If the causal graph CG(Π) is connected and n &gt; 1, then this elimination is not lossy, and can only improve the overall estimate.</note>

			<note place="foot" n="3"> For a partial assignment S on V , φi(S) denotes the abstract partial assignment obtained from S by replacing S[v] (if any) with φi(S[v]).</note>

			<note place="foot" n="4"> No information is lost here because we still keep either fork or inverted fork for each variable of Π.</note>

			<note place="foot" n="7"> We note that a very slight modification of the uniform actioncost partition results in ratio of 2/3 for all our three heuristics. Such optimizations, however, are outside of our scope here.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Accuracy of Fork-Decomposition Heuristics</head><p>Going beyond our running example, obviously we would like to assess the effectiveness of fork-decomposition heuristics on a wider set of domains and problem instances. A standard method for that is to implement admissible heuristics within some optimality-preserving search algorithm, run it against a number of benchmark problems, and count the number of node expansions performed by the search algorithm. The fewer nodes the algorithm expands, the better. While such experiments are certainly useful and important, as noted by <ref type="bibr" target="#b10">Helmert and Mattmüller (2008)</ref>, their results almost never lead to absolute statements of the type "Heuristic h is well-suited for solving problems from benchmark suite X", but only to relative statements of the type "Heuristic h expands fewer nodes than heuristic h on a benchmark suite X". Moreover, one would probably like to get a formal certificate for the effectiveness of her heuristic before proceeding with its implementation. In what follows, we formally analyze the effectiveness of the fork-decomposition heuristics similarly to the way <ref type="bibr" target="#b10">Helmert and Mattmüller (2008)</ref> study some state-of-theart admissible heuristics. Given domain D and heuristic h, Helmert and Mattmüller consider the asymptotic performance ratio of h in D. The goal is to find a value</p><p>, and (ii) there is a family of problems {Π n } n∈N ⊆ D and solvable, non-goal states {s n } n∈N such that s n ∈ Π n , lim n→∞ h * (s n ) = ∞, and</p><p>. In other words, h is never worse than α(h, D) · h * (plus a sublinear term), and it can become as bad as α(h, D) · h * (plus a sublinear term) for arbitrary large inputs; note that the existence and uniqueness of α(h, D) are guaranteed for any h and D.</p><p>Helmert and Mattmüller (2008) study the asymptotic performance ratio of the admissible heuristics h + , h k , h PDB , and h PDB add on some benchmark domains from the first four International Planning Competitions, namely GRIPPER,</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Complexity results for SAS + planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bäckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nebel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comp. Intell</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="625" to="655" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Planning as heuristic search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bonet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Geffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIJ</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="5" to="33" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The computational complexity of propositional STRIPS planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bylander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIJ</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="165" to="204" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Pattern databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Culberson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schaeffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comp. Intell</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="318" to="334" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multi-agent off-line coordination: Structure and complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Domshlak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dinitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECP</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="277" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Planning with pattern databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Edelkamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECP</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="13" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Additive pattern database heuristics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Felner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Korf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAIR</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="279" to="318" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Admissible heuristics for optimal planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haslum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Geffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICAPS</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="140" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Domain-independent construction of pattern database heuristics for cost-optimal planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haslum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Botea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Helmert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bonet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Koenig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1007" to="1012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">New admissible heuristics for domain-independent planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haslum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bonet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Geffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1163" to="1168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Accuracy of admissible heuristic functions in selected planning domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Helmert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mattmüller</surname></persName>
		</author>
		<editor>AAAI.</editor>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Extended abstract in the ICAPS&apos;07 workshops</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Flexible abstraction heuristics for optimal sequential planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Helmert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haslum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICAPS</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="176" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Complexity results for standard benchmark domains in planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Helmert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIJ</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="219" to="262" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A planning heuristic based on causal graph analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Helmert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICAPS</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="161" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The Fast Downward planning system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Helmert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAIR</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="191" to="246" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Solving Planning Tasks in Theory and Practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Helmert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<pubPlace>Freiburg</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Albert-Ludwigs University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. Dissertation</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Friends or foes? An AI planning perspective on abstraction and search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Domshlak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICAPS</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="294" to="303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">State-variable planning under structural restrictions: Algorithms and complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jonsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bäckström</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIJ</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="125" to="176" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The role of macros in tractable planning over causal graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jonsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1936" to="1941" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Structural patterns of tractable sequentially-optimal planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Domshlak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICAPS</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="200" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Optimal additive composition of abstraction-based admissible heuristics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Domshlak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICAPS (this volume)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Heuristics -Intelligent Search Strategies for Computer Problem Solving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
