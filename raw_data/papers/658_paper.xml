<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:36+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Online Identification of Hierarchical Heavy Hitters: Algorithms, Evaluation, and Applications</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 25-27, 2004</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Zhang</surname></persName>
							<email>yzhang@research.att.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumeet</forename><surname>Singh</surname></persName>
							<email>susingh@cs.ucsd.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhabrata</forename><surname>Sen</surname></persName>
							<email>sen@research.att.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">񮽙</forename><surname>Nick</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duffield</forename><surname>񮽙</surname></persName>
							<email>duffield@research.att.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Lund</surname></persName>
							<email>lund@research.att.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">񮽙 CSE Department</orgName>
								<orgName type="institution">AT&amp;T Labs -Research</orgName>
								<address>
									<addrLine>Florham Park</addrLine>
									<postCode>07932</postCode>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>92040</postCode>
									<settlement>San Diego</settlement>
									<region>CA</region>
									<country>USA §</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Online Identification of Hierarchical Heavy Hitters: Algorithms, Evaluation, and Applications</title>
					</analytic>
					<monogr>
						<title level="m">IMC&apos;04</title>
						<meeting> <address><addrLine>Taormina, Sicily, Italy</addrLine></address>
						</meeting>
						<imprint>
							<date type="published">October 25-27, 2004</date>
						</imprint>
					</monogr>
					<note>Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. ACM 1-58113-821-0/04/0010 ...$5.00.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>C23 [Computer-Communications Networks]: Network Opera- tions-Network Monitoring</term>
					<term>Network Management General Terms Measurement</term>
					<term>Algorithms Keywords Network Anomaly Detection</term>
					<term>Data Stream Computation</term>
					<term>Hierarchi- cal Heavy Hitters</term>
					<term>Change Detection</term>
					<term>Packet Classification</term>
				</keywords>
			</textClass>
			<abstract>
				<p>In traffic monitoring, accounting, and network anomaly detection, it is often important to be able to detect high-volume traffic clusters in near real-time. Such heavy-hitter traffic clusters are often hierarchical (i.e., they may occur at different aggregation levels like ranges of IP addresses) and possibly multidimensional (i.e., they may involve the combination of different IP header fields like IP addresses, port numbers, and protocol). Without prior knowledge about the precise structures of such traffic clusters, a naive approach would require the monitoring system to examine all possible combinations of aggregates in order to detect the heavy hitters, which can be prohibitive in terms of computation resources. In this paper, we focus on online identification of 1-dimensional and 2-dimensional hierarchical heavy hitters (HHHs), arguably the two most important scenarios in traffic analysis. We show that the problem of HHH detection can be transformed to one of dynamic packet classification by taking a top-down approach and adaptively creating new rules to match HHHs. We then adapt several existing static packet classification algorithms to support dynamic packet classification. The resulting HHH detection algorithms have much lower worst-case update costs than existing algorithms and can provide tunable deterministic accuracy guarantees. As an application of these algorithms, we also propose robust techniques to detect changes among heavy-hitter traffic clusters. Our techniques can accommodate variability due to sampling that is increasingly used in network measurement. Evaluation based on real Internet traces collected at a Tier-1 ISP suggests that these techniques are remarkably accurate and efficient.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Motivation and background</head><p>The Internet has emerged as a critical communication infrastructure, carrying traffic for a wide range of important scientific, business and consumer applications. Network service providers and enterprise network operators need the ability to detect anomalous events in the network, for network management and monitoring, reliability, security and performance reasons. While some traffic anomalies are relatively benign and tolerable, others can be symptomatic of potentially serious problems such as performance bottlenecks due to flash crowds <ref type="bibr" target="#b23">[24]</ref>, network element failures, malicious activities such as denial of service attacks (DoS) <ref type="bibr" target="#b22">[23]</ref>, and worm propagation <ref type="bibr" target="#b28">[28]</ref>. It is therefore very important to be able to detect traffic anomalies accurately and in near real-time, to enable timely initiation of appropriate mitigation steps. This paper focuses on streaming techniques for enabling accurate, near real-time detection of anomalies in IP network traffic data.</p><p>A major challenge for anomaly detection is that traffic anomalies often have very complicated structures: they are often hierarchical (i.e., they may occur at arbitrary aggregation levels like ranges of IP addresses and port numbers) and sometimes also multidimensional (i.e., they can only be exposed when we examine traffic with specific combinations of IP address ranges, port numbers, and protocol). In order to identify such multidimensional hierarchical traffic anomalies, a naive approach would require the monitoring system to examine all possible combinations of aggregates, which can be prohibitive even for just two dimensions. Another challenge is the need to process massive streams of traffic data online and in near real-time. Given today's traffic volume and link speeds, the input data stream can easily contain millions or more of concurrent flows, so it is often infeasible or too expensive to maintain per-flow state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Heavy hitters, aggregation and hierarchies</head><p>A very useful concept in identifying dominant or unusual traffic patterns is that of hierarchical heavy hitters (HHHs) <ref type="bibr" target="#b10">[11]</ref>. A heavy hitter is an entity which accounts for at least a specified proportion of the total activity measured in terms of number of packets, bytes, connections etc. A heavy hitter could correspond to an individual flow or connection. It could also be an aggregation of multiple flows/connections that share some common property, but which themselves may not be heavy hitters.</p><p>Of particular interest to our application is the notion of hierarchical aggregation. IP addresses can be organized into a hierarchy according to prefix. The challenge for hierarchical aggregation is to efficiently compute the total activity of all traffic matching relevant prefixes. A hierarchical heavy hitter is a hierarchical aggregate that accounts for some specified proportion of the total activity. Aggregations can be defined on one or more dimensions, e.g., source IP address, destination IP address, source port, destination port, and protocol fields for IP flows. Correspondingly, in this paper we will be concerned with multidimensional hierarchical heavy hitters, i.e., multidimensional sets of hierarchical aggregates that account for some specified proportion of the total activity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Contribution and approach</head><p>The main contribution of this paper is the development of several efficient streaming algorithms for detecting multidimensional hierarchical heavy hitters from massive data streams with a large number of flows. The common component of these algorithms is an adaptive data structure that carries a synopsis of the traffic in the form of a set of estimated hierarchical aggregates of traffic activity. The data structure is adapted to the offered traffic in that each aggregate contains no more than a given proportion of the total activity (with possible exception for those aggregates that are not further divisible).</p><p>These algorithms have much lower worst-case update costs than existing algorithms, and provide data independent deterministic accuracy guarantees. By adjusting the threshold proportion for detection, the level of detail reported can be traded off against the computation time.</p><p>A key theoretical contribution that enables our work is that we establish the close connection between multidimensional hierarchical heavy hitter detection and packet classification, two important problems often studied separately in the literature. In packet classification one maps packets onto a given set of fixed prefixes. Our problem is more challenging in that the set of prefixes (corresponding to the heavy-hitter traffic clusters) is dynamic, adapting to the set of IP addresses presented by the traffic and the relative activity on each of the prefixes. In fact, all our algorithms have static counterparts in the packet classification world (e.g., <ref type="bibr" target="#b31">[31,</ref><ref type="bibr" target="#b33">33]</ref>).</p><p>Our original motivation for this work was network anomaly detection. Change detection, an important component in anomaly detection, involves detecting traffic anomalies by deriving a model of normal behavior based on the past traffic history and looking for significant changes in short-term behavior (on the order of minutes to hours) that are inconsistent with the model. In the present context, this requires detecting changes across time in the activity associated with the heavy hitters. As an application of our method, we describe how standard change detection techniques can be adapted for robust use with the activity time series of hierarchical heavy hitters generated from the measured traffic. Evaluation based on real Internet traces collected at a Tier-1 ISP suggests that these techniques are remarkably accurate and efficient.</p><p>An important challenge to change detection stems from the fact that usage measurements are increasingly sampled. For instance, for NetFlow data, there are typically 2 levels of sampling: (i) packet sampling at the routers during the formation of NetFlow records <ref type="bibr" target="#b9">[10]</ref>, and (ii) smart sampling <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b14">15]</ref> of the NetFlow records within the measurement infrastructure. Our techniques accommodate the inherent sampling variability within our predictive scheme. Specifically, we can set alarm thresholds in order to keep the false positive rate due to sampling variability within acceptable limits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Related work</head><p>There is considerable literature in the area of statistical anomaly detection. Change detection has been extensively studied in the context of time series forecasting and outlier analysis <ref type="bibr" target="#b34">[34,</ref><ref type="bibr" target="#b8">9]</ref>. The standard techniques include simple smoothing techniques (e.g., exponential averaging), the more general Box-Jenkins ARIMA modeling <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b0">1]</ref>, and wavelet-based methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b3">4]</ref>. Prior works have applied these techniques to network fault detection (e.g., <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b35">35,</ref><ref type="bibr" target="#b18">19]</ref>) and intrusion detection (e.g., <ref type="bibr" target="#b7">[8]</ref>). Barford et al. recently provided a good characterization of different types of anomalies <ref type="bibr" target="#b4">[5]</ref> and proposed wavelet-based methods for change detection <ref type="bibr" target="#b3">[4]</ref>.</p><p>Existing works on heavy hitter detection lack the multidimensional adaptive hierarchical drill-down capability that our deterministic techniques offer. Existing change detection techniques typically can only handle a relatively small number of time series. Recent efforts use probabilistic summarization techniques like sketches to avoid per-flow state, for scalable heavy hitter detection <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">17]</ref> and change detection <ref type="bibr" target="#b25">[26]</ref>. <ref type="bibr" target="#b10">[11]</ref> presents both deterministic and sketch-based probabilistic online algorithms for hierarchical heavy hitter detection in one dimension. <ref type="bibr" target="#b17">[18]</ref> presents effective techniques for offline computation of multidimensional heavy hitters. Recently, Cormode et al. <ref type="bibr" target="#b11">[12]</ref> proposed an algorithm for multidimensional heavy hitter detection, which is the closest in spirit to our work. We will discuss their algorithm further at the end of Section 3.1.</p><p>The remainder of the paper is organized as follows: Section 2 formally presents the multidimensional HHH detection and change detection problems. Section 3 provides detailed descriptions of our proposed multidimensional HHH detection algorithms, and Section 4 describes our proposed techniques for change detection for HHH clusters. Section 5 outlines our evaluation methodology, and Section 6 presents evaluation results for our HHH detection and change detection algorithms. Finally, Section 7 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">PROBLEM SPECIFICATION</head><p>In this section, we formally define the notion of multidimensional hierarchical heavy hitters and introduce the heavy hitter detection problem.</p><p>We adopt the Cash Register Model <ref type="bibr" target="#b29">[29]</ref> to describe the streaming data. Let I = α1, α2, · · · , be an input stream of items that arrives sequentially. Each item αi = (ki, ui) consists of a key ki, and a positive update ui ∈ R. Associated with each key k is a time varying signal A <ref type="bibr">[k]</ref>. The arrival of each new data item (ki, ui) causes the underlying signal A[ki] to be updated:</p><formula xml:id="formula_0">A[ki]+ = ui.</formula><p>Below we first review the definition of Heavy Hitter and Hierarchical Heavy Hitters. DEFINITION 1 (HEAVY HITTER). Given an input stream I = {(ki, ui)} with total sum SU M = P i ui and a threshold φ (0 ≤ φ ≤ 1), a Heavy Hitter (HH) is a key k whose associated total value in I is no smaller than φSU M . More precisely, let v k = P i:k i =k ui denote the total value associated with each key k in I. The set of Heavy Hitters is defined as {k|v k ≥ φSU M }.</p><p>We define the heavy hitter problem as the problem of finding all heavy hitters, and their associated values, in a data stream. For instance, if we use the destination IP address as the key, and the byte count as the value, then the corresponding HH problem is to find all destination IP addresses that account for at least a proportion φ of the total traffic. DEFINITION 2 (HIERARCHICAL HEAVY HITTER). Let I = {(ki, ui)} be an input stream whose keys ki are drawn from a hierarchical domain D of height h. For any prefix p of the domain hierarchy, let elem(D, p) be the set of elements in D that are de-</p><formula xml:id="formula_1">scendents of p. Let V (D, p) = P k v k : k ∈ elem(D, p)</formula><p>denote the total value associated with any given prefix p. The set of Hierarchical Heavy Hitters (HHH) is defined as {p|V (D, p) ≥ φSU M }.</p><p>We define the hierarchical heavy hitter problem as the problem of finding all hierarchical heavy hitters, and their associated values, in a data stream. If we use the destination IP address to define the hierarchical domain, then the corresponding HHH problem not only wants to find destination IP addresses but also all those destination prefixes that account for at least a proportion φ of the total traffic.</p><p>Note that our definition of HHH is different from that of <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b17">18]</ref>. Specifically, we would like to find all the HH prefixes, whereas <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b17">18]</ref> returns a prefix p only if its traffic remains above φSU M even after excluding all traffic from HH prefixes that are descendents of p. All our algorithms can be adapted to use this more strict definition of HHH. We choose to use a simpler definition as part of our goal of HHH detection is to perform change detection on HHHs. If we do not output all the heavy hitter prefixes, then we can easily miss those big changes buried inside the prefixes that were not tracked (under the more strict definition).</p><p>We can generalize the definition of HHH to multiple dimensions:</p><formula xml:id="formula_2">DEFINITION 3 (MULTIDIMENSIONAL HHH). Let D = D1 × · · · × Dn be the Cartesian product of n hierarchical domains Dj of height hj (j = 1, 2, · · · , n). For any p = (p1, p2, · · · , pn) ∈ D, let elem(D, p) = elem(D1, p1)×· · ·×elem(Dn, pn). Given an input stream I = {(ki, ui)}, where ki is drawn from D, let V (D, p) = P k v k : k ∈ elem(D, p).</formula><p>The set of Multidimensional Hierarchical Heavy Hitters is defined as {p|V (D, p) ≥ φSU M }.</p><p>For simplicity, we also refer to a multidimensional hierarchical heavy hitter as a HHH cluster in the rest of the paper.</p><p>The multidimensional hierarchical heavy hitter problem is defined as the problem of finding all multidimensional hierarchical heavy hitters, and their associated values, in a data stream. As an example, we can define D based on source and destination IP addresses. The corresponding 2-dimensional HHH problem is to find all those source-destination prefix combinations &lt; p1, p2 &gt; that account for at least a proportion φ of the total traffic.</p><p>Once the multidimensional hierarchical heavy hitters have been detected in each time interval, we then need to track their values across time to detect significant changes, which may indicate potential anomalies. We refer to this as the change detection problem.</p><p>Our goal in this paper is to develop efficient and accurate streaming algorithms for detecting multidimensional hierarchical heavy hitters and significant changes in massive data streams that are typical of today's IP traffic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">MULTIDIMENSIONAL HHH DETECTION</head><p>To recall, our goal is to identify all possible keys (in the context of network traffic a key can be made up of fields in the packet header) that have a volume associated with them that is greater than the heavy-hitter detection threshold at the end of the time interval. A key may be associated with very large ranges. For example in the case of IP prefixes the range is: [0, 2 32 ). Also the key may be a combination of one or more fields, which can result in significant increase in the complexity of the problem. Clearly monitoring all possible keys in the entire range can be prohibitive (especially in the multidimensional context where we would have to consider a crossproduct of all the individual ranges).</p><p>Our solution to this problem entails building an adaptive data structure that dynamically adjusts the granularity of the monitoring process to ensure that the particular keys that are heavy-hitters (or more likely to be heavy-hitters) are correctly identified without wasting a lot of resources (in terms of time and space) for keys that are not heavy-hitters. In the 1-dimensional case, our data structure resembles a decision tree that dynamically drills down and starts monitoring a node (that is associated with a key) closely only when its direct ancestor becomes sufficiently large. In the 2-dimensional case, our data structure provides similar dynamic drill-down capability.</p><p>There are two key parameters that we will use throughout the rest of the paper: φ and 񮽙. Given the total sum SU M , φSU M is the threshold for a cluster to qualify as a heavy hitter; 񮽙SU M specifies the maximum amount of inaccuracy that we are willing to tolerate in the estimates generated by our algorithms.</p><p>To guide the building process of the summary data structure, we use a threshold, which we call the split threshold (T split ), to make local decisions at each step. It is used to make a decision as to when the range of keys under consideration should be looked at in a finer grain. T split is chosen to ensure that the maximum amount of traffic we miss during the dynamic drill-down is at most 񮽙SU M for any cluster. The actual choice of T split depends on the algorithm.</p><p>For now we assume that SU M is a pre-specified constant. Later in Section 3.6, we will introduce a simple technique that allows us to specify T split in terms of the actual total sum in a given time interval.</p><p>To exemplify the algorithms described in this section, we consider the source and the destination IP fields as the two dimensions for HHH detection. We also use what we call the volume, the number of bytes of traffic, associated with a given key, as the metric that we would like to use for detecting heavy-hitters. The metric as well as the fields to be considered for the dimensions may be changed based on the application requirements.</p><p>We start by considering a simple baseline solution to the HHH detection problem followed by adaptive algorithms for 1-dimensional and 2-dimensional HHH detection, arguably the two most important scenarios for traffic analysis. We conclude this section with a discussion on how our algorithms can be used as building blocks for general n-dimensional HHH detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Baseline solution</head><p>Below we describe a relatively straightforward, albeit inefficient, solution to the n-dimensional HHH detection problem. The scheme transforms the problem to essentially multiple (non-hierarchical) HH detection problems, one for each distinct combination of prefix length values across all the dimensions of the original key space. For an n-dimensional keyspace with a hierarchy of height hi in the i-th dimension, there are Π n i=1 (hi + 1) non-hierarchical HH detection problems, which have to be solved in tandem. Such a brute force approach will need to update the data structure for all possible combinations of prefix lengths. So the per-item update time is proportional to Π n i=1 (hi + 1). We use the above approach as a baseline for evaluating the multidimensional HHH detection algorithms proposed later in this section. We use the following two baseline variants that differ in the specific HH detection algorithm used. In the interest of space, we only provide a high level summary of the HH detection algorithms; readers are referred to <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b27">27]</ref> for detailed descriptions. Baseline variant 1: Sketch-based solution (sk), which uses sketchbased probabilistic HH detection. Count-Min sketch <ref type="bibr" target="#b13">[14]</ref> is a probabilistic summary data structure based on random projections (see <ref type="bibr" target="#b29">[29]</ref> for a good overview of sketch and specific sketch operations). Let</p><formula xml:id="formula_3">[m] denote set {0, 1, · · · , m − 1}. A sketch S consists of a H × K table of registers: TS[i, j] (i ∈ [H], j ∈ [K]). Each row TS[i, ·] (i ∈ [H])</formula><p>is associated with a hash function hi that maps the original key space to <ref type="bibr">[K]</ref>. We can view the data structure as an array of hash tables. Given a key, the sketch allows one to reconstruct the value associated with it, with probabilistic bounds on the reconstruction accuracy. The achievable accuracy is a function of both the number of hash functions (H), and the size of hash tables (K). The baseline scheme uses a separate sketch data structure per distinct prefix length combination in all the dimensions. Baseline variant 2: Lossy Counting-based solution (lc), which uses a deterministic, single-pass, sampling-based HH detection algorithm called Lossy Counting (see <ref type="bibr" target="#b27">[27]</ref>). Lossy Counting uses two parameters: 񮽙 and φ, where 0 ≤ 񮽙 񮽙 φ ≤ 1. At any instant, let N be the total number of items in the input data stream. Lossy Counting can correctly identify all heavy-hitter keys whose frequencies exceed φN . lc provides lower and upper bounds on the count associated with a heavy hitter. The gap between the two bounds is guaranteed to be at most 񮽙N . The space overhead for the algorithm is O( 1 񮽙 log(񮽙N )). The Lossy Counting algorithm can be modified to work with byte data instead of count data. All the complexity and accuracy results still apply except that we need to replace N with SU M . We use this adapted version in our evaluation.</p><p>We note that the algorithm in <ref type="bibr" target="#b11">[12]</ref> is also based on Lossy Counting. So we expect its accuracy to be similar to that of lc. In addition, while their algorithm is normally much more efficient than lc, the worst-case amortized update cost is comparable to lc (the worst-case scenario can occur when the keys in the input stream are uniformly distributed, which can be caused by events like a distributed denialof-service attack using spoofed source addresses). So although we do not directly compare against their algorithm, we expect the performance of lc to be indicative of the worst-case performance of their algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">A trie-based solution to 1-d HHH detection</head><p>Our goal is to identify the prefixes (considering that we use the destination IP as the key) that are responsible for an amount of traffic that exceeds a given threshold. We would like to do so while maintaining minimal state and performing a minimum number of update operations for each arriving flow or packet.</p><p>The hierarchical nature of the problem reminds us of the classical IP lookup problem in which for every received packet the IP destination field in the packet header is used to search for a longest matching prefix in a set of given IP prefixes (also known as a routing table). The difference between our particular situation and the IP lookup problem is that in the IP lookup problem the set of prefixes is given as an input and is often static. In contrast, we need to generate dynamically (based on the packet arrival pattern) the set of prefixes that are associated with the heavy hitters.</p><p>Despite the difference, however, we are able to develop an effective solution to 1-d HHH detection by adapting an existing solution to the static IP lookup problem -the trie-based solution proposed by Srinivasan et al. <ref type="bibr" target="#b32">[32]</ref>.</p><p>Trie is a simple data structure. Each node in a one-bit trie has at most two child nodes, one associated with bit 0 and the other with bit 1. Srinivasan et al. <ref type="bibr" target="#b32">[32]</ref> have extended on the basic idea of one-bit tries to create more refined multi-bit tries that are better suited for the IP lookup problem. Our algorithm is designed and implemented for m-bit tries, where each node of the trie has 2 m children, similar to the idea of the multi-bit tries. However for simplicity we describe our algorithm using one-bit tries.</p><p>The trie data structure. We maintain a standard trie data structure (as illustrated in <ref type="figure">Figure 1</ref>). Each node n in the trie is associated with a prefix p * identified by the path between the root of the trie and the node. Array n.child contains pointers to the children of n. Field n.depth gives the depth of n. Field n.fringe indicates whether n is a fringe node -we consider n as a fringe node if after its creation, we see less than T split amount of traffic associated with destination prefix p; otherwise, we consider n as an internal node. Field n.volume records the volume of traffic associated with prefix p that we see after n is created and before n becomes an internal node. Field n.subtotal gives the total volume of traffic for the entire subtrie rooted at n, excluding the portion already accounted for by n.volume. Fields n.miss copy and n.miss split represent estimated volume of traffic missed by node n (i.e., traffic that is associated with prefix p but appears before the creation of n). The copy-all and the splitting rules are used to compute n.miss copy and n.miss split, respectively (details to follow). The last four volume related fields are used to estimate the total volume of traffic that is associated with prefix p. We will describe the estimation algorithm later in this section.</p><p>// vol type is the data type for volume typedef struct { trie * child <ref type="bibr">[·]</ref>; // child <ref type="bibr">[i]</ref> points to the i-th child int depth; // the depth of this node boolean fringe; // true iff volume for entire subtrie &lt; T split vol type volume; // volume of traffic trapped at this node vol type subtotal;</p><p>// total volume of traffic in all descendents vol type miss copy; // missed traffic (estimated by copy-all) vol type miss split; // missed traffic (estimated by splitting) } trie;</p><p>Figure 1: The trie data structure Updating the trie. Our data structure starts with a single node trie that is associated with the zero-length prefix * . The volume field associated with this node is incremented with the size of each arriving packet. When the value in this field exceeds T split , we mark the node as internal and create one new child node associated with the prefix 0 * or 1 * that the incoming packet matches. The size of the current packet is then used to initialize the volume field in the newly created child node. The structure develops dynamically with the arrival of each new packet. This procedure is summarized in <ref type="figure">Figure 2</ref>.</p><formula xml:id="formula_4">1 int UPDATE 1D(key, value) 2 n = root 3 while (true) 4 if (n.fringe) 5 if (n.volume + value &lt; T split ) 6</formula><p>n.volume+ = value 7 return n.depth − 1 8 else 9</p><p>n.fringe = f alse 10 if (n.depth = W ) 11</p><p>n.subtotal = value 12 return n.depth</p><formula xml:id="formula_5">13 endif 14 endif 15 else if (n.depth = W ) 16</formula><p>n.subtotal+ = value 17 return n.depth 18 endif 19 index = get N th bit(key, n.depth + 1)</p><formula xml:id="formula_6">20 c = get child(n,index) 21 if (c = N U LL) 22 c = create child(n, index) 23 endif 24 n = c 25 endwhile</formula><p>Figure 2: The update operation is very simple: walk down the trie until we reach a fringe node, and check if we can update its volume. if the updated volume is still below T split , make the update and return; otherwise, mark the node as internal and continue walking down the trie. The actual implementation also includes some special handling when we reach the bottom of the trie (i.e., we use up all bits in the key)</p><p>In <ref type="figure" target="#fig_0">Figure 3</ref> we illustrate the update operation for a trie with T split set to 10. The arriving packet has a Destination IP prefix of 100 * and a size of 5 bytes. <ref type="figure" target="#fig_0">Figure 3 (a)</ref> shows the trie at the time of the packet arrival. The algorithm first performs a longest matching prefix operation on the trie and arrives at the node associated with prefix 10 * . Adding 5 bytes to the volume field of this node would make its value cross T split . Therefore, the algorithm creates a new node associated with prefix 100 * (i.e., the child node associated with bit 0). The size of the current packet is used to initialize the volume field of the newly created node. One can see that our trie construction process guarantees that the values of the volume field in any internal node is always less than T split . As a result, if we set T split = 񮽙SU M/W , we can ensure that the maximum amount of traffic we miss as we dynamically drill down to the fringe is at most 񮽙SU M .</p><p>The time complexity of the operations described above is on the same order of magnitude as a regular IP lookup operation, i.e., O(W ). For every packet arrival, we update at most one node in the trie. At most one new node is created during each update as long as the volume for the new item is below T split (in case the volume exceeds T split , we need to create an entire new branch all the way to the maximum depth W ). It is easy to see that at each depth, there can be no more than SU M/T split = W// internal nodes (otherwise the total sum over all the subtries rooted at those nodes would exceed SU M , which is impossible). So the worst-case memory requirement of the data structure is O(W 2 //). Reconstructing volumes for internal nodes. In our trie building algorithm, every packet arrival results in at most one update. The update occurs at the node which is the most specific node representing the destination IP prefix (of the packet) at the time of the packet arrival. Therefore we need to reconstruct the volumes of the internal nodes at the end of the time interval. By delaying the reconstruction process to the end of the time interval, the reconstruction cost is amortized across the entire time interval. To compute the volumes associated with all the internal nodes, we perform a recursive post-order traversal of the trie. In each recursive step the volume of the current node is computed as being the sum of the volume represented in the current trie node and its child nodes. This procedure is illustrated in <ref type="figure">Figure 4</ref>. Estimating the missed traffic for each node. We note that because of utilizing T split to guide the trie construction process the volumes represented in the internal nodes even after reconstruction are not entirely accurate. In order to more accurately estimate the volume associated with a given node, we also need to include an estimate of the missed traffic for that node. Below we consider three ways of estimating the missed traffic.</p><formula xml:id="formula_7">1 void COMPUTE MISSED 1D(n) 2 for (each child c of n) 3 if (c 񮽙 = N U LL ) 4</formula><p>c.miss copy = n.volume + n.miss copy Copy-all: the missed traffic for a node N is estimated as the sum of the total traffic seen by the ancestors of node N in the path from node N to the root of the tree. Note that copy-all is conservative in that it copies the traffic trapped at a node to all its descendents. It always gives an upper bound for the missed traffic. Since our update operation maintains the invariant that every internal node n has n.volume below T split , the estimate given by the copy-all rule is further upper bounded by depth of the node ×T split .</p><p>No-copy: this is the other extreme that optimistically assumes the amount of missed traffic to be 0.</p><p>Splitting: the total contribution of missed traffic by a node n is split among all its children c in proportion to the total traffic for c. Essentially what this assumes is that the traffic pattern before and after the creation of a node are very similar, so we can predict missed traffic by proportionally splitting the traffic trapped at a node to all its children.</p><p>Both the copy-all and the splitting rule can be easily implemented by traversing the trie in a top-down fashion (as shown in <ref type="figure">Figure 5</ref>). Detecting HHHs. Once we have an estimate of the missed traffic, we can combine it with the total amount of traffic we have seen and use the sum as input for HHH detection. The accuracy clearly depends on which rule we use: copy-all ensures that there is no false negative but there will be some false positives; no-copy ensures that there is no false positive but there may be some false negatives; splitting will have fewer false positives than copy-all and fewer false negatives than no-copy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Detecting 2-d HHHs via Cross-Producting</head><p>We next consider the 2-dimensional HHH problem and develop a solution by adapting the cross-producting technique <ref type="bibr" target="#b33">[33]</ref>, which was originally proposed for solving the packet classification problem <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b19">20]</ref>.</p><p>The high level idea of our solution is to execute our 1-dimensional algorithm described in Section 3.2, for each of the dimensions (IP destination, and IP source) and to use the length associated with the longest matching prefix nodes in each of the dimensions as an index into a data-structure that holds the volume data for the 2-dimensional HHHs.</p><p>In our solution, we maintain three data structures. Two tries are used to keep track of the 1-dimensional information, a W × W array H of hash tables is used to keep track of the 2-dimensional tuples. A tuple &lt; p1, p2 &gt; comprises of the longest matching prefix in both the dimensions. The array is indexed by the lengths of the prefixes p1 and p2. In the case of IPv4 prefixes, for a 1-bit trie-based solution, W = 32. Updating the summary data structure.</p><p>For every incoming packet we first update the individual 1-dimensional tries, which return the longest matching prefix in each of the dimensions. This gives us two prefixes p1 and p2 with lengths l1 and l2 respectively. Next the two lengths are used as an index to identify the hash table H[l1][l2]. &lt; p1, p2 &gt; is then used as a lookup key in the hash table H[l1] <ref type="bibr">[l2]</ref>. Subsequently, the volume field of the entry associated with the key is incremented. This process is repeated for every arriving packet. <ref type="figure">Figure 6</ref> illustrates the basic algorithm.</p><p>For every packet three update operations are performed, one operation in each of the two 1-dimensional tries, and one operation in at most one of the hash-tables. This results in a very fast algorithm. The memory requirement in the worst case is O((W 2 //) 2 ) = O(W 4 // 2 ), due to the use of cross-producting. But in practice, we expect the actual memory requirement to be much lower. Reconstructing volumes for 2-d internal nodes. To compute the total volume for the internal nodes, we just need to add the volume for each element in the hash tables to all its ancestors. This can be implemented by scanning all the hash elements twice. During the first pass, for every entry e represented by key &lt; p1, p2 &gt; (where p1 and p2 represent prefixes) with prefix lengths &lt; l1, l2 &gt; we add the volume associated with e to its left parent in the hash-map represented by key &lt; ancestor(p1), p2 &gt; and lengths &lt; l1 − 1, l2 &gt;.</p><formula xml:id="formula_8">1 void UPDATE CP(key 1 , key 2 , value) 2 l 1 = UPDATE 1D(trie 1 , key 1 , value) 3 l 2 = UPDATE 1D(trie 2 , key 2 , value) 4 if (l 1 ≥ 0 ∧ l 2 ≥ 0 ) 5 p 1 = prefix(key 1 , l 1 ) 6 p 2 = prefix(key 2 , l 2 ) 7 H[l 1 ][l 2 ].update(&lt; p 1 , p 2 &gt;,</formula><p>Note that we start from entries with the largest l1 and end with entries with the smallest l1. Then in the second pass, we add the volume to right parent represented by the key &lt; p1, ancestor(p2) &gt; and lengths &lt; l1, l2 − 1 &gt;. This time we start from entries with the largest l2 and end with entries with the smallest l2. Estimating the missed traffic for each node. The algorithm is as follows. For each key (recall that the key is made up of the destination prefix and the source prefix) in the hash table traverse the individual tries to find the prefix represented by the key and return the missed traffic estimate obtained from the node (by applying either the copy-all, or the splitting rule as described in Section 3.2). The missed traffic is then estimated as the maximum of the two estimates returned by the two 1-d tries. Using the maximum preserves the conservativeness of copy-all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Grid-of-Tries and Rectangle Search</head><p>The proposed scheme using the Cross-Producting technique is very efficient in time, however it can be potentially memory intensive in the worst case. We try to overcome this drawback by adapting two other well known algorithms for two-dimensional packet classification to our problem: Grid-of-Tries and Rectangle Search <ref type="bibr" target="#b33">[33]</ref>.</p><p>Just like Cross-Producting, both Grid-of-Tries and Rectangle Search have been applied in the packet classification context. This is not a coincidence. Conceptually, if we view each node as a rule, then finding nodes on the fringe becomes a packet classification problem.</p><p>However most packet classification algorithms are optimized for a relatively static rule set (through pre-computation), whereas in our context, we may need to dynamically maintain the fringe set. This may involve updating n nodes and possibly creating n new nodes. Despite the clear difference, we are able to adapt Grid-of-Tries and Rectangle Search to solve our problem. Since both algorithms have been well documented in the literature, we will only illustrate the basic idea and highlight the main difference. Interested readers should refer to <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b31">31,</ref><ref type="bibr" target="#b1">2]</ref> for further details on these algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Grid-of-Tries</head><p>The grid-of-tries data structure has been introduced by Srinivasan et al. <ref type="bibr" target="#b33">[33]</ref> as a solution to the 2-dimensional packet classification problem. The data structure contains two levels of tries. The first level is associated with the IP destination prefixes in the classifier (a predefined rule set) while the second level tries are associated with IP source prefixes in the classifier.</p><p>For every valid prefix (P1) node in the first level trie there is a pointer to a second level trie. The second level trie is created using all the prefixes (P2) for which there is a rule P1,P2 in the classifier. For a complete description the reader is kindly directed to <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b1">2]</ref>. As in the 1-dimensional HHH detection case, our grid-of-tries data structure is dynamically built based on the packet arrival pattern. Constructing grid-of-tries for 2-d HHH detection. Each node in the data structure contains a pointer to each of its children. In addition each node in the first-level trie maintains a pointer to a secondlevel trie and each node in the second-level trie maintains a jump pointer (details to follow) for fast trie traversal. The thing to note is that there is only one first-level trie, but multiple second-level tries. Specifically, there is a second-level trie for each node in the firstlevel trie. Each node also stores a volume field associated with the volume of traffic that corresponds to all the packets having a prefix equal with the prefix of the node from the moment that the node is created till the moment when new child nodes are associated with the node.</p><p>Let us assume the existence of a current grid-of-tries structure at the given moment. New nodes and tries may be appended to the current grid-of-tries with the arrival of a new packet. First, a longest matching prefix (LMP) operation is executed in the first-level trie (using the destination prefix). A fringe node is always identified. Then same as in the case of our 1-d trie algorithm (described in section 3.2) if the volume associated with this node becomes greater than T split then a new child node is created and associated with this node. As in the 1-d algorithm, the size of the current packet is used to initialize the volume field for the newly created child node. In addition to adding child nodes in the first-level trie, in our 2-d algorithm we must also initialize and associate a new second-level trie with each one of these newly created children. These second-level tries when first created are only initialized with a root node. The size of the current packet is used to increment the volume associated with the second-level trie that is associated with the new LMP in the first-level trie.</p><p>The arrival of a packet may also result in a situation where the node represented by the LMP in the second-level trie exceeds T split . In this case a new child is created and associated with this node in the second-level trie in a way similar to the 1-dimensional HHH detection node creation process.</p><p>Every packet that arrives may contribute to multiple updates in the volume field of the nodes in the second dimension tries. To illustrate the update process let us consider the example in <ref type="figure" target="#fig_4">Figure 7</ref>, and the arrival of a packet with destination IP prefix 000 * , and source IP prefix 111 * with a size of 4 bytes. T split is set to 10 for this illustration. <ref type="figure" target="#fig_4">Figure 7</ref> represents the grid-of-tries data structure at the time of the packet arrival. For the moment ignore the dotted lines in the figure. This arriving packet contributes to a modification in the value of the volume field in each one of the second-dimension tries associated with the LMP node in the first-dimension and all ancestors of this LMP node. <ref type="figure" target="#fig_5">Figure 8</ref> shows the data structure after the update operation. The nodes that are affected by the update are shown in grey. To walk through the process, first a LMP operation was done in the first-level trie using the first prefix 000 * , and the value of the volume field associated with this LMP node is increment. We next follow the pointer to the second-level trie. Again we do a LMP operation in the second-level trie using the second prefix 111 * . Our search terminates with the node for prefix 1 * . If we were to add the size of the current packet to the volume associated with this node it would increase beyond T split . We therefore create a new child node for this node. The size of the current packet is used to initialize the volume associated with the new child node for prefix 11 * as this new node now represents the LMP. We must also update the second level tries associated with all the less specific prefixes of 000 * namely 00 * , 0 * and * .</p><p>In order to provide a fast update operation, each fringe node in the second-level trie contains a pre-computed jump pointer. Each fringe node in a second-level trie T2 for prefix P2 originating at prefix P1 in the first-level trie maintains a jump pointer to the same prefix P2 in a second-level trie that is associated with the direct ancestor of P1. Note that the jump pointer discussed here can be maintained dynamically -whenever we create a node in the second-level trie associated with P1, we also create a node for the second-level trie associated with the direct ancestor of P1 (if not already present). In contrast, schemes discussed in the packet classification context are more complicated and require precomputation <ref type="bibr" target="#b1">[2]</ref>. Utilizing jump pointers allows us to keep the time complexity within O(W ) as dur-  ing the update process we can avoid having to restart the longest prefix matching problem at the root of every second-level trie (recall that we need to update every second-level trie associated with all ancestors of the longest matching prefix node in the path between the node and the root of the first-level trie). The dashed lines in <ref type="figure" target="#fig_4">Figure 7</ref> and 8 represent jump pointers. To ensure we only miss 񮽙SU M traffic in the worst case, we need to choose</p><formula xml:id="formula_9">T split = 񮽙SU M/(2W ). The space requirement is O(W 2 · (2W )//) = O(2W 3 //).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Rectangle Search</head><p>Rectangle Search <ref type="bibr" target="#b33">[33]</ref> is another classic solution proposed for 2-dimensional packet classification. Like Grid-of-Tries, it can be adapted to solve the 2-dimensional HHH detection problem.</p><p>Conceptually, Rectangle Search does exactly the same thing as Grid-of-Tries -updating all the elements on the fringe and expanding it whenever necessary. The major difference lies in how the algorithm locates all the elements on the fringe. Grid-of-Tries does so using jump pointers. In the worst case, it requires 3W memory accesses, where W is the width of the key. Rectangle Search uses hash tables instead and requires 2W (hashed) memory accesses in the worst case.</p><p>The basic data structure for Rectangle Search is a set of hash tables arranged into a 2-dimensional array. The update operation for a new tuple &lt; k1, k2 &gt; (with value v) is illustrated in <ref type="figure" target="#fig_0">Figure 3</ref>.4.2. We first consider the case when v is below T split , which is the common case as the total number . We then increment l1 by 1 and continue (i.e., move towards right in <ref type="figure" target="#fig_0">Figure 3</ref>.4.2(c)). The algorithm terminates whenever either l1 &gt; W or l2 &lt; 0. Since during each step either we either increment l1 by one or decrement l2 by one, the algorithm takes at most 2W −1 steps to terminate. When v is above T split , the algorithm is virtually identical, except that for each l1 we need to insert one element with value 0 into each hash table H[l1][j] (l2 &lt; j &lt; W ) and then one element with value v into hash table H[l1] <ref type="bibr">[W ]</ref>. In the worst case, this may create (W + 1) 2 new elements. But since the number of elements above T split is small (below SU M/T split ), the amortized cost is quite low.</p><p>The pseudo code in <ref type="figure" target="#fig_8">Figure 10</ref> illustrates the general idea for the update operation when v is below T split . The actual implementation is more detailed due to issues like boundary cases.</p><p>Just like Grid-of-Tries, Rectangle Search requires O(2W 3 //) space to guarantee an error bound of 񮽙SU M .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Lazy expansion</head><p>In all the algorithms described so far, whenever we receive an item &lt; k1, k2 &gt; with value v above T split , we will create state for all its ancestors &lt; p1, p2 &gt; if they do not already exist. Such express expansion of the fringe has the advantage that it leads to less missed traffic for the fringe nodes and thus higher accuracy. However, it also requires a lot of space, especially when T split is very small and there are a large number of items with value above it (this can happen, for instance, when the maximum depth of the trie is large). Here we l 1 = 0; l 2 = W ; // lower left corner 3</p><p>while  introduce a simple technique, lazy expansion to significantly reduce the space requirement. The basic idea for lazy expansion is very simple. Whenever we receive a large item with value v satisfying v/T split ∈ [k − 1, k], we split it into k smaller items, each with value v/k &lt; T split . We then perform k separate updates. Since each item is below T split , it will lead to the creation of no more than W elements. So long as k &lt; W , we are guaranteed to reduce space requirement while still achieving the same deterministic worst-case accuracy guarantee. Meanwhile, we can modify the update operation to batch k updates together (by taking into account the multiplicities of the item). This avoids any increase in the update cost.</p><formula xml:id="formula_10">( l 1 ≤ W ∧ l 2 ≥ 0 ) 4 p 1 = pref ix(k 1 , l 1 ); p 2 = pref ix(k 2 , l 2 ) 5 e = H[l1][l2].lookup(&lt; p 1 , p 2 &gt;) 6 if ( undefined(e) ) 7 l 2 −− //</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Compression</head><p>So far all our algorithms assume a fixed value for SU M . For many online applications, however, it may be desirable to set the threshold as a fraction of the actual total traffic volume for the current interval, which is not known until all the traffic is seen. Our strategy is to first use a small threshold based on some conservative estimate of the total traffic (i.e., a lower bound), and increase the threshold when a large amount of additional traffic is seen. Note that as we increase the threshold, we need to remove all the nodes that should no longer exist under the new threshold. We refer to this as the compression operation.</p><p>The compression algorithm for the 1-d case is illustrated in <ref type="figure" target="#fig_9">Fig- ures 11 and 12</ref>. We maintain a lower bound and an upper bound of the actual sum (SU M ). Whenever the actual sum exceeds the upper bound, we perform the compression operation and then double the upper bound. The compression operation simply walks through the trie in a top down manner and removes the descendents of all the fringe nodes (according to the new threshold). The algorithms are more involved in 2-d case, but the high-level idea is very similar. We omit them for the interest of brevity. We make the following comments:</p><p>• In the worst case, compression can double the space requirement. It also adds some computational overhead. But the number of compression operations only grows logarithmically with the value of SU M . In practice, we can often get a reasonable prediction of the actual sum based on past history. So typically we just need a very small number of compressions.</p><p>• Compression can potentially provide a better accuracy bound.</p><p>In particular, a node can potentially get created sooner than with a larger threshold, so the amount of missed traffic can be lower (but in the worst case, the accuracy guarantee still</p><formula xml:id="formula_11">1 initialization: 2 SU M L = lower bound of actual SU M 3 SU M U = 2 · SU M L 4 T split = 񮽙 · SU M L /W 5 upon each update: 6 if (SU M ≥ SU M U ) 7 SU M L = SU M 8 SU M U = 2 · SU M 9 T split = 񮽙 * SU M L /W 10 COMPUTE TOTAL 1D(root) 11</formula><p>COMPRESS 1D(root, T split ) 12 endif <ref type="figure">Figure 11</ref>: We maintain a lower bound and an upper bound of the actual total traffic volume (SU M ) and perform compression whenever the actual SU M exceeds the upper bound.</p><p>1 // assuming COMPUTE TOTAL 1D has been called 2 void COMPRESS 1D(n,thresh) 3 if ( n.volume + n.subtotal &lt; thresh ) 4</p><p>n.fringe = true 5 n.volume = n.volume + n.subtotal 6 n.subtotal = 0 7 delete all descendents of n 8 else 9</p><p>for <ref type="formula">(</ref> remains the same). We will demonstrate such effects later in Section 6.</p><p>• Compression also makes it possible to aggregate multiple data summaries (possibly for different data sources or created at different times or locations). For example, in the 1-d case, to merge two tries, we just need to insert every node in the second trie into the first trie, update the total sum and detection threshold, and then perform the compression operation (using the new detection threshold). Such aggregation capability can be very useful for applications like detecting distributed denial-of-service attacks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">5-d HHH detection for network anomaly detection</head><p>We can use Rectangle Search and Grid-of-Tries as a building block to solve the general n-dimensional HHH detection problem and always result in a factor of W improvement over the brute-force approach. However, this may still be too slow for many applications.</p><p>Fortunately, for many practical applications, we do not need to deal with general HHH detection in all the fields. This is precisely the case for network anomaly detection, our primary motivating application. In this context, we need to handle 5 fields: (src ip, dst ip, src port, dst port, protocol). For protocol, we would typically require exact match (TCP, UDP, ICMP, others). For source or destination port, we can construct some very fat and shallow tree. For instance, we can use a 3-level tree, with level 0 being * (i.e., don't care), level 1 being the application class (Web, chat, news, P2P, etc.), and level 2 being the actual port number. In addition, we typically only need to match on one of the port numbers (instead of their combination). Finally, we typically only care about port numbers for TCP and UDP protocols. Putting all these together, it often suffices to just consider the following 6 combinations in the context of network anomaly detection. For each combination, we have an array of grid-of-tries. So the update operation involves updating 6 tries. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">APPLICATION TO SCALABLE CHANGE DETECTION</head><p>Change detection is a major component for statistical anomaly detection. The standard techniques for change detection include different smoothing techniques (such as exponential averaging), the BoxJenkins ARIMA modeling <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b0">1]</ref> and wavelet-based <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b3">4]</ref>. In the context of network applications, however, one often needs to deal with tens of millions of network time series and it is infeasible to apply standard techniques on per time series basis. To address the challenge, Krishnamurthy et al. <ref type="bibr" target="#b25">[26]</ref> propose to perform scalable change detection on massive data streams through the use of sketch, a probabilistic data summary technique. Sketch-based change detection works very well when there is only a single fixed aggregation level. But if we want to apply it to find changes at all possible aggregation levels, we have to take a brute-force approach and run one instance of sketch-based change detection for every possible aggregation level, which can be prohibitive.</p><p>In this section, we demonstrate how we can perform scalable change detection for all possible aggregation levels by using our HHH detection algorithms as a pre-filtering mechanism. The basic idea is to extract all the HHH traffic clusters using a small HHH threshold φ in our HHH detection algorithms, reconstruct time series for each individual HHH traffic cluster, and then perform change detection for each reconstructed time series. Intuitively, if a cluster never has much traffic, then it is impossible to experience any significant (absolute) changes. So we expect our approach to capture most big changes so long as the HHH threshold φ is sufficiently small. We show later in Section 6.2 that this is indeed the case.</p><p>A major issue we need to address is how to deal with the reconstruction errors introduced by our summary data structure. The picture is further complicated by the increasing use of sampling in network measurements, which introduces sampling errors to the input stream. Lack of effective mechanisms to accommodate such errors can easily lead to false alarms (i.e., detection of spurious changes). Our change detection method can accommodate both types of errors in a unified framework. It is quite general and can be applied to any linear forecast model, including various smoothing techniques and Box-Jenkins ARIMA modeling.</p><p>Below we present our method in the context of one specific change detection method: Holt-Winters, which has been successfully applied in the past for anomaly detection <ref type="bibr" target="#b7">[8]</ref>. Given a time series {Xi}, the (non-seasonal) Holt-Winters forecast model maintains a separate smoothing baseline component Si and a linear trend component Ti. There are two exponential smoothing parameters α ∈ [0, 1] and</p><formula xml:id="formula_12">β ∈ [0, 1]. Si =  α Xi−1 + (1 − α) (Si−1 + Ti−1) i &gt; 2 X1 i = 2<label>(1)</label></formula><formula xml:id="formula_13">Ti =  β (Si − Si−1) + (1 − β) Ti−1 i &gt; 2 X1 − X0 i = 2<label>(2)</label></formula><p>The forecast is simply Fi = Si + Ti. The forecast error is then Ei = Xi − Fi. Big changes can be detected by looking for data points that significantly deviate from the forecast, i.e., with forecast errors Ei exceeding the (time-varying) detection threshold DTi. For online change detection, it is common to maintain an exponentially weighted moving average of |Ei| and set DTi to be some multiple of this smoothed deviation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Extracting time series</head><p>Given a traffic cluster (with true traffic volume Xi in interval i), our summary data structure produces three different values by using different rules to calculate the amount of missed traffic: a lower bound X L i (using the no-copy rule), an upper bound X U i (using the copy-all rule), and an estimate X S i (using the splitting rule). Our experience with HHH detection suggests that X S i often gives the most accurate estimate (see Section 6.1). Therefore, we use time series {X S i } as the input for the Holt-Winters forecast model to obtain E S i and DT S i , which are estimates for the true forecast errors Ei and detection thresholds DTi, respectively. We also use X L i and X U i to obtain tight bounds on the true forecast errors Ei as shown in Section 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Dealing with missing clusters</head><p>One important issue we need to deal with is the presence of missing clusters. A cluster may not appear in the summary structure for every interval. When this happens, we would still like to estimate its associated traffic volume, otherwise there will be a gap in the reconstructed time series. Fortunately, our summary structure allows us to conveniently obtain such estimates. For example, given a 2-d missing cluster with key &lt; p1, p2 &gt;, conceptually all we need to do is to insert a new element with key &lt; p1, p2 &gt; and value 0 into the summary data structure, which will result in one or more newly created fringe nodes. We can then obtain estimates for the first newly created fringe node and use them as the corresponding estimates for &lt; p1, p2 &gt;. After this, we can then remove all the newly created nodes through compression. Note that in the final implementation, we do not need to actually create the new fringe nodes and then remove them -we just need to do a lookup to find the first insertion position.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Obtaining bounds on forecast errors</head><p>Let the use of superscript L and U on a variable denote the lower and upper bounds for the variable, respectively. For example, X L i denotes the lower bound for Xi. Below we show how to compute E L i and E U i , the bounds for the true forecast errors Ei. A naive solution. At the first glance, it seems rather straightforward to compute E L i and E U i -we can directly apply (1) and (2) to recursively compute bounds for Si, Ti and then use them to form bounds for Fi and Ei. More specifically, we have</p><formula xml:id="formula_14">S U i = α X U i−1 + (1 − α) (S U i−1 + T U i−1 )<label>(3)</label></formula><formula xml:id="formula_15">S L i = α X L i−1 + (1 − α) (S L i−1 + T L i−1 )<label>(4)</label></formula><formula xml:id="formula_16">T U i = β (S U i − S L i−1 ) + (1 − β) T U i−1<label>(5)</label></formula><formula xml:id="formula_17">T L i = β (S L i − S U i−1 ) + (1 − β) T L i−1 (6) F U i = S L i + T L i F L i = S U i + T U i<label>(7)</label></formula><formula xml:id="formula_18">E U i = X U i − F L i E L i = X L i − F U i<label>(8)</label></formula><p>Unfortunately, reconstruction errors can accumulate exponentially with this approach and cause the resulted bounds E L i and E U i to be too loose to be useful. This is evident in <ref type="figure" target="#fig_0">Figure 13(a)</ref>, which shows the forecast error bounds produced by the naive solution when  </p><formula xml:id="formula_19">s[i, j] =  α j = i − 1 (1 − α) (s[i − 1, j] + t[i − 1, j]) j &lt; i − 1 t[i, j] = β (s[i, j] − s[i − 1, j]) + (1 − β) t[i − 1, j]</formula><formula xml:id="formula_20">E U i = X U i − X j: f [i,j]&gt;0 f [i, j] · X L j − X j: f [i,j]&lt;0 f [i, j] · X U j E L i = X L i − X j: f [i,j]&gt;0 f [i, j] · X U j − X j: f [i,j]&lt;0 f [i, j] · X L j</formula><p>As shown in <ref type="figure" target="#fig_0">Figure 13</ref>(b), our solution yields very tight bounds. Note that the above solution requires keeping the entire interval series</p><formula xml:id="formula_21">[X L i , X U i ].</formula><p>Our solution is simply to ignore the remote past. This is reasonable as the use of exponential smoothing means the remote past has very little effect on predicting the future. That is, f [i, j] becomes very small when i − j is sufficiently large. As a result, we only need to keep state for the most recent few intervals for each flow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Testing for significant changes</head><p>Recall that in Section 4.1 we apply time series analysis on X S i to compute E S i and DT S i ; in Section 4.3 we show how to compute the forecast error bounds. To accommodate the reconstruction errors introduced by the summary data structure, our detection criteria combines both DT S i and the forecast error bounds E L i , E U i . More specifically, we report a significant change whenever the two intervals</p><formula xml:id="formula_22">[E L i , E U i ] and [−DT S i , DT S i ] do not overlap, i.e., [E L i , E U i ] ∩ [−DT S i , DT S i ] = ∅.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Dealing with sampling errors</head><p>Network measurements are increasingly subject to sampling. This introduces inherent variability into the traffic metrics under study. This section describes how the effects of sampling variability can be accommodated within our framework.</p><p>The idea is to represent each sampled measurement in the form (key, value, var) where value is an unbiased usage estimate (e.g. of bytes or packets in a flow) arising from sampling, and var is a sampling variance associated with the estimate. In this framework, the values to be estimated are considered as fixed rather than statistical quantities. Conditioned upon these values, the sampling decisions can be assumed independent. Hence when measurements are aggregated, the variance of the aggregate is taken to be the sum of the individual variances.</p><p>The aggregate variance can then be used to attach error bars to time series of a heavy hitters aggregate. We just need to maintain an estimate of the variance. This is easy because the variance can be updated in exactly the same way as the value: whenever n.value = n.value + value we do n.var = n.var + var</p><p>In the end, besides obtaining X L , X U , X S for each cluster, we also have the corresponding estimates for aggregated sampling variance:</p><formula xml:id="formula_23">V L , V U , V S . We can then replace X L and X U with X L * − s " V U " 0.5 and X U * = X U + s " V U " 0.</formula><p>5 , respectively. We can make s sufficiently large so that the probability for any actual value to fall outside the interval [X L * , X U * ] is extremely low (for example, using the 6 sigma rule if we the sampling error is close to Gaussian). We can then use X L * and X U * together with X S in our earlier analysis. Due to space limit, we do not explicitly show how the estimate value and its variance var are calculated when working with sampled flow statistics. Details can be found in <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b14">15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EVALUATION METHODOLOGY</head><p>We evaluate our HHH detection algorithms along a number of dimensions to measure their accuracy and resource (space and time) requirements. We use the following accuracy metrics.</p><p>• False Positive (F P ) measures the number of entities that the algorithm incorrectly identifies as Hierarchical Heavy Hitters.</p><p>• False Negative (F N ) measures the number of Hierarchical Heavy Hitters entities that the algorithm fails to identify as such.</p><p>• Error estimate (ES) for a HHH cluster is measured as the difference between the actual volume and the volume estimated by the algorithm.</p><p>For the accuracy experiments, we compute the F P , F N and ES values as follows: an offline evaluation computes the exact volumes for every multidimensional cluster, and given a value of φ, determines the true set of HHH clusters and their actual volumes. Examining the differences in set membership with the HHH set output by the online HHH detection algorithms yields the F P and F N . For each correctly identified HHH cluster, the difference between the actual and estimated volume yields ES.</p><p>We use the following resource metrics:</p><p>• Space Overhead : measured in terms of the number of entries in the two types of data structures involved: (a) array and (b) hash table.</p><p>• We use the following naming conventions for the different 2-d HHH detection algorithms: Cross Producting (cp), Grid-of-Tries (got), Rectangle Search (rs). cp * , got * , and rs * are the corresponding variants with the lazy expansion optimization enabled. We compare these techniques against the three baseline HHH detection algorithms described in Section 3.1. For the sketch-based technique sk, recall that the accuracy bound depends on both H and K. In the evaluations, we set K = 10// and</p><formula xml:id="formula_24">H = log(SU M · (1 + 32/gran) 2 /δ)/ log(K񮽙),</formula><p>where gran is the granularity we are using (e.g., gran = 8 indicates we only consider prefix lengths 0, 8, 16, 24 and 32), and SU M is the total traffic volume. This ensures that with probability 1 − δ the method gives no false positives (the analysis is similar to the proof of Theorem 6 in <ref type="bibr" target="#b13">[14]</ref>). In our evaluation we set δ = 0.01. We also tested a less expensive solution sk2 that uses H = 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Dataset description</head><p>We use multiple large netflow traces collected from a tier-1 ISP to drive the evaluations of our algorithms (see <ref type="table">Table 1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Evaluation of HHH detection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">Resource Efficiency</head><p>We first compare the amortized runtime costs of different HHH detection algorithms. <ref type="figure">Figure 14</ref> compares the average number of operations for each newly arrived item using different algorithms and granularities on trace ISP-100k. Clearly, all our algorithms significantly outperform the brute-force solutions by orders of magnitude. In addition, for high resolution (i.e., gran = 1), the use of lazy expansion further reduces the runtime costs significantly for both got and rs. This is not surprising, as lazy expansion can significantly reduce the number of nodes to be created, resulting in a much smaller summary structure and thus runtime costs.</p><p>We next evaluate the space requirements. To better illustrate the behavior of these algorithms under different granularities, we normalize the space cost by 1// · (32/gran) 2 , the maximum possible number of flows whose traffic volume exceeds 񮽙SU M .</p><p>The results are summarized in <ref type="figure">Figures 15(a)</ref>-(b). Across both granularities, sk2 has the highest space requirement. Among the proposed algorithms, the pair got and rs have very similar space requirements, as do their counterpart pair got * and rs * that use lazy expansion.</p><p>For high resolution (gran = 1, see <ref type="figure">Figure 15</ref>(a)), got and rs have substantially higher space requirements than the existing lc algorithm. However, the use of lazy expansion in got * and rs * results in substantially smaller space requirements that are comparable to that for lc. For example, the space requirement for rs * is just 14% of that for rs. Cross-Producting has the least overhead, both with and without lazy expansion. For the low resolution scenario (gran = 8, see <ref type="figure">Figure 15</ref>(b)), lazy expansion does not have any noticeable impact on the space usage of the proposed algorithms, and lc has the least space requirement. Note that the values in <ref type="figure">Figures 15(a)</ref>-(b) represent only conservative estimates of the space usage, as they depict only the space required by the hash table or array entries required in each approach, and ignore any auxiliary overhead associated with maintaining those data structures. For instance, rs, rs * and lc use hash tables and thus require additional space to maintain the keys. An array-based approach like got or got * does not have this additional overhead. Hence the actual difference between the space requirement of got * and lc is smaller than shown in <ref type="figure">Figure 15(b)</ref>. A more accurate space comparison should also account for these extra overheads.</p><p>The above plots demonstrate that lazy expansion results in both low space usage and low computation overhead. In the remainder of the evaluations, we shall use the lazy expansion variants (got * , rs * , cp * ) of our proposed algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Accuracy</head><p>A number of factors determine the accuracy of the proposed algorithms -we consider each of them in turn. Note that under the same situation, got and rs always provide identical estimates of the count associated with a cluster, and hence have identical accuracy (F N , F P and ES) measures. In the following accuracy evaluations, we therefore only present results for got * , with the knowledge that the accuracy-related conclusions for got * apply identically to rs * .</p><p>First we consider the impact of the three heuristics copy-all, nocopy, and splitting (introduced in Section 3.2) for estimating the overall traffic corresponding to a cluster. <ref type="figure">Figures 16(a)</ref>-(b) com- Recall that by definition, copy-all has F N = 0, and no-copy has F P = 0 (the corresponding plots are omitted from the figures for better readability). The plots show that across all combinations of HHH detection algorithm and missing traffic estimation heuristic, both the F P and F N values are higher for smaller φ and and decrease for larger φ. F P for copy-all is substantially higher than for the other 2 heuristics, for both got * and cp * , particularly for small φ. Note also that no-copy has the worst F N among the three copy schemes. Given the low F P and F N for splitting, in the remainder of the evaluations, we focus on this heuristic. We next examine the impact of the compression technique (see Section 3.6) on the accuracy. <ref type="figure" target="#fig_4">Figures 17(a)</ref>-(b) respectively plot the F N and F P as a function of φ, for different HHH detection algorithms, when compression is not used. <ref type="figure" target="#fig_5">Figures 18(a)</ref>-(b) present the corresponding plots when compression is used. Note that the Lossy Count based baseline HHH detection algorithm lc can be configured to detect HHHs using either a lower bound estimate (which ensures F P = 0), or an upper bound estimate (which ensures F N = 0) of the actual volume of each HHH; we use lc-noFP and lc-noFN to refer to these two configurations of lc, respectively. The set of plots reveal that compression significantly improves both and FN, for both cp * and got * . The cause of this behavior can be traced to the way compression works. Recall that the compression technique begins with a small initial estimate of the total volume -its expansion threshold is therefore smaller initially. Hence cp * (also got * ) with compression may create a node for a HHH cluster and begin accounting for its traffic at an earlier instant, and therefore miss less counts for the cluster. This contributes to the increased accuracy. A second point to take away from the graphs is that the FP and FN values are low and comparable for the baselines and the proposed schemes, even without compression.</p><p>The detailed evaluations above are all based on the ISP-100K trace. We next use the much larger one month long trace ISP-1mon to measure the accuracy of got * across the one-month period. We present the cummulative distribution of the FP and FN for two different routers in <ref type="figure" target="#fig_17">Figures 19(a)-(b)</ref>. The plots show that the bulk of the FP and FN values are very low, for both routers.   <ref type="table">Table 2</ref>: Normalized Error Estimates (absolute value) for the one month trace ISP-1mon (gran = 1).</p><p>The F P and F N metrics measure an algorithm's ability to correctly identify HHH clusters. We are also interested in the accuracy of the the estimated volumes for the HHH clusters. <ref type="table">Table 2</ref> shows the empirical distribution of the absolute value of ES (defined in Section 5) normalized by 1//, for gran = 1. The values indicate that got with lazy expansion and compression has significantly lower ES than lc-noFN, lc-noFP and sk2. Only the baseline algorithm sk seems to have slightly better ES values that got * . However, the computation cost for sk is significantly higher (recall <ref type="figure">Figure 14)</ref>.</p><p>In summary, the key conclusions from the HHH evaluations are: (i) The techniques lazy expansion, splitting and compression are effective and should be used. (ii) compared to the baseline algorithms, the proposed algorithms got * , cp * , and rs * have orders of magnitude smaller run-time costs, comparable or smaller space requirements, and comparable FN and FP values. Also the algorithm got had substantially lower volume reconstruction error values than the baselines -the only exception being sk, for which got had slightly worse ES. <ref type="figure">Figure 20</ref> summarizes the overlap percentage between top N biggest changes reported by online and offline algorithms. The overlap ratio is always above 97% even for very large N . For N below 100, the top N lists produced by the two algorithms often differ by no more than one element. <ref type="figure" target="#fig_19">Figure 21</ref> illustrates the effects of smart sampling <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b14">15]</ref> on ac-   curacy. With a sampling threshold of 300KB, we are able to reduce the number of flow records to be processed by a factor of 12. Yet the accuracy still consistently remains above 90%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Evaluation on change detection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSIONS</head><p>In this paper, we present several efficient streaming algorithms for detecting multidimensional hierarchical heavy hitters. These algorithms are based on adaptive synopsis data structures that hierarchically organize the traffic into its most active components. The algorithms are much more efficient than existing algorithms, and provide data-independent deterministic accuracy guarantees on traffic estimates for the multidimensional hierarchical heavy hitters. Our motivating application is network anomaly detection, and we use robust techniques to detect changes among such heavy hitters. Our techniques can accommodate variability due to sampling that is increasingly used in network measurement. Evaluation using real Internet traces collected at a Tier-1 ISP suggests that these techniques are remarkably accurate and efficient. Our results are promising and point to the potential of using our algorithms as a building block for network anomaly detection and traffic measurement in large networks. We are developing a prototype anomaly detection system that embodies the algorithms developed in this paper.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 (</head><label>3</label><figDesc>b) shows the trie after the update operation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 : (a) shows the trie at the arrival of a packet of size 5 bytes and prefix 100 * . T split is set to 10. (b) shows the trie af- ter accounting for the packet. The newly created node is repre- sented in grey. In both tries, dotted circles represent the internal nodes, while solid circles represent the fringe nodes.Figure 4 : The total volume associated with an internal node can be reconstructed recursively in a bottom-up fashion.</head><label>31004</label><figDesc>Figure 3: (a) shows the trie at the arrival of a packet of size 5 bytes and prefix 100 * . T split is set to 10. (b) shows the trie after accounting for the packet. The newly created node is represented in grey. In both tries, dotted circles represent the internal nodes, while solid circles represent the fringe nodes. 1 vol type COMPUTE TOTAL 1D(n) 2 if (n.depth 񮽙 = W ) 3 n.subtotal = 0 4 for (each child c of n) 5 if ( c 񮽙 = N U LL ) 6 child total = COMPUTE TOTAL 1D(c) 7 n.subtotal+ = child total 8 endif 9 endfor 10 endif 11 return (n.volume + n.subtotal) Figure 4: The total volume associated with an internal node can be reconstructed recursively in a bottom-up fashion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>5 Figure 5 : The missed traffic can be estimated in a top-down fash- ion (using either the copy-all or the splitting rule)</head><label>55</label><figDesc>Figure 5: The missed traffic can be estimated in a top-down fashion (using either the copy-all or the splitting rule) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 : The update operation for Cross-Producting involves two 1 -dimensional trie updates and one hash table update.</head><label>61</label><figDesc>Figure 6: The update operation for Cross-Producting involves two 1-dimensional trie updates and one hash table update.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 : The grid-of-trie data structure at the time of a packet arrival. One can see a second-level trie is associated (connected by dotted lines in the figure) with each node in the first level trie. The dashed lines represent jump pointers (which are always between nodes with the same source prefix).</head><label>7</label><figDesc>Figure 7: The grid-of-trie data structure at the time of a packet arrival. One can see a second-level trie is associated (connected by dotted lines in the figure) with each node in the first level trie. The dashed lines represent jump pointers (which are always between nodes with the same source prefix).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 : The grid-of-trie data structure after the update oper- ation. The nodes to which we add the size of the current packet are shown in grey. The dashed lines represent jump pointers (which are always between nodes with the same source prefix).</head><label>8</label><figDesc>Figure 8: The grid-of-trie data structure after the update operation. The nodes to which we add the size of the current packet are shown in grey. The dashed lines represent jump pointers (which are always between nodes with the same source prefix).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>More specifically, for each destination prefix length l1 and source prefix length l2, there is an associated hash table H[l1][l2]. Initially, only H[0][0] contains an element &lt; * , * &gt; with volume 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 : The update operation for rectangle search. The fringe nodes are in dark shade, and the internal nodes are in light shade. When a new tuple &lt; k1, k2 &gt; (with value v) arrives, we start from the bottom left corner and move towards the upper right corner. T split is set to 10 .</head><label>910</label><figDesc>Figure 9: The update operation for rectangle search. The fringe nodes are in dark shade, and the internal nodes are in light shade. When a new tuple &lt; k1, k2 &gt; (with value v) arrives, we start from the bottom left corner and move towards the upper right corner. T split is set to 10. So a new element gets created. of elements above the T split is limited. The algorithm starts with (l1, l2) = (0, W ) (the lower left corner in Figure 3.4.2(c)). During each step, the algorithm checks if tuple &lt; p1, p2 &gt; belongs to the hash table H[l1][l2], where pi = pref ix(ki, li). If &lt; p1, p2 &gt; does not exist in H[l1][l2], we simply decrement l2 by 1 (i.e., move upwards in Figure 3.4.2(c)) and continue. Otherwise, we have found an element e. If e is a fringe node and e.volume + v is below T split , we simply add v to e.volume. Otherwise, either e is already an internal node (when updating some other descendents of e) or should become one after this update. In either case, we create a new element with key &lt; p1, pref ix(k2, l2 + 1) &gt; and value v and insert it into H[l1][l2+1]. In case l2 = 0 and e becomes a new internal node, then we also expand the fringe towards the right by creating an element with the key &lt; pref ix(k1, l1 +1), p2 &gt; and inserting it into H[l1 + 1][l2]. We then increment l1 by 1 and continue (i.e., move towards right in Figure 3.4.2(c)). The algorithm terminates whenever either l1 &gt; W or l2 &lt; 0. Since during each step either we either increment l1 by one or decrement l2 by one, the algorithm takes at most 2W −1 steps to terminate. When v is above T split , the algorithm is virtually identical, except that for each l1 we need to insert one element with value 0 into each hash table H[l1][j] (l2 &lt; j &lt; W ) and then one element with value v into hash table H[l1][W ]. In the worst case, this may create (W + 1) 2 new elements. But since the number of elements above T split is small (below SU M/T split ), the amortized cost is quite low. The pseudo code in Figure 10 illustrates the general idea for the update operation when v is below T split . The actual implementation is more detailed due to issues like boundary cases. Just like Grid-of-Tries, Rectangle Search requires O(2W 3 //) space to guarantee an error bound of 񮽙SU M .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 : The update operation for Rectangle Search.</head><label>10</label><figDesc>Figure 10: The update operation for Rectangle Search.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 12 : Compression is done in a top-down manner.</head><label>12</label><figDesc>Figure 12: Compression is done in a top-down manner.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 13 :</head><label>13</label><figDesc>Figure 13: Forecast error bounds when X L i = 0, X U i = 1 (α = 0.5, β = 0.25)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>We can prove by induction that s[i, j] = s[i − 1, j − 1] and t[i, j] = t[i − 1, j − 1] for ∀j &gt; 2 (proof omitted for the inter- est of brevity). So when we increment i, we only need to compute s[i, j] and t[i, j] for j ≤ 2. Once we have s[i, j] and t[i, j], let f [i, j] = s[i, j] + t[i, j]. We then compute the forecast error bounds E L i and E U i as</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 14 : Amortized runtime costs for different algorithms. The total sum is assumed to be given in advance. The cost for sk (not shown) is 5. 5 times more than sk2 due to the use of 11 instead of 2 tables per sketch.</head><label>145</label><figDesc>Figure 14: Amortized runtime costs for different algorithms. The total sum is assumed to be given in advance. The cost for sk (not shown) is 5.5 times more than sk2 due to the use of 11 instead of 2 tables per sketch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 15 : Normalized space costs of different algorithms. (nor- malized space cost = total space cost /cost for sk (not shown) is 5. 5 times more than that forFigure 16 :</head><label>15516</label><figDesc>Figure 15: Normalized space costs of different algorithms. (normalized space cost = total space cost / [1// · (32/gran) 2 ]). The cost for sk (not shown) is 5.5 times more than that for sk2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 17 :</head><label>17</label><figDesc>Figure 17: Accuracy without compression</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 18 :</head><label>18</label><figDesc>Figure 18: Accuracy with compression.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 19 : Cummulative distribution of error ratios over an en- tire month (algo =</head><label>19</label><figDesc>Figure 19: Cummulative distribution of error ratios over an entire month (algo = got * , 񮽙 = 0.001).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 20 : Overlap between top N biggest changes reported by online and offline algorithms for router2 in trace ISP-1day. On- line algorithms uses got* with compression and lazy expansion (񮽙 = 0 .</head><label>200</label><figDesc>Figure 20: Overlap between top N biggest changes reported by online and offline algorithms for router2 in trace ISP-1day. Online algorithms uses got* with compression and lazy expansion (񮽙 = 0.001, φ = 0.001).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 21 : Overlap between top N biggest changes reported by online and offline algorithms for router2 in trace ISP-1day. Smart sampling with threshold between 20KB and 300KB is used (threshold = 300KB reduces the number of records to be processed by a factor of 12).</head><label>21</label><figDesc>Figure 21: Overlap between top N biggest changes reported by online and offline algorithms for router2 in trace ISP-1day. Smart sampling with threshold between 20KB and 300KB is used (threshold = 300KB reduces the number of records to be processed by a factor of 12).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Computation Overhead : measures the runtime overheads of different HHH detection algorithms.in terms of the following three types of operations: (a) lookup/update, i.e., get an entry from an array (via array indexing) or a hash table (via a hash table lookup) and possibly update its value; (b) insertion, i.e., inserting</head><label></label><figDesc></figDesc><table>new entries into an array or a hash table; (c) deletion, 
i.e., deleting entries from an array or a hash table. 

</table></figure>

			<note place="foot" n="1"> void UPDATE RS(k 1 , k 2 , v)</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are grateful to Bill Aiello, Chuck Kalmanek, Muthu Muthukrishnan, Divesh Srivastava, and Mikkel Thorup for thought-provoking discussions. We would also like to thank Florin Baboescu, Flip Korn, George Varghese, and the anonymous reviewers for giving us valuable comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Time series analysis and forecasting techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Arsham</surname></persName>
		</author>
		<ptr target="http://obelia.jde.aca.mmu.ac.uk/resdesgn/arsham/opre330Forecast.htm" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Packet classification for core routers: Is there an alternative to CAMs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Baboescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varghese</surname></persName>
		</author>
		<ptr target="http://citeseer.ist.psu.edu/baboescu03packet.html" />
	</analytic>
	<monogr>
		<title level="m">INFOCOM</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Scalable packet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Baboescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varghese</surname></persName>
		</author>
		<ptr target="http://citeseer.ist.psu.edu/baboescu01packet.html" />
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM</title>
		<meeting>ACM SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A signal analysis of network traffic anomalies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kline</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Plonka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGCOMM Internet Measurement Workshop</title>
		<meeting>the ACM SIGCOMM Internet Measurement Workshop<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Characteristics of network traffic flow anomalies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Plonka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGCOMM Internet Measurement Workshop</title>
		<meeting>the ACM SIGCOMM Internet Measurement Workshop<address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Time Series Analysis, Forecasting and Control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E P</forename><surname>Box</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Jenkins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976" />
			<publisher>Holden-Day</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Time Series Analysis, Forecasting and Control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E P</forename><surname>Box</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">C</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Aberrant behavior detection in time series for network monitoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brutlag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 14th USENIX System Administration Conference (LISA XIV)</title>
		<meeting>of the 14th USENIX System Administration Conference (LISA XIV)<address><addrLine>New Orleans, LA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Forecasting time series with outliers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-M</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="13" to="35" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cisco</surname></persName>
		</author>
		<ptr target="http://www.cisco.com/univercd/cc/td/doc/product/software/ios123/123newft/123t/123t2/nfstatsa.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Finding hierarchical heavy hitters in data streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Korn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Very Large Data Bases</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Diamond in the rough: Finding hierarchical heavy hitters in multi-dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Korn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGMOD</title>
		<meeting>ACM SIGMOD</meeting>
		<imprint>
			<date type="published" when="2004-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">What&apos;s hot and what&apos;s not: Tracking most frequent items dynamically</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM PODC &apos;2003</title>
		<meeting>ACM PODC &apos;2003</meeting>
		<imprint>
			<date type="published" when="2003-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Improved data stream summaries: The count-min sketch and its applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
		<ptr target="http://dimacs.rutgers.edu/∼graham/pubs/cm-full.pdf" />
	</analytic>
	<monogr>
		<title level="m">Journal of Algorithms</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Predicting resource usage and estimation accuracy in an IP flow measurement collection infrastructure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Duffield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCOMM Internet Measurement Workshop</title>
		<meeting><address><addrLine>Miami Beach, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Charging from sampled network usage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Duffield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Thorup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCOMM Internet Measurement Workshop</title>
		<meeting><address><addrLine>San Francisco, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">New directions in traffic measurement and accounting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Estan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varghese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM</title>
		<meeting>ACM SIGCOMM<address><addrLine>Pittsburgh, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automatically inferring patterns of resource consumption in network traffic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Estan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varghese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM</title>
		<meeting>ACM SIGCOMM<address><addrLine>Karlsruhe, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fault detection in an ethernet network using anomaly signature matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Feather</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Siewiorek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Maxion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM</title>
		<meeting>ACM SIGCOMM</meeting>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Tradeoffs for packet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Feldmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
		<ptr target="http://citeseer.ist.psu.edu/feldmann00tradeoffs.html" />
	</analytic>
	<monogr>
		<title level="m">INFOCOM (3)</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="1193" to="1202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Packet classification on multiple fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mckeown</surname></persName>
		</author>
		<ptr target="http://citeseer.ist.psu.edu/gupta99packet.html" />
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM</title>
		<meeting>ACM SIGCOMM</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="147" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Proactive network fault detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE INFOCOM &apos;97</title>
		<meeting>IEEE INFOCOM &apos;97<address><addrLine>Kobe, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Houle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Weaver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Thomas</surname></persName>
		</author>
		<ptr target="http://www.cert.org/archive/pdf/DoStrends.pdf" />
	</analytic>
	<monogr>
		<title level="j">Trends in Denial of Service Attack Technology</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Flash crowds and denial of service attacks: Characterization and implications for CDNs and web sites</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rabinovich</surname></persName>
		</author>
		<ptr target="http://www.research.att.com/∼bala/papers/www02-fc.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the World Wide Web Conference</title>
		<meeting>the World Wide Web Conference<address><addrLine>Honolulu, Hawaii</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Schemes for fault identification in communication networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Katzela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Networking</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="753" to="764" />
			<date type="published" when="1995-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Sketch-based change detection: Methods, evaluation, and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<ptr target="http://www.research.att.com/∼yzhang/papers/nad-imc03.pdf" />
		<title level="m">ACM/USENIX Internet Measurement Conference</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Approximate frequency counts over data streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Manku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Very Large Data Bases</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">The spread of the Sapphire/Slammer worm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Paxson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shannon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Staniford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Weaver</surname></persName>
		</author>
		<ptr target="http://www.cs.berkeley.edu/∼nweaver/sapphire/" />
		<imprint>
			<date type="published" when="2003-02" />
		</imprint>
		<respStmt>
			<orgName>CAIDA</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Data streams: Algorithms and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Muthukrishnan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>Manuscript based on invited talk from 14th SODA</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Packet classification using multidimensional cutting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Baboescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varghese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="http://citeseer.ist.psu.edu/singh03packet.html" />
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM</title>
		<meeting>ACM SIGCOMM</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Packet classification using tuple space search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varghese</surname></persName>
		</author>
		<ptr target="http://citeseer.ist.psu.edu/srinivasan99packet.html" />
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM</title>
		<meeting>ACM SIGCOMM</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="135" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Faster IP lookups using controlled prefix expansion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varghese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Computer Systems</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fast and scalable layer four switching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varghese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Waldvogel</surname></persName>
		</author>
		<ptr target="http://citeseer.ist.psu.edu/srinivasan98fast.html" />
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGCOMM</title>
		<meeting>ACM SIGCOMM</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Outliers, level shifts, and variance changes in time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Tsay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Internet service performance failure detection. Performance Evaluation Review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Glynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Richardson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998-08" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
