<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:35+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Incorporating a User Model to Improve Detection of Unhelpful Robot Answers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2009-12-04">December 4, 2009</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Makatchev</surname></persName>
							<email>mmakatch@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">The Robotics Institute</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reid</forename><surname>Simmons</surname></persName>
							<email>reids@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">The Robotics Institute</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Incorporating a User Model to Improve Detection of Unhelpful Robot Answers</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2009-12-04">December 4, 2009</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Dialogues with robots frequently exhibit social dialogue acts such as greeting , thanks, and goodbye. This opens the opportunity of using these dialogue acts for dialogue management, in particular for detecting misunderstandings. Our corpus analysis shows that the social dialogue acts have different scopes of their associations with the discourse features within the dialogue: greeting in the user&apos;s first turn is associated with such distant, or global, features as the likelihood of having questions answered, persistence, and ending with bye. The user&apos;s thanks turn, on the other hand, is strongly associated with the helpful-ness of the preceding robot&apos;s answer. We therefore interpret the greeting as a component of a user model that can provide information about the user&apos;s traits and be associated with discourse features at various stages of the dialogue. We conduct a detailed analysis of the user&apos;s thanking behavior and demonstrate that user&apos;s thanks can be used in the detection of unhelpful robot&apos;s answers. Incorporating the greeting information further improves the detection. We discuss possible applications of this work for human-robot dialogue management.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Adapting to the model of a user's knowledge and/or emotional state (in short, a user model) has been shown to improve performance of dialogue systems on such metrics as time to task completion (e.g. <ref type="bibr" target="#b26">[27]</ref>), learning gains <ref type="bibr" target="#b5">[6]</ref>, and learning efficiency and user's perception of the quality of the dialogue <ref type="bibr" target="#b4">[5]</ref>. Deciding on the best action to be taken given a particular user and dialogue state can be done offline by analyzing a corpus of dialogues, but for online interaction, recognizing the state of the current user has to be performed on-the-fly from the ongoing interaction. For example the Roboceptionist <ref type="bibr" target="#b6">[7]</ref>, shown in <ref type="figure" target="#fig_0">Figure 1</ref>, is installed at a high-traffic entrance of a university building, and does not track users from session to session. Therefore, the user model has to be constructed from the first turns of the dialogue, so that the dialogue manager can take advantage of the model in adapting to the user while the interactive session is still in progress.</p><p>Our particular setting is additionally complicated by the fact that user input is typed, not spoken, thus excluding the possibilities of using prosody and other features of the user's speech. In other human-robot interaction scenarios, Fischer and Bateman <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> found significant dependencies between the presence of greetings in the user's first utterance and both prosodic and conversational "peculiarities" of the dialogues. Examples of such conversational peculiarities include reformulations, clarification questions and user's initiative. Similarly to their study, we analyze transcripts of human-robot dialogues with the goal of finding dependencies between the first turn of the dialogue and dialogue patterns that potentially indicate a user's interaction style. The patterns of our interest however differ from those in <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> and are inspired by such user traits as the willingness to carry on after the robot demonstrates lack of understanding (Persistence), as well as the user's adherence to social obligations, such as thanking the robot after the robot gives an answer to the user's question (AnswerThanked) and ending an interaction with a goodbye (EndingWithBye). We present results of the analysis of an annotated corpus of dialogues that demonstrates two significant associations. First, EndingWithBye and QuestionAnswered patterns are significantly associated with whether the dialogue was initiated by the human or by the robot. Second, the patterns of Persistence, EndingWithBye, QuestionAnswered and AnswerThanked are significantly associated with whether the user greeted the robot in the user's first turn. In particular, the considerable spans (in number of turns) observed between the Greeting and the patterns such as AnswerThanked and EndingWithBye motivate us to consider whether these associations are components of a user model that persists through the interaction.</p><p>As an application of the found associations, we focus on the problem of recognizing a specific type of the dialogue error, namely, the situation when the robot's answer is unhelpful to the user. We deem the robot's answer unhelpful if either the robot admits the failure to make sense of the question (non-understanding) or to find the right piece of information, or the answer provided is irrelevant due to a misunderstanding at the intention and conversation levels <ref type="bibr" target="#b16">[17]</ref>, as in the example shown in <ref type="figure">Figure 2</ref>. Recognizing the unhelpfulness due misunderstanding is harder, because the degree of relevance of the answer is ultimately up to the user's interpretation. As Skantze and Edlund <ref type="bibr" target="#b23">[24]</ref> point out, the general problem of error detection in dialogue could be divided into three subcases: early error detection, late error detection and error prediction. Early error detection does not use any input beyond the user's utterance that causes misunderstanding or non-understanding. Late error detection allows taking into account dialogue turns that follow the trouble-causing user's utterance. Error prediction is concerned with predicting errors that occur at the later stages of the dialogue. In this paper we are concerned with late error detection and error prediction.</p><p>Existing work on late detection of misunderstandings caused by automated speech recognition errors (e.g. <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b13">14]</ref>) has shown considerable accuracy using local dialogue context and prosodic features. Intuitively, detecting unhelpfulness of an answer due to a misunderstanding, in situations similar to the one shown in <ref type="figure">Figure 2</ref>, should benefit from incorporating cues from the user turns that follow the robot's answer. Indeed, in the telephone-based train information and room reservation domains, cues such as user corrections <ref type="bibr" target="#b25">[26]</ref> and lexical-level features of the following user turn <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref> demonstrate good performance in detecting misunderstandings.</p><p>In the area of intelligent tutoring systems, the problematic segments of educational dialogues are, for example, those that exhibit disagreement between participants of collaborative learning environments and those within which the student demonstrates a non-understanding of a concept. In these applications, dialogue act sequences and user's state estimated from the prosody were good predictors of poor collaboration (e. g. <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b7">8]</ref>).</p><p>The human-robot dialogues that we analyze regularly exhibit social dialogue acts, such as Greetings, Thanks, and Goodbye. We hypothesize that the social dialogue acts can be used as positive and negative cues and demonstrate that the user's Thanks is a significant predictor of the helpfulness of the robot's preceding answer. Unhelpful answer detection can be further improved by leveraging the difference in the thanking behavior between users that greeted the robot and users that did not. Similar differences in conversational features with respect to to the presence of a greeting in the user's first turn were reported by Fischer <ref type="bibr" target="#b2">[3]</ref>. The improvement achieved by incorporating the feature of a distant (in this case the initial) dialogue act is not surprising, since using features outside of the immediate vicinity of the spot of interest within a dialogue has been shown to improve detection of end-of-turn <ref type="bibr" target="#b19">[20]</ref>, dialogue act classification <ref type="bibr" target="#b18">[19]</ref>, early error detection <ref type="bibr" target="#b23">[24]</ref> and rewards obtained by state-based models of dialogue <ref type="bibr" target="#b17">[18]</ref>. Interestingly, while global contextual information helps, <ref type="bibr" target="#b20">[21]</ref> and <ref type="bibr" target="#b17">[18]</ref> demonstrated that just widening local context window does not lead to an improved performance on speech act recognition or learned dialogue policies respectively. Our results support the findings of the importance of global context in dialogues by demonstrating its relevance in our corpus of human-robot dialogues for the particular task of unhelpful answer detection.</p><p>Misunderstood questions can also be thought of in terms of grounding <ref type="bibr" target="#b1">[2]</ref>, defined as the process of adding material to the common ground between speakers. A misunderstood question in these terms is a type of error in adding material to the common ground between the user and the robot. Recognizing and recovering from a misunderstanding can therefore be viewed as a type of common ground maintenance. Managing the dialogue to achieve and maintain the desired degree of groundedness has been demonstrated to improve human perceptions of dialogues <ref type="bibr" target="#b21">[22]</ref>. The system described in <ref type="bibr" target="#b21">[22]</ref> predicts the degree of groundedness of a material by treating relevant dialogue acts as evidence of understanding, e.g. acts that acknowledge understanding, acts that refer to the material, or acts that rely on the understanding of the material. Our work is similar to the approach of <ref type="bibr" target="#b21">[22]</ref> in that we use the following user's turn (namely the presence of Thanks) as a feature in our predictor of the answer helpfulness (which implies question understanding). Unlike <ref type="bibr" target="#b21">[22]</ref>, however, we also utilize the distant discourse information of the presence of Greeting in the user's first turn. In summary, we are modeling how well the answer was grounded, how well the question was understood, and how well the answer will be grounded (based on the presence of a Greeting). In this respect, the work on detecting unhelpful answers can be viewed as modeling actual and anticipated grounding behavior in human-robot dialogues.</p><p>The paper is organized as follows. Section 2 introduces the corpus of human-robot dialogues. Section 3 presents the results of the analysis of associations between the initiator of the interaction and discourse and between the presence of Greeting in the user's first turn and discourse. We analyze user's thanking behavior in Section 4. In Section 5 we evaluate the performance of the user's Greeting and user's Thanks as predictors of the answer unhelpfulness. The paper concludes with a discussion of the results and an outline of the future work on improving the user model and the ways it may be used in dialogue management.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">HUMAN-ROBOT DIALOGUE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Roboceptionist</head><p>The Roboceptionist is a robot stationed in a kiosk at a high-traffic entrance of a Carnegie Mellon University building ( <ref type="figure" target="#fig_0">Figure 1</ref>). The robot's face is rendered on a flatscreen display that is mounted on a neck joint enabling it to pan to follow the passers- by who are detected by the laser range scanner. Greeting of a passer-by is triggered by a user entering an area that is close to the robot with a minimal forward velocity. Regardless of whether the Roboceptionist has initiated the interaction by greeting the user, the user can start interacting with the robot by typing on the keyboard mounted in front of the robot. The Roboceptionist will respond by producing a synthesized voice reply as well as text that appears on the screen, next to its face. The first version of the Roboceptionist was introduced in 2003, and after an initial peak, it currently averages 30-40 interactions per day.</p><p>The robot has been provided with a back story covering its past career and personal life, developed by students in the Drama department. Occasionally, the robot refers to these story lines, which makes them a recurring topic of dialogues. The other topics that the robot is designed to handle, and that make a large fraction of the dialogues, include the weather and directions to rooms, buildings and people <ref type="bibr" target="#b12">[13]</ref>. With the exception of followup questions, like the one in the second line of the dialogue in <ref type="figure">Figure 2</ref>, the robot's dialogue manager is reactive, namely it keeps track of only the last user turn. In particular, the robot does not remember whether it exchanged greetings with the current user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Human-robot dialogue corpus</head><p>The corpus of human-robot dialogues that we analyze represents transcripts of uncontrolled interactions that are collected on a near-daily basis. To generate the dataset, the transcripts are first automatically segmented into individual dialogues, and dialogues with more than 20 turns 1 are discarded to eliminate outliers and some of the errors of the segmentation procedure. We annotated the dialogue using a multidimensional annotation in the spirit of DIT++ <ref type="bibr" target="#b0">[1]</ref>, tailoring it to our domain as necessary. Specifically, we manually labeled 1960 turns of 287 dialogues that oc-curred over 8 days in March of 2008 with respect to such dialogue acts as Greeting, Thanks, Goodbye, UserQuestion, Answer, InterpNegFeedback (robot's admitting its failure to make sense of the preceding user's turn), and Rude language. Discourse patterns of interest to us, such as QuestionAnswered, Persistence, AnswerThanked are expressed in terms of these dialogue acts.</p><p>We used this manually labeled corpus of dialogues to train decision tree classifiers for each of the dialogue acts. The examples of the decision tree classifiers for user's Greeting and user's Question are shown in <ref type="figure" target="#fig_3">Figure 3</ref>. Using unstemmed words as the features, these classifiers each achieve the accuracy of at least 0.89 and F1-scores of at least 0.88 (10-fold cross-validation is used to select the size of the trees). The high quality of the automated labeling justifies expanding the analysis to a larger corpus of dialogues. The results presented below correspond to the automatically labeled corpus of 1676 dialogues (11,024 dialogue turns) that occurred during the months of March and April of 2008.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RELATING DISCOURSE FEATURES TO THE</head><p>INITIATOR AND THE GREETING</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data analysis</head><p>In the following data analysis, we estimate the relation between two (not mutually exclusive) ways to begin a dialogue and the discourse: (1) whether the dialogue has been initiated by the robot and (2) whether the user has started the dialogue with a Greeting (e.g. "Hi", "Good morning"). We define a dialogue as initiated by the robot if the user started typing within 10 seconds from the time the robot has greeted a passer-by.</p><p>The features of dialogues that we compare include start time, dialogue duration in seconds, dialogue duration in number of turns, total number of user's words, average number of user's words per user's turn, user's Goodbye as their last turn (EndingWithBye), robot's admitting its failure to make sense of the preceding user's turn (InterpNegFeedback), user's rude language (Rude), user's Persistence-robot's InterpNegFeedback followed by a non-empty user's turn that is not a Goodbye, UserQuestion, user's QuestionAnswered (i.e. question was parsed correctly and received a reasonable answer 2 ), and user thanking the robot after the question has been reasonably answered (AnswerThanked). Under user greeting/no-greeting conditions we also compare the total number of user's words and average number of user's words per user's turn for the "inner" dialogue turns that exclude the two user turns trivially affected by the presence of a Greeting: an initial Greeting and trailing Goodbye.</p><p>The results are shown in <ref type="table">Tables 1 and 2</ref>. Where the units are not specified, the number represents the fraction of all the relevant dialogues where the respective dialogue pattern is present. For example, the fraction of dialogues containing the  QuestionAnswered pattern is counted only among the dialogues that include user's questions, and the fraction of dialogues containing the AnswerThanked pattern is counted only among the dialogues that include user's questions that were reasonably answered by the robot. Differences of the means of variables that represent numerical counts or times are tested for significance by a two-sample t-test. The 2-by-2 contingency tables that show counts of dialogues containing respective discourse patterns among all the relevant dialogues that (a) were initiated by the robot/user, or (b) do/do not include greeting in the user's first turn, are tested for independence using <ref type="bibr">Pearson</ref>  <ref type="table">Table 1</ref>: Associations between the initiator of the dialogue and the discourse, using dialogue turns labeled by a classifier. Values marked with * and * * correspond to significant results at 0.05 and 0.01 levels respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Discussion</head><p>While the initiator of the dialogue does not show as much effect on the discourse as whether the user started with a Greeting, robot-initiated dialogues show a slight increase in the fraction of dialogues with QuestionAnswered, user's Greeting, and a negative effect on EndingWithBye. Further analysis is necessary to explain these differences.</p><p>The effect of the user's Greeting on the length of the dialogue in terms of the number of turns can be explained by the additional pair of greeting turns. It appears that presence of a Greeting does not change the overall verbosity of the dialogue when the Greeting and Goodbye turns are excluded. However, the average length (words per turn) of the inner turns is slightly larger for the interactions that start with a  <ref type="table">Table 2</ref>: Associations between a Greeting in the user's first turn and the discourse, using dialogue turns labeled by a classifier. Values marked with * and * * correspond to significant results at 0.05 and 0.01 levels respectively.</p><p>Greeting. Users starting with a Greeting tend to exhibit more Persistence and are more than 2.6 times are as likely to thank the robot after it answers their question (AnswerThanked). They also have a better chance of having their questions parsed. The fact that users that start with a Greeting have fewer chances of being not understood by the robot (InterpNegFeedback) is not explained by the presence of trivial "hi-hi-bye-bye" interactions, since the difference remains significant for interactions containing more than 4 turns (not shown in the <ref type="table">Table)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ANALYSIS OF USER'S THANKING BEHAV-IOR</head><p>The analysis presented in Section 3 uncovered the tendency of users who greet the robot to also say thanks after having their questions answered. In this section, we explore the user's thanking behavior in more detail. The annotation scheme we have used so far does not differentiate between the types of the questions and is loose in defining what it means to have the question reasonably answered. For example, in our particular context, the question "How old are you?" does not warrant "thanks" even after a helpful answer. On the other hand, an answer to another information seeking question, "Where is Wean Hall?" can be followed by "Thanks." We hypothesize a relationship between the relevance, or helpfulness, of the robot's answer and the presence of thanks in the following user's turn. For example, if the robot misinterpreted the question and gave directions to a location that is different from the one intended by the user, the answer, while reasonable, is certainly not helpful (as in the example in <ref type="figure">Figure 2)</ref>. In this section, we use a finer grained manual annotation of the user's questions and robot's answers to uncover the relationship between the presence of user's greeting, helpfulness of the robot's answer, and whether the user thanked the robot. In particular, we describe and evaluate a classifier of Unhelpful robot's answers that uses the presence of Thanks in the user's following turn and the presence of Greeting in the user's first turn as its features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Manually labeled corpus of thanking behavior</head><p>We use a finer grained annotation for the analysis of thanking behavior that consists of labeling user's turns as Thankable and Non-thankable questions and robot's responses as Helpful and Unhelpful answers. We extended our manual annotation of the 8-day corpus of 287 dialogues with these additional labels, considering partial answers as unhelpful and excluding the combinations of an answer and a followup question, e.g. "The Robotics Education Lab is in NSH 3206. Would you like directions?", where the thanking behavior is complicated by the interference with an answer to the question "Would you like directions?".</p><p>Notice, that the label Thankable question is defined by semantics and pragmatics, rather than by syntactic features, so it is possible that an utterance is a Thankable question, but not a UserQuestion according to the previous, more syntactically-biased labeling scheme, as in "I meant another Frank." <ref type="figure">(Figure 2</ref>). The contingency table of UserQuestions and Thankable questions among all user utterances is presented in <ref type="table">Table 3</ref>.</p><p>Thankable question ¬Thankable question UserQuestion 148 223 ¬UserQuestion 58 549 <ref type="table">Table 3</ref>: Distribution of UserQuestions and Thankable questions among all user turns.</p><p>The split of the Thankable questions between users with and without Greeting in their first turn is 92 to 114 (no significant departure from the independence hypothesis according to Pearson's Chi-squared test). 16 of these Thankable questions are followed by a combination of an answer and a followup question and are removed from further analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Data analysis</head><p>We restrict our following analysis to the 190 sequences of dialogue turns that contain a Thankable question, e.g. &lt;Thankable question, Unhelpful answer, Thanks&gt;. A single dialogue can contain multiple sequences. <ref type="figure">Figures 4 and 5</ref> show the mosaic plots of the counts of discourse patterns starting with the user's Thankable question, followed by the robot's Helpful, or Unhelpful, answer that were or were not, followed by the user's Thanks for three sets of dialogues: (a) dialogues where users greeted the robot on their first turn, (b) dialogues where users did not greet the robot on their first turn, and (c) all dialogues.</p><p>Color shading indicates cells responsible for the Pearson residuals that exceed (in absolute value) critical values corresponding to 0.1 and 0.01 levels. The departure from independence between user's Thanks and the helpfulness of the answer is significant (p &lt; 0.01), both conditionally on the user's Greeting and for all users pooled together. Conditionally on Greeting, the violation of the independence hypothesis is most prominent among the users who greeted the robot (p &lt; 0.1 for all cells), especially when the users also Thanked the robot (p &lt; 0.01). While users that did not greet also tend to thank less, both users that greeted and users that did not appear to thank a considerable fraction of unhelpful answers, in a sense of "Thanks anyways."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Detecting unhelpful answers</head><p>We use two binary features (Greeting in the first turn and Thanks in the turn following a robot's answer) to predict a binary variable (Unhelpful answer), hence we can represent all possible deterministic classifiers by 16 decision trees. Two of the classifiers are trivial and always output Helpful or Unhelpful. We compare the performances of the set of two non-trivial classifiers that use Thanks as their only feature with the set of all 16 classifiers (12 of which use both features non-trivially) that use both features by comparing their ROC curves, namely the graphs of their respective true positive rates tpr = tp/(tp + f n) versus false positive rates f pr = f p/(f p + tn), where tp corresponds to the answers correctly detected Unhelpful, f p to the answers incorrectly detected as Unhelpful, tn to the answers correctly detected as Helpful, and f n to the answers incorrectly detected as Helpful. One of the properties of ROC space is that one could always combine a number of classifiers by random sampling in a way that the ROC points of their combinations would trace a convex hull of the ROC points/curves of the individual classifiers <ref type="bibr" target="#b14">[15]</ref>. Therefore, to compare two sets of classifiers we have to consider only the classifiers that are on the convex hull of each of the sets. Since we can always add the two trivial constant classifiers to any classifier set, the convex hulls will always contain points (0, 0) and (1, 1). For example, the ROC curve corresponding to random combinations between these two trivial classifiers (i.e. with probability p ask classifier (0, 0) that outputs Helpful, otherwise ask classifier (1, 1) that outputs Unhelpful) is the dotted diagonal in <ref type="figure" target="#fig_7">Figure 7</ref>.</p><p>The dashed line in <ref type="figure" target="#fig_7">Figure 7</ref> corresponds to the convex hull of the set of two classifiers that use Thanks as their only feature. From this set, only the classifier A: Thanked → Helpful, else Unhelpful is on the hull. The solid line corresponds to the convex hull of all 16 classifiers. The two classifiers that are on the latter convex hull are A, and the classifier that extends the condition in A to also predict Helpful for all users that greeted: B: Thanked ∨ Greeted → Helpful, else Unhelpful.</p><p>For comparison we also plot the performance of classifiers C that randomly samples between A and the trivial "always output Helpful" classifier with a probability p such that its f pr is approximately equal to f pr of B, and D and E that use no features and approximately match B's f pr and tpr respectively.</p><p>The bars shown in <ref type="figure" target="#fig_7">Figure 7</ref> correspond to the 90% empirical confidence intervals that are constructed by applying the bootstrap to generate 1000 samples from the original sample of 190 dialogue turn sequences (see <ref type="bibr" target="#b14">[15]</ref> for details on using the bootstrap for ROC curve analysis). The accuracy and F1-scores shown in the figure are indicative of a class skew. Indeed, the slope of iso-accuracy lines is</p><formula xml:id="formula_0">f n + tn tp + f p = #Helpful #Unhelpful = 76 114 ≈ 0.67.</formula><p>While neither the difference in tpr between the two-feature classifier B and the single-feature classifier C nor the difference in tpr between C and the random classifier D is significant at 0.1 level, the improvements in tpr between B and D, and in f pr between B and E are both significant at 0.05 level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>The analysis of the unconstrained human-robot dialogues that we presented has shown that the user's social dialogue acts, such as greeting and thanks are significantly associated with the certain types of system's errors and that greeting is associated with discourse patterns at various stages of the dialogue. In particular, the user's greeting in the first dialogue turn is associated with remote and global discourse features such as ending the dialogue with goodbye, persistence, and the likelihood of receiving an answer. User's thanks, while also associated with the greeting, is a considerable predictor of (un)helpful answers, especially when combined with the greeting. Fischer and Bateman <ref type="bibr" target="#b3">[4]</ref> explain similar associations in their human-robot dialogues using the principle of recipient design <ref type="bibr" target="#b22">[23]</ref> and in particular Fischer <ref type="bibr" target="#b2">[3]</ref> shows that both dialogue openings and discourse patterns are associated with the user's preconceptions about robots. This explanation and the seemingly global scope of associations involving the greeting in the user's first turn motivated us to treat this feature as a component of a user model. Future work includes improving unhelpful answer detection by using additional lexical-level features of the following user turn <ref type="bibr" target="#b10">[11]</ref>, and by expanding the user model to include other features of the early dialogue turns.</p><p>Our larger goal, however, is to use the unhelpful answer detection and the user model to help interpret user's utterances and guide the dialogue. For example, long range associations between dialogue acts provide additional cues to the structure of the discourse that may improve discourse parsing <ref type="bibr" target="#b18">[19]</ref> and semantic interpretation that takes into account discourse context. The user model could help guide the dialogue by providing additional encouragement to an anticipated non-persistent user. Finally, detecting and adapting to its own unhelpfulness may give the robot a degree of metacognition that could improve the interaction experience.    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Roboceptionist interacting with a user.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>U</head><label></label><figDesc>Figure 2: A verbatim fragment of an actual dialogue, with the person's last name and room modified for privacy, parts of robot utterances truncated for brevity, and the labels "U:" and "R:" added to denote the user and robot turns.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(b) Decision tree classifier of the user's Question dialogue act.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Classification trees for user's Greeting and Question dialogue acts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>(</head><label></label><figDesc>b) Users who did not greet the robot.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Figure 4: Thanking after a helpful answer within (a) users who greeted and (b) users who did not greet the robot. The shading is based on the maximum absolute values of Pearson residuals statistic. Cells shaded in light and in fully saturated colors correspond to residuals that exceed critical values of the permutation test for independence (conditional on Greeting) at 0.1 and 0.01 levels respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: True positive and false positive rates (ROC curves) for the classifiers of Unhelpful answers relying on the user's Thanks as the only feature (dashed line). The detailed explanation is in the text.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: True positive and false positive rates (ROC curves) for the classifiers of Unhelpful answers relying on the user's Thanks as the only feature (dashed line) and incorporating both the user's Thanks and Greetings as features (solid line). The detailed explanation is in the text.</figDesc></figure>

			<note place="foot" n="1"> Here, and in the remainder of the paper, we count separately each user and robot turn.</note>

			<note place="foot" n="2"> We are loose in our interpretation of what constitutes a reasonable answer. We consider an answer to any plausible interpretation of the question as reasonable. For example, the robot&apos;s answer in the second line of Figure 2 is reasonable, albeit unhelpful.</note>

			<note place="foot" n="3"> An abridged version of this corpus analysis has been presented as a short paper at HRI&apos;09 [16].</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Dimensions in dialogue act annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bunt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC)</title>
		<meeting>the Fifth International Conference on Language Resources and Evaluation (LREC)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Contributing to discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">F</forename><surname>Schaefer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="259" to="294" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The role of users&apos; preconceptions in talking to computers and robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Workshop on &apos;How People Talk to Computers, Robots, and Other Artificial Communication Partners</title>
		<editor>K. Fischer</editor>
		<meeting>of the Workshop on &apos;How People Talk to Computers, Robots, and Other Artificial Communication Partners<address><addrLine>Hansewissenschaftskolleg, Delmenhorst</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-04" />
			<biblScope unit="page" from="112" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Keeping the initiative: an empirically motivated approach to predicting user-initiated dialogue contributions in hci</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Bateman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EACL</title>
		<meeting>of EACL</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adapting to student uncertainty improves tutoring dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Forbes-Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Litman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 14th Int. Conf. on Artificial Intelligence in Education (AIED)</title>
		<meeting>14th Int. Conf. on Artificial Intelligence in Education (AIED)<address><addrLine>Brighton, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Designing and evaluating an uncertaintyadaptive spoken dialogue tutoring systems. (under review)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Forbes-Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Litman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Designing robots for long-term social interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gockley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Forlizzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Michalowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sellner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Snipes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. on Intelligent Robots and Systems</title>
		<meeting>Int. Conf. on Intelligent Robots and Systems</meeting>
		<imprint>
			<date type="published" when="2005-08" />
			<biblScope unit="page" from="2199" to="2204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Applying user models to improve team decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Drury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Gaimari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kurland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zarrella</surname></persName>
		</author>
		<idno>MTR 060150</idno>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
<note type="report_type">MITRE Technical Report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Using dialogue features to predict trouble during collaborative learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">N</forename><surname>Linton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Gaimari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hitzeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zarrella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">User Modeling and User-Adapted Interaction</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="85" to="134" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">New feature parameters for detecting misunderstandings in a spoken dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hirasawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Miyazaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Aikawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int Conf. of Spoken Language Processing</title>
		<meeting>Int Conf. of Spoken Language essing<address><addrLine>Bejing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="154" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Problem spotting in human-machine interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Krahmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Swerts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Theune</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weegels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eurospeech</title>
		<meeting>Eurospeech</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1423" to="1426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Error detection in spoken human machine interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Krahmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Swerts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Theune</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weegels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. of Speech Technology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="29" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">How do people talk with a robot? An analysis of human-robot dialogues in the real world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Makatchev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CHI</title>
		<meeting>CHI</meeting>
		<imprint>
			<date type="published" when="2009-04" />
			<biblScope unit="page" from="3769" to="3774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Predicting automatic speech recognition performance using prosodic cues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Hirschberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Swerts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="218" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Confidence bands for ROC curves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Macskassy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Provost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<idno>IS-03-04</idno>
	</analytic>
	<monogr>
		<title level="m">CeDER Working Paper</title>
		<meeting><address><addrLine>NY</addrLine></address></meeting>
		<imprint>
			<publisher>Stern School of Business</publisher>
			<date type="published" when="2004" />
		</imprint>
		<respStmt>
			<orgName>New York University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Relating initial turns of humanrobot dialogues to discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Makatchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Simmons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Human-Robot Interaction (HRI)</title>
		<meeting>the International Conference on Human-Robot Interaction (HRI)</meeting>
		<imprint>
			<date type="published" when="2009-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Toward a taxonomy of communication errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Paek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ISCA Tutorial and Research Workshop on Error Handling in Spoken Dialogue Systems</title>
		<meeting>ISCA Tutorial and Research Workshop on Error Handling in Spoken Dialogue Systems</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="53" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Evaluating the markov assumption in markov decision processes for spoken dialogue management export</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Paek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chickering</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="66" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The predictive power of game structure in dialogue act recognition: Experimental results using maximum entropy estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Poesio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mikheev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICSLP</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Optimizing endpointing thresholds using dialogue features in a spoken dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eskenazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGdial</title>
		<meeting><address><addrLine>Columbus, OH</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dialogue act classication using language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Reithinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Klesen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Eurospeech</title>
		<meeting>of Eurospeech<address><addrLine>Rhodes</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="2235" to="2238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Improving a virtual human using a model of degrees of grounding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Traum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A simplest systematics for the organisation of turn-taking for conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sacks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schegloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jefferson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="696" to="735" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Early error detection on word level</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Skantze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Edlund</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ITRW on Robustness Issues in Conversational Interaction</title>
		<meeting>of ITRW on Robustness Issues in Conversational Interaction</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Modeling the process of collaborative learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Soller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lesgold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Workshop on New Technologies in Collaborative Learning</title>
		<meeting><address><addrLine>Awaji-Yumebutai, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Corrections in spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Swerts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hirschberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICSLP-2000</title>
		<meeting>ICSLP-2000</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="615" to="618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A personalized system for conversational recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Goker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Langley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="393" to="428" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
