<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T17:05+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Understanding Sources of Inefficiency in General-Purpose Chips</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>June 19-23, 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rehan</forename><surname>Hameed</surname></persName>
							<email>rhameed@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engineering</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wajahat</forename><surname>Qadeer</surname></persName>
							<email>wqadeer@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engineering</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Megan</forename><surname>Wachs</surname></persName>
							<email>wachs@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engineering</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omid</forename><surname>Azizi</surname></persName>
							<email>oazizi@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engineering</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Solomatnikov</surname></persName>
							<email>solomatnikov@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Hicamp Systems</orgName>
								<address>
									<settlement>Menlo Park</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
							<email>bcclee@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engineering</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Richardson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engineering</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Kozyrakis</surname></persName>
							<email>kozyraki@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engineering</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Horowitz</surname></persName>
							<email>horowitz@stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engineering</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Understanding Sources of Inefficiency in General-Purpose Chips</title>
					</analytic>
					<monogr>
						<title level="m">ISCA&apos;10</title>
						<meeting> <address><addrLine>Saint-Malo, France</addrLine></address>
						</meeting>
						<imprint>
							<date type="published">June 19-23, 2010</date>
						</imprint>
					</monogr>
					<note>Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. 978-1-4503-0053-7/10/06...$10.00.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>C54 [Computer Systems Implementation]: VLSI Systems - customization</term>
					<term>heterogeneous CMP; C13 [Processor Architectures]: Other Architecture Styles -Heterogeneous (Hybrid) Systems General Terms Algorithms</term>
					<term>Measurement</term>
					<term>Performance</term>
					<term>Design</term>
					<term>Experimentation Keywords ASIC</term>
					<term>H264</term>
					<term>chip multiprocessor</term>
					<term>high-performance</term>
					<term>energy efficiency</term>
					<term>customization</term>
					<term>Tensilica</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Due to their high volume, general-purpose processors, and now chip multiprocessors (CMPs), are much more cost effective than ASICs, but lag significantly in terms of performance and energy efficiency. This paper explores the sources of these performance and energy overheads in general-purpose processing systems by quantifying the overheads of a 720p HD H.264 encoder running on a general-purpose CMP system. It then explores methods to eliminate these overheads by transforming the CPU into a specialized system for H.264 encoding. We evaluate the gains from customizations useful to broad classes of algorithms, such as SIMD units, as well as those specific to particular computation, such as customized storage and functional units. The ASIC is 500x more energy efficient than our original four-processor CMP. Broadly, applicable optimizations improve performance by 10x and energy by 7x. However, the very low energy costs of actual core ops (100s fJ in 90nm) mean that over 90% of the energy used in these solutions is still &quot;overhead&quot;. Achieving ASIC-like performance and efficiency requires algorithm-specific optimizations. For each sub-algorithm of H.264, we create a large, specialized functional unit that is capable of executing 100s of operations per instruction. This improves performance and energy by an additional 25x and the final customized CMP matches an ASIC solution&apos;s performance within 3x of its energy and within comparable area.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Most computing systems today are power limited, whether it is the 1W limit of a cell phone, or the 100W limit of a server. Since technology scaling no longer provides the energy savings, it once did <ref type="bibr" target="#b0">[1]</ref>, designers must turn to other techniques for continued performance improvements and tractable energy costs. One attractive option is to understand and to incorporate sources of ASIC efficiency, since general-purpose processors can be outclassed by three orders of magnitude in both performance and energy efficiency by ASIC designs <ref type="bibr" target="#b5">[5]</ref>.</p><p>The desire to achieve ASIC-like compute efficiencies with microprocessor-like application development cost is pushing designers to explore two new areas. One area aims to create CPU designs with much lower energy per instruction <ref type="bibr" target="#b6">[6]</ref>, while the other aims to create new design methodologies to reduce the cost of creating customized hardware. Examples of the latter include using higher levels of abstraction (e.g., C-to-RTL <ref type="bibr" target="#b8">[8]</ref>, <ref type="bibr" target="#b7">[7]</ref>), and even full chip generators using extensible processors <ref type="bibr" target="#b1">[2]</ref>. A critical first step in all of these approaches is to understand, in quantitative terms, the types and magnitudes of energy overheads in general-purpose processors. Once these are understood, it is then possible to explore ways to eliminate these overheads and assess the feasibility of creating an efficient, general-purpose machine.</p><p>This paper quantifies general-purpose overheads, exploring a series of customizations that reduce overheads to achieve ASIClike efficiency. In particular, we consider three broad strategies: (1) techniques to exploit instruction-and data-level parallelism, such as VLIW and SIMD, (2) techniques to customize instructions by fusing complex, frequently occurring instruction sub-graphs, and (3) techniques to create application-specific data storage with fused functional units. These strategies span a range of general and domain-specific customization, incurring progressively greater design effort.</p><p>We evaluate these strategies by transforming a general-purpose, Tensilica-based, extensible CMP system into a highly efficient 720p HD H.264 encoder. We choose H.264 because it demonstrates the large energy advantage of ASIC solutions (500x) and because there exist commercial ASICs that can serve as a benchmark. Moreover, H.264 contains a variety of computational motifs, from highly data parallel algorithms (motion estimation) to control intensive ones (CABAC).</p><p>The results are striking. Starting from a 500x energy penalty, adding relatively wide (16x) SIMD execution units improves performance by 10x and energy efficiency by 7x. Since SIMD units are often augmented with special fused instructions to accelerate important applications, we introduce our own custom fused instructions to improve both performance and energy efficiency by an additional 1.4x. Despite these customizations, which collectively improve energy efficiency by 10x, the resulting solution is still 50x less energy efficient than an ASIC.</p><p>An examination of the energy breakdown clearly demonstrates why. Since the SIMD unit customizes datapath widths of 8-12bits, functional unit energy comprises less than 10 percent of the total even when performing more than 10 operations per cycle. Thus, to create a truly efficient processor, one needs to construct instructions that aggregate enough computation to offset the energy overheads of flexible instruction and data fetch. Creating such "magic" instructions improves energy efficiency by another 18x and yields a solution within 3x of a full ASIC design.</p><p>While identifying the right customizations for a given application takes significant effort, it is hard to achieve ASIC-like efficiencies without them. The inescapable conclusion is that truly efficient designs will require application-specialized hardware. If energy efficiency is going to drive future computing design, then we need frameworks that allow application experts to easily (and at low cost) create customized solutions. The fact that, for our application, we can achieve good efficiency using processor instruction extensions is an encouraging sign.</p><p>Since our experiments use an extensible processor, the next section reviews some of the prior work in this area, provides an overview of H.264 encoding, and describes the performance of hardware and software solutions. Section 3 then presents our experimental methodology, describing our baseline, generic H.264 implementation on a Tensilica CMP and outlining our strategies for customizing this system. The performance and efficiency gains are described in Section 4, which also explores the causes of the overheads and different methods for addressing them. Using the insight gained from our results, Section 5 discusses the broader implications for efficient computing and supporting application driven design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BACKGROUND</head><p>Since we use an extensible processor for our case study, we first describe prior work on efficient computing, focusing on processor extensions. With this background, we then provide an overview of H.264 encoding and its main compute stages. The section ends by describing hardware and software implementations to demonstrate the performance advantages of an ASIC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Related Work in Efficient Computing</head><p>General-purpose processors are often customized to improve their efficiency for specific application domains. For example, SIMD architectures achieve higher performance for multimedia and other data-parallel applications, while DSP processors are tailored to perform signal-processing tasks efficiently. More recently, ELM <ref type="bibr" target="#b6">[6]</ref> and AnySP <ref type="bibr" target="#b10">[10]</ref> have been optimized for embedded and mobile signal processing applications, respectively, by reducing processor overheads. While these strategies are meant to cover a broad spectrum of applications, special instructions are sometimes added to accelerate frequently used or critical operations for specific applications. For example, Intel's SSE4 <ref type="bibr" target="#b11">[11]</ref>[12] includes instructions to accelerate matrix transpose and sum-of-absolutedifferences.</p><p>Customizable processors allow designers to take the next step, and create instructions tailored to applications. Extensible processors such as Tensilica's Xtensa provide a base design that the designer can extend with custom instructions and datapath units <ref type="bibr" target="#b9">[9]</ref>. Extending the ISA for a given application can be done either manually or with automated tools. Tensilica provides an automated ISA extension tool <ref type="bibr" target="#b19">[18]</ref>, which achieves speedups of 1.2x to 30x for EEMBC benchmarks <ref type="bibr" target="#b18">[17]</ref> and signal processing algorithms <ref type="bibr" target="#b17">[16]</ref>. Other tools have similarly demonstrated significant gains from automated ISA extension <ref type="bibr" target="#b13">[13]</ref> <ref type="bibr" target="#b14">[14]</ref>. While automatic ISA extensions can be very effective, manually creating ISA extensions gives even larger gains: Tensilica reports speedups of 40x to 300x for kernels such as FFT, AES and DES encryption <ref type="bibr" target="#b20">[19]</ref>[20] <ref type="bibr" target="#b22">[21]</ref>.</p><p>Our work takes customizable processors, which are much less efficient than ASICs, and determines what is required to close that efficiency gap within a flexible framework. While previous studies have demonstrated significant improvements in performance and efficiency, we explore the reasons for these gains, which is essential to determine the nature and degree of customization necessary for future systems. Our approach starts with a generic CMP system, then customizes its memory system and processors to determine the magnitude and sources of overhead eliminated in each step toward achieving a high efficiency 720p HD H.264 encoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">H.264 Algorithm and Computational Motifs</head><p>To understand how we customize a generic CMP to efficiently implement H.264, we must first understand the basic components of the H.264 algorithm. Five major functions comprise more than 99% of the total execution time in our base CMP implementation: We implement the H.264 baseline profile at level 3.1; however, we use CABAC in place of CAVLC because CABAC is more complex and more challenging to improve <ref type="bibr" target="#b24">[23]</ref> <ref type="bibr" target="#b25">[24]</ref>. CABAC is also more representative of advanced coding steps in other applications. IME finds the closest match for an image-block from a previous reference image, and computes a vector to represent the observed motion. While it is one of the most compute intensive parts of the encoder, the basic algorithm lends itself well to data parallel architectures. When run on our base CMP, IME takes up 56% of the total encoder execution time and 52% of total energy. The next step, FME, refines the initial match from integer motion estimation and finds a match at quarter-pixel resolution. FME is also data parallel, but it has some sequential dependencies and a more complex computation kernel that makes it more challenging to parallelize. FME takes up 36% of the total execution time and 40% of total energy on our base CMP design. Since FME and IME together dominate the computational load of the encoder, optimizing these algorithms is essential for an efficient H.264 system design.</p><p>IP then uses previously encoded neighboring image-blocks within the current image to form a prediction for the current imageblock. While the algorithm is still dominated by arithmetic operations, the computations are much less regular than the motion estimation algorithms. Additionally, there are sequential dependencies not only within the algorithm but also with the transform and quantization function.</p><p>Next, in DCT/Quant, the difference between a current and predicted image block is transformed and quantized to generate quantized coefficients, which then go through the inverse quantization and inverse transform to generate the reconstructed pixels. The basic function is relatively simple and data parallel. However, it is invoked a number of times for each 16x16 image block, which calls for an efficient implementation. For the rest of this paper, we merge these operations into the IP stage. The combined operation accounts for 7% of the total execution time and 6% of total energy. Finally, CABAC is used to entropy-encode the coefficients and other elements of the bit-stream. Unlike the previous algorithms, CABAC is sequential and control dominated. While it takes only 1.6% of the execution time and 1.7% of total energy on our base design, CABAC often becomes the bottleneck in parallel systems due to its sequential nature. This becomes particularly important because we need to speed up the application by around 250x on a four-processor system. After speedups in the first four functions, CABAC becomes the bottleneck and cannot be ignored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Current H.264 Implementations</head><p>The computationally intensive H.264 encoding algorithm poses a challenge for general-purpose processors, and is typically implemented as an ASIC. Prior work has demonstrated efficient hardware architectures for various sub-algorithms in H.264 <ref type="bibr" target="#b35">[33]</ref> <ref type="bibr" target="#b36">[34]</ref>[35] <ref type="bibr" target="#b38">[36]</ref>. T.-C. Chen et al. implement a full-system H.264 encoder <ref type="bibr" target="#b4">[4]</ref> and demonstrate that real-time HD H.264 encoding is possible in hardware using relatively low power and area cost. Later implementations employ clever algorithmic optimizations which sacrifice some signal-to-noise ratio (SNR) but significantly reduce energy and area <ref type="bibr" target="#b30">[29]</ref> <ref type="bibr" target="#b31">[30]</ref>. While these optimizations are useful, our study works with the basic algorithms similar to those in <ref type="bibr" target="#b4">[4]</ref>. Our aim is to understand the mechanisms behind high efficiency of custom hardware, and these insights are not likely to change significantly for a particular algorithmic variant.</p><p>There has also been H.264 software optimizations, particularly for motion estimation, which takes most of the encoding time. For example, sparse search techniques along with other algorithmic modifications speed up software performance of IME and FME by up to 10x with negligible loss in SNR <ref type="bibr" target="#b33">[31]</ref>  <ref type="bibr" target="#b34">[32]</ref>. Combining aggressive algorithmic modifications with multiple cores and SSE extensions lead to highly optimized H.264 encoders on Intel processors <ref type="bibr" target="#b3">[3]</ref>[37].</p><p>Despite these optimizations, software implementations of H.264 lag far behind dedicated ASICs. <ref type="table" target="#tab_0">Table 1</ref> compares a software implementation of a 480p SD encoder <ref type="bibr" target="#b3">[3]</ref> to a 720p HD ASIC implementation <ref type="bibr" target="#b4">[4]</ref>. The software implementation employs a 2.8 GHz Intel Pentium 4 executing highly optimized SSE code. This results in very high-energy consumption and low area efficiency. It is also worth noting that the software implementation relies on various algorithmic simplifications, which drastically reduce the computational complexity to achieve real-time performance, but result in a 20% decrease in compression efficiency for a given SNR <ref type="bibr" target="#b3">[3]</ref>. The custom ASIC hardware, on the other hand, consumes over 500x less energy and is far more efficient in its use of silicon area as shown by the area numbers in <ref type="table" target="#tab_0">Table 1</ref>. The ASIC makes few algorithmic simplifications and consequently has a negligible drop in compression efficiency <ref type="bibr" target="#b4">[4]</ref>.  <ref type="bibr" target="#b23">[22]</ref> estimates the energy and area of the resulting system. Its results are within 30% of the actual energy numbers <ref type="bibr" target="#b26">[25]</ref>, which is adequate since we are looking for more than two orders of magnitude improvements in energy efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Baseline H.264 Implementation</head><p>We use H.264 encoder reference code JM 8.6 for our experiments <ref type="bibr" target="#b40">[38]</ref>. In the reference implementation, H.264's video encoding path is very long and suffers from sequential dependencies that restrict parallelism. We carefully analyze existing H.264 partitioning techniques and implement algorithmic changes in IME that remove some dependencies and allow mapping of the five major algorithmic blocks to the four-stage macro-block (MB) pipeline shown in <ref type="figure">Figure 1</ref>. This mapping exploits task level parallelism at the macro block level and significantly reduces the inter-processor communication bandwidth requirements by sharing data between pipeline stages.</p><p>To build a base system, we map the four-stage macro-block partition of H.264 to a four-processor CMP system where each processor has 16KB 2-way set associative instruction and data caches. <ref type="table" target="#tab_1">Table 2</ref> presents our base system's performance and energy efficiency for the individual 720p HD H.264 subalgorithms to highlight the large area and energy efficiency gap between our base CMP and the reference ASIC. At approximately 8.6B instructions to process one frame (IME), our base system consumes about 140 pJ/instruction-a reasonable value for a general-purpose system.   We analyze the performance and energy efficiency of this base CMP implementation and compare it to that of the ASIC. We allocate the processor's energy into different functional units as shown in <ref type="table" target="#tab_2">Table 3</ref>, which reports the energy consumed by our base four-processor CMP system. As expected, the energy required for each task is related to the time required for that task, since the energy of each instruction is similar. The RISC implementations of IME and FME, which are the major contributors to performance and energy consumption, have a performance gap of 525x and an energy gap of over 700x with respect to the ASIC.</p><p>We also note that while IP, DCT, Quant and CABAC are much smaller parts of the total energy/delay, even they need about 100x energy improvements to reach ASIC-level values.</p><p>This data makes it clear how far we need to go to approach ASIC efficiency. Clearly, the energy spent in instruction fetch (IF) is an overhead due to the programmable nature of the processors and is absent in a custom hardware state machine, but eliminating all this overhead only increases the energy efficiency by less than 2x. Even if we assume everything but the functional unit energy is overhead, we still end up with energy savings of only 20x-not nearly enough to reach ASIC levels. As the rest of this paper demonstrates, we need to both customize functional units (for correct bit widths, for efficient multi-input or output operations, etc.) and remove almost all other processor overheads (instruction fetches, register file accesses, etc.) to approach ASIC efficiency. <ref type="table">Table 4</ref>. Different stages of specialization, and the types of optimizations implemented.</p><p>Step 1 is very general; step 2 is often done in general-purpose SIMD units for important applications; step 3 builds application specific functional units.</p><p>Step 1</p><p>Step 2</p><p>Step 3</p><p>Inst. decode logic  <ref type="table">Table 4</ref> defines three classes of processor customization. At the first stage we restrict ourselves to relatively general purpose datapath extensions such as SIMD and VLIW units; such extensions are frequently found in processor designs today and will be part of future efficient processors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Customization Strategies</head><p>At the second stage, we add a limited degree of algorithm-specific customization.</p><p>Operation fusion -the creation of new instructions that combine sequences of existing instructionsproduces new functional units. We limit new instructions to operand requirements (i.e., two input operands, one output) that match those for existing instructions; new instructions must fit in existing instruction formats and datapath. This constraint is the same as that of Intel's SSE instructions. These customizations, at least for key functions, are also likely to exist in future processors. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">RESULTS</head><p>We implement and evaluate the three-customization strategies of <ref type="table">Table 4</ref>, detailing their effectiveness. For algorithm-specific instructions, we outline strategies for each major phase of computation. Collectively, these results describe how efficiencies improve by 170x over the baseline in Section 3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">SIMD and VLIW Enhancements</head><p>Using Tensilica's FLIX (Flexible Length Instruction eXtension) feature, we create processors with 2-and 3-slot VLIW instructions. Using TIE, we add SIMD execution units to the base processor with vector register files of custom depths and widths. As expected, DLP algorithms using SIMD units show a large decrease in processor energy; speedup increases as the number of instructions executed decreases. IME and FME use 16 and 18-way SIMD datapaths and achieve speedups of 10x and 14x. Intra/DCT/Quant using an 8-way SIMD datapath achieves a speedup of 6x. The SIMD units use custom-width functional units instead of standard 32-bit versions to enable more efficient computation, and generally run between 8 and 16 bits. As <ref type="figure">Figure  4</ref> shows, even performing 16 concurrent operations barely increases the percentage energy used by the functional units, which still comprise around 10% of the total. Even the register file energy decreases by 4-6x using SIMD since we use 8-bit vector elements, and scale down register file depths, so its percentage contribution to the total energy does not increase considerably.</p><p>While SIMD only works for data-parallel algorithms, all H.264 sub-algorithms achieve speedups from VLIW instructions, with 2-slot VLIW offering higher energy efficiency than 3 slots. 2-slot VLIW gains up to 1.5x more performance. For CABAC, VLIW instructions increase the code size, and the resulting increase in cache size and cache access energy offsets any energy gains. SIMD and VLIW speed up the application by 10x, decreasing IF energy by 10x, but the percentage of energy going to IF does not change much. IF still consumes more energy than functional units. Furthermore, while CABAC is not initially an issue, its power dissipation is unchanged by these optimizations, and is now a major contributor to overall power dissipation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Operation Fusion</head><p>The second customization strategy builds on the first and evaluates additional gains offered by the fusion of frequently occurring complex instruction subgraphs. Operation fusion is particularly interesting because it can be targeted by a number of automatic tools <ref type="bibr" target="#b23">[22]</ref>. Fusion of complex subgraphs is useful because it reduces both instruction count and register file accesses-intermediate results are consumed within the fused operation and do not need to be stored in the register file. An additional benefit is the ability to create more energy efficient hardware implementations of the fused operations. For data parallel algorithms, we fuse together both RISC as well as SIMD operations. We pipeline our functional units to ensure fused operations do not increase clock cycle time.</p><p>To illustrate operation fusion, we present a pixel up-sampling example taken from FME: Before creating fused instructions, we split the equation into three parts based on computation similarities: 20x of the reference frame. Upsampling uses a major portion of FME compute time, so we want to enhance its performance and energy efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="0">+20x 1 , -5x -1 -5x 2, and x 2 + x 3</head><p>Note that the two-input operand restriction is not broken because the accumulator register (acc), internal to the functional unit, is used implicitly. Similarly, the instruction supplies the constant multiplication factor directly, avoiding a register file access. These new instructions improve energy efficiency by reducing register file accesses by forwarding the result of the multiplication directly to an adder and by using an accumulator.</p><p>. This allows us to keep the number of input operands per fused instruction equal to two and thus we do not increase the number of register file ports. Each instruction fuses addition/subtraction with multiplication, which is implemented using shift and adds. <ref type="figure">Figure 5</ref> presents the newly created instructions.    <ref type="bibr">264</ref> encoder, and an energy efficiency gain of almost 10x, but still uses greater than 50x more energy than an ASIC. The basic problem is clear. For H.264, the basic operations are very simple and low energy. In our base machine we overestimate the energy consumed by the functional units, since we count the entire 32-wide functional unit energy. When we move to the SIMD machine, we tailor the functional unit to the desired width, which reduces the required energy. However, executing 10s of narrow width operations per instruction still leaves a machine that is spending 90% of its energy on overhead functions, with only 10% going to the functional units.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Algorithm Specific Instructions</head><p>To bridge the remaining gap, we must create instructions that can execute 100s of operations in a single instruction. To achieve this parallelism requires creating instructions that are tightly connected to custom data storage elements with algorithmspecific communication links to supply the large amounts of data required, and thus tend to be very closely tied to the specific algorithmic methods being optimized. These storage elements can then be directly wired to custom designed multiple input and possibly multiple output functional units, directly implementing the required communication for the function in hardware.</p><p>Once this hardware is in place, the machine can issue "magic" instructions that can accomplish large amounts of computation at very low costs. This type of structure eliminates almost all the processor overheads for these functions by eliminating most of the communication overhead (register file, bus, and instruction fetch) associated with processors. We call these "magic" instructions, since these operations can have a large effect on both the energy and performance of an application and yet would be difficult to derive directly from the code. They typically require an understanding of the underlying algorithms and the capabilities and limitations of existing hardware resources, thus requiring greater effort on part of the designer. Since the IP stage uses some techniques similar to FME the rest of the section will focus on FME, IME and CABAC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">FME Strategy</head><p>To illustrate a "magic" instruction, we begin by returning to the pixel upsampling example. In H.264, upsampling uses an FIR filter that requires one new pixel per iteration. Thus after one upsampling step, we can reuse pixels x -1 â€¦ x 3 , and only need to load x 4 . Normal register files require us to do five register transfers for each upsampling step, significantly increasing the energy dissipated in the instruction fetch and decode logic and also in the register file. While some machines have indexing register files that help with this issue <ref type="bibr" target="#b6">[6]</ref>, we still need to read all the operations from the register file to perform the computation.</p><p>To reduce instruction fetches and register file transfers, we augment the processor register file with a custom 8-bit wide, six entry shift register structure which works like a FIFO: every time a new 8-bit value is loaded, all elements are shifted. This eliminates the use of expensive register file accesses for either data shifting or operand fetch, which are now both handled by short local wires. Additionally, since all six entries can now be accessed in parallel we create a six input multiplier/adder which can be implemented much more efficiently (using carry-save addition) than the composition of normal 2 input adders. Finally since we need to perform the upsampling in 2-D, we build a shift register structure that stores the horizontally upsampled data, and feeds its outputs to a number of vertical upsampling units (see <ref type="figure" target="#fig_6">Figure 6</ref>). This transformation yields large savings even beyond the savings in instruction fetch energy. From a pure datapath perspective (register file, pipeline registers, and functional units), this approach dissipates less than 1/30th the energy of a traditional approach.</p><p>The FME SIMD code highlights the advantages of this approach over using larger SIMD arrays. The SIMD implementation suffers from code replication and excessive local memory and register file accesses, in addition to not having the most efficient functional units. FME contains seven different sub-block sizes ranging from 16x16 pixel blocks to 4x4 blocks, and not all of them can fully exploit the 18-way SIMD datapath. Additionally, to use the 18-way SIMD datapath, each sub-block requires a slightly different code sequence, which results in code replication and more I-fetch power because of the larger I-cache. Next, FME fits a streaming data flow model where most of the intermediate data has a short life and is consumed by instructions that are only a few cycles behind; by storing such intermediate data in the register file, energy is wasted on unnecessary register file accesses. This intermediate data also leaves less space in the register file for non-intermediate data, resulting in additional loads and stores. Finally, not all computations are able to benefit from fusion because our register files can only supply two operands at a time.</p><p>To avoid these issues, our custom hardware upsampler processes 4x4 pixels. This allows us to reuse the same computation loop repeatedly without any code replication, which, in turn, lets us reduce the I-cache from a 16KB 4-way cache to a 2KB directmapped cache. Due to the abundance of short-lived data, we remove the vector register files and replace them with custom storage buffers. The magic instruction reduces the instruction cache energy by 54x and processor fetch and decode energy by 14x. Finally, as <ref type="figure">Figure 4</ref> shows, 35% of the energy is now going into the functional units.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">IME Strategy</head><p>4x4 sum of absolute differences (SAD) calculations are important for IME. <ref type="figure" target="#fig_7">Figure 7</ref> shows the custom datapath elements added to the IME processor to accelerate this function. The 16-way SIMD SAD unit of the fusion-optimized processor has been replaced by a 16x16 SAD unit, which can perform 256 SAD operations in one cycle. Since our standard vector register files cannot feed enough data to this unit per cycle, these registers have been replaced by state registers, which allow parallel access to all 16-pixel rows and enable this datapath to perform one 256-pixel computation per cycle. The fetch overhead of SAD operations is thus reduced by roughly 16x. Additionally, this custom storage structure has support for parallel shifts in all four directions, thus allowing much greater data reuse, and drastically reducing the cycles spent on loads, shifts and pointer arithmetic operations as well as data cache accesses. "Magic" instructions and storage elements are also created for other major algorithmic functions in IME to achieve similar gains. More than 65% of total IME cycles are spent in overhead instructions. Thus, by reducing instruction overheads and by amortizing the remaining overheads over larger datapath widths, this strategy improves performance and energy efficiency by 20-30x.</p><p>The large number of parallel operations means that this functional unit finally consumes around 40% of the total instruction energy. This would be even higher, but we further reduced energy (approximately 30%) by employing reduced precision arithmetic where only 5 pixel-bits are used in distortion calculations instead of 8. This technique is also employed by our reference ASIC and causes negligible drop in SNR <ref type="bibr" target="#b4">[4]</ref>. These optimizations along with a small set of other custom operations enable the IME processor to match ASIC performance and come within 3x of ASIC energy <ref type="bibr" target="#b17">16</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">CABAC Strategy</head><p>CABAC originally consumed less than 2% of the total energy. However, after adding "magic" instructions for data parallel components, CABAC dominates the total energy. However, it requires a different set of optimizations because it is highly control oriented and not data parallel. Thus, for CABAC, we are more interested in control fusion than operation fusion.</p><p>A critical part of CABAC is the arithmetic encoding stage, which is a highly serialized process with small amounts of computation, but significant control flow. We break arithmetic coding down into a simple pipeline and drastically change it from the reference code implementation, reducing the binary encoding of each symbol to five instructions. While there are several if-then-else conditionals reduced to single instructions (or with several compressed into one), the most significant reduction came in the encoding loop, which is written as a while loop over every bit of the RANGE in the reference code as shown in <ref type="figure">Figure 8</ref>. This loop (including the implicit doubly nested loops in put_one_bit_ plus_outstanding) was reduced to a single constant time instruction and a rarely executed small while loop by fundamentally changing the algorithm as shown in <ref type="figure">Figure 9</ref>. Since we now do buffering on a 64-bit basis, word1full is rarely true, and wordsOustanding is almost never greater than 0.</p><p>The other critical part of CABAC is the conversion of non-binary valued DCT coefficients to binary codes in the binarization stage.</p><p>To improve the efficiency of this step, we create a 16-entry LIFO structure to store DCT coefficients. To each LIFO entry, we add a single-bit flag to identify zero-valued DCT coefficients. These structures, along with their corresponding logic, reduce register file energy by bringing the most frequently used values out of the register file and into custom storage buffers. Using "magic" instructions we produce Unary and Exponential-Golomb codes using simple operations, which help reduce datapath energy. These modifications are inspired by the ASIC implementation described in <ref type="bibr" target="#b16">[15]</ref>. CABAC is optimized to achieve the bit rate required for H.264 level 3.1 at 720p video resolution. ASIC-like efficiency required 2-3 special hardware units for each sub-algorithm, which is significant customization work. After this effort, the processors optimized for data-parallel algorithms have a total speedup of up to 600x and an energy reduction of 60-350x compared to our base CMP. For CABAC total performance gain is 17x and energy gain is 8x. <ref type="figure">Figure 4</ref> provides the final energy breakdowns.  <ref type="table" target="#tab_7">Table 6</ref> shows area in mm 2 for the evaluated optimization strategies. The last column shows the area efficiency for each step, which is defined as speedup/area. Customizing cache sizes to the requirements of each algorithm results in substantial area savings as depicted by "RISC with Mem Cust". General-purpose optimizations increase the area substantially compared to vanilla RISC versions, but they also help improve the area efficiency for data-parallel algorithms. However, control-intensive CABAC does not benefit from such optimizations. Further customization of datapaths not only improves area efficiency tremendously but also results in a smaller area compared to general-purpose optimizations. Customizations not only reduce the number of instructions, but also substantially improve data reuse inside the processor, which in turn reduces cache sizes. This reduction in memory area helps offset area increases due to addition of custom units.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Area Efficiency</head><p>It might seem that the efficiency of our solution is higher than that of an ASIC, but the ASIC is designed to run at 100MHz in 0.18um while our magic version is designed to run at 435MHz. If we assume that the ASIC in 90nm can run at 435MHz without any modifications, it can achieve 4.35x better performance and thus 4.35x better area efficiency, making it substantially more area efficient than our solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Other Applications</head><p>While H.264 is representative of applications with very simple compute operations, other applications, for example floating point (FP) applications, have higher-energy operations. FP arithmetic consumes 10x the energy of integer arithmetic; FP functional units comprise a larger fraction of total instruction energy. Thus, one might think less parallelization is required to amortize instruction overheads for FP applications.</p><p>However FP operations comprise only 20% of the dynamic instruction stream for representative applications <ref type="bibr" target="#b27">[26]</ref> <ref type="bibr" target="#b28">[27]</ref>. For this reason, FP energy will likely be a small fraction of total application energy. To match the most efficient H.264 design points, 35% or more of the total application energy should be in the ALU. Thus, with an instruction overhead of approximately 130pJ, functional unit energy will need to be at least 70 pJ, which is equivalent to 7 FP operations, or approximately 35 instructions (given a 20% FP instruction mix). While this level of parallelism might be possible for some applications with SIMD and operation fusion, it seems likely that customizations will be needed to achieve this number of ops/instruction for most applications. This is especially true if some part of the application is control and not data limited.</p><p>Finally, some applications are dominated by memory costs. In truly memory-bound applications, computation is not the bottleneck, so data path customizations will have little effect. For these applications, it is the energy efficiency of bringing application data to the core that fundamentally needs to be improved. Co-optimization of the memory system and the application can yield large savings in these situations <ref type="bibr" target="#b29">[28]</ref>, but the advantages of application customization over a conventional memory design with a few adjustable parameters still needs to be explored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">ENERGY EFFICIENT COMPUTERS</head><p>It is now easy to see how an ASIC can be 2-3 orders of magnitude lower energy than a processor. For many applications, and most of the ones performed by ASICs, the basic operations being performed are very low energy, using 8-16 bit integers like in H.264. These applications are computation-and not data fetchlimited, so the fundamental energy/operation bound is a couple hundred femtojoules in a 90nm process, which is equivalent to moving one bit less than a mm. All other costs in a processorinstruction fetch, register fetch, data fetch, control, and pipeline registers-are much larger (140pJ) and dominate overall power.</p><p>Standard SIMD and simple operation fusion instructions can only go so far to improve the performance and energy efficiency. It is hard to aggregate more than 10-20 operations into an instruction without incurring growing inefficiencies, and with tens of operations per cycle we still have a machine where around 90% of the energy is going into overhead functions. In addition, some of these overhead instructions are just to control or sequence the data (e.g., CABAC).</p><p>Thus, the solution is "instructions" that perform hundreds of operations each time they are executed, so the overhead of the instruction is better balanced by the work performed. Unfortunately this is hard to do in a general way, since bandwidth requirements and utilization of a larger SIMD array would be problematic. We solved this problem by building custom storage units tailored to the application, and then directly connecting the necessary functional units to these storage units. These custom storage units greatly amplified the register fetch bandwidth, since data in the storage units are used for many different computations. In addition, since the intra-storage and functional unit communications were fixed and local, they could be managed at ASIC-like energy costs. The efficiencies found in these custom datapaths are impressive, since, in H.264, at least, they take advantage of data sharing patterns and create very efficient multiple input operations. This means that even if researchers are able to a create a processor which decreases the instruction and data fetch parts of a processor by more than 10x, these solutions will not be as efficient as solutions with "magic" instructions.</p><p>Of course including these "magic" instructions requires custom hardware, and some might say we are just building an ASIC in our processor. While we agree that creating "magic" instructions requires a thorough understanding of the application as well as hardware, we feel that adding this hardware in an extensible processor framework has many advantages over just designing an ASIC. These advantages come from the constrained processor design environment and the software, compiler, and debugging tools available in this environment.</p><p>For example, once the initial effort in understanding the application and its characteristics was done, the extensible processor allowed us to implement and verify the fully customized "magic" configuration for each algorithm in two to three man-months, which would not have been possible with an ASIC flow. Many of the low-level issues, like interface design and pipelining, are automatically handled. In addition, since all hardware is wrapped in a general-purpose processor, the application developer retains enough flexibility in the processor to make future algorithmic modifications. In fact, in this type of design environment, one might be tempted to make the new hardware that supports the "magic" instructions a little more flexible than required, providing some runtime flexibility just to increase the probability of it still being useful if the algorithm changes.</p><p>Yet an extensible processor alone is not a sufficient solution, since one still needs to take one or more of these processors and create a working chip system. Designing and validating a chip is an extremely hard and expensive task. If application customization will be needed for efficiency-and our data indicates it will bewe need to start creating systems that will efficiently allow savvy application experts to create these optimized chip level solutions. This will require extending the ideas for extensible processors to extensible full chip systems. We are currently working on this creating this type of system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION</head><p>Ideally, we would like ASIC-like energy efficiencies-100x to 1000x more energy efficient than general-purpose CPUs-on our next generation processors. Our data, while not conclusive, indicates that this goal will be hard to achieve. The basic problem is that many applications include extremely simple, low energy operations. Since the energy of these operations is very low, any overhead, from the register fetch to the pipeline registers in a processor, is likely to dominate. The good news is that this large overhead per instruction makes estimating the energy savings easy-you simply look at the performance gains-but the bad news is that adding data parallel hardware like wide SIMD units will still leave you far from an ASIC.</p><p>It is encouraging that we were able to achieve ASIC energy levels in a customized processor by creating customized hardware that easily fit inside a processor framework and executed 100s of simple operations per instruction. Extending a processor instead of building an ASIC seems like the correct approach; since it provides a number of software development advantages and the energy cost of this option seems small. The key challenge now is to build a design system that lets application designers create these types of customizations with much greater ease.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>(</head><label></label><figDesc>i) IME: Integer Motion Estimation (ii) FME: Fractional Motion Estimation (iii) IP: Intra Prediction (iv) DCT/Quant: Transform and Quantization and (v) CABAC: Context Adaptive Binary Arithmetic Coding.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 . Four stage macroblock partition of H. 264 . (a) Data flow between different pipeline stages. (b) How the four stage pipeline works on different macro blocks. The IP stage includes DCT+Quant. EC is the CABAC stage.</head><label>1264</label><figDesc>Figure 1. Four stage macroblock partition of H.264. (a) Data flow between different pipeline stages. (b) How the four stage pipeline works on different macro blocks. The IP stage includes DCT+Quant. EC is the CABAC stage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Finally</head><label></label><figDesc>, at the third stage we allow unrestricted tailoring of the datapath according to algorithm needs by introducing arbitrary new compute operations as well as by complementing or even replacing the register files with custom storage structures. The results of these customizations shown in Figures 2, 3 and 4 are described in more detail in the next section.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>x n = x - 2</head><label>2</label><figDesc>-5x -1 + 20x 0 + 20x 1 -5x 2 + x H.264 uses this equation to perform upsampling of pixels in the reference image frame. In the equation x 3 n is the newly calculated up-sampled pixel, formed by applying an interpolation filter on pixels x -2 â€¦ x 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 . Each set of bar graphs represents speedup at each stage of optimization. Each optimization builds on those of the previous stage with the first bar in each set representing RISC speedup, followed by generic optimizations such as SIMD and VLIW, then operation fusion and finally "magic" instructions Figure 2 . Each set of bar graphs represents energy consumption (ÂµJ) at each stage of optimization for IME, FME, IP and CABAC respectively. Each optimization builds on the ones in the previous stage with the first bar in each set representing RISC energy dissipation followed by generic optimizations such as SIMD and VLIW, operation fusion and ending with "magic"Figure 5 . FME upsampling after fusion of two multiplications and two additions. AddShft takes two inputs, multiplies both with the multiplicand and adds the result. Multiplication is performed using shifts and adds. Operation fusion results in 3 instructions instead of the RISC's 5 add/sub and 4 multiplication instructions.</head><label>3255</label><figDesc>Figure 3. Each set of bar graphs represents speedup at each stage of optimization. Each optimization builds on those of the previous stage with the first bar in each set representing RISC speedup, followed by generic optimizations such as SIMD and VLIW, then operation fusion and finally "magic" instructions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 . Datapath energy breakdown for H. 264 . IF is instruction fetch/decode (including the I-cache). D-$ is the D-cache. Pip is the pipeline registers, busses, and clocking. Ctl is random control. RF is the register file. FU is the functional elements. Only the top bar (FU), or perhaps the top two (FU + RF) contribute useful work in the processor. For this application it is hard to achieve much more than 10% of the power in the FU without adding custom hardware units. This data was estimated from processor simulations.</head><label>4264</label><figDesc>Figure 4. Datapath energy breakdown for H.264. IF is instruction fetch/decode (including the I-cache). D-$ is the D-cache. Pip is the pipeline registers, busses, and clocking. Ctl is random control. RF is the register file. FU is the functional elements. Only the top bar (FU), or perhaps the top two (FU + RF) contribute useful work in the processor. For this application it is hard to achieve much more than 10% of the power in the FU without adding custom hardware units. This data was estimated from processor simulations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 . FME upsampling unit, showing merged storage and computation. Customized shift registers directly wired to function logic result in efficient upsampling. Ten integer pixels from local memory are used for row upsampling in RFIR blocks. Half upsampled pixels along with appropriate integer pixels are loaded into shift registers. CFIR accesses six shift registers in each column simultaneously to perform column upsampling.</head><label>6</label><figDesc>Figure 6. FME upsampling unit, showing merged storage and computation. Customized shift registers directly wired to function logic result in efficient upsampling. Ten integer pixels from local memory are used for row upsampling in RFIR blocks. Half upsampled pixels along with appropriate integer pixels are loaded into shift registers. CFIR accesses six shift registers in each column simultaneously to perform column upsampling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 . Custom storage and compute blocks for IME's 4x4 SAD calculation. Current and reference-pixel register files allow parallel access to all pixel values to feed the 16x16 SAD array. In addition, the RefPixel Regfile supports operations to shift all pixel rows down by one row or shift all pixel columns right by one pixel location.</head><label>7</label><figDesc>Figure 7. Custom storage and compute blocks for IME's 4x4 SAD calculation. Current and reference-pixel register files allow parallel access to all pixel values to feed the 16x16 SAD array. In addition, the RefPixel Regfile supports operations to shift all pixel rows down by one row or shift all pixel columns right by one pixel location.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 . CABAC arithmetic encoding loop in H. 264 reference code looping over every bit of the "RANGE.Figure 9 . CABAC arithmetic encoding loop after insertion of "magic" instructions. The loop corresponding to RANGE has been reduced to one single constant time instruction BIARI_ENCODE_PIPE_5.</head><label>82649</label><figDesc>Figure 8. CABAC arithmetic encoding loop in H.264 reference code looping over every bit of the "RANGE." word1full = BIARI_ENCODE_PIPE_5(); if (word1full){ wordsOutstanding = WRITE_OUT_WORD1(); while(wordsOutstanding){ wordsOutstanding = WRITE_OUT_UNRESOLVED(); } } Figure 9. CABAC arithmetic encoding loop after insertion of "magic" instructions. The loop corresponding to RANGE has been reduced to one single constant time instruction BIARI_ENCODE_PIPE_5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table>Intel's highly optimized, 2.8GHz Pentium 4 implementation 
of a 480p H.264 encoder versus a 720p HD ASIC. The second row 
presents Intel's SD data scaled to HD H.264. ASIC numbers have 
been scaled from 180nm to 90nm. 

Perf. 
(fps) 
Area 
(mm 2 
Enrgy/frame 
(mJ) 
) 
Intel (720x480 SD) 
30 
122 
742 
Intel (1280x720 HD) 
11 
122 
2023 
ASIC 
30 
8 
4 

3. EXPERIMENTAL METHODOLOGY 

Our experiments use a CMP platform based on Tensilica's 
extensible RISC cores [2][39][40]. This baseline implementation 
defines the gap we seek to bridge between general-purpose 
computing and ASIC efficiencies. We use the extensible platform 
to implement three different classes of customizations, each more 
application specific than the previous one. We independently 
customize each processor's datapath using Tensilica's TIE 
language and optimize memory system parameters. To quickly 
simulate and evaluate different design options, we created a 
multiprocessor simulation framework that employs Tensilica's 
Xtensa Modeling Platform (XTMP) as its base. We use 
Tensilica's ISA extension framework to specify the number of 
VLIW slots, the width for the SIMD data paths, the number and 
size of register files, custom hardware instructions, and custom 
data storage elements. Tensilica's TIE compiler generates 
simulation models for different processor configurations and their 
energy explorer tool </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 .</head><label>2</label><figDesc></figDesc><table>Performance and energy for a generic Tensilica CMP 
implementation of H.264. Intra combines IP, DCT, and Quant. The 
gap numbers compare these values to an equivalent ASIC. 

Performance 

Area 
(mm 2 ) 

Energy/ 
Frame 
(mJ) 
Perf. 
Gap 
Energy 
Gap 
MC/ 
MB 
Frame 
/sec 

IME 
2.10 
0.06 
1.04 
1179 
525.0x 
707x 

FME 
1.36 
0.08 
1.04 
921 
342.0x 
468x 

Intra 
0.25 
0.48 
1.04 
137 
63.0x 
157x 

CABAC 0.06 
1.82 
1.04 
39 
16.7x 
261x 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 .</head><label>3</label><figDesc></figDesc><table>Datapath energy breakdown for our base implementation in 
mJ/frame. IF is instruction fetch/decode (including the I-cache). D-$ 
is the D-cache. Pip is the pipeline registers, buses, and clocking. Ctl is 
random control. RF is the register file. FU is the functional elements. 
Data estimates from processor simulations. 

IF D-$ Pip Ctl 
RF 
FU 
Total 

IME 
410 218 257 113 
113 
68 
1179 

FME 
286 196 205 
90 
90 
54 
921 

Intra 
54 20 
29 
13 
13 
8 
137 

CABAC 12 
2 
8 
4 
4 
2 
32 

Total 
762 436 499 220 
220 
132 
2269 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 5 .</head><label>5</label><figDesc></figDesc><table>Fused operations added to each unit and the resulting 
performance and energy gains. FME required fusion of large 
subgraphs to get significant performance improvement. 

# of 
fused 
ops 

Op 
Depth 
Energy 
Gain 
Perf 
Gain 

IME 
4 
3-5 
1.5 
1.6 

FME 
2 
18-34 
1.9 
2.4 

Intra 
8 
3-7 
1.9 
2.1 

CABAC 
5 
3-7 
1.1 
1.1 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 presents</head><label>5</label><figDesc>the number of fused operations created for each H.264 algorithm, the average size of the fused instruction subgraphs, and the total energy and performance gain achieved through fusion. Interestingly, IME and FME do not share any instructions, though Intra and FME share instructions for the Hadamard transform. DCT transform also implements the same transform instructions. CABAC's fused operations provide negligible performance and energy gains of 1.1x. Fused instructions give the largest advantage for FME, on average doubling the energy/performance advantage of SIMD/VLIW. Employing fused operations in combination with SIMD/VLIW results in an overall performance improvement of 15x for the H.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="true"><head>Table 6 -Area and area efficiency at various stages of customization</head><label>6</label><figDesc></figDesc><table>Area (mm 

2 

Speedup 

) 
Area 
Efficiency 
(Speedup/ 
Area) 

IME FME IP CABAC Total 

RISC 
1.39 1.39 1.39 1.39 5.56 
1 
0.18 
RISC with 
Memory 
Cust. 

0.80 1.39 1.06 1.44 4.69 
1 
0.21 

GP Opt. 1.79 4.12 1.76 1.55 9.22 
9.2 
1.00 
OP 
Fusion 
1.83 3.32 1.63 1.64 8.42 15.7 
1.87 

Magic 2.10 2.28 1.58 1.1 7.06 
256 
36.25 
ASIC @ 
100MHz 
2.82 3.33 1.47 0.27 7.89 
243 
30.81 

ASIC @ 
435MHz 
2.82 3.33 1.47 0.27 7.89 1057 
133.97 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">ACKNOWLEDGMENTS</head><p>This work would have not been possible without great support and cooperation from many people at Tensilica including Chris Rowen, Dror Maydan, Bill Huffman, Nenad Nedeljkovic, David Heine, Govind Kamat and others. The authors acknowledge the support of the C2S2 Focus Center, one of six research centers funded under the Focus Center Research Program (FCRP), a Semiconductor Research Corporation subsidiary, and earlier support from DARPA. This material is based upon work partially supported under a Sequoia Capital Stanford Graduate Fellowship. The National Science Foundation under Grant #0937060 to the Computing Research Association also supports this material for the CIFellows Project. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the view of the National Science Foundation or the Computing Research Association.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Scaling, Power and the Future of CMOS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Naffziger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bernstein</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>20 th</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Chip Multi-Processor Generator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Solomatnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Firoozshahian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Qadeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Shacham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kelley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Asgar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wachs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hameed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Horowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th Annual Design Automation Conference</title>
		<meeting>the 44th Annual Design Automation Conference</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="262" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<title level="m">Conference on VLSI Design</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Real-time H.264/avc Codec on Intel architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Iverson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mcveigh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Reese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Int. Conf. Image Processing (ICIP&apos;04)</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Analysis and architecture design of an HDTV720p 30 frames/s H.264/AVC encoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="673" to="688" />
			<date type="published" when="2006-06" />
		</imprint>
	</monogr>
	<note>Circuits and Systems for Video Technology</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A design environment for high-throughput low-power dedicated signal processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Camera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Markovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Smilkstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Ammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yeo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Augsburger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nikolic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Brodersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="420" to="431" />
			<date type="published" when="2002-03" />
		</imprint>
	</monogr>
	<note>Solid-State Circuits</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An Energy-Efficient Processor Architecture for Embedded Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Balfour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Black-Schaffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Architecture Letters</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="32" />
			<date type="published" when="2007-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Catapult C Synthesis-Based Design Flow: Speeding Implementation and Increasing Flexibility</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mccloud</surname></persName>
		</author>
		<ptr target="http://www.techonline.com/electronics_directory/techpaper/193102520" />
	</analytic>
	<monogr>
		<title level="j">Mentor Graphics Technical Library</title>
		<imprint>
			<date type="published" when="2004-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Creating power-efficient application engines for SoC design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kathail</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synfora, Inc. SoC Central</title>
		<imprint>
			<date type="published" when="2005-02-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Flexible architectures for engineering successful SOCs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rowen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Leibson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Design Automation Conf, 2004. Proceedings. 41st</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="692" to="697" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">AnySP: anytime anywhere anyway signal processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Woh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mahlke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mudge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Flautner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGARCH Comp. Arch. News</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="128" to="139" />
			<date type="published" when="2009-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Motion Estimation with IntelÂ® Streaming SIMD Extensions 4 (IntelÂ® SSE4)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Intel Corp</surname></persName>
		</author>
		<ptr target="http://software.intel.com/en-us/articles/motion-estimation-with-intel-streaming-simd-extensions-4-intel-sse4/" />
		<imprint/>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Intel SSE4 Programming Reference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Intel Corp</surname></persName>
		</author>
		<ptr target="http://softwarecommunity.intel.com/isn/Downloads/Intel%20SSE4%20Programming%20Reference.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Automated custom instruction generation for domain-specific processor acceleration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">T</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Mahlke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1258" to="1270" />
			<date type="published" when="2005-10" />
		</imprint>
	</monogr>
	<note>Computers</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Applicationspecific instruction generation for configurable processor architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 ACM/SIGDA 12th international Symposium on Field Programmable Gate Arrays</title>
		<meeting>the 2004 ACM/SIGDA 12th international Symposium on Field Programmable Gate Arrays<address><addrLine>Monterey, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<title level="m">FPGA &apos;04</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="183" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A VLSI Architecture for High-Performance CABAC Encoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shojania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sudharsanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Communications and Image Processing (SPIE), 2005. Proceedings</title>
		<imprint>
			<date type="published" when="2005-06" />
			<biblScope unit="volume">5960</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Customizable Embedded Processors: Design Technologies and Applications (Systems on Silicon)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ienne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Leupers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Xtensa LX2 Benchmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tensilica</forename><surname>Inc</surname></persName>
		</author>
		<ptr target="http://www.tensilica.com/products/xtensa-customizable/xtensa-lx2/benchmarks.htm" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tensilica</forename><surname>Inc</surname></persName>
		</author>
		<title level="m">The What, Why, and How of Configurable Processors</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Implementing the Advanced Encryption Standard on XtensaÂ® Processors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tensilica</forename><surname>Inc</surname></persName>
		</author>
		<ptr target="http://www.tensilica.com/products/literature-docs/application-notes/tie-application-notes/advanced-encryption-standard.htm" />
		<imprint/>
	</monogr>
	<note>Application note</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Implementing the Fast Fourier Transform (FFT)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tensilica</forename><surname>Inc</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Application note. [Online</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Xtensa Processor Extensions for Data Encryption Standard (DES)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tensilica</forename><surname>Inc</surname></persName>
		</author>
		<ptr target="http://www.tensilica.com/products/literature-docs/application-notes/tie-application-notes/data-encryption-extensions.htm" />
		<imprint/>
	</monogr>
	<note>Application note</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">How to Minimize Energy Consumption while Maximizing ASIC and SOC Performance&quot; White Paper</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tensilica</forename><surname>Inc</surname></persName>
		</author>
		<ptr target="http://www.tensilica.com/uploads/white_papers/Xenergy_Tensilica.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Overview of the H.264/AVC Coding Standard</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weigand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bjontegaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Luthra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<date type="published" when="2003-07" />
			<biblScope unit="volume">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<title level="m">Draft ITU-T Recommendation and Final Draft International Standard of Joint Video Specification, Joint Video Team, ITU-T Recommendation H.264 and ISO/IEC 14496-10 AVC</title>
		<imprint>
			<date type="published" when="2003-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Xtensa Energy Estimator (Xenergy) -User&apos;s Guide</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tensilica</forename><surname>Inc</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Characteristics of workloads used in high performance and technical computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cheveresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ramsay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Feucht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sharapov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st annual international conference on Supercomputing</title>
		<meeting>the 21st annual international conference on Supercomputing</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Scientific applications vs. SPEC-FP: a comparison of program behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rupnow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Underwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Compton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th annual international conference on Supercomputing</title>
		<meeting>the 20th annual international conference on Supercomputing</meeting>
		<imprint>
			<date type="published" when="2006-07-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Optimization of sparse matrix-vector multiplication on emerging multicore platforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Oliker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vuduc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shalf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yelick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Demmel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 ACM/IEEE conference on Supercomputing</title>
		<meeting>the 2007 ACM/IEEE conference on Supercomputing<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">A</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-K</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chang</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>242mw 10mm 2</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A 7mw-to-183mw dynamic quality-scalable h.264 video encoder chip</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-I</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2007 IEEE ISSCC Dig. Tech. Papers</title>
		<meeting>2007 IEEE ISSCC Dig. Tech. Papers</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">264/AVC high pro file encoder chip</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Design Automation Conference</title>
		<meeting>the 45th Design Automation Conference</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fast Integer Pel and Fractional Pel Motion Estimation for JVT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iso/Iec Mpeg &amp;amp; Itu-T</forename><surname>Vceg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JVT-F017</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Fast mode decision and motion estimation for JVT/H.264</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><forename type="middle">C</forename><surname>Tourapis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Tourapis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyce</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Image Processing</title>
		<meeting>IEEE International Conference on Image Processing</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Analysis and Architecture Design of Variable Block-Size Motion Estimation for H.264/AVC</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-Y</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Circuits and Systems</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A VLSI architecture design of an edge based fast intra prediction mode decision algorithm for h.264/avc</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ikenaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th ACM Great Lakes Symposium on VLSI</title>
		<meeting>the 17th ACM Great Lakes Symposium on VLSI</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Fully Utilized And Reusable Architecture For Fractional Motion Estimation Of H.264/Avc</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-G</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference On Acoustics Speech And Signal Processing</title>
		<meeting>IEEE International Conference On Acoustics Speech And Signal Processing</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">High-Throughput Architecture for H.264/AVC CABAC Compression System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Osorio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Bruguera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Implementation of H.264 encoder and decoder on personal computers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Communication and Image Representation</title>
		<imprint>
			<date type="published" when="2006-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Joint Video Team Reference Software JM8</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
		</imprint>
		<respStmt>
			<orgName>ITU-T</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A memory system design framework: creating smart memories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Firoozshahian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Solomatnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Shacham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Asgar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Horowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th annual international symposium on Computer architecture</title>
		<meeting>the 36th annual international symposium on Computer architecture</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Using a Configurable Processor Generator for Computer Architecture Prototyping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Solomatnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Firoozshahian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Shacham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Asgar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wachs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Qadeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Horowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 42nd Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
