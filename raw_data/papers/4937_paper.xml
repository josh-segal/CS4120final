<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T17:07+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Linux Kernel: A Challenging Workload for Transactional Memory</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hany</forename><forename type="middle">E</forename><surname>Ramadan</surname></persName>
							<email>ramadan@cs.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">J</forename><surname>Rossbach</surname></persName>
							<email>rossbach@cs.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmett</forename><surname>Witchel</surname></persName>
							<email>witchel@cs.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">The Linux Kernel: A Challenging Workload for Transactional Memory</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The Linux operating system kernel <ref type="bibr" target="#b3">[4]</ref> is a large, mature, freely available, and well-tuned concurrent program. As such it is an ideal workload for a transactional memory hardware design.</p><p>Operating systems need transactional memory for performance scalability, to help maintainability, and to provide services related to transactions to user programs. Most general purpose computing platforms run operating systems, and OS services must be scalable or applications will see the OS as a scalability bottleneck. The OS should not interfere with applications making use of the increased number of processing contexts available on modern CPUs. There has been enormous effort over the past decade to make the OS scalable, and the result has been increased code complexity that is starting to threaten continued innovation. For instance, mm/filemap.c has 50 lines of comments detailing lock ordering constraints. Finally, if the OS is to provide transaction-related services (such as supporting user-level transactions across a context switch), it could probably do so most naturally if the OS itself were implemented with transactions.</p><p>This paper raises issues about how an OS can take advantage of a transactional memory hardware system. While there have been trace-based studies of OSes on transactional hardware <ref type="bibr" target="#b0">[1]</ref>, and designs for virtualizable transactions <ref type="bibr" target="#b21">[22]</ref>, these have ignored many inter-esting issues to make running an OS on transactional hardware truly practical.</p><p>The contributions of this paper include the following observations.</p><p>• The most natural way to handle interrupts requires that a single thread of control can have multiple concurrently active transactions. Existing models do not accomodate this approach; we propose a new model called transaction stacking to enable this functionality. (Section 2) • Conflict management, the mechanism that determines which transaction must restart when two transactions conflict, is essential for performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Interrupts</head><p>Interrupts generally refer to asynchronous events, such as the countdown timer expiring, or the disk device signaling the completion of a data transfer, while exceptions refer to synchronous events like system calls and invalid opcodes. Interrupts start the OS executing from a hardware-defined location in privileged code. Interrupts can occur during the execution of the OS itself, or during execution of user code. While an interrupt is being handled, another one may be raised, even by the same device. In order to ensure forward progress interrupt handlers mask interrupts that are of equal or lower priority to the interrupt being handled.</p><p>Interrupts occur much more often that context switches-timer interrupts can fire every 1 millisecond, whereas a typical time slice for a Linux process is 100 milliseconds. Moreover, with processor speeds growing more slowly, I/O devices are poised to narrow their performance gap (e.g., through multi-gigabit network interfaces), maintaining the pressure for frequent interrupts.</p><p>User-mode programs also experience asynchronous control flow, primarily via signal handlers, which share similar issues as interrupts. However, interrupts are far more frequent in the OS than signals are at user level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Interrupts and transactions</head><p>We believe that the best way to integrate interrupt handling with transactional memory is to allow a single thread of control to have multiple active, but independent, transactions at once. We call this stacking, which is distinct from nesting because the transactions are independent. We discuss stacking in the next section.</p><p>This section considers possible OS strategies for integrating interrupt handling with transactions and demonstrates that support for stacking is necessary. Consider the arrival of an interrupt while the kernel is executing. The same thread (the OS on processor N) executes the interrupt handler in the same address space. What should the system do? Possibilities include:</p><p>• Make a rule against two active transactions in interrupt handlers. If interrupt handlers cannot actually use transactions, it is possible to simply execute the handler code. If the handler performs a memory operation that conflicts with the interrupted transaction, the hardware would abort the paused transaction after the handler returns. However, denying transactions to interrupt handlers denies an important tool for synchronization to the part of the OS that needs it the most.</p><p>• Abort the first transaction when the second one starts. This would allow the interrupting event-handler to use memory transactions. The aborted transaction must be re-executed once the event handler finishes. However, this approach aborts all interrupted transactions, whether or not there is a conflict with the interrupt handler's transaction. This approach aborts many more transactions than necessary.</p><p>• Nest the transactions <ref type="bibr" target="#b18">[19]</ref>. The problem with nesting the transactions is that there is typically no meaningful relationship between the interrupted transaction and the transactions which the interrupt handler creates. Flattening or closed nesting is not an option. If the outer transaction fails, flattening would fail the inner transaction and hence cancel the effect of receiving the interrupt. Open nesting, which would allow a parent abort to perform compensatory actions, would mean that every interrupt handler would need code to undo its effects. Were such code possible, it would be more complicated than the locking that transactions are intended to replace.</p><p>• Treat the interrupt as a context switch. Recent proposals for transactional hardware <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b21">22]</ref> have included the ability for a thread's transaction to survive across a context switch. These systems maintain overflow state on a per-process basis, enabling a transaction to be in a "swapped out" state. Virtualizable transactions <ref type="bibr" target="#b21">[22]</ref> associate a transaction data structure with each address space. This allows a thread transitioning from user to kernel code to flush its user-level transaction state to memory while it executes kernellevel transactions. The memory flush might hurt performance, but a thread can have two active transactions, one in each address space. If an interrupt arrives while the kernel is executing, then not even virtualizable transactions can help because the thread and address space are the same for both active transactions. Adding multiple context identifiers to the kernel address space to enable interrupts to be treated as context switches does not seem worth the hardware investment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Stacked transactions</head><p>We suggest a mechanism for allowing interrupt handlers to use transactional memory called stacked transactions. Stacked transactions allows multiple independent concurrent transactions in a single thread. Note that the concepts of nesting and stacking are orthogonal; one can have a stacked, nested transaction. "Stacked" is borrowed from the terminology that interrupt handlers are "stacked" on top of each other.</p><p>The mechanisms developed for allowing transactions to survive context switches can be used to implement the "stacked" transaction model, however these mechanisms were not developed with stacking in mind <ref type="figure">Figure 1</ref>. An example where an interrupt handler uses stack memory that is also used by an existing transaction A. When transaction A restarts, the stack memory has been changed from when the transaction began. A transactional memory design that allows multiple concurrent transactions for a single thread must address this issue. so it is likely that more efficient designs are possible. Because interrupt handlers usually execute with interrupts disabled, they tend to be short. It should be possible to virtualize stacked transactions with mechanisms that are less expensive than those required for virtualization of transactions across context switches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Issues for stacked transactions</head><p>The ability of a single thread of control to own multiple outstanding transactions has the potential to affect various aspects of transactional memory systems. We investigated two issues in our implementation effort: conflict management, and stack memory. Conflict management policies, the mechanisms that determine which transaction "wins" if two conflict, need to be sensitive to whether conflicting transactions are stacked. Assume the OS is executing transaction A and receives an interrupt and begins executing transaction B. If A and B conflict, the system must abort A, otherwise the system will livelock.</p><p>A second issue arises under the following circumstances: while transaction A is active, it makes a function call that returns, but some stack 1 memory values modified by the call conflict with those modified by the interrupt handler 2 . Reuse of the stack memory creates an artificial conflict between otherwise independent transactions. This is illustrated in <ref type="figure">Figure 1</ref>. If the caller started the transaction and then called the callee 3 , the callee's stack frame becomes part of the callers transaction state. This can cause a spurious conflict with an interrupt handler for an interrupt that arrives after the callee has returned. To avoid this problem software could drop the memory stack locations <ref type="bibr" target="#b0">1</ref> Note that this refers to a thread's memory stack, not to stacked transactions. <ref type="bibr" target="#b1">2</ref> This is an issue regardless of whether the interrupt handlers uses a transaction or not. <ref type="bibr" target="#b2">3</ref> In the figure the transaction starts in the callee from a transaction's set when the function returns, or the hardware might exclude these ranges from transactional sets in the first place.</p><p>A correctness issue arises if transaction A starts in a function that returns before the interrupt handler runs, as shown in <ref type="figure">Figure 1</ref>. The non-transactional writes of the interrupt handler change the state of the stack locations used by transaction A. When the handler returns, transaction A aborts, restoring its program counter and stack pointer to the values they had at the start of the transaction. Unfortunately the stack frame that was active when the transaction started has been overwritten by the interrupt handler. This problem is tricky to solve. Perhaps the top of the stack becomes part of the state checkpointed by the hardware, and is restored on a transaction retry.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Conflict management hints are essential</head><p>Transactional hardware will need to accept programmer hints for conflict resolution. For instance, an argument to xbegin, the instruction that begins a transaction, might specify whether to favor readers or writers. OS performance might require several shades of favoritism, as reader/writer spin locks naturally favor readers, but read-copy-update (RCU) <ref type="bibr" target="#b1">[2]</ref> data structures favor readers even more heavily. Other forms of favoritism, for instance a low priority transaction that defers to most other transactions, should be investigated. Kernel developers have encoded rich information about how synchronization conflicts should be resolved, and transactional synchronization would disregard that information at peril of performance.</p><p>Consider seqlocks and RCU data structures: seqlocks are designed to favor writers, while RCU data structures favor readers. Seqlocks are similar to reader/writer spinlocks, but they give higher priority to the writer. Writers may always proceed (though only one writer is allowed at a time), while readers may have to retry their operations. RCU data structures prioritize readers by avoiding reader locks for a restricted class of data structures (dynamically allocated data structures that are accessed by pointers). Writers must copy the object they wish to modify, and then atomically replace the old object with the new. Writer code can have locks and might require data structure redesign. Readers cannot sleep or be preempted.</p><p>The need for sophisticated hardware contention management is pressing in the OS because real contention can be the common case for some workloads. For instance, in our experiments we were able to induce many real data conflicts in Linux's directory entry cache (dcache) code by doing simultaneous reads and updates within a directory. Transactions are optimistic and therefore are most effective when real contention is rare. It is likely that conflict management for transactions in the OS will require some adaptation so the system does not become unresponsive when the real conflict rate spikes. During such activity conservative locking is the most effective strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Will transactional memory simplify programming?</head><p>A major benefit of transactional memory is that it simplifies reasoning about concurrent programs. The problem with this argument for Linux is that there is considerable complexity in the kernel to deal with synchronization and coordination that is not easily expressed with transactional semantics. This section discusses synchronization primitives within Linux that cannot or perhaps should not be replaced by transactional memory: per-CPU data structures and blocking primitives (semaphores, completions, and mutexes),</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Per-CPU data structures</head><p>Separating out state that does not need to be shared across processors is good design practice. Modern operating systems formalize this with the notion of per-CPU variables and data structures. Per-CPU data structures do not need to be protected against access by any other processor. Is eliminating cross-processor synchronization a worthwhile complication to the programing model? Should per-CPU data structures be turned into transactions? Doing so would keep the programming model uniform, but might harm performance. Can the transactional models leverage the fact that a variable is guaranteed not to be accessed from another processor? Per-CPU variables form a building block for complicated code. For example, the Linux kernel slab memory allocator <ref type="bibr" target="#b2">[3]</ref> uses per-CPU variables to implement a shared heap. The initial version of the slab memory allocator (slab.c) in the Linux 2.2 kernel was roughly 2,005 lines of code (2.2.26). It increased to 3,070 lines of code for the 2.6 kernel (2.6.11) <ref type="bibr" target="#b3">4</ref> . Linux maintainers note that "many of the changes in the slab allocator for 2.6 are . . . related to the reduction of lock contention." <ref type="bibr" target="#b23">[24]</ref>.</p><p>The OS disables interrupts to protect per-CPU data structures from concurrent access by threads on the same processor. Transactions can provide isolation between threads on the same CPU in simple cases, but more research is needed to determine whether transactions can eliminate the need for most of this type of interrupt disabling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Blocking operations</head><p>There is ongoing research on integration of blocking operations with a transactional model <ref type="bibr" target="#b22">[23]</ref>, for instance the transactional extensions to Concurrent Haskell <ref type="bibr" target="#b7">[8]</ref> have introduced modular blocking primitives that monitor a transaction's working set. The Linux kernel supports three different blocking synchronization primitives (semaphores, completions and mutexes), all optimized for different environmental assumptions.</p><p>Semaphores are objects that allow a certain number of waiters (usually one) into a critical section. Waiters are descheduled and placed on a queue, where they are awakened by a thread releasing the semaphore. For instance, processes queue themselves waiting for console access if they cannot get immediate access. Completions are a type of semaphore that avoid a race condition on a dynamically allocated semaphore. Mutexes <ref type="bibr" target="#b17">[18]</ref> are a smaller, faster, binary-only semaphore with more restricted use than semaphores (they were introduced in Linux 2.6.16).</p><p>Blocking primitives raise the following research questions.</p><p>• If the latency of a blocking operation is dominated by the wait, is it necessary to optimize the operation? Maybe blocking operations are fine the way they are implemented because threads spend much more time waiting for a resource to become available than they do queuing themselves for the resource.</p><p>• If transactional primitives can reduce the instruction count to grab or release a blocking object, how much does that help performance and scalability? Maybe transactions play a useful role in the implementation of blocking primitives.</p><p>• Blocking primitives can be used in complicated ways. The semaphore that protects the memory mapping data structures is tested during the frequently executed page fault handling path. Different processing happens during a page fault if the semaphore is held or not. Would a reimplementation of the semaphore need to support this kind of operation?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">I/O in transactions</head><p>Transactions must be restartable, so most proposals disallow I/O during a transaction. Our experiments revealed that Linux often performs I/O with spin locks held, thwarting an easy conversion of spin locks to use transactions. About one-third of Linux's spin locks had I/O performed at some point while they were locked. Some locks are held for long periods of time during significant I/O (e.g. the real-time clock lock during boot). We did observe that many I/O operations performed with spin locks held can be correctly re-executed with possibly small performance consequences. For instance, inter-processor interrupts (IPIs) are used to do system-wide TLB invalidations. Invalidating TLBs multiple times does not affect correctness, so it would be possible to include TLB shootdowns within a transaction, even though the transaction performs I/O. The performance consequences need to be investigated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Preliminary Results</head><p>We have early results from implementing a generic hardware transactional memory model in the Simics <ref type="bibr" target="#b14">[15]</ref> machine simulation framework (version 3.0.10). Our model implements stacked transactions, as described in Section 2.2, so that interrupt handlers are able to use transactions. We replaced the majority of spin locks in the Linux kernel, version 2.6.16.1 <ref type="bibr" target="#b4">5</ref> , with transactions. Here we discuss preliminary results using system boot as the workload.</p><p>Lock acquisition is translated to a begin transaction instruction, and the lock release is translated to an end transaction instruction. We could not replace every spin lock with a transaction. The most common problem was if a spin lock is ever held while I/O is performed. In that case, we conservatively do not convert it to use transactions. Of the 1,437 calls to spin lock in Linux, about two-thirds are for locks that are never held during I/O in the workloads we executed.</p><p>We ran experiments with 2, 4, 6, and 8 simulated processors. Our simple performance model assumes 1 instruction per cycle, and infinitely fast devices. The memory hierarchy has a two-level cache per processor, with split instruction and data caches at the L1 level and a unified L2. The L1 caches are each 16Kb, 4-way associative, with 64-byte cache lines, assuming a 1-cycle cache hit and a 16-cycle cache miss penalty. The L2 caches are 4Mb, 8-way associative, with 64-byte cache lines and a 200 cycle miss penalty to main memory. The L2's communicate using a MESI snooping protocol, and the main memory is a single shared 256 MB memory. Figure 2 compares normalized boot times for the kernel using traditional spinlocks, and transactions. The transactionalized kernel shows a modest performance gain of about 2%. These results, while preliminary, are at least encouraging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Related work</head><p>Lamport was among the first to propose that concurrent reading and writing of data need not require locks <ref type="bibr" target="#b13">[14]</ref>. Notions of optimistic concurrency control first appeared in the database domain <ref type="bibr" target="#b12">[13]</ref>, but did not gain wide acceptance in the database community <ref type="bibr" target="#b16">[17]</ref>.</p><p>Herlihy introduced the concepts of lock-free, waitfree and obstruction-free synchronization <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>, while transactional memory as a programming concept has its roots in <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b10">11]</ref>.</p><p>Among more recent research on hardware transactional memory (HTM) is Speculative Lock Elision <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>, which implements atomicity with the cache and speculatively identifies locks, and Transactional Coherence and Consistency <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b5">6]</ref>, wherein all computation is transactionalized. Unbounded Transactional Memory <ref type="bibr" target="#b0">[1]</ref> and Virtual Transactional Memory <ref type="bibr" target="#b21">[22]</ref> have addressed issues of virtualization and providing the programmer with freedom from platform-specificity and resource limitations.</p><p>Operating systems that make heavy use of nonblocking primitives include Synthesis <ref type="bibr" target="#b15">[16]</ref> and the Cache Kernel <ref type="bibr" target="#b4">[5]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Normalized boot time for an unmodified Linux compared with transactionalized Linux.</figDesc></figure>

			<note place="foot" n="4"> In the most recent version of the kernel (2.6.16.1), the code size has increased to 3,863 lines, primarily to support NUMA.</note>

			<note place="foot" n="5"> The &quot;.1&quot; release came less than a week after the 2.6.16 release, and fixes a dead-lock introduced in the kernel scheduler, among other things.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unbounded transactional memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Anaian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Asanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kuszmaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Leiserson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCA</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Using read-copy-update techniques for system v ipc in the linux 2.5 kernel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Arcangeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">E</forename><surname>Mckenney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipankar</forename><surname>Sarma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Annual Technical Conference, FREENIX Track</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="297" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The slab allocator: An object-caching kernel memory allocator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bonwick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">USENIX Summer</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Understanding the Linux Kernel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bovet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cesati</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>O ´ Reilly Media, Inc</publisher>
		</imprint>
	</monogr>
	<note>3rd edition</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The synergy between nonblocking synchronization and operating system structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Greenwald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cheriton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Programming with transactional coherence and consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hammond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Carlstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hertzberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Olukotun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS</title>
		<imprint>
			<date type="published" when="2004-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Transactional memory coherence and consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hammond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Carlstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hertzberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wijaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Olukotun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="2004-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Composable memory transactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Herlihy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Principles and Practice of Parallel Programming</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Wait-free synchronization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Herlihy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TOPLAS</title>
		<imprint>
			<date type="published" when="1991-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Obstructionfree synchronization: Double-ended queues as an example</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Herlihy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Luchangco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Moir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl Conf. on Distributed Computing Systems</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Transactional memory: Architectural support for lock-free data structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Herlihy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Moss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="1993-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An architecture for mostly functional languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Knight</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on LISP and Functional programming</title>
		<imprint>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On optimistic methods of concurrency control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Kung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">T</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Database Systems</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1981-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Concurrent reading and writing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lamport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Communications of the ACM</title>
		<imprint>
			<date type="published" when="1977-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Simics: A full system simulation platform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Magnusson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Christianson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eskilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer</title>
		<imprint>
			<date type="published" when="2002-02" />
			<biblScope unit="volume">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A lock-free multiprocessor os kernel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Massalin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Operating System Review</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Less optimism about optimistic concurrency control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mohan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In International Workshop on Res. Issues in Data Eng</title>
		<imprint>
			<date type="published" when="1992-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Why on earth do we need a new mutex subsystem, and what&apos;s wrong with semaphores?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingo</forename><surname>Molnar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Nested transactional memory: Model and preliminary architecture sketches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Moss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hosking</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Synchronization and Concurrency in Object-Oriented Languages</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Speculative lock elision: Enabling highly concurrent multithreaded execution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rajwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICRO</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Transactional lockfree execution of lock-based programs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rajwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASPLOS</title>
		<imprint>
			<date type="published" when="2002-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Virtualizing transactional memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Rajwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maurice</forename><surname>Herlihy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konrad</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd Annual International Symposium on Computer Architecture</title>
		<meeting>the 32nd Annual International Symposium on Computer Architecture</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2005-06" />
			<biblScope unit="page" from="494" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Panel: Are locks dead?</title>
		<ptr target="http://research.microsoft.com/˜tharris/scool05/" />
	</analytic>
	<monogr>
		<title level="m">SCOOL 2005</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">What to expect with the 2.6 VM</title>
		<ptr target="http://www.uwsg.iu.edu/hypermail/linux/kernel/0306.3/1647.html" />
	</analytic>
	<monogr>
		<title level="m">Linux Kernel Archive thread (Mel Gorman)</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
