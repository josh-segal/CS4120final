<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:33+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Impact of Linguistic Analysis on the Semantic Graph Coverage and Learning of Document Extracts</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jurij</forename><surname>Leskovec</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<addrLine>5000 Forbes Avenue</addrLine>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>Pennsylvania</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Jozef Stefan Institute</orgName>
								<address>
									<addrLine>Jamova 39</addrLine>
									<postCode>1000</postCode>
									<settlement>Ljubljana</settlement>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natasa</forename><surname>Milic-Frayling</surname></persName>
							<email>natasamf@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Ltd Roger Needham Bldg</orgName>
								<address>
									<addrLine>7 J J Thomson Avenue</addrLine>
									<postCode>CB3 0FB</postCode>
									<settlement>Cambridge</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marko</forename><surname>Grobelnik</surname></persName>
							<email>marko.grobelnik@ijs.si</email>
							<affiliation key="aff2">
								<orgName type="institution">Jozef Stefan Institute</orgName>
								<address>
									<addrLine>Jamova 39</addrLine>
									<postCode>1000</postCode>
									<settlement>Ljubljana</settlement>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Impact of Linguistic Analysis on the Semantic Graph Coverage and Learning of Document Extracts</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Automatic document summarization is a problem of creating a document surrogate that adequately represents the full document content. We aim at a summarization system that can replicate the quality of summaries created by humans. In this paper we investigate the machine learning method for extracting full sentences from documents based on the document semantic graph structure. In particular, we explore how the Support Vector Machines (SVM) learning method is affected by the quality of linguistic analyses and the corresponding semantic graph representations. We apply two types of linguistic analysis: (1) a simple part-of-speech tagging of noun phrases and verbs and (2) full logical form analysis which identifies Subject-Predicate-Object triples, and then build the semantic graphs. We train the SVM classifier to identify summary nodes and use these nodes to extract sentences. Experiments with the DUC 2002 and CAST datasets show that the SVM based extraction of sentences does not differ significantly for the simple and the sophisticated syntactic analysis. In both cases the graph attributes used in learning are essential for the classifier performance and the quality of extracted summaries.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Document summarization refers to the task of creating document surrogates that are smaller in size but retain various characteristics of the original document, depending on the intended use. The ultimate objective of summarization systems is to enable automatic abstracting of the document text, with all the properties that humans bring to that process. However, that task stretches beyond text analysis to domain knowledge, inference, and language generation. Most of the research has therefore been concerned with methods for text processing and extraction of textual segments that approximate human abstracts. Recently, document summarization research has been given a significant boost by the Document Understanding <ref type="bibr">Copyright © 2005</ref>, American Association for Artificial Intelligence (www.aaai.org). All rights reserved.</p><p>Conference <ref type="bibr">(DUC 2002)</ref>, which provides an experimentation framework and a forum for exchanging ideas.</p><p>Recent work by ( <ref type="bibr" target="#b7">Vanderwende et al. 2004</ref>) and ( <ref type="bibr" target="#b3">Leskovec et al. 2005</ref>) demonstrates the use of rich document semantic structure for document summarization. Both represent the document text as a semantic graph that consists of nodes representing terms and edges capturing the relations among terms. They use the graph properties to identify nodes that are useful for creating document extracts and abstracts. This approach is a significant departure from the traditional way of qualifying summary sentences using features such as the location of a sentence in a document or the appearance of specific key words in sentences, and applying heuristic scoring or machine learning techniques.</p><p>( <ref type="bibr" target="#b3">Leskovec et al. 2005</ref>) use a machine learning technique to identify sub-structures of the document semantic graph that are found in human created sentence extracts. These are then used to create document summaries by extracting full sentences from the original document text. ( <ref type="bibr" target="#b7">Vanderwende et al. 2004</ref>), on the other hand, apply a task specific scoring technique, aimed at capturing event summaries, and use a score threshold to identify substructures for generating the summary text.</p><p>In both instances, the semantic graphs are based on a sophisticated linguistic analysis which identifies subjectpredicate-object of individual sentences. This raises a question that we address in this paper: what role does linguistic analysis play in learning graph sub-structures and optimizing the quality of extracted sentences? Is it possible to relax the complexity of sentence analysis and still obtain decent summary extracts?</p><p>Our experiments show that the use of a less sophisticated linguistic analysis and the corresponding semantic representations does not affect the performance of sentence extraction. In fact, in some instances it leads to summaries with a better coverage of manually created summaries. The resulting semantic graphs typically cover a larger percentage of the document and summary text, without diluting the semantic graph properties. Indeed, the graph attributes used in learning remain essential for the performance of the classifier and sentence selection.</p><p>Our results thus open the door to more flexible and economical ways of building semantic graphs for the purpose of summarization. The proven robustness of the SVM learning algorithm seems as a good basis for tackling more challenging problems, such as cross-document summarization and generation of document abstracts.</p><p>In the following sections we introduce the basic concepts of the model, referring to the related work as appropriate. We discuss the experiment set up and the results of the subgraph learning experiments. We conclude by summarizing our results and outlining the future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Background Research</head><p>Most of the past research in automated document summarization stays within shallow text parsing and statistical processing. The latter typically involves scoring and selecting candidate sentences using heuristics based on sentence location, statistical measures of term prominence, similarity between sentences, presence of proper names or certain syntactic features in the sentence, etc. <ref type="bibr" target="#b4">(Mani 1998)</ref> and <ref type="bibr" target="#b2">(Kupiec 1995</ref>) took a more systematic approach and applied machine learning to the set of similar attributes.</p><p>Alternative approaches have been taken, for example, by <ref type="bibr">(Salton, et al. 1994</ref>) who applied information retrieval techniques to identify the topical structure of documents from the similarities between paragraphs and used it to create summaries. Recently <ref type="bibr" target="#b6">(Mihalcea 2004</ref>) combined sentence similarity with graph representation and obtained very encouraging results towards approximating human abstracts. In that model graph nodes correspond to individual sentences and the links capture sentence similarities. Each node is assigned a score based on similarity statistics and graph properties, which then facilitates the selection of nodes and summary sentences.</p><p>While these approaches focus on sentence or paragraph features, (Marcu 1999) compares the meaning of clauses in documents and human created abstracts using human subjects. He showed that, in order to compose an abstract from clauses extracted from original documents, one may have to start with a pool of clauses almost three times larger than the length of the resulting abstract. This implies that concepts that exist in both abstracts and original documents are scattered across clauses. Therefore, in order to take a step towards document abstracting, it is important to work with sub-sentence textual units. For this reason, the work by ( <ref type="bibr" target="#b7">Vanderwende et al. 2004</ref>) and ( <ref type="bibr" target="#b3">Leskovec et al. 2005</ref>) is of particular interest. In the following section we discuss NLPWin (Heidron 2000), the linguistic tool they both use to perform linguistic analysis and generate semantic graph representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Linguistic Analysis</head><p>NLPWin is a natural language processing tool which provides deep syntactic and partial semantic analysis of text. NLPWin segments the text into individual sentences and processes them in several steps, starting with the lexical and morphological analysis of individual linguistic tokens and creating a parse tree. We are particularly interested in the next phase, referred to as Portrait, in which the parse tree is analyzed to identify the correct placement of the modifier phrases ( <ref type="figure" target="#fig_0">Figure 1</ref>). In the final phase, NLPWin produces the main functional elements of the sentence, Subject-Predicate-Object, referred to as logical form triples ( <ref type="figure">Figure 2)</ref>.</p><p>We use the Portrait analysis to extract simple linguistic structures, such as noun phrases (designated as NP) and verbs. In one of the semantic graph representations we include modifiers of nouns, e.g., adjectives, as graph nodes while in others we use only normalized head nouns, e.g., for "Supreme court" we retain the head noun "court".</p><p>For the Logical Form Analysis we use the Heads of Subject, Object, and Predicate to create 'atomic' graph structures that consist of node triples or head noun nodes and Predicate edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantic Graph Construction and Analysis</head><p>Similarly to ( <ref type="bibr" target="#b3">Leskovec et al. 2005</ref>), we create document semantic graphs in the following three steps:</p><p>• Syntactic analysis of text -We use two levels of syntactic analysis from the NLPWin Portrait output: (1) <ref type="figure">Figure 2</ref>. NLPWin Logical Form shows the Subject, Object, Predicate ("confirm") nodes. In the parenthesis are semantic tags of the nodes. noun-phrase and verb detection, with part-of-speech information and (2) the logical form triple.</p><p>• Co-reference resolution -In text, different surface forms may refer to the same entity. We identify co-references for named entities, such as names of people, places, and companies by post-processing the NLPWin output.</p><p>• Semantic graph fusion -We merge the graphs of individual sentences based on the match of their nodes in normalized form and analyze the graph properties.</p><p>After the creation of the semantic graphs we determine node attributes that are used by the SVM classifier. In the final stage, when the relevant nodes are identified, we apply a sentence extraction algorithm to obtain the final selection of summary sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Creation of the Semantic Graph</head><p>From the NLPWin analysis we use three different sets of linguistic features: (ANV) -Adjectives, nouns, and verbs (NPV) -Head nouns (from noun phrases) and verbs (LF) -Heads of logical form triples. As elementary graph structures, we consider triples of linguistic terms, modeled after the logical form triples. The triples can be incorporated into the graphs in two ways. Firstly, in case of LF triples, the Predicate, i.e., verb node, can be viewed as a link between the Subject and Object nodes. Alternatively, a verb node can be treated as a node itself. In the latter case, the links are not named but could inherit linguistic relations ("Dsubj", "Dobj", in <ref type="figure">Figure 2</ref>) as in the representation by ( <ref type="bibr" target="#b7">Vanderwende et al. 2004</ref>). We thus have two graph representations for each of the three sets of linguistic features above: (NL) -NamedLink representation, where links correspond to linguistic features. In (NPV) the link refers to a verb. In the case of (ANV), where we explicitly used modifiers as nodes, links can also be nouns. (N) -Nodes representation, where links have no labels. All the linguistic terms are represented as nodes of the graph. <ref type="figure" target="#fig_1">Figures 3 and 4</ref> show the NamedLink and Nodes representations for (ANV) and (LF), for the paragraph:</p><p>"Clarence Thomas was confirmed as Supreme Court Justice in October 1991 by a razor-thin margin of 52-48. Thomas, who has opposed affirmative action, has not taken public stands on other key issues. His reputation was damaged by accusations of sexual harassment. As the youngest justice he is expected to be on the court for decades." [From DUC2002 Data set] Finally, sentences may not always produce full LF. However, such sentences may be plausible candidates for a summary sentence. For that reason we consider including not only triples but also pairs of linguistic terms. Inclusion of pairs, however, is not suitable for the NamedLink semantic graph representation because of the incomplete paths (links without nodes). Thus we consider pairs only within the Nodes representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Characterizing Graph Nodes</head><p>For each node in the graph representation, we specify a number of attributes that characterize the node. These attributes are used by the learning algorithm to differentiate the nodes that are useful for extracting document summaries from those that are not. Similarly to (Leskovec     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Learning from the Graphs</head><p>We train the linear Support Vector Machine (SVM) classifier to identify sub-structures of the semantic graphs, i.e., the node triples and pairs, that are useful for identifying sentences for document extracts. The SVM learner is applied to a rich set of attributes described above.</p><p>In fact, each type of attributes, i.e., linguistic attributes, graph attributes, and document structure attributes, are represented as sparse vectors of binary and real-valued features. Depending on the experiment, we concatenate selected attribute type vectors into a single feature vector and normalize it to the unit length. The concatenated vectors represent individual nodes in the graph. Similarly we obtain feature vectors for sub-structure elements, i.e., triples and pairs, by concatenating and normalizing the individual node feature vectors. All our experiments are conducted with the same SVM settings: the parameter C is set to 1 and J to 4. Here C controls the tradeoff between the fit to the data and the generalization of the model. The parameter J, on the other hand, enables us to weigh training errors on positive examples J times more than on negative examples. We set J to 4, aiming at a higher recall so that human extracted sentences are more likely to be included, possibly at the expense of lower precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Extracting Sentences</head><p>Once the SVM classifies the sub-structure units, i.e., triples and pairs, into summary and non-summary ones, we use them to extract sentences from the text. For a newly processed document, we score each sentence based on the confidence scores of summary triples (and pairs) it contains. In particular, we add up confidence scores of constituent summary triples and pairs, ignoring the scores of non-summary ones. From sentences that score above the classification threshold we select a predefined number of sentences for the summary. In our experiments, that number is determined as the average number of sentences in the document extracts of a particular data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>In order to evaluate the impact of various linguistic analyses on the graph properties and classification performance, we conducted experiments with several datasets and used standard evaluation measures. Almost half of these documents have human extracted sentences. These are not used in the official DUC evaluation since DUC is primarily focused on generating abstracts. Thus, we cannot make a direct comparison with DUC systems performance. However, the data is useful for the objectives of our research. Cast Data Set. CAST corpus ( <ref type="bibr">Hasler et al. 2003</ref>) contains texts from the Reuters Corpus, annotated with information that can be used to train and evaluate automatic summarization methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Sets</head><p>Four annotators marked 15% of document sentences as essential and an additional 15% as important for the summary. However, the distribution of documents across assessors was rather arbitrary, which lead to an uneven number of user judgments across documents. For that reason, in our experiments we use the set of 89 documents annotated by a single assessor, Annotator 1. We run separate experiments for extraction of short summariesdataset CAST-15%, that include sentences marked as essential, and longer summaries -dataset CAST-30%, containing sentences that are marked as essential or important. An average length article in the CAST data set contains about 29 sentences. The assessor selected on average 6 sentences for short summaries and additional 6 for longer summaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph Characteristics</head><p>Text Coverage. It is important to analyze how many sentences are, in fact, covered by semantic graphs since only those sentences that are represented by the graph are considered for learning. Furthermore, only those test sentences that produce linguistic nodes that are recognized by the system can be classified. Thus, the linguistic procedures themselves define the upper limit on the performance of the summary extraction systems. <ref type="table">Table 1</ref> shows, as expected, that the coverage of sentences increases with a simpler linguistic analysis and inclusion of node pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment Design and Evaluation Measures</head><p>Our aim is to investigate the impact of different levels of linguistic analysis on the performance of the classifier. To that end, we performed an exhaustive set of experiments that involves three data sets and, for each of them, three models of linguistic analysis (ANV), (NPV) and (LF), using NamedLink and Nodes representations of semantic graphs (see <ref type="table" target="#tab_2">Table 2</ref>). We also added pairs of nodes to the Nodes representation to see the impact of smaller substructures on the sentence extraction performance.</p><p>For each experiment, we ran 10-fold cross-validation and performed a t-test to determine statistical significance of observed differences in performance. Furthermore, during the learning procedure we varied the types of attributes associated with the graph nodes (see <ref type="table" target="#tab_5">Table 5</ref>, for example). Evaluation Measures. For each experiment we present the standard precision and recall measures that capture the percentage of correctly extracted summary sentences for the fixed length summary. We also report the corresponding F1 measure, defined as a harmonic mean of the two statistics. All the statistics are micro-averaged over the instances of sentence classification.</p><p>In addition, we determine the word coverage of human extracts achieved by our extracted summaries. Even if the system fails to extract the correct sentence, it is important to assess whether the extracted sentence is close in content to the correct one. We thus calculate the overlap between automatically extracted summaries and human extracted summaries using ROUGE, a measure adopted by DUC. ROUGE is recall oriented, based on n-gram statistics, and found to be highly correlated with human evaluations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment Findings</head><p>Robustness of the SVM Classifier. SVM classifier learns equally well from both the simple and more sophisticated linguistic analysis. <ref type="table" target="#tab_1">Table 3</ref> shows typical results on the three data sets that we used. The sentence extraction does not suffer from simpler linguistic analysis. In fact, on DUC 2002 data, learning from the simplest linguistic model (ANV -adjective, noun, verb) performs equally as well as the LF representation, according to the F1 measure. The ROUGE score for ANV, in fact, shows a statistically significant increase over the LF score. Robustness of the Graph Properties. Increasing the coverage of summary sentences, by relaxing the linguistic analysis and combining pairs and triples of linguistic nodes, does not seem to dilute the value of graph properties or negatively affect sentence extraction. <ref type="table" target="#tab_4">Table 4</ref> shows the results for DUC 2002 data. The F1 measure, which captures the sentence level performance, is not significantly affected. The ROUGE score, measuring the word level   <ref type="table" target="#tab_5">Table 5</ref> shows a subset of experiments that verify the individual contribution of attribute types to the performance of the summarizer. Adding graph attributes to document structure (referred to as Position) and linguistic attributes systematically helps sentence extractions across different linguistic analyses. For example, the difference in the ROUGE scores for LF and ANV <ref type="table" target="#tab_5">(Table 5</ref>) and the two sets of attributes is statistically significant. Similar behavior is observed with the Cast datasets. This confirms that semantic graphs associated with simpler analyses (e.g., ANV) are amenable to learning of relevant semantic nodes and can produce improved sentence extracts <ref type="table" target="#tab_5">(Table 5</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Concluding Remarks</head><p>In this paper we investigated several aspects of the document summarization technique that involves creating a semantic graph of the document and training a SVM classifier to identify relevant structures for summary extracts. We demonstrated that it is possible to achieve comparable and often improved summary extracts by applying a simple linguistic analysis and building semantic graphs based on resulting triples and pairs. Reducing the complexity of syntactic analysis yields a wider coverage of document and summary texts. On one hand we expect increase in performance since more examples are used in SVM training and more of test summary sentences are processed by the system. On the other, semantic graphs with simple and possibly less distinctive nodes may cause degradation of the learning process and poorer summaries. Thus, it was important to establish empirically which of these factors prevail. We show that the SVM is robust and learns well from simpler linguistic analyses while graph attributes remain essential in improving the node classification and summary extraction across all of the experiments. We expect that robustness of the SVM will prove useful in addressing more challenging tasks of cross document summarization and creation of document abstracts.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DUC 2002</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Parse tree from the NLPWin Portrait analysis for the sentence: "Clarence Thomas was confirmed as Supreme Court Justice in October 1991".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Two graph representations, NamedLink and Nodes, for the basic linguistic analysis: attributes, nouns, and verbs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>(</head><label></label><figDesc>a) NamedLink (NL) representation of the (ANV) analysis. Link names are indicated in darker (blue) boxes. (b) Nodes (N) representation of the (ANV) analysis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. NamedLink and Nodes representation for the Logical Form analysis, showing heads of the Subject, Predicate and Object terms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>(</head><label></label><figDesc>a) NamedLink (NL) representation of the (LF) analysis. Link names are indicated in darker (blue) boxes (b) Nodes (N) representation of the (LF) analysis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>DUC2002 Data Set.</head><label></label><figDesc>DUC 2002 is one of the document collections provided by the Document Understanding Conference (DUC). Since we are looking at the problem of extracting summary sentences, we use a training part of the DUC 2002 data, which consists of 300 newspaper articles on 30 different topics, collected from Financial Times, Wall Street Journal, Associated Press, and similar sources.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head></head><label></label><figDesc>in the document and the location of the triple or the pair within the sentence. These values are assigned to the corresponding nodes. We also determine the frequency and location of the word inside the sentence, and the number of different senses of the word.</figDesc><table>at al. 2005) we use three types of attributes: linguistic 
attributes, graph attributes, and text location statistics, 
which approximate a discourse structure of the document. 
Linguistic attributes. For each node, NLPWin provides 
part-of-speech tags and about 70 semantic tags (e.g., 
gender, location name, person name, etc.). We use in total 
118 distinct linguistic attributes for each node. 
Graph attributes. For each node in a semantic graph we 
calculate the number of incoming and outgoing links, Hubs 
and Authorities and PageRank weights (Page et al. 1998). 
We include statistics on the number of nodes reachable in 
2, 3, and 4 hops away, respectively, and the total number of 
reachable nodes. Altogether there are 14 distinct graph 
attributes calculated for each node in the semantic graph. 
Document structure attributes. For each elementary sub-
structure, a triple or a pair, we consider the location of the 
corresponding sentence </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 3 .</head><label>3</label><figDesc>Comparison of the three linguistic analyses, using only node triples, for the summaries of predefined length. Graph representation is NamedLinks. We used all attributes for learning.</figDesc><table>DUC 2002 
Semantic 
Structure 
Prec. 
Recall 
F1 
Rouge 

ANV 
0.39 
0.40 
0.40 
0.67 
NPV 
0.37 
0.39 
0.38 
0.65 
LF 
0.40 
0.40 
0.40 
0.64 

CAST-30% 
Semantic 
Structure 
Prec. 
Recall 
F1 
Rouge 

ANV 
0.43 
0.57 
0.49 
0.67 
NPV 
0.41 
0.66 
0.50 
0.63 
LF 
0.42 
0.67 
0.52 
0.66 

CAST-15% 
Semantic 
Structure 
Prec. 
Recall 
F1 
Rouge 

ANV 
0.44 
0.44 
0.44 
0.64 
NPV 
0.48 
0.47 
0.48 
0.61 
LF 
0.45 
0.44 
0.45 
0.61 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 .</head><label>2</label><figDesc></figDesc><table>Experiment design involves four different dimensions. 
A mixture of node triples and node pairs was used to create only 
the Nodes representation of the semantic graph. 

Data Set 
Linguistic 
Analysis 

Graph 
Representation 

Sub-structure 
units 

DUC 
CAST-15% 
CAST-30% 

ANV 
NPV 
LF 

NamedLinks 
Nodes 

Triples 
Triples+Pairs 
(for Nodes) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 4 .</head><label>4</label><figDesc>Comparison of the three linguistic analyses, with and without node pairs included in the graph. The results are for the Nodes only representation, using all attributes for learning.</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 .</head><label>5</label><figDesc></figDesc><table>Comparison of the three linguistic analyses, with varied 
attribute sets for graph nodes. The results are shown for the 
NamedLink graph (from triples), for fixed length summaries. 

DUC 2002 
Semantic Struct. 
Attributes 
Prec. Recall 
F1 
Rouge 

ANV with 
Pos + Ling 
0.27 
0.58 
0.37 
0.65 

ANV with 
Pos + Ling + Graph 
0.39 
0.40 
0.40 
0.67 

NPV with 
Pos + Ling 
0.37 
0.35 
0.36 
0.62 

NPV with 
Pos + Ling + Graph 
0.37 
0.39 
0.38 
0.65 

LF with 
Pos + Ling 
0.26 
0.61 
0.36 
0.62 

LF with 
Pos + Ling + Graph 
0.40 
0.40 
0.40 
0.64 </table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Orasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mitkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<ptr target="http://tides.nist.govHasler" />
		<title level="m">Building better corpora for summarization. Corpus Linguistics&apos;03</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>Document Understanding Conference</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Intelligent Writing Assistance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">G</forename><surname>Heidron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Natural Language Processing</title>
		<editor>Robert Dale, Herman Moisl, and Harold Somers, Marcel Dekker</editor>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Trainable Document Summarizer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kupiec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pederson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SIGIR&apos;95</title>
		<meeting>of SIGIR&apos;95</meeting>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Extracting Summary Sentences Based on the Document Semantic Graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Milic-Frayling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grobelnik</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<idno>TR-2005-07</idno>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
<note type="report_type">Microsoft Technical Report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bloedorn</surname></persName>
		</author>
		<title level="m">Machine Learning of Generic and User-Focused Summarization. AAAI&apos;98</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The automatic construction of large-scale corpora for summarization research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marcu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page">99</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Graph-based ranking algorithms for sentence extraction, applied to text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automatic Analysis, Theme Generation, and Summarization of Machine-Readable Texts. Science, 264</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Winograd T. ; G</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vanderwende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Menezes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Digital libraries project report</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
		<respStmt>
			<orgName>Stanford University. Salton,</orgName>
		</respStmt>
	</monogr>
	<note>The PageRank citation ranking: Bringing order to the web. Event-Centric Summary Generation. DUC&apos;04</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
