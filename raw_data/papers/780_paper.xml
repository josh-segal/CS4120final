<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Linear Programming Boosting for Uneven Datasets</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jurij</forename><surname>Leskovec</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Jozef Stefan Institute</orgName>
								<address>
									<settlement>Ljubljana</settlement>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jurij</forename><surname>Leskovec@ijs</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Jozef Stefan Institute</orgName>
								<address>
									<settlement>Ljubljana</settlement>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Si</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Jozef Stefan Institute</orgName>
								<address>
									<settlement>Ljubljana</settlement>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Shawe-Taylor</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Royal Holloway University of London</orgName>
								<address>
									<settlement>Egham</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Linear Programming Boosting for Uneven Datasets</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>The paper extends the notion of linear programming boosting to handle uneven datasets. Extensive experiments with text classification problem compare the performance of a number of different boosting strategies, concentrating on the problems posed by uneven datasets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Boosting is a method of combining so-called weak learners that individually only perform slightly better than a random classifier into a weighted combination that classifies with high accuracy. In general boosting has been shown to exhibit a remarkable resistance to overfitting. An explanation for this phenomenon suggests that this results from boosting optimising the margin of the underlying weighted combination of weak learners <ref type="bibr" target="#b10">[10]</ref>.</p><p>This interpretation has suggested a number of modifications of the underlying boosting strategy through changing the measure of the margin distribution that is optimised <ref type="bibr" target="#b8">[8]</ref>. Taking a 1-norm of the slack variables and optimising the 1-norm of the coefficients leads to a linear programme. If this is solved by so-called column generation, the resulting algorithm can be seen as a boosting algorithm <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>, where the primal solution gives the weightings of the weak learners and the dual solution the distributions over examples.</p><p>The question of how to adapt boosting to handle uneven training sets was considered by Karakoulas and Shawe-Taylor <ref type="bibr" target="#b7">[7]</ref>. They introduced the U-boost algorithm that biased the distribution weighting in favour of the examples from the smaller class.</p><p>The aim of the current paper is to introduce a version of the linear programming boosting that is tuned for uneven datasets. This is a natural approach to handling uneven datasets as the algorithm optimises a cost criterion that can be adapted to reflect the unevenness of the dataset.</p><p>At the same time we present extensive experiments comparing a number of different boosting strategies and methods of weak learner generation. Our main test bed for the experimental work is the Reuters document collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Boosting algorithms</head><p>In this section we introduce the boosting algorithms considered in our experiments, including the adaptation of the linear programming algorithm for uneven datasets.</p><p>Boosting is a method to find a highly accurate classification rule by combining many weak or base hypotheses. Each weak hypothesis may be only moderately accurate. Weak learners are trained sequentially. Each weak learner is trained on examples which the preceding weak learners found most difficult to classify.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">AdaBoost</head><p>Let S = (x 1 , y 1 ), . . . , (x m , y m ) be a set of training examples. Each instance x i belongs to a domain X and has assigned a single class y i . Each class y i belongs to a finite label space Y. In this paper we focus on binary classification problems in which Y = {−1, +1}. We call examples having y i = +1 positive and those having y i = −1 negative examples.</p><p>A weak learning algorithm accepts as input a sequence of training examples S and a distribution D t (where D t (i) could be interpreted as the misclassification cost of the i-th training example). Based on this input the weak learner outputs a weak hypothesis h. We interpret the sign of h(x) as the predicted label and the magnitude |h(x)| as the confidence in that prediction. The parameter α t is chosen to measure the importance Proceedings of the Twentieth International Conference on Machine Learning <ref type="bibr">(ICML-2003)</ref>, <ref type="bibr">Washington DC, 2003.</ref> Given β and a training set: S = (x 1 , y 1 ), . . . , (x m , y m ) where</p><formula xml:id="formula_0">x i ∈ X , y i ∈ {−1, +1} Initialise: D 1 (i) = 񮽙 w + if y i = +1 w − else where w + w − = β and 񮽙 m i=1 D 1 (i) = 1 For t = 1, . . . , T :</formula><p>Pass distribution D t to weak learner Get weak hypothesis h t :</p><formula xml:id="formula_1">X → R Choose α t ∈ R Update: D t+1 (i) = Dt(i) exp(−αtβiyiht(xi))</formula><p>Zt where β i = 1 β if y i = +1 and 1 if otherwise, and Z t is a normalization factor Output the final hypothesis: of the weak hypothesis h t in the final linear combination of weak hypotheses.</p><formula xml:id="formula_2">f (x) = 񮽙 T t=1 α t h t (x)</formula><p>At each round of boosting AdaBoost <ref type="bibr" target="#b11">[11]</ref> increases the weights of wrongly classified training examples (i.e. if the signs of h t and y i differ) and decreases the weights of correctly classified examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">AdaUBoost</head><p>A common scenario when learning on imbalanced data sets is that the trained classifier classifies all examples to the major class. In text classification we often encounter this problem when we are learning a binary classifier to separate a small topic from the rest of the documents. In order to avoid this problem, we would like to emphasise the importance of the smaller class. We assume that the smaller class is the positive class while the dominant class is the negative one.</p><p>AdaUBoost <ref type="bibr" target="#b7">[7]</ref> utilises most of the ideas of AdaBoost <ref type="bibr" target="#b11">[11]</ref>, but introduces an unequal loss function and modified weight updating rule. The choice of a parameter β will force uneven misclassification costs for training examples (figure 1).</p><p>Examples from the smaller, positive, class will initially get assigned β times larger weights than negative examples. The parameter β will also guide the weight updating rule to increase the weight of false negatives more aggressively than of false positives. On the other hand it will decrease the weights of true positives more conservatively than of true negatives. Under this updating rule the weights of positive examples typically maintain higher values. Each weak hypothesis therefore tends to correctly classify more positive examples, since they maintain higher weights. The final hypothesis, a linear combination of the weak hypotheses, will also correctly classify more positive examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">LPBoost</head><p>LPBoost <ref type="bibr" target="#b4">[5]</ref> is a linear program (LP) approach to boosting. The paper <ref type="bibr" target="#b4">[5]</ref> shows that taking a 1-norm of the slack variables and optimising the 1-norm of the coefficients leads to a linear programme. If this is solved by so-called column generation, the resulting algorithm can be seen as a boosting algorithm <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>, where the primal solutions give the weightings of the weak learners and the dual solutions the distributions over examples.</p><p>LPBoost iteratively optimises dual misclassification costs and dynamically generates weak hypotheses to make new LP columns. In contrast to gradient boosting algorithms, which may only converge in the limit, LPBoost converges in a finite number of iterations to a globally optimal solution satisfying well-defined optimality conditions.</p><p>One would expect LPBoost to be computationally expensive. We found, however, that an iteration of LPBoost is slightly more expensive than an iteration of AdaBoost, but on the other hand LPBoost needs far fewer iterations than AdaBoost to converge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">LPUBoost</head><p>The LPBoost algorithm <ref type="bibr" target="#b4">[5]</ref> is motivated from a generalisation analysis that bounds the test error in terms of the 1-norm of the vector of coefficients, margin achieved and the slack variables. The minimisation of the bound leads to a Linear Programme that gives the formulation above when converted to the dual.</p><p>We now give a similar motivation for the uneven version of the LPBoost algorithm, we have named LPUBoost. In this case we assume that the cost of misclassifying a positive example (assuming that the positive class is the less populated) is larger than that of misclassifying a negative example. Hence, the loss L f associated with a classification function f is given by</p><formula xml:id="formula_3">L f (x, y) = βP (f (x) ≤ 0 and y = 1) +P (f (x) ≥ 0 and y = −1),</formula><p>where as with AdaUBoost β &gt; 1 gives the higher cost of misclassification of positive examples. We can upper bound this loss as follows</p><formula xml:id="formula_4">L f (x, y) ≤ β(1 + y) 2ρ (ρ − f (x)) + + 1 − y 2ρ (f (x) + ρ) + ,<label>(1)</label></formula><p>where ρ &gt; 0 and (·) + denotes the function that is the identity if its argument is greater than 0 and 0 otherwise. We can now apply the Rademacher technique <ref type="bibr" target="#b0">[1]</ref> Given β and a training set: S = (x 1 , y 1 ), . . . , (x m , y m ) where to bound the loss in terms of its empirical value and the Rademacher complexity of the function class. The Rademacher complexity of a class does not increase if we move to its convex hull and so the bound involves the 1-norm of the slack variables scaled by the inverse margin plus the Rademacher complexity of the weak learners again scaled by the inverse margin. We omit the details because of space constraints. The resulting bound is optimised by the following Linear Programme: For LPUBoost we take the same LP formulation of boosting as in LPBoost, but we introduce a new parameter β having the same role as in AdaUBoost. Positive examples have a β times higher bound on their misclassification costs</p><formula xml:id="formula_5">x i ∈ X , y i ∈ {−1, +1} Initialise: α = 0, n = 0, β LP = 0 u i = 񮽙 w + if y i = +1 w − otherwise where w + w − = β and 񮽙 m i=1 u i = 1 Repeat n = n + 1 Pass distribution D t to weak learner Get weak hypothesis h n : X → R Check for optimal solution: if 񮽙 m i=1 u i y i h n (x i ) ≤ β LP then n = n − 1, break Solve restricted master for new costs: argmin (u,βLP) β LP subject to 񮽙 m i=1 u i y i h j (x i ) ≤ β LP , j = 1, . . . , n and 񮽙 m i=1 u i = 1 and D 񮽙+ ≤ u i ≤ D + , if y i = +1 D 񮽙− ≤ u i ≤ D − , otherwise, i = 1, . . . , m End α = Lagrangian multipliers from last LP Output the final hypothesis: f (x) = 񮽙 n j=1 α j h j (x)</formula><formula xml:id="formula_6">min α,ρ,ξ + ,ξ − −ρ + D 񮽙 β 񮽙 m i=1 ξ + i + 񮽙 m i=1 ξ − i 񮽙 subject to y i 񮽙 n j=1 α j h j (x i ) ≥ ρ − ξ yi i , ξ + i , ξ − i ≥ 0, i = 1, . . . , m α j ≥ 0, j = 1, . . . , n and 񮽙 m i=1 α i = 1.</formula><formula xml:id="formula_7">u i ( D 񮽙+ D 񮽙− = D + D − = β).</formula><p>The choice of parameter D LB controls the lower bound on the misclassification cost u i . We could set it to 0, but we rather set D − = 1 mν , where ν ∈ (0, 1), and</p><formula xml:id="formula_8">D − D 񮽙− = D + D 񮽙+ = D LB .</formula><p>The problem we observed is the sensitivity of LP and LPU boost to the value of parameter ν, which has to be tuned with some care to obtain a good convergence rate.</p><p>LPUBoost combines AdaUBoost having an uneven loss function and LPBoost having a well-defined stopping criterion with a mechanism to prevent overfitting. This makes LPUBoost a good algorithm for learning on uneven training sets: maintaining higher weights on positive examples while using an LP to obtain an optimal combination of weak hypotheses with respect to a well-motivated optimisation criterion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Weak learning algorithms</head><p>A weak learning algorithm is a procedure for computing weak hypotheses. Boosting finds a set of weak hypotheses by repeatedly calling a weak learning algorithm. The weak hypotheses are linearly combined into a single rule. The input of the weak learning algorithm is a distribution or vector of weights (misclassification costs), and a training data set. Weak learning algorithms use the weights to find a weak hypothesis which has a moderately low error with respect to the weights.</p><p>Due to the weight updating rule examples which are hard to classify will get incrementally higher weights while the examples easy to classify get lower weights. The effect is to force the subsequent weak learners to concentrate on hard-to-classify examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">AdaBoost.MH class of weak hypotheses</head><p>Boosting is a general purpose method that can be combined with any weak learner. In practice it has been combined with a wide variety of classes including decision trees and neural networks.</p><p>In this paper we focus on boosting using very simple classifiers. All classifiers considered in this section have the form of a one level decision tree (if-then rule). The test is to check for the presence of a word in a given document. Based on the presence of the word the weak hypothesis outputs a prediction. We interpret the sign of the prediction as a predicted class (recall we are dealing with binary problems) and the magnitude of the output as the confidence in that prediction.</p><p>For example: if we try to predict which documents belong to the Sports category, we will train a classifier to make a distinction between Sports documents (positive class) and the rest of the documents (negative class). Then our weak hypothesis could be a rule: "if the word football occurs in a document, then we are highly confident the document belongs to Sports category. On the other hand, if football does not occur in a document then we predict the document does not belong to the Sports category with low confidence."</p><p>Formally, we write w ∈ x to mean a term w occurs in document x. So we define a weak hypotheses h which makes predictions:</p><formula xml:id="formula_9">h(x) = 񮽙 c + if w ∈ x c − if w / ∈ x<label>(2)</label></formula><p>where c + and c − are real numbers.</p><p>Let us also define: given a current distribution D t and a term w: let X + be a set of documents having the term w, X + = {x : w ∈ x}, X − = {x : w / ∈ x} and b, l ∈ {+, −} then we calculate W has−word class :</p><formula xml:id="formula_10">W b l = 񮽙 xi∈X b ∧yi=l D t (i)<label>(3)</label></formula><p>The weak learners presented in this subsection all have the same form of weak hypotheses, but they impose different restrictions on the values c + , c − and α t and use different criterion to choose a weak hypothesis at each round of learning.</p><p>At each round of learning our weak learners search all possible terms. For each term, the values c + and c − and a score are assigned to that particular weak learner. After all terms have been searched, a learner with best score is chosen. Different weak learners use different scores.</p><p>For AdaBoost.MH a bound on empirical loss (fraction of misclassified examples) has been proven by Schapire and Singer <ref type="bibr" target="#b11">[11]</ref>. They showed that the Hamming loss (MH stands for minimum Hamming loss) of the boosted function obtained using AdaBoost.MH is at most 񮽙 T t=1 Z t , where Z t is a normalization factor at round t. This upper bound can be a used as a guideline for choosing α t and the design of the weak learning algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Real AdaBoost.MH</head><p>The first algorithm is called AdaBoost.MH (Real.MH) with real-valued predictions <ref type="bibr" target="#b12">[12]</ref>. We permit c + and c − to be unrestricted real valued predictions.</p><p>It was shown in <ref type="bibr" target="#b11">[11]</ref> that Z t is minimised by choosing</p><formula xml:id="formula_11">c b = 1 2 ln 񮽙 W b + W b − 񮽙<label>(4)</label></formula><p>and setting α t = 1 implies that:</p><formula xml:id="formula_12">Z t = 2 񮽙 񮽙 W + + W + − + 񮽙 W − + W − − 񮽙<label>(5)</label></formula><p>Thus we choose the term w for which Z t has the minimal value. As suggested in Schapire and Singer <ref type="bibr" target="#b12">[12]</ref> we smooth the values of c b to limit the magnitudes of predictions</p><formula xml:id="formula_13">c b = 1 2 ln 񮽙 W b + + 񮽙 W b − + 񮽙 񮽙 (6) We use 񮽙 = 1 m . Since W b + and W b − ∈ [0, 1], this bounds |c b | by roughly 1 2 ln(1//).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Disc AdaBoost.MH</head><p>AdaBoost.MH with discrete predictions (Disc.MH) forces the predictions c b of the weak hypothesis to be either +1 or −1. This is a more traditional setting where predictions do not carry confidences, and α t is a measure of confidence in the weak hypothesis. We still minimise Z t for a given term w. Using the same notation as introduced in the previous section, we set:</p><formula xml:id="formula_14">c b = sign(W b + − W b − )<label>(7)</label></formula><p>We can interpret the choice of c b as a weighted majority vote over training examples. Let r t = |W + + − W + − | + |W − + − W − − |, then it can be shown <ref type="bibr" target="#b11">[11]</ref>, that in order to minimise Z t we should choose:</p><formula xml:id="formula_15">α t = 1 2 ln 񮽙 1 + r t 1 − r t 񮽙<label>(8)</label></formula><p>giving Z t = 񮽙 1 − r 2 t . So we choose a weak hypothesis (a term w) which has the smallest Z t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">Disc and Real AdaBoost.LP</head><p>The LPBoost algorithm <ref type="bibr" target="#b4">[5]</ref> (see Section 2.3) suggests that at each round of boosting a weak hypothesis h with maximal sum of misclassification costs D t multiplied by class value y i ∈ {−1, +1} and prediction h:</p><formula xml:id="formula_16">DtSum = m 񮽙 i=1 D t (i)h(x i )y i<label>(9)</label></formula><p>should be chosen. Since this is a different criterion for choosing the best weak-hypothesis in AdaBoost.MH, we obtain two new weak learners. We call them Real.LP and Disc.LP. They differ from AdaBoost.MH in the way weak hypothesis is chosen, instead of minimising Z t , DtSum is maximised.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4.">Disc and Real AdaBoost.U</head><p>Karakoulas and Shawe-Taylor in their paper on boosting imbalanced training sets <ref type="bibr" target="#b7">[7]</ref> proposed a new method for calculating Z t and choosing α t .</p><p>Note that in case of an uneven loss function (AdaUBoost, LPUBoost) we have an additional parameter β. Positive examples will get β times higher weight than negative examples. The parameter β will also guide the weight updating rule to increase the weight of false negatives more aggressively than of false positives. We define Z t as:</p><formula xml:id="formula_17">Z t (α t ) = m 񮽙 i=1 D t (i) exp (−α t β i h t (x i )y i )<label>(10)</label></formula><p>where β i = 1/β if y i = +1 and 1 if otherwise. To minimise the error we seek to minimise Z t with respect to α t . By taking the first derivative of <ref type="formula" target="#formula_4">(10)</ref> and equating it to zero and introducing notation</p><formula xml:id="formula_18">W c,p = 񮽙 m i=1 D t (i)|y i = c ∧ h(x i ) = p, where c, p ∈ {−1, +1}, we get: − exp(−α t /β)W ++ /β + exp(α t /β)W −+ /β + exp(α t )W +− − exp(−α t )W −− = 0. Substituting Y = exp(α t )</formula><p>we obtain:</p><formula xml:id="formula_19">C 1 Y 1−1/β + C 2 Y 1+1/β + C 3 Y 2 + C 4 = 0<label>(11)</label></formula><p>where</p><formula xml:id="formula_20">C 1 = −W ++ /β, C 2 = W −+ /β, C 3 = W +− , C 4 = −W −− .</formula><p>The root of equation <ref type="formula" target="#formula_4">(11)</ref> can be found numerically. Z 񮽙񮽙 t (α t ) &gt; 0 implies Z t (α t ) is convex and has only one minimum.</p><p>A weak hypothesis h with minimal Z t is chosen. This is another way of calculating α t and two new weak learners can be obtained (Real.U, Disc.U). They differ from AdaBoost.MH only in the way Z t is calculated and for discrete learners we set α t to be the solution of (11) which minimises Z t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental evaluation</head><p>The following sections describe the experimental setup. We also describe and analyse experiments performed using the four boosting algorithms and six text categorization weak learners that were described in the previous sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental setup</head><p>We performed empirical evaluation on the ModApte split of the Reuters-21578 dataset compiled by David Lewis. The split consists of 12, 902 documents of which 9, 603 are used for training and 3, 299 for testing.</p><p>The following preprocessing was performed: all words were converted to lower case and punctuation marks  <ref type="formula" target="#formula_10">(538)</ref>  were removed. We removed stop words from a list of 523 English words. We used the Porter stemmer <ref type="bibr" target="#b9">[9]</ref> and retained only those terms having document frequency larger than 3. After the preprocessing the corpus contained 6, 242 distinct features (terms).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>We compare some of the results with Support Vector</head><p>Machines <ref type="bibr" target="#b3">[4]</ref>. We used the SV M light <ref type="bibr" target="#b5">[6]</ref> implementation of SVM with a linear kernel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Performance on Reuters categories</head><p>Based on category size we have chosen a set of 16 Reuters-21578 categories. Some of them are large (earn, acq) and some really small (potato, platinum) having only a few examples.</p><p>We trained boosting binary classifiers to make predictions whether a document belongs to a category or not. We assigned all documents having the category a positive class and all other documents a negative class.</p><p>We ran a set of 120 experiments for a single Reuters category using combinations of all the described boosting algorithms and weak learners. In all experiments a number of rounds of learning was set to 300. We tested the combinations of the following parameters: ν: 0.1, 0.2; D LB : 0, 10, 50, 100; β: 2, 4, 8.</p><p>For each boosting algorithm we display the best experiment using the standard information retrieval F1 score on the test dataset. We realise that choosing the best performance on the test set invalidates their status. But the aim of this experiment was to get the idea about the best possible performance (upper bound) of various algorithms. <ref type="table" target="#tab_0">Table 1</ref> shows results for chosen categories.   As we can see from the averages LPUBoost (LPU) is dominant, followed by the LPBoost (LP) and AdaUboost (U). AdaBoost (Ada) and linear SVM are far behind. On large categories Ada, U and SVM are a little better than LP and LPU, but as we move to smaller categories the qualities of LPU (and also LP and U to some extent) seem to appear. AdaUBoost has the feature of uneven loss function which helps and LPBoost has the mechanism to find an optimal combination of weak hypotheses; both these features are combined in LPUBoost.</p><p>On small categories Ada and U overfit the training data ( <ref type="figure" target="#fig_4">figure 3</ref>). AdaUBoost is more resistant to overfitting than AdaBoost. On the other hand the performance of LP and LPU on the training set decreases with decreasing category size, but on the test set it remains at about the same level. We can see that LP and LPU are superior to Ada and SVM while U does a little worse than LP and LPU.</p><p>Secondly we performed the same set of 120 experiments using stratified 5 fold cross validation. Based on average F1 score over 5 trials, we have chosen best parameter configuration for each algorithm. <ref type="table" target="#tab_1">Table 2</ref> shows the average F1 on test set.</p><p>We can see that results obtained by cross validation <ref type="table" target="#tab_1">(table 2)</ref> are not far from the optimal <ref type="table" target="#tab_0">(table 1)</ref>. For algorithms with a small set of parameters (AdaBoost, SVM) the difference between optimal and cross validation performance is small. There is a surprisingly large gap for U and even larger for LP.</p><p>SVM performs best of all algorithms on categories with more than 1% of positive training examples, but as we decrease the category size it is no more competitive. LPUBoost performs best and not far from optimal. We also observed that optimal parameter settings are different from those obtained by cross validation. Performance of LPUBoost is quite stable on the whole range of categories of various sizes. <ref type="figure" target="#fig_6">Figure 4</ref> shows typical learning curves of boosting algorithms. In the top row we see the typical performance of AdaBoost on large categories and the oscillations we noticed in AdaUBoost. The bottom row shows LP and LPU. We observe larger jumps in performance than for instance with Ada or U. Typically at the early rounds of learning LP (LPU) is not stable, but when we move forward performance gets more stable, when finally the algorithm converges. LP and LPU use many fewer weak hypotheses than Ada or U . We trained Ada and U for 300 rounds (300 weak hypotheses were chosen). LP and LPU converged in around 50 rounds for large and around 5 or less rounds of learning for small categories. For some of the smallest categories LPU picked just 1 or 2 weak hypotheses and made no error -for category platinum it is sufficient to check for the presence of a word platinum in order to make perfect predictions.</p><p>Considering chosen weak learners we see Real.MH gives best performance for most of the categories. This is in accordance with the results reported in <ref type="bibr" target="#b12">[12]</ref>.</p><p>Real.MH is followed by Disc.MH and Real.LP. Special weak learners did not improve the performance -not even in combination with the boosting algorithm they were designed to work together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Discarding positive training examples</head><p>We took 2 largest categories: earn and acq. Training set consists of all negative and a number of randomly selected positive training examples. Test set is unchanged. By selecting a number of positive training examples we artificially created a small category.</p><p>We performed the same set of 120 experiments as in section 4.2. For each boosting algorithm we display the best experiment using the F1 score on the test set. This means we show the upper bound of the algorithm. <ref type="figure" target="#fig_7">Figure 5</ref> shows the results which are surprising. Previous experiments showed that LPU is best on uneven training sets, because it does not overfit and picks a sufficiently small number of weak learners. But <ref type="figure" target="#fig_7">figure 5</ref> shows a different picture. As the number of positive training examples decreases, the performance of LPU (LP) also dramatically decrease, but the performance of U (Ada) remains almost at the same level.</p><p>We observed almost the same things with acq: U is still the best, closely followed by LPU. Performance of Ada and LP is poor and after the number of positive training examples drops bellow 50, F1 is less than 0.1.</p><p>Since experiment showed that the best possible performance of LP and LPU are far behind from Ada and U, we didn't run stratified cross validation.</p><p>LPU (LP) performed very well on naturally uneven datasets. But when we artificially create an small category, the performance of LPU decreased dramatically.</p><p>This suggests that there is a fundamental difference between naturally small and artificially small categories. We think that Reuters' editors categorizing documents made earn very diverse (broad and not specific), while a small category like platinum is very specific. Note that the test set is unchanged so it resembles original category (has the same distribution as original category). To make good predictions using small training (and large diverse testing) earn one has to "overfit" by taking all (not necessarily significant) features of the training data. On the other hand we have to be very careful and take only really significant features to make good predictions on platinum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>This paper introduces LPUBoost boosting algorithm. We provide both theoretical and empirical evidence that LPUBoost is well suited for text categorization for uneven data sets.</p><p>LPUBoost has many benefits over gradient-based approaches: finite termination at globally optimal solution, well-defined convergence criteria, unequal loss function and use fewer weak hypotheses.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The algorithm AdaUBoost (AdaBoost, if β = 1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. The algorithm LPUBoost (LPBoost, if β = 1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>The parameter D</head><label></label><figDesc>controls the trade off between max- imising the margin and controlling the slack vari- ables. Those associated with positive examples re- ceive β times the weight of those from negative ex- amples in line with the bound (1), while the condition 񮽙 m i=1 α i = 1 ensures the resulting function lies in the convex hull of the set of weak learners. The dual Lin- ear Programme of the above is solved by the algorithm LPUBoost of Figure 2.4 with D − = D and D + = βD.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Performance on Reuters categories of different sizes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Comparison of various boosting algorithms learning curves</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Discarding earn positive training examples</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 . Test F1 of Reuters categories (with the number of positive training documents). We omit the weak learner used with a certain boosting algorithm.</head><label>1</label><figDesc></figDesc><table>Category 
Ada 
U 
LP 
LPU SVM 
earn (2877) 
0.97 0.97 0.91 0.92 
0.98 
acq (1650) 
0.90 0.94 0.69 0.85 
0.93 
money-fx </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 .</head><label>2</label><figDesc>Average test F1 based on 5 fold cross validation.</figDesc><table></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Rademacher and gaussian complexities: Risk bounds and structural results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahar</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mendelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="463" to="482" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A column generation algorithm for boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristin</forename><forename type="middle">P</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayhan</forename><surname>Demiriz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning: Proceedings of the 17th International Conference, ICML&apos;2K</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A column generation algorithm for boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristin</forename><forename type="middle">P</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayhan</forename><surname>Demiriz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="225" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">An Introduction to Support Vector Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Linear programming boosting via column generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayhan</forename><surname>Demiriz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristin</forename><forename type="middle">P</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="225" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Text categorization with support vector machines: learning with many relevant features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECML-98</title>
		<meeting>ECML-98</meeting>
		<imprint/>
	</monogr>
	<note>10th</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<title level="m">European Conference on Machine Learning, number 1398</title>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="137" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Optimizing classifiers for imbalanced training sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grigoris</forename><surname>Karakoulas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Neural Information Processing Workshop, NIPS&apos;98</title>
		<meeting>Neural Information Processing Workshop, NIPS&apos;98</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Boosting the margin distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huma</forename><surname>Lodhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grigoris</forename><surname>Karakoulas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Intelligent Data Engineering and Automated Learning -IDEAL 2000</title>
		<meeting>Intelligent Data Engineering and Automated Learning -IDEAL 2000</meeting>
		<imprint>
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">An algorithm for suffix stripping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Boosting the margin: A new explanation for the effectiveness of voting methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Sun Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1651" to="1686" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Improved boosting algorithms using confidence-rated predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Learing Theory</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="80" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Boostexter: A boosting-based system for text categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="135" to="168" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
