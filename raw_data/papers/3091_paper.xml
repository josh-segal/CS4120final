<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Eigenvoice Speaker Adaptation via Composite Kernel PCA</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
							<email>[jamesk@cs.ust.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Hong Kong University of Science and Technology Clear Water Bay</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Mak</surname></persName>
							<email>mak@cs.ust.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Hong Kong University of Science and Technology Clear Water Bay</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Ho</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Hong Kong University of Science and Technology Clear Water Bay</orgName>
								<address>
									<settlement>Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Eigenvoice Speaker Adaptation via Composite Kernel PCA</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Eigenvoice speaker adaptation has been shown to be effective when only a small amount of adaptation data is available. At the heart of the method is principal component analysis (PCA) employed to find the most important eigenvoices. In this paper, we postulate that nonlinear PCA, in particular kernel PCA, may be even more effective. One major challenge is to map the feature-space eigenvoices back to the observation space so that the state observation likelihoods can be computed during the estimation of eigenvoice weights and subsequent decoding. Our solution is to compute kernel PCA using composite kernels, and we will call our new method kernel eigenvoice speaker adaptation. On the TIDIGITS corpus, we found that compared with a speaker-independent model, our kernel eigenvoice adaptation method can reduce the word error rate by 28-33% while the standard eigenvoice approach can only match the performance of the speaker-independent model.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years, there has been a lot of interest in the study of kernel methods <ref type="bibr" target="#b0">[1]</ref>. The basic idea is to map data in the input space X to a feature space via some nonlinear map ϕ, and then apply a linear method there. It is now well known that the computational procedure depends only on the inner products 1 ϕ(x i ) 񮽙 ϕ(x j ) in the feature space (where x i , x j ∈ X ), which can be obtained efficiently from a suitable kernel function k(·, ·). Besides, kernel methods have the important computational advantage that no nonlinear optimization is involved. Thus, the use of kernels provides elegant nonlinear generalizations of many existing linear algorithms. A well-known example in supervised learning is the support vector machines (SVMs). In unsupervised learning, the kernel idea has also led to methods such as kernel-based clustering algorithms and kernel principal component analysis <ref type="bibr" target="#b1">[2]</ref>.</p><p>In the field of automatic speech recognition, eigenvoice speaker adaptation <ref type="bibr" target="#b2">[3]</ref> has drawn some attention in recent years as it is found particularly useful when only a small amount of adaptation speech is available; e.g. a few seconds. At the heart of the method is principal component analysis (PCA) employed to find the most important eigenvoices. Then a new speaker is represented as a linear combination of a few (most important) eigenvoices and the eigenvoice weights are usually estimated by maximizing the likelihood of the adaptation data. Conventionally, these eigenvoices are found by linear PCA. In this paper, we investigate the use of nonlinear PCA to find the eigenvoices by kernel methods. In effect, the nonlinear PCA problem is converted to a linear PCA problem in the highdimension feature space using the kernel trick. One of the major challenges is to map the feature-space eigenvoices back to the observation space to compute the state observation likelihood of adaptation data during the estimation of eigenvoice weights and likelihood of test data during decoding. Our solution is to compute kernel PCA using composite kernels. We will call our new method kernel eigenvoice speaker adaptation.</p><p>Kernel eigenvoice adaptation will have to deal with several parameter spaces. To avoid confusion, we denote the several spaces as follows: the d 1 -dimensional observation space as O; the d 2 -dimensional speaker (supervector) space as X ; and the d 3 -dimensional speaker feature space as F.</p><formula xml:id="formula_0">Notice that d 1 񮽙 d 2 񮽙 d 3 in general.</formula><p>The rest of this paper is organized as follows. Brief overviews on eigenvoice speaker adaptation and kernel PCA are given in Sections 2 and 3. Sections 4 and 5 then describe our proposed kernel eigenvoice method and its robust extension. Experimental results are presented in Section 6, and the last section gives some concluding remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Eigenvoice</head><p>In the standard eigenvoice approach <ref type="bibr" target="#b2">[3]</ref>, speech training data are collected from many speakers with diverse characteristics. A set of speaker-dependent (SD) acoustic hidden Markov models (HMMs) are trained from each speaker where each HMM state is modeled as a mixture of Gaussian distributions. A speaker's voice is then represented by a speaker supervector that is composed by concatenating the mean vectors of all HMM Gaussian distributions. For simplicity, we assume that each HMM state consists of one Gaussian only. The extension to mixtures of Gaussians is straightforward. Thus, the ith speaker supervector consists of R constituents, one from each Gaussian, and will be denoted by</p><formula xml:id="formula_1">x i = [x 񮽙 i1 . . . x 񮽙 iR ] 񮽙 ∈ R d2 .</formula><p>The similarity between any two speaker supervectors x i and x j is measured by their dot product</p><formula xml:id="formula_2">x 񮽙 i x j = R 񮽙 r=1 x 񮽙 ir x jr .<label>(1)</label></formula><p>PCA is then performed on a set of training speaker supervectors and the resulting eigenvectors are called eigenvoices. To adapt to a new speaker, his/her supervector s is treated as a linear combination of the first M eigenvoices {v 1 , . . . , v M }, i.e., s = s (ev) = 񮽙 M m=1 w m v m where w = [w 1 , . . . , w M ] 񮽙 is the eigenvoice weight vector. Usually, only a few eigenvoices (e.g., M &lt; 10) are employed so that a little amount of adaptation speech (e.g., a few seconds) will be required. Given the adaptation data o t , t = 1, . . . , T , the eigenvoice weights are in turn estimated by maximizing the likelihood of the o t 's. Mathematically, one finds w by maximizing the Q function:</p><formula xml:id="formula_3">Q(w) = Q π + Q a + Q b (w),</formula><p>where</p><formula xml:id="formula_4">Q π = R 񮽙 r=1 γ 1 (r) log(π r ) , Q a = R 񮽙 p,r=1 T −1 񮽙 t=1 ξ t (p, r) log(a pr ) ,</formula><formula xml:id="formula_5">and, Q b (w) = R 񮽙 r=1 T 񮽙 t=1 γ t (r) log(b r (o t , w)) ,<label>(2)</label></formula><p>and π r is the initial probability of state r; γ t (r) is the posterior probability of observation sequence being at state r at time t; ξ t (p, r) is the posterior probability of observation sequence being at state p at time t and at state r at time t + 1; b r is the Gaussian pdf of the rth state after re-estimation. Furthermore, Q b is related to the new speaker supervector s by</p><formula xml:id="formula_6">Q b (w) = − 1 2 R 񮽙 r=1 T 񮽙 t=1 γ t (r) 񮽙 d 1 log(2π) + log |C r | + 񮽙o t − s r (w)񮽙 2 Cr 񮽙 ,<label>(3)</label></formula><p>where</p><formula xml:id="formula_7">񮽙o t − s r (w)񮽙 2 Cr = (o t − s r (w)) 񮽙 C −1 r (o t − s r (w))</formula><p>and C r is the covariance matrix of the Gaussian at state r.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Kernel PCA</head><p>In this paper, the computation of eigenvoices is generalized by performing kernel PCA instead of linear PCA. In the following, let k(·, ·) be the kernel with associated mapping ϕ which maps a pattern x in the speaker supervector space X to ϕ(x) in the speaker feature space F. Given a set of N patterns (speaker supervectors) {x 1 , . . . , x N }, denote the mean of the ϕ-mapped feature vectors by</p><formula xml:id="formula_8">¯ ϕ = 1 N 񮽙 N i=1 ϕ(x i )</formula><p>, and the "centered" map by˜ϕby˜ by˜ϕ</p><formula xml:id="formula_9">(with˜ϕwith˜ with˜ϕ(x) = ϕ(x) − ¯ ϕ). Eigendecomposition is performed oñ K, the centered version of K = [k(x i , x j )] ij , as˜Kas˜ as˜K = UΛU 񮽙 , where U = [α 1 , . . . , α N ] with α i = [α i1 , . . . , α iN ] 񮽙 , and Λ = diag(λ 1 , . . . , λ N ). Notice that˜Kthat˜ that˜K is related to K by˜Kby˜ by˜K = HKH, where H = I − 1 N 11 񮽙 is the centering matrix, I</formula><p>is the N × N identity matrix, and</p><formula xml:id="formula_10">1 = [1, . . . , 1] 񮽙 , an N -dimensional vector.</formula><p>The mth orthonormal eigenvector of the covariance matrix in the feature space is then given by <ref type="bibr" target="#b1">[2]</ref> as</p><formula xml:id="formula_11">v m = 񮽙 N i=1 αmi √ λm˜ϕ λm˜ λm˜ϕ(x i ) .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Kernel Eigenvoice</head><p>As seen from Eqn (3), the estimation of eigenvoice weights requires the evaluation of the distance between adaptation data o t and Gaussian means of the new speaker in the observation space O. In the standard eigenvoice method, this is done by first breaking down the adapted speaker supervector s to its R constituent Gaussians s 1 , . . . , s R . However, the use of kernel PCA does not allow us to access each constituent Gaussians directly. To get around the problem, we investigate the use of composite kernels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Definition of the Composite Kernel</head><p>For the ith speaker supervector x i , we map each constituent x ir separately via a kernel k r (·, ·) to ϕ r (x ir ), and then construct ϕ(x i ) as ϕ(</p><formula xml:id="formula_12">x i ) = [ϕ 1 (x i1 ) 񮽙 , . . . , ϕ R (x iR ) 񮽙 ] 񮽙 .</formula><p>Analogous to Eqn (1), the similarity between two speaker supervectors x i and x j in the composite feature space is measured by</p><formula xml:id="formula_13">k(x i , x j ) = R 񮽙 r=1 k r (x ir , x jr ) .</formula><p>Note that if k r 's are valid Mercer kernels, so is k <ref type="bibr" target="#b0">[1]</ref>.</p><p>Using this composite kernel, we can then proceed with the usual kernel PCA on the set of N training speaker supervectors and obtain α m 's, λ m 's, and the orthonormal eigenvectors v m 's (m = 1, . . . , M ) of the covariance matrix in the feature space F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">New Speaker in the Feature Space</head><p>In the following, we denote the supervector of a new speaker by s. Similar to the standard eigenvoice approach, its˜ϕits˜ its˜ϕ-mapped speaker feature vector 2 ˜ ϕ (kev) (s) is assumed to be a linear combination of the first M eigenvectors, i.e.,</p><formula xml:id="formula_14">˜ ϕ (kev) (s) = M 񮽙 m=1 w m v m = M 񮽙 m=1 N 񮽙 i=1 w m α mi √ λ m ˜ ϕ(x i ).<label>(4)</label></formula><p>Its rth constituent is then given by˜ϕ by˜ by˜ϕ</p><formula xml:id="formula_15">(kev) r (s r ) = M 񮽙 m=1 N 񮽙 i=1 w m α mi √ λ m ˜ ϕ r (x ir ) .</formula><p>Hence, the similarity between ϕ (kev) r (s r ) and ϕ r (o t ) is given by</p><formula xml:id="formula_16">k (kev) r (s r , o t ) ≡ ϕ(s r ) 񮽙 ϕ r (o t ) = 񮽙񮽙 M 񮽙 m=1 N 񮽙 i=1 w m α mi √ λ m ˜ ϕ r (x ir ) 񮽙 + ¯ ϕ r 񮽙 񮽙 ϕ r (o t ) = 񮽙񮽙 M 񮽙 m=1 N 񮽙 i=1 w m α mi √ λ m (ϕ r (x ir ) − ¯ ϕ r ) 񮽙 + ¯ ϕ r 񮽙 񮽙 ϕ r (o t ) = M 񮽙 m=1 N 񮽙 i=1 w m α mi √ λ m (k r (x ir , o t ) − ¯ ϕ 񮽙 r ϕ r (o t )) + ¯ ϕ 񮽙 r ϕ r (o t ) ≡ A(r, t) + M 񮽙 m=1 w m √ λ m B(m, r, t),<label>(5)</label></formula><p>where</p><formula xml:id="formula_17">¯ ϕ r = 1 N 񮽙 N i=1 ϕ r (x ir ) is the rth part of ¯ ϕ, A(r, t) = ¯ ϕ 񮽙 r ϕ r (o t ) = 1 N N 񮽙 j=1 k r (x jr , o t ),</formula><p>and</p><formula xml:id="formula_18">B(m, r, t) = 񮽙 N 񮽙 i=1 α mi k r (x ir , o t ) 񮽙 − A(r, t) 񮽙 N 񮽙 i=1 α mi 񮽙 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Maximum Likelihood Adaptation Using an Isotropic Kernel</head><p>On adaptation, we have to express 񮽙o t − s r 񮽙 2 Cr of Eqn <ref type="formula" target="#formula_6">(3)</ref> as a function of w. Consider using isotropic kernels for k r so that k r (x ir , x jr ) = κ(񮽙x ir − x jr 񮽙 Cr ). Then k</p><formula xml:id="formula_19">(kev) r (s r , o t ) = κ(񮽙o t − s r 񮽙 2</formula><p>Cr ), and if κ is invertible, 񮽙o t − s r 񮽙 2 Cr will be a function of k (kev) r (s r , o t ), which in turn is a function of w by Eqn (5). In the sequel, we will use the Gaussian kernel k r (x ir , x jr ) = exp(−β r 񮽙x ir − x jr 񮽙 2 Cr ), and hence</p><formula xml:id="formula_20">񮽙o t − s r 񮽙 2 Cr = − 1 β r log k (kev) r (s r , o t ) = − 1 β r log 񮽙 A(r, t) + M 񮽙 m=1 w m √ λ m B(m, r, t) 񮽙 .<label>(6)</label></formula><p>Substituting Eqn (6) for the Q b function in Eqn (3), and differentiating with respect to each eigenvoice weight, w j , j = 1, . . . , M , we obtain</p><formula xml:id="formula_21">∂Q b ∂w j = 1 2 񮽙 λ j R 񮽙 r=1 T 񮽙 t=1 γ t (r) β r · B(j, r, t) k (kev) r (s r , o t ) .<label>(7)</label></formula><p>not exist, its notation as˜ϕas˜ as˜ϕ (kev) (s) is not exactly correct. However, the notation is adopted for its intuitiveness and the readers are advised to infer the existence of s based on the context.</p><p>Since Q π and Q a do not depend on w,</p><formula xml:id="formula_22">∂Q ∂w j = ∂Q b ∂w j .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Generalized EM Algorithm</head><p>Because of the nonlinear nature of kernel PCA, Eqn (6) is nonlinear in w and there is no closed form solution for the optimal w. In this paper, we instead apply the generalized EM algorithm (GEM) <ref type="bibr" target="#b3">[4]</ref> to find the optimal weights. GEM is similar to standard EM except for the maximization step: EM looks for w that maximizes the expected likelihood of the E-step but GEM only requires a w that improves the likelihood. Many numerical methods may be used to update w based on the derivatives of Q. In this paper, gradient ascent is used to get w(n) from w(n − 1) based only on the first-order derivative as:</p><formula xml:id="formula_23">w(n) = w(n − 1) + η(n)Q 񮽙 | w=w(n−1)</formula><p>, where Q 񮽙 = ∂Q b ∂w and η(n) is the learning rate at the nth iteration. Methods such as the Newton's method that uses the second-order derivatives may also be used for faster convergence, at the expense of computing the more costly Hessian in each iteration.</p><p>The initial value of w(0) can be important for numerical methods like gradient ascent. One reasonable approach is to start with the eigenvoice weights of the supervector composed from the speaker-independent model x (si) . That is,</p><formula xml:id="formula_24">w m = v 񮽙 m ˜ ϕ(x (si) ) = N 񮽙 i=1 α mi √ λ m ˜ ϕ(x i ) 񮽙˜ϕ񮽙˜ 񮽙˜ϕ(x (si) ) = N 񮽙 i=1 α mi √ λ m [ϕ(x i ) − ¯ ϕ] 񮽙 [ϕ(x (si) ) − ¯ ϕ] = N 񮽙 i=1 α mi √ λ m 񮽙 k(x i , x (si) )+ 1 N 2 N 񮽙 p,q=1 k(x p , x q )− 1 N N 񮽙 p=1 񮽙 k(x i , x p )+k(x (si) , x p ) 񮽙 񮽙 .<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Robust Kernel Eigenvoice</head><p>The success of the eigenvoice approach for fast speaker adaptation is due to two factors: (1) a good collection of "diverse" speakers so that the whole speaker space is captured by the eigenvoices; and (2) the number of adaptation parameters is reduced to a few eigenvoice weights. However, since the amount of adaptation data is so little the adaptation performance may vary widely. To get a more robust performance, we propose to interpolate the kernel eigenvoice˜ϕeigenvoice˜ eigenvoice˜ϕ (kev) (s) obtained in Eqn (4) with the˜ϕthe˜ the˜ϕ-mapped speaker-independent (SI) supervector˜ϕsupervector˜ supervector˜ϕ(x (si) ) to obtain the final speaker adapted model˜ϕmodel˜ model˜ϕ (rkev) (s) as follows:</p><formula xml:id="formula_25">˜ ϕ (rkev) (s) = w 0 ˜ ϕ(x (si) ) + (1 − w 0 ) ˜ ϕ (kev) (s) , 0.0 ≤ w 0 ≤ 1.0 ,<label>(9)</label></formula><p>where˜ϕwhere˜ where˜ϕ (kev) (s) is found by Eqn (4). By replacing˜ϕreplacing˜ replacing˜ϕ (kev) (s) by˜ϕby˜ by˜ϕ (rkev) (s) for the computation of the kernel value of Eqn <ref type="formula" target="#formula_16">(5)</ref>, and following the mathematical steps in Section 4, one may derive the required gradients for the joint maximum-likelihood estimation of w 0 and other eigenvoice weights in the GEM algorithm.</p><p>Notice that˜ϕthat˜ that˜ϕ (rkev) (s) also contains components iñ ϕ(x (si) ) from eigenvectors beyond the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental Evaluation</head><p>The proposed kernel eigenvoice adaptation method was evaluated on the TIDIGITS speech corpus <ref type="bibr" target="#b4">[5]</ref>. Its performance was compared with that of the speaker-independent model and the standard eigenvoice adaptation method using only 3s, 5.5s, and 13s of adaptation speech. If we exclude the leading and ending silence, the average duration of adaptation speech is 2.1s, 4.1s, and 9.6s respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">TIDIGITS Corpus</head><p>The TIDIGITS corpus contains clean connected-digit utterances sampled at 20 kHz. It is divided into a standard training set and a test set. There are 163 speakers (of both genders) in each set, each pronouncing 77 utterances of one to seven digits (out of the eleven digits: "0", "1", . . ., "9", and "oh".). The speaker characteristics is quite diverse with speakers coming from 22 dialect regions of USA and their ages ranging from 6 to 70 years old.</p><p>In all the following experiments, only the training set was used to train the speakerindependent (SI) HMMs and speaker-dependent (SD) HMMs from which the SI and SD speaker supervectors were derived.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Acoustic Models</head><p>All training data were processed to extract 12 mel-frequency cepstral coefficients and the normalized frame energy from each speech frame of 25 ms at every 10 ms. Each of the eleven digit models was a strictly left-to-right HMM comprising 16 states and one Gaussian with diagonal covariance per state. In addition, there were a 3-state "sil" model to capture silence speech and a 1-state "sp" model to capture short pauses between digits. All HMMs were trained by the EM algorithm. Thus, the dimension of the observation space d 1 is 13 and that of the speaker supervector space d 2 = 11 × 16 × 13 = 2288.</p><p>Firstly, the SI models were trained. Then an SD model was trained for each individual speaker by borrowing the variances and transition matrices from the corresponding SI models, and only the Gaussian means were estimated. Furthermore, the sil and sp models were simply copied to the SD model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Experiments</head><p>The following five models/systems were compared:</p><p>SI: speaker-independent model EV: speaker-adapted model found by the standard eigenvoice adaptation method.</p><p>Robust-EV: speaker-adapted models found by our robust version of EV, which is the interpolation between the SI supervector and the supervector found by EV. That is,</p><formula xml:id="formula_26">s (rev) = w 0 s (si) + (1 − w 0 )s (ev) , 0.0 ≤ w 0 ≤ 1.0 .</formula><p>KEV: speaker-adapted model found by our new kernel eigenvoice adaptation method as described in Section 4.</p><p>Robust-KEV: speaker-adapted model found by our robust KEV as described in Section 5.</p><p>All adaptation results are the averages of 5-fold cross-validation taken over all 163 test speaker data. The detailed results using different numbers of eigenvoices are shown in <ref type="figure">Figure 1</ref>, while the best result for each model is shown in <ref type="table" target="#tab_0">Table 1</ref>.  <ref type="figure">Figure 1</ref>: Word recognition accuracies of adapted models found by KEV and robust KEV using different numbers of eigenvoices.</p><p>From <ref type="figure">Figure 1</ref>, the KEV method can outperform the SI model even with only two eigenvoices using only 2.1s of speech. Its performance then improves slightly with more eigenvoices or more adaptation data. If we allow interpolation with the SI model as in robust KEV, the saturation effect is even more pronounced: even with one eigenvoice, the adaptation performance is already better than that of SI model, and then the performance does not change much with more eigenvoices or adaptation data. The results seem to suggest that the requirement that the adapted speaker supervector is a weighted sum of few eigenvoices is both the strength and weakness of the method: on the one hand, fast adaptation becomes possible since the number of estimation parameters is small, but adaptation saturates quickly because the constraint is so restrictive that all mean vectors of different acoustic models have to undergo the same linear combination of the eigenvoices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>In this paper, we improve the standard eigenvoice speaker adaptation method using kernel PCA with a composite kernel. In the TIDIGITS task, it is found that while the standard eigenvoice approach does not help, our kernel eigenvoice method may outperform the speaker-independent model by about 28-33% (in terms of error rate improvement).</p><p>Right now the speed of recognition using the adapted model that resulted from our kernel eigenvoice method is slower than that from the standard eigenvoice method because any state observation likelihoods cannot be directly computed but through evaluating the kernel values with all training speaker supervectors. One possible solution is to apply sparse kernel PCA <ref type="bibr" target="#b5">[6]</ref> so that computation of the first M principal components involves only M (instead of N with M 񮽙 N ) kernel functions. Another direction is to use compactly supported kernels <ref type="bibr" target="#b6">[7]</ref>, in which the value of κ(񮽙x i − x j 񮽙) vanishes when 񮽙x i − x j 񮽙 is greater than a certain threshold. The kernel matrix then becomes sparse. Moreover, no more computation is required when 񮽙x i − x j 񮽙 is large.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 : Word recognition accuracies of SI model and the best adapted models found by EV, robust EV, KEV, and robust KEV using 2.1s, 4.1s, and 9.6s of adaptation speech.</head><label>1</label><figDesc>6s of adaptation speech over the SI model. When the SI model is interpolated with the KEV model in our robust KEV method, the WER reduction further improves to 27.5%, 31.7%, and 33.3% respectively. These best results are obtained with 7 to 8 eigenvoices. The results show that nonlinear PCA using composite kernels can be more effective in finding the eigenvoices.</figDesc><table>SYSTEM 
2.1s 
4.1s 
9.6s 
SI 
96.25 
EV 
95.61 95.65 95.67 
robust EV 
96.26 96.26 96.27 
KEV 
96.85 97.05 97.05 
robust KEV 97.28 97.44 97.50 

From Table 1, we observe that the standard eigenvoice approach cannot obtain better perfor-
mance than the SI model 3 . On the other hand, using our kernel eigenvoice (KEV) method, 
we obtain a word error rate (WER) reduction of 16.0%, 21.3%, and 21.3% with 2.1s, 4.1s, 
and 9.</table></figure>

			<note place="foot" n="1"> In this paper, vector/matrix transpose is denoted by the superscript 񮽙 .</note>

			<note place="foot" n="2"> The notation for a new speaker in the feature space requires some explanation. If s exists, then its centered image is˜ϕis˜ is˜ϕ (kev) (s). However, since the pre-image of a speaker in the feature space may</note>

			<note place="foot">M selected kernel eigenvoices for adaptation. Thus, robust KEV adaptation may have the additional benefit of preserving the speaker-independent projections on the remaining less important but robust eigenvoices in the final speaker-adapted model.</note>

			<note place="foot" n="3"> The word accuracy of our SI model is not as good as the best reported result on TIDIGITS which is about 99.7%. The main reasons are that we used only 13-dimensional static cepstra and energy, and each state was modelled by a single Gaussian with diagonal covariance. The use of this simple model allowed us to run experiments with 5-fold cross-validation using very short adaptation speech. Right now our approach requires computation of many kernel function values and is very computationally expensive. As a first attempt on the approach, we feel that the use of this simple model is justified. We are now working on its speed-up and its extension to HMM states of Gaussian mixtures.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Acknowledgements</head><p>This research is partially supported by the Research Grants Council of the Hong Kong SAR under the grant numbers HKUST2033/00E, HKUST6195/02E, and HKUST6201/02E.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Learning with Kernels. MIT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Nonlinear component analysis as a kernel eigenvalue problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1299" to="1319" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Rapid Speaker Adaptation in Eigenvoice Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Junqua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Niedzielski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Speech and Audio Processing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="695" to="707" />
			<date type="published" when="2000-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A Database for Speaker-Independent Digit Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Leonard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<meeting>the IEEE International Conference on Acoustics, Speech, and Signal Processing</meeting>
		<imprint>
			<date type="published" when="1984" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="4211" to="4214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Sparse kernel feature analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">L</forename><surname>Mangasarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopfsch¨schölkopf</surname></persName>
		</author>
		<idno>99-03</idno>
		<imprint>
			<date type="published" when="1999" />
			<pubPlace>Madison</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Data Mining Institute, University of Wisconsin</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Classes of kernels for machine learning: A statistics perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Genton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="299" to="312" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
