<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:43+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Computing Nash Equilibria of Action-Graph Games</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navin</forename><forename type="middle">A R</forename><surname>Bhat</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Physics</orgName>
								<orgName type="department" key="dep2">Department of Computer Science</orgName>
								<orgName type="institution">University of Toronto Toronto</orgName>
								<address>
									<postCode>M5S 1A7</postCode>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Leyton-Brown</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of British Columbia Vancouver</orgName>
								<address>
									<postCode>V6T 1Z4</postCode>
									<region>BC Canada</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Computing Nash Equilibria of Action-Graph Games</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Action-graph games (AGGs) are a fully expressive game representation which can compactly express both strict and context-specific independence between players&apos; utility functions. Actions are represented as nodes in a graph G, and the payoff to an agent who chose the action s depends only on the numbers of other agents who chose actions connected to s. We present algorithms for computing both symmetric and arbitrary equilibria of AGGs using a continuation method. We analyze the worst-case cost of computing the Jacobian of the payoff function, the exponential-time bottleneck step, and in all cases achieve exponential speedup. When the in-degree of G is bounded by a constant and the game is symmetric, the Jacobian can be computed in polynomial time.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>When modeling interactions between self-interested agents in a multiagent system, it is natural to use game theory as a theoretical foundation. (For an introduction to games and equilibrium concepts, see e.g., Fudenberg and Tirole <ref type="bibr">[1991]</ref>.) The central game-theoretic solution concept is the Nash equilibrium, a fixed-point in mixed strategy space which Nash <ref type="bibr">[1950]</ref> proved exists in every finite game. It remains an important open question to determine whether the problem of finding a Nash equilibrium belongs to P <ref type="bibr" target="#b16">[Papadimitriou, 2001]</ref>; the best known algorithms for computing equilibria are exponential. One state of the art general-purpose algorithm is the continuation method of Govindan and Wilson <ref type="bibr">[2003]</ref>, a gradientfollowing algorithm which is based on topological insight into the graph of the Nash equilibrium correspondence by <ref type="bibr" target="#b7">Kohlberg and Mertens [1986]</ref>. (For a good survey describing earlier algorithms for games with more than two players, see <ref type="bibr" target="#b11">[McKelvey &amp; McLennan, 1996]</ref>.) The worst-case complexity of Govindan and Wilson's algorithm is open because the worst-case number of gradient-following steps is not known; however, in practice the algorithm's runtime is dominated by the computation of Jacobian of the payoff function, required for computing the gradient, which is both best-and worst-case exponential in the number of agents. For many games this algorithm is an impressive step beyond the previous state of the art; however, it is still only practical when the numbers of players and of actions per player are small (roughly on the order of 5-10).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Compact game representations</head><p>One response to the computational difficulty of computing the equilibria of general games has been the investigation of compact game representations that can be leveraged to yield more efficient computation. One influential class of representations exploits strict independencies between players' utility functions; this class includes graphical games <ref type="bibr" target="#b4">[Kearns et al., 2001]</ref>, multi-agent influence diagrams <ref type="bibr" target="#b8">[Koller &amp; Milch, 2001]</ref> and game nets <ref type="bibr" target="#b9">[La Mura, 2000]</ref>. Various algorithms were proposed to take advantage of these representations, including exact algorithms for games with special structure <ref type="bibr" target="#b4">[Kearns et al., 2001;</ref><ref type="bibr" target="#b8">Koller &amp; Milch, 2001]</ref> and approximate algorithms for arbitrary games <ref type="bibr" target="#b19">[Vickrey &amp; Koller, 2002]</ref>. Recently, Blum et al. <ref type="bibr">[2003]</ref> adapted Govindan and Wilson's continuation algorithm to leverage these representations in an exact algorithm for arbitrary games. Their algorithm computes the Jacobian of the payoff function for unrestricted graphical games and MAIDs. It requires time exponential in the tree width of the underlying graph, an exponential improvement over the Govindan and Wilson algorithm.</p><p>A second approach to compactly representing games focuses on context-specific independencies in agents' utility functions-that is, games in which agents' abilities to affect each other depend on the actions they choose-and often also on symmetries in agents' utility functions <ref type="bibr">[Rosen- thal, 1973;</ref><ref type="bibr" target="#b12">Monderer &amp; Shapley, 1996;</ref><ref type="bibr" target="#b5">Kearns &amp; Mansour, 2002;</ref><ref type="bibr" target="#b18">Roughgarden &amp; Tardos, 2001]</ref>. Our past work on local-effect games (LEGs) also falls into this class <ref type="bibr" target="#b10">[Leyton- Brown &amp; Tennenholtz, 2003]</ref>. LEGs are similar in spirit to action-graph games (AGGs), the game representation we introduce here. They have the same graphical representation, with actions corresponding to nodes, and edges indicating context-specific utility dependencies between actions. However, LEGs involve a series of assumptions: that utility independence between actions is always bidirectional; that all agents share the same action sets; and that utility decomposes into a sum of local effects from individual actions. Thus, LEGs cannot represent arbitrary games. Intuitively, AGGs can be understood as unrestricted LEGs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Technical background 2.1 Action-graph games</head><p>An action-graph game (AGG) is a tuple N, S, ν, u. Let N ≡ {1, . . . , n} denote the set of agents in the game. Each agent i has the set of action choices S i , so the set of pure action profiles is</p><formula xml:id="formula_0">S ≡ i∈N S i (1)</formula><p>where is the Cartesian product. Although the actions available to different agents may be distinct, agents may also have action choices in common. Let</p><formula xml:id="formula_1">S ≡ i∈N S i<label>(2)</label></formula><p>denote the set of distinct action choices in the game. Let ∆ denote the set of possible distributions of agents over actions, where a distribution is a number of agents who chose each action. For a given distribution D ∈ ∆, denote by D(s) the number of agents who chose action s. D : S → N |S| is a function mapping from a pure strategy profile s to an agent distribution D.</p><p>Let G be the action graph: a graph having one node for every action s ∈ S. The neighbor relation is given by ν : S → 2 S . Let there be a directed edge from s to s in G iff s ∈ ν(s). Note that s ∈ ν(s) is possible. The utility function</p><formula xml:id="formula_2">u : S × ∆ → R<label>(3)</label></formula><p>maps from an action choice s and a distribution of agents D to a payoff. Observe that all agents have the same utility function. The utility function has the property that given any action s and any pair of distributions D and D ,</p><formula xml:id="formula_3">[∀s ∈ ν(s), D(s ) = D (s )] ⇒ u(s, D) = u(s, D ).<label>(4)</label></formula><p>In other words, for every i and j agent i's utility is independent of agent j's action choice conditional on agent j choosing an action which is not in the neighborhood of agent i's action choice. This is the sense in which AGGs express context-specific independencies in utility functions. Beyond this condition, there are no restrictions on the function u. In some cases it will be notationally simpler for us to write u(s) as a shorthand for u(s i , D(s)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Examples</head><p>Any arbitrary game can be encoded as an AGG as follows. Create a unique node s i for each action available to each agent i. Thus ∀s ∈ S, D(s) ∈ {0, 1}, and ∀ı, s∈Si D(s) must equal 1. The distribution simply indicates each agent's action choice, and the representation is no more or less compact than the normal form.</p><p>Example 1 <ref type="figure">Figure 1</ref> shows an arbitrary 3-player, 3-action game encoded as an AGG. As always, nodes represent actions and directed edges represent membership in a node's neighborhood. The dotted boxes represent the players' action sets: player 1 has actions 1, 2 and 3; etc. Observe that there is always an edge between pairs of nodes belonging to different action sets, and that there is never an edge between nodes in the same action set.</p><p>In a graphical game <ref type="bibr" target="#b4">[Kearns et al., 2001</ref>] nodes denote agents and there is an edge connecting each agent i to each other agent whose actions can affect i's utility. Each agent then has a payoff matrix representing his local game with neighboring agents; this representation is more compact than normal form whenever the graph is not a clique. Graphical games can be represented as AGGs by replacing each node i in the graphical game by a distinct cluster of nodes S i representing the action set of agent i. If the graphical game has an edge from i to j, create edges so that ∀s i ∈ S i , ∀s j ∈ S j , s i ∈ ν(s j ). The AGG and graphical game representations are equally compact. In Corollary 1 below we show that our general method for computing the payoff Jacobian for AGGs is as efficient as the method specialized to graphical games due to <ref type="bibr" target="#b0">Blum et al. [2003]</ref>.</p><p>Example 2 <ref type="figure">Figure 2</ref> shows the AGG representation of a graphical game having three nodes and two edges between them (i.e., player 1 and player 3 do not directly affect each others' payoffs). The AGG may appear more complex than the graphical game; in fact, this is only because players' actions are made explicit.</p><p>The AGG representation becomes even more compact when agents have actions in common, with utility functions depending only on the number of agents taking these actions rather than on the identities of the agents. <ref type="figure" target="#fig_0">Figure 3</ref> represents a setting in which n ice cream vendors must choose one of four Note that this game exhibits context-specific independence without any strict independence, and that the graph structure is independent of n.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example 3 The action graph in</head><p>Other examples of compact AGGs that cannot be compactly represented as graphical games include: location games, role formation games, traffic routing games, product placement games and party affiliation games.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Notation</head><p>Let ϕ(X) denote the set of all probability distributions over a set X. Define the set of mixed strategies for i as</p><formula xml:id="formula_4">Σ i ≡ ϕ(S i ),<label>(5)</label></formula><p>and the set of all mixed strategy profiles as</p><formula xml:id="formula_5">Σ ≡ i∈N Σ i .<label>(6)</label></formula><p>We denote an element of Σ i by σ i , an element of Σ by σ, and the probability that player i plays action s by σ i (s).</p><p>Next, we give notation for applying some of the concepts defined in Section 2.1 to situations where one or more agents are omitted. By ∆ −{i,i } we denote the set of possible distributions of agents other than i and i , and by Define the expected utility to agent i for playing pure strategy s, given that all other agents play the mixed strategy profile σ −i , as</p><formula xml:id="formula_6">D −{i,i } we denote an element of ∆ −{i,i } . Analogously, we define N −{i,i } , S −{i,i } , Σ −</formula><formula xml:id="formula_7">V i s (σ −i ) ≡ s −i ∈S −i u(s, s −i ) Pr(s −i |σ −i ).<label>(7)</label></formula><p>The set of i's pure strategy best responses to a mixed strat-</p><formula xml:id="formula_8">egy profile σ −i is arg max s V i s (σ −i )</formula><p>, and hence the full set of i's pure and mixed strategy best responses to σ −i is</p><formula xml:id="formula_9">BR i (σ −i ) ≡ ϕ(arg max s V i s (σ −i )).<label>(8)</label></formula><p>A strategy profile σ is a Nash equilibrium iff </p><formula xml:id="formula_10">∀i ∈ N, σ i ∈ BR i (σ −i ).<label>(9)</label></formula><formula xml:id="formula_11">D (s) (s ) ≡ D(s ) s ∈ ν(s) s ∈ν(s) D(s ) s = ∅ .<label>(10)</label></formula><p>In the analogous way, we define S (s) , s (s) , Σ (s) and σ (s) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Continuation Methods</head><p>Continuation methods are a technique for solving certain systems of equations when the solution to a perturbed system is known. Given a game of interest with payoff function u(s i , s −i ), one constructs a continuum of games Γ λ with payoff functions u λ parameterized by a single parameter λ, such that λ = 0 yields the game of interest Γ 0 , and λ = 1 yields a game Γ 1 having a known solution. Then beginning with the known solution, the continuation method traces the solution as λ is decreased to zero, at which point the desired solution is obtained. A good introduction to continuation methods is given in Blum et al.</p><p>[2003]; we follow their treatment here. A more detailed explanation of the method can be found in Govindan and Wilson <ref type="bibr">[2003]</ref>.</p><p>Nash equilibria are fixed points of a mapping that improves a player's utility by changing his strategy. This mapping yields a system of equations to which continuation methods can be applied. The expected utility of agent i is</p><formula xml:id="formula_12">E[u(s i , s −i )] = si∈Si σ i (s i )V i si (σ −i ),<label>(11)</label></formula><p>where we recall that V i s i (σ −i ) from Equation <ref type="formula" target="#formula_7">(7)</ref> is the expected payoff to agent i when he plays pure strategy s i and other agents play mixed strategy profile σ −i . Consider the following strategy-improvement mapping for all agents:</p><formula xml:id="formula_13">σ = R(σ + V (σ)).<label>(12)</label></formula><p>Here we introduce the retraction operator R : R m → Σ.</p><p>The retraction operator takes a vector of dimension m ≡ i∈N |S i |, and normalizes it by mapping it to the nearest point in Σ in Euclidean distance. Mapping from σ to σ in Equation (12) corresponds to increasing the probabilities of playing strategies that have better payoffs, while lowering the probabilities of playing strategies that have worse payoffs. Its fixed points σ = σ, where no further (local) improvement can be achieved for any agent, are the Nash equilibria. Rather than searching in Σ, Govindan and Wilson found it computationally expedient to search in the unnormalized space R m for a w such that σ = R(w); then the equilibrium is given by σ = R(w) such that w satisfies</p><formula xml:id="formula_14">R(w) = w + R (V (R(w))) .<label>(13)</label></formula><p>The perturbed system can now be introduced: replace V with V + λb, where b is a bonus to each agent depending on his identity and action choice, but independent of the actions of the other agents. If for each given agent i, b i s i is sufficiently large for one particular action s i and zero for all others, then there will be a unique Nash equilibrium where each agent i plays the pure strategy s i . We then have the system of equations F (w, λ) = 0, where</p><formula xml:id="formula_15">F (w, λ) = w − R(w) − (V (R(w)) + λb).<label>(14)</label></formula><p>For λ = 1, w is known; we then wish to decrease λ to zero while maintaining F (w, λ) = 0. This requires that dF = 0 along the path. Pairs (w, λ) satisfying this condition then map out a graph of the correspondence w(λ), which is with probability one over all choices of the bonus a one-manifold without boundary. Thus</p><formula xml:id="formula_16">dF (w, λ) = w F ∂F ∂λ dw dλ = 0<label>(15)</label></formula><p>A nontrivial solution requires that w F ∂F ∂λ be singular, and its null space defines the direction that is followed by the graph of the correspondence w(λ). Using Equation <ref type="formula" target="#formula_3">(14)</ref> we obtain</p><formula xml:id="formula_17">w F = I − (I + V )R<label>(16)</label></formula><p>where I is the m × m identity matrix. Computing the Jacobian of F is dominated by the Jacobian of V . The derivatives can be taken analytically; elements of the Jacobian for which i = i vanish, and we obtain for the i = i elements of the Jacobian of V ,</p><formula xml:id="formula_18">∂V i si (σ −i ) ∂σ i (s i ) ≡ V i,i si,s i (σ)<label>(17)</label></formula><formula xml:id="formula_19">= s∈S u (s i , D(s i , s i , s)) P r(s|σ)<label>(18)</label></formula><p>and</p><formula xml:id="formula_20">P r(s|σ) = j∈N σ j (s j ).<label>(19)</label></formula><p>(Recall that whenever we use an overbar in our notation, it is equivalent to the subscript −{i, i }. For example, s ≡ s −{i,i } .) Equation <ref type="formula" target="#formula_9">(18)</ref> shows that the V i,i si,s i (σ) element of the Jacobian can be interpreted as the expected utility of agent i when she takes action s i , agent i takes action s i , and all other agents use mixed strategies according to σ.</p><p>The size of the set S is exponential in n, but since the sum must visit each member of the set, both best-and worstcase scenario computation of the right-hand side of Equation (18) is exponential in the number of agents. In the sections that follow, we describe algorithms for the efficient computation of this expression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Other applications of the payoff Jacobian</head><p>Efficient computation of the payoff Jacobian is important for more than this continuation method. For example, the iterated polymatrix approximation (IPA) method of Govindan and Wilson <ref type="bibr">[2004]</ref> has the same problem at its core. At each step the IPA method constructs a polymatrix game that is a linearization of the current game with respect to the mixed strategy profile, the Lemke-Howson algorithm is used to solve this game, and the result updates the mixed strategy profile used in the next iteration. Though theoretically it offers no convergence guarantee, IPA is typically much faster than the continuation method; often it is used to give the continuation method a quick start. Another application of the payoff Jacobian is in multiagent reinforcement learning algorithms that perform policy search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Computing the Jacobian</head><p>Whenever ∃s i , ∃s such that s ∈ ν(s i ), there exist distributions of agents that are equivalent from the point of view of agent i. Furthermore, whenever ∃i, ∃j = i, S i S j = ∅, there exist pure action profiles that are equivalent from the point of view of agents who choose certain actions. That is, when some action s is available to multiple agents, agents care only about the number of agents who choose s and not their identities. We express the first kind of indifference by projecting the action graph; the second is expressed through partitioning the pure action profiles into distributions of agent numbers. Each provides computational benefits. It will be seen below that partitioning amounts to dynamic programming, i.e. pushing in of sums that analytically accounts for symmetry in the problem. For arbitrary equilibria, the speedup due to projection is exponential as long as the maximum indegree of the graph G is less than the number of nodes in G. This speedup typically overwhelms the gain due to partitioning in non-symmetric equilibria; however, for the important case of symmetric action space (i.e. ∀i, S i = S), partitioning guarantees computation of the Jacobian in polynomial time. In Section 3.1 we consider equilibria of arbitrary action-graph games; in Section 3.2 we analyze symmetric equilibria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Arbitrary equilibria</head><p>Given arbitrary action set S, the Jacobian can be expressed compactly through projection at the level of the pure action profiles (recall the definition of projection in Equation (10)). Projecting onto action s i , we rewrite the Jacobian given in Equations <ref type="formula" target="#formula_9">(18)</ref> and <ref type="formula" target="#formula_10">(19)</ref> as</p><formula xml:id="formula_21">V i,i s i ,s i (σ) = s (s i ) ∈S (s i ) u s i , D(s i , s (si) i , s (s i ) ) P r s (s i ) |σ (si)<label>(20)</label></formula><p>where</p><formula xml:id="formula_22">P r s (s i ) |σ (s i ) = j∈N σ (si) j (s (si) j ).<label>(21)</label></formula><p>To reflect the indifference between pure action profiles giving rise to the same distribution, we define an equivalence relation that partitions S:</p><formula xml:id="formula_23">s ∼ s iff D (s) = D s .<label>(22)</label></formula><p>Then denote by S(D) the equivalence class containing all s such that D (s) = D. The analogous partitioning can be done in the projected space, yielding e.g. S(D <ref type="bibr">(si)</ref> ).</p><p>To exploit this indifference, we rewrite the elements of the Jacobian in Equations <ref type="formula" target="#formula_1">(20)</ref> and <ref type="formula" target="#formula_1">(21)</ref>  </p><formula xml:id="formula_24">V i,i s i ,s i (σ) = D (s i ) ∈∆ (s i ) u s i , D s i , s i , D (si) P r D (si) |σ (s i )<label>(23)</label></formula><p>where</p><formula xml:id="formula_25">P r D (si) |σ (s i ) = s (s i ) ∈ S D (s i ) P r s (s i ) |σ (s i ) .<label>(24)</label></formula><p>Given the value P r(s (s i ) |σ (s i ) ) for some s (s i ) , dynamic programming can be used to compute the result for another "adjacent" value s (s i ) in constant time. We introduce the permutation operation (j ↔ j ), such that s (si) is the pure strategy profile obtained from s (s i ) by switching the actions of agents j and j . Thus s (si) = s (s i ) (j↔j ) . Then we have that P r s</p><formula xml:id="formula_26">(s i ) (j↔j ) |σ (si) = σ (si) j s (si) j σ (si) j s (si) j σ (s i ) j s (s i ) j σ (s i ) j s (s i ) j P r s (si) |σ (si) .<label>(25)</label></formula><p>We note that some elements of the Jacobian are identical:</p><formula xml:id="formula_27">∀s / ∈ ν(s i ), s / ∈ ν(s i ), V i,i s i ,s (σ) = V i,i s i ,s (σ).<label>(26)</label></formula><p>Intuitively, Equation <ref type="formula" target="#formula_1">(26)</ref> expresses context-specific independence: the property that if agent i takes an action outside the neighborhood of the action taken by i, then i is indifferent to which particular action was taken by i . It amounts to projecting the Jacobian. Given that the Jacobian has O(m 2 ) entries, and given Equation <ref type="formula" target="#formula_1">(26)</ref>, we have that the Jacobian has O(n 2 |S|(I + 1)) independent entries.</p><p>Theorem 1 Computation of the Jacobian for arbitrary action-graph games using Equations <ref type="formula" target="#formula_1">(23)</ref> and <ref type="formula" target="#formula_1">(24)</ref> takes time that is O (I + 1) n poly(n)poly (|S|) .</p><p>Proof. Computing elements of the Jacobian using Equations <ref type="formula" target="#formula_1">(23)</ref> and <ref type="formula" target="#formula_1">(24)</ref> involves computing the right hand side of Equation <ref type="formula" target="#formula_1">(21)</ref>  , for each</p><formula xml:id="formula_28">D (s i ) ∈ ∆ (s i ) .</formula><p>Since this is just a partitioning of the space S (si) , it amounts to a sum over all elements of the set S (si) . This is the same number of elements as in the sum for the Jacobian in Equations <ref type="formula" target="#formula_1">(20)</ref> and <ref type="formula" target="#formula_1">(21)</ref>. Depending on their specific action sets, each agent has the choice of some subset of the at most I + 1 actions in the projected graph G (si) , and these choices are independent. Thus S (si) has O (I + 1) n elements. Using Equation <ref type="formula" target="#formula_1">(26)</ref>, we have that the Jacobian has O(n 2 |S|(I + 1)) independent elements. Then computation of the full Jacobian takes time that is O (I + 1) n poly(n)poly (|S|) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary 1 For a graphical game encoded as an AGG, if</head><p>f is the maximum family size and α is the maximum number of actions available to each agent, the Jacobian can be computed in time that is O poly(α f )poly(n)poly (|S|) .</p><p>Proof. Graphical games can be written as AGGs following the procedure given in Section 2.2. Define the family of agent i, f am(i), to be the set of all agents j such that ∃s i ∈ S i , ∃s j ∈ S j , s j ∈ ν(s i ). Compute the Jacobian using the method of Equations <ref type="formula" target="#formula_1">(20)</ref> and (21). The key to the complexity of computing the Jacobian is the size of the set S (s i ) . For all elements of S (s i ) , all agents j / ∈ f am(i) take action ∅. Each agent in f am(i) has at most α available actions in the projected graph G (si) . Since there are at most f such agents, and since all agents choose independently, therefore S (s i ) = O(α f ). Then the full Jacobian can be computed in time that is O poly(α f )poly(n)poly (|S|) . This result is consistent with that of Blum et al. <ref type="bibr">[2003]</ref>, in which the graphical game representation is leveraged to speed up computation of the payoff Jacobian. We note that for strict independence there is a result for AGGs similar to Equation (26) indicating that further elements of the Jacobian are equal; also, the domain of the product in equation (21) can be reduced. These provide further (polynomial) speedup. We omit these results here for reasons of space but note that the full exponential speedup described in <ref type="bibr" target="#b0">[Blum et al., 2003</ref>] is already obtained by projecting the action graph.</p><p>We note that for an arbitrary action-graph game, it may not be convenient to list the elements of each class S D (si) ; in such a case the Jacobian should be computed using Equations <ref type="formula" target="#formula_1">(20)</ref> and <ref type="formula" target="#formula_1">(21)</ref>. However, many games have structure that allows convenient iteration over members of these classes, and for such games the method of Equations <ref type="formula" target="#formula_1">(23)</ref> and <ref type="formula" target="#formula_1">(24)</ref> provide a constant speedup in computation of the Jacobian. In the method of Equations <ref type="formula" target="#formula_1">(20)</ref> and <ref type="formula" target="#formula_1">(21)</ref>, the utility function is evaluated O((I + 1) n ) times, whereas using Equations <ref type="formula" target="#formula_1">(23)</ref> and <ref type="formula" target="#formula_1">(24)</ref>  nonnegative integers (see e.g. <ref type="bibr" target="#b15">[Nijenhuis &amp; Wilf, 1975]</ref></p><formula xml:id="formula_29">), ∆ (si) ∀i,S i →S = n + S (s i ) − 1 S (si) − 1 . (27)</formula><p>This expression is a polynomial in n with degree S</p><formula xml:id="formula_30">(s i ) −1,</formula><p>and it follows that ∆</p><formula xml:id="formula_31">(s i ) ∀i,S i →S = Θ n S (s i ) −1 . (28)</formula><p>Thus max si ∆ (si) = O(n I ). So whereas computing the Jacobian using Equations <ref type="formula" target="#formula_1">(20)</ref> and <ref type="formula" target="#formula_1">(21)</ref> requires evaluating the utility function O((I + 1) n ) times, using Equations (23) and (24) require evaluating the utility function O(n I ) times. Since P r(s (s i ) |σ (si) ) is computed an exponential number of times in both cases, the overall speedup is by a constant factor.</p><p>In some games, utility functions depend linearly on the number of agents taking each action. This is true, e.g. for local-effect games <ref type="bibr" target="#b10">[Leyton-Brown &amp; Tennenholtz, 2003]</ref>, where the utility function is defined as </p><formula xml:id="formula_32">u(s i , D) = a∈S f si,a (D(a)) .<label>(</label></formula><formula xml:id="formula_33">u s i , D (s i ) (a→a ) = u s i , D (s i ) + f s i ,a D (s i ) (a→a ) (a) − f s i ,a D (s i ) (a) + f si,a D (si) (a→a ) (a ) − f si,a D (si) (a )</formula><p>. <ref type="formula" target="#formula_2">(30)</ref> Thus the summation in Equation <ref type="formula" target="#formula_1">(29)</ref> can be evaluated once rather than |∆ (s i ) | times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Symmetric equilibria</head><p>Nash proved <ref type="bibr">[1951]</ref> that all finite symmetric games have at least one symmetric equilibrium. We seek such an equilibrium here, specializing to the case in which all agents have the same action choices: ∀i, ∀j, S i = S j = S. All agents use the same mixed strategy: σ i = σ j ≡ σ * . In order to compute a symmetric equilibrium, the continuation method must be seeded with a symmetric equilibrium of the perturbed (λ = 1) game. This is accomplished by giving all agents the same bonus, so in the perturbed initial equilibrium all agents take the same action. Then since the path-following algorithm is symmetric (i.e. the operation of propagation along the path commutes with the permutation of agent identities), the path-following algorithm takes a symmetric perturbed equilibrium to a symmetric equilibrium of the unperturbed game.</p><p>Since all agents have the same strategies, each pure action profile is equally likely, so for any</p><formula xml:id="formula_34">s ∈ S(D (si) ) P r D (s i ) |σ (si) * = S(D (s i ) ) P r s (si) |σ (si) * ,<label>(31)</label></formula><p>where</p><formula xml:id="formula_35">P r s (s i ) |σ (si) * = a∈S (s i ) (σ (si) * (a)) D (s i ) (a) .<label>(32)</label></formula><p>The classes vary exponentially in size. Sizes are given by</p><formula xml:id="formula_36">S D (si) = n! a∈S (s i ) D (si) (a) !<label>(33)</label></formula><p>which is the multinomial coefficient. The largest classes are those in which agents are distributed as uniformly as possible across the nodes of the projected graph (relative to the unprojected graph, this corresponds to having just as many agents choosing each action in ν(s i ) as choose all the other actions combined).</p><p>Furthermore, the Jacobian simplifies, since we need no longer consider individual agent identities in V , so instead of considering V i,i s i ,s i (σ), we consider V * s,s (σ * ), which equals V i,i s i ,s i (σ) for any i = i . We replace the strategy improvement mapping of Equation <ref type="formula" target="#formula_1">(12)</ref> with</p><formula xml:id="formula_37">σ * = R(σ * + V * (σ * )).<label>(34)</label></formula><p>We can thus compute the Jacobian as</p><formula xml:id="formula_38">V * si,s i (σ * ) = D (s i ) ∈∆ (s i ) u s i , D s i , s i , D (s i ) P r D (s i ) |σ (s i ) *<label>(35)</label></formula><p>where P r(D   <ref type="formula" target="#formula_1">(32)</ref>, the results for all other projected distributions (nodes) can be computed by using Equation (36) at each subsequent step on the path. Generating the Hamiltonian path corresponds to finding a combinatorial Gray code for compositions; an algorithm with constant amortized running time is given by <ref type="bibr" target="#b6">Klingsberg [1982]</ref>. To provide some intuition, it is easy to see that a simple, "lawnmower" Hamiltonian path exists for any lower-dimensional projection of H ∆ (s i ) , with the only state required to compute the next node in the path being a direction value for each dimension.</p><formula xml:id="formula_40">P r D (si) (a→a ) |σ (s i ) * = σ (s i ) * (a )D (s i ) (a) σ (si) * (a) D (si) (a ) + 1 P r D (si) |σ (s i ) * .<label>(36</label></formula><p>Theorem 2 Computation of the Jacobian for symmetric action-graph games using Equations (35), (31), (32) and (36) takes time that is O(poly(n I )poly(|S|)).</p><p>Proof. Recall from Equation (28) that when all agents have the same action choices, ∆</p><formula xml:id="formula_41">(si) = Θ n S (s i ) −1 .<label>(37)</label></formula><p>The summation for an element of the Jacobian V * therefore has Θ n S (s i ) −1</p><p>terms. If the utility function is taken to be straightforward to compute, then the initial summand requires O(n) time. Through dynamic programming the computation of subsequent summands can be done in constant time. Since there are O(|S| 2 ) independent entries in the Jacobian to be computed, the computation of the symmetric Jacobian takes time O(poly(n I )poly(|S|)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and Future Work</head><p>This paper introduced action-graph games, which compactly represent both strict and context-specific independencies between players' utility functions. We showed how the structure of this graph can affect the computation of the Jacobian of the payoff function, the bottleneck step of the Govindan and Wilson continuation algorithm. We presented algorithms for computing both general and symmetric equilibria of AGGs. We showed that in the general case, computation of the Jacobian grows exponentially with the action graph's maximal in-degree rather than with its total number of nodes, yielding exponential savings. We also showed that the Jacobian can be computed in polynomial time for symmetric AGGs when the action graph's maximal in-degree is constant, and described two dynamic programming techniques to further speed up this case.</p><p>The full version of this paper will include two sections that could not be included here. First, a game is k-symmetric if agents have one of k types and all agents of a given type affect other agents in the same way (see e.g. Example 3). Nash's proof that a symmetric equilibrium exists in every finite symmetric game implies that a k-symmetric equilibrium exists in every finite k-symmetric game. We will extend our results to the k-symmetric case, showing that the Jacobian can still be computed in polynomial time for constant k. Second, we will provide an implementation and experimental evaluation of our algorithms, derived from the publicly available implementation of Blum et al. <ref type="bibr">[2003]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 1: AGG representation of an arbitrary 3-player, 3-action game</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>{i,i } and σ −{i,i } .the distribution that results when the actions of i and i are added to D.</head><label></label><figDesc></figDesc><table>As a 
shorthand for the subscript −{i, i }, which we will need 
frequently in the remainder of the paper, we use an overbar, 
yielding ∆, D, N , S, S, Σ and σ . When only one agent is 
omitted, we write e.g. ∆ −i . Finally, we overload our no-
tation, denoting by D(s i , s 
i , D) </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>and a new node denoted ∅. The only edges included in G (s) are the directed edges from each of the nodes ν(s) to the node s. The projected distribution D (s) is defined over the nodes of G (s) as</head><label></label><figDesc></figDesc><table>Finally, we describe the projection of a distribution of 
agents onto a smaller action space. Intuitively we construct 
a graph from the point of view of an agent who took a par-
ticular action, expressing his indifference between actions 
that do not affect his chosen action. For every action s ∈ S 
define a reduced graph G (s) by including only the nodes 
ν(s) </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>in terms of the pro- jected distribution D (s i ) rather than the projected pure ac- tion profile s (s i ) , obtaining</head><label></label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>for each s (s i ) ∈ S D (si)</head><label></label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>it is evaluated once for each D (s i ) ∈ ∆ (s i ) .</head><label></label><figDesc></figDesc><table>Consider the operation of extending all 

agents' action sets via ∀i, S i → S. Then 



∆ 

(si) 



is bounded 

from above by 



∆ 

(s i ) 





∀i,S i →S 

. This bound is the number 

of (ordered) combinatorial compositions of n into 



S 

(s i ) 





</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>si) |σ (s i ) * ) is given by(s i ) as D (s i ) ≡ D (s i ) (a→a ) . Then consider the graph H ∆ (s i ) whose nodes are the elements of the set) | − 1)-dimensional simplex. Having computed P r(D (s i ) |σ (s i ) * ) for one node of H ∆ (s i ) corre- sponding to distribution D (s i ) , we can compute the result for an adjacent node in O(|S (si) |) time:</head><label></label><figDesc></figDesc><table>Eqns (31) and (32). Bet-
ter still, dynamic programming allows us to avoid reeval-
uating these equations for every D 
(si) ∈ ∆ 
(si) . Denote 

the distribution obtained from D 
(s i ) by decrementing by 

one the number of agents taking action a ∈ S 
(s i ) and 

incrementing by one the number of agents taking action 
a ∈ S 
∆ 
(si) , and 

whose directed edges indicate the effect of the operation 
(a → a ). This graph is a regular triangular lattice in-

scribed within a (|S 
(s i </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>) H ∆ (s i ) always has a Hamiltonian path [Knuth, unpub- lished], so having computed P r(D (s i ) |σ (s i ) * ) for an ini- tial D (s i ) using Equation</head><label></label><figDesc></figDesc><table></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A continuation method for Nash equilibria in structured games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shelton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Game theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fudenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tirole</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A global Newton method to compute Nash equilibria</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Govindan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Economic Theory</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="65" to="86" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Computing Nash equilibria by iterated polymatrix approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Govindan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Economic Dynamics and Control</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1229" to="1241" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Graphical models for game theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Littman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>UAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Efficient Nash computation in large population games with bounded influence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mansour</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>UAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Gray code for compositions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Klingsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Algorithms</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="41" to="44" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On the strategic stability of equilibria</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kohlberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mertens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1003" to="1038" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multi-agent influence diagrams for representing and solving games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Milch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">La</forename><surname>Mura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
		<title level="m">Game networks. UAI</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Local-effect games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Leyton-Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tennenholtz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Computation of equilibria in finite games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mckelvey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mclennan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of computational economics</title>
		<editor>J. R. H. Amman</editor>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Potential games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Monderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shapley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Games and Economic Behavior</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="124" to="143" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Equilibrium points in n-person games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Nash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="1950" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="48" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Non-cooperative games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Nash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematics</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="286" to="295" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Combinatorial algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nijenhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Wilf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975" />
			<publisher>Academic Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Algorithms, games and the internet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Papadimitriou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>STOC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A class of games possessing purestrategy Nash equilibria</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rosenthal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Game Theory</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="65" to="67" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Bounding the inefficiency of equilibria in nonatomic congestion games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Roughgarden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tardos</surname></persName>
		</author>
		<idno>TR2002-1866</idno>
		<imprint>
			<date type="published" when="2001" />
			<pubPlace>Cornell, Ithaca</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Multi-agent algorithms for solving graphical games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vickrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
