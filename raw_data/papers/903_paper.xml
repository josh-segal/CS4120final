<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:37+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fine-Grain Performance Scaling of Soft Vector Processors</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>October 11-16, 2009</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Yiannacouras</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<addrLine>10 King&apos;s College Road Toronto</addrLine>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Gregory</forename><surname>Steffan</surname></persName>
							<email>steffan@eecg.utoronto.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<addrLine>10 King&apos;s College Road Toronto</addrLine>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Rose</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<addrLine>10 King&apos;s College Road Toronto</addrLine>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Fine-Grain Performance Scaling of Soft Vector Processors</title>
					</analytic>
					<monogr>
						<title level="m">CASES&apos;09</title>
						<meeting> <address><addrLine>Grenoble, France</addrLine></address>
						</meeting>
						<imprint>
							<date type="published">October 11-16, 2009</date>
						</imprint>
					</monogr>
					<note>Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>C13 [Processor Architectures]: Other Architecture Styles-Adaptable architectures General Terms Measurement</term>
					<term>Performance</term>
					<term>Design Keywords Soft processor</term>
					<term>FPGA</term>
					<term>vector</term>
					<term>SIMD</term>
					<term>microarchitecture</term>
					<term>VESPA</term>
					<term>VIRAM</term>
					<term>ASIP</term>
					<term>SPREE</term>
					<term>custom</term>
					<term>application spe- cific</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Embedded systems are often implemented on FPGA devices and 25% of the time [2] include a soft processor-a processor built using the FPGA reprogrammable fabric. Because of their prevalence and flexibility, soft processors are compelling targets for customization-although current soft processors provide few architectural variations. Recent work has proposed augmenting soft processors with customizable vector processing support, enabling designers to easily scale performance by exploiting the data parallelism available in an application. However this approach provides only coarse-grain scaling, by successively doubling the number of vector datapaths for less than double the performance. In this work we further augment soft vector processors with more fine-grain architectural modifications: we add support for (i) vector chaining and (ii) heterogeneous vector lanes, allowing the soft vector processor to be customized to not only the data-level parallelism available in an application , but to the functional unit demand. We evaluate the area and wall clock performance with full hardware implementations on state-of-the-art FPGAs and find that chaining can provide between 15-45% average performance for less area than doubling the lanes, and that heterogeneous lanes can save 6-13% area with little or no performance loss in some cases. Finally, we implement 1200 soft vector processors variants and find that the peak performance per area compared to our base vector processor can be increased by an average of 13% and up to 34% when choosing the best variant per application.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>FPGAs are commonly used to implement embedded systems because of their low cost and fast time-to-market. Approximately 25% of FPGA designs contain a processor implemented in the FPGA reprogrammable fabric <ref type="bibr" target="#b1">[2]</ref>, such as the Altera Nios II or Xilinx Microblaze. These soft processors provide a software design environment for quickly implementing system components which do not require highly-optimized hardware implementations and can instead be implemented in a soft processor that is customized to achieve the desired performance/area/power. Current commercial soft processors are based on simple singleissue pipelines with few architectural variations, motivating research on configurable soft processor architectures that enable further customization.</p><p>While the customization of traditional hard processors has been thoroughly studied, the trade-offs on an FPGA substrate can be vastly different yet accurately measuredincluding area, clock speed, and power. As a result, several architectural axes have been recently studied in a soft processor context including: (i) single-issue inorder pipelines <ref type="bibr" target="#b16">[17]</ref> which provide a limited design space; (ii) VLIW pipelines <ref type="bibr" target="#b10">[11]</ref> which are limited due to port limitations on FPGA block memories; (iii) multi-threaded pipelines <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b12">13]</ref> and multiprocessors <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref> which exploit thread-level parallelism but require parallelization of the software; and (iv) vector processors <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref> which can scale performance by instantiating multiple vector lanes (the perelement datapaths of a vector processor) to exploit the datalevel parallelism in an application. However, the flexibility of recently proposed soft vector processors is primarily limited to scaling the number of vector lanes by powers-of-two, to avoid division and multiplication operations in the control. For example, lane scaling provides only seven different configurations between a one-lane soft vector processor that consumes a fraction of the smallest FPGA device and a 64-lane configuration that fills one of the largest FPGA devices currently available-hence a system designer is provided with only very coarse-grain (powers-of-two) control over performance/area trade-offs when choosing an appropriate soft vector processor instantiation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Fine-Grain Customization of Soft Vector Processors</head><p>In this work we extend soft vector processors with architectural features that allow for more fine-grain customization over current single-issue soft vector processors. Specifically we target the varying functional unit demand across applications by implementing (i) vector chaining, while parameterizing the number of vector instructions that can be simultaneously executed; and (ii) heterogeneous lanes, that parameterize the functional units that exist within individual lanes.</p><p>Vector Chaining A vector processor with support for vector chaining can begin execution of the element operations of one vector instruction before completing all the element operations of a previous vector instruction <ref type="bibr" target="#b9">[10]</ref>.</p><p>To support this simultaneous execution of multiple vector instructions, many operands must be read/written from/to the vector register file simultaneously. The conventional solution is to exploit a many-ported register file-but this design is not well-suited to an FPGA substrate since the block memories on FPGAs are normally limited to only two ports. Instead we propose to support chaining through a banked register file where the number of banks determines how many vector instructions can be in-flight. For some benchmarks, this results in significantly better utilization of the existing functional units and even motivates the replication of functional units in high demand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Heterogeneous Lanes</head><p>Typically the lanes in a vector processor are identical, requiring all functional units to exist even when data-parallel code uses only some of them. We introduce the ability to have a given functional unit supported in only a subset of the lanes, thus supporting heterogeneous lanes where some lanes are missing certain functional unit types. For those lanes, operations are timemultiplexed onto the lanes which do support the required functional unit. A designer can therefore create the exact number of desired functional units, similar to what would be done in a custom hardware design.</p><p>We evaluate these modifications using a full in-hardware implementation on a Stratix III FPGA executing data parallel EEMBC benchmarks. We show that with chaining we gain significant performance with more modest area cost than doubling the number of lanes. We show that heterogeneous lanes can provide area savings over homogeneous lanes with little or no performance degradation. Finally, compared to all previously possible configurations, we gain up to 34% performance-per-area after exhaustively searching the design space to minimize performance-per area on a perapplication basis.</p><p>Our goal is to enable fine-grain customization of soft processors, allowing an FPGA-based embedded systems designer to use a few architectural parameters to specify a soft processor optimized to specific application and system design requirements; as a result, the amount of laborious hardware design is reduced. In the long term we envision that FPGA CAD tools will employ soft processor generators in conjunction with heuristics for automatically mapping applications to architectural configurations under a given performance/area constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Related Work</head><p>Vector processor architecture has been thoroughly studied both in multi-chip supercomputers and single-chip microprocessors <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b11">12]</ref>, but much less so in the FPGA context. The FPGA design flow allows us to accurately measure area, clock speed, and real in-system performance of benchmarks. Finally, the reprogrammability of an FPGA leads us to appreciate architectural features that can benefit only a few applications, whereas historically these features would be deemed failures in a general-purpose context.</p><p>Yu et. al. <ref type="bibr" target="#b20">[21]</ref> recently demonstrated the potential for vector processing as a simple-to-use and scalable accelerator for soft processors. In particular, the authors show that a vector processor can scale performance better than Altera's C2H behavioral synthesis tool. They also propose configurable architectural options such as lane-local memories and direct support for vector reductions which both exploit FPGAspecific features. However, their design does not support vector chaining nor heterogeneous vector lanes.</p><p>Hasan et. al.</p><p>[8] designed a floating point FPGA-based vector processor for solving sparse sets of equations. Using this application a number of targetted customizations were performed including vector chaining. Follow on work <ref type="bibr" target="#b8">[9]</ref> considered partial reconfiguration to create custom hardware units for an application. Cho et. al. studied a 16-way integer SIMD processor for multimedia kernels <ref type="bibr" target="#b3">[4]</ref> and explored the effect various levels of banking in the memory. Our work considers soft vector processor architecture more generally and thoroughly explores a large design space.</p><p>In our own previous work <ref type="bibr" target="#b19">[20]</ref> we implemented the VESPA FPGA-based vector processor in dated 130nm hardware and evaluated its performance scalability up to 16 lanes across various data parallel EEMBC benchmarks. No support for vector chaining or heterogeneous lanes was considered. Some parameterization of the instruction set was explored, but this customization can be orthogonal to any architectural tuning. Similarly, the memory system was explored, but its customization can be influenced by the scalar processor which often shares the cache. Customizing the vector processor compute architecture and pipeline through chaining and heterogeneous lanes can specifically target the vectorized workload and adds another much needed dimension of customizability to soft vector processors-in this work we build on VESPA to evaluate these features. In addition, we port the VESPA system to new 65nm FPGA hardware enabling the exploration of larger soft vector processor architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Contributions</head><p>This paper makes the following contributions: (i) we implement VESPA on a state-of-the-art Stratix III FPGA device while accurately measuring area, clock frequency, and cycle performance of our modifications using full EEMBC benchmarks executed from off-chip DDR2 memory; (ii) we propose and evaluate an FPGA-specific implementation of vector chaining with the required register file bandwidth facilitated exclusively via banking; (iii) we propose and investigate heterogeneous vector lanes in a soft vector processor; and (iv) we exhaustively explore a design space of 1200 VESPA configurations and show that these modifications allow for more fine-grain architectural customization as well as better performance per area.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">IMPLEMENTING FINE-GRAIN CUSTOMIZATIONS</head><p>In this section we describe the parameterized base VESPA design implemented in Verilog then describe how we augment it with fine-grain customization features-namely support for both vector chaining and heterogeneous lanes. <ref type="figure" target="#fig_0">Figure 1</ref> shows a block diagram of the VESPA processor that consists of a scalar MIPS-based processor automatically generated using the SPREE system <ref type="bibr" target="#b17">[18]</ref>, coupled with a parameterized vector coprocessor based on the VIRAM <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b11">12]</ref> vector instruction set. <ref type="figure" target="#fig_1">Figure 2</ref> the pipelines within VESPA. The scalar SPREE processor is a 3-stage pipeline with full forwarding and a 1-bit branch history table. The parameters of the VESPA system are listed in <ref type="table" target="#tab_1">Table 1</ref> with our newly added parameters marked with an asterisk. The top group of parameters configure the compute architecture, the middle group configures the instruction set architecture, and the bottom group configures the memory architecture. VESPA's architecture and parameters are as follows: The vector coprocessor consists of L parallel vector lanes where each lane can perform operations on a single element in a pipelined fashion. The width W of each vector lane datapath is 32 bits by default, but can be reduced for applications that require less than the full 32 bit-width. MVL determines the maximum vector length supported in hardware.  The scalar processor and vector coprocessor share a single instruction stream fed by an instruction cache. The scalar processor and vector coprocessor are both in-order pipelines, but can execute out-of-order with respect to each other except for memory operations which are serialized to maintain sequential consistency. Both share a directmapped data cache with parameterized depth DD and cache line size DW. A crossbar routes each byte in a cache line to/from M of the L vector lanes in a given cycle. A full crossbar (M=L) can significantly reduce the clock frequency of the design when L is large; in such cases M can be reduced to restore the clock rate and save area, but additional cycles will be required to move data between the cache lines and vector lanes. The data cache is equipped with a hardware prefetcher configured with parameters DPK and DPV. In this work we use only two prefetching configurations: off and prefetching of 8 times the current vector length (no prefetching is done for scalar instructions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Base VESPA Design</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Supporting Vector Chaining</head><p>VESPA has three functional unit types, an ALU, a multiplier/shifter, and a memory unit, but only one functional unit type can be active at a time. Additional parallelism can be exploited by noting that for sufficiently long vectors, the first element-operations of one vector instruction are guaranteed to be independent of the last element-operations of another. Traditional vector processors exploit this using a large many-ported register file to feed operands to all functional units keeping many of them busy simultaneously. This approach was shown to be more area-efficient than using many banks and few ports as in historical vector supercomputers <ref type="bibr" target="#b2">[3]</ref>. But since FPGAs can not efficiently implement a large many-ported register file, our solution is to return to this historical approach and use multiple banks each with 2 read ports and 1 write port (achieved by duplicating the register file). We partition the vector elements among the different banks allowing instructions operating on different elements to each use a register bank to feed their respective functional unit thus achieving the multiple vector instruction execution required for vector chaining. <ref type="figure">Figure 3</ref> shows an example of our implementation of vector chaining using two register banks to support a maximum of 2 vector instructions in flight for a 1-lane VESPA processor. Once resource, read-after-write, and bank conflicts are resolved, instructions will enter the Bank Queue and cycle between the even and odd element banks until all element operations are completed. During that time another instruction can enter the queue and rotate through the cyclical Bank Queue resulting in 2 element operations being issued per cycle. As each operation completes the result is written back to the appropriate register bank. Using a cyclical queue simplifies the control logic necessary for assigning a bank to an element operation, but causes a cycle delay for the few vector instructions which can not start on an even element (most vector instructions start with element 0).</p><p>The number of register banks B used to support vector chaining is parameterized and must be a power of two. A value of 1 reduces VESPA to a single-issue vector processor without vector chaining support eliminating the Bank Queue and multiplexing. VESPA can potentially issue as many as B instructions at a time, provided they each have available functional units. To increase the likelihood of this, VESPA allows replication of the ALU for each bank, the APB parameter enables or disables this feature. Since multipliers are generally scarce we do not support duplication for the multiply/shift unit, and we also do not support multiple memory requests in-flight because of VESPA's locking cache.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Supporting Heterogeneous Lanes</head><p>Increasing the vector lanes duplicates the default lane configuration, so all vector lanes are identical, or homogeneous. In this work we modify this assumption by allowing the multiplier units (also used for shifting) to appear in only some of the lanes. This allows for a heterogeneous mix of lanes where not all lanes will have each of the three functional unit types. A user can specify the number of lanes with ALUs using L, the number of lanes with multipliers with X, and the number of lanes with access to the cache with M. Because of the frequency of ALU operations across the benchmarks and because of their relative size compare to the overhead, we do not support the elision of ALUs. Therefore VESPA requires that L is greater than or equal to the greater of X or M. This is a reasonable limitation since the multipliers are generally scarce, and the memory crossbar generally large, so reducing those units will have greater impact on area savings while being more likely to only mildly affect performance.</p><p>As shown in <ref type="figure" target="#fig_3">Figure 4</ref> some area overhead is required to buffer operands and time-multiplex operations into the lanes which have the desired functional units, so the area savings from removing multipliers and shrinking the crossbar must offset this. In place of the missing functional units is a parallel-loading Input Queue which accepts input operands from all lanes with missing functional units and transfers them to the corresponding lanes that have the functional unit. The output is then loaded into an Output Queue which transfers the results back to the original lane.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">MEASUREMENT METHODOLOGY</head><p>In this section we describe our infrastructure used for executing, verifying, and evaluating the new VESPA features. Specifically, we describe our hardware platform, processor system, verification process, CAD tool measurement methodology, benchmarks, and compiler.</p><p>Hardware Platform All processors are fully synthesized and implemented on an FPGA system.</p><p>We use the Terasic DE3-340 board equipped with a single Stratix III EP3SL340H1152C3 which is one of the largest state-of-theart FPGAs currently available. We also use a 1GB DDR2-533 memory device for the storage of instructions and data in a program.</p><p>Processor System Each design consists of the VESPA soft vector processor with separate first-level direct-mapped instruction and data caches and the Altera DDR2 full-rate memory controller that connects to the DDR2 DIMM. The VESPA configurations are capable of 100-110MHz clock rates on the mid-speed 3S340C3 device. However we clock all designs at 100 MHz and the memory system at 266 MHz and then correct the wall clock time using the highest clock frequency achievable by that design on a faster 3S340C2. This allows us to model the performance of high-end FPGAs without owning them. The time dilation effects between the processor and memory from this correction generally do not affect the results significantly.</p><p>Testing All instances of VESPA are fully tested in hardware using the built-in checksum values encoded into each EEMBC benchmark. Debugging is performed using Modelsim and is guided by comparing traces of all writes to the scalar and vector register files. This trace is extracted from RTL simulation using Modelsim and compared against an analogous trace obtained from instruction-set simulation using the MINT <ref type="bibr" target="#b15">[16]</ref> MIPS simulator augmented with the VIRAM extensions. Altera SignalTap II is used for inhardware debugging. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">COARSE-GRAIN TRADE-OFFS: VECTOR LANES</head><p>In this section we show the powerful scaling afforded by soft vector processors and point out the gaps in the design space that need to be filled. <ref type="figure">Figure 5</ref> shows the cycle performance improvement for each of our benchmarks as we increase the number of lanes on an otherwise aggressive VESPA architecture with full memory support (full memory crossbar, 16KB data cache with 64-byte cache lines and hardware prefetching). The figure verifies that impressive  scaling still exists between 1 and 16 lanes on our state-ofthe-art hardware platform. We also measure the effect of 32 lanes for the first time and notice that the performance scaling continues for benchmarks which have the available data parallelism. We see 10x average performance for 16 lanes, and 14x for 32 lanes with a peak of 24x. <ref type="figure">Figure 6</ref> shows the area/performance space for these configurations and highlights the coarse-grain nature of using vector lanes to trade area and performance. The area cost of increasing the number of lanes can be substantial, for example growing from 8 to 16 lanes requires more than 10000 ALMs worth of silicon. While this powerful parameter allows VESPA to take leaps in the area/performance space, our new architectural parameters enable more fine-grain area/performance trade-offs as shown in the next section.  </p><note type="other">0 5 1 0 1 5 2 0 2 5 C y c l e S p e e d u p v s 1 L a n</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">FINE-GRAIN TRADE-OFFS</head><p>In this work we added parameterized vector chaining to VESPA, as well as heterogeneous lanes which allows a user to have L lanes of ALUs, X lanes of multipliers, and M lanes for the memory crossbar. These additions can be used to customize the vector core to the functional unit demands in an application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Impact of Vector Chaining</head><p>We measured the effect of vector chaining via register file banking across our benchmarks using a vector processor with full memory support. We vary the number of banks from 2 to 4 and for each toggle the ALU per bank APB parameter and compare the resultant four designs to a single bank (no vector chaining) VESPA. <ref type="figure" target="#fig_5">Figure 7</ref> shows the cycle speedup of chaining across our benchmarks for an 8-lane vector processor, as well as the area normalized to the 1 bank configuration. The area cost of banking is considerable, starting at 27% for a second register bank and the expensive multiplexing logic needed between the 2 banks and functional units. The average performance improvement of this 27% area investment is approximately 26%, and in the best case is 54%. Note that if instead of adding a second bank, the designer opted to double the number of lanes to 16, the average performance gain would be 49% for an area cost of 77%. Two banks provide half that performance improvement at one third the area, and is hence clearly a more fine-grain trade-off than increasing lanes.</p><p>Replicating the ALUs for each of the 2 banks (2 banks, 2 ALUs) provides some additional performance, except for fbital where the performance improvement is significant. fbital executes many arithmetic operations per datum making demand for the ALU high and hence benefiting greatly from increased ALUs and justifying the additional 7% area. Similarly the 4 bank configuration with no ALU replication benefits only few benchmarks, specifically rgbyiq, imgblend, filt3x3. These benchmarks have a near equal blend of arithmetic, multiply/shifting, and memory operations and thus benefit from the additional register file bandwidth of extra banks. However the area cost of the 4th bank becomes significant at 59%. Finally, <ref type="bibr">with</ref>   of the 1 bank configuration, our benchmarks and singleissue pipeline with locking cache can not exploit this peak performance. <ref type="figure" target="#fig_6">Figure 8</ref> shows that the speedup achieved from banking is reduced as the lanes are increased. Chaining allows multiple vector instructions to be executed if both the appropriate functional unit and register bank are available. But because only one instruction is fetched per cycle, chaining is only effective when the vector instructions are long enough to stall the vector pipeline, in other words, when the length of a vector is greater than the number of lanes. As the number of lanes increases, vector instructions are completed more quickly providing less opportunity for overlapping execution. In the slowest vector processor speedups from banking can average as high as 60% across our benchmarks, while in the fastest banking achieves only 23% speedup. The 1 lane vector processor represents a peak speedup achievable under extremely high load with long vector operations on the vector coprocessor.</p><p>The vector register file is comprised of many FPGA block RAMs. Given block RAMs with maximum width WBRAM and total depth of DBRAM , and using the parameters from <ref type="table" target="#tab_1">Table 1</ref>, the number of block RAMs is equal to the greater of L · W · B/WBRAM or 32MV L × W/DBRAM . For vector processors with many lanes, making the first expression greater, adding more banks increases the number of block RAMs used. For example increasing from 1 to 4 banks with no ALU replication on a 16 lane VESPA with MVL=128 adds 38% area just in block RAMs and 56% in total. On a design with many unused block RAMs this increase can be justified, moreover the added capacity of the block RAMs can be fully utilized by the vector processor with a corresponding increase in MVL. <ref type="figure">Figure 9</ref> shows the wall clock time versus area space of the no chaining (solid dots) configurations from 1 to 16 lanes, identical to <ref type="figure">Figure 6</ref>. We overlay two vector chaining configurations on the same figure and observe that the points with 2 banks appear about one third of the way to the next solid dot, proving that chaining can trade area/performance at finer increments than doubling lanes. Note that the 4 bank configurations are omitted since the area cost is significant and the additional performance is often modest compared to 2 banks. Since we have complete measurement capabilities of the area and performance we are able to identify that vector chaining in this case is indeed a tradeoff and not a global improvement (it did not move VESPA toward the origin of the figure). Figure 10: Performance impact of varying X for a VESPA with L=32, M=16, DW=64, DD=16K, and DPV=8VL, area and performance is normalized to the X=32 configuration.</p><p>Another option for fine-grain area/performance tradeoffs is to use lane configurations that are not powers of two, resulting in cumbersome control logic which involves multiplication and division operations. Since the control logic is often critical, and the additional area overhead significant, this approach would likely generate inferior configurations that, in terms of <ref type="figure">Figure 9</ref>, would form a curve further from the origin than the processors with lanes that are powers of two. Chaining, on the other hand is shown to directly compete with these configurations, and in Section 6 is shown to even improve performance per unit area. Note that instruction scheduling in software could further improve the performance of vector chaining, but in many of our benchmarks only very little rescheduling was either necessary or possible, so we did not manually schedule instructions to exploit chaining.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Impact of Heterogeneous Lanes</head><p>The X parameter determines the number of lanes with multiplier units. We evaluate the effect of varying X on a 32 lane VESPA processor with 16 memory crossbar lanes and a prefetching 16KB data cache with 64B line size. Each halving of X doubles the number of cycles needed to complete a vector multiply. We measure the overall cycle performance and area and normalize it to the full X=32 configuration. <ref type="figure" target="#fig_0">Figure 10</ref> shows that in some benchmarks such as filt3x3 the performance degradation is dramatic, while in other  benchmarks such as conven there is no impact at all. Programs with no vector multiplies can have multipliers removed completely with the instruction-set subsetting technique explored in <ref type="bibr" target="#b19">[20]</ref>, but programs with just few multiplies such as viterb can have its multipliers reduced with very small performance penalties. The resultant saved area can then be used for other architectural features or components of the system. The area savings from reducing the multipliers is small starting at 6% for halving the number of multipliers to 16, the savings asymptotically grow and saturate at 13%. Since the multipliers are efficiently implemented in the FPGA as a dedicated block, the contribution to the overall silicon area is small, and the additional overhead for multiplexing operations into the few lanes with multipliers ultimately cancel the area savings. However multipliers are often found in short supply, so a designer might be willing to accept the performance penalty if another more critical system component could benefit from the multipliers. <ref type="figure" target="#fig_0">Figure 11</ref> shows the effect on clock frequency as the number of lanes with multipliers is varied. The large memory crossbar is primarily responsible for the limited clock frequency in the design.</p><formula xml:id="formula_0">1 2 0 X = 1 X = 2 X = 4 X = 8 X = 1 6 X = 3 2 C l o c k F r e q u e n c y ( M H z ) N u m b e r o f L a n e s w i t h M u l t i p l i</formula><p>As a result removing multipliers has only a moderate impact on clock frequency. Specifically values of X between 2 and 8 achieve a 97 MHz clock over the original 93 MHz. The X=1 configuration achieves 95 MHz. All of the configurations match or improve on the clock of the full X=32 configuration. In general we do not expect the inserted logic for supporting heterogeneous lanes to degrade the clock frequency.</p><p>Overall the heterogeneous lanes mechanism provides an effective means of conserving FPGA dedicated multiplier block for applications which have low demand for them. The memory crossbar explored in <ref type="bibr" target="#b19">[20]</ref> uses the same heterogeneous lanes mechanism to reduce the crossbar size for applications which exhibit low demand of the memory system. Together these parameters can be used to closely match the instruction mix in an application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">EXPANDING THE VESPA DESIGN SPACE</head><p>With the new banking and heterogeneous lanes parameters, the VESPA design space has grown significantly making it increasingly interesting to pursue customized architectures. In this section we explore that design space and quantify the additional benefit of our new parameters.  We vary all combinations of the explored parameter values listed in the last column of <ref type="table" target="#tab_7">Table 3</ref> and implement each architectural configuration. Note that the instruction cache was not very influential so it is not explored here; we also do not perform any modifications which reduce the functionality of the vector processor (e.g. lane width reductions or instruction disabling). A total of almost 1200 designs were explored, with the new parameters expanding the number of design points by 8x. <ref type="figure" target="#fig_0">Figure 12</ref> shows the average performance and area of all the VESPA configurations. The design space spans a total of 15x in area and 19x in performance providing a wide range of design points for an FPGA embedded system designer to choose from. Moreover, VESPA now provides more fine-grain coverage of this design space. The pareto optimal points in the figure approximate a straight line providing steady performance returns on area investments until the high-area designs begin suffering from significant clock frequency decay. Additional retiming or pipelining can mitigate this decay. Currently clock frequencies range from 134 MHz to 91 MHz. The maximum area is over 50000 equivalent ALMs, which accounts for more than onequarter of the silicon area of the device. In terms of just logic implemented in Stratix III ALMs, the largest design consumes more than one-third of the available ALMs in the device.</p><p>As area is increased, two branches emerge: the topmost (slowest) being the designs throttled by a small 16B cache line size, and the middle branch throttled by cache misses without prefetching. With both larger cache lines and prefetching enabled the fastest and largest designs in the 5. (DD = 32KB) and (DW = 16B) -Configurations with extra block RAMs used only to expand the cache depth which was shown to be ineffective in accelerating benchmark performance <ref type="bibr" target="#b18">[19]</ref>.</p><p>We also add the values DPV=7 and MVL=4*L to the exploration. With these new values and the above exclusions, the design space is reduced to 768 configurations. We can further reduce this design space to a much smaller set of pareto-optimal configurations which dominate all other configurations on average across this benchmark set. Note that certain configurations can benefit a specific application without being pareto-optimal on average. <ref type="figure" target="#fig_0">Figure 13</ref> shows the wall clock performance and area design space of the pareto-optimal VESPA configurations after pruning and adding the new MVL and DPV values. The MVL value of 4*L instructs VESPA to implement a maximum vector length that is four times the number of lanes. Typically the maximum vector length is large to enable long vectors, but for a single lane configuration this only adds significant area overhead without significant performance. The 4*L value allows for much smaller configurations to be explored. The smallest pareto-optimal configuration is 1838 equivalent ALMs which is signficantly smaller than any of the previously explored configurations in <ref type="figure" target="#fig_0">Figure 12</ref>.</p><p>The pareto-optimal points span an area of 28x and wall clock times of 18x. This range of areas is much larger than the 15x seen previously because of the reason described above. The performance range however has been reduced slightly from 19x to 18x. This reduction is due to the eliminated low-performance configurations which are dominated by the faster pareto-optimal configurations. The peak performance is the same in both cases, but the worstcase performance for the pareto-optimal points is less than for the full 1200 point design space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Per-Application Analysis</head><p>A key motivation for FPGA-based soft processors is their ability to be customized to a given application. This application-specific customization can aid FPGA designers in meeting their system design constraints more quickly and more easily. We therefore analyze the configurations from the original 1200 point design space which achieve the best performance-per-area on a per-application basis. Using this analysis we quantify the benefit of selecting a custom VESPA configuration over the best overall configuration. <ref type="table" target="#tab_8">Table 4</ref> shows the VESPA configuration with the best performance-per-area for each benchmark selected out of the 1200 explored designs. Surprisingly, all chosen configurations have 2 banks, and fbital has the ALU per bank parameter enabled. Four of the chosen configurations also make use of the X parameter to instantiate half as many multipliers as lanes. The second-last column shows how much the performance-per-area has improved because of these new parameters compared to choosing the best configuration without the new parameters. We achieve up to 34% (average of 13%) better performance-per-area compared to the VESPA configurations without chaining and heterogeneous lanes.</p><p>The selected configurations for each benchmark vary significantly. For example fbital achieves a peak performanceper-area with a small 4 lane VESPA with aggressive chaining and small cache. Most benchmarks benefit from advanced memory systems, but none benefit from more than 16 lanes due to the clock frequency decay discussed earlier. The table also shows the best overall configuration across all benchmarks, which we refer to as the general purpose or GP configuration and is shown in the last row of the table. The general purpose VESPA uses chaining through 2 register banks and as a result increases its performance-per-area by 14% over the general purpose VESPA before adding these parameters. The last column shows the performanceper-area benefit of choosing a custom VESPA configuration for each benchmark compared to using the general purpose VESPA. On average a 12% performance-per-area benefit is seen, with a peak of 44%, motivating research into automatically selecting a configuration for a given application. Note that processors with similar performance-per-area can have drastically different performance and area profiles, amplifying the variation.</p><p>With the exception of viterb the benchmarks are characteristically similar: streaming-oriented across a large data set with little data re-use. With greater benchmark diversity we expect the improvements in selecting a per-application configuration to be significantly higher. Nonetheless, these improvements highlight the value in matching the soft vector processor architecture to the application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSIONS</head><p>We implemented VESPA in hardware using the Stratix III FPGA on a Terasic DE3 board which is equipped with a DDR2 DIMM. We verified the increased scalability of VESPA across a set of benchmarks mostly from the industry standard EEMBC suite, and noted the coarse-grain area/performance trade offs within it.</p><p>We proposed an FPGA-specific implementation of vector chaining facilitated exclusively through register file banks since FPGA block RAMs have only two access ports. We parameterized the number of banks in the architecture, as well as allowed duplication of the ALU for each bank and observed more fine-grain trade offs could be achieved. Performance gains averaged between 15% and 45% with area costs significantly less than doubling lanes.</p><p>We further augmented VESPA with the ability to implement heterogeneous lanes, allowing separate specification of the number of lanes with ALUs, multipliers, and memory units. This provided further fine-grain control over the architecture allowing each functional unit to exactly meet its demands. Between 6-13% area can be saved compared to homogeneous lanes, in some benchmarks, with little or no performance degradation.</p><p>We observed that our modified VESPA spans an enormous 28x space in area, and 18x in performance. The addition of our new parameters results in up to 34% (average 13%) increased peak performance per area achievable on a per-application basis over the previous VESPA. Our new architectural parameters further motivate the customization of soft processors to their application providing up to 44% (average 12%) better performance per area for choosing a unique configuration for each benchmark versus selecting one configuration for all benchmarks. This motivates further design space expansion and eventual inclusion of algorithms to map applications to processor configurations in FPGA CAD tools. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: VESPA processor block diagram.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: VESPA pipeline architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 : Vector chaining support for a 1 -lane VESPA processor with 2 banks.</head><label>31</label><figDesc>Figure 3: Vector chaining support for a 1-lane VESPA processor with 2 banks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Heterogeneous lanes support for multipliers on a VESPA with 4 lanes and X=1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 : Performance/area design space of 1- 32 lane VESPA cores with full memory support.</head><label>632</label><figDesc>Figure 6: Performance/area design space of 1-32 lane VESPA cores with full memory support.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 : Cycle performance of different banking configurations across our benchmarks on an 8-lane VESPA with full memory support.</head><label>7</label><figDesc>Figure 7: Cycle performance of different banking configurations across our benchmarks on an 8-lane VESPA with full memory support.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 : Cycle performance averaged across our benchmarks for different lane configuration all with full memory support.</head><label>8</label><figDesc>Figure 8: Cycle performance averaged across our benchmarks for different lane configuration all with full memory support.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 11 :</head><label>11</label><figDesc>Figure 11: Clock frequency impact of varying X for a VESPA with L=32, M=16, DW=64, DD=16K, and DPV=8VL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 12 : Average wall clock performance and area of 1200 soft vector processor variations.</head><label>12</label><figDesc>Figure 12: Average wall clock performance and area of 1200 soft vector processor variations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 13 : Average wall clock performance and area of pareto-optimal soft vector processor configura- tions from 768 pruned and expanded design space.</head><label>13</label><figDesc>Figure 13: Average wall clock performance and area of pareto-optimal soft vector processor configurations from 768 pruned and expanded design space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 : Configurable parameters for VESPA.</head><label>1</label><figDesc></figDesc><table>Parameter 
Symbol Value Range 

Compute 
Vector Lanes 
L 
1,2,4,8,16,. . . 
Memory Crossbar Lanes 
M 
1,2,4,8,. . . L 
Multiplier Lanes* 
X 
1,2,4,8,. . . L 
Register File Banks* 
B 
1,2,4,. . . 
ALU per Bank* 
APB 
true/false 

ISA 
Maximum Vector Length 
MVL 
2,4,8,16,. . . 
Vector Lane Bit-Width 
W 
1,2,3,4,. . . , 32 
Each Vector Instruction 
-
on/off 

Memory 

ICache Depth (KB) 
ID 
4,8,. . . 
ICache Line Size (B) 
IW 
16,32,64,. . . 
DCache Depth (KB) 
DD 
4,8,. . . 
DCache Line Size (B) 
DW 
16,32,64,. . . 
DCache Miss Prefetch 
DPK 
1,2,3,. . . 
Vector Miss Prefetch 
DPV 
1,2,3,. . . 

Bank 0 

(even 
elments) 

Mult/Shift 

Mem 
Unit 

A 
L 
U 

Bank 1 

(odd 
elments) 

M 
U 
X 
M 
U 
X 
M 
U 
X 
M 
U 
X 
M 
U 
X 

M 
U 
X 

Instr 

Bank 
Queue 

Vector 
Register 
File 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Benchmark applications. 
EEMBC 
Input 
Output Largest Vector 
Benchmark 
Description 
Source 
Suite (Dataset) size (B) size (B) 
Element 
autcor 
auto correlation 
EEMBC/VIRAM 
Telecom (2) 
1024 
64 
32 bits 
conven 
convolution encoder EEMBC/VIRAM 
Telecom (1) 
517 
1024 
1 bit 
rgbcmyk 
rgb filter 
EEMBC/VIRAM Digital Ent. (5) 1628973 2171964 
8 bits 
rgbyiq 
rgb filter 
EEMBC/VIRAM Digital Ent. (6) 1156800 1156800 
16 bits 
fbital 
bit allocation 
EEMBC/VIRAM 
Telecom (2) 
1536 
512 
16 bits 
viterb 
viterbi encoder 
EEMBC/VIRAM 
Telecom (2) 
688 
44 
16 bits 
ip checksum 
checksum 
EEMBC (kernel) 
Networking 
40960 
40 
32 bits 
imgblend 
combine two images 
VIRAM 
-
153600 
76800 
16 bits 
filt3x3 
image filter 
VIRAM 
-
76800 
76800 
16 bits 

FPGA CAD Tools A key value of performing FPGA-
based processor research directly on an FPGA is that we 
can attain high quality measurements of the area consumed 
and the clock frequency achieved-these are provided by 
the FPGA CAD tools. We use aggressive timing constraints 
to maximize the CAD tool's effort for default optimization 
settings but with register retiming and register duplication 
enabled. Through experimentation we found that these 
settings provided the best area, delay, and runtime trade-
off. We also performed 8 such runs for every vector 
configuration to average out the non-determinism in modern 
CAD algorithms. The relative silicon areas of each FPGA 
resource relative to a single Adaptive Logic Module (ALM) 
was supplied to us by Altera [5] for the Stratix II. We 
extrapolated this for Stratix III and used these equivalent 
areas to calculate the total silicon area consumed on the 
Stratix III measured in units of equivalent ALMs-the 
silicon area of a single ALM including its routing. 

Benchmarks As listed in Table 2, the top six are 
uncompromised benchmarks from the EEMBC [1] industry-
standard benchmark collection. 
The fifth is a kernel 
extracted from an EEMBC benchmark executing a hand-
made data set, and the last two benchmarks were provided 
to us from the VIRAM group. Cycle counts are collected 
from a complete execution on our hardware platform. 

Compilation Framework Benchmarks are built using a 
MIPS port of GNU gcc 4.2.0 with -O3 optimization level. 
Experiments with this version of gcc's auto-vectorization 
capability showed that it is in its infancy, preventing us 
from automatically generating vectorized code from key 
EEMBC program loops. Instead we use the GNU assembler 
ported to support VIRAM vector instructions. Hand-
vectorized assembly EEMBC routines were provided to us 
by Kozyrakis who used them during his work on the VIRAM 
processor [12]. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head></head><label></label><figDesc>4 banks and 4 ALUs per lane the area of VESPA is almost doubled exceeding the cost of adding more lanes while performing slower; as a result we do not further study this inferior configuration. Though its peak performance is 4x that</figDesc><table>0 

0 
. 
2 

0 
. 
4 

0 
. 
6 

0 
. 
8 

1 

1 
. 
2 

1 
. 
4 

1 
. 
6 

1 
. 
8 

1 
L 
a 
n 
e 
2 
L 
a 
n 
e 
s 
4 
L 
a 
n 
e 
s 
8 
L 
a 
n 
e 
s 
1 
6 
L 
a 
n 
e 
s 

C y c l 

e 
S 
p 
e e 
d 
u 
p 

4 
B 
a 
n 
k 
s 
, 
4 
A 
L 
U 
s 

4 
B 
a 
n 
k 
s 
, 
1 
A 
L 
U 

2 
B 
a 
n 
k 
s 
, 
2 
A 
L 
U 
s 

2 
B 
a 
n 
k 
s 
, 
1 
A 
L 
U 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="true"><head>Table 3 : Explored VESPA architectural parameters.</head><label>3</label><figDesc></figDesc><table>Parameter 
Symbol 
Explored 

Compute 
Vector Lanes 
L 
1,2,4,8,16,32 
Memory Crossbar Lanes 
M 
L, L/2 
Multiplier Lanes* 
X 
L, L/2 
Register File Banks* 
B 
1,2,4 
ALU per Bank* 
APB 
true/false 

ISA 
Maximum Vector Length 
MVL 
128, 256 
Vector Lane Bit-Width 
W 
-
Each Vector Instruction 
-
-

Memory 

ICache Depth (KB) 
ID 
-
ICache Line Size (B) 
IW 
-
DCache Depth (KB) 
DD 
8, 32 
DCache Line Size (B) 
DW 
16, 64 
DCache Miss Prefetch 
DPK 
-
Vector Miss Prefetch 
DPV 
off, 8*VL 

1 

2 

4 

8 

1 
6 

3 
2 

4 
0 
9 
6 
8 
1 
9 
2 
1 
6 
3 
8 
4 
3 
2 
7 
6 
8 
6 
5 
5 
3 
6 

N o r 
m 
a l i 
z 
e 
d 
W 
a l l 
C l 
o c 
k 
T i 
m 
e 

A 
r 
e 
a 
( 
E 
q 
u 
i 
v 
a 
l 
e 
n 
t 
A 
L 
M 
s 
) 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Configurations with best performance-per-area for each benchmark 
VESPA Configuration 
Performance per Area 
Benchmark 
DD 
DW DPV APB B MVL L M X vs old VESPA vs GP 
autcor 
8KB 16B 
0 
0 
2 
7 
8 
8 
8 
1.03 
1.19 
conven 
32KB 64B 8VL 
0 
2 
7 
8 
8 
4 
1.07 
1.05 
rgbcmyk 
32KB 64B 8VL 
0 
2 
7 
8 
8 
4 
1.10 
1.05 
rgbyiq 
32KB 64B 8VL 
0 
2 
8 
16 16 16 
1.21 
1.00 
ip checksum 
32KB 64B 8VL 
0 
2 
7 
8 
8 
4 
1.21 
1.05 
imgblend 
32KB 64B 8VL 
0 
2 
8 
16 16 16 
1.14 
1.06 
filt3x3 
32KB 64B 8VL 
0 
2 
8 
16 16 16 
1.34 
1.11 
fbital 
8KB 16B 
0 
1 
2 
7 
4 
4 
4 
1.05 
1.44 
viterb 
32KB 64B 8VL 
0 
2 
7 
4 
4 
2 
1.01 
1.18 
GEOMEAN 
1.13 
1.12 
General Purpose (GP) 32768 
64 
8VL 
0 
2 
7 
8 
8 
8 
1.14 
1 </table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<ptr target="http://www.eembc.org" />
		<title level="m">The Embedded Microprocessor Benchmark Consortium</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Altera Corporation. Private Communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Allen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Vector Microprocessors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Asanovic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
		<respStmt>
			<orgName>University of California-Berkeley</orgName>
		</respStmt>
	</monogr>
<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An fpga based simd processor with a vector memory unit. Circuits and Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Sung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 2006 IEEE International Symposium on</title>
		<meeting>2006 IEEE International Symposium on</meeting>
		<imprint>
			<date type="published" when="2006-05" />
			<biblScope unit="page" from="21" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Altera Corporation. Private Communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cliff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">CUSTARD -A Customisable Threaded FPGA Soft Processor and Tools</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dimond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Mencer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Field Programmable Logic (FPL)</title>
		<imprint>
			<date type="published" when="2005-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A multithreaded soft processor for sopc area reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Capalija</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">G</forename><surname>Vranesic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Field-Programmable Custom Computing Machines</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="131" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fpga-based vector processing for solving sparse sets of equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ziavras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Field-Programmable Custom Computing Machines, 2005. FCCM 2005. 13th Annual IEEE Symposium on</title>
		<imprint>
			<date type="published" when="2005-04" />
			<biblScope unit="page" from="331" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Runtime partial reconfiguration for embedded vector processors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Z</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Ziavras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Technology, 2007. ITNG &apos;07. Fourth International Conference on</title>
		<imprint>
			<date type="published" when="2007-04" />
			<biblScope unit="page" from="983" to="988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Computer Architecture; A Quantitative Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Hennessy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<pubPlace>San Francisco, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An fpga-based vliw processor with custom hardware execution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hoare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kusic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fazekas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Foster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FPGA &apos;05: Proceedings of the 2005 ACM/SIGDA 13th international symposium on Field-programmable gate arrays</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="107" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Scalable, vector processors for embedded systems. Micro</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kozyrakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Patterson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>IEEE</publisher>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="36" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Scaling Soft Processor Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Labrecque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yiannacouras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Steffan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Field-Programmable Custom Computing Machines (FCCM&apos;08)</title>
		<meeting><address><addrLine>Palo Alto, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">An fpga-based soft multiprocessor system for ipv4 packet forwarding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ravindran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Satish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005-08" />
			<biblScope unit="page" from="487" to="492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Application-Specific Customization and Scalability of Soft Multiprocessors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Unnikrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tessier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Field-Programmable Custom Computing Machines (FCCM&apos;09)</title>
		<meeting><address><addrLine>Napa, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">MINT: a front end for efficient simulation of shared-memory multiprocessors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Veenstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Fowler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Workshop on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS &apos;94)</title>
		<meeting>the Second International Workshop on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS &apos;94)<address><addrLine>Durham, NC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994-01" />
			<biblScope unit="page" from="201" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The Microarchitecture of FPGA Based Soft Processors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yiannacouras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Steffan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CASES&apos;05: International Conference on Compilers, Architecture and Synthesis for Embedded Systems</title>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="202" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Application-specific customization of soft processor microarchitecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yiannacouras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Steffan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">FPGA&apos;06: Proceedings of the International Symposium on Field Programmable Gate Arrays</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="201" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improving memory systems for soft vector processors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yiannacouras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Steffan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WoSPS&apos;08: Workshop on Soft Processor Systems</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Vespa: Portable, scalable, and flexible fpga-based vector processors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yiannacouras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Steffan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CASES&apos;08: International Conference on Compilers, Architecture and Synthesis for Embedded Systems</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Vector processing as a soft-core cpu accelerator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lemieux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Eagleston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Field programmable gate arrays</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="222" to="232" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
