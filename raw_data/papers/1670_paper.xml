<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:39+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Minimum Expected Distortion in Gaussian Source Coding with Uncertain Side Information</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">T K</forename><surname>Ng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Tian</surname></persName>
							<email>†chao.tian@epfl.ch</email>
							<affiliation key="aff1">
								<orgName type="department">School of Computer and Communication Sciences</orgName>
								<orgName type="institution">LICOS, EPFL</orgName>
								<address>
									<settlement>Lausanne</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><forename type="middle">J</forename><surname>Goldsmith</surname></persName>
							<email>andrea@wsl.stanford.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shlomo</forename><surname>Shamai</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Dept. of Electrical Engineering</orgName>
								<orgName type="institution">Technion -Israel Institute of Technology</orgName>
								<address>
									<postCode>32000</postCode>
									<settlement>Haifa</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shitz</forename></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Electrical Engineering</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<postCode>94305</postCode>
									<settlement>Stanford</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Minimum Expected Distortion in Gaussian Source Coding with Uncertain Side Information</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We consider a layered approach to source coding with side information received over an uncertain channel that minimizes expected distortion. Specifically, we assume a Gaussian source encoder whereby the decoder receives a compressed version of the symbol at a given rate, as well as an uncompressed version over a separate side-information channel with slow fading and noise. The decoder knows the realization of the slow fading but the encoder knows only its distribution. We consider a layered encoding strategy with a base layer describing the source assuming worst-case fading on the side-information channel, and subsequent layers describing the source under better fading conditions. Optimization of the layering scheme utilizes the Heegard-Berger rate-distortion function that describes the rate required to meet a different distortion constraint for each fading state. When the side-information channel has two discrete fading states, we obtain closed-form expressions for the optimal rate allocation between the fading states and the resulting minimum expected distortion. For multiple fading states, the minimum expected distortion is formulated as the solution of a convex optimization problem. Under discretized Rayleigh fading, we show that the optimal rate allocation puts almost all rate into the base layer associated with the worst-case fading. This implies that uncertain side information yields little performance benefit over no side information. Moreover, as the source coding rate increases, the benefit of uncertain side-information decreases.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>In lossy data compression, side information at the decoder can help reduce the distortion in the reconstruction of the source <ref type="bibr" target="#b0">[1]</ref>. However, in scenarios such as distributed compression in a wireless sensor network, the side information may be acquired over an unreliable wireless channel. In this work we consider a Gaussian source where the encoder is subject to a rate constraint and the distortion metric is mean squared error. In addition to the compressed symbol, we assume that the decoder observes the original symbol through a separate analog fading channel. We assume, similar to the approach in <ref type="bibr" target="#b1">[2]</ref>, that the fading is quasi-static, and that the decoder knows the fading realization but the encode knows only its distribution. The rate-distortion function that dictates the rate required to satisfy the distortion constraint associated with each fading This work was supported by the US Army under MURI award W911NF-05-1-0246, the ONR under award N00014-05-1-0168, DARPA under grant 1105741-1-TFIND, and a grant from Intel. state is given by Heegard and Berger in <ref type="bibr" target="#b2">[3]</ref>. In this work we consider a layered encoding strategy based on the uncertain fading in the side-information channel, and optimize the rate allocation among the possible fading states to minimize expected distortion.</p><p>When the side-information channel exhibits no fading, the distortion is given by the Wyner-Ziv rate-distortion function <ref type="bibr" target="#b3">[4]</ref>. Rate-distortion is considered in <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref> when the side information is also available at the encoder, and in <ref type="bibr" target="#b6">[7]</ref> when there is a combination of decoder-only and encoder-and-decoder side information. Successive refinement source coding in the presence of side information is considered in <ref type="bibr" target="#b7">[8]</ref>. In <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, expected distortion is minimized in the transmission of a Gaussian source over a slowly fading channel in the absence of channel state information at the transmitter (CSIT). Another application of source coding with uncertain side information is in systematic lossy source-channel coding <ref type="bibr" target="#b10">[11]</ref> over a fading channel without CSIT: For example, when upgrading legacy communication systems, a digital channel may be added to augment an existing analog channel. In this case the analog reception then plays the role of side information in the decoding of the description from the digital channel.</p><p>The remainder of the paper is organized as follows. The system model is presented in Section II. Section III derives the minimum expected distortion when the sideinformation channel has discrete fading states. Section IV presents numerical results under discretized Rayleigh fading. Section V considers continuous fading distributions, followed by conclusions in Section VI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. SYSTEM MODEL A. Source Coding with Uncertain Side Information</head><p>Consider the system model shown in <ref type="figure" target="#fig_1">Fig. 1</ref>. An encoder wishes to describe a real Gaussian source sequence {X} under a rate constraint of R X bits per symbol, where the sequence of random variables are independent identically distributed (iid) with X ∼ N(0, σ 2 X ). The decoder, in addition to receiving the encoder's description, observes side information Y 񮽙 , where</p><formula xml:id="formula_0">Y 񮽙 = √ SX + Z, with Z ∼ iid N (0, 1)</formula><p>. Hence the quality of the side information depends on S, the power gain of the side-information channel. We assume S is a quasi-static random variable that  is unchanged after its realization. The decoder knows the realization of S, but the encoder knows only its distribution given by the probability density function (pdf) f S (s). The decoder forms an estimate of the source and reconstructs the sequence { ˆ X}. We are interested in minimizing the expected squared error distortion E <ref type="bibr">[D]</ref> of the reconstruction, where D = (X − ˆ X) 2 . Suppose the side-information channel has M discrete fading states. Let the probability distribution of S be given as follows:</p><formula xml:id="formula_1">R X {X} { ˆ X} E[D] S ∼ f S (s) Y 񮽙 = √ SX + Z Z ∼ N (0, 1) X ∼ N (0, σ 2 X )</formula><formula xml:id="formula_2">Pr{S = s i } = p i , i = 1, . . . , M ; M 񮽙 i=1 p i = 1, (1)</formula><p>where the s i 's are enumerated in ascending order</p><formula xml:id="formula_3">s 1 &lt; s 2 &lt; · · · &lt; s M . Let Y 񮽙</formula><p>i denote the side information under fading state s i :</p><formula xml:id="formula_4">Y 񮽙 i 񮽙 √ s i X + Z, i = 1, . . . , M.<label>(2)</label></formula><p>Note that the set of side information random variables are stochastically degraded. LetˆXLetˆ LetˆX i be the reconstruction when side information Y 񮽙 i is available at the decoder, and D i be the corresponding squared error distortion. The minimum expected distortion under rate constraint R X is then given by</p><formula xml:id="formula_5">E[D] * = min D : R(D)≤RX p T D,<label>(3)</label></formula><p>where</p><formula xml:id="formula_6">p 񮽙 񮽙 p 1 . . . p M 񮽙 T , D 񮽙 񮽙 D 1 . . . D M 񮽙 T , and R(D)</formula><p>is the rate-distortion function that simultaneously satisfies the distortion set D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Heegard-Berger Rate-Distortion Function</head><p>The rate-distortion function that dictates the rate required to simultaneously satisfy a set of distortion constraints associated with a set of degraded side-information random variables is given by Heegard and Berger in <ref type="bibr" target="#b2">[3]</ref> (an alternate form for M = 2 is described in <ref type="bibr" target="#b11">[12]</ref>). When the side information random variables satisfy the degradedness condition</p><formula xml:id="formula_7">X ↔ Y M ↔ Y M −1 ↔ · · · ↔ Y 1 , the rate- distortion function is R HB (D) = min W M 1 ∈P (D) M 񮽙 i=1 I(X; W i |Y i , W i−1 1 ),<label>(4)</label></formula><p>where W i 1 denotes the vector W 1 , . . . , W i . The minimization takes place over P (D), the set of all W M 1 jointly distributed with X, Y M 1 such that:</p><formula xml:id="formula_8">W M 1 ↔ X ↔ Y M ↔ Y M −1 ↔ · · · ↔ Y 1 ,<label>(5)</label></formula><p>and there exists decoding functionsˆXfunctionsˆ functionsˆX i (Y i , W i 1 )'s under given distortion measures d i 's that satisfy</p><formula xml:id="formula_9">E[d i (X, ˆ X i )] ≤ D i , i= 1, . . ., M.<label>(6)</label></formula><p>As noted in <ref type="bibr" target="#b2">[3]</ref>, since R HB (D) depends on X, Y M 1 only through the marginal distribution p(x, y i ), i = 1, . . ., M , the degradedness of the side information need not be physical. We construct Y M 1 to have the same marginals as <ref type="formula" target="#formula_5">(3)</ref> is then given by the Heegard-Berger rate-distortion function (4) with squared error distortion measures</p><formula xml:id="formula_10">Y 񮽙 M 1 by setting p(y i |x) = p(y 񮽙 i |x), i = 1, . . ., M . The rate-distortion function R(D) in</formula><formula xml:id="formula_11">d i (X, ˆ X i ) = (X − ˆ X i ) 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. MINIMUM EXPECTED DISTORTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Gaussian Source under Squared Error Distortion</head><p>First we consider the case when the side-information channel has only two discrete fading states (M = 2). The Heegard-Berger rate-distortion function for this case is</p><formula xml:id="formula_12">R HB (D 1 , D 2 ) = min W1,W2 ∈P (D1 ,D2) {I(X; W 1 |Y 1 ) + I(X; W 2 |Y 2 , W 1 )}.<label>(7)</label></formula><p>For a Gaussian source under a squared error distortion measure, a jointly Gaussian codebook is optimal <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b12">[13]</ref>.</p><p>When W M 1 , X are jointly Gaussian, the mutual information expressions in (7) evaluate to</p><formula xml:id="formula_13">I(X; W 1 |Y 1 ) + I(X; W 2 |Y 2 , W 1 ) = h(X|Y 1 ) − h(X|Y 1 , W 1 ) + h(X|Y 2 , W 1 ) − h(X|Y 2 , W 1 , W 2 ) (8) = 1 2 log(VAR[X|Y 1 ]) − 1 2 log VAR[X|Y 1 , W 1 ] VAR[X|Y 2 , W 1 ] − 1 2 log(VAR[X|Y 2 , W 1 , W 2 ]) (9) = − 1 2 log(s 1 + σ −2 x ) − 1 2 log 񮽙 1 + (s 2 − s 1 )VAR[X|Y 1 , W 1 ] 񮽙 − 1 2 log(VAR[X|Y 2 , W 1 , W 2 ]),<label>(10)</label></formula><p>where log is base 2, and (10) follows from expanding the conditional variance expressions by applying Lemma 1 and Corollary 1 as given below.</p><formula xml:id="formula_14">Lemma 1: Let X, W k 1 be jointly Gaussian random vari- ables. If Y = √ sX +Z, where Z ∼ N (0, 1) is independent from X, W k 1 , then VAR[X|Y, W k 1 ] = 񮽙 VAR[X|W k 1 ] −1 + s 񮽙 −1 .<label>(11)</label></formula><p>Proof: The lemma follows from the minimum mean square error (MMSE) estimate of Gaussian random variables. Let X, W, where</p><formula xml:id="formula_15">W 񮽙 񮽙 W 1 . . . W k 񮽙 T , be dis- tributed as 񮽙 W X 񮽙 ∼ N 񮽙񮽙 μ W μ X 񮽙 , 񮽙 Σ W Σ WX Σ T WX σ 2 X 񮽙񮽙 .<label>(12)</label></formula><p>The conditional distribution is Gaussian <ref type="bibr" target="#b13">[14]</ref>, and the corresponding variance is</p><formula xml:id="formula_16">VAR[X|Y, W] = σ 2 X − 񮽙 Σ WX √ sσ 2 X 񮽙 T 񮽙 Σ W √ sΣ WX √ sΣ T WX sσ 2 X + 1 񮽙 −1 񮽙 Σ WX √ sσ 2 X 񮽙 (13) = σ 2 X − Σ T WX Σ W −1 Σ WX 1 + s(Σ T WX Σ W −1 Σ WX ) (14) = 񮽙 VAR[X|W] −1 + s 񮽙 −1 .<label>(15)</label></formula><formula xml:id="formula_17">񮽙 Corollary 1: Let Y j = √ s j X + Z, Y i = √ s i X + Z. VAR[X|Y i , W k 1 ] VAR[X|Y j , W k 1 ] = 1 + (s j − s i )VAR[X|Y i , W k 1 ].<label>(16)</label></formula><p>񮽙 We substitute (10) in <ref type="formula" target="#formula_12">(7)</ref>, and minimize over W 1 , W 2 to obtain:</p><formula xml:id="formula_18">R HB (D 1 , D 2 ) = − 1 2 log(s 1 + σ −2 x ) + min W1 񮽙 − 1 2 log 񮽙 1 + (s 2 − s 1 )VAR[X|Y 1 , W 1 ] 񮽙 + min W2 񮽙 − 1 2 log(VAR[X|Y 2 , W 1 , W 2 ]) 񮽙 񮽙 .<label>(17)</label></formula><p>In the inner minimization in <ref type="formula" target="#formula_12">(17)</ref>,</p><formula xml:id="formula_19">R HB (D 1 , D 2 ) is decreas- ing in VAR[X|Y 2 , W 1 , W 2 ]; hence the choice of W 2 is optimal when max W2 VAR[X|Y 2 , W 1 , W 2 ] = min(VAR[X|Y 2 , W 1 ], D 2 ),<label>(18)</label></formula><p>where the first term in the min(·) expression follows from the non-negativity of mutual information I(X; W 2 |Y 2 , W 1 ), and the second one follows from the distortion constraint:</p><formula xml:id="formula_20">VAR[X|Y 2 , W 1 , W 2 ] = E 񮽙񮽙 X − ˆ X 2 (Y 2 , W 1 , W 2 ) 񮽙 2 񮽙 ≤ D 2 .<label>(19)</label></formula><p>Similarly, in the outer minimization in (17), W 1 is optimal when</p><formula xml:id="formula_21">max W1 VAR[X|Y 1 , W 1 ] = min(VAR[X|Y 1 ], D 1 ),<label>(20)</label></formula><p>which follows from the non-negativity of I(X; W 1 |Y 1 ), and the distortion constraint:</p><formula xml:id="formula_22">VAR[X|Y 1 , W 1 ] = E 񮽙񮽙 X − ˆ X 1 (Y 1 , W 1 ) 񮽙 2 񮽙 ≤ D 1 . (21)</formula><p>Next, we consider the construction of W 1 , W 2 that achieve the rate-distortion function, namely jointly Gaussian random variables with conditional variances that satisfy (18), <ref type="bibr">(20)</ref>. We construct W 1 , W 2 as given by</p><formula xml:id="formula_23">W 1 = a 1 X + N 1 , W 2 = a 2 X + N 2 ,<label>(22)</label></formula><p>where</p><formula xml:id="formula_24">N i ∼ iid N (0, 1), i = 1, 2, is independent from X, Y 1 , Y 2 .</formula><p>For notational convenience, we define</p><formula xml:id="formula_25">R 1 񮽙 min W1 I(X; W 1 |Y 1 )<label>(23)</label></formula><formula xml:id="formula_26">R 2 񮽙 min W2 I(X; W 2 |Y 2 , W 1 ).<label>(24)</label></formula><p>We interpret R 1 as the rate of a source coding base layer that describes X when the side-information quality is that of Y 1 or better. On the other hand, R 2 is the rate of a top layer that describes X only when the decoder has the better side information Y 2 . The rate of the base layer under optimal W 1 is given by</p><formula xml:id="formula_27">R 1 = min W1 {h(X|Y 1 ) − h(X|Y 1 , W 1 )}<label>(25)</label></formula><formula xml:id="formula_28">= 1 2 log (σ −2 X + s 1 ) −1 ˜ D 1 ,<label>(26)</label></formula><p>where˜D</p><formula xml:id="formula_29">where˜ where˜D 1 񮽙 min 񮽙 D 1 , (σ −2 X + s 1 ) −1 񮽙 .<label>(27)</label></formula><p>The a 1 that achieves <ref type="formula" target="#formula_4">(26)</ref> is determined from the constraint˜D constraint˜ constraint˜D 1 = VAR[X|Y 1 , W 1 ], which evaluates to</p><formula xml:id="formula_30">a 1 = ˜ D −1 1 − σ −2 X − s 1 .<label>(28)</label></formula><p>Similarly, under optimal W 2 , the rate of the top layer is</p><formula xml:id="formula_31">R 2 = min W2 {h(X|Y 2 , W 1 ) − h(X|Y 2 , W 1 , W 2 )}<label>(29)</label></formula><p>= 1 2 log</p><formula xml:id="formula_32">( ˜ D −1 1 + s 2 − s 1 ) −1 ˜ D 2 ,<label>(30)</label></formula><p>where˜D</p><formula xml:id="formula_33">where˜ where˜D 2 񮽙 min 񮽙 D 2 , ( ˜ D −1 1 + s 2 − s 1 ) −1 񮽙 .<label>(31)</label></formula><p>The a 2 that achieves <ref type="formula" target="#formula_5">(30)</ref>  </p><formula xml:id="formula_34">a 2 = ˜ D −1 2 − ˜ D −1 1 − (s 2 − s 1 ).<label>(32)</label></formula><p>Finally, we substitute (26), (30) in (7) to obtain the ratedistortion function:</p><formula xml:id="formula_35">R HB (D 1 , D 2 ) = R 1 + R 2 (33) = − 1 2 log(σ −2 X + s 1 ) − 1 2 log˜Dlog˜ log˜D 2 − 1 2 log 񮽙 1 + (s 2 − s 1 ) ˜ D 1 񮽙 ,<label>(34)</label></formula><p>where˜Dwhere˜ where˜D 1 , ˜ D 2 are as defined in <ref type="formula" target="#formula_4">(27)</ref>, (31). Note that the derivation of (34) depends on the side information only through the marginals p(y i |x)'s; therefore, the ratedistortion function applies as well to the stochastically degraded side information Y 񮽙 M , . . . , Y 񮽙 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Optimal Distortion Trade-off and Rate Allocation</head><p>Under a source coding rate constraint of R X , the achiev-</p><formula xml:id="formula_36">able distortion set is {(D 1 , D 2 ) | R HB (D 1 , D 2 ) ≤ R X }. Setting R HB (D 1 , D 2 ) = R X , the boundary of {(D 1 , D 2 )</formula><p>} defines the Pareto optimal trade-off curve between the two distortion constraints, which is given by</p><formula xml:id="formula_37">D 2 = 񮽙 2 2RX (σ −2 X + s 1 ) 񮽙 1 + (s 2 − s 1 )D 1 񮽙񮽙 −1 ,<label>(35)</label></formula><p>over the interval: We find the optimal operating point on the Pareto curve to minimize the expected distortion:</p><formula xml:id="formula_38">񮽙 2 2RX (σ −2 X + s 1 ) 񮽙 −1 ≤ D 1 ≤ (σ −2 X + s 1 ) −1 .<label>(36)</label></formula><formula xml:id="formula_39">E[D] * = min D1 ,D2 : RHB (D1,D2 )≤RX p 1 D 1 + p 2 D 2<label>(37)</label></formula><p>After substituting (35) in (37), from the Karush-KuhnTucker (KKT) optimality conditions we obtain the optimal base layer distortion D * 1 :</p><formula xml:id="formula_40">D * 1 = min 񮽙 max(D − 1 , D 񮽙 1 ), D + 1 񮽙 ,<label>(38)</label></formula><p>where</p><formula xml:id="formula_41">D − 1 = (2 2RX (σ −2 X + s 1 ) 񮽙 −1<label>(39)</label></formula><formula xml:id="formula_42">D 񮽙 1 = 1 s 2 − s 1 񮽙񮽙 2 2RX σ −2 X + s 1 s 2 − s 1 p 1 p 2 񮽙 −1/2 − 1 񮽙<label>(40)</label></formula><formula xml:id="formula_43">D + 1 = (σ −2 X + s 1 ) −1 ,<label>(41)</label></formula><p>and the optimal top layer distortion D * 2 :</p><formula xml:id="formula_44">D * 2 = min 񮽙 max(D − 2 , D 񮽙 2 ), D + 2 񮽙 ,<label>(42)</label></formula><p>where</p><formula xml:id="formula_45">D − 2 = (2 2RX (σ −2 X + s 2 ) 񮽙 −1<label>(43)</label></formula><formula xml:id="formula_46">D 񮽙 2 = 񮽙 2 2RX (σ −2 X + s 1 )(s 2 − s 1 )p 2 /p 1 񮽙 −1/2<label>(44)</label></formula><formula xml:id="formula_47">D + 2 = 񮽙 2 2RX (σ −2 X + s 1 ) + s 2 − s 1 񮽙 −1 .<label>(45)</label></formula><p>The corresponding optimal rate allocation R * 1 , R * 2 can be found as given in (26), (30).</p><p>The optimal rate allocation is plotted in <ref type="figure" target="#fig_2">Fig. 2</ref> for R X = 1, σ 2 X = 1, and s 1 = 0 dB. Note that R * 2 , the rate allocated to the top layer, is not monotonic with the side-information channel condition. As fading state s 2 improves, R * 2 increases to take advantage of the better sideinformation quality. However, when s 2 is large, R * 2 begins to decline as the expected distortion is dominated by the worse fading state. Moreover, the optimal rate allocation is heavily skewed towards the lower layer: R * 2 &gt; 0 only when p 2 is large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Multiple Discrete Fading States</head><p>The rate-distortion function (34) extends directly to the case when the side-information channel has multiple discrete fading states (M &gt; 2). Specifically, we construct the random variables W i 's to be</p><formula xml:id="formula_48">W i = a i X + N i , i= 1, . . . , M,<label>(46)</label></formula><p>where N i ∼ iid N (0, 1), then the rate of the i th layer is</p><formula xml:id="formula_49">R i 񮽙 min Wi I(X; W i |Y i , W i−1 1 ) (47) = min Wi {h(X|Y i , W i−1 1 ) − h(X|Y i , W i 1 )} (48) = 1 2 log ( ˜ D −1 i−1 + s i − s i−1 ) −1 ˜ D i ,<label>(49)</label></formula><p>where˜D</p><formula xml:id="formula_50">where˜ where˜D i 񮽙 min 񮽙 D i , ( ˜ D −1 i−1 + s i − s i−1 ) −1 񮽙 .<label>(50)</label></formula><p>The a i that achieves <ref type="formula" target="#formula_7">(49)</ref>  </p><formula xml:id="formula_51">a i = ˜ D −1 i − ˜ D −1 i−1 − (s i − s i−1 ).<label>(51)</label></formula><p>As <ref type="formula" target="#formula_7">(49)</ref> in <ref type="formula" target="#formula_7">(4)</ref> to obtain the rate-distortion function:</p><formula xml:id="formula_52">R HB (D) = 񮽙 M i=1 R i , we substitute</formula><formula xml:id="formula_53">R HB (D) = − 1 2 log(σ −2 X + s 1 ) − 1 2 log˜Dlog˜ log˜D M − 1 2 M −1 񮽙 i=1 log 񮽙 1 + (s i+1 − s i ) ˜ D i 񮽙 ,<label>(52)</label></formula><p>where˜Dwhere˜ where˜D i is as defined in (50).</p><p>Unlike the case when M = 2, however, a closed-form expression for the minimum expected distortion E[D] * does not appear analytically tractable. Nevertheless, the expected distortion minimization in (3) can be formulated as the following convex optimization problem over the variables</p><formula xml:id="formula_54">D i , ˜ D i for i = 1, . . ., M : minimize p T D (53) subject to 0 ≤ D i , 0 ≤ ˜ D i , i= 1, . . ., M<label>(54)</label></formula><formula xml:id="formula_55">− 1 2 log(σ −2 X + s 1 ) − 1 2 log˜Dlog˜ log˜D M − 1 2 M −1 񮽙 i=1 log 񮽙 1 + (s i+1 − s i ) ˜ D i 񮽙 ≤ R X<label>(55)</label></formula><formula xml:id="formula_56">˜ D 1 ≤ (σ −2 X + s 1 ) −1 (56) ˜ D i ≤ ( ˜ D −1 i−1 + s i − s i−1 ) −1 , i = 2, . . . , M (57) ˜ D i ≤ D i , i= 1, . . ., M.<label>(58)</label></formula><p>The constraints (56), (57) and (58) derive from expanding the condition in (50). The minimization can be efficiently computed by standard convex optimization techniques <ref type="bibr" target="#b14">[15]</ref>. Moreover, convexity implies that a local optimum is globally optimal. Note that under the KKT optimality conditions,</p><formula xml:id="formula_57">˜ D * i = D * i for i = 1, . . ., M .</formula><p>It implies that the set of distortion inequality constraints (6) are tight when the expected distortion is minimized.  <ref type="figure">Fig. 3</ref>. Minimum expected distortion in source coding with uncertain side information (σ 2 X = 1, ¯ S = 10 dB).</p><formula xml:id="formula_58">Distortion D No-SI E[D] * E[D E-SI ] D SI</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. NUMERICAL RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 3 shows the minimum expected distortion E[D]</head><p>* , when the side-information channel is described by a discretized Rayleigh fading distribution. We assume σ 2 X = 1, and ¯ S 񮽙 E[S] = 10 dB. The Rayleigh distribution is truncated at 2 ¯ S, and discretized into M = 20 fading states with evenly spaced channel power gains s 1 , . . . , s M .</p><p>For comparison, along with E[D] * , in <ref type="figure">Fig. 3</ref> we also show the distortion under different assumptions on the side information. When no side information is available, the distortion is given by the rate-distortion function for a Gaussian source <ref type="bibr" target="#b15">[16]</ref>:</p><formula xml:id="formula_59">D No-SI = σ 2 X 2 −2RX .<label>(59)</label></formula><p>In the absence of side information, D No-SI is an upper bound to E[D] * . Next, if the encoder knows the realization of S, then for each fading state it can achieve the Wyner-Ziv rate-distortion function <ref type="bibr" target="#b3">[4]</ref>, and the corresponding expected distortion is</p><formula xml:id="formula_60">E[D E-SI ] = 񮽙 ∞ 0 f S (s)(σ −2 X + s) −1 ds 2 −2RX .<label>(60)</label></formula><p>With knowledge of S at the encoder,</p><formula xml:id="formula_61">E[D E-SI ] is a lower bound to E[D] * .</formula><p>Finally, when there is no uncertainty in the side-information channel with S = ¯ S, the distortion is given by the Wyner-Ziv rate-distortion function:</p><formula xml:id="formula_62">D SI = (σ −2 X + ¯ S) −1 2 −2RX .<label>(61)</label></formula><p>By Jensen's inequality, E[D E-SI ] &gt; D SI ; hence uncertainty in the side-information channel always hurts performance. We observe in <ref type="figure">Fig. 3</ref> that when R X is small, E[D] * achieves a smaller distortion than when no side information is available. However, when R X is large, E <ref type="bibr">[D]</ref> * is almost as large as D No-SI ; the uncertain side information is negligibly more useful than having no side information at all. Remarkably, for all R X (and a wide range of parameters σ 2 X and ¯ S), the minimum expected distortion is achieved at R * 1 = R X and R * i = 0 for i = 2, . . . , M . Hence the optimal rate allocation concentrates at the base layer of the source code. These numerical results suggest that the optimal rate allocation to minimize the expected distortion is conservative: unless the better fading states are highly probable, no rate is allocated to the source coding layers other than the base layer, since it is not beneficial to dedicate source coding layers to take advantage of these better states. When R X is small, the reduction in VAR <ref type="bibr">[X]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONTINUOUS FADING DISTRIBUTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Continuous Rate Distribution</head><p>In this section, we investigate the optimal rate allocation and minimum expected distortion when the sideinformation channel fading distribution is continuous. We consider the expected-distortion-rate function, i.e.,</p><formula xml:id="formula_63">E[D] as a function of R 񮽙 񮽙 R 1 . . . R M 񮽙 T , since it is continuous</formula><p>and differentiable in the entire nonnegative orthant</p><formula xml:id="formula_64">{R i ≥ 0, i = 1, . . . , M }. The expected distortion is E[D] = p T D = p 1 D 1 + p 2 D 2 + · · · + p M D M , (62)</formula><p>where D i is found by recursively expanding <ref type="formula" target="#formula_7">(49)</ref>:</p><formula xml:id="formula_65">D i = 񮽙 (((σ −2 X + s 1 )2 2R1 + s 2 − s 1 )2 2R2 + · · · )2 2RM 񮽙 −1 .<label>(63)</label></formula><p>Suppose the channel power gains of the fading states start at s 1 = 0, and they are evenly spaced with s i+1 −s i = Δs. In the limit of Δs → 0, M → ∞, the fading probability is given by the continuous pdf f S (s):</p><formula xml:id="formula_66">p i ∼ = f S [i]Δs, where f S [i] 񮽙 f S ((i − 1)Δs),<label>(64)</label></formula><p>and the rate allocation is given by the continuous rate distribution function R(s):</p><formula xml:id="formula_67">R i ∼ = R[i]Δs, where R[i] 񮽙 R((i − 1)Δs).<label>(65)</label></formula><p>The expected distortion over f S (s) is</p><formula xml:id="formula_68">E[D] = lim Δs→0 ∞ 񮽙 i=1 f S [i]D[i]Δs,<label>(66)</label></formula><p>where</p><formula xml:id="formula_69">D[i] = 񮽙 σ −2 X 2 2 񮽙 i j=1 R[j]Δs + i−1 񮽙 j=1 񮽙 2 2 񮽙 i k=j R[k]Δs 񮽙 Δs 񮽙 −1 ,<label>(67)</label></formula><p>which follows from substituting s i+1 − s i = Δs in (63 </p><formula xml:id="formula_70">E[D] = 񮽙 ∞ 0 f S (s)u 񮽙 (s) 񮽙 σ −2 X + u(s) 񮽙 −1 ds,<label>(68)</label></formula><p>where u(s) 񮽙</p><formula xml:id="formula_71">񮽙 s 0 2 −2 񮽙 t 0 R(r) dr dt,</formula><p>with the boundary conditions:</p><formula xml:id="formula_72">u 񮽙 (0) = 1, u 񮽙 (∞) = 2 −2RX .</formula><p>Over any interval where the optimal rate distribution R * (s) is continuous, the corresponding u(s), u 񮽙 (s) are also continuous, and they have to satisfy the necessary condition for optimality as given by the Euler-Lagrange equation <ref type="bibr" target="#b16">[17]</ref>:</p><formula xml:id="formula_73">d ds 񮽙 ∂F ∂u 񮽙 񮽙 − ∂F ∂u = 0,<label>(69)</label></formula><p>where</p><formula xml:id="formula_74">F (s, u, u 񮽙 ) 񮽙 f S (s)u 񮽙 (s) 񮽙 σ −2 X +u(s) 񮽙 −1 .</formula><p>Taking the derivatives, (69) evaluates to:</p><formula xml:id="formula_75">f 񮽙 S (s) σ −2 X + u(s) = 0.<label>(70)</label></formula><p>We suppose in general for the given fading distribution, f 񮽙 S (s) 񮽙 = 0; then no u(s) satisfies <ref type="formula" target="#formula_12">(70)</ref>, and the EulerLagrange condition does not lead to a continuous solution for the optimal rate distribution. We conjecture that the optimal rate allocation is discrete even when the fading distribution is continuous and smooth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Conservative Rate Allocation</head><p>While the Euler-Lagrange equation <ref type="formula" target="#formula_9">(69)</ref> does not prescribe the necessary conditions for discrete rate allocation, the numerical results in Section IV suggest that under Rayleigh fading the optimal rate allocation may concentrate at the lowest layer, i.e., R(s) = R X δ(s). In this section we assume such rate allocation and investigate the expected distortion under Rayleigh fading.</p><p>Let the pdf of the Rayleigh fading distribution be f S (s) = ¯ S −1 e −s/ ¯ S , s ≥ 0.</p><p>When the rate distribution is R(s) = R X δ(s), the expected distortion evaluates to e −t /t dt. Note that when R X is large such that</p><formula xml:id="formula_77">E[D] = 񮽙 ∞ 0 f S (s) σ −2 X 2 2RX + s ds (72) = − ¯ S −1 exp( ¯ S −1 σ −2 X 2 2RX ) Ei(− ¯ S −1 σ −2 X 2 2RX ),<label>(</label></formula><formula xml:id="formula_78">σ −2 X 2 2RX 񮽙 K 񮽙 ¯ S, E[D] ≈ 񮽙 K 0 f S (s) σ −2 X 2 2RX + s ds ≈ 񮽙 K 0 f S (s) σ −2 X 2 2RX ds (74) ≈ σ 2 X 2 −2RX = D No-SI .<label>(75)</label></formula><p>Therefore, as is observed in <ref type="figure">Fig. 3</ref>, under Rayleigh fading with large R X , we expect uncertain side information is no more useful than no side information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>We considered the problem of Gaussian source coding under squared error distortion with uncertain side information at the decoder. When the side-information channel has two discrete fading states, we derived closed-form expressions for the optimal rate allocation among the fading states and the corresponding minimum expected distortion.</p><p>The optimal rate allocation is conservative: rate is allocated to the non-base code layer only if the better fading state is highly probable. Otherwise the distortion reduction from utilizing non-base code rate when the better state is realized is not sufficient to compensate for the distortion increase that results from reducing the code rate of the base layer to allocate rate to the higher layer. For multiple discrete fading states, the minimum expected distortion was shown to be the solution of a convex optimization problem. Under discretized Rayleigh fading, it is observed that the optimal rate allocation concentrates at the base layer associated with the worst-case fading state, and the uncertain side information is negligibly more useful than no side information, especially when the source coding rate is large.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Source coding with uncertain side information.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Optimal rate allocation that minimizes expected distortion. The side-information channel has two discrete fading states (s 1 = 0 dB).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Source Coding Rate RX (bits/symbol)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>73) where Ei(·) is the exponential integral function: Ei(x) 񮽙 − 񮽙 ∞ −x</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>1 , W 2 ], which evaluates to</head><label></label><figDesc></figDesc><table>is determined from˜Dfrom˜ from˜D 2 = 
VAR[X|Y 2 , W </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>is determined from˜Dfrom˜ from˜D i = VAR[X|Y i , W i 1 ], which evaluates to</head><label></label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>outperforms D No-SI . When R X is large, however, as the better fading states are not exploited, the gap between E[D] * and D No-SI vanishes.</head><label></label><figDesc></figDesc><table>from the 
side information at the decoder is significant, thus E[D]  *  
</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The rate-distortion function for source coding with side information at the decoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Wyner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ziv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="1976-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A broadcast approach for a singleuser slowly fading MIMO channel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shamai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">)</forename><surname>Shitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Steiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2617" to="2635" />
			<date type="published" when="2003-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Rate distortion when side information may be absent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Heegard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Berger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="727" to="734" />
			<date type="published" when="1985-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The rate-distortion function for source coding with side information at the decoder-II: General sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Wyner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. Contr</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="60" to="80" />
			<date type="published" when="1978-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A new class of lower bounds to information rates of stationary sources via conditional rate-distortion functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="480" to="489" />
			<date type="published" when="1973-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The rate loss in the wyner-ziv problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2073" to="2084" />
			<date type="published" when="1996-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On rate-distortion with mixed types of side information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Effros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1698" to="1705" />
			<date type="published" when="2006-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On successive refinement for the Wyner-Ziv problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Steinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Merhav</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1636" to="1654" />
			<date type="published" when="2004-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Recursive power allocation in Gaussian layered broadcast coding with successive refinement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T K</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gündgünd¨gündüz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Goldsmith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Erkip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Conf. Commun</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>to appear at IEEE Internat</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Minimum expected distortion in Gaussian layered broadcast coding with successive refinement</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Symp. Inform. Theory</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>to appear at</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Systematic lossy source/channel coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shamai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">)</forename><surname>Shitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Verdúverd´verdú</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="564" to="579" />
			<date type="published" when="1998-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Rate-distortion function when side-information may be present at the decoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Kaspi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2031" to="2034" />
			<date type="published" when="1994-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On scalable source coding with decoder side informations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Diggavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Symp. Inform. Theory</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>to appear at</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leon-Garcia</surname></persName>
		</author>
		<title level="m">Probability and Random Processes for Electrical Engineering</title>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
	<note>2nd ed</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vandenberghe</surname></persName>
		</author>
		<title level="m">Convex Optimization</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Elements of Information Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<publisher>Wiley-Interscience</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Calculus of Variations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">M</forename><surname>Gelfand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V</forename><surname>Fomin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1963" />
			<publisher>PrenticeHall, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
