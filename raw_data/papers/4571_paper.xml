<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:53+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Relevance Feedback Based on Parameter Estimation of Target Distribution</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">C</forename><surname>Sia</surname></persName>
							<email>kcsia@cse.cuhk.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong Shatin</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<region>N.T</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwin</forename><surname>King</surname></persName>
							<email>king@cse.cuhk.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong Shatin</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<region>N.T</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Relevance Feedback Based on Parameter Estimation of Target Distribution</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CBIR</term>
					<term>parameter estimation</term>
					<term>expecta- tion maximization</term>
					<term>relevance feedback</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Relevance Feedback formulations have been proposed to refine query result in Content-Based Image Retrieval (CBIR) in the past few years. Many of them focus on a learning approach to solve the feedback problem. In this paper, we present an Expectation Maximization (EM) approach to estimate the user&apos;s target distribution through user&apos;s feedback. Furthermore, we describe how to use Maximum Entropy display to fully utilize user&apos;s feedback information. We detail the process and also demonstrate the result through experiments.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Introduction</head><p>In Content-Based Image Retrieval Systems, low level features vectors, which may include texture, color and shape, are extracted from the image for storage, manipulation, and retrieval purpose. Many systems use the one-shot approach during retrieval where a query is given in the form of a feature vector and the result is calculated based on the distance between feature vectors of query and images in database, whil the similarity of images is based on this distance measure.</p><p>In order to understand the user's need in a search, a relevance feedback approach is used. Every time, the retrieval system presents the user a set of images, the user then selects those, he thinks, which are relevant and gives feedback to the retrieval system. Based on the feedback, the system can capture the user's need more accurately.</p><p>In this paper, we describe some current approaches in Section 2. In Section 3, we point out some problems that exist in current approaches. We then propose a relevance feedback architecture that use EM to estimate the user's target and maximum entropy display to utilizes the user's distinguishing power in order to narrow down the retrieval process. In Section 4, we verify the correctness of our algorithm and compare our approach with Rui's approach using the precision versus recall measure. We then give some final remarks and conclude.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. Background</head><p>Relevance feedback is used to capture users' searching criteria. In each pass, the retrieval system presents user a set of images, user then gives feedback to the system, indicating which one is relevant. The system makes some update to the parameter and presents user another set of images. This process is illustrated in <ref type="figure" target="#fig_0">Fig. 1</ref>.</p><p>Base on this architecture, Rui et. al.</p><p>[5] formulated a weight updating method to capture user's preference on different features, such as color or texture. Cox et. al. <ref type="bibr" target="#b0">[1]</ref> formulated a Bayesian Learning approach to learn which image is more likely to be user's target based on the feedback. In the following section, we review these two approaches in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Rui's Weight Updating Method</head><p>In <ref type="bibr" target="#b4">[5]</ref>, objects in image database are modelled as</p><formula xml:id="formula_0">O = O(D, F, R),<label>(1)</label></formula><p>where D is the raw image data, F = {f i } is a set of low level visual features, such as color, texture, and shape, and R = {r ij } is the set of representations for f i , which is defined as</p><formula xml:id="formula_1">r ij = [r ij1 , ..., r ijk , ..., r ijK ].<label>(2)</label></formula><p>Moreover, the feature vector is organized in a hierarchical manner. The overall similarity of two images O a and O b is defined as</p><formula xml:id="formula_2">S(O a , O b ) = 񮽙 i W i S(f a i , f b i ),<label>(3)</label></formula><formula xml:id="formula_3">S(f a i , f b i ) = 񮽙 j W ij S(r a ij , r b ij ),<label>(4)</label></formula><formula xml:id="formula_4">S(r a ij , r b ij ) = m(r a ij , r b ij , W ijk ),<label>(5)</label></formula><p>where m is the distance measure function, while W i , W ij and W ijk are the weights associated with each features, its representation and each dimension respectively. For each feedback, they will follow the two procedures described below to update the weight in order to capture user's interest in different features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Interweight Updating Procedure</head><p>Suppose RT is the set of most similar images according to the overall similarity function Eq. 3, for each feature representation ij, the system retrieves a set of similar images, RT ij , according to that particular feature representation. The weight, W ij , is updated according to</p><formula xml:id="formula_5">W ij = 񮽙 W ij + R, RT ij l ∈ RT and l = 1, ..., N, W ij , otherwise</formula><p>where N is the number of most similar images and R is the degree of relevance indicated by the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Intraweight Updating Procedure</head><p>For the set of relevant images indicated by user's feedback, the system computes the standard deviation, σ ijk , in each dimension, and the weight for each dimension is updated as Eq. (6). We can see that if σ ijk is large, then the dimension is not ideal for discriminating relevant and irrelevant images, so its weight is updated as follows,</p><formula xml:id="formula_6">W ijk = 1 σ ijk .<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Cox's Bayesian Formulation Method</head><p>In <ref type="bibr" target="#b0">[1]</ref>, each image is associated with a probability of being the user's target. The retrieval process consists of two steps. In each pass, the system selects a set of images and presents to user. Through the feedback, the system updates the likelihood measure to the query of each image accordingly. The probability is updated using the Bayes' rule as follows,</p><formula xml:id="formula_7">P (T = T i |H t ) = P (A t |T = T i , D t , S t−1 )P (T = T i |H t−1 ) 񮽙 n j=1 P (A t |T j , D t , S t−1 )P (T j |H t−1 ) .<label>(7)</label></formula><p>The meaning of Eq. <ref type="formula" target="#formula_7">(7)</ref> is that the probability of T i being the target image at iteration t is equal to product of the probability of T i being the target at iteration t − 1 and the probability of user give such feedback at iteration t provided that T i is the target, over the summation of probability of other images.</p><p>Moreover, as each image is associated with a probability of being the target, <ref type="bibr" target="#b0">[1]</ref> proposed a maximum entropy display strategy to select image presenting to user. As a result, the system is expected to get most information gain from user's feedback. Besides, <ref type="bibr" target="#b2">[3]</ref> also details the procedure to apply this strategy. This method inspires the display model of our proposal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Expectation Maximization</head><p>Expectation Maximization (EM) algorithm was first proposed in 1977 <ref type="bibr" target="#b1">[2]</ref> . It was used to solve the maximumlikelihood from incomplete data. Given a mixture of Gaussians, the EM algorithm estimates the parameter of each mixture, say, mean and variance. Our approach is based on EM algorithm to estimate the parameter of user's target distribution.</p><p>Nigam et. al. <ref type="bibr" target="#b3">[4]</ref> and Wu et. al. <ref type="bibr" target="#b7">[8]</ref> also used the EM algorithm to classify documents and images respectively. The EM approaches utilize the information contained in unlabeled data (irrelevant data) to help estimating user's target distribution more efficiently and accurately. More recently, Wang et. al. <ref type="bibr" target="#b6">[7]</ref> proposed a Wiener filter approach to learn user's feedback in an optimal fashion. Tian et. al. <ref type="bibr" target="#b5">[6]</ref> proposed the Support Vector Machine (SVM) to classify out the user's target. All these newly suggested methods tends to model the feedback process as a learning process and apply algorithms in computer learning to help.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. Problem Definition and Proposed Solution</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problem Definition</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Estimation</head><p>In <ref type="bibr" target="#b4">[5]</ref>, the weight updating method is a distance based similarity measure. The weight is a measure of how important a particular feature, or dimension is in the query process. It makes use of the weight in calculating the distance measure. While in <ref type="bibr" target="#b0">[1]</ref>, a global update of probability to all images in database is used. It is not parametric based, and the global updating processes seems to be the 0-7803-7278-6/02/$10.00 ©2002 IEEE computational bound when the size of image database grows. In our proposal, we estimate the parameter of user's target distribution. With these parameters, we can capture user's need more accurately, and the process of selecting images to display becomes easier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Display Selection</head><p>Many other approaches always overlook the process of selecting images to display. If we keep displaying the most similar images to user, we have no way to capture user's need in a broader sense. In <ref type="bibr" target="#b0">[1]</ref>, the mostinformative display updating scheme try to achieve this, since each images is associated with a probability value, a maximum entropy display is used to select images. However, when the size of image database is large, the number of permutation is huge, so a sampling approach is used to choose images that maximize the entropy. In our proposal, we have estimated the user's target distribution parameters, thus we can select images located in the boundary to display, as illustrated in <ref type="figure" target="#fig_1">Fig. 2</ref>. This is analogous to the maximum entropy selection. Through this way, we can have the most information gain from user's feedback. Moreover, our estimation strategy is related to our display selection strategy greatly. Since we select images located around the boundary region, our estimation is not simply calculating the variance of relevant images directly. Instead, we use a new approach, which will be discussed in section III-D.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Proposed Solution</head><p>We propose to use a statistical learning method, expectation maximization (EM) to estimate the distribution of user's search target, which will fully utilize the distinguish power by user in classifying relevant and irrelevant images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Model</head><p>Let DB = {I i } n i=1 be a set of database objects, and a set of feature parameters be θ = {θ i } m i=1 . For each image in the database, we perform low level feature extraction to map it to a high dimensional data point by function f , which extracts a real-valued d-dimensional vector as,</p><formula xml:id="formula_8">f : I × θ → R d ,<label>(8)</label></formula><p>where θ i means a specific feature, for example, the color histogram, the co-occurrence matrix based texture feature or the Fourier descriptor. Then an image will be mapped to a high dimensional vector, R d . We assume the user's searching target distribution is a cluster in the high dimensional space. Our goal is to estimate this distribution as accurately as possible, based on the user's feedback. We focus on one feature at this moment first. For each dimension under this feature, we estimate the mean, µ and variance, δ of the user's target distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Relevance Feedback</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Resolving conflicts</head><p>In each pass, we will give user a set of images to choose. The user then indicates whether a specific image is relevant or not. Let R + and R − be the set of relevant images and the set of irrelevant images in each pass respectively. Let Rel( 񮽙 I i ) be the measure of how relevant an image 񮽙 I i and be defined as.</p><formula xml:id="formula_9">Rel t+1 ( 񮽙 I i ) = Rel t ( 񮽙 I i ) + 1 񮽙 I i ∈ R + (9) Rel t+1 ( 񮽙 I i ) = Rel t ( 񮽙 I i ) − 1 񮽙 I i ∈ R −<label>(10)</label></formula><p>We only consider images of Rel( 񮽙 I) &gt; 0 and Rel( 񮽙 I) &lt; 0. The images are divided into two classes, the relevant one and the irrelevant one. we indicate it as I + and I − respectively. Using equation Eq. (9) and Eq. (10), we can resolve the conflict between successive feedbacks given by user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Expectation Maximization Approach</head><p>After the user indicated some relevant and irrelevant images, we estimate the mean and variance of user's target distribution in each dimension by the EM algorithm. In <ref type="figure" target="#fig_1">Fig. 2</ref>, we try to fit the Gaussian distribution having the data points selected by user located in the boundary region; in other words, we are going to maximize the expression: Eq. 11. The reason why we use this expression is that most of the images we give to user to distinguish will fall in the area of medium likelihood (boundary case), so we fit our maximum likelihood function in order to make images appear in the medium likelihood region.</p><formula xml:id="formula_10">E = 񮽙 Ii∈I + 񮽙 j=1 P (I i |θ j ) × ( 1 √ 2πδ j − P (I i |θj))<label>(11)</label></formula><p>0-7803-7278-6/02/$10.00 ©2002 IEEE</p><formula xml:id="formula_11">P (I i |θj) = 1 √ 2πδ j exp − (I ij −µ j ) 2 2δ 2 j (12)</formula><p>where j is the subscript for dimension and θ j is the combination of µ and δ for a particular dimension j. I + is the set of relevant images and I ij is the value of feature vector of image I i in dimension j.</p><p>For finding the mean, the obvious way is to find the average of all relevant data, i.e.,</p><formula xml:id="formula_12">µ j = 񮽙 i∈I + I ij |I + | .<label>(13)</label></formula><p>In order to find the best fitting δ j , we differentiate E with respect to δ j as follows.</p><formula xml:id="formula_13">dE dδ j = 0<label>(14)</label></formula><formula xml:id="formula_14">񮽙 i∈I + ( −1 πδ 3 exp − (I ij −µ j ) 2 2δ 2 j + (I ij − µ j ) 2 2πδ 5 exp − (I ij −µ j ) 2 2δ 2 j + 1 πδ 3 exp − (I ij −µ j ) 2 δ 2 j − (P ij − µ j ) 2 πδ 5 exp − (I ij −µ j ) 2 δ 2 j ) = 0</formula><p>(15) As this maximum likelihood objective function is hard to solve, we use EM algorithm to estimate the δ j . We make use of the parameter from the previous step to derived the new parameter value. We substitute oldj P (I ij |θ oldj ), and come out with an update equation for δ j :</p><formula xml:id="formula_15">δ 2 j = 񮽙 i∈I + ((I ij − µ j ) 2 2 1 4 π − 3 4 − δ 1 2 oldj P 1 2 old (I ij − µ j ) 2 2 1 2 π − 1 2 ) 񮽙 i∈I + (2 1 4 π − 3 4 − δ 1 2 oldj P 1 2 old 2 1 2 π −1 )<label>(16)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Maximum Entropy Display</head><p>Since we have captured the µ and δ of user's target distribution, we proceed to select images that lie in the boundary case to display, and let user determine whether they are relevant or irrelevant. We choose images that are ±kδ away from the µ such that P (µ±kδ) = 1 √ 2πδ</p><p>−P (µ±kδ). After solving this equation, we found that k is equal to 1.1774. In our experiment, we choose points around µ + kδ or µ − kδ in each dimension to display. This is analogous to the maximum entropy display as we choose the ambiguous images for user to classify, thus we fully utilize the power of user in distinguishing different image classes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. Experiments</head><p>Here, we propose a set of experiments to verify the correctness and measure the performance of our proposed algorithm. We would like to make sure of the convergence property is met. Moreover, we compare our proposed method with the Rui's method in terms of accuracy.</p><p>1. We generate a mixture of Gaussians with class labels and store in a text file. 2. Base on our proposed algorithm, the program selects 18 data points in each iteration, and presents their class label to user. 3. The user choose one class as his target, if he find data points come from his target, he gives feedback to system indicating that they are relevant. 4. After several iteration, we see if the estimated distribution parameters converge towards the parameters used to generate the user's target class 5. We use Root-Mean-Square error to measure the difference between actual and estimated µ and δ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experimental Setup</head><p>In the experiments we focus only on synthetic data sets. These data sets are generated by Matlab as mixture of Gaussians. We specify the mean and variance for each class and use Matlab random function to generate. Our experiments were performed on program written by C++ running on Sun Ultra 5/400 with 256Mb ram. The synthetic data sets are mixture of Gaussians, and the parameters are listed in <ref type="table">Table 1</ref>. The µ of each class is uniformly distributed within the range, and the δ of each class is value lies within the range indicated of probability 0.68 (the two values are the ±1 standard deviation of the gaussian function used to generate δ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Convergence Experiment</head><p>To test the convergence property, we make sure that the Root-Mean-Square (RMS) error decreases in each iteration. <ref type="table">Tables 2-4</ref> demonstrate the RMS error of estimated mean and standard deviation along each iteration. The fields indicated as not applicable are those with fewer than 3 relevant samples given. It is because our algorithm starts to estimate the mean and variance when 2 and 3 relevant data points are accumulated respectively.</p><p>0-7803-7278-6/02/$10.00 ©2002 IEEE  The data below for each dimension is an average of 4 test cases for that particular dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Performance Experiment</head><p>We have implemented the intraweight updating version (Eq. 6) of Rui's approach to compare with our EM approach to see how we can improve the retrieval accuracy by estimating user's target. We carry out this experiment using synthetic data, which is a mixture of Gaussians with the parameter same as the 4 dimensional case in the previous experiment.</p><p>According to the intraweight update equation, we update the weight base on variance of retrieved relevant data points. After several iterations (normally 6 to 7), we compute a K-nn(K nearest neighbors) search incorporating the weight measure to analyze the precision versus  recall measure. For our proposed algorithm, as we can estimate the µ and δ of the target distribution, we again perform a K-nn search starting from the mean µ while dropping those data points away from the µ more than two δ. <ref type="figure" target="#fig_5">Fig. 6</ref>,7,8,9 shows the precision versus recall graph for 4 test cases. We have done 9 cases, in 4 of them, EM outperforms Rui's approach, while in other 5 cases, EM ties or performs a little better than Rui's approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. Conclusion</head><p>In this paper, we proposed an approach for CBIR to estimate the user's target through learning from user's feedback via EM algorithm. We have demonstrated the correctness and accuracy of our algorithm. We proposed a display selection strategy that utilizes the information  given by user in dividing image classes in contrast to the K-nn search approach for result display. Moreover, we try to solve the conflicts between successive feedbacks from user. Also, our method is based on the parameter estimation of target distribution, we do not need to perform a global update each image in the database accordingly.</p><p>However, our algorithm also has weaknesses. Since we need to accumulate up to 3 relevant data points before estimating the standard deviation, user might find this too long. Moreover, we use maximum entropy strategy for display, thus, user might feel that the system cannot present the most relevant data in the retrieval process.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Relevance feedback architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Fitting µ and σ for data points selected to display</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. RMS of estimated mean along each feedback iteration</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. No. of feedback given along each feedback iteration</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. precision recall graph : tie case</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>TABLE I Parameters of the synthetic data</head><label>I</label><figDesc></figDesc><table>Dimension 
Class No. 
Class Size 
Range of µ 
Range of δ 
4 
50 
50 
[-1,1] 
[0.2,0.6] 
6 
70 
50 
[-1.5,1.5] 
[0.2,0.6] 
8 
85 
50 
[-1.5,1.5] 
[0.15,0.45] 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>TABLE II Four dimensional test case data</head><label>II</label><figDesc></figDesc><table>Iteration 
Feedback Given 
RMS mean 
RMS std 
1 
1.5 
not applicable 
not applicable 
2 
1.5 
0.292545 
0.20655 
3 
5.5 
0.217373 
0.203525 
4 
6.5 
0.19565 
0.180268 
5 
5.75 
0.202975 
0.16099 
6 
9.25 
0.156245 
0.134668 
7 
7 
0.154993 
0.1253 
8 
5.25 
0.146323 
0.116223 
9 
7 
0.13309 
0.111628 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>TABLE III Six dimensional test case data</head><label>III</label><figDesc></figDesc><table>Iteration 
Feedback Given 
RMS mean 
RMS std 
1 
1.25 
not applicable 
not applicable 
2 
4 
0.269095 
not applicable 
3 
3.75 
0.237395 
not applicable 
4 
4.25 
0.23813 
0.182255 
5 
2.75 
0.286803 
0.172855 
6 
7.25 
0.207565 
0.136693 
7 
9.5 
0.1705 
0.122663 
8 
8.5 
0.151863 
0.122808 
9 
9.5 
0.155308 
0.121773 
10 
8.25 
0.143003 
0.10449 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>TABLE IV Eight dimensional test case data</head><label>IV</label><figDesc></figDesc><table>Iteration 
Feedback Given 
RMS mean 
RMS std 
1 
1.75 
0.203065 
not applicable 
2 
5.25 
0.22882 
0.13232 
3 
9.25 
0.215707 
0.087263 
4 
9.75 
0.176893 
0.059613 
5 
12 
0.215953 
0.059937 
6 
13.5 
0.199765 
0.065423 
7 
15.75 
0.16033 
0.052733 
8 
16 
0.147903 
0.052118 
9 
15.25 
0.111283 
0.057955 
10 
16.25 
0.10208 
0.05726 

</table></figure>

			<note place="foot" n="0">-7803-7278-6/02/$10.00 ©2002 IEEE</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This research is supported in part by an Earmarked Grant from the Hong Kong's University Grants Committee (UGC), CUHK #4407/99E.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The bayesian image retrieval system, pichunter, theory, implementation, and psychophysical experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Minka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">V</forename><surname>Papathomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Yianilos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="20" to="37" />
			<date type="published" when="2000-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Statist. Soc. B</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="185" to="197" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Relevance feedback content-based image retrieval using query distribution estimation based on maximum entropy principle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings to the International Conference on Neural Information Processing (ICONIP2001)</title>
		<editor>L. Zhang and F. Gu</editor>
		<meeting>to the International Conference on Neural Information Processing (ICONIP2001)<address><addrLine>Shanghai, China</addrLine></address></meeting>
		<imprint>
			<publisher>Fudan University Press</publisher>
			<date type="published" when="2001" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="699" to="704" />
		</imprint>
		<respStmt>
			<orgName>Fudan University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Text classification from labeled and unlabeled documents using EM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="103" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Relevance feedback: A power tool for interactive content-based image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehrota</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Circuits and Video Technology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="644" to="655" />
			<date type="published" when="1998-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Update relevant image weights for content-based image retrieval using support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings to the IEEE Conference on Multimedia and Expo</title>
		<meeting>to the IEEE Conference on Multimedia and Expo</meeting>
		<imprint>
			<date type="published" when="2000-06" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1199" to="1202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Optimal adaptive learning for image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-M</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2001" />
			<publisher>December</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Discriminant-em algorithm with application to image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings to the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>to the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2000-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="222" to="227" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
