<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T17:00+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Increase-Decrease Congestion Control for Real-time Streaming: Scalability</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitri</forename><surname>Loguinov</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Department City</orgName>
								<orgName type="department" key="dep2">Dept. of Electrical &amp; Computer Engineering</orgName>
								<orgName type="institution" key="instit1">University of New York New York</orgName>
								<orgName type="institution" key="instit2">Michigan State University</orgName>
								<address>
									<postCode>10016, 48824</postCode>
									<settlement>East Lansing</settlement>
									<region>NY, MI</region>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hayder</forename><surname>Radha</surname></persName>
							<email>radha@egr.msu.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Computer Science Department City</orgName>
								<orgName type="department" key="dep2">Dept. of Electrical &amp; Computer Engineering</orgName>
								<orgName type="institution" key="instit1">University of New York New York</orgName>
								<orgName type="institution" key="instit2">Michigan State University</orgName>
								<address>
									<postCode>10016, 48824</postCode>
									<settlement>East Lansing</settlement>
									<region>NY, MI</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Increase-Decrease Congestion Control for Real-time Streaming: Scalability</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Typically, NACK-based congestion control is dismissed as being not viable due to the common notion that &quot;open-loop&quot; congestion control is simply &quot;difficult.&quot; Emerging real-time streaming applications, however, often rely on rate-based flow control and would benefit greatly from scalable NACK-based congestion control. This paper sheds new light on the performance of NACK-based congestion control and measures the amount of &quot;difficulty&quot; inherently present in such protocols. We specifically focus on increase-decrease (I-D) congestion control methods for real-time, rate-based streaming. First, we introduce and study several new performance measures that can be used to analyze the class of general I-D congestion control methods. These measures include monotonicity of convergence to fairness and packet-loss scalability (explained later in the paper). Second, under the assumptions that the only feedback from the network is packet loss, we show that AIMD is the only TCP-friendly method with monotonic convergence to fairness. Furthermore, we find that AIMD possesses the best packet-loss scalability among all TCP-friendly binomial schemes [2] and show how poorly all of the existing methods scale as the number of flows is increased. Third, we show that if the flows can obtain the knowledge of an additional network parameter (i.e., the bottleneck bandwidth), the scalability of AIMD can be substantially improved. We conclude the paper by studying the performance of a new scheme, called Ideally-Scalable Congestion Control (ISCC), both in simulation and a NACK-based MPEG-4 streaming application over a Cisco testbed.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Congestion is an inherent property of the currently besteffort Internet. Consequently, transport protocols (such as TCP) commonly implement congestion control, which refers to end-to-end algorithms executed by a protocol in order to properly adapt the sending rate of a network flow to the available bandwidth in the path along which the flow sends its packets. Protocols with ACK-based flow control utilize one or another version of TCP-friendly congestion control, which includes Jacobson's modifications to TCP <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b8">[9]</ref>, TCP-like congestion control (e.g., <ref type="bibr" target="#b18">[19]</ref>), increase-decrease algorithms (e.g., <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b20">[21]</ref>), and equationbased methods (e.g., <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b14">[15]</ref>). These algorithms are shown to work well in the environment where the sender relies on "selfclocking," which refers to the use of positive acknowledgements in congestion control.</p><p>However, current real-time streaming applications in the Internet <ref type="bibr" target="#b17">[18]</ref> typically rely on NACK-based (i.e., rate-based) flow control 1 , for which congestion control either does not exist, or assumes a very rudimentary form <ref type="bibr" target="#b17">[18]</ref>. Furthermore, congestion control in NACK-based applications is typically labeled as being "difficult" due to the "open-loop" operation of its flow control, and the actual extent of "difficulty" remains neither documented nor measured.</p><p>At the same time, before emerging real-time streaming applications can gain wide-spread acceptance, we believe that they first must implement some form of scalable congestion control. Therefore, in this paper, we undertake an analysis and performance study that sheds the light on both the exact difficulties found in "open-loop" congestion control and the extent of penalty incurred by a NACK-based protocol in an Internetlike environment. In the course of our investigation, we found that traditional NACK-based congestion control possessed poor scalability (i.e., their use resulted in high packet loss when the number of simultaneous flows was large) and that the stability of existing NACK-based schemes was much lower than that of similar ACK-based schemes. Note that this paper does not study a fundamental question of whether NACKbased congestion control can achieve the same level of stability as its ACK-based counterparts, but rather investigates previously-undocumented drawbacks of NACK-based congestion control and attempts to improve the performance of the existing schemes in rate-based applications.</p><p>Studying new congestion control methods in this paper, we sometimes drift away from TCP-friendly schemes. Hence, we must mention a few words about why find such practice acceptable. We argue that in the future Internet, it is quite possible that UDP traffic will not compete with TCP in the same router queues (e.g., DiffServ may be used to separate these types of traffic at the router level). This intuition is driven by the fact that real-time flows have substantially different delay requirements from those of TCP, and it may not be practical to mix the two types of traffic in the same queues. Furthermore, NACK-based applications are unlikely to be fully TCPfriendly, because they often do not follow TCP's fast retransmit and timeout backoff algorithms and do not rely on the "packet-conservation" principle <ref type="bibr" target="#b8">[9]</ref> in their flow control.</p><p>The remainder of the paper is organized as follows. Section II provides the necessary background on increase-decrease (I-D) congestion control. In section III, we define the notion of monotonic convergence to fairness of general I-D congestion control and derive certain desired properties of control functions that guarantee such monotonic convergence. We next focus on binomial algorithms <ref type="bibr" target="#b1">[2]</ref> in section IV and, under simple assumptions, derive their average link utilization and packet loss rate in the stable state. In section V, we study packet-loss scalability of binomial congestion control and show that AIMD possesses the best scalability among all TCPfriendly schemes. In addition, we show that to achieve optimal scalability (i.e., constant packet loss), a congestion control scheme must have the knowledge of the bottleneck bandwidth.</p><p>In section VI, we investigate the feasibility of using real-time bottleneck bandwidth estimates as a supplement to binomial congestion control and study whether the new schemes can achieve better scalability than AIMD in a real network. We conclude the paper in section VII.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. BACKGROUND</head><p>Within the class of end-to-end congestion control protocols, we specifically focus on the class of increase-decrease (I-D) methods. I-D congestion control implements a simple reactive control system, which responds to congestion by decreasing the sending rate and responds to the absence of congestion by increasing the sending rate. Hence, at any stage, the decision of I-D congestion control is binary.</p><p>Furthermore, the increase and decrease functions are local <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b4">[5]</ref>, which means that they only use the local state of a flow in computing the next value of the sending rate. In addition, I-D congestion control usually assumes a memoryless model <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b4">[5]</ref>, in which the amount of increase and decrease is based only on the value of the current sending rate rather than on the history of the sending rate (e.g., several flavors of "AIMD with history" are examined in <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>). In this paper, we explicitly assume a local and memoryless model of I-D congestion control.</p><p>To prevent high-frequency oscillations on timescales smaller than it is needed to receive the feedback from the network, I-D congestion control is executed on discrete timescales of R time units long. Typically, R is a multiple of the round-trip delay (RTT) and in many cases, simply equals the RTT.</p><p>Many papers study congestion control in the context of window-based flow control <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b20">[21]</ref> and apply I-D formulas to the size of congestion window cwnd. In such notation, assuming that the size of congestion window cwnd during interval i for a particular flow is given by w i , I-D congestion control can be summarized as:</p><p>.</p><p>(</p><formula xml:id="formula_0">1)    &gt; − = + = + 0 ), ( 0 ), ( 1 f w W w f w W w w i D i i I i i</formula><p>where f is the congestion feedback (positive values indicate congestion), and W I and W D are the increase and decrease functions of window-based I-D congestion control, respectively. In practice, feedback f is usually equal to the packet loss rate observed by the flow during the last interval (i.e., interval i).</p><p>Since our work focuses on rate-based streaming applications (in which cwnd has little meaning), we must write an equivalent formulation of increase-decrease congestion control using the value of each flow's sending rate r i instead of congestion window w i . The conversion from the packet-based notation to the rate-based notation is straightforward, i.e., each unit of w i is equivalent to a rate of MTU/RTT bits/s, where the MTU (Maximum Transmission Unit) is given in bits and the RTT is given in seconds. In other words, r i = MTU/RTTw i . Therefore, assuming that r i is the sending rate of a particular flow during discrete interval i, the I-D congestion control (1) for that flow can be re-written as:</p><formula xml:id="formula_1">, (2)    &gt; − = + = + 0 ), ( 0 ), ( 1 f r R r f r R r r i D i i I i i</formula><p>where R I and R D are the increase and decrease functions of rate-based I-D congestion control, respectively.</p><p>One special case of I-D congestion control is given by binomial algorithms, where the increase and decrease functions are simple power functions <ref type="bibr" target="#b1">[2]</ref>:</p><formula xml:id="formula_2">or , (3)      = = − l D k I w w W w w W β α ) ( ) (      = = − l D k I r r R r r R σ λ ) ( ) (</formula><p>where all constants α, β, λ, σ are positive. For binomial algorithms, the difference between the two notations lies only in the constants in front of the corresponding power functions. Hence, the conversion from the window-based to the ratebased notation is supplied by the following formulas:</p><formula xml:id="formula_3">1 +       = k RTT MTU α λ and l RTT MTU −       = 1 β σ .<label>(4)</label></formula><p>Throughout the rest of the paper, we will use both versions of binomial algorithms in (3), sometimes referring to constants (λ,σ) instead of constants (α,β), while keeping in mind the conversion in (4).</p><p>A special case of binomial congestion control that is implemented in TCP is called AIMD (Additive Increase, Multiplicative Decrease) <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b8">[9]</ref>. In AIMD, k equals 0, i.e., W I (w) = α (α &gt; 0), and l equals 1, i.e., W D (w) = βw (0 &lt; β &lt; 1).</p><p>AIMD(α,β) is TCP long-term fair 2 , if it achieves the same average throughput when competing with a TCP connection under the same end-to-end conditions. The necessary condition for such long-term fairness is <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b20">[21]</ref> 3 α = 3β/(2-β). On the other hand, for binomial congestion control (3) to be TCPfriendly, Bansal et al. <ref type="bibr" target="#b1">[2]</ref> show that k + l must be equal to 1. Among such (non-AIMD) TCP-friendly binomial congestion control, they propose two methods called IIAD (Inverse Increase, Additive Decrease) with k = 1, l = 0, and SQRT (Square Root) with k = l = ½.</p><p>Finally, we should mention that the analysis of increasedecrease congestion control typically assumes an ideal network with synchronized and immediate feedback <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>. Synchronized feedback means that all flows sharing a congested link receive notifications about packet loss at the same time. Immediate feedback means that if the capacity of any link along an end-to-end path is exceeded during interval i, feedback f is positive for interval i. Under these ideal conditions, Chiu and Jain <ref type="bibr" target="#b4">[5]</ref> show that all AIMD schemes converge to a fair state. In addition, Bansal et al. <ref type="bibr" target="#b1">[2]</ref> show that for binomial algorithms (3) to converge to fairness, k + l must be strictly greater than zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. GENERAL I-D CONTROL</head><p>Not all increase-decrease functions R I and R D guarantee convergence to fairness. In the context of I-D congestion control, convergence to fairness is usually defined as the ability of any number of identical flows sharing a common bottleneck link to reach a state in which their rates become equal and stay equal infinitely long. Even though in practice this is a very difficult goal to achieve, under the ideal conditions of synchronized and immediate feedback, many schemes can guarantee convergence to fairness. Generally, monotonic convergence is not necessary, but it is beneficial, because non-monotonic convergence tends to temporarily drive the system into extremely unfair states (i.e., one flow receiving much higher bandwidth), especially in the presence of random packet losses and heterogeneous feedback delays. Later in this paper, we will relax the above condition of monotonic convergence, but will keep the rest of the results in this section as they are applicable to both binomial algorithms and the ideally-scalable schemes studied in section V. porarily drive the system into extremely unfair states (i.e., one flow receiving much higher bandwidth), especially in the presence of random packet losses and heterogeneous feedback delays. Later in this paper, we will relax the above condition of monotonic convergence, but will keep the rest of the results in this section as they are applicable to both binomial algorithms and the ideally-scalable schemes studied in section V.</p><p>It is common <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b11">[12]</ref> to examine the case of two flows sharing a link, since the extension to n flows can be easily performed by considering flows pair-wise. It is also common to use a continuous fluid approximation model <ref type="bibr" target="#b1">[2]</ref> and disregard the discrete nature of packets (i.e., all packets are infinitely divisible). Furthermore, in this paper, we use a max-min fairness function f i instead of Chiu's fairness index <ref type="bibr" target="#b4">[5]</ref>. Recall that max-min fairness of n flows with non-zero sending rates (x 1 ,…, x n ) is given by: It is common <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b11">[12]</ref> to examine the case of two flows sharing a link, since the extension to n flows can be easily performed by considering flows pair-wise. It is also common to use a continuous fluid approximation model <ref type="bibr" target="#b1">[2]</ref> and disregard the discrete nature of packets (i.e., all packets are infinitely divisible). Furthermore, in this paper, we use a max-min fairness function f i instead of Chiu's fairness index <ref type="bibr" target="#b4">[5]</ref>. Recall that max-min fairness of n flows with non-zero sending rates (x 1 ,…, x n ) is given by:</p><formula xml:id="formula_4">( ) j i j i x x f / min ≠ = .<label>(6)</label></formula><p>Consider two flows X and Y sharing a bottleneck link under the above assumptions. Suppose that during interval i, the flows' sending rates are given by x i and y i , respectively. To help us understand the behavior of a two-flow I-D control system, we use <ref type="figure" target="#fig_0">Figure 1</ref> from <ref type="bibr" target="#b4">[5]</ref>. In the figure, the axes represent the sending rate of each of the two flows. Furthermore, line y = x is known as the fairness line and represents points <ref type="bibr">(x, y)</ref> in which fairness f equals 1. Assuming that the capacity of the bottleneck link is C, line x + y = C is called the efficiency line and represents points in which the bottleneck link is about to overflow. Given a particular point P i = (x i , y i ) in the figure, line y = mx connecting P i to the origin is called the equi-fairness line (i.e., points along the line have the same fairness f i = x i /y i = 1/m). Furthermore, we define efficiency e i of point P i as the combined rate of both flows in that point, i.e., e i = x i + y i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Decrease Function</head><p>To ensure monotonic convergence and proper response to congestion signals, the following four conditions must hold during each decrease step assuming that the system is in some point P i just before the decrease step.</p><p>First, the efficiency in the new state must be strictly less than that in the old state, i.e., e i+1 &lt; e i . This condition ensures that flows backoff during congestion. Second, the fairness must not decrease in the new state, i.e., f i+1 ≥ f i . This condition guarantees monotonic convergence to fairness, and as pointed out before, although desired, it is often not available in practice. Consequently, we will relax this condition later in the paper. Third, to properly maintain convergence, the system must not arbitrarily cross or oscillate around the fairness line, i.e., it must stay on the same side of the fairness line at all times. For the case in <ref type="figure" target="#fig_0">Figure 1</ref>, we can write:</p><formula xml:id="formula_5">(y i &gt; x i ) ⇒ (y i+1 &gt; x i+1</formula><p>). Finally, the system must not allow rates below or equal to zero, i.e., given an arbitrary state with x i &gt; 0 and y i &gt; 0, we must guarantee that y i+1 &gt; 0 and x i+1 &gt; 0.</p><p>The first condition is equivalent to:</p><formula xml:id="formula_6">0 ) ( ) ( 1 1 &lt; − − = − + − + + i D i D i i i i y R x R y y x x ,<label>(7)</label></formula><p>which can be satisfied with any positive function R D (x) &gt; 0, ∀x &gt; 0. The second condition is equivalent to:</p><formula xml:id="formula_7">i i i i y x y x ≥ + + 1 1 , x i &gt; 0, y i &gt; 0.<label>(8)</label></formula><p>Expanding the last inequality using (2) and generalizing by dropping the indexes (the inequality depends only on x i and y i ), we get:</p><formula xml:id="formula_8">, for all x &gt; 0, y &gt; 0, x &lt; y. (9) 0 ) ( ) ( ≥ − x yR y xR D D Writing y = x + ∆x, for ∆x &gt; 0: ( ) 0 ) ( ) ( ) ( ≥ ∆ − − ∆ + x xR x R x x R x D D D , (10) x x R x x R x x R D D D ) ( ) ( ) ( ≥ ∆ − ∆ + , for x &gt; 0, ∆x &gt; 0. (11)</formula><p>Restricting R D (x) to be a differentiable function for all x &gt; 0, (11) is equivalent to:</p><formula xml:id="formula_9">x x R x R D D ) ( ) ( ≥ ′ , for all x &gt; 0.<label>(12)</label></formula><p>Bringing R D (x) to the left and taking the integral (both x and R D (x) are known to be positive):</p><formula xml:id="formula_10">∫ ∫ ≥ x dx x R x dR D D ) ( ) (</formula><p>, for all x &gt; 0.</p><p>, for all x &gt; 0.</p><formula xml:id="formula_12">(14) 1 ln ) ( ln m x x R D + ≥ , for all x &gt; 0. (15) x m x R D 2 ) ( ≥</formula><p>The result in <ref type="bibr" target="#b14">(15)</ref> shows that the original condition (12) restricts R D (x) to grow no slower than some linear function m 2 x.</p><p>Using similar derivations, we find that the third condition (i.e., the non-cross-over condition) results in:</p><formula xml:id="formula_13">1 ) ( &lt; ′ x R D , for all x &gt; 0,<label>(16)</label></formula><p>which means that R D (x) must grow slower than function x (i.e., the slope of R D (x) in all points x &gt; 0 must be less than 1). Finally, the fourth condition</p><formula xml:id="formula_14">, for all x &gt; 0 (17) 0 ) ( &gt; − x R x D</formula><p>is automatically satisfied by combining (12) and (16) above. To summarize by combining <ref type="formula">(15)</ref> and <ref type="formula" target="#formula_4">(16)</ref>, function R D (x) must be positive and differentiable for all values of x &gt; 0, and must be an asymptotically (i.e., for substantially large x) linear function of x, with the slope strictly less than 1. For example, AIMD function R D (x) = σx clearly satisfies these conditions for 0 &lt; σ &lt; 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Increase Function</head><p>The analysis of increase function R I (x) is similar to the above. This time, instead of four conditions, we have only three. First, the efficiency in the new state must increase (i.e., e i+1 &gt; e i ), which guarantees that flows will probe for new bandwidth in the absence of congestion. Second, the fairness must not decrease (i.e., f i+1 ≥ f i ), which is the result of the same monotonicity requirement as before. And third, the system must not cross the fairness line (i.e., y i+1 &gt; x i+1 ). Crossing the fairness line violates monotonic converge to fairness and, as we will see later, never happens in practice (i.e., among binomial schemes).</p><p>The first condition is satisfied with any positive function R I (x), i.e., R I (x) &gt; 0, ∀x &gt; 0. The second condition is the opposite of (12) due to a different sign in <ref type="formula">(2)</ref>:</p><formula xml:id="formula_15">x x R x R I I ) ( ) ( ≤ ′ , for all x &gt; 0.<label>(18)</label></formula><p>Finally, the third condition is similar to (16), but assumes the following shape:</p><formula xml:id="formula_16">, for all x &gt; 0. (19) 1 ) ( − &gt; ′ x R I</formula><p>Using (18), we find that R I must grow no faster than some linear function m 3 x and using <ref type="bibr" target="#b18">(19)</ref>, R I cannot decay quicker than -x. For example, AIMD increase function R I (x) = λ again satisfies all conditions of monotonic convergence for λ &gt; 0.</p><p>We will look at other examples in the next section while studying binomial congestion control methods <ref type="bibr" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Convergence</head><p>Note that the above conditions still do not guarantee convergence to fairness. In other words, the conditions guarantee that if the system converges, it will do so monotonically, but the fact of convergence has not been established yet. Hence, we impose a final restriction on R D and R I -either the decrease or the increase step must strictly improve fairness, i.e., one of (12), (18) must be a strict inequality. If (12) is made into a strict inequality, we can no longer satisfy the condition in (16). Consequently, (12) must remain in its present form, and (18) must become a strict inequality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. PROPERTIES OF BINOMIAL ALGORITHMS A. Overview</head><p>Consider binomial algorithms in (3). Clearly, both functions R I and R D are positive for x &gt; 0 and therefore, satisfy the first condition. The second condition (i.e., monotonically nondecreasing fairness) results in the following restrictions on k and l from applying (12) and the strict form of <ref type="formula" target="#formula_7">(18)</ref>:</p><formula xml:id="formula_17">. (20)    ≥ − &gt; ⇒      ≥ &lt; − − − + − 1 1 / / 1 ) 1 ( l k x x lx x x kx l l k k σ σ λ λ</formula><p>The third (i.e., non-cross-over) condition derived from (16) and (19) restricts l even further, but does not impose any limit on k (assuming sufficiently large x):</p><formula xml:id="formula_18">. (21)    ≤ = ⇒      &lt; &lt; − + 1 1 1 l anything k x l x k l k σ λ</formula><p>Note that restriction on l in <ref type="formula">(21)</ref> is dictated by the fact that sending rate x of a flow is not limited a-priori and the selection of a positive constant σ such that it is less than x 1-l /l, for substantially large x &gt; 0, is feasible only when power 1-l is strictly non-negative. <ref type="bibr" target="#b3">4</ref> Later in this paper, we will show how restriction l ≤ 1 can be lifted and what kind of advantages such schemes bring to congestion control protocols.</p><p>Consequently, assuming that the upper limit on x is not known, for a binomial algorithm to possess monotonic convergence to fairness, both <ref type="formula">(20)</ref> and <ref type="formula">(21)</ref> must be satisfied. In practice, this means that l must be strictly 1. Knowing that for TCP-friendly binomial congestion control k + l must be one <ref type="bibr" target="#b1">[2]</ref>, we arrive at the fact that AIMD is the only TCP-friendly binomial algorithm with monotonic convergence to fairness. Hence, for the rest of the paper, we will study schemes with non-monotonic convergence to fairness, because we want to go beyond what AIMD has to offer.</p><p>In the absence of monotonic convergence, <ref type="bibr" target="#b1">[2]</ref> shows that the necessary condition for convergence is k + l &gt; 0 (i.e., flows make due progress towards the fairness line not necessarily at every step, but between every two consecutive decrease steps). Hence, dropping the monotonicity requirement and combining (21) with the convergence rule k + l &gt; 0, we notice that the necessary restrictions on k and l for convergence of nonmonotonic binomial algorithms are: k &gt; -1 and l ≤ 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Efficiency</head><p>The average efficiency is an important property of a congestion control scheme, which reflects how well the scheme utilizes the bottleneck bandwidth in the stable state. Clearly, higher efficiency is more desirable (but not necessarily at the expense of other properties of the scheme, such as packet loss or convergence speed). Formulas derived in this section not only help us study the efficiency of binomial schemes, but also are a necessary background for our packet-loss scalability analysis in the next section.</p><p>We define the average efficiency of a scheme as the percentage of the bottleneck link utilized by the scheme over a long period of time once the scheme has reached its stable state. In the stable state, each flow's sending rate will oscillate between two points, which we call the upper point (U) and the lower point (L) as shown in <ref type="figure">Figure 2</ref>. When a single flow is present in the network, U equals the capacity of the bottleneck link C. When n flows compete over a shared link of capacity C, U equals C/n for each flow (because the flows have reached fairness by this time). In both cases, L = U -σU l according to <ref type="bibr" target="#b2">(3)</ref>.</p><p>In addition, since the pattern in <ref type="figure">Figure 2</ref> is repetitive, it is sufficient to determine the average throughput of a flow during a single oscillation (i.e., between points A and B) rather than over a longer period of time. Note that in the window-based notation of congestion control, the maximum capacity of the link is given by W = C⋅RTT/MTU.</p><p>Using a continuous fluid approximation and results from <ref type="bibr" target="#b1">[2]</ref>, each flow's rate x(t) during the increase phase (i.e., between points A and B) is given by:</p><formula xml:id="formula_19">1 1 ) 1 ( ) ( +       + = k R t k t x λ ,<label>(22)</label></formula><p>where R is a fixed duration of the control interval (which is typically equal to the value of the RTT). Following <ref type="bibr" target="#b1">[2]</ref>, the duration between points A and B in <ref type="figure">Figure 2</ref> is: ( )</p><formula xml:id="formula_20">) 1 ( 1 1 1 1 1 +       − − = ∆ + − + k R U U t k l k λ σ ,<label>(23)</label></formula><p>and the total amount of bits transmitted during the same interval is:</p><p>( )</p><formula xml:id="formula_21">) 2 ( 1 1 2 1 2 +       − − = + − + k R U U X k l k λ σ .<label>(24)</label></formula><p>Consequently, we derive that the flow's average sending rate during the interval is X/∆t and the average efficiency (i.e., percent utilization) of a binomial congestion control scheme is:</p><formula xml:id="formula_22">( ) ( )       − − +       − − + = ∆ = + − + − 1 1 2 1 1 1 ) 2 ( 1 1 ) 1 ( k l k l U k U k t U X e σ σ .<label>(25)</label></formula><p>Note that (25) can be converted to the window-based notation by replacing σ with β and rate U with its window equivalent. We also note that for large n, the exact model of efficiency e in (25) becomes inapplicable when U = C/n drops below σ 1/(1-l) . We can no longer use any of the above derivations due to the fact that 1-σ(C/n) l-1 becomes negative, which is caused by the "drop-below-zero" effect (i.e., rate x(t) becomes negative) that we tried to avoid before in (17). This condition was automatically satisfied given monotonic convergence to fairness in (12), but in the absence of monotonicity, we must explicitly restrict n to the following:</p><formula xml:id="formula_23">U L time t flow's sending rate x(t) A B ∆ t ) 1 /( 1 ) 1 /( 1 l l W C n − − = &lt; β σ .<label>(26)</label></formula><p>We next focus on simplifying the expression in <ref type="bibr">(25)</ref>. Equation (25) contains two terms of the form 1-(1-z) q , which can be expanded using Taylor series to: <ref type="figure">Figure 2</ref>. Oscillation of the sending rate in the stable state.</p><formula xml:id="formula_24">      − − + − − = − ... 6 ) 2 )( 1 ( 2 1 1 ) 1 ( 2 z q q z q qz z q − 1 .<label>(27)</label></formula><p>Note that for l &lt; 1, the value of z is less than 1, which means that the higher order terms in <ref type="bibr">(27)</ref> get progressively smaller. Hence, by keeping the first two terms 5 in <ref type="bibr">(27)</ref>, we arrive at the following approximation to the exact formula in (25):</p><formula xml:id="formula_25">1 1 2 1 − − − − = l l U k U e σ σ .<label>(28)</label></formula><p>To perform a self-check, we plug AIMD parameters (l = 1, k = 0) into (28) and get the familiar (and exact) formula of the average efficiency of an AIMD scheme: e = (2-β)/2 (recall that σ = β in AIMD).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Packet Loss</head><p>The amount of packet loss during the stable state is another important property of a congestion control scheme. Consider one oscillation cycle between points A and B in <ref type="figure">Figure 2</ref> and the case of a single flow. The maximum amount of overshoot under non-ideal (i.e., non-continuous) conditions will be the value of the increase function just before the flow reaches its upper boundary C in point B. Hence, the amount of the maximum overshoot for a single flow is given by λC -k R, where R is the fixed duration between control actions. Knowing how many bits X were sent by the flow during the same interval of duration ∆t, we can write the average percentage of lost data p 1 using (24) and assuming the worst case of the maximum overshoot as:</p><formula xml:id="formula_26">( ) ( ) , 1 1 ) 2 ( ) 2 ( 1 1 ) 2 ( 2 1 2 2 2 2 2 1 2 2 2 1       − − + ≈ + +       − − + = + = + − + + − + − − k l k k l k k k C C k k C C k R C X R C p σ λ λ σ λ λ λ<label>(29)</label></formula><p>when λC -k R &lt;&lt; X. In particular, for AIMD schemes, the packet loss rate in the worst case is given by: . <ref type="formula">(30)</ref> A close look at the last equation reveals that as the number of flows increases (i.e., C is replaced by C/n), AIMD's packet loss rate will also increase. Furthermore, the amount of in-</p><formula xml:id="formula_27">( )<label>( ) ( ) β</label></formula><note type="other">( ) ). ( ) / ( ) 1 ( 2 ) 1 ( 2 1 2 1 1 1 2 + + − − + + = + − + − ≈ k l l l k l n n O n C k C k n s σ σ (32) crease is proportional to n</note><p>2 , where n is the number of flows. This confirms a well-known fact that AIMD scales as n 2 when it comes to packet loss <ref type="bibr" target="#b13">[14]</ref>. Note that as n→∞, the amount of overshoot λC -k R will become large compared to the value of X, and the approximations above will no longer work. However, the exact formulas in <ref type="bibr">(29)</ref> and <ref type="formula">(30)</ref> will asymptotically approach the correct value of 100%. Hence, packet loss increase factor s n of binomial algorithms is proportional to n l+2k+1 for small n and grows no faster than n l+2k+1 for the rest of n. For AIMD, we get the familiar scalability formula of n 2 , whereas the IIAD (i.e., k = 1, l = 0) and SQRT (i.e., k = l = ½) algorithms scale as n 3 and n 2.5 , respectively. Furthermore, among all TCP-friendly schemes (i.e., k + l = 1), packet loss increase s n is proportional to n 3-l , which means that TCP-friendly schemes with the largest l scale best. Since we already established that l must be no more than 1 (the non-cross-over condition), we arrive at our first major conclusion -among TCP-friendly binomial schemes, AIMD scales best.</p><p>Consider a simple explanation of why AIMD scales quadratically. In AIMD, the increase in packet loss by a factor of n 2 comes from two places -from the reduction in the number of discrete increase steps N during interval ∆t by a factor of n (because the increase distance U-L becomes n times smaller), and from the reduction of duration ∆t by the same factor of n (due to the same reason). As a result, the number of bits sent during the interval (which is proportional to N∆t) is reduced by a factor of n 2 , and the amount of overshoot is unchanged (i.e., λR). Consequently, the total amount of lost packets relative to the number of sent packets is increased by a factor of n 2 .</p><p>We should make several observations about the applicability of (32) in practice. First, we assumed in <ref type="bibr">(29)</ref> that the overshoot will be as large as possible, i.e., λU -k R. However, in many cases the actual overshoot will be some random value distributed between zero and λU -k R. Second, recall our discussion of AIMD's scalability in the previous section. When the increase distance U-L becomes small compared to the value of the increase step, AIMD starts scaling as a linear function rather than a quadratic function. Hence, (32) is accurate only when the increase steps are small compared to C/n. The results based on the above model can be further skewed, if λU -k R becomes large compared to X, in which case we must use the exact formula in <ref type="bibr">(29)</ref>.</p><p>There are two reasons why we do not see this kind of performance degradation in practice. First, our results in <ref type="formula">(30)</ref> are based on a continuous fluid model, which assumes that packets are infinitely divisible. However, in practice, this approximation is true only when the amount of increase λR is negligible compared to the difference between the upper and lower limits, i.e., U-L in <ref type="figure">Figure 2</ref>. Hence, when the number of discrete increase steps N becomes equal to 1 (or approaches 1), it can no longer be reduced by a factor of n, because it must remain an integer. Taking into account a fixed value of N = 1, the increase in packet loss becomes a linear rather than a quadratic function o B. Simulation f n. Second, most protocols employing AIMD rely on positive ACKs in implementing congestion control. This "selfclocking" <ref type="bibr" target="#b8">[9]</ref>, or "packet conservation," is capable of significantly improving the scalability aspects of AIMD, because the sender does not inject more packets into the network than the network can handle at any given time. "Open-loop" congestion control (i.e., NACK-based flow control) does not have this nice cushion to fall back on, and NACK-based AIMD schemes suffer a higher packet loss increase than equivalent ACK-based schemes. In the next section, we will look at the scalability of general binomial algorithms and study how we can reduce the amount of packet loss as the number of flows increases.</p><p>To verify these theoretical results and show some examples, we present simulation results of AIMD(1,½) and IIAD(1,½) schemes over a T1 link (i.e., C = 1,544 kb/s). For AIMD, we set MTU/RTT at two constant values of 5,000 and 50,000 bps (the corresponding schemes will be called AIMD 1 and AIMD 2 ) to show how their scalability changes when λ becomes large compared to the upper boundary U = C/n. For IIAD we selected MTU/RTT = 10,000 bps to allow the scheme to maintain p n &lt;&lt; 100% (otherwise, IIAD loses its n 3 packet loss increase). We used a discrete event simulation, in which n flows of the same type shared a common link. We used our prior assumption of immediate and synchronized feedback, as well as the assumption that the flows employed a NACK-based protocol (i.e., "open-loop" congestion control).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. PACKET-LOSS SCALABILITY OF CONGESTION CONTROL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overview</head><p>Suppose the average packet loss when n flows share a link of capacity C is given by p n . Let packet loss increase factor s n be the ratio of p n to p 1 . Parameter s n specifies how fast packet loss increases when more flows share a common link and directly relates to the ability of the scheme to support a large number of flows (i.e., schemes with lower s n scale better). Using (29), we derive: <ref type="figure" target="#fig_3">Figure 3</ref> shows the variation of parameter s n (based on the actual, rather than the maximum overshoot) during the simulation as a function of n for the three flows. In AIMD 1 , packet loss increase ratio s 100 reaches a factor of 6,755, which is equivalent to scalability of n 1.91 (just below the predicted n 2 ). On the other hand, AIMD 2 maintains its quadratic packet-loss increase only until n = 7, at which time it switches to a linear increase. The AIMD 2 scheme reaches an increase factor of s 100 = 352, which is equivalent to an overall scalability of n 1.27 . It may seem at first that the larger increase step λ of the AIMD 2 scheme is better; however, due to a larger λ, AIMD 2 is much more aggressive in searching for bandwidth and suffers a lot more packet loss than AIMD 1 for all values of n. Thus, for exand using a two-term approximation from <ref type="bibr">(27)</ref>: ample, for n = 100, AIMD 2 loses 55% of all sent packets, while AIMD 1 loses only 10%.</p><formula xml:id="formula_28">( ) ( )       − − + ≈ + − + + 2 1 2 2 2 2 2 / 1 1 ) 2 ( k l k k n n C C n k p σ λ ,<label>(31)</label></formula><p>Finally, IIAD's scalability performance is much worse than that of either of AIMD schemes as can be seen in the figure.</p><p>The packet loss with 100 flows (i.e., p 100 ) is 219,889 times larger than the packet loss with one flow (i.e., p 1 ). Hence, under the given conditions, the overall scalability of IIAD is approximately n 2.67 (again slightly less than the predicted n 3 ).</p><p>As pointed out before and as shown in <ref type="figure" target="#fig_3">Figure 3</ref>, the actual increase in packet loss under non-ideal (i.e., discrete) conditions may be lower than that predicted by <ref type="bibr">(32)</ref>. Nevertheless, the theoretical result in (32) can be used as a good performance measure in comparing the scalability of different binomial schemes (e.g., as predicted, AIMD scales much better than IIAD).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Feasibility of Ideal Scalability</head><p>We next examine the "ideal scalability" of binomial schemes and derive its necessary conditions. We define a scheme to have ideal scalability, if s n is constant for all n. This definition is driven by the fact that no matter how small packet loss p 1 can be made in a non-scalable scheme (i.e., a scheme with quickly-growing s n ), there will be a link of sufficient capacity that will accommodate such large number of concurrent flows n that p n will be unacceptably high. This is especially true given the no-better-than-quadratic scalability of binomial congestion control. Consequently, the ideal situation would be to have a scheme that maintains a consistent packet loss rate regardless of the number of flows utilizing the scheme over a shared link, i.e., p n = p 1 for all n. Furthermore, we would like to have a scheme that maintains the same packet loss over links of different capacity C.</p><p>To solve the above problem, we examine (32) again in order to find congestion control schemes that allow s n to remain constant. Clearly, the necessary conditions for this ideal scalability are (the second condition is needed for convergence):</p><formula xml:id="formula_29">. (33)    &gt; − &lt; ⇒    &gt; + = + + 1 1 0 0 1 2 l k l k k l</formula><p>The l &gt; 1 condition means that if we plan to satisfy the noncross-over conditions (16), (21), or prevent the scheme from reducing its rate below zero, ideal scalability requires the knowledge of some tight upper limit on sending rate x (see discussion following (21) earlier). Consequently, only assuming that x is limited by a constant (i.e., C), is it possible to find such σ that will satisfy the necessary condition σ &lt; 1/(lx l-1 ) in (21) for all rates 0 &lt; x ≤ C. Hence, we come to our second major conclusion -among I-D congestion control schemes, ideal scalability is possible only when sending rates x are limited from above by a constant, i.e., when flows have the knowledge of the bottleneck capacity. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AIMD1 AIMD2 IIAD</head><p>There are two simple ways how an application can learn the value of C -by using real-time end-to-end measurements or by asking the network to provide an explicit feedback with the value of C. In the next section, we will examine the viability of applying the former method to sampling the capacity of the bottleneck link and the possibility of using such estimates in ideally-scalable congestion control. Note that all flows sharing a single link must receive an estimate of C that is fairly close to the true capacity of the link <ref type="bibr" target="#b5">6</ref> . A major drawback of employing congestion control that relies on real-time estimates of C is that different flows may form a different estimate, which may result in poor convergence and/or scalability depending on the amount of error. Hence, our approach in this section relaxes one condition (i.e., l ≤ 1), but imposes a new one -all flows must measure the bottleneck capacity with high consistency. Note that a thorough evaluation of various bandwidth estimation methods for the purpose of ideally-scalable congestion control is beyond the scope of this paper.</p><p>We also speculate that schemes with ideal scalability may be somewhat difficult to use in practice due to two factors -errors in measuring capacity C <ref type="bibr" target="#b5">[6]</ref> and typically slower convergence to fairness due to less-aggressive probing for bandwidth. Nevertheless, we investigated ideally-scalable congestion control until we established a working version of the algorithm, which we will present in the remainder of the paper. Note that much more work in this area is required before we can recommend an I-D congestion control method other than AIMD for practical use over the Internet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Ideally-Scalable Congestion Control</head><p>In this section, we introduce a new method, called IdeallyScalable Congestion Control (ISCC), and show how values of the bottleneck capacity can be used to select the values of (λ,σ). Note that other ways of selecting (λ,σ) may be possible to achieve the same goal of constant s n . We use notation ISCC(x) to refer to the ideally-scalable scheme described in this section with parameter l equal to x and parameter k equal to -(l+1)/2.</p><p>Assuming that C is known and assuming that x(t) ≤ C at all times t (i.e., each application will limit its sending rate to be no higher than C), we can satisfy σ &lt; 1/(lx l-1 ) in (21) by choosing the following σ :</p><formula xml:id="formula_30">1 1 − = l D C m σ ,<label>(34)</label></formula><p>where l &gt; 1 and m D is some constant greater than or equal to l. It is easy to show that the decrease step of schemes with σ according to <ref type="bibr">(34)</ref> is no more than x/m D for any given state</p><note type="other">x &gt; 0. Hence, rate x is guaranteed to stay positive at all times. By varying constant m D , the scheme can adjust its average efficiency, where larger values of m D mean higher efficiency. Cisco 3620 Cisco 3620 Cisco 3660 Cat alyst 2912 Client Server Cat alyst 2912 T1 T1 10 mb/ s 10 mb/ s 100 mb/ s 100 mb/ s</note><p>In addition, we must carefully select the value of λ so that the negative value of power k is not allowed to cause uncontrollably-high increase steps. One way to attempt to achieve this is to select a fixed value α and then multiply it by (MTU/RTT) k+1 as shown in (4). However, the increase steps will still remain virtually unlimited, because the value of MTU/RTT has little relationship to the value of C (which is needed to effectively limit λx -k ). In addition, different flows may use different multiplicative factors in (4) due to the differences in the RTT or the MTU. An alternative approach is to apply a similar thinking to that used before in selecting σ -choose λ so that the increase step is always no more than x/m I for any given rate x, where m I is some constant greater than or equal to one. This can be written as: choose λ so that the increase step is always no more than x/m I for any given rate x, where m I is some constant greater than or equal to one. This can be written as: </p><formula xml:id="formula_31">1 , / ≥ ≤ − I I k m m x x λ 1 , / ≥ ≤ − I I k m m x x<label>(35)</label></formula><p>λ which is satisfied with the following choice of λ: which is satisfied with the following choice of λ:</p><formula xml:id="formula_32">1 , 1 ≥ = + I I k m m C λ .<label>(36)</label></formula><p>Parameter m I can be used to vary the aggressiveness of the scheme in searching for new bandwidth, where larger values of m I result in less aggressive behavior of the scheme. Furthermore, the above selection of λ and σ allows us to separate the value of packet loss p 1 from the capacity of the bottleneck link C. Combining <ref type="formula" target="#formula_26">(29)</ref>, <ref type="formula" target="#formula_3">(34)</ref> and <ref type="formula" target="#formula_4">(36)</ref> </p><formula xml:id="formula_33">+ + − − + = + k m m k p k D I (37)</formula><p>In the next section, we compare the performance of one particular ISCC congestion control scheme in a NACK-based real-time streaming application with that of IIAD, AIMD, and TFRC (TCP-Friendly Rate Control) <ref type="bibr" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EXPERIMENTS A. Choice of Powers Functions</head><p>We start with an observation that if l becomes much larger than 1.0 in an ISCC scheme and sending rate x is much smaller than capacity C (e.g., when n is large), such congestion control becomes less responsive to packet loss. Being less responsive usually results in very small rate reductions that often cannot elevate congestion in a single step. Thus, schemes with large l usually need multiple back-to-back decrease steps to move the system below the efficiency line in <ref type="figure" target="#fig_0">Figure 1</ref>. Our assumptions above do not model this behavior and the actual resulting packet loss in these schemes turns out to be higher than predicted by (32) and the convergence time is sometimes substantially increased.</p><p>Hence, from this perspective, larger values of l are not desirable. The only value of l that guarantees ideal scalability among TCP-friendly schemes (i.e., k + l = 1 and l + 2k + 1 = 0) is quite high and, specifically, equals 3. In practice, this scheme converges very slowly <ref type="bibr" target="#b6">7</ref> and may not be a feasible solution for the real Internet. Among non-TCP-friendly schemes, values of l close to 1.0 force k to come close to -1.0 (because l+2k+1 must still remain zero), which also results in slower convergence to fairness as sum k + l approaches zero <ref type="bibr" target="#b7">8</ref> .</p><p>Among an infinite number of ISCC schemes, we arbitrarily selected a scheme with l = 2 (k = -1.5), which achieves reasonable performance in terms of both packet loss and convergence, and show its performance in this paper. Note that this particular scheme is somewhat less aggressive that TCP and typically would yield bandwidth to TCP, if employed over a shared path (however, this effect becomes noticeable only when the number of flows n is large). Hence, the practical application of this ISCC scheme in the Internet would require the use of new QoS methods in routers (i.e., DiffServ) as discussed in the introduction. Alternatively, it may be possible to use other ISCC schemes (with a different l), which are not penalized by TCP and which do not suffer from much slower convergence. Due to limited space, we consider finding the best ISCC scheme to be beyond the scope of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Real-time Bandwidth Estimation</head><p>In this section, we briefly examine the accuracy of real-time bandwidth estimation in our NACK-based streaming application and in the next section, we show the performance of ISCC(2), which relies on these real-time estimates for computing the values of λ and σ.</p><p>We used a Cisco network depicted in <ref type="figure" target="#fig_4">Figure 4</ref> for all reallife experiments in this paper. During the experiment, we disabled WRED and WFQ on all T1 interfaces to reflect the current setup of backbone routers. The server supplied real-time bandwidth-scalable MPEG-4 video, which included the FGS (Fine-Granular Scalable) enhancement layer <ref type="bibr" target="#b16">[17]</ref> and the regular base layer, to the client. Consequently, at any time t, the server was able to adapt its streaming rate to the rate x(t) requested by the client, as long as x(t) was no less than the rate of the base layer b 0 and no more than the combined rate of both layers.</p><p>We used a 10-minute MPEG-4 video sequence with the base layer coded at b 0 = 14 kb/s and the enhancement layer coded up to the maximum rate of 1,190 kb/s. Note that two concurrent flows were needed to fully load the bottleneck link. Hence, our experiments below do not cover the case of n = 1, and s n is defined as the ratio of p n to p 2 .</p><p>During the experiment, the client applied a simple packetbunch estimation technique <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b15">[16]</ref> to server's video packets. To simplify the estimation of the bottleneck bandwidth, the <ref type="bibr" target="#b6">7</ref> Slow convergence was found experimentally. 8 Values of k + l close to zero mean that the system makes very small steps toward the fairness line and thus, converges very slowly. server sent its packets in bursts of a pre-defined length. A bandwidth sample was derived from each burst that contained at least three packets.</p><p>To establish a baseline performance, <ref type="figure" target="#fig_6">Figure 5</ref> (left) plots the PDFs of IP bandwidth estimates 9 obtained by two AIMD(1,½) flows over the T1 link in <ref type="figure" target="#fig_4">Figure 4</ref> (both flows used a fixed value of MTU/RTT equal to 30 kb/s). As the figure shows, the flows measured the IP bottleneck bandwidth to be 1,510 kb/s, which is very close to the actual T1 rate of 1,544 kb/s (the discrepancy is easily explained by the data-link/physical layer overhead on the T1 line). Furthermore, both flows were in perfect agreement, and 99.5% of estimates of each flow were between 1,500 and 1,520 kb/s. Nevertheless, what matters most to the ISCC congestion control is the ability of flows to establish consistent estimates, rather than accurate estimates. To this extent, we found that the actual disagreement between the flows during the experiment was negligible and did not noticeably impact packet loss rates or fairness. Due to limited space, we skip a detailed performance study of our bandwidth estimation scheme and move on to show the scalability results in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Scalability Results</head><p>We extensively tested ISCC in simulation and found that it performed very well, in fact achieving constant packet loss. Due to the lack of space, we were forced to remove the simulation results from this paper, and show only real-life experiments over a Cisco testbed (see below).</p><p>In our application with NACK-based congestion control, all methods used slow start at the beginning of each transfer; however, the results below exclude the behavior of the network during slow start and focus on the performance of the schemes in the interval starting 5 seconds after the last flow finished its slow start and ending when the first flow terminated. <ref type="bibr" target="#b9">10</ref> This interval was 520 to 600 seconds long (depending on the number of flows) and included a combined transfer of approximately 60,000 packets.  During the experiment, we tried to select the parameters of the schemes so that the average packet loss of two competing flows using each scheme was between 0.3% and 0.6%. This constraint resulted in selecting MTU/RTT equal to 30 kb/s for AIMD(1,½), and 50 kb/s for IIAD(½,2). The value of the MTU variable in TFRC's equation <ref type="bibr" target="#b6">[7]</ref> was selected to be 180 bytes, whereas the actual MTU used during the experiment was 1,500 bytes for all schemes. Note that TFRC was the only protocol, which used real-time measurements of the RTT in its computation of the rate.</p><p>The efficiency and aggressiveness parameters of the ISCC(2) scheme were set with the same goal in mind to maintain low initial packet loss p 2 : m D = 2 and m I = 20. These parameters guarantee that each flow does not decrease its rate by more than ½ and does not probe for new bandwidth more aggressively that by 5% (i.e., 1/20) of the current sending rate.</p><p>The results of the experiment are summarized in <ref type="figure" target="#fig_8">Figure 6</ref>, which shows packet-loss increase factor s n for four different schemes and values of n between 2 and 50. The results of the experiment show that all non-scalable schemes maintained a steady packet-loss increase to well over 15%. For example, IIAD reached p 50 = 45% (p 2 = 0.29%), AIMD 22% (p 2 = 0.38%), and TFRC 20% (p 2 = 0.26%).</p><p>e.</p><p>On the other hand, the packet loss of the ISCC(2) scheme climbed only to 3.1% over the same range of flows n (p 2 = 0.57%). A least-squares fit suggests that the increase in ISCC's packet loss is very slow, but noticeable (i.e., n 0.47 ). Thus, even though the ISCC scheme was not able to achieve constant packet loss in practice, it did show a substantially better performance than any other schem In addition, under the worst conditions (i.e., n ≈ 50), our data show that the non-scalable protocols maintained a "frozen" picture between 11% and 42% of the corresponding session due to underflow events (which are produced when a frame is missing from the decoder buffer at the time of its decoding). Clearly, these results indicate that high packet loss is very harmful, even in the presence of low RTTs (50-200 ms), large startup delays (3 seconds in our case), and an efficient packet loss recovery mechanism (our retransmission scheme <ref type="bibr" target="#b8">9</ref> Note that bandwidth estimates were derived from bandwidth samples by using the median of the past 20-seconds worth of samples. <ref type="bibr" target="#b9">10</ref> Flows were started with a 1.5-second delay. were able to recover all base-layer packets before their deadlines until loss rates exceeded approximately 15%). At the same time, the ISCC(2) scheme was able to recover all frames (including base and enhancement layer) before their decoding deadlines, representing an ideal streaming situation for an end-user.</p><p>Therefore, we come to the conclusion that non-scalable schemes are poorly suited for rate-based protocols that do not utilize self-clocking and that ideally-scalable schemes promise to provide a constant packet-loss scalability not only in simulation, but also in practice. Nevertheless, further study is required in this area to understand the tradeoffs between the different values of l and k, as well as establish whether slower convergence to fairness found in simulation has any strong implications in large networks (i.e., in the real Internet).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION</head><p>The difficulty of "open-loop" congestion control stems from the fact that the sender in such protocols is not governed by "self-clocking" of acknowledgements and typically continues to stress the network at the same rate even in the presence of severe packet loss and congestion. In such situations of aggravated packet loss, the main problem of NACK-based congestion control can be narrowed down to cases when the client either does not receive any server packets at all (which by default prohibits it from changing the server's rate), or takes multiple retransmissions of control messages to notify the server about the new reduced rate.</p><p>Interestingly, these problems are only noticeable when the congestion is severe enough to require multiple retransmissions of the client's control messages, or when the network encounters periods of heavily-bursty loss. Our experiments with traditional (i.e., non-scalable) NACK-based congestion control methods found that packet loss rates increased very rapidly as the number of flows on the shared link increased.</p><p>To investigate this observation further, we analyzed the class of binomial algorithms and derived the formulas of packet loss increase factor s n as a function of the number of flows: s n = O(n l+2k+1 ). Using our derivations we found that among all proposed binomial schemes, AIMD had the best scalability O(n 2 ) and the lowest packet loss. Furthermore, we showed that unless the schemes had the knowledge of bottleneck capacity C, the scalability of AIMD could not be improved, and even the performance of AIMD was inadequate for actual use in NACK-based applications. Even though all the derivations in the paper assumed synchronized and immediate feedback, our final formulas were found to hold in a number of streaming experiments over a real Cisco network with random packet loss and delayed feedback.</p><p>Given the knowledge of the bottleneck bandwidth, we showed that ideal scalability was both theoretically and practically possible; however, the ISCC schemes were found to be slower in their convergence to fairness when the number of flows n was large. Even though ISCC schemes are "more careful" in probing for new bandwidth, the average efficiency of these schemes was no worse than that of AIMD or IIAD (due to limited space, not discussed in the main body of the paper).</p><p>Regardless of whether ISCC is a viable protocol for the current or future (i.e., DiffServ) Internet, this paper not only answered the question of why NACK-based congestion control is "difficult," but it also measured the exact magnitude of this "difficulty" and provided one solution that overcomes the rapid packet-loss increase typical to "open-loop" congestion control.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Two-flow I-D control system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Parameter s n (i.e., packet-loss scalability) of AIMD and IIAD in simulation based on actual packet loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Setup of the experiment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 (</head><label>5</label><figDesc>right) shows the PDFs of bandwidth estimates ob- tained by 32 simultaneous AIMD(1,½) flows running over the same topology in Figure 4 and with the same value of MTU/RTT. This time, the majority of estimates lie in the prox- imity of 1,490 kb/s, and 95.5% of estimates are contained be- tween 1,400 and 1,620 kb/s (i.e., within 7% of 1,510 kb/s). The lower accuracy of bandwidth estimation in the second case is explained by the lower average sending rate of each flow (i.e., 36 kb/s compared to 559 kb/s in the first case).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. The PDFs of bandwidth estimates with 2 (left) and 32 (right) AIMD(1,½) flows over a shared T1 link.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Packet-loss increase factor s n for the Cisco experiment.</figDesc></figure>

			<note place="foot" n="1"> Note that ACK-based flow control could be used in real-time streaming, but it typically results in some form of QoS penalty (such as longer startup delays, more frequent buffer underflow events, etc.).</note>

			<note place="foot" n="2"> Sometimes called TCP-compatible [2], [8] or TCP-friendly [21]. 3 Note that some papers [2], [20], [21] use a different notation, in which W D (w) = (1-β)w and this formula has a different form. Furthermore, if the rate of AIMD is dominated by timeouts, the formula assumes yet another form [21].</note>

			<note place="foot" n="0">-7803-7476-2/02/$17.00 © 2002 IEEE. INFOCOM 2002</note>

			<note place="foot" n="4"> Note that we implicitly assume that x is limited from below by some constant x min . In window-based congestion control, x min is equivalent to one unit of cwnd (i.e., MTU/RTT), and in rate-based congestion control, x min is the minimum rate at which real-time material can be received (e.g., the rate of the base video layer). 4 0-7803-7476-2/02/$17.00 © 2002 IEEE. INFOCOM 2002</note>

			<note place="foot" n="5"> A one-term approximation used in [2] typically possesses an insufficient accuracy. 5 0-7803-7476-2/02/$17.00 © 2002 IEEE. INFOCOM 2002</note>

			<note place="foot" n="6"> The more the error, the slower will be the convergence. Unfortunately, the lack of space does not permit us to show this result more conclusively. 7 0-7803-7476-2/02/$17.00 © 2002 IEEE. INFOCOM 2002</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">TCP Congestion Control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Allman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Paxson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Stevens</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999-04" />
		</imprint>
	</monogr>
	<note>IETF RFC 2581</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Binomial Congestion Control Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE INFOCOM</title>
		<imprint>
			<date type="published" when="2001-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dynamic Behavior of Slowly-Responsive Congestion Control Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Floyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shenker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCOMM</title>
		<imprint>
			<date type="published" when="2001-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Measuring Bottleneck Link Speed in Packet Switched Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Crovella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal on Performance Evaluation</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Analysis of the Increase and Decrease Algorithms for Congestion Avoidance in Computer Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D-M.</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Networks and ISDN Systems</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">What Do Packet Dispersion Techniques Measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dovrolis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE INFOCOM</title>
		<imprint>
			<date type="published" when="2001-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Equation-Based Congestion Control for Unicast Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Floyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Handley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Padhye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCOMM</title>
		<imprint>
			<date type="published" when="2000-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A Comparison of Equation-Based and AIMD Congestion Control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Floyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Handley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Padhye</surname></persName>
		</author>
		<ptr target="http://www.aciri.org/tfrc/aimd.pdf" />
	</analytic>
	<monogr>
		<title level="j">ACIRI Technical Report</title>
		<imprint>
			<date type="published" when="2000-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Congestion Avoidance and Control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Jacobson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCOMM</title>
		<imprint>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Loss Proportional Decrease based Congestion Control in the Future Internet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bharghavan</surname></persName>
		</author>
		<ptr target="http://timely.crhc.uiuc.edu/Drafts/tech.lipd.ps.gz" />
		<imprint>
			<date type="published" when="1999-07" />
		</imprint>
	</monogr>
<note type="report_type">University of Illinois Technical Report</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A Comparison of End-toEnd Congestion Control Algorithms: The Case of AIMD and AIPD</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K-W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bharghavan</surname></persName>
		</author>
		<ptr target="http://timely.crhc.uiuc.edu/~kwlee/psfiles/infocom2001.ps.gz" />
		<imprint>
			<date type="published" when="2000" />
		</imprint>
		<respStmt>
			<orgName>University of Illinois</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An Integrated Source Coding and Congestion Control Framework for Video Streaming in the Internet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K-W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Puri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ramchandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bharghavan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE INFOCOM</title>
		<imprint>
			<date type="published" when="2000-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An Empirical Study of Real Audio Traffic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heidemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE INFOCOM</title>
		<imprint>
			<date type="published" when="2000-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Scalable Service Differentiation Using Purely End-to-End Mechanisms: Features and Limitations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nandagopal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K-W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bharghavan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IFIP/IEEE International Workshop on Quality of Service (IWQoS)</title>
		<imprint>
			<date type="published" when="2000-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Modeling TCP Throughput: A Simple Model and its Empirical Validation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Padhye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Firoiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Towsley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kurose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGCOMM</title>
		<imprint>
			<date type="published" when="1998-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Measurements and Analysis of End-to-End Internet Dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Paxson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
		<respStmt>
			<orgName>UC Berkeley</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Scalable Internet Video Using MPEG-4</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Radha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Parthasarathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Signal Processing: Image Communication</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Real</forename><surname>Realplayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Networks</surname></persName>
		</author>
		<ptr target="http://www.real.com" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">RAP: An End-to-End Rate-based Congestion Control Mechanism for Real-time Streams in the Internet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rejaie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Handley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Estrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE INFOCOM</title>
		<imprint>
			<date type="published" when="1999-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Transient Behaviors of TCP-friendly Congestion Control Protocols</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE INFOCOM</title>
		<imprint>
			<date type="published" when="2001-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">General AIMD Congestion Control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Lam</surname></persName>
		</author>
		<ptr target="//ftp.cs.utexas.edu/pub/lam/gaimd.ps.gz" />
		<imprint>
			<date type="published" when="2000-05" />
		</imprint>
		<respStmt>
			<orgName>University of Texas at Austin</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report ftp</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
