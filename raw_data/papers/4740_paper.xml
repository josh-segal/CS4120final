<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">When Cache Blocking of Sparse Matrix Vector Multiply Works and Why</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajesh</forename><surname>Nishtala</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California at Berkeley</orgName>
								<address>
									<addrLine>Computer Science Division Berkeley</addrLine>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Vuduc</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California at Berkeley</orgName>
								<address>
									<addrLine>Computer Science Division Berkeley</addrLine>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">W</forename><surname>Demmel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California at Berkeley</orgName>
								<address>
									<addrLine>Computer Science Division Berkeley</addrLine>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><forename type="middle">A</forename><surname>Yelick</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California at Berkeley</orgName>
								<address>
									<addrLine>Computer Science Division Berkeley</addrLine>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">When Cache Blocking of Sparse Matrix Vector Multiply Works and Why</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We present new performance models and a new, more compact data structure for cache blocking when applied to the sparse matrix-vector multiply (SpM×V) operation, y ← y + A · x. Prior work indicates that cache blocked SpM×V performs very well for some matrix and machine combinations, yielding speedups as high as 3x. We look at the general question of when and why performance improves, finding that cache blocking is most effective when simultaneously 1) x does not fit in cache, 2) y fits in cache, 3) the non-zeros are distributed throughout the matrix, and 4) the non-zero density is sufficiently high. We extend our prior performance models, which bounded performance by assuming x and y fit in cache, to consider these classes of matrices. Unlike our prior model, the updated models are accurate enough to use as a heuristic for predicting the optimum block sizes. We conclude with architectural suggestions that would make processor and memory systems more amenable to SpM×V.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction and Overview</head><p>We consider the problem of building high-performance implementations of sparse matrix-vector multiply (SpM×V), or y ← y + A · x. We call x the source vector and y the destination vector. Making SpM×V fast is complicated both by modern hardware architectures and by the overhead of manipulating sparse data structures. It is not unusual to see SpM×V run at under 10% of the peak floating point performance of a single processor. Moreover, in contrast to optimizing dense matrix kernels (dense BLAS), performance depends on the non zero structure of the matrix which may not be known until run-time.</p><p>In prior work on the Sparsity system (version 1.0) <ref type="bibr" target="#b5">[6]</ref>, Im developed an algorithm generator and search strategy for SpM×V that was quite effective in practice. The Sparsity generators employed a variety of performance optimization techniques, including register blocking, cache blocking, and multiplication by multiple vectors. Cache blocking differs from register blocking in that cache blocking reorders memory accesses to increase temporal locality, whereas register blocking compresses the data structure to reduce memory traffic. This paper focuses on cache blocking (Section 2) and asks the fundamental questions of what limits exist on such performance tuning, and how close tuned code gets to these limits. The models presented in this paper (Section 3) extend our prior models <ref type="bibr" target="#b12">[13]</ref> by accounting for the TLB, enabling accurate selection of optimal cache block sizes. It increases the complexity of the data structures used to represent the matrix by adding an extra set of row pointers for each block. The fundamental trade off we need to make is whether the benefit of the added temporal locality outweighs the costs associated with accessing the added overhead.</p><p>We classify the set of matrices on which we see benefits from cache blocking, concluding that cache blocking is most effective when simultaneously 1) x does not fit in cache 2) y fits in cache, 3) the non zeros are distributed throughout the matrix and 4) the non-zero density is sufficiently high. In particular all the test matrices in <ref type="table" target="#tab_0">Table 1</ref> (except Matrix 1) are sparse enough so that register blocking <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13]</ref> has no significant effect.</p><p>Traditional static models of cache behavior used to select tile sizes for dense kernels cannot be applied to sparse kernels due to the presence of indirect and irregular memory accesses known only at run-time. Nevertheless, there have been a number of notable attempts. Temam and Jalby <ref type="bibr" target="#b10">[11]</ref>, Heras, et al. <ref type="bibr" target="#b4">[5]</ref>, and Fraguela, et al. <ref type="bibr" target="#b1">[2]</ref> have developed sophisticated probabilistic cache miss models, but assume uniform distribution of non-zero entries. These models are primarily distinguished from one another by their ability to account for self-and cross-interference misses. Our model in Section 3 differs from the prior work in that 1) we consider multi-level memory hierarchies including the TLB, and 2) explicitly model the execution time in addition to cache misses.</p><p>Gropp, et al., use bounds similar to the ones we develop to analyze and tune a computational fluid dynamics code <ref type="bibr" target="#b2">[3]</ref>; Heber, et al., present a detailed performance study of a fracture mechanics code on Itanium <ref type="bibr" target="#b3">[4]</ref>. This paper considers tuning for matrices that come a variety of other domains, and is furthermore concerned with performance modeling for cache block size selection.</p><p>Due to space limitations we only present the high level intuitions and summary data. We refer the reader to the full report <ref type="bibr" target="#b6">[7]</ref> for a detailed investigation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Summary of the Cache Blocking Optimization</head><p>We assume a reference implementation which stores the matrix in a compressed sparse row (CSR) format <ref type="bibr" target="#b7">[8]</ref>. Cache blocking breaks the CSR matrix into multiple smaller r cache x c cache CSR matrices and then stores these sequentially in memory. Below, we discuss how 1)we compress the size of each block using the row start/end (RSE) optimization, and 2) further exploit the fact that each cache block is a smaller matrix. The latter technique also allows easy recursion with multiple levels of cache blocking.</p><p>Row Start / End (RSE) When matrices (especially band matrices) are blocked it is possible that within a cache block non-zeros do not exist on all the rows. The first cache block, for example, might have only non zero elements in the first tenth of the rows and have the rest of the cache block be empty. However the basic cache blocked data structure would loop over all zero rows without doing any useful work. In order to avoid the unnecessary accesses, a new vector that contains row start(RS) and row end (RE) information for each cache block is also created to point to the first and last nonzero rows in the cache block. This new indexing information makes the performance less sensitive to the size of the cache block. Performance results have shown that this optimization can only help improve performance <ref type="bibr" target="#b6">[7]</ref>.</p><p>Exploiting Cache Block Structure As described above, the cache blocked matrix can be thought of as many smaller sparse matrices stored sequentially in memory. We can exploit this fact by calling our prior sparse matrix vector multiplication routines on each smaller matrix, passing the appropriate part of the source and destination vectors as arguments. The advantage of handling the multiplication in this fashion is that the inner loops can be generated independently of the code for cache blocking and code previously written for non-cache blocked implementations can be reused. This optimization also allows easy recursion with multiple levels of cache blocking. Tests indicate that the function call overhead is negligible since the number of cache blocks for a matrix is usually small compared to the total memory operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Analytic Models of Memory System Performance</head><p>We create analytic upper and lower bounds on performance by modeling various levels of the memory hierarchy. The load and cache models are identical to our prior models <ref type="bibr" target="#b11">[12]</ref>. Due to space limitations we do not present those models here. The lower bound model assumes only compulsory misses while the upper bound assumes that every access to x, y, and matrix miss.</p><p>Overall Performance Model We extend our prior model <ref type="bibr" target="#b11">[12]</ref> by adding a term to account for TLB misses. The new execution time model is as follows:</p><formula xml:id="formula_0">T = κ−1 񮽙 i=1 h i α i + m κ α mem + m T LB α TLB ,<label>(1)</label></formula><p>We assume perfect nesting of the caches, thus h i+1 = m i − m i+1 , where h i and m i are the hits and misses at the i th level of cache respectively. To estimate the upper bound on performance, we set the m i terms to count only the compulsory misses at the i th level. In addition we set the m T LB term to be M (T LB) model (r, c) which is described below. For the lower bound on performance we set all the cache miss terms to be the upper bound on cache misses at each level and set the TLB misses to be the upper bound on TLB misses. TLB Miss Model According to our simple load and cache miss models, cache blocking has no benefit since the blocking adds overhead to the data storage. To factor this in, we need to be able to model at least the most important level of the memory system more accurately to expose the advantages of locality. Empirical evidence suggests that the largest performance gains using cache blocking come from minimizing TLB misses. Below, we present intuition behind our TLB miss modeling, m T LB , and refer the reader elsewhere <ref type="bibr" target="#b6">[7]</ref> for full expressions. For each row and column block size shown above, the value in the cell contains the number of matrices whose performance was within 90% of peak if that block size was chosen. We define TLB Size to be the number of entries in the TLB multipliled by the page size. On the Itanium 2 this was 2MB or 256 doubles.</p><p>As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, measurements indicate two distinct categories of good block sizes for our matrix suite for the Itanium 2. Matrices 2-11 showed the best performance when c cache equaled 1 4 th the TLB size (in words). Matrices 12-14 did not benefit at all from blocking, i.e., c cache equals the column dimension. This dichotomy existed on other platforms as well. Furthermore, performance was relatively insensitive to the row block size, suggesting no row blocking is needed. Our TLB model reflects these observations by switching between expressions for lower and upper bounds on TLB misses as the block size varies <ref type="bibr" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Verification of the Analytic Model</head><p>We evaluate SpM×V on a set of matrices that are large enough and sparse enough for cache blocking to have a significant effect. The properties of the 14 matrices that were chosen are referenced in <ref type="table" target="#tab_0">Table 1</ref>. We evaluate the performance model in which we use true hardware counters through PAPI <ref type="bibr" target="#b0">[1]</ref> to predict the performance (henceforth called the PAPI model) and compare it to the model in which we use estimates of lower and upper bound of cache and TLB misses (henceforth termed the analytic model). The cache and memory latencies were derived from published processor manuals, curve fitting, and experimental work using the Saavedra-Barrera memory system microbenchmark <ref type="bibr" target="#b8">[9]</ref> and MAPS benchmarks <ref type="bibr" target="#b9">[10]</ref>. Due to space limitations we only present a summary of the data for the Itanium 2. The model of Section 3 over predicts absolute performance by up to a factor of 2 on the Itanium 2, implying time still unaccounted for. Moreover, the relative performance as a function of block size is well predicted, meaning we can use the model as a heuristic for choosing a good block size. Indeed, performance at the optimal block sizes in the PAPI model are all within 90% of the best on Itanium 2, implying the model is a good heuristic if the miss models are accurate. Furthermore, except in the case of Matrix 3, the analytic model makes similarly good predictions on the Itanium 2, yielding 90% of the best performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation Across Matrices and Platforms</head><p>Matrix Structure The speedups for each matrix varied across machines, but the best speedups <ref type="table" target="#tab_1">(Table 2)</ref> were observed for the same matrices. The best speedups occurred with Matrices 5-8, 2, and 10-11. Except for Matrices 7 and 8, these matrices have small row dimension and very large column dimension, with non-zeros scattered throughout the matrix. Furthermore, the largest increases in cache misses as c cache increased occurred on the matrices the largest speedups, implying that cache blocking had the intended effect of increasing locality.</p><p>Matrices 12-14 are so sparse that there is effectively no reuse when accessing the source vector and thus blocking does not help, even though their source vector is large. Matrices with densities higher than 10 −5 were helped with cache blocking, provided that their column block size is large enough (greater than 200,000 elements). There was enough reuse in x for the blocking to payoff. We also find that in general matrices in which the row dimension is much less than the column dimension benefit the most from cache blocking. The smaller row dimension implies the overhead added by cache blocking is small since the number of rows themselves are limited. The larger column dimension implies that the unblocked implementations lack locality. Even though Matrix 3 has a large column dimension, blocking did not yield much performance improvement. We performed additional experiments on random but banded matrices confirming theoretical work by Temam and Jalby <ref type="bibr" target="#b10">[11]</ref>. As expected, cache blocking does not help when the band is relatively narrow because the natural access pattern to x is optimal, but pays off as the band grows. In this latter case, the RSE optimization smooths out differences in performance across block sizes <ref type="bibr" target="#b6">[7]</ref>.</p><p>Platform Evaluation Certain matrices such as Matrix 5 experienced significant performance gains through cache blocking on the Itanium 2 and the Power 4, but the speedup was less drastic on the Pentium 3. We expect that as the average number of cycles to access the memory grows, cache blocking will provide a good improvement in performance since cache blocking allows us to reduce expensive accesses to the main memory. The behavior of cache blocked SpM×V has a number of implications for architecture and systems. First, the TLB misses reduced by cache blocking can also be avoided by creating large page sizes. Second, two paths to memory would be ideal since only access to x are helped by caches, and not accesses to the matrix itself. Separate paths would prevent cache conflicts between matrix data and source vector data. In contrast, increased associativity only partially addresses this issue since it still allows premature eviction of "old" source vector elements by matrix elements. Future work might verify the impact of separate memory paths on the hybrid scalar-vector architecture of the Cray X1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Work</head><p>The empirical findings discussed in this paper and our full report indicate that TLB misses have the largest impact on performance. Cache blocking significantly reduces these misses particularly when x is large, y is small, the distribution of non-zeros is nearly random, and the non-zero density is sufficiently high. Our new performance bounds models incorporate the effect of TLB by implicitly modeling capacity and conflict misses ignored by our prior models <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>. Moreover, these new models predict optimal (or near-optimal) cache block sizes.</p><p>Future work should focus on improving the accuracy of the miss models at all the levels in the memory hierarchy and obtain more accurate memory latencies. More accurate models should lead to even more accurate heuristics that decide when and how to cache block a sparse matrix, given the platform and matrix structure. Future work would also analyze the problem on novel architectures.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Histogram of Block sizes for Itanium 2. For each row and column block size shown above, the value in the cell contains the number of matrices whose performance was within 90% of peak if that block size was chosen. We define TLB Size to be the number of entries in the TLB multipliled by the page size. On the Itanium 2 this was 2MB or 256 doubles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 . Matrix Benchmark Suite. Matrices are listed in alphabetical order. Note that matrices 6, 7, and 8 are just modified versions of matrix 5.</head><label>1</label><figDesc></figDesc><table>Application Area 
Dimension 
Nonzeros Density 
1 Dense Matrix 
2000 x 2000 
4000000 1.00 
2 Statistical Experimental Design 
231 x 319770 
8953560 1.21e-1 
3 Linear programming (LP) 
52260 x 379350 
1567800 7.91e-5 
4 LP 
10280 x 243246 
1408073 5.63e-4 
5 Latent Semmantic Indexing 
10000 x 255943 
3712489 1.45e-3 
6 column wise expansion of LSI 
10000 x 2559430 
3712489 1.45e-4 
7 row wise expansion of LSI 
100000 x 255943 
3712489 1.45e-4 
8 row wise stamping of LSI 
100000 x 255943 
37124890 1.45e-3 
9 Queuing model of mutual exclusion 65535 x 65535 
1114079 2.59e-4 
10 Italian Railways scheduling (LP) 4284 x 1092610 
11279748 2.41e-3 
11 Italian Railways scheduling (LP) 4284 x 546305 
5661231 2.42e-3 
12 Web connectivity graph (WG) 
1000005 x 1000005 3105536 3.11e-6 
13 WG after MMD reordering 
1000005 x 1000005 3105536 3.11e-6 
14 WG after RCM reordering 
1000005 x 1000005 3105536 3.11e-6 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 . Speedups across Matrices and Across Platforms. This table shows the performance of the optimum cache block divided by the performance of the non-blocked implementation on that platform for that matrix.</head><label>2</label><figDesc></figDesc><table>Matrix No. 
Platform 
1 
2 
3 
4 
5 
6 
7 
8 
9 10 11 12 13 14 
Itanium 2 1.00 1.27 1.28 1.14 2.00 2.84 1.72 1.94 1.00 1.40 1.34 1.00 1.00 1.00 
Pentium 3 1.01 1.61 1.02 1.15 1.40 1.33 1.10 N/A 1.00 1.21 1.21 1.00 1.00 1.00 
Power 4 1.01 1.77 1.24 1.37 1.97 2.93 1.68 N/A 1.00 1.75 1.73 1.01 1.09 1.01 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A scalable crossplatform infrastructure for application performance tuning using hardware counters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dongarra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Garner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>London</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Supercomputing</title>
		<meeting>Supercomputing</meeting>
		<imprint>
			<date type="published" when="2000-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Memory hierarchy performance prediction for sparse blocked algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Fraguela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Doallo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Zapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Parallel Processing Letters</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards realistic bounds for implicit CFD codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">D</forename><surname>Gropp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Kasushik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Keyes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">F</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Parallel Computational Fluid Dynamics</title>
		<meeting>Parallel Computational Fluid Dynamics</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="241" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fracture mechanics on the Intel Itanium architecture: A case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Dolgert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Mazurkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Stringer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on EPIC Architectures and Compiler Technology</title>
		<meeting><address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Modeling and improving locality for irregular problems: sparse matrix-vector product on cache memories as a case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Heras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">B</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C C</forename><surname>Dominguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">F</forename><surname>Rivera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HPCN Europe</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="201" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Optimizing the performance of sparse matrix-vector multiplication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Im</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000-05" />
		</imprint>
		<respStmt>
			<orgName>University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Performance modeling and analysis of cache blocking in sparse matrix vector multiply</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nishtala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Vuduc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Yelick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
		<respStmt>
			<orgName>University of California, Berkeley, EECS Dept.</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">SPARSKIT: A basic toolkit for sparse matrix computations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Saad</surname></persName>
		</author>
		<ptr target="www.cs.umn.edu/Research/arpa/SPARSKIT/sparskit.html" />
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">CPU Performance Evaluation and Execution Time Prediction Using Narrow Spectrum Benchmarking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Saavedra-Barrera</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992-02" />
		</imprint>
		<respStmt>
			<orgName>University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Modeling application performance by convolving machine signatures with application profiles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carrington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wolter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Characterizing the behavior of sparse algorithms on caches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Temam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jalby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Supercomputing &apos;92</title>
		<meeting>Supercomputing &apos;92</meeting>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Performance optimizations and bounds for sparse matrix-vector multiply</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vuduc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Yelick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kamil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nishtala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Supercomputing</title>
		<meeting>Supercomputing<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Automatic performance tuning of sparse matrix kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Vuduc</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
		<respStmt>
			<orgName>University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
<note type="report_type">PhD thesis</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
