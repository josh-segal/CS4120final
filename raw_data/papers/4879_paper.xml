<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T17:04+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">F4: Large-Scale Automated Forecasting Using Fractals</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepayan</forename><surname>Chakrabarti</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Automated Learning and Discovery School of Computer Science</orgName>
								<orgName type="department" key="dep2">Computer Science Department School of Computer Science</orgName>
								<orgName type="institution" key="instit1">Carnegie Mellon University</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
							<email>christos@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Automated Learning and Discovery School of Computer Science</orgName>
								<orgName type="department" key="dep2">Computer Science Department School of Computer Science</orgName>
								<orgName type="institution" key="instit1">Carnegie Mellon University</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">F4: Large-Scale Automated Forecasting Using Fractals</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H28 [Database Applications]: Data Mining-time se- ries forecasting General Terms Algorithms Keywords Time series</term>
					<term>Automated forecasting</term>
					<term>Fractals</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Forecasting has attracted a lot of research interest, with very successful methods for periodic time series. Here, we propose a fast, automated method to do non-linear forecasting, for both periodic as well as chaotic time series. We use the technique of delay coordinate embedding, which needs several parameters; our contribution is the automated way of setting these parameters, using the concept of &apos;intrinsic di-mensionality&apos;. Our operational system has fast and scalable algorithms for preprocessing and, using R-trees, also has fast methods for forecasting. The result of this work is a black-box which, given a time series as input, finds the best parameter settings, and generates a prediction system. Tests on real and synthetic data show that our system achieves low error, while it can handle arbitrarily large datasets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Given the sequence of values taken by an observable over time, a forecasting system attempts to predict the observable's values over some future time period. This has applicability in a wide range of fields, such as financial systems (exchange rates), physics (laser fluctuations) and biology (physiological data over time). Many techniques have been suggested, but are either too simplistic for many realworld problems (such as linear models like ARMA), or require long training times and large number of parameters (such as Neural Networks).</p><p>Our approach uses a forecasting method called "Delay Coordinate Embedding". This has the advantage of being firmly grounded in theory, and can handle periodic as well as chaotic datasets. Its disadvantage was that its parameters had to be set manually. Our F4 (Fractal FOREcasting) system provides automatic methods to do this, without any human intervention. This results in a black-box which, given any time series, can automatically find the optimal parameters and build a prediction system.</p><p>Our method, being completely automated, can operate in a sensor network setting, which is an area of increasing interest ( <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b2">[3]</ref>). Each sensor will be collecting time series data, and it will be doing forecasting, and thus be able to spot outliers and find patterns. In such an environment, human intervention and manual setting of parameters is out of the question, because sensors may be operating in a humanhostile environment, with low communication bandwidth for shipping data and getting human feedback.</p><p>Problem Definition (Predict-1):</p><p>• Given a time series x1, x2, . . . , xt,</p><p>• predict the value of xt+1. Later in the paper, we shall generalize the problem to allow multiple time series and n-step-ahead predictions. An example time series is shown in <ref type="figure" target="#fig_1">Figure 1</ref>(a).</p><p>The rest of the paper is organized as follows: Section 2 gives a background tutorial on certain techniques used by our algorithms. Section 3 details our contributions, and gives the algorithms we use. Section 4 gives our experiments and results. Section 5 describes related work in the field of time series prediction, followed by the conclusions in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">BACKGROUND</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Delay Coordinate Embedding</head><p>We first introduce certain concepts. Let the observation sequence be represented by the series xt, which gives the value of the time series at time t. Let us define the following vector: </p><p>Here, τ is some real number greater than zero called the time delay, and L (called the lag length) is any integer greater than zero. Definition 2. Lag Plot: A plot of this (L + 1) dimensional vector space is called the Lag Plot for lag L. This vector space is also called the Phase-Space.</p><p>We explain the technique we use with an example. <ref type="figure" target="#fig_1">Fig- ure 1(a)</ref> shows a plot of the Logistic Parabola time series. Let us draw its lag plot with a lag of L = 1, for a moment leaving aside the question of why L = 1 was chosen. The lag plot is shown in <ref type="figure" target="#fig_1">Figure 1(b)</ref>. We see that a definite structure becomes apparent in the lag plot, which was hidden in the first plot. This can be exploited for prediction purposes. To predict xt+1 given xt, we find all the points in the lag plot whose X-values are the k-nearest-neighbors of xt (assuming a given k). We take the Y-values of these points, and interpolate between them. The result is our predicted value of xt+1. This idea can be generalized to lag plots with L &gt; 1, with KNN being done on the L dimensions representing xt−τ , . . . , xt−Lτ , followed by interpolation on the dimension representing xt. As against this, we show the fit obtained by using an autoregressive (AR) model in <ref type="figure" target="#fig_1">figure 1(c)</ref>. AR attempts to minimize least-squares distance, which leads to very bad predictions on chaotic time sequences such as the Logistic Parabola, as shown.</p><p>This soundness of this method is based on a certain result (generally known as Takens' Theorem), which is outside the scope of this paper. It says that there is an optimal value of L, and increasing L beyond that value will not yield any better predictions. Interested readers are referred to <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b26">26]</ref> for details.</p><p>Hence, the problem of time series prediction can be divided into two subproblems:</p><p>1. Finding the right values for the lag length (Lopt) and number of nearest neighbors (kopt)</p><p>2. Prediction of future values given the current delay coordinate vector</p><p>The value of the time delay (τ ) is usually τ = 1. For setting the correct lag length Lopt, most current implementations either involve manual parameter setting or techniques requiring thresholding/bucketization. This is one of the issues for which we propose solutions. Again, the determination of kopt has till now been ad hoc. Here we propose a method to automatically set the value of kopt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FalseNearestNeighbors</head><p>The problem is finding the optimal value for lag. Abarbanel( <ref type="bibr" target="#b0">[1]</ref>) suggests a method called False Nearest Neighbors to estimate this. We found this technique to be unsuitable for inclusion in a black-box prediction system, because it requires thresholding, and the results are sensitive to the threshold. Our upcoming methods solve this problem of choosing L.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fractals</head><p>The fractal dimension of a cloud of points gives an estimate of the "intrinsic dimensionality" of the data in that space. For example, if we consider points along the diagonal of a cube, the intrinsic dimensionality of these points is 1 (because they actually lie along a straight line), but the extrinsic dimensionality is 3 (because the individual points are expressed in 3D-coordinates). Similarly, a parabola in two dimensions (as in <ref type="figure" target="#fig_1">Figure 1(b)</ref>) also has an intrinsic dimensionality of 1. There are several fractal dimensions existing in literature. Two of the most used ones are called the "correlation fractal dimension" and the "Hausdorff dimension". The correlation integral is obtained by plotting the number of pairs of points (P (r)) within a radius r, against r, on a log-log plot. For fractals, the plot consists of a horizontal part followed by an incline, and then another horizontal part. The correlation integral is the slope of the middle part. A faster way to compute it is through the Box-counting plot( <ref type="bibr" target="#b3">[4]</ref>). <ref type="figure" target="#fig_3">Figure 2</ref> shows several example datasets, and their fractal dimensions. Plots (a) and (b) show the 'Circle' dataset, where the fractal dimension is found to be 1. This correctly captures the fact that given one dimension, the other dimension is automatically determined, so the intrinsic dimensionality is only 1. Plot (c) shows a randomly spread cloud of points, whose fractal dimension is found to be 2 from plot (d). Again, this is expected because the dimensions are mutually independent in this case. Plots (e) and (f) show the fractal dimension plot for a set of points called the "Sierpinski Triangle". Here, each dimension provides some information about the other, so the fractal dimension should be between 1 (for complete information) and 2 (for no information). It is actually found to be approximately 1.56. The reader is referred to <ref type="bibr" target="#b21">[21]</ref> for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Symbol Meaning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">PROPOSED METHOD</head><p>We recap the problem: Given a time series x1, x2, . . . , xt, predict the value of xt+1. We can generalize this problem as follows:</p><p>Problem Definition (Predict-n):</p><p>The training set (also called the historical data, for example, stocks) is a set of time series generated by the same physical system over separate periods of time.</p><formula xml:id="formula_1">T S = X1, . . . , XN</formula><p>where Xi = xt i , xt i +1, . . . , x t i +(l i −1) . Here, xt is the value of the time series at time t, and li is the length of sequence Xi. Also, the forecasting system is provided with the query sequence Y = y1, . . . , y l from the same physical system, which must be forecasted; that is, we need to find y l+1 , y l+2 , . . . and so on. Thus, we have several training sequences, and one query sequence.</p><p>If we had only one training sequence, which was also the query sequence, then this would reduce to the Predict-1 problem.</p><p>We automate the delay-coordinate-embedding approach in our forecasting system. An advantage of this approach is its firm mathematical basis <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b26">26]</ref>. To automate the forecasting process, the system needs to be able to automatically . This appears hard to predict, but on generating the two-dimensional lag-plot, shown in (b), we see the pattern in the data. This pattern can be used for prediction. Part (c) shows the AR fit, which is obviously not good.  The first figure shows the overview of the F4 system. Given a training set and a query, it forecasts the future of the query time series. The second figure expands the F4 system. The training set of time series is fed into a preprocessor, which outputs the "best" values of lag-length and number of nearest neighbors(k) to use. Then the time series are stored in an R-Tree using this lag-length. When queries come, the its k-nearest neighbors in lag space are retrieved. The points succeeding these neighbors are noted and interpolated to give the value for the prediction for the current query. The preprocessor itself is our novel contribution, and the shaded portions can be off-the-shelf components.</p><p>set the values of the parameters, such as the optimal lag length Lopt and optimal number of nearest neighbors kopt.</p><p>The thrust of our research has been on formalizing methods for setting these parameters, without the use of thresholding/bucketization techniques, which introduce arbitrariness into the system. Thus, we shall have a black box, which, given a time series, will generate a similarity search system based on this approach, with all parameters set automatically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Estimating the optimal lag length Lopt</head><p>Given a cloud of points in an L-dimensional space, let us call its fractal dimension fL. Now, with a given time series, we can form several clouds of points by considering L = 1 . . . Lmax. Now we define the concept of a "Fractal Dimension vs Lag" (FDL) plot.</p><p>Definition 3. FDL plot of a sequence: This is a plot of fL versus L, for L = 1 . . . Lmax.</p><p>Beyond a certain point, increasing the lag length adds no new information regarding the state space, so the FDL plot should flatten out. The lag at which it settles could be used as the optimal lag length. For example, <ref type="figure">Figure 6</ref>(a) shows the FDL plot for the LASER dataset. We see that the plot starts flattening at lag L = 7. Thus, the optimal lag length in this case is Lopt = 7. Current algorithms for finding fractal dimension scale almost linearly with number of datapoints, so using this method is fast and scalable.</p><p>Generating the FDL plot requires a value of Lmax. We generate this value adaptively. We find fL for L = 1, 2, . . .  <ref type="bibr">[L]</ref> is within delta=95% of the maximum fd return L(opt); } One possible method for estimating Lopt would be by using Cross-Validation. In this case, the historical data is divided into a training set and a holdout set, and for each L = 1, 2, . . . , Lmax, the error is estimated over the holdout set. The value of L at which this error is minimized is chosen to be Lopt. But this approach requires us to do k-nearestneighbors for each value of L, which means that an R-Tree has to be built for each value. This is an extremely timeconsuming operation, and cannot be done for large datasets.</p><p>Hence, this technique cannot be used to find Lopt. Our approach is more scalable and can be extended to very large datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Estimating the Number of Nearest Neighbors kopt</head><p>Our approach requires finding k nearest neighbors to a given delay vector. Current implementations leave the value of k to be fixed manually. The textbook approach is to have a dynamic assignment by using the technique of crossvalidation. In this, we start by dividing the available data into a training and a holdout set. Using the optimal lag, we build an R-Tree using the training set. Then, starting with k as 1, we find the prediction error over the holdout set. We keep incrementing k until the prediction error stops decreasing significantly.</p><p>We propose a new method for setting kopt in this problem setting. Our observation is that the minimum number of points needed to bracket one point in f dimensions is f + 1. This leads us to the following conjecture.</p><p>Conjecture 1. The optimal number of nearest neighbors should depend linearly on the intrinsic dimensionality; that is,</p><formula xml:id="formula_2">kopt = O(f )<label>(2)</label></formula><p>To do a better interpolation, we need to bracket it in each dimension. This leads to k = 2f . We add a constant for handling noise, and that leads to the formula kopt = 2f + 1. This is the technique we use. The results seem to suggest that this provides pretty good prediction accuracy (better than cross-validation, and it is also faster). It must still be mentioned that this is only a heuristic, which works well in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Speed and Scalability</head><p>Finally, this system depends on making predictions on the basis of past regularities in the data. Thus, the data must be stored in a form making such similarity searches fast and efficient. Storage of and similarity searches over delay coordinate vectors leads to several problems. One is the problem of dimensionality curse: the larger the dimension of the delay coordinate vector, the more acute the problem. Another problem is that of fast retrieval from the database. We have already implemented a time series similarity search prototype, which uses the R-Tree spatial data access method ( <ref type="bibr" target="#b13">[14]</ref>). The dimensionality curse is tackled by the use of feature extraction, DFT ( <ref type="bibr" target="#b8">[9]</ref>), DWT, segmented means ( <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b15">16]</ref>) and such methods.</p><p>The other point of concern is the speed and scalability of the preprocessing step. We show in Section 4.2 that this step is indeed fast. We give order-of-magnitude computations, as well as experimental wall-clock times to prove this. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Interpolation</head><p>A related question is determining the correct method for interpolating between the predictions given by the chosen k nearest neighbors. We tried out several interpolation methods: one uses plain averaging over the k predictions, another weights the predictions by the exponential of the negative of the distance squared (here, distance refers to the Euclidean distance between the current delay vector and the neighboring delay vector). We settled on an SVD-based interpolation method, detailed in <ref type="bibr" target="#b25">[25]</ref>, where the least-squares fitting line through the nearest neighbor predictions is used as an approximation of the true predictor function. The projection of the point-of-prediction on to this line gives the value of the prediction.</p><p>Thus, the main aim of our work was to find formal methods for choosing values for lag length (Lopt) and number of nearest neighbors used for interpolation (kopt). The success of the work can be judged by comparing the results produced by using these parameters against those when the parameters are chosen on an ad hoc basis. We have compared them on several datasets, the results of which will be described in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">RESULTS</head><p>We compared out algorithm to several parameter settings based on computation time required and prediction accuracy. We used several datasets, both real and synthetic, on which to test our algorithm. These were:</p><p>• Synthetic (but realistic):</p><p>-Lorenz equations (LORENZ): N = 20, 000 points.</p><p>The equations are:</p><formula xml:id="formula_3">˙ x = σ(y − x) (3) ˙ y = −xz + rx − y (4) ˙ z = xy − bz (5)</formula><p>where σ, b and r are constants. These equations have been used to model convection currents.</p><p>• Real-world:</p><p>-Laser Fluctuations (LASER): N = 10, 000 points, this is Time Series A from the Santa Fe competition(1992) <ref type="figure">Figure 4</ref> gives snapshots of these datasets. Several other datasets were also tested, but are not detailed due to space considerations; results in all cases were similar. The following subsections will describe each of the datasets and the results we obtained on them.</p><p>For prediction accuracy, we used the typical measure called Normalized Mean Squared Error <ref type="bibr" target="#b1">[2]</ref>.</p><formula xml:id="formula_4">N M SE = 1 σ 2 N N i=1 (xi − ˆ xi) 2 (6)</formula><p>where xi is the true value of the ith point in the series of length N , ˆ xi is the predicted value, and σ is the standard deviation of the true time series during the prediction interval. The lower this value, the better the algorithm.</p><p>We did experiments to answer the following questions:</p><p>• how good (that is, accurate) are the proposed choices of Lopt and kopt</p><p>• how fast is the preprocessing</p><p>• how fast is the forecasting</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Accuracy</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LORENZ dataset</head><p>The LORENZ dataset is a synthetic dataset which models convection currents. Results from the LORENZ dataset are shown in <ref type="figure">Figure 5</ref>. The observations are:</p><p>1. The plot is seen to flatten out at a lag length of five. This verifies Takens' theorem, and the mathematical justification for our technique.</p><p>2. NMSE was also computed for each lag length, and we see that plot 5(b) has its minimum at lag length of four. This is close to the value that our approach gives. The difference in NMSEs for these two lags is also not much different.</p><p>3. We also show a sample 150-step-ahead prediction sequence. The prediction accuracy is excellent.</p><p>4. We ran AR with the same window size as out Lopt, that is, 5. Our method is seen to clearly outperform the AR(5) model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LASER dataset</head><p>This is a dataset of fluctuations measured during the operation of a Laser. It is more widely known as "Data Set A" from the Santa Fe competition <ref type="bibr" target="#b1">[2]</ref>. We used the first 6000 points as the training set. Our results on a particular stretch of the dataset are shown in <ref type="figure">Figure 6</ref>. The observations are:</p><p>1. The FDL plot flattens out at around L = 7, which is chosen as Lopt.</p><p>2. The NMSE versus Lag plot shows that this choice is one of the smallest values of L which give good accuracy.</p><p>3. We also show a sample 100-step-ahead prediction sequence, where we predict using the AR model, using a window size of 7(= Lopt). Our prediction is clearly better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Preprocessing Time</head><p>For the experiment, we generated the LORENZ dataset for different lengths of time. <ref type="figure">Figure 7 (plots a and b)</ref> give the experimental results. It can be seen that the preprocessing time varies almost linearly with the size of the training set N , and quadratically with L. This verifies the assertions in Section 3.3. Here we plot forecasting time versus database size. Our method is found to clearly outperform sequential scan, without suffering from dimensionality curse problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Forecasting Time</head><p>The same experimental setting as before is used in this. <ref type="figure">Figure 7</ref> (plot c) gives the results when forecasting time is compared with database size (that is, the length of the time series). It can be seen that the system easily outperforms plain Sequential Search. The observations to note are:</p><p>• F4 takes approximately constant time (about 1.5 seconds), which is interactive.</p><p>• F4 does not suffer from dimensionality curse problems, thanks to our careful design (using segmented means and R-Trees).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">RELATED WORK</head><p>Work on time series can be broadly classified into three categories: Linear Prediction, Non-linear Prediction and Time-Series-Indexing related work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Linear Prediction</head><p>There exist a large number of linear models, such as AR, MA, ARIMA, ARFIMA, and so on. The basic ideas are illustrated here in the case of the ARMA(M,N) model, where the equation for xt is given by:</p><formula xml:id="formula_5">xt = M m=1 amxt−m + N n=0 bnet−n<label>(7)</label></formula><p>where the ams lead to internal dynamics, and the bns are weighing factors for external inputs et. It has been widely used in all areas of time series analysis and discrete-time signal processing. Reference texts for this are <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">22]</ref>. The downside of linear models is that they fail in the presence of non-linearities in the underlying process. We have provided an intuitive reason for this with regard to the Logistic Parabola dataset ( <ref type="figure" target="#fig_1">figure 1(c)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Non-linear Prediction</head><p>One nonlinear prediction method is the Delay Coordinate Embedding method, which has been described in Section 2. Another approach has been through the use of Artificial Neural Networks <ref type="bibr" target="#b30">[30,</ref><ref type="bibr" target="#b31">31,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b28">28]</ref>. Neural networks use the same idea: find a function f which gives the best fit for xt = f (xt−1, . . . , ft−w). The only difference is in the method for estimating the function f . A taxonomy of neural network structures for time-series processing is provided in <ref type="bibr" target="#b19">[20]</ref>. But all these methods suffer from the traditional problems associated with neural networks: long training times and large number of parameters. Hidden Markov Models(HMMs) ( <ref type="bibr" target="#b23">[23]</ref>) have also been used ( <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>). There is a similarity between these models and our technique, but the forward-backward algorithm for finding the parameters in such models is O(N 2 ) and hence not scalable to large datasets. Also our approach seems to lead to a more natural problem description.</p><p>Another method is called the Method of Analogues ( <ref type="bibr" target="#b17">[18]</ref>). This approach is simple and has few free parameters, but works only for low-dimensional chaotic attractors, and only for predictions over a short period of time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Other Time Series Work</head><p>Time sequences have been studied from several points of view, other than prediction. <ref type="bibr" target="#b12">[13]</ref> and <ref type="bibr" target="#b24">[24]</ref> are some recent surveys on time series similarity and indexing. One problem of particular relevance to the data-mining and database communities has been the storage and indexing of large time series datasets for supporting fast similarity search. Similarity search is an important aspect of our technique too, and hence is relevant for us. Since the sequences to be stored are typically n-dimensional data, spatial databases such as R-Trees( <ref type="bibr" target="#b13">[14]</ref>) and variants have been used. But such structures cannot efficiently handle very high-dimensional data. Hence, techniques have been sought to reduce dimensionality: <ref type="bibr" target="#b16">[17]</ref> used Singular Value Decomposition (SVD) to do this. In <ref type="bibr" target="#b32">[32]</ref>, the authors use an approach called "Segmented Means" in which the time series is subdivided in equal-sized windows, and the means of the data in those windows are stored. The authors give techniques to get carry out exact k-nearest-neighbor and range queries in such situations. A similar technique is detailed in <ref type="bibr" target="#b15">[16]</ref>. In <ref type="bibr" target="#b5">[6]</ref>, the authors attempt to find local correlations in the data, as opposed to global correlations, and then perform dimensionality reduction on the locally correlated clusters of data individually. In a similar vein, <ref type="bibr" target="#b14">[15]</ref> try to fit a set of constant value segments of varying lengths to the series, thus achieving data compression.</p><p>Another aspect of time series research has been the problem of finding rules/patterns from the series. One approach by <ref type="bibr" target="#b7">[8]</ref> was to form subsequences of the data, which were clustered, and then rule finding methods were used to obtain rules from the sequence of clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSIONS</head><p>We focussed on building a fast and completely automated non-linear forecasting system. The major contributions of this work are the following:</p><p>• The automatic estimation of vital forecasting parameters, namely of the optimal lag Lopt and a good guess for the number of neighbors kopt. The novelty is the use of 'fractal dimensions' for this purpose.</p><p>• Scalability: 'F4' is the first scalable, 'black-box' forecasting method, capable of handling arbitrarily large datasets, and with fast forecasting algorithms.</p><p>• Experiments on real and synthetic datasets, that show that our method is not only fast and scalable, but also accurate, achieving low prediction error.</p><p>Additional, smaller contributions include the following:</p><p>• The modularization of the forecasting problem: the 'F4' system ( <ref type="figure" target="#fig_4">Figure 3</ref>) can trivially use better/newer access methods, as they come along, although the chosen R-tree and 'segmented means' perform very well. It can also trivially accommodate newer/better interpolation methods, once the k nearest neighbors have been retrieved.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>b</head><label></label><figDesc>= [xt, xt−τ , xt−2τ , . . . , xt−Lτ ]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Definition 1 .</head><label>1</label><figDesc>Delay Coordinate Vector: The vector b is called a delay coordinate vector because its terms are the time-delayed data values from the time series.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>(Figure 1 :</head><label>1</label><figDesc>Figure 1: The logistic parabola: The equation generating this dataset is: xt = 3.8xt−1(1 − xt−1) + et, where et is a N(0, 0.001) random variable. This is a chaotic dataset, a sample of which is shown in (a). This appears hard to predict, but on generating the two-dimensional lag-plot, shown in (b), we see the pattern in the data. This pattern can be used for prediction. Part (c) shows the AR fit, which is obviously not good.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>(Figure 2 :</head><label>2</label><figDesc>Figure 2: Examples of Fractal Dimension (FD) plots: The circle of plot (a) is a smooth curve; its fractal dimension is found to be 1 from the slope of plot (b). Plot (c) shows a dataset with points spread randomly in 2 dimensions. The slope from plot (d) is close to 2 as expected. Plot (e) shows a self-similar cloud of points; its fractal dimension is approximately 1.56 from plot (f ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: The Proposed Forecasting Process: The first figure shows the overview of the F4 system. Given a training set and a query, it forecasts the future of the query time series. The second figure expands the F4 system. The training set of time series is fed into a preprocessor, which outputs the "best" values of lag-length and number of nearest neighbors(k) to use. Then the time series are stored in an R-Tree using this lag-length. When queries come, the its k-nearest neighbors in lag space are retrieved. The points succeeding these neighbors are noted and interpolated to give the value for the prediction for the current query. The preprocessor itself is our novel contribution, and the shaded portions can be off-the-shelf components.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>till the variation in fL for several successive values (w) of L lies within 񮽙 of their values. In our experiments, we used w = 10, and 񮽙 = max(0.3, 10% of the moving average of the Fractal Dimension ). We found that the results are not sensitive to particular choices of these values. When the variation is within this range, it signals that the flat portion of the FDL plot has been reached, and we do not need to find fL for higher L. The pseudo-code for this algorithm is as follows: find_best_lag(X,Max){ /* X is the time series, with individual * elements being x(t). */ for(i = 1;; i++){ V = The vector space with lag length of i; fd[i] = fractal dimension of V; if we have reached the flat portion break; } L(opt) = minimum L such that fd</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Lemma 1 .</head><label>1</label><figDesc>Time complexity of the preprocessing step is O(N L 2 opt ) Proof 1. Given a cloud of N points in L-dimensional space, algorithms exist for calculating the fractal dimension in O(N L * log(N L)) time. But better algorithms can remove the log(N L) factor, and what we observed in our experi- ments is that calculation of the fractal dimension of a cloud of points is indeed O(N L) on the average. The preprocessing time of our algorithm is spent in generating the FDL plot, where fractal dimensions of clouds of points are calculated for dimensionality L = 1 . . . O(Lopt). Thus, the total time taken is O(N.1 + N.2 + . . . + N.Lopt) = O(N L 2 opt ). Thus the preprocessing is linear in the length of the time series and quadratic in the value of Lopt.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :Figure 5 :Figure 6 :Figure 7 :</head><label>4567</label><figDesc>Figure 4: The datasets: These are samples of the datasets we use in our experiments.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Analysis of Observed Chaotic Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D I</forename><surname>Abarbanel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Time Series Prediction: Forecasting the Future and Understanding the Past</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Weigend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Gershenfeld</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Addison Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Continuous queries over data streams. Sigmod Record</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Widom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Estimating the selectivity of spatial queries using the &apos;correlation&apos; fractal dimension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Belussi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 21th International Conference on Very Large Data Bases</title>
		<editor>U. Dayal, P. M. D. Gray, and S. Nishio</editor>
		<meeting>21th International Conference on Very Large Data Bases<address><addrLine>Zurich, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="299" to="310" />
		</imprint>
	</monogr>
	<note>VLDB&apos;95</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Towards sensor database systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sheshadri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Conference on Mobile Data Management</title>
		<meeting>the Second International Conference on Mobile Data Management<address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Local dimensionality reduction: A new approach to indexing high dimensional spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehrotra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th VLDB Conference</title>
		<meeting>the 26th VLDB Conference<address><addrLine>Cairo, Egypt</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The Analysis of Time Series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chatfield</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<publisher>Chapman and Hall</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Rule discovery from time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-I</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mannila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Renganathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 3rd International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Fast subsequence matching in time-series databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranganathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Manolopoulos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>SIGMOD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Forecasting probability densities by using hidden markov models with mixed states</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dimitriadis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Time Series Prediction: Forecasting the Future and Understanding the Past</title>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deformable markov model templates for time-series pattern matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="81" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">On computing correlated aggregates over continual data streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Korn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2001 ACM Sigmod International Conference on Management of Data</title>
		<meeting>the 2001 ACM Sigmod International Conference on Management of Data<address><addrLine>Santa Barbara, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Time series similarity search measures and time series indexing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gunopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGMOD</title>
		<meeting>the ACM SIGMOD<address><addrLine>Santa Barbara</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">624</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">R-trees: A dynamic index structure for spatial searching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guttman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<publisher>ACM SIGMOD</publisher>
			<biblScope unit="page" from="47" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Locally adaptive dimensionality reduction for indexing large time series databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pazzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGMOD</title>
		<meeting><address><addrLine>Santa Barbara, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A simple dimensionality reduction technique for fast similarity search in large time series databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Pazzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge Discovery and Data Mining, Current Issues and New Applications, 4th Pacific-Asia Conference</title>
		<editor>T. Terano, H. Liu, and A. Chen</editor>
		<meeting><address><addrLine>Kyoto, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000" />
			<biblScope unit="volume">1805</biblScope>
			<biblScope unit="page" from="122" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficiently supporting ad hoc queries in large datasets of time sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Korn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGMOD</title>
		<meeting>SIGMOD<address><addrLine>Tucson, Arizona, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Time series prediction by using the method of analogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Kostelich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Lathrop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Time Series Prediction: Forecasting the Future and Understanding the Past</title>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Nonlinear signal processing using neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lapedes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Farber</surname></persName>
		</author>
		<idno>LA-UR-87-2662</idno>
		<imprint>
			<date type="published" when="1987" />
			<pubPlace>Los Alamos National Laboratory, Los Alamos, NM</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Neural Network Architectures for Temporal Sequence Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="243" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Addison</forename><surname>Wesley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Chaos and Fractals: New Frontiers of Science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-O</forename><surname>Peitgen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jurgens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Saupe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Priestley</surname></persName>
		</author>
		<title level="m">Spectral Analysis and Time Series</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A tutorial on hidden markov models and selected applications in speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rabiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Proc</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="257" to="284" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Comparison of access methods for time-evolving data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Salzberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">J</forename><surname>Tsotras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="158" to="221" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Time Series Prediction by Using Delay Coordinate Embedding(Data Set A)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sauer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Addison Wesley</publisher>
			<biblScope unit="page" from="175" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Yorke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Casdagli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Embedology</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Stat. Phys</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="579" to="616" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Detecting strange attractors in turbulence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Takens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Dynamical Systems and Turbulence</title>
		<editor>D. A. Rand and L.-S. Young</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1981" />
			<biblScope unit="volume">898</biblScope>
			<biblScope unit="page" from="366" to="381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Time Series Prediction by Using a Connectionist Network with Internal Delay Line</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Addison Wesley</publisher>
			<biblScope unit="page" from="195" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Predicting the future: A connectionist approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Weigend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Huberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Neural Systems</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="193" to="209" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Beyond Regression: New Tools for Prediction and Analysis in the Behavioural Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Werbos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974" />
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Harvard University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Generalization of backpropagation with application to a recurrent gas market model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neur. Net</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="339" to="356" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Fast time sequence indexing for arbitrary lp norms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-K</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">26th VLDB</title>
		<meeting><address><addrLine>Cairo, Egypt</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="385" to="394" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
