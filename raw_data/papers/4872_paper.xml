<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T17:04+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PathSim: Meta Path-Based Top-K Similarity Search in Heterogeneous Information Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
							<email>hanj@illinois.edu‡xyan@cs.ucsb.edu§psyu@cs.uic.edu⋄tiwu@microsoft.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xifeng</forename><surname>Yan</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of California at Santa Barbara</orgName>
								<address>
									<settlement>Santa Barbara</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Illinois at Chicago</orgName>
								<address>
									<settlement>Chicago</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Wu</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Microsoft Corporation</orgName>
								<address>
									<settlement>Redmond</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">⋄</forename></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
								<address>
									<settlement>Urbana</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">PathSim: Meta Path-Based Top-K Similarity Search in Heterogeneous Information Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Similarity search is a primitive operation in database and Web search engines. With the advent of large-scale heterogeneous information networks that consist of multi-typed, interconnected objects , such as the bibliographic networks and social media networks , it is important to study similarity search in such networks. Intuitively, two objects are similar if they are linked by many paths in the network. However, most existing similarity measures are defined for homogeneous networks. Different semantic meanings behind paths are not taken into consideration. Thus they cannot be directly applied to heterogeneous networks. In this paper, we study similarity search that is defined among the same type of objects in heterogeneous networks. Moreover, by considering different linkage paths in a network, one could derive various similarity semantics. Therefore, we introduce the concept of meta path-based similarity, where a meta path is a path consisting of a sequence of relations defined between different object types (i.e., structural paths at the meta level). No matter whether a user would like to explicitly specify a path combination given sufficient domain knowledge, or choose the best path by experimental trials, or simply provide training examples to learn it, meta path forms a common base for a network-based similarity search engine. In particular, under the meta path framework we define a novel similarity measure called PathSim that is able to find peer objects in the network (e.g., find authors in the similar field and with similar reputation), which turns out to be more meaningful in many scenarios compared with random-walk based similarity measures. In order to support fast online query processing for PathSim queries, we develop an efficient solution that partially materializes short meta paths and then concatenates them online to compute top-k results. Experiments on real data sets demonstrate the effectiveness and efficiency of our proposed paradigm.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Heterogeneous information networks are the logical networks involving multiple typed objects and multiple typed links denoting different relations, such as bibliographic networks, social media Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Articles from this volume were invited to present their results at The 37th International Conference on Very Large Data Bases, August 29th -September 3rd 2011, Seattle, Washington. networks, and the knowledge network encoded in Wikipedia. It is important to provide effective search functions in such networks, where links play an essential role and attributes for objects are difficult to fully obtain. In particular, we are interested in providing similarity search functions for objects that are from the same type. For example, in a bibliographic network, a user may be interested in the (top-k) most similar authors for a given author, or the most similar venues for a given venue; in the Flickr network, a user may be interested in searching for the most similar pictures for a given picture, and so on.</p><p>Similarity search has been extensively studied for traditional categorical and numerical data types in relational data. There are also a few studies leveraging link information in networks. Most of these studies are focused on homogeneous networks or bipartite networks, such as personalized PageRank (P-PageRank) <ref type="bibr" target="#b9">[10]</ref>, SimRank <ref type="bibr" target="#b7">[8]</ref> and SCAN <ref type="bibr" target="#b19">[20]</ref>. However, these similarity measures are disregarding the subtlety of different types among objects and links. Adoption of such measures to heterogeneous networks has significant drawbacks: Objects of different types and links carry different semantic meanings, and it does not make sense to mix them to measure the similarity without distinguishing their semantics. To distinguish the semantics among paths connecting two objects, we introduce a meta path-based similarity framework for objects of the same type in a heterogeneous network. A meta path is a sequence of relations between object types, which defines a new composite relation between its starting type and ending type. Consider a bibliographic network extracted from DBLP with four types of objects, namely, authors (A), papers (P), terms (T), and venues (C). <ref type="table" target="#tab_0">Table 1</ref> shows the top-4 most similar venues for a given venue, DASFAA, based on (a) the common authors shared by two venues, or (b) the common topics (i.e., terms) shared by two venues. These two scenarios are represented by two distinct meta paths: (a) CP AP C, denoting that the similarity is defined by the meta path "venue-paper-author-paper-venue", whereas (b) CP T P C, by the meta path "venue-paper-topic-paper-venue". A user can choose either (a) or (b) or their combination based on the preferred similarity semantics. According to <ref type="bibr">Path (a)</ref>, DASFAA is closer to DEXA, WAIM, and APWeb, i.e., those that share many common authors, whereas according to <ref type="bibr">Path (b)</ref>, it is closer to Data Knowl. Eng., ACM Trans. DB Syst., and Inf. Syst., i.e., those that address many common topics. The meta path framework provides a powerful mechanism for a user to select an appropriate similarity semantics, by choosing a proper meta path, or learn it from a set of training examples of similar objects.</p><p>Under the proposed meta path-based similarity framework, there are multiple ways to define a similarity measure between two objects, based on concrete paths following a given meta path. One may adopt some existing similarity measures, such as (1) random walk used in P-PageRank, (2) pairwise random walk used in SimRank, or directly apply (3) P-PageRank and (4) SimRank on the extracted sub-network. However, these measures are biased to either highly visible objects (i.e., objects associated with a large number of paths) or highly concentrated objects (i.e., objects with a large percentage of paths going to a small set of objects). We propose a new similarity measure PathSim, which is able to capture the subtle semantics of similarity among peer objects in a network. In comparison, given a query object, PathSim can identify objects that not only are strongly connected but also share similar visibility in the network given the meta path. <ref type="table" target="#tab_1">Table 2</ref> presents in three measures the results of finding top-5 similar authors for "Anhai Doan", who is a well-established young researcher in the database field, under the meta path AP CP A (based on their shared venues), in the database and information system (DBIS) area. P-PageRank returns the most similar authors as those published substantially in the area, i.e., highly ranked authors; SimRank returns a set of authors that are concentrated on a small number of venues shared with Doan; whereas PathSim returns Patel, Deshpande, Yang and Miller, who share very similar publication records and are also rising stars in the database field as Doan. Obviously, PathSim captures desired semantic similarity as peers in such networks. Compared with P-PageRank and SimRank, the calculation for PathSim is much more efficient, as it is a local graph measure. But it still involves expensive matrix multiplication operations for top-k search functions, as we need to calculate the similarity between the query and every object of the same type in the network. In order to support fast online query processing for large-scale networks, we propose a methodology that partially materializes short length meta paths and then online concatenates them to derive longer meta path-based similarity. First, a baseline method (PathSim-baseline) is proposed, which computes the similarity between query object x and all the candidate objects y of the same type. Next, a coclustering based pruning method (PathSim-pruning) is proposed, which prunes candidate objects that are not promising according to their similarity upper bounds.</p><p>The contributions of this paper are summarized as below.</p><p>1. It investigates similarity search in heterogeneous information networks, a new but increasingly important issue due to the proliferation of linked data and their broad applications. 2. It proposes a new framework of meta path-based similarity and a new definition of similarity measure, PathSim, that captures the subtle similarity semantics among peer objects in networks. 3. Computing PathSim is more efficient than computing PPageRank and SimRank due to the usage of limited meta paths. Moreover, we provide an efficient co-clustering-based computation framework for fast query processing in large information networks. 4. Our experiments demonstrate the effectiveness of meta pathbased similarity framework and the PathSim measure, in comparison with random walk-based measures, and the efficiency of PathSim search algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">PROBLEM DEFINITION</head><p>In this section, we introduce a meta path-based similarity framework, a novel similarity measure under this framework, PathSim, and propose a PathSim-based top-k similarity search problem in information networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Heterogeneous Information Network</head><p>A heterogeneous information network is a special type of information network with the underneath data structure as a directed graph, which either contains multiple types of objects or multiple types of links. DEFINITION 1. Information Network. An information network is defined as a directed graph G = (V, E) with an object type mapping function φ : V → A and a link type mapping function ψ : E → R, where each object v ∈ V belongs to one particular object type φ(v) ∈ A, and each link e ∈ E belongs to a particular relation ψ(e) ∈ R.</p><p>Different from the traditional network definition, we explicitly distinguish object types and relationship types in the network. Notice that, if a relation exists from type A to type B, denoted as A R B, the inverse relation R −1 holds naturally for B R −1 A. For most of the times, R and its inverse R −1 are not equal, unless the two types are the same and R is symmetric. When the types of objects |A| &gt; 1 or the types of relations |R| &gt; 1, the network is called heterogeneous information network; otherwise, it is a homogeneous information network. EXAMPLE 1. A bibliographic information network is a typical heterogeneous network, containing objects from four types of entities: papers (P), venues (i.e., conferences/journals) (C), authors (A), and terms (T). For each paper p ∈ P , it has links to a set of authors, a venue, a set of words as terms in the title, a set of citing papers, and a set of cited papers, and the link types are defined by these relations.</p><p>Given a complex heterogeneous information network, it is necessary to provide its meta level (i.e., schema-level) description for better understanding. Therefore, we propose the concept of network schema to describe the meta structure of a network. DEFINITION 2. Network schema. The network schema is a meta template for a heterogeneous network G = (V, E) with the object type mapping φ : V → A and the link mapping ψ : E → R, which is a directed graph defined over object types A, with edges as relations from R, denoted as TG = (A, R).</p><p>The concept of network schema is similar to that of the ER (Entity-Relationship) model in database systems, but only captures the entity type and their binary relations, without considering the attributes for each entity type. Network schema serves as a template for a network, and tells how many types of objects there are in the network and where the possible links exist. Notice that although a relational database can often be transformed into an information network, the latter is much more general and can handle more unstructured and non-normalized data and links, and is also easier to deal with graph operations such as calculating the number of paths between two objects. EXAMPLE 2. Bibliographic network schema. For a bibliographic network defined in Example 1, the network schema is shown in <ref type="figure" target="#fig_1">Fig. 1(a)</ref>. Links exist between authors and papers denoting the writing or written-by relations, between venues and papers denoting the publishing or published-in relations, between papers and terms denoting using or used-by relations, and between papers, denoting citing or cited-by relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Meta Path-based Similarity Framework</head><p>In a heterogeneous network, two objects can be connected via different paths. For example, two authors can be connected via "author-paper-author" path, "author-paper-venue-paperauthor" path, and so on. Intuitively, the semantics underneath different paths imply different similarities. Formally, these paths are called meta paths, defined as follows.</p><p>DEFINITION 3. Meta path. A meta path P is a path defined on the graph of network schema TG = (A, R), and is denoted in the form of A1</p><formula xml:id="formula_0">R 1 −→ A2 R 2 −→ . . . R l −→ A l+1 , which defines a composite relation R = R1 • R2 • . . .</formula><p>• R l between type A1 and A l+1 , where • denotes the composition operator on relations.</p><p>The length of P is the number of relations in P. Further, we say a meta path is symmetric if the relation R defined by it is symmetric. For simplicity, we also use type names denoting the meta path if there exist no multiple relations between the same pair of types: P = (A1A2 . . . A l+1 ). For example, in the DBLP network, the co-author relation can be described using the length-2 meta path A writing −→ P written-by −→ A, or short as AP A if there is no ambiguity. We say a path p = (a1a2 . . . a l+1 ) between a1 and a l+1 in network G follows the meta path P, if ∀i, φ(ai) = Ai and each link ei = 񮽙aiai+1񮽙 belongs to each relation Ri in P. We call these paths as path instances of P, which are denoted as p ∈ P. A meta path P ′ is the reverse meta path of P, if P ′ is the reverse path of P in TG, which is denoted as P −1 and defines an inverse relation of the one defined by P. Similarly, we define the reverse path instance of p as the reverse path of p in G, which is denoted as p −1 . Two meta paths P1 = (A1A2 . . . A l ) and P2 = (A ′ 1 A ′ 2 . . . A ′ k ) are concatenable if and only if A l = A ′ 1 , and the concatenated path is written as P = (P1P2), which equals to (A1A2 . . . A l A ′ 2 . . . A ′ k ). A simple example of concatenation is: AP and P A can be concatenated to the meta path AP A, which defines the co-author relation.</p><p>Analogously, a meta path in an information network corresponds to a feature in a traditional data set. Given a user-specified meta path, say P = (A1A2 . . . A l ), several similarity measures can be defined for a pair of objects x ∈ A1 and y ∈ A l , according to the path instances between them following the meta path. We list several straightforward measures:</p><p>• Path count: the number of path instances p between x and y following P: s(x, y) = |{p : p ∈ P}|.</p><p>• Random walk: s(x, y) is the probability of the random walk that starts form x and ends with y following meta path P, which is the sum of the probabilities of all the path instances p ∈ P starting with x and ending with y, denoted as P rob(p): s(x, y) = 񮽙 p∈P P rob(p).</p><p>• Pairwise random walk: for a meta path P that can be decomposed into two shorter meta paths with the same length P = (P1P2), s(x, y) is then the pairwise random walk probability starting from objects x and y and reaching the same middle object: s(x, y) = 񮽙 (p 1 p 2 )∈(P 1 P 2 ) P rob(p1)P rob(p −1 2 ), where P rob(p1) and P rob(p −1 2 ) are random walk probabilities of the two path instances.</p><p>In general, we can define a meta path-based similarity framework for the object x and object y as: s(x, y) = 񮽙 p∈P f (p), where f (p) is some measure defined on the path instance p between x and y. Notice that, for measures P-PageRank and SimRank defined on homogeneous networks, they are weighted combinations of random walk measure or pairwise random walk measure over different meta paths in homogeneous networks, in which the meta paths are in the form of the concatenation of one relation with different lengths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">PathSim: A Novel Similarity Measure</head><p>Although there have been several similarity measures as presented above, they are biased to either highly visible objects or highly concentrated object but cannot capture the semantics of peer similarity. For example, the path count and random walk-based similarity always favor objects with large degrees, and the pairwise random walk-based similarity favors concentrated objects that the majority of the links goes to a small portion of objects. However, in many scenarios, finding similar objects in networks is to find similar peers, such as finding similar authors based on their field and reputation, finding similar actors based on their movie style and productivity, and finding similar products based on its function and popularity.</p><p>This motivated us to propose a new, meta path-based similarity measure, called PathSim, that captures the subtlety of peer similarity. The intuition behind it is that two similar peer objects should not only be strongly connected, but also share comparable visibility. As the relation of peer should be symmetric, we then confine PathSim merely on the symmetric meta paths. It is easy to see that, round trip meta paths with the form of P = (P l P −1 l ) are always symmetric. DEFINITION 4. PathSim: A Meta path-based similarity measure. Given a symmetric meta path P, PathSim between two objects of the same type x and y is:</p><formula xml:id="formula_1">s(x, y) = 2 × |{px񮽙y : px񮽙y ∈ P}| |{px񮽙x : px񮽙x ∈ P}| + |{py񮽙y : py񮽙y ∈ P}|</formula><p>where px񮽙y is a path instance between x and y, px񮽙x is that between x and x, and py񮽙y is that between y and y.</p><p>This shows that given a meta path P, s(x, y) is defined in terms of two parts: (1) their connectivity defined by the number of paths between them following P; and (2) the balance of their visibility, where the visibility is defined as the number of path instances between themselves. Notice that we do count multiple occurrences of a path instance as the weight of the path instance, which is the product of weights of all the links in the path instance. To see how this new measure works, we compare PathSim with a set of measures using a toy example to find peer authors, using meta path ACA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EXAMPLE 3. Comparing a set of measures. Table 3(a) shows a toy example of adjacency matrix WAC between authors and venues in a network, denoting the number of papers published</head><p>by each author in each venue. The query is to find the peer authors for "Mike". As "Bob" has exactly the same publication records as "Mike", it is expected to be the most similar peer. PathSim generates similarity scores: s(M ike, Jim) = 2×(2×50+1×20) (2×2+1×1)+(50×50+20×20) = 0.0826, s(M ike, Bob) = 1, and so on; and the similarity scores derived by P-PageRank, SimRank, random walk (RW), and pairwise random walk (PRW) on the same meta path ACA, are also illustrated in  We now introduce the calculation of PathSim between any two objects of the same type given a certain meta path. DEFINITION 5. Commuting matrix. Given a network G = (V, E) and its network schema TG, a commuting matrix M for a meta path P = (A1A2 . . . A l ) is defined as M = WA 1 A 2 WA 2 A 3 . . . WA l−1 A l , where WA i A j is the adjacency matrix between type Ai and type Aj . M (i, j) represents the number of paths instances between object xi ∈ A1 and object yj ∈ A l under meta path P.</p><p>For example, commuting matrix M for the meta path P = (AP A) is a co-author matrix, with each element representing the number of co-authored papers for the pair of authors. Given a symmetric meta path P, PathSim between two objects xi and xj from the same type can be calculated as s(xi, xj) =</p><formula xml:id="formula_2">2M ij M ii +M jj</formula><p>, where M is the commuting matrix for the meta path P, Mii and Mjj are the visibility for xi and xj in the network given the meta path.</p><p>It is easy to see that the commuting matrix for the reverse meta path of P l , which is P −1 l , is the transpose of commuting matrix for P l . In this paper, we only consider the meta path in the round trip form of P = (P l P −1 l ), to guarantee its symmetry and therefore the symmetry of the PathSim measure. Notice that, if the meta path is length-2, the measure of PathSim is degenerated to a measure that compares the similarity of the neighbor sets of two objects, which is called Dice's coefficient <ref type="bibr" target="#b3">[4]</ref>. By viewing PathSim in the meta path-based similarity framework, f (p) = 2</p><formula xml:id="formula_3">w(a 1 ,a 2 )...w(a l−1 ,a l )</formula><p>M ii +M jj , for any path instance p starting from xi and ending with xj following the meta path, where w(ai, aj ) is the weight for the link 񮽙ai, aj 񮽙 defined in the adjacency matrix.</p><p>Some good properties of PathSim, such as symmetric, selfmaximum and balance of visibility, are shown in Theorem 1. For the balance property, we can see that the larger difference of the visibility of the two objects, the smaller upper bound for their PathSim similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>THEOREM 1. Properties of PathSim:</head><p>1. Symmetric: s(xi, xj) = s(xj, xi). 2. Self-maximum: s(xi, xj) ∈ [0, 1], and s(xi, xi) = 1. 3. Balance of Visibility:</p><formula xml:id="formula_4">s(xi, xj) ≤ 2 √ M ii /M jj + √ M jj /M ii .</formula><p>PROOF. See Proof in the Appendix.</p><p>Under the definition of PathSim, we formally define our top-k similarity search problem as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DEFINITION 6. Top-k similarity search under PathSim.</head><p>Given an information network G and the network schema TG, given a meta path P = (P l P −1 l ), where P l = (A1A2 . . . A l ), the top-k similarity search for an object xi ∈ A1 is to find sorted k objects in the same type A1, such that s(xi, xj ) ≥ s(xi, x ′ j ), for any x ′ j not in the returning list and xj in the returning list, where s(xi, xj) is defined as in Def. 4.</p><p>Although using meta path-based similarity we can define similarity between two objects given any round trip meta paths, the following theorem tells us a very long meta path is not very meaningful. Indeed, due to the sparsity of real networks, objects that are similar may share no immediate neighbors, and longer meta paths will propagate similarities to remote neighborhoods. For example, as in the DBLP example, if we consider the meta path AP A, only two authors that are co-authors have a non-zero similarity score; but if we consider longer meta paths like AP CP A or AP T P A, authors will be considered to be similar if they have published papers in a similar set of venues or sharing a similar set of terms no matter whether they have co-authored. But how far should we keep going? The following theorem tells us that a very long meta path may be misleading. We now use P k to denote a meta path repeating k times of the basic meta path pattern of P, e.g., (ACA) 2 = (ACACA).</p><p>THEOREM 2. Limiting behavior of PathSim under infinity length meta path. Let meta path P (k) = (P l P −1 l ) k , M P be the commuting matrix for meta path P l , and M (k) = (M P M T P ) k be the commuting matrix for P (k) , then by PathSim, the similarity between objects xi and xj as k → ∞ is:</p><formula xml:id="formula_5">lim k→∞ s (k) (i, j) = 2r(i)r(j) r(i)r(i) + r(j)r(j) = 2 r(i) r(j) + r(j) r(i)</formula><p>where r is the primary eigenvector of M , and r(i) is the i th item. PROOF. See Proof in the Appendix.</p><p>As primary eigenvectors can be used as authority ranking of objects <ref type="bibr" target="#b15">[16]</ref>, the similarity between two objects under an infinite meta path can be viewed as a measure defined on their rankings (r(i) is the ranking score for object xi). Two objects with more similar ranking scores will have higher similarity (e.g., SIGMOD will be similar to AAAI). Later experiments ( <ref type="table" target="#tab_8">Table 8</ref>) <ref type="bibr">will</ref> show that this similarity, with the meaning of global ranking, is not that useful. Notice that, the convergence of PathSim with respect to path length is usually very fast and the length of 10 for networks of the scale of DBLP can almost achieve the effect of a meta path with an infinite length. Therefore, in this paper, we only aim at solving the top-k similarity search problem for a relatively short meta path.</p><p>Even for a relatively short length, it may still be inefficient in both time and space to materialize all the meta paths. Thus we propose in Section 3 materializing commuting matrices for short length meta paths, and concatenating them online to get longer ones for a given query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">ONLINE QUERY PROCESSING FOR SINGLE META PATH</head><p>This section is on efficient top-k PathSim similarity search for online queries, under a single meta path, with two algorithms proposed: PathSim-baseline and PathSim-pruning, both returning exact top-k results for the given query. The algorithm for multiple meta path combination with different weights is discussed in Appendix B. Note that the same methodology can be adopted by other meta path-based similarity measures, such as RW and PRW, by taking a different definition of commuting matrix accordingly.</p><p>While the definition of meta path-based similarity search is flexible to accommodate different queries, it requires expensive computations (matrix multiplications), which is not affordable for online query processing in large-scale information networks. One possible solution is to materialize all the meta paths within a given length. Unfortunately, it is time and space expensive to materialize all the possible meta paths. For example, in the DBLP network, the similarity matrix corresponding to a length-4 meta path, AP CP A, for identifying similar authors publishing in common venues is a 710K × 710K matrix, whose non-empty elements reaches 5G, and requires storage size more than 40G (up to 4T for longer meta path between authors). Thus we propose the solution to partially materialize commuting matrices for short length meta paths, and concatenate them online to get longer ones for a given query, which returns search results in a reasonable response time while reduces the storage space significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Single Meta Path Concatenation</head><p>Given a meta path P = (</p><formula xml:id="formula_6">P l P −1 l ), where P l = (A1 · · · A l ), the commuting matrix for path P l is M P = WA 1 A 2 WA 2 A 3 · · · WA l−1 A l , the commuting matrix for path P is M = M P M T P .</formula><p>Let n be the number of objects in A1. For a query object xi ∈ A1, if we compute the top-k most similar objects xj ∈ A1 for xi on-the-fly, without materializing any intermediate results, computing M from scratch would be very expensive. On the other hand, if we have pre-computed and stored the commuting matrix M = M P M T P , it would be a trivial problem to get the query results: We only need to locate the corresponding row in the matrix for the query xi, re-scale it using (Mii+Mjj)/2, and finally sort the new vector and return the top-k objects. However, fully materializing the commuting matrices for all possible meta paths is also impractical, since the space complexity (O(n 2 )) would prevent us from storing M for every meta path. Instead of taking the above extreme, we partially materialize commuting matrix M T P for meta path P −1 l , and compute top-k results online by concatenating P l and P −1 l into P without full matrix multiplication. We then examine the concatenation problem, i.e., if the commuting matrix M for the full meta path P is not pre-computed and stored, but the commuting matrix M T P corresponding to the partial meta path P −1 l has been pre-computed and stored. In this case, we assume the main diagonal of M , i.e., D = (M11, . . . , Mnn), is pre-computed and stored. Since for Mii = M P (i, :)M P (i, :) T , the calculation only involves M P (i, :) itself, and only O(nd) in time and O(n) in space are required, where d is the average number of non-zero elements in each row of M P for each object. As the commuting matrices of P l and P −1 l are transpose to each other, we only need to store one of them in the sparse form. But from the efficiency point of view, we will keep both row index and column index for fast locating any rows and columns. In this study, we only consider concatenating the partial paths P l and P −1 l into the form P = P l P −1 l or P = P −1 l P l . For example, given a prestored meta path AP C, we are able to answer queries for meta paths AP CP A and CP AP C. For our DBLP network, to store commuting matrix for partial meta path AP C only needs around 25M space, which is less than 0.1% of the space for materializing meta path AP CP A. Other concatenation forms that may lead to different optimization methods are also possible (e.g., concatenating several short meta paths). In the following discussion, we focus on the algorithms using the concatenation form P = P l P −1 l .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Baseline</head><p>Suppose we know the commuting matrix M P for path P l , and the diagonal vector D = (Mii) n i=1 , in order to get top-k objects xj ∈ A1 with the highest similarity for the query xi, we need to compute s(i, j) for all xj. The straightforward baseline is: (1) first apply vector-matrix multiplication to get</p><formula xml:id="formula_7">M (i, :) = M P (i, :)M T P ; (2) calculate s(i, j) = 2M (i,j) M (i,i)+M (j,j)</formula><p>for all xj ∈ A1; and (3) sort s(i, j) to return the top-k list in the final step. When n is very large, the vector-matrix computation will be too time consuming to check every possible object xj. Therefore, we first select xj 's that are not orthogonal to xi in the vector form, by following the links from xi to find 2-step neighbors in commuting matrix M P , i.e.,</p><formula xml:id="formula_8">xj ∈ CandidateSet = { 񮽙 y k ∈M P .neighbors(x i ) M T P .neighbors(y k )},<label>where</label></formula><p>M P .neighbors(xi)= {y k |M P (xi, y k ) 񮽙 = 0}, which can be easily obtained in the sparse matrix form of M P that indexes both rows and columns. This will be much more efficient than pairwise comparison between the query and all the objects of that type. We call this baseline concatenation algorithm as PathSim-baseline (See Algorithm 2). The PathSim-baseline algorithm, however, is still time consuming if the candidate set is very large. Although M P can be relatively sparse given a short length meta path, after concatenation, M could be dense, i.e., the CandidateSet could be very large. Still, considering the query object and one candidate object represented by query vector and candidate vector, the dot product between them is proportional to the size of their non-zero elements. The time complexity for computing each candidate is O(d) on average and O(m) in the worst case, that is, O(nm) in the worst case for all the candidates, where n is the row size of M P , i.e., the number of objects in type A1, and m the column size of M P , i.e., the number of objects in type A l , and d the average non-zero element for each object in M P . We now propose a co-clustering based topk concatenation algorithm, by which non-promising target objects are dynamically filtered out to reduce the search space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Co-Clustering Based Pruning</head><p>In the baseline algorithm, the computational costs involve two factors. First, the more candidates to check, the more time the algorithm will take; second, for each candidate, the dot product of query vector and candidate vector will at most involve m operations, where m is the vector length. The intuition to speed up the search is to prune unpromising candidate objects using simpler calculations. Based on the intuition, we propose a co-clustering (i.e., clustering rows and columns of a matrix simultaneously) based path concatenation method, which first generates co-clusters of two types of objects for partial commuting matrix, then stores necessary statistics for each of the blocks corresponding to different cocluster pairs, and then uses the block statistics to prune the search space. For better illustration, we call clusters of type A1 as target clusters, since the objects in A1 are the targets for the query; and call clusters of type A l as feature clusters, since the objects in A l serve as features to calculate the similarity between the query and the target objects. By partitioning A1 into different target clus- ters, if a whole target cluster is not similar to the query, then all the objects in the target cluster are likely not in the final top-k lists and can be pruned. By partitioning A l into different feature clusters, cheaper calculations on the dimension-reduced query vector and candidate vectors can be used to derive the similarity upper bounds. This pruning idea is illustrated in <ref type="figure" target="#fig_2">Fig. 2</ref> as follows. Given the partial commuting matrix M T l and its 3 × 3 co-clusters, and the query vector M l (xi, :) for query object xi, first the query vector is compressed into the aggregated query vector with the length of 3, and the upper bounds of the similarity between the query and all the 3 target clusters are calculated based on the aggregated query vector and aggregated cluster vectors; second, for each of the target clusters, if they cannot be pruned, calculate the upper bound of the similarity between the query and each of the 3 candidates within the cluster using aggregated vectors; third, if the candidates cannot be pruned, calculate the exact similarity using the non-aggregated query vector and candidate vectors.</p><p>The details of the co-clustering algorithm and the co-clustering based pruning algorithm, PathSim-pruning are introduced in Appendix A. Experiments show that PathSim-Pruning can significantly improve the query processing speed comparing with the baseline algorithm, without affecting the search quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTS</head><p>For the experiments, we use the bibliographic network extracted from DBLP and the Flickr network to show the effectiveness of the PathSim measure and the efficiency (Appendix A.1) of the proposed algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Sets</head><p>We use the DBLP dataset downloaded in Nov. 2009 as the main test dataset. It contains over 710K authors, 1.2M papers, and 5K venues (conferences/journals). After removing stopwords in paper titles, we get around 70K terms appearing more than once. Our DBLP networks are built according to the network schema introduced in Example 2, except that there is no direct link between papers since DBLP provides very limited citation information. This dataset is referred as "full DBLP dataset". Two small subsets of the data (to alleviate the high computational costs of P-PageRank and SimRank) are used for the comparison with other similarity measures in effectiveness: (1) "DBIS dataset", which contains all the 464 venues and top-5000 authors from the database and information system area; and (2) "4-area dataset", which contains 20 venues and top-5000 authors from 4 areas: database, data mining, machine learning and information retrieval <ref type="bibr" target="#b16">[17]</ref>, and cluster labels are given for all the 20 venues and a subset of 1713 authors.</p><p>For additional case studies (See Appendix C), we construct a Flickr network from a subset of the Flickr data, which contains four types of objects: images, users, tags, and groups. Links exist between images and users, images and tags, and images and groups. We use 10,000 images from 20 groups as well as their related 664 users and 10284 tags appearing more than once to construct the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Effectiveness</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Comparing PathSim with other measures</head><p>When a meta path P = (P l P l −1 ) is given, other measures such as random walk (RW) and pairwise random walk (PRW) can be applied on the same meta path, and P-PageRank and SimRank can be applied on the sub-network extracted from P. For example, for the meta path CP AP C (CAC in short) for finding venues sharing the same set of authors, the bipartite graph MCA, derived from commuting matrix corresponding to CP A can be used in both PPageRank and SimRank algorithms. In our experiments, the damping factor for P-PageRank is set as 0.9 and the one for SimRank is set as 0.8.</p><p>First, a case study is shown in <ref type="table" target="#tab_4">Table 4</ref>, which is applied on "DBIS dataset", under the meta path CAC. One can see that for query "PKDD" (short for "Principles and Practice of Knowledge Discovery in Databases", a European data mining conference), PPageRank favors venues with higher visibility, such as KDD and several well-known venues; SimRank prefers concentrated venues (i.e., a large portion of publications goes to a small set of authors) and returns many not well-known venues such as "Local Pattern Detection" and KDID; RW also favors highly visible objects such as KDD, but brings in fewer irrelevant venues due to that it utilizes merely one short meta path; PRW performs similar to SimRank, but brings in more not so well-known venues due to the short meta path it uses; whereas PathSim gives venues with similar area as well as similar reputation as PKDD, such as ICDM and SDM.</p><p>We then labeled top-15 results for 15 queries from venue type (SIGMOD, VLDB, ICDE, PODS, EDBT, DASFAA, KDD, ICDM, PKDD, SDM, PAKDD, WWW, SIGIR, TREC and APWeb) in "DBIS dataset", to test the quality of the ranking lists given by 5 measures. We label each result object with relevance score as three levels: 0-non-relevant, 1-some-relevant, and 2-veryrelevant. Then we use the measure nDCG (Normalized Discounted Cumulative Gain, with the value between 0 and 1, the higher the better) <ref type="bibr" target="#b8">[9]</ref> to evaluate the quality of a ranking algorithm by comparing its output ranking results with the labeled ones ( <ref type="table" target="#tab_5">Table 5</ref>). The results show that PathSim gives the best ranking quality in terms of human intuition, which is consistent with the previous case study.</p><p>Next, we study the performance of different single meta pathbased similarity measures, including PathSim, RW, and PRW, in the task of clustering, where these measures use exactly the same information to determine the pairwise similarity between objects. Note the clustering problem is rather different from node-oriented similarity search but can still be used to roughly compare the sensitivity of the similarity measures. We use "4-area dataset" to evaluate the clustering performance, since this dataset naturally has 4 clusters, under the meta path CAC for venues and ACA for authors. We apply Normalized Cut <ref type="bibr" target="#b14">[15]</ref> to the 3 similarity matrices, and use NMI (Normalized Mutual Information, with the value between 0 and 1, the higher the better) <ref type="bibr" target="#b15">[16]</ref> to calculate the clustering accuracy for both venues and authors, and their weighted average accuracy over the two types. The average clustering accuracy results (based on 100 runs) for the venues-author network with different similarity measures are summarized in <ref type="table" target="#tab_6">Table 6</ref>. It turns out that PathSim produces overall better performance in terms of weighted average of clustering accuracy in both types.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Semantic meanings of different meta paths</head><p>As we pointed out, different meta paths give different semantic meanings, which is one of the reasons that similarity definitions in homogeneous networks cannot be applied directly to heterogeneous networks. Besides the motivating example in the introduction section, <ref type="table" target="#tab_7">Table 7</ref> shows the author similarity under two scenarios for author Christos Faloutsos: co-authoring papers and publishing papers in the same venues, represented by the meta paths AP A and AP CP A respectively. One can see that the first path returns co-authors who have strongest connections with Faloutsos (e.g., students and close collaborators) in DBLP, whereas AP CP A returns those publishing papers in the most similar venues. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The impact of path length</head><p>The next interesting question is how the length of meta path impacts the similarity definition. <ref type="table" target="#tab_8">Table 8</ref> shows an example of venues similar to "SIGMOD" with three meta paths, using exactly the same basic meta path, but with different repeating times. These meta paths are (CP AP C) 2 , (CP AP C) <ref type="bibr" target="#b3">4</ref> and its infinity form (global ranking-based similarity). Notice that in (CP AP C) 2 , two venues are similar if they share many similar authors who publish papers in the same venues; while in (CP AP C) 4 , the similarity definition of those venues will be further relaxed, namely, two venues are similar if they share many similar authors who publish papers in similar venues. Since venue type only contains 5K venues, we are able to get the full materialization commuting matrix for (CP AP C) 2 . (CP AP C) 4 is obtained using meta path concatenation from (CP AP C) 2 . The results are summarized in <ref type="table" target="#tab_8">Table 8</ref>, where longer path gradually bring in more remote neighbors, with higher similarity score, and finally it degenerates into global ranking comparison. Through this study, we can see that the meta path with relatively short length is good enough to measure similarity, and a long meta path may even reduce the quality. <ref type="table" target="#tab_9">Table 9</ref> shows that short meta paths produce better similarity measures in terms of clustering accuracy. We checked two other meta paths, namely CP T P C and AP T P A, which give the same conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">RELATED WORK</head><p>Similarity measure has been widely studied in categorical, numerical, or mix-type data sets, such as cosine similarity defined on two vectors, Jaccard coefficient on two sets, and Euclidean distance on two numerical data points. Based on the traditional similarity measures, a recent study <ref type="bibr" target="#b18">[19]</ref> proposes an efficient top-k similarity pair search algorithm, top-k-join, in relational database, which only considers similarity between tuples. Also widely studied are k nearest neighbor search in spatial data <ref type="bibr" target="#b10">[11]</ref> and other high dimensional data <ref type="bibr" target="#b1">[2]</ref>, which aims at finding top-k nearest neighbors according to similarities defined on numerical features. However, these similarity definitions cannot be applied to networks.</p><p>Similarity measures defined on homogeneous networks emerged recently. Personalized PageRank <ref type="bibr" target="#b9">[10]</ref> is an asymmetrical similarity measure that evaluates the probability starting from object x to visit object y by randomly walking on the network with restart. More discussions on how to scale the calculation for online queries are in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b17">18]</ref>, etc., and how to derive top-k answers efficiently is studied in <ref type="bibr" target="#b6">[7]</ref>. SimRank <ref type="bibr" target="#b7">[8]</ref> is a symmetric similarity measure defined on homogeneous networks, which can also be directly applied to bipartite networks. The intuition behind SimRank is propagating pairwise similarity to their neighboring pairs. Due to its computational complexity, there are many follow-up studies (e.g., <ref type="bibr" target="#b11">[12]</ref>) on speeding up such calculations. SCAN <ref type="bibr" target="#b19">[20]</ref> measures similarity of two objects by comparing their immediate neighbor sets.</p><p>ObjectRank <ref type="bibr" target="#b0">[1]</ref> and PopRank <ref type="bibr" target="#b12">[13]</ref> first noticed that heterogeneous relationships could affect the random walk, and assigned different propagation factors to each type of object relationship to either derive a revised version of P-PageRank (ObjectRank) or a global PageRank (PopRank). However, such solutions only give one particular combination of all the possible meta paths using the fixed weights determined by the damping factor and propagation factors between different types. In our PathSim definition, users can freely specify the meta paths they are interested in and assign any weight to them. Random walk style similarity search is not adopted in PathSim, which overcomes the disadvantage of returning highly ranked objects rather than similar peers.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">DISCUSSIONS</head><p>In this study, we assume that users know how to choose meta path. In practice, there are several ways for a user to select the best meta path or meta path combinations. First, a user can make a choice based on her interest and domain knowledge. Second, she can have several experimental trials, such as those done in Section 4, and choose the best one according to her intuition. Third, she can label a small portion of data according to specific applications. For example, one can label similar objects or rank them, and then train the best meta path(s) and their weights by some learning algorithms. By doing so, one can automatically choose appropriate meta paths as well as the associated weights, and make the similarity search adaptable to different application scenarios. The problem on how to choose and weight different meta paths is similar to the feature selection process in machine learning. In-depth study for a systematic solution is left as a future research task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSIONS</head><p>We have introduced a novel and practical notion of meta pathbased similarity for heterogeneous information networks. We comparatively and systematically examine different semantics of similarity measures in such networks and introduce a new meta pathbased similarity measure to find similar objects of the same type in such networks. Meta paths give users flexibility to choose different meta paths and their combinations based on their applications. Moreover, we propose a new similarity measure, PathSim, under this framework, which produces overall better similarity qualities than the existing measures. Since meta paths can be arbitrarily given, it is unrealistic to fully materialize all the possible similarity results given different meta paths and their combinations. However, online calculation requires matrix multiplication, which is time consuming especially when the vector and matrix are not sparse. Therefore, we proposed an efficient solution that partially materializes several short meta paths and then applies online concatenation and combination among paths to give the top-k results for a query. Experiments on real data sets show the effectiveness of the similarity measure and the efficiency of our method. The framework of meta path-based similarity search in networks can be enhanced in many ways, e.g., weight learning for different meta paths, which may help provide accurate similarity measures in real systems and discover interesting relationships among objects. 1: //Initialization. 2: Randomly assign row objects into {Ru} U u=1 ;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Greedy Co-Clustering Algorithm</head><p>3: Randomly assign column objects into {Cv} V v=1 ;</p><p>4: repeat 5: //get center vector of each Ru:</p><formula xml:id="formula_9">6: f (Ru) = 1 |Ru| 񮽙 V v=1 M T P (Ru, Cv);</formula><p>7: //Adjust row objects 8: foreach object x i in row objects do 9:</p><formula xml:id="formula_10">f (x i ) = 񮽙 V v=1 M T P (x i , Cv );</formula><p>10:</p><formula xml:id="formula_11">assign x i into Ru, u = arg min k KL(f (x i )||f (Ru));</formula><p>11: end for 12: //get center vector of each Cv:</p><formula xml:id="formula_12">13: f (Cv ) = 1 |Cv | 񮽙 U u=1 M T P (Ru, Cv)</formula><p>14: //Adjust column objects 15: foreach object y j in row objects do 16:</p><formula xml:id="formula_13">f (y j ) = 񮽙 U u=1 M P (Ru, y j );</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>17:</head><p>assign y j into Cv , v = arg min l KL(f (y j )||f (Cv ));</p><p>18: end for 19: until {Ru}, {Cv } do not change significantly.</p><p>Once the clusters for each type of objects are obtained, the commuting matrix can be decomposed into disjoint blocks. To facilitate further concatenation on two meta paths for queries, necessary statistical information is stored for each block. For each block b denoted by row cluster Ru and column cluster Cv, we store:</p><p>1. Element sum of each block T {U ×V } :</p><formula xml:id="formula_14">tuv = 񮽙 i∈Ru 񮽙 j∈Cv M T P (i, j);</formula><p>2. Sum of row vectors (1-norm of each column vector) of each block T {U ×m} 1</p><p>:</p><formula xml:id="formula_15">t uv,1 (j) = 񮽙 i∈Ru M T P (i, j), for j ∈ Cv;</formula><p>3. Square root of sum of square of row vectors (2-norm of each column vector) of each block T T {U ×m} 1</p><p>:</p><formula xml:id="formula_16">t 2 uv,1 (j) = 񮽙 񮽙 i∈Ru (M T P (i, j)) 2 , for j ∈ Cv;</formula><p>4. Sum of column vectors (1-norm of each row vector) of each block</p><formula xml:id="formula_17">T {n×V } 2 : t uv,2 (i) = 񮽙 j∈Cv M T P (i, j), for i ∈ Ru;</formula><p>5. Square root of sum of square of column vectors (2-norm of each row vector) of each block T T {n×V } 2</p><p>:</p><formula xml:id="formula_18">t 2 uv,2 (i) = 񮽙 񮽙 j∈Cv (M T P (i, j)) 2 , for i ∈ Ru.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Pruning Strategy in Path Concatenation</head><p>Now let's focus on how we can get top-k results efficiently for a query given the materialized block-wise commuting matrix. The intuition is that we first check the most promising target cluster, then if possible, prune the whole target cluster; if not, we first use simple calculations to decide whether we need to further calculate the similarity between the query and the candidate object, then compute the exact similarity value using more complex operations only for those needed. THEOREM 3. Bounds for block-based similarity measure approximation. Given a query object x, the query vector is x = M P (x, :). Let D be the diagonal vector of M , letˆx1letˆ letˆx1 be the compressed query vector given feature clusters {Ru} U u=1 , wherêwherê x1(u) = maxj∈R u {x(j)}, and letˆx2letˆ letˆx2 be the 2-norm query vector given feature clusters Ru, wherê x2(u) = 񮽙 񮽙 j∈Ru x(j) 2 , the similarity between x and target cluster Cv, and the similarity between x and candidate y ∈ Cv can be estimated using the following upper bounds:</p><formula xml:id="formula_19">1. upperbound 1: ∀y ∈ Cv , s(x, y) ≤ s(x, Cv) = 񮽙 y∈Cv s(x, y) ≤ 2ˆx2ˆx T 1 T (:,v) D(x)+1 ; 2. upperbound 2: ∀y ∈ Cv, s(x, y) ≤ 2ˆx2ˆx T 2 T T 1 (:,y) D(x)+D(y) .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PROOF. See Proof in the Appendix D.</head><p>In Theorem 3, the upper bound for s(x, Cv) can be used to find the most promising target clusters as well as to prune target clusters if it is smaller than the lowest similarity in the current top-k results. The upper bound for s(x, y) can be used to prune target objects that are not promising, which only needs at most U times calculation, whereas the exact calculation needs at most m times calculation. Here, U is the number of feature clusters and m is the number of feature objects, i.e., objects of type A l .</p><p>The search strategy is to first sort the target clusters according to their upper bound of the similarity between the query x and the cluster Cv, i.e., s(x, Cv), in a decreasing order. The higher the similarity the more likely this cluster contains more similar objects to x. It is very critical to use the order to check the most promising target clusters first, by which the most desirable objects are retrieved at an early stage and the upper bounds then have stronger power to prune the remaining candidates. When a new target cluster needs to be checked, the upper bound can be used to prune the whole target cluster and all the remaining target clusters, if it is smaller than the k-th value of the current top-k list. Next, when going to check the candidates within the target cluster, the upper bound between query object x and candidate y can be used to prune non-promising candidates if it is smaller than the current threshold. The algorithm PathSim-pruning is summarized in Algorithm 3. On Line 5, min(S) is the lowest similarity in the current top-k result set S. Similar to PathSim-baseline (Algorithm 2), before the pruning steps, we still need to first derive the candidate set. Compared with the baseline algorithm, the pruning-based algorithm at most checks the same number of candidates with the overhead to calculate the upper bounds. In practice, a great number of candidates can be pruned, and therefore the performance can be enhanced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 (PathSim-Baseline) Vector-Matrix Multiplication Based Path Concatenation</head><p>Input:</p><formula xml:id="formula_20">Query x i , Commuting Matrix M P , Diagonal Vector D, top-k K Output: Top-k List SortList 1: CandidateSet = ∅; 2: foreach y k ∈ M P .neighbors(x i ) do 3: foreach x j ∈ M T P</formula><p>.neighbors(y k ) do 4:</p><formula xml:id="formula_21">CandidateSet = CandidateSet ∪ {x j };</formula><p>5: end for 6: end for 7:   </p><formula xml:id="formula_22">List = ∅; 8: foreach x j ∈ CandidateSet do 9: value = 2 * M P (i, :)M P (j, :) T /(D(i) + D(j))</formula><formula xml:id="formula_23">s(x i , x j ) = 2M P (x i ,:)(M P (x j ,:)) T D(x i )+D(</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Efficiency Comparison</head><p>The time complexity for SimRank is O <ref type="figure" target="#fig_2">(KN 2 d 2 )</ref>, where K is the number of iterations, N is the total number of objects, and d is the average neighbor size; the time complexity for calculating PPageRank for one query is O <ref type="figure">(KN d)</ref>, where K, N, d has the same meaning as in SimRank; whereas the time complexity for PathSim using P athSim-baseline for single query is O(nd), where n &lt; N is the number of objects in the target type, d is the average degree of objects in target type for partial commuting matrix M P l . The time complexity for RW and PRW are the same as PathSim. We can see that similarity measure only using one meta path is much more efficient than those also using longer meta paths in the network (e.g., SimRank and P-PageRank).</p><p>In this sub-section, two algorithms proposed in Section 3, i.e., PathSim-baseline and PathSim-pruning, are compared, for efficiency study under different meta paths, namely, CP AP C, (CP AP C) 2 and AP CP A (denoted as CAC, CACAC and ACA for short). For the co-clustering algorithm, the number of clusters for authors is set as 50, and that for conferences as 20. It is easy to see that the more clusters used, the more accurate the upper bounds would be, however the longer the calculation for the upper bounds would be. A trade-off should be made to decide the best number of clusters. Due to the limited space, we do not discuss the issue in this paper.</p><p>First, we check the impacts of the number of neighbors of the query on the execution time. Note, a query object with higher degree usually leads to larger number of neighbors. Therefore, two test query sets are selected based on their degrees to test the execution time for each meta path: one is of top-20 objects and the other is of 1001th-1020th objects according to their link degrees. We compare the performance of the two algorithms under three meta paths. Each query is executed 5 times and the output time is the total average execution time within each query set, and the results are summarized in <ref type="figure" target="#fig_4">Figure 3</ref>. From the results, one can see (1) PathSim-pruning is more efficient than PathSim-baseline; (2) the improvement rate depends on the meta path, the denser the corresponding commuting matrix, the higher rate PathSim-pruning can improve; and (3) the improvement rate also depends on the queries, the more neighbors of a query, the higher rate PathSim-pruning can improve. In <ref type="figure" target="#fig_6">Figure 4</ref>, we compare the efficiency under different top-k's (k = 5, 10, 20) for PathSim-pruning using query set 1. Intuitively, a smaller top-k has stronger pruning power, and thus needs less execution time, as demonstrated. Now we compare the pruning power of PathSim-pruning vs. PathSim-baseline by considering two factors: the size of the neighbors of a query <ref type="figure">(Fig. 5</ref>) and the density of the partial commuting matrix M P <ref type="figure">(Fig. 6</ref>). 500 queries are randomly chosen for two meta paths (CAC and CACAC), and the execution time is averaged with 10 runs. The results show that the execution time for PathSim-baseline is almost linear to the size of the candidate set, and the improvement rate for PathSim-pruning is larger for queries with more neighbors, which requires more calculation for exact dot product operation between a query vector and candidate vectors. Also, the denser that the commuting matrix corresponding to the partial meta path (MCP AP C in comparison with MCP A), the greater the pruning power. The improvement rates are 18.23% and 68.04% for the two meta paths. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. MULTIPLE META PATH COMBINA-TION</head><p>In Section 3, we presented algorithms for similarity search in single meta path. Now, we present a solution to combine multiple meta paths together. Formally, given r round trip meta paths from Type A back to Type A, P1, P2, . . . , Pr, and their corresponding commuting matrix M1, M2, . . . , Mr, with weights w1, w2, . . . , wr specified by users, the combined similarity between objects xi, xj ∈ A are defined as:</p><formula xml:id="formula_24">s comb (xi, xj) = 񮽙 r l=1 w l s l (xi, xj), where s l (xi, xj) = 2M l (i,j) M l (i,i)+M l (j,j)</formula><p>. EXAMPLE 4. Following the motivating example in the introduction section, <ref type="table" target="#tab_0">Table 10</ref> shows the results of combining two meta paths P1 = CP AP C and P2 = CP T P C with different weights specified by w1 and w2, for query "DASFAA".  The reason why we need to combine several meta paths is that, each meta path provides a unique angle (or a unique feature space) to view the similarity between objects, and the ground truth may be a cause of different factors. Some useful guidance of the weight assignment includes: longer path utilizes more remote relationships and thus should be assigned with a smaller weight, such as in PPageRank and SimRank; and, meta path with more important relationships should be assigned with a higher weight. For automatically determining the weights, users could provide training examples of similar objects to learn the weights of different meta paths using machine learning algorithms.</p><p>Since each meta path plays an independent role to decide the similarity, we can calculate top list for each of them and then combine the results together. The critical problem is how to determine if the remaining candidate objects are not going to appear in the final top-k list, and thus can be safely removed. The general idea for the search strategy is: (1) get top-k ′ objects for each meta path using single path top-k search algorithm, where k ′ should be larger than k (e.g., in a order of 2k, 4k, 8k, and so on); (2) check for each meta path, whether current top-k ′ objects can guarantee higher similarity than the remaining ones, if not, expanding the top-k ′ list by recalculating the single meta path top-k ′ list with a bigger k ′ (e.g., k ′ = 2k ′ ); (3) repeat (2) until all the candidates generated for each meta path can guarantee they are in the final list; and (4) get the exact similarity score for each candidate and return top-k of the candidates. One possible upper bound for remaining objects other than those in the current top-k lists can be calculated as</p><formula xml:id="formula_25">upper k = 񮽙 l w l * T opKList[l]</formula><p>.min, where T opKList <ref type="bibr">[l]</ref>.min stands for the lowest similarity score of Top-k for the l th meta path. The FA and TA methods <ref type="bibr" target="#b4">[5]</ref> could also be applied here, if the full ranking list is ready for each meta path using PathSim-baseline. We now study the accuracy of combined meta paths using the "fourarea dataset", evaluated by the clustering performance given the similarity matrix. First, two meta paths for the type conference, namely, CAC and CT C (short for CP AP C and CP T P C), are selected and their linear combinations with different weights are considered. Second, two meta paths with the same basic path but different lengths, namely ACA and (ACA) 2 , are selected and their linear combinations with different weights are considered. The clustering accuracy measured by NMI for conferences and authors is shown in <ref type="table" target="#tab_0">Table 11</ref>, which shows that the combination of multiple meta paths can produce better similarity than the single meta path in terms of clustering accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. CASE STUDY ON FLICKR NETWORK</head><p>In this case study, we show that one can merely use links in the network rather than any content information to retrieve similar images for a query image. Let "I" represent image, "T" tags that associated with each image, and "G" groups that each image belongs to. Two meta paths are used and compared. The first is IT I, which means common tags are used by two images at evaluation of their similarity. The results are shown in <ref type="figure" target="#fig_8">Fig. 7</ref>. The second meta path is IT IGIT I, which means tags similarities are further measured by their shared groups, and two images could be similar even they do not share many exact same tags as long as these tags are used by many images of the same groups. One can see that the second meta path gives better results than the first one as shown in <ref type="figure" target="#fig_9">Fig. 8</ref>, where the first image is the input query. This is likely due to that the latter meta path provides additional information related to image groups, and thus improves the similarity measure between images.  Discussion. The Flickr network is an interesting example that goes beyond the relational data. Our running example of bibliographic network can be viewed as a network constructed from relational data. So, naturally, it leads to two questions: (1) one may wonder whether the meta path-based top-k similarity search can be applied to relational databases. The answer to this question is "Yes", if we treat data from multiple relations as information networks. For example, to find the students most similar to a given student, one can view multiple relations as interconnected information networks and meta-paths to be selected can be based on the course taken, venues of the publications, advisors, or their weighted combinations. (2) One may also wonder whether the meta path-based similarity search can go far beyond the network formed based on relational data. This case study on the Flickr network shows that the analysis of heterogeneous information networks can go far beyond typical relational data since this network consists of links connecting photos with bags of terms and groups. There are many networks that cannot be constructed from relational data. For example, a news/blog network contains links among themes, categories, time, locations, authors, terms, pictures, and so on, beyond relational data. Similarity search in such networks can be readily handled under the framework presented in this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. PROOFS OF THEOREMS</head><p>Here are the proofs of the theorems introduced in the previous sections. (2) Let M l (i, :) = (a1, a2, . . . , ap), M l (j, :) = (b1, b2, . . . , bp), easy to see a k , b k are nonnegative for all 1 ≤ k ≤ p, then Mij = 񮽙 p k=1 a k b k ≥ 0, Mii = 񮽙 p k=1 a 2 k &gt; 0 (no dangling object), and Mjj = 񮽙 p k=1 b 2 k &gt; 0, therefore s(xi, xj) ≥ 0; also, 񮽙 p k=1 a 2 k + 񮽙 p k=1 b 2 k ≥ 2 񮽙 p k=1 a k b k , with equality holding when a k = b k for every k, therefore s(xi, xj) ≤ 1, and s(xi, xi) = 1. </p><formula xml:id="formula_26">(3) M ij = 񮽙 k a k b k ≤ 񮽙 񮽙 k a 2 k 񮽙 k b 2 k = 񮽙 M ii M</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. ACKNOWLEDGEMENT</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Proceedings of the VLDB Endowment, Vol. 4, No. 11 Copyright 2011 VLDB Endowment 2150-8097/11/08... $ 10.00.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Bibliographic network schema and meta paths.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 : Illustration of Pruning Strategy.</head><label>2</label><figDesc>Figure 2: Illustration of Pruning Strategy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Input: Commuting Matrix M T P , number of feature clusters (row clusters) U , number of target clusters (column clusters) V Output: row clusters {Ru} U u=1 , column clusters {Cv } V v=1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 3 (</head><label>3</label><figDesc>PathSim-Pruning) Cluster-based Top-k Search on Path Concatenation Input: Query x i , Commuting matrix M T P , Feature clusters {Ru} U u=1 , Target clusters {Cv } V v=1 , Diagonal vector D, top-k K. Output: Top-k list S. 1: Set CandidateSet = x i .neighbors.neighbors; 2: S = ∅; 3: Sort clusters in {Cv } V v=1 according to upper bound of s(x i , Cv); 4: foreach Cv with decreasing order do 5: if the upper bound of s(x i , Cv) &lt; min(S) then 6: break; 7: else 8: foreach x j ∈ Cv and x j ∈ CandidateSet do 9: if the upper bound of s(x i , x j ) &lt; min(S) then 10: continue; 11: else 12:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: PathSim-baseline vs. PathSim-pruning on "full DBLP dataset".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Average query execution time given different top-k's on "full DBLP dataset" using PathSim-pruning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 : Efficiency study for queries with different neighbor size un- der meta path CAC on "full DBLP dataset" based on 500</head><label>5500</label><figDesc>Figure 5: Efficiency study for queries with different neighbor size under meta path CAC on "full DBLP dataset" based on 500 queries.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Top-6 images in Flickr network under meta path IT I.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: Top-6 images in Flickr network under meta path IT IGIT I.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Theorem 1 :</head><label>1</label><figDesc>Properties of PathSim. PROOF. (1) s(xi, xj) = 2M ij M ii +M jj = 2M ji M ii +M jj = s(xj, xi), since Mij = M P (i, :) · M l (j, :) = M l (j, :) · M l (i, :) = Mji, where · means the dot product of two vectors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>jj (by Cauchy- Schwarz inequality), then s(x i , x j ) ≤ 2 √ M ii /M jj + √ M jj /M ii . Theorem 2: Limiting behavior of PathSim under infinity length meta path. PROOF. Since M = (M P M T P ) is real symmetric, it can be decomposed as M = P DP T , where D is a diagonal matrix with the values of eigenvalues of M , P is an orthogonal ma- trix composed of eigenvectors corresponding to eigenvalues in D. Let r be the first column in P , then M k = P D k P T . Let s (k) ij = 2M k (i,j) M k (i,i)+M k (j,j) , λ1 be the largest eigenvalue of M , then s (k) ij = 2(P D k P T /λ k 1 )(i,j) (P D k P T (i,i)+P D k P T (j,j))/λ k 1 , and lim k→∞ s (k) ij = 2r(i)r(j) r(i)r(i)+r(j)r(j) . Theorem 3: Bounds for block-based similarity measure ap- proximation. PROOF. 1. 񮽙 y∈Cv s(x, y) = 񮽙 y∈Cv 2x T y D(x)+D(y) ≤ 2x T 񮽙 y∈Cv y D(x)+1 = 񮽙 u 2x(Ru) T 񮽙 y∈Cv y(Ru) D(x)+1 ≤ 񮽙 u 2ˆx2ˆx 1 (u)T (u,v) D(x)+1 = 2ˆx2ˆx T 1 T (:,v) D(x)+1 , since according to Holder's Inequality, a T b ≤ ||a||∞||b|| 1 . 2. s(x, y) = 2x T y D(x)+D(y) = 2 񮽙 u x(Ru) T y(Ru) D(x)+D(y) . Since a T b ≤ ||a|| 2 ||b|| 2 according to Cauchy-Schwarz inequality, then the above for- mula ≤ 2 񮽙 u ˆ x 2 (u)T T 1 (u,y) D(x)+D(y) = 2ˆx2ˆx T 2 T T 1 (:,y) D(x)+D(y) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 : Top-4 similar venues for "DASFAA" under two meta paths.</head><label>1</label><figDesc></figDesc><table>Rank 
CP AP C path 
CP T P C path 
1 
DASFAA 
DASFAA 
2 
DEXA 
Data Knowl. Eng. 
3 
WAIM 
ACM Trans. DB Syst. 
4 
APWeb 
Inf. Syst. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table>Top-5 similar authors for "AnHai Doan" in DBIS area. 

Rank 
P-PageRank 
SimRank 
PathSim 
1 
AnHai Doan 
AnHai Doan 
AnHai Doan 
2 
Philip S. Yu 
Douglas W. Cornell 
Jignesh M. Patel 
3 
Jiawei Han 
Adam Silberstein 
Amol Deshpande 
4 
Hector Garcia-Molina 
Samuel DeFazio 
Jun Yang 
5 
Gerhard Weikum 
Curt Ellmann 
Renée J. Miller 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 (b).</head><label>3</label><figDesc></figDesc><table>One can see that 
PathSim is the only measure giving the result that Bob and Mary are 
more similar to Mike than Jim is, in terms of peers, which follows 
human intuition. 

(a) Adjacency matrix WAC. 

SIGMOD 
VLDB 
ICDE 
KDD 
Mike 
2 
1 
0 
0 
Jim 
50 
20 
0 
0 
Mary 
2 
0 
1 
0 
Bob 
2 
1 
0 
0 
Ann 
0 
0 
1 
1 

(b) Similarity between Mike and other authors. 

Jim 
Mary 
Bob 
Ann 
P-PageRank 
0.3761 
0.0133 
0.0162 
0.0046 
SimRank 
0.7156 
0.5724 
0.7125 
0.1844 
RW 
0.8983 
0.0238 
0.0390 
0 
PRW 
0.5714 
0.4444 
0.5556 
0 
PathSim 
0.0826 
0.8 
1 
0 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Comparison of a set of similarity measures. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 4 : Case study of five similarity measures on query"PKDD" on the "DBIS dataset".</head><label>4</label><figDesc></figDesc><table>Rank 
P-PageRank 
SimRank 
RW 
PRW 
PathSim 
1 
PKDD 
PKDD 
PKDD 
PKDD 
PKDD 
2 
KDD 
Local Pattern Detection 
KDD 
Local Pattern Detection 
ICDM 
3 
ICDE 
KDID 
ICDM 
DB Support for DM Appl. 
SDM 
4 
VLDB 
KDD 
PAKDD 
Constr.-Bsd. Min. &amp; Induc. DB 
PAKDD 
5 
SIGMOD 
Large-Scale Paral. Data Min. 
SDM 
KDID 
KDD 
6 
ICDM 
SDM 
TKDE 
MCD 
Data Min. Knowl. Disc. 
7 
TKDE 
ICDM 
SIGKDD Expl. 
Pattern Detection and Discovery 
SIGKDD Expl. 
8 
PAKDD 
SIGKDD Expl. 
ICDE 
RSKD 
Knowl. Inf. Syst. 
9 
SIGIR 
Constr.-Bsd. Min. &amp; Induc. DB 
SEBD (Italian Sympo. on Adv. DB) 
WImBI (Web Intell. Meets Brain Inf.) 
J. Intell. Inf. Syst. 
10 
CIKM 
TKDD 
CIKM 
Large-Scale Paral. Data Min. 
KDID 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>Top-15 query results accuracy for five similarity measures on 

"DBIS dataset" measured by nDCG. 

P-PageRank 
SimRank 
RW 
PRW 
PathSim 
Accuracy 
0.5552 
0.6289 
0.7061 
0.5284 
0.7446 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table>Clustering accuracy for single meta path-based simi-
larity measures on "4-area dataset". 

RW 
PRW 
PathSim 
Venue NMI 
0.6159 
0.8198 
0.8116 
Author NMI 
0.6486 
0.6364 
0.6501 
Weighted Avg. NMI 
0.6485 
0.6371 
0.6507 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table>Top-10 most similar authors to "Christos Faloutsos" 
under different meta paths on "full DBLP dataset". 

(a) Path: AP A 

Rank 
Author 
1 
Christos Faloutsos 
2 
Spiros Papadimitriou 
3 
Jimeng Sun 
4 
Jia-Yu Pan 
5 
Agma J. M. Traina 
6 
Jure Leskovec 
7 
Caetano Traina Jr. 
8 
Hanghang Tong 
9 
Deepayan Chakrabarti 
10 
Flip Korn 

(b) Path: AP CP A 

Rank 
Author 
1 
Christos Faloutsos 
2 
Jiawei Han 
3 
Rakesh Agrawal 
4 
Jian Pei 
5 
Charu C. Aggarwal 
6 
H. V. Jagadish 
7 
Raghu Ramakrishnan 
8 
Nick Koudas 
9 
Surajit Chaudhuri 
10 
Divesh Srivastava 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" validated="false"><head>Table 8 : Top-10 similar venues to "SIGMOD" under meta paths with different lengths on "full DBLP dataset". (a) Path: (CP AP C) 2</head><label>8</label><figDesc></figDesc><table>Rank 
Venue 
Score 
1 
SIGMOD Conference 
1 
2 
VLDB 
0.981 
3 
ICDE 
0.949 
4 
TKDE 
0.650 
5 
SIGMOD Record 
0.630 
6 
IEEE Data Eng. Bull. 
0.530 
7 
PODS 
0.467 
8 
ACM Trans. Database Syst. 
0.429 
9 
EDBT 
0.420 
10 
CIKM 
0.410 

(b) Path: (CP AP C) 4 

Rank 
Venue 
Score 
1 
SIGMOD Conference 
1 
2 
VLDB 
0.997 
3 
ICDE 
0.996 
4 
TKDE 
0.787 
5 
SIGMOD Record 
0.686 
6 
PODS 
0.586 
7 
KDD 
0.553 
8 
CIKM 
0.540 
9 
IEEE Data Eng. Bull. 
0.532 
10 
J. Comput. Syst. Sci 
0.463 

(c) Path: (CP AP C) ∞ 

Rank 
Venue 
Score 
1 
SIGMOD Conference 
1 
2 
AAAI 
0.9999 
3 
ESA 
0.9999 
4 
IEEE Trans. on Commun. 
0.9999 
5 
STACS 
0.9997 
6 
PODC 
0.9996 
7 
NIPS 
0.9993 
8 
Comput. Geom. 
0.9992 
9 
ICC 
0.9991 
10 
ICDE 
0.9984 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 9 :</head><label>9</label><figDesc></figDesc><table>Impacts of length of meta path on clustering accuracy 
on the "4-area dataset". 

CAC 
(CAC) 2 
(CAC) 3 
Venue NMI 
0.8116 
0.4603 
0.4531 
ACA 
(ACA) 2 
(ACA) 3 
Author NMI 
0.6501 
0.6091 
0.5346 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" validated="true"><head>Table 10 : "DASFAA" with multiple meta paths.</head><label>10</label><figDesc></figDesc><table>Rank 
w1=0.2,w2=0.8 
w1=0.5,w2=0.5 
w1=0.8,w2=0.2 

1 
DASFAA 
DASFAA 
DASFAA 
2 
Data Knowl. Eng. 
DEXA 
DEXA 
3 
CIKM 
CIKM 
WAIM 
4 
EDBT 
Data Knowl. Eng. 
CIKM 
5 
Inf. Syst. 
EDBT 
APWeb 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" validated="false"><head>Table 11 :</head><label>11</label><figDesc></figDesc><table>Clustering accuracy for PathSim for meta path com-
binations on "DBIS dataset". 

w1 
0 
0.2 
0.4 
0.6 
0.8 
1 
w2 
1 
0.8 
0.6 
0.4 
0.2 
0 
CAC; CT C 
0.7917 
0.7936 
0.8299 
0.8587 
0.8123 
0.8116 
ACA; (ACA) 2 
0.6091 
0.6219 
0.6506 
0.6561 
0.6508 
0.6501 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>In this Appendix, we present the technical details of the coclustering based pruning algorithm, examine the case of multiple meta path combination, show an additional experiment on the</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Objectrank: authority-based keyword search in databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Balmin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Hristidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Papakonstantinou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB&apos;04</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="564" to="575" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fast nearest neighbor search in high-dimensional space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Berchtold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ertl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE&apos;98</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="209" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Information-theoretic co-clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mallela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Modha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;03</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="89" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Measures of the amount of ecologic association between species</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">R</forename><surname>Dice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ecology</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="297" to="302" />
			<date type="published" when="1945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Optimal aggregation algorithms for middleware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fagin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lotem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PODS&apos;01</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="102" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Towards scaling fully personalized pageRank: algorithms, lower bounds, and experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fogaras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rácz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Csalogány</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sarlós</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Math</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="333" to="358" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast algorithms for topk personalized pagerank queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chakrabarti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;08</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1225" to="1226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Simrank: a measure of structural-context similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;02</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="538" to="543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cumulated gain-based evaluation of IR techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jarvelin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kekalainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TOIS</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Scaling personalized web search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;03</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="271" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Voronoi-based k nearest neighbor search for spatial network databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kolahdouzan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shahabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB&apos;04</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="840" to="851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Accuracy estimate and optimization techniques for simrank computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lizorkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Velikhov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grinev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Turdakov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>PVLDB</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="422" to="433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Object-level ranking: bringing order to web objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;05</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="567" to="574" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Crd: fast co-clustering on large datasets utilizing sampling-based matrix decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD&apos;08</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="173" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on PAMI</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="888" to="905" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Rankclus: integrating clustering with ranking for heterogeneous information network analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EDBT&apos;09</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="565" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">iTopicModel: Information Network-Integrated Topic Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM&apos;09</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="493" to="502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast Random Walk with Restart and Its Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM&apos;06</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="613" to="622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Top-k set similarity joins</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDE&apos;09</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="916" to="927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Scan: a structural clustering algorithm for networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yuruk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A J</forename><surname>Schweiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;07</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="824" to="833" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
