<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:58+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Regular Expression Learning for Information Extraction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunyao</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of EECS</orgName>
								<orgName type="institution" key="instit1">IBM Almaden Research Center San Jose</orgName>
								<orgName type="institution" key="instit2">University of Michigan</orgName>
								<address>
									<postCode>95120, 48109</postCode>
									<settlement>Ann Arbor</settlement>
									<region>CA, MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajasekar</forename><surname>Krishnamurthy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of EECS</orgName>
								<orgName type="institution" key="instit1">IBM Almaden Research Center San Jose</orgName>
								<orgName type="institution" key="instit2">University of Michigan</orgName>
								<address>
									<postCode>95120, 48109</postCode>
									<settlement>Ann Arbor</settlement>
									<region>CA, MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sriram</forename><surname>Raghavan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of EECS</orgName>
								<orgName type="institution" key="instit1">IBM Almaden Research Center San Jose</orgName>
								<orgName type="institution" key="instit2">University of Michigan</orgName>
								<address>
									<postCode>95120, 48109</postCode>
									<settlement>Ann Arbor</settlement>
									<region>CA, MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shivakumar</forename><surname>Vaithyanathan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of EECS</orgName>
								<orgName type="institution" key="instit1">IBM Almaden Research Center San Jose</orgName>
								<orgName type="institution" key="instit2">University of Michigan</orgName>
								<address>
									<postCode>95120, 48109</postCode>
									<settlement>Ann Arbor</settlement>
									<region>CA, MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">V</forename><surname>Jagadish</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of EECS</orgName>
								<orgName type="institution" key="instit1">IBM Almaden Research Center San Jose</orgName>
								<orgName type="institution" key="instit2">University of Michigan</orgName>
								<address>
									<postCode>95120, 48109</postCode>
									<settlement>Ann Arbor</settlement>
									<region>CA, MI</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Regular Expression Learning for Information Extraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Regular expressions have served as the dominant workhorse of practical information extraction for several years. However, there has been little work on reducing the manual effort involved in building high-quality, complex regular expressions for information extraction tasks. In this paper, we propose Re-LIE, a novel transformation-based algorithm for learning such complex regular expressions. We evaluate the performance of our algorithm on multiple datasets and compare it against the CRF algorithm. We show that ReLIE, in addition to being an order of magnitude faster, outperforms CRF under conditions of limited training data and cross-domain data. Finally, we show how the accuracy of CRF can be improved by using features extracted by ReLIE.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A large class of entity extraction tasks can be accomplished by the use of carefully constructed regular expressions (regexes). Examples of entities amenable to such extractions include email addresses and software names (web collections), credit card numbers and social security numbers (email compliance), and gene and protein names (bioinformatics), etc. These entities share the characteristic that their key representative patterns (features) are expressible in standard constructs of regular expressions. At first glance, it may seem that constructing * Supported in part by NSF 0438909 and NIH 1-U54-DA021519. a regex to extract such entities is fairly straightforward. In reality, robust extraction requires the use of rather complex expressions, as illustrated by the following example.</p><p>Example 1 (Phone number extraction). An obvious pattern for identifying phone numbers is "blocks of digits separated by hyphens" represented as R 1 = (\d+\-)+\d+. 1 While R 1 matches valid phone numbers like 800-865-1125 and 725-1234, it suffers from both "precision" and "recall" problems. Not only does R 1 produce incorrect matches (e.g., social security numbers like 123-45-6789), it also fails to identify valid phone numbers such as 800. <ref type="bibr">865.1125, and (800)</ref>865-CARE. An improved regex that addresses these problems is R 2 = (\d{3}[-.\ ()]){1,2}[\dA-Z]{4}.</p><p>While multiple machine learning approaches have been proposed for information extraction in recent years ( <ref type="bibr" target="#b23">McCallum et al., 2000;</ref><ref type="bibr">Cohen and McCal- lum, 2003;</ref><ref type="bibr" target="#b20">Klein et al., 2003;</ref><ref type="bibr">Krishnan and Man- ning, 2006</ref>), manually created regexes remain a widely adopted practical solution for information extraction <ref type="bibr" target="#b1">(Appelt and Onyshkevych, 1998;</ref><ref type="bibr" target="#b15">Fukuda et al., 1998;</ref><ref type="bibr" target="#b7">Cunningham, 1999;</ref><ref type="bibr" target="#b26">Tanabe and Wilbur, 2002;</ref><ref type="bibr" target="#b22">Li et al., 2006;</ref><ref type="bibr" target="#b10">DeRose et al., 2007;</ref><ref type="bibr" target="#b28">Zhu et al., 2007</ref>). Yet, with a few notable exceptions, which we discuss later in Section 1.1, there has been very little work in reducing this human effort through the use of automatic learning techniques. In this paper, we propose a novel formulation of the problem of learn-ing regexes for information extraction tasks. We demonstrate that high quality regex extractors can be learned with significantly reduced manual effort. To motivate our approach, we first discuss prior work in the area of learning regexes and describe some of the limitations of these techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Learning Regular Expressions</head><p>The problem of inducing regular languages from positive and negative examples has been studied in the past, even outside the context of information extraction <ref type="bibr" target="#b0">(Alquezar and Sanfeliu, 1994;</ref><ref type="bibr" target="#b11">Dupont, 1996;</ref><ref type="bibr" target="#b14">Firoiu et al., 1998</ref>; <ref type="bibr" target="#b17">Garofalakis et al., 2000;</ref><ref type="bibr" target="#b9">Denis, 2001;</ref><ref type="bibr" target="#b8">Denis et al., 2004;</ref><ref type="bibr" target="#b13">Fernau, 2005;</ref><ref type="bibr" target="#b16">Galassi and Giordana, 2005;</ref><ref type="bibr" target="#b2">Bex et al., 2006</ref>). Much of this work assumes that the target regex is small and compact thereby allowing the learning algorithm to exploit this information. Consider, for example, the learning of patterns motivated by DNA sequencing applications ( <ref type="bibr">Galassi and Gior- dana, 2005</ref>). Here the input sequence is viewed as multiple atomic events separated by gaps. Since each atomic event is easily described by a small and compact regex, the problem reduces to one of learning simple regexes. Similarly, in XML DTD inference ( <ref type="bibr" target="#b17">Garofalakis et al., 2000;</ref><ref type="bibr" target="#b2">Bex et al., 2006</ref>), it is possible to exploit the fact that the XML documents of interest are often described using simple DTDs. E.g., in an online books store, each book has a title, one or more authors and price. This information can be described in a DTD as book ‚Üê titleauthor + price. However, as shown in Example 1, regexes for information extraction rely on more complex constructs.</p><p>In the context of information extraction, prior work has concentrated primarily on learning regexes over relatively small alphabet sizes. A common theme in <ref type="bibr" target="#b25">(Soderland, 1999;</ref><ref type="bibr" target="#b6">Ciravegna, 2001;</ref><ref type="bibr" target="#b27">Wu and Pottenger, 2005;</ref><ref type="bibr" target="#b12">Feldman et al., 2006</ref>) is the problem of learning regexes over tagged tokens produced by other text-processing steps such as POS tagging, morphological analysis, and gazetteer matching. Thus, the alphabet is defined by the space of possible tags output by these analysis steps. A similar approach has been proposed in <ref type="bibr" target="#b3">(Brill, 2000)</ref> for POS disambiguation. In contrast, our paper addresses extraction tasks that require "fine-grained" control to accurately capture the structural features of the entity of interest. Consequently, the domain of interest consists of all characters thereby dramatically increasing the size of the alphabet. To enable this scale-up, the techniques presented in this paper exploit advanced syntactic constructs (such as character classes and quantifiers) supported by modern regex languages.</p><p>Finally, we note that almost all of the above described work define the learning problem over a restricted class of regexes. Typically, the restrictions involve either disallowing or limiting the use of Kleene disclosure and disjunction operations. However, our work imposes no such restrictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Contributions</head><p>In a key departure from prior formulations, the learning algorithm presented in this work takes as input not just labeled examples but also an initial regular expression. The use of an initial regex has two major advantages. First, this expression provides a natural mechanism for a domain expert to provide domain knowledge about the structure of the entity being extracted. Second, as we show in Section 2, the space of output regular expressions under consideration can be meaningfully restricted by appropriately defining their relationship to the input expression. Such a principled approach to restrict the search space permits the learning algorithm to consider complex regexes in a tractable manner. In contrast, prior work defined a tractable search space by placing restrictions on the target class of regular expressions. Our specific contributions are:</p><p>‚Ä¢ A novel regex learning problem consisting of learning an "improved" regex given an initial regex and labeled examples Consider the task of identifying instances of some entity E. Let R 0 denote the input regex provided by the user and let M(R 0 , D) denote the set of matches obtained by evaluating R 0 over a document col-</p><formula xml:id="formula_0">lection D. Let M p (R 0 , D) = {x ‚àà M(R 0 , D) : x instance of E} and M n (R 0 , D) = {x ‚àà M(R 0 , D) :</formula><p>x not an instance of E} denote the set of positive and negative matches for R 0 . Note that a match is positive if it corresponds to an instance of the entity of interest and is negative otherwise. The goal of our learning task is to produce a regex that is "better" than R 0 at identifying instances of E. Given a candidate regex R, we need a mechanism to judge whether R is indeed a better extractor for E than R 0 . To make this judgment even for just the original document collection D, we must be able to label each instance matched by R (i.e., each element of M(R, D)) as positive or negative. Clearly, this can be accomplished if the set of matches produced by R are contained within the set of available labeled examples, i.e., if M(R, D) ‚äÜ M(R 0 , D). Based on this observation, we make the following assumption: Assumption 1. Given an input regex R 0 over some alphabet Œ£, any other regex R over Œ£ is a candidate for our learning algorithm only if L(R) ‚äÜ L(R 0 ). (L(R) denotes the language accepted by R).</p><p>Even with this assumption, we are left with a potentially infinite set of candidate regexes from which our learning algorithm must choose one. To explore this set in a principled fashion, we need a mechanism to move from one element in this space to another, i.e., from one candidate regex to another. In addition, we need an objective function to judge the extraction quality of each candidate regex. We address these two issues below.</p><p>Regex Transformations To systematically explore the search space, we introduce the concept of regex transformations. Definition 1 (Regex Transformation). Let R Œ£ denote the set of all regular expressions over some alphabet Œ£. A regex transformation is a function T :</p><formula xml:id="formula_1">R Œ£ ‚Üí 2 RŒ£ such that ‚àÄR ‚àà T (R), L(R ) ‚äÜ L(R).</formula><p>For example, by replacing different occurrences of the quantifier + in R 1 from Example 1 with specific ranges (such as {1,2} or {3}), we obtain expressions such as R 3 = (\d+\-){1,2}\d+ and R 4 = (\d{3}\-)+\d+. The operation of replacing quantifiers with restricted ranges is an example of a particular class of transformations that we describe further in Section 3. For the present, it is sufficient to view a transformation as a function applied to a regex R that produces, as output, a set of regexes that accept sublanguages of L(R). We now define the search space of our learning algorithm as follows: Definition 2 (Search Space). Given an input regex R 0 and a set of transformations T , the search space of our learning algorithm is T (R 0 ), the set of all regexes obtained by (repeatedly) applying the transformations in T to R 0 .</p><p>For instance, if the operation of restricting quantifiers that we described above is part of the transformation set, then R 3 and R 4 are in the search space of our algorithm, given R 1 as input.</p><p>Objective Function We now define an objective function, based on the well known F-measure, to compare the extraction quality of different candidate regexes in our search space.</p><formula xml:id="formula_2">Using M p (R, D) (resp. M n (R, D))</formula><p>to denote the set of positive (resp. negative) matches of a regex R, we define</p><formula xml:id="formula_3">precision(R, D) = M p (R, D) M p (R, D) + M n (R, D) recall(R, D) = M p (R, D) M p (R 0 , D) F(R, D) = 2 ¬∑ precision(R, D) ¬∑ recall(R, D) precision(R, D) + recall(R, D)</formula><p>The regex learning task addressed in this paper can now be formally stated as the following optimization problem: Definition 3 (Regex Learning Problem). Given an input regex R 0 , a document collection D, labeled sets of positive and negative examples M p (R 0 ,D) and M n (R 0 ,D), and a set of transformations T , compute the</p><formula xml:id="formula_4">output regex R f = argmax R‚ààT (R0 ) F(R, D).</formula><p>When applied to a collection of University web pages, we discovered that R 5 identified correct instances such as Netscape 2.0, Windows 2000 and Installation Designer v1.1. However, R 5 also extracted incorrect instances such as course numbers (e.g. ENGLISH 317), room numbers (e.g. Room 330), and section headings (e.g. Chapter 2.2). To eliminate spurious matches such as ENGLISH 317, let us enforce the condition that "each word is a single upper-case letter followed by one or more lower-case letters". To accomplish this, we focus on the sub-expression of R 5 that identifies capitalized words, R 5 1 = ([A-Z]\w * \s+)+, and replace it with</p><formula xml:id="formula_5">R 5 1a = ([A-Z][a-z] * \s+)+.</formula><p>The regex resulting from R 5 by replacing R 5 1 with R 5 1a will avoid matches such as ENGLISH 317.</p><p>An alternate way to improve R 5 is by explicitly disallowing matches against strings like ENGLISH, Room and Chapter. To accomplish this, we can exploit the negative lookahead operator supported in modern regex engines. Lookaheads are special constructs that allow a sequence of characters to be checked for matches against a regex without the characters themselves being part of the match. As an example, (?!Ra)R b ("?!" being the negative lookahead operator) returns matches of regex R b but only if they do not match R a . Thus, by replacing R 5 1 in our original regex with R 5 1b =(?! ENGLISH|Room|Chapter)[A-Z]\w * \s+, we produce an improved regex for software names.</p><p>The above examples illustrate the general principle of our transformation technique. In essence, we isolate a sub-expression of a given regex R and modify it such that the resulting regex accepts a sublanguage of R. We consider two kinds of modifications -drop-disjunct and include-intersect. In dropdisjunct, we operate on a sub-expression that corresponds to a disjunct and drop one or more operands of that disjunct. In include-intersect, we restrict the chosen sub-expression by intersecting it with some other regex. Formally, Definition 4 (Drop-disjunct Transformation). Let R ‚àà R Œ£ be a regex of the form R = R a œÅ(X)R b , where œÅ(X) denotes the disjunction R 1 |R 2 | . . . |R n of any non-empty set of regexes X = {R 1 , R 2 , . . . , R n }.</p><formula xml:id="formula_6">The drop-disjunct transformation DD(R, X, Y ) for some Y ‚äÇ X, Y = ‚àÖ results in the new regex R a œÅ(Y )R b . Definition 5 (Include-Intersect Transformation). Let . \W \s \w [a-zA-Z] \d|[0-9] _ [a-z] [A-Z]</formula><p>Figure 1: Sample Character Classes in Regex R ‚àà R Œ£ be a regex of the form R = R a XR b for some</p><formula xml:id="formula_7">X ‚àà R Œ£ , X = ‚àÖ. The include-intersect transformation II(R, X, Y ) for some Y ‚àà R Œ£ , Y = ‚àÖ results in the new regex R a (X ‚à© Y )R b .</formula><p>We state the following proposition (proof omitted in the interest of space) that guarantees that both drop-disjunct and include-intersect restrict the language of the resulting regex, and therefore are valid transformations according to Definition 1.</p><formula xml:id="formula_8">Proposition 1. Given regexes R, X 1 , Y 1 , X 2 and Y 2 from R Œ£ such that DD(R, X 1 , Y 1 ) and II(R, X 2 , Y 2 ) are applicable, L(DD(R, X 1 , Y 1 )) ‚äÜ L(R) and L(II(R, X 2 , Y 2 )) ‚äÜ L(R).</formula><p>We now proceed to describe how we use different syntactic constructs to apply drop-disjunct and include-intersect transformations. Character Class Restrictions Character classes are short-hand notations for denoting the disjunction of a set of characters (\d is equivalent to (0|1...|9); \w is equivalent to (a|. . .|z|A|. . .|Z|0|1. . .|9| ); etc.). 2 <ref type="figure">Figure 1</ref> illustrates a character class hierarchy in which each node is a stricter class than its parent (e.g., \d is stricter than \w). A replacement of any of these character classes by one of its descendants is an instance of the drop-disjunct transformation. Notice that in Example 2, when replacing R 5 1 with R 5 1a , we were in effect applying a character class restriction. Quantifier Restrictions Quantifiers are used to define the range of valid counts of a repetitive sequence. For instance, a{m,n} looks for a sequence of a's of length at least m and at most n. Since quantifiers are also disjuncts (e.g., a{1,3} is equivalent to a|aa|aaa), the replacement of an expression R{m, n} with an expression R{m 1 , n 1 } (m ‚â§ m 1 ‚â§ n 1 ‚â§ n) is an instance of the drop-disjunct transformation. For example, given a subexpression of the form a{1,3}, we can replace it with one of a{1,1}, a{1,2}, a{2,2}, a{2,3}, or a{3,3}. Note that, before applying this transformation, wildcard expressions such as a+ and a * are replaced by a{0,maxCount} and a{1,maxCount} respectively, where maxCount is a user configured maximum length for the entity being extracted. Negative Dictionaries Observe that the includeintersect transformation (Definition 5) is applicable for every possible sub-expression of a given regex R. Note that a valid sub-expression in R is any portion of R where a capturing group can be introduced. <ref type="bibr">3</ref> Consider a regex R = R a XR b with a subexpression X; the application of include-intersect requires another regex Y to yield R a (X ‚à©Y )R b . We would like to construct Y such that R a (X ‚à© Y )R b is "better" than R for the task at hand. Therefore, we construct Y as ¬¨Y where Y is a regex constructed from negative matches of R. Specifically, we look at each negative match of R and identify the substring of the match that corresponds to X. We then apply a greedy heuristic (see below) to these substrings to yield a negative dictionary Y . Finally, the transformed regex R a (X ‚à©¬¨Y )R b is implemented using the negative lookahead expression Ra(?! Y')XR b . Greedy Heuristic for Negative Dictionaries Implementation of the above procedure requires certain judicious choices in the construction of the negative dictionary to ensure tractability of this transformation. Let S(X) denote the distinct strings that correspond to the sub-expression X in the negative matches of R. <ref type="bibr">4</ref> Since any subset of S(X) is a candidate negative dictionary, we are left with an exponential number of possible transformations. In our implementation, we used a greedy heuristic to pick a single negative dictionary consisting of all those elements of S(X) that individually improve the F-measure. For instance, in Example 2, if the independent substitution of R 5 1 with (?!ENGLISH) <ref type="bibr">[</ref>   ‚Ä¢ Applying every transformation on the current regex R new to obtain a set of candidate regexes ‚Ä¢ From the candidates, choosing the regex R whose F-measure over the training dataset is maximum</p><formula xml:id="formula_9">F (R, Mtr) 7. if (F (R , Mtr) &lt;= F (Rnew, Mtr)) return Rnew 8. if (F (R , M val ) &lt; F (Rnew, M val )) return Rnew 9. Rnew = R 10. } while(true) end</formula><p>To avoid overfitting, ReLIE terminates when either of the following conditions is true: (i) there is no improvement in F-measure over the training set; (ii) there is a drop in F-measure when applying R on the validation set. The following proposition provides an upper bound for the running time of the ReLIE algorithm. Proposition 2. Given any valid set of inputs M tr , M val , R 0 , and T , the ReLIE algorithm terminates in at most | M n (R 0 , M tr )| iterations. The running time of the algorithm T T otal (R 0 , M tr , M val ) ‚â§ | M n (R 0 , M tr )| * t 0 , where t 0 is the time taken for the first iteration of the algorithm.</p><p>Proof. With reference to <ref type="figure" target="#fig_0">Figure 2</ref>, in each iteration, the F-measure of the "best" regex R is strictly better than R new . Since L(R ) ‚äÜ L(R new ), R eliminates at least one additional negative match compared to R new . Hence, the maximum number of iterations is | M n (R 0 , M tr )|.</p><p>For a regular expression R, let n cc (R) and n q (R) denote, respectively, the number of character classes and quantifiers in R. The maximum number of possible subexpressions in R is |R| 2 , where |R| is the length of R. Let MaxQ(R) denote the maximum number of ways in which a single quantifier appearing in R can be restricted to a smaller range. Let F cc denote the maximum fanout 5 of the character class hierarchy. Let T ReEval (D) denote the average time taken to evaluate a regex over dataset D.</p><p>Let R i denote the regex at the beginning of iteration i. The number of candidate regexes obtained by applying the three transformations is</p><formula xml:id="formula_10">NumRE(Ri, Mtr) ‚â§ ncc(Ri) * Fcc+nq(Ri) * MaxQ(Ri)+|Ri| 2</formula><p>The time taken to enumerate the character class and quantifier restriction transformations is proportional to the resulting number of candidate regexes. The time taken for the negative dictionaries transformation is given by the running time of the greedy heuristic (Section 3). The total time taken to enumerate all candidate regexes is given by (for some constant c)</p><formula xml:id="formula_11">TEnum(Ri, Mtr) ‚â§ c * (ncc(Ri) * Fcc + nq(Ri) * MaxQ(Ri) + |Ri| 2 * Mn(Ri, Mtr) * T ReEval (Mtr))</formula><p>Choosing the best transformation involves evaluating each candidate regex over the training and validation corpus and the time taken for this step is</p><formula xml:id="formula_12">T P ickBest (Ri, Mtr, M val ) = NumRE(Ri, Mtr) * (T ReEval (Mtr) + T ReEval (M val ))</formula><p>The total time taken for an iteration can be written as</p><formula xml:id="formula_13">TI (Ri, Mtr, M val ) =TEnum(Ri, Mtr) + T P ickBest (Ri, Mtr, M val )</formula><p>It can be shown that the time taken in each iteration decreases monotonically (details omitted in the interest of space). Therefore, the total running time of the algorithm is given by</p><formula xml:id="formula_14">T T otal (R0 , Mtr , M val ) = TI (Ri, Mtr, M val ) ‚â§ | Mn(R0 , Mtr )| * t0 .</formula><p>where t 0 = T I (R 0 , M tr , M val ) is the running time of the first iteration of the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we present an empirical study of the ReLIE algorithm using four extraction tasks over three real-life data sets. The goal of this study is to evaluate the effectiveness of ReLIE in learning complex regexes and to investigate how it compares with standard machine learning algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setup</head><p>Data Set The datasets used in our experiments are:</p><p>‚Ä¢ EWeb: A collection of 50,000 web pages crawled from a corporate intranet. <ref type="bibr">5</ref> Fanout is the number of ways in which a character class may be restricted as defined by the hierarchy (e.g. <ref type="figure">Figure 1</ref>).</p><p>‚Ä¢ AWeb: A set of 50,000 web pages obtained from the publicly available University of Michigan Web page collection ( <ref type="bibr" target="#b22">Li et al., 2006</ref>), including a subcollection of 10,000 pages (AWeb-S).</p><p>‚Ä¢ Email: A collection of 10,000 emails obtained from the publicly available Enron email collection ( <ref type="bibr" target="#b24">Minkov et al., 2005</ref>).</p><p>Extraction Tasks SoftwareNameTask, CourseNumberTask and PhoneNumberTask were evaluated on EWeb, AWeb and Email, respectively. Since web pages have large number of URLs, to keep the labeling task manageable, URLTask was evaluated on</p><p>AWeb-S.</p><p>Gold Standard For each task, the gold standard was created by manually labeling all matches for the initial regex. Note that only exact matches with the gold standard are considered correct in our evaluations. 6</p><p>Comparison Study To evaluate ReLIE for entity extraction vis-a-vis existing algorithms, we used the popular conditional random field (CRF). Specifically, we used the MinorThird <ref type="bibr">(Cohen, 2004</ref>) implementation of CRF to train models for all four extraction tasks. For training the CRF we provided it with the set of positive and negative matches from the initial regex with a context of 200 characters on either side of each match <ref type="bibr">7</ref> . Since it is unlikely that useful features are located far away from the entity, we believe that 200 characters on either side is sufficient context. The CRF used the base features described in <ref type="bibr" target="#b5">(Cohen et al., 2005</ref>). To ensure fair comparison with ReLIE, we also included the matches corresponding to the input regex as a feature to the CRF. In practice, more complex features (e.g., dictionaries, simple regexes) derived by domain experts are often provided to CRFs. However, such features can also be used to refine the initial regex given to ReLIE. Hence, with a view to investigating the "raw" learning capability of the two approaches, we chose to run all our experiments without any additional manually derived features. In fact, the patterns learned by ReLIE through transformations are often similar to the features that domain experts may provide to CRF. We will revisit this issue in Section 5.4.</p><p>Evaluation We used the standard F-measure to evaluate the effectiveness of ReLIE and CRF. We divided each dataset into 10 equal parts and used X% of the dataset for training (X=10, 40 and 80), 10% for validation, and remaining (90-X)% for testing. All results are reported on the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>Four extraction tasks were chosen to reflect the entities commonly present in the three datasets.</p><p>‚Ä¢ </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Raw Extraction Quality</head><p>The cross-validated results across all four tasks are presented in <ref type="figure" target="#fig_2">Figure 3</ref>.</p><p>‚Ä¢ With 10% training data, ReLIE outperforms CRF on three out of four tasks with a difference in Fmeasure ranging from 0.1 to 0.2.</p><p>‚Ä¢ As training data increases, both algorithms perform better with the gap between the two reducing for all the four tasks. For CourseNumberTask and URLTask, CRF does slightly better than ReLIE for larger training dataset. For the other two tasks, ReLIE retains its advantage over CRF. 9</p><p>The above results indicate that ReLIE performs comparably with CRF with a slight edge in conditions of limited training data. Indeed, the capability to learn high-quality extractors using a small training set is important because labeled data is often expensive to obtain. For precisely this same reason, we would ideally like to learn the extractors once and then apply them to other datasets as needed. Since these other datasets may be from a different domain, we next performed a cross-domain test (i.e., training and testing on different domains).   Cross-domain Evaluation <ref type="table" target="#tab_6">Table 1</ref> summarizes the results of training the algorithms on one data set and testing on another. The scenarios chosen are: (i) SoftwareNameTask trained on EWeb and tested on AWeb, (ii) URLTask trained on AWeb and tested on Email, and (iii) PhoneNumberTask trained on Email and tested on AWeb. <ref type="bibr">10</ref> We can see that ReLIE significantly outperforms CRF for all three tasks, even when provided with a large training dataset. Compared to testing on the same dataset, there is a reduction in F-measure (less than 0.1 in many cases) when the regex learned by ReLIE is applied to a different dataset, while the drop for CRF is much more significant (over 0.5 in many cases). <ref type="bibr">11</ref> Training Time Another issue of practical consideration is the efficiency of the learning algorithm. <ref type="table" target="#tab_4">Table 2</ref> reports the average training and testing time for both algorithms on the four tasks. On average Re-LIE is an order of magnitude faster than CRF in both building the model and applying the learnt model. Robustness to Variations in Input Regexes The transformations done by ReLIE are based on the structure of the input regex. Therefore given different input regexes, the final regexes learned by ReLIE will be different. To evaluate the impact of the structure of the input regex on the quality of the regex learned by ReLIE, we started with different regexes <ref type="bibr">12</ref> for the same task. We found that ReLIE is robust to variations in input regexes. For instance, on SoftwareNameTask, the standard deviation in F-measure <ref type="bibr">10</ref> We do not report results for CourseNumberTask as course numbers are specific to academic webpages and do not appear in the other two domains 11 Similar cross-domain performance deterioration for a machine learning approach has been observed by <ref type="bibr" target="#b18">(Guo et al., 2006</ref>). <ref type="bibr">12</ref> Recall that the search space of ReLIE is limited by L(R0) (Assumption 1). Thus to ensure meaningful comparison, for the same task any two given input regexes R0 and R 0 are chosen in such a way that although their structures are different,</p><formula xml:id="formula_15">Mp(R0, D) = Mp(R 0 , D) and Mn(R0, D) = Mn(R 0 , D).</formula><p>of the final regexes generated from six different input regexes was less than 0.05. Further details of this experiment are omitted in the interest of space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Discussion</head><p>The results of our comparison study <ref type="figure" target="#fig_2">(Figure 3</ref>) indicates that for raw extraction quality ReLIE has a slight edge over CRF for small training data. However, in cross-domain performance ( </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(?![,:])\W?)[A-Z\d]{3,4}\b</head><p>CourseNumberTask</p><formula xml:id="formula_16">R0 \b([A-Z][a-zA-Z]+)\s+\d{3,3}\b</formula><p>Rfinal \b(((?!(At|Between| ¬∑ ¬∑ ¬∑ Contact|Some|Suite|Volume)) <ref type="bibr">[</ref>  After examining the features learnt by CRF, it was clear that while CRF could learn features such as the negative dictionary it is unable to learn characterlevel features. This should not be surprising since our CRF was trained with primarily tokens as features (cf. Section 5.1). While this limitation was less of a factor in experiments involving data from the same domain (some effects were seen with smaller training data), it does explain the significant difference between the two algorithms in cross-domain tasks where the vocabulary can be significantly different. Indeed, in practical usage of CRF, the main challenge is to come up with additional complex features (often in the form of dictionary and regex patterns) that need to be given to the CRF ( <ref type="bibr" target="#b24">Minkov et al., 2005</ref>). Such complex features are largely handcrafted and thus expensive to obtain. Since the Re-LIE transformations are operations over characters, a natural question to ask is: "Can the regex learned by ReLIE be used to provide features to CRF?" We answer this question below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">ReLIE as Feature Extractor for CRF</head><p>To understand the effect of incorporating ReLIEidentified features into CRF, we chose the two tasks (CourseNumberTask and PhoneNumberTask) with the least F-measure in our experiments to determine raw extraction quality. We examined the final regex produced by ReLIE and manually extracted portions to serve as features. For example, the negative dictionary learned by ReLIE for the CourseNumberTask (At|Between| ¬∑ ¬∑ ¬∑ |Volume) was incorporated as a feature into CRF. To help isolate the effects, for each task, we only incorporated features corresponding to a single transformation: negative dictionaries for CourseNumberTask and quantifier restrictions for PhoneNumberTask. The results of these experiments are shown in <ref type="table" target="#tab_5">Table 3</ref>. The first point worthy of note is that performance has improved in all but one case. Second, despite the F-measure on CourseNumberTask being lower than PhoneNumberTask (presumably more potential for improvement), the improvements on PhoneNumberTask are significantly higher. This observation is consistent with our conjecture in Section 5.1 that CRF learns token-level features; therefore incorporating negative dictionaries as extra feature provides only limited improvement. Admittedly more experiments are needed to understand the full impact of incorporating ReLIE-identified features into CRF. However, we do believe that this is an exciting direction of future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Summary and Future Work</head><p>We proposed a novel formulation of the problem of learning complex character-level regexes for entity extraction tasks. We introduced the concept of regex transformations and described how these could be realized using the syntactic constructs of modern regex languages. We presented ReLIE, a powerful regex learning algorithm that exploits these ideas. Our experiments demonstrate that ReLIE is very effective for certain classes of entity extraction, particularly under conditions of cross-domain and limited training data. Our preliminary results also indicate the possibility of using ReLIE as a powerful feature extractor for CRF and other machine learning algorithms. Further investigation of this aspect of ReLIE presents an interesting avenue of future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: ReLIE Search Algorithm 4 ReLIE Search Algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2</head><label>2</label><figDesc>Figure 2 describes the ReLIE algorithm for the Regex Learning Problem (Definition 3) based on the transformations described in Section 3. ReLIE is a greedy hill climbing search procedure that chooses, at every iteration, the regex with the highest Fmeasure. An iteration in ReLIE consists of: ‚Ä¢ Applying every transformation on the current regex R new to obtain a set of candidate regexes ‚Ä¢ From the candidates, choosing the regex R whose F-measure over the training dataset is maximum</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Extraction Quality a a For SoftwareNameTask, with 80% training data we could not obtain results for CRF as the program failed repeatedly during the training phase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>A-Z][a-zA-Z]</head><label></label><figDesc>+))\s+\d{3,3}\b URLTask R0 \b(\w+://)?(\w+\.){0,2}\w+\.\w+(/[ ‚àß \s]+){0,20}\b Rfinal \b((?!(Response 20010702 1607.csv| ¬∑ ¬∑ ¬∑ ))((\w+://)?(\w+\.){0,2}\w+\.(?!(ppt | ¬∑ ¬∑ ¬∑ doc))[a-zA-Z]{2,3}))(/[ ‚àß \s]+){0,20}\b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Task ( Training, Testing)</head><label>(</label><figDesc></figDesc><table>Data for Training 

10% 
40% 
80% 
ReLIE CRF ReLIE CRF ReLIE CRF 
SoftwareNameTask(EWeb,AWeb) 0.920 0.297 0.977 0.503 0.971 N/A 

URLTask(AWeb-S,Email) 

0.690 0.209 0.784 0.380 0.801 0.507 
PhoneNumberTask(Email,AWeb) 0.357 0.130 0.475 0.125 0.513 0.120 

Table 1: Cross Domain Test (F-measure). 

Technique 

SoftwareNameTask CourseNumberTask 
URLTask 
PhoneNumberTask 

training testing training testing training testing training testing 

ReLIE 

511.7 
20.6 
69.3 
18.4 
73.8 
7.7 
39.4 
1.1 
CRF 
7597.0 2315.8 482.5 
75.4 
438.7 53.8 434.8 
57.7 

t(ReLIE) 
t(CRF) 

0.067 0.009 0.144 0.244 0.168 0.143 0.091 0.019 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="true"><head>Table 2 : Average Training/Testing Time (sec)(with 40% data for training)</head><label>2</label><figDesc></figDesc><table>Task(Extra Feature) 

Data for Training 
10% 
40% 
80% 
CRF C+RL CRF C+RL CRF C+RL 
CourseNumberTask(Negative Dictionary) 0.553 0.624 0.644 0.764 0.854 0.845 

PhoneNumberTask(Quantifier) 

0.695 0.893 0.820 0.937 0.821 0.964 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 3 :</head><label>3</label><figDesc>ReLIE as Feature Extractor (C+RL is CRF enhanced with features learned by ReLIE).</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 1 )1\W+)?\W?\d{3,3}\W * \s * \W?[A-Z\d]{2,4}\s * \W?[A-Z\d]{2,4}\b Rfinal \b(1\W+)?\W?\d{3,3}((?![,])\W * )\s * \W?[A-Z\d]{3,3}\s * (</head><label>1</label><figDesc></figDesc><table>ReLIE 
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Sample Regular Expressions Learned by ReLIE(R0: input regex; R f inal : final regex learned; the parts of R0 

modified by ReLIE and the corresponding parts in R f inal are highlighted.) 

into [A-Z\d]{3,3}). 
</table></figure>

			<note place="foot" n="1"> Throughout this paper, we use the syntax of the standard Java regex engine (Java, 2008).</note>

			<note place="foot" n="3"> Instantiating Regex Transformations In this section, we describe how transformations can be implemented by exploiting the syntactic constructs of modern regex engines. To help with our description, we introduce the following task: Example 2 (Software name extraction). Consider the task of identifying names of software products in text. A simple pattern for this task is: &quot;one or more capitalized words followed by a version number&quot;, represented as R 5 = ([A-Z]\w * \s+)+[Vv]?(\d+\.?)+.</note>

			<note place="foot" n="2"> Note that there are two distinct character classes \W and \w</note>

			<note place="foot" n="3"> For instance, the sub-expressions of ab{1,2}c are a, ab{1,2}, ab{1,2}c, b, b{1,2}, b{1,2}c, and c. 4 S(X) can be obtained automatically by identifying the substring corresponding to the group X in each entry in Mn(R,D)</note>

			<note place="foot" n="6"> The labeled data will be made publicly available at http://www.eecs.umich.edu/db/regexLearning/. 7 Ideally, we would have preferred to let MinorThird extract appropriate features from complete documents in the trainingset but could not get it to load our large datasets.</note>

			<note place="foot" n="8"> URLTask may appear to be simplistic. However, extracting URLs without the leading protocol definitions (e.g. http) can be challenging.</note>

			<note place="foot" n="9"> For SoftwareNameTask, with 80% training data we could not obtain results for CRF as the program failed repeatedly during the training phase.</note>

			<note place="foot" n="13"> To obtain these negative dictionaries, ReLIE not only needs to correctly identify the dictionary entries from negative matches but also has to place the corresponding negative lookahead expression at the appropriate place in the regex.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their insightful and constructive comments and suggestions. We are also grateful for comments from David Gondek and Sebastian Blohm.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Incremental grammatical inference from positive and negative data using unbiased finite state automata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Alquezar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sanfeliu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SSPR</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The common pattern specification language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><forename type="middle">E</forename><surname>Appelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyan</forename><surname>Onyshkevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TIPSTER TEXT PROGRAM</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Inference of concise DTDs from XML data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Geert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bex</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VLDB</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Pattern-based disambiguation for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGDAT</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Information Extraction from the World Wide Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mccallum</surname></persName>
		</author>
		<ptr target="http://minorthird.sourceforge.net" />
	</analytic>
	<monogr>
		<title level="m">KDD William W. Cohen. 2004. Minorthird: Methods for identifying names and ontological relations in text using heuristics for inducing regularities from data</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning to Understand Web Site Update Requests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Adaptive information extraction from text by rule induction and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Ciravegna</surname></persName>
		</author>
		<editor>IJ-CAI</editor>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">JAPE -a java annotation patterns engine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cunningham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning regular languages using RFSAs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francois</forename><surname>Denis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theor. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="267" to="294" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning regular languages from simple positive examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francois</forename><surname>Denis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="37" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">DBLife: A Community Information Management Platform for the Database Research Community In CIDR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Derose</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Incremental regular inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Dupont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICGI</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Self-supervised Relation Extraction from the Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronen</forename><surname>Feldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISMIS</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Algorithms for learning regular expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henning</forename><surname>Fernau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ALT</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Learning regular languages from positive evidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Firoiu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
	<note>In CogSci</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Toward information extraction: identifying protein names from biological papers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fukuda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pac Symp Biocomput</title>
		<imprint>
			<biblScope unit="page" from="707" to="718" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Learning regular expressions from noisy sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ugo</forename><surname>Galassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Attilio</forename><surname>Giordana</surname></persName>
		</author>
		<editor>SARA</editor>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">XTRACT: a system for extracting document type descriptors from XML documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minos</forename><surname>Garofalakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Empirical Study on the Performance Stability of Named Entity Recognition Model across Domains In EMNLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hong Lei Guo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Java Regular Expressions</surname></persName>
		</author>
		<ptr target="http://java.sun.com/javase/6/docs/api/java/util/regex/package-summary.html" />
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Named Entity Recognition with Character-Level Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An Effective Two-Stage Model for Exploiting Non-Local Dependencies in Named Entity Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Getting work done on the web: Supporting transactional queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunyao</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Maximum Entropy Markov Models for Information Extraction and Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Extracting personal names from emails: Applying named entity recognition to informal text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Einat</forename><surname>Minkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT/EMNLP</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning information extraction rules for semi-structured and free text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="233" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Tagging gene and protein names in biomedical text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorraine</forename><surname>Tanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W. John</forename><surname>Wilbur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1124" to="1132" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A semisupervised active learning algorithm for information extraction from textual data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianhao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">M</forename><surname>Pottenger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JASIST</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="258" to="271" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Navigating the intranet with high precision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaiyu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Loeser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sriram</forename><surname>Raghavan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
	<note>Shivakumar Vaithyanathan</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
