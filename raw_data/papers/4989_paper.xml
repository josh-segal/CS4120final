<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T17:09+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Humans Perform Semi-Supervised Classification Too *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojin</forename><surname>Zhu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Wisconsin</orgName>
								<address>
									<postCode>53706</postCode>
									<settlement>Madison</settlement>
									<region>WI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Rogers</surname></persName>
							<email>ttrogers@wisc.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruichen</forename><surname>Qian</surname></persName>
							<email>qian2@wisc.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Wisconsin</orgName>
								<address>
									<postCode>53706</postCode>
									<settlement>Madison</settlement>
									<region>WI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuck</forename><surname>Kalish</surname></persName>
							<email>cwkalish@wisc.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Humans Perform Semi-Supervised Classification Too *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We explore the connections between machine learning and human learning in one form of semi-supervised classification. 22 human subjects completed a novel 2-class categorization task in which they were first taught to categorize a single labeled example from each category , and subsequently were asked to categorize, without feedback, a large set of additional items. Stimuli were visually complex and unrecognizable shapes. The unlabeled examples were sampled from a bimodal distribution with modes appearing either to the left (left-shift condition) or right (right-shift condition) of the two labeled examples. Results showed that, although initial decision boundaries were near the middle of the two labeled examples, after exposure to the unlabeled examples, they shifted in different directions in the two groups. In this respect, the human behavior conformed well to the predictions of a Gaussian mixture model for semi-supervised learning. The human behavior differed from model predictions in other interesting respects, suggesting some fruitful avenues for future inquiry.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Semi-supervised learning-the effort to develop classifiers that can capitalize on both labeled and unlabeled training data-has attracted considerable interest in the machine learning community. New semi-supervised methods have significantly improved machine learning in various applications, including text categorization, computer vision, and bioinformatics, see <ref type="bibr" target="#b2">(Chapelle, Zien, &amp; Schölkopf 2006</ref>; Zhu 2005) for recent reviews. Given these successes, we ask the fundamental question: Do humans perform semisupervised classification? That is, do humans use "unlabeled data" in addition to "labeled data" to learn categories? If so, can we explain such behavior with mathematical models developed for semi-supervised machine learning? Answers to these questions may shed light on the cognitive process behind human learning, which may in turn lead to novel machine learning approaches <ref type="bibr" target="#b10">(Mitchell 2006;</ref><ref type="bibr" target="#b8">Langley 2006</ref>).</p><p>Many people would agree that the first answer seems to be "yes". After all, a child learns with supervision from parents and teachers, as well as without supervision by silently observing the world around her. Despite a significant amount of research in psychology on supervised and unsupervised learning (e.g., <ref type="bibr" target="#b9">(Love 2002</ref>) and the references therein), semi-supervised learning is not well studied. Although some prior research indirectly supports the above intuitions, e.g., <ref type="bibr" target="#b7">(Graf Estes et al. 2006;</ref><ref type="bibr">Tenenbaum &amp; Xu 2000)</ref>, we are aware of just one previous study that directly investigates semi-supervised learning in humans. Specifically, <ref type="bibr">Stromsten (2002, Chapter 3</ref>) used drawings of artificial fish to show that human categorization behavior can be influenced by the presence of unlabeled examples. Though certainly suggestive, this experiment had two limitations. First, Stromsten used a single positive labeled example and no negative labeled examples, making it a one-class setting similar to novelty detection or quantile estimation. Recent semi-supervised machine learning research has, in contrast, focused primarily on two-class classification with positive and negative examples. Second, since Stromsten used stimuli 1 that correspond to a familiar real-world concept (i.e. fish), it is difficult to know whether his results reflect prior knowledge about the category, or new learning obtained over the course of the experiment.</p><p>The current work describes a new study that clearly demonstrates one form of semi-supervised classification in humans. In a two-class learning paradigm, we show that the learned decision boundary is determined by both labeled and unlabeled data. In our experiment, participants view a series of visually complex shapes, and must guess to which of 2 categories each stimulus belongs. "Labeled" examples consist of trials for which the participant gets accurate feedback, and "unlabeled" examples consist of trials without feedback. Given the same labeled data but different unlabeled data, people form different decision boundaries. To account for this behavior, we propose that semi-supervised category learning in humans can be described with a generative mixture model, a traditional machine learning method <ref type="bibr" target="#b12">(Nigam et al. 2000)</ref>. Our paper thus takes the first steps toward designing and interpreting human learning experiments based on semi-supervised machine learning models. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Semi-Supervised Learning Task</head><p>We start by introducing a classic classification task in semisupervised machine learning. For simplicity, let us assume each example is represented by a one-dimensional feature x ∈ R. There are two classes y ∈ {1, 2}. Consider the following two scenarios: 1. We are given only two labeled training examples (x 1 , y 1 ) = (−1, 1) and (x 2 , y 2 ) = (1, 2). The best estimate of the decision boundary is x = 0: everything to the left should be classified as y = 1, while others as y = 2. 2. In addition to the two labeled examples above, we are also given a large number of unlabeled examples x 3 , . . . , x n . The correct class labels for these unlabeled examples are unknown. However we observe that they form two groups as in <ref type="figure" target="#fig_0">Figure 1</ref>. Under the assumption that examples in each class form a coherent group (e.g., follow a Gaussian distribution), our estimate of the decision boundary should be between the two groups instead (solid line in <ref type="figure" target="#fig_0">Figure 1</ref>).</p><p>Comparing the two scenarios in <ref type="figure" target="#fig_0">Figure 1</ref>, we expect to see a shift ∆ in the decision boundaries. The amount of shift depends on the particular distributions of labeled and unlabeled data. Intuitively, the decision boundary estimated from only labeled data may be unreliable, since the number of labeled examples is small. One can show that if the "coherent group" assumption is correct, unlabeled data will lead to a better estimate of the decision boundary 2 . This is a wellstudied semi-supervised machine learning method <ref type="bibr" target="#b1">(Castelli &amp; Cover 1996;</ref><ref type="bibr" target="#b13">Ratsaby &amp; Venkatesh 1995)</ref>, and has shown empirical successes <ref type="bibr" target="#b12">(Nigam et al. 2000;</ref><ref type="bibr" target="#b0">Baluja 1998)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Behavioral Experiment</head><p>Our study of human semi-supervised learning closely follows the above setting. We compare two scenarios: 1) the participant receives only labeled examples, which happen to be off the true class centers, versus 2) the participant also receives unlabeled examples sampled from the true class conditional feature distributions. Our goal is to determine whether the participant's category decision boundary shifts between the two scenarios. An appropriate shift would indicate that the participant's mental representations of the two categories take into account distributional information from the unlabeled data. <ref type="bibr">2</ref> Some cautionary notes are provided in <ref type="bibr" target="#b3">(Cozman, Cohen, &amp; Cirelo 2003</ref>) when the assumption is wrong. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants and Materials</head><p>Participants were 22 students from University of Wisconsin, participating for partial course credit.</p><p>In our experiment, each example is a 3D shape displayed to the subject on a computer screen. To keep later analysis simple, the examples are parameterized by a single parameter x. A similar setting was described by <ref type="bibr" target="#b11">Mozer, Jones, &amp; Shettel (2006)</ref>, who used circles of different sizes as the examples. Size, however, is a less than ideal parameter, first because people may bring relevant prior knowledge to the task (for instance, the knowledge that size varies continuously along an infinite range), and second because size is limited by what can be displayed on a computer screen. To avoid these difficulties, we generated novel, artificial 3D stimuli based on "supershapes" introduced in <ref type="bibr" target="#b6">(Gielis 2003)</ref>. The shapes change with x smoothly in several aspects simultaneously. <ref type="figure" target="#fig_2">Figure 2</ref> shows a few shapes and their x values. In our experiment the examples are organized into six sequential blocks. We refer to <ref type="figure" target="#fig_1">Figure 3</ref> in the following description.</p><p>Block 1 (labeled) consists of 2 labeled examples (x = −1, y = 1 and x = 1, y = 2) each appearing 10 times, with the total of 20 trials appearing in a different random order for each participant. The repetition of 2 items in this block ensures quick learning of the 2 distinct labeled examples.</p><p>Block 2 (test-1) consists of 21 evenly spaced unlabeled examples x = −1, −0.9, −0.8, . . . , 1, appearing in a different random order for each participant. We use them to test the learned decision boundary after Block 1.</p><p>Block 3 (unlabeled-1) is one of the three unlabeled data blocks. We sample 230 unlabeled examples from an equal mixture of two Gaussian distributions, representing the "true" concepts to be learned. Importantly, the means are shifted away from the labeled examples at x = −1 and x = 1: for 12 participants the two Gaussian distributions are shifted to the left, and for the other 10 participants they are shifted to the right, so that in both groups the labeled examples from Block 1 are not prototypical examples of each class. For the left-shifted mixture, we use</p><formula xml:id="formula_0">x ∼ 1 2 N(−1 − 1.28σ, σ 2 ) + 1 2 N(1 − 1.28σ, σ 2 ), (1)</formula><p>where N(µ, σ 2 ) is a Gaussian distribution with mean µ and variance σ 2 . We set the standard deviation σ = 1/3. We choose the shift ∆ = 1.28σ because 80% of the area under the Normal curve is within 1.28 standard deviation of the mean, which puts the labeled examples off the center, but not so extreme as to be outliers. Similarly, for the rightshifted mixture, we use</p><formula xml:id="formula_1">x ∼ 1 2 N(−1 + 1.28σ, σ 2 ) + 1 2 N(1 + 1.28σ, σ 2 )</formula><p>. In addition, we add 21 "range examples" evenly spaced in the interval x ∈ [−2.5, 2.5]. The range examples ensure that the unlabeled examples for both groups span the same range, so that any measured shift in the decision boundary cannot be explained by differences in the range of examples viewed. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Participants were told that they would see microscopic images of pollen particles from one of two fictitious flowers ("Belianthus" or "Nortulaca"), and were asked to classify each image by pressing the B or N key, respectively. They were instructed that they would receive audio feedback for the first 20 trials, after which they must make their best guess for a large set of items without any feedback. To ensure useful measurements of both speed and accuracy, participants were asked to respond as quickly as possible without making too many mistakes.</p><p>All participants saw the 815 stimuli in blocks 1 through 6 presented in order, but order within each block was randomized separately for each subject. In addition, 12 of the participants received Blocks 3,4,5 with left-shifted unlabeled stimuli (L-subjects), while the other 10 received rightshifted stimuli (R-subjects) <ref type="bibr">3</ref> .</p><p>Stimuli were displayed on a 15-inch CRT monitor in a darkened room at a normal viewing distance. The stimulus remained on-screen until a response was detected, after which the screen went blank for a duration of 1 second. Decisions and response times (time from onset of the stimulus to the detection of a key-press measured in milliseconds) were recorded for each trial. For each of the 20 stimuli in Block 1, the participants received an affirmative sound if they made the correct classification, or a warning sound if they were wrong. There was no audio feedback for the remaining stimuli.</p><p>The experiment manipulates one within-subjects factor (the category boundary is assessed either before or after exposure to the unlabeled data) and one between-subjects factor (unlabeled data distributions are shifted to the left or right of the labeled examples).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and discussion</head><p>Data from 1 subject in the left-shift condition were discarded, as the participant appeared to "give up" halfway through the experiment, making the same "N" response for virtually every stimulus. From the remaining subjects (11 in left-shift condition and 10 in right-shift condition), we make the following observations:</p><p>Unlabeled data helps determine the decision boundary. We compared the participants' classification on blocks test-1 vs. test-2. In test-1, we expect the decision boundary to be around x = 0 for all participants, because they have just seen the same 20 labeled examples at x = −1 and x = 1 <ref type="figure" target="#fig_1">(Figure 3)</ref>. If unlabeled data helps learning, the decision boundary in test-2 should shift towards left for L-subjects <ref type="figure" target="#fig_1">(Figure 3</ref>), or right for R-subjects. To quantify the decision boundary, we fit logistic regression functions p(y = 2|x) = 1/(1 + exp(−(βx + β 0 ))) to the data. For all participants on the test-1 block, the data consists of (x, ˆ y) pairs, wherê y ∈ {1, 2} is each participant's classification on x within test-1. <ref type="figure" target="#fig_4">Figure 4(a)</ref> shows the best fit (β = 4.99, β 0 = −0.54, the dotted curve). The decision boundary is x = −β 0 /β = 0.11 where p(y|x) = 0.5. This decision boundary is close to zero as expected <ref type="bibr">4</ref> . The curve is also relatively steep, showing that the participants are highly consistent on their classifications.</p><p>The best fit for R-subjects after seeing the unlabeled data is shown by the dashed curve (β = 3.00, β 0 = −1.44). The decision boundary is at x = 0.48. This represents a shift to the right of ∆ R = 0.37 on average, compared to the test-1 decision boundary. This shift represents the effect of unlabeled data on the R-subjects, and fits the expectation of semisupervised classification. For L-subjects on test-2, the best fit is the solid curve (β = 2.37, β 0 = 0.23). The decision boundary is at x = −0.10, which represents a shift to the left by ∆ L = −0.21, also consistent with semi-supervised learning. For visual inspection, we also show the empirical percentage of class 2 responses with different symbols in <ref type="figure" target="#fig_4">Figure 4</ref>(a). . Clearly the test-2 decision boundaries shift toward the expected directions. Symbols represent empirical fraction of participants classifying a particular x as class 2, within: L-subjects in test-1 (△), R-subjects in test-1 (•), L-subjects in test-2 (), and R-subjects in test-2 (•). (b) Seeing unlabeled data shifts the perception of 'difficult stimuli', as revealed by reaction time. The difficult stimuli in each case correspond well with the decision boundaries.</p><p>To test the statistical reliability of these observations, we fit a separate logistic function to each individual participant's decision data for blocks test-1 and test-2, and from these curves computed the decision boundary for each subject on each test. Thus for each subject we obtained an estimate of the decision boundary before and after exposure to the unlabeled data. These data were subject to a repeatedmeasures analysis of variance assessing the influence of test block (1 versus 2, within-sj factor) and group (left-shift versus right-shift, between-sjs factor) on the location of the decision boundary. The results showed a significant interaction between the two factors (F(1,18) = 7.82, p &lt; 0.02), indicating that after exposure to the unlabeled data, the decision boundary shifted in significantly different directions for the two groups.</p><p>Reaction time reflects decision boundary shift. Reaction time is the time elapsed between the appearance of the stimulus and the detection of a response-a long reaction time implies that the stimulus is relatively difficult to classify. It follows that stimuli near the decision boundary will be associated with longer reaction times. If the unlabeled data shift the participant's mental representation of the decision boundary, this shift should be reflected by a shift in the peak reaction time. <ref type="figure" target="#fig_4">Figure 4</ref>(b) verifies this hypothesis. <ref type="figure">The Fig- ure</ref> shows mean reaction times (excluding outliers more than ±3 beyond log reaction time) for each stimulus in the first test block, computed over all participants (squares in <ref type="figure" target="#fig_4">Fig- ure 4(b)</ref>). The dotted curve shows the same data smoothed with a Gaussian kernel smoother. After seeing just the labeled examples at -1 and 1, people react quickly to examples near these points (rt ≈ 600ms), but are much slower (≈800ms) for examples 'in the middle', that is, near the decision boundary. The peak is slightly to the right of the nominal decision boundary x = 0 for an unknown reason, which is consistent with <ref type="figure" target="#fig_4">Figure 4(a)</ref>.</p><p>We then compute the average reaction time on block test-2 separately for L-subjects (black triangles and solid curve in the <ref type="figure">Figure)</ref> and R-subjects (black dots and dashed curve in the <ref type="figure">Figure)</ref>. The overall reaction time on test-2 is faster than on test-1, reflecting the participants' greater familiarity with the experiment. More importantly, L-subjects have a reaction time plateau around x = −0.1, which is left-shifted compared to test-1, whereas R-subjects have a reaction time peak around x = 0.6, which is right-shifted. In line with the accuracy data, the reaction times suggest that exposure to the unlabeled data has shifted the decision boundary in different directions in the two groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Semi-Supervised Model</head><p>In this section we consider whether the boundary-shifts reflected in the behavioral data are consistent with those predicted by a model developed for semi-supervised machine learning. We assume humans represent each category with a central prototype and a spread around the prototype. This allows us to model each category using a Gaussian distribution, whose mean and variance characterizes the prototype and the spread, respectively. Therefore our binary classification experiment can be modeled with a Gaussian mixture model (GMM) with two components 5 , parameterized by θ = {w 1 , µ 1 , σ 2 1 , w 2 , µ 2 , σ 2 2 }. The w's are non-negative component weights that sum to 1.</p><p>Before seeing any examples, we assume a prior distribution over θ. Learning involves updating the GMM parameters to best explain the observed labeled and unlabeled examples. One approach is to perform Bayesian analysis and compute the posterior distribution of θ (Tenenbaum 1999). However, to keep the model comparable with the existing semi-supervised learning literature <ref type="bibr" target="#b12">(Nigam et al. 2000)</ref>, we instead compute the maximum a posteriori (MAP) point estimate of θ. We assume exchangeability and let D = {(x 1 , y 1 ), . . . , (x l , y l ), x l+1 , . . . , x n } be the set of l labeled and n − l unlabeled examples seen so far. The MAP estimate argmax θ p(θ|D), which represents the updated internal model, can be found (up to local maxima) with the standard EM algorithm <ref type="bibr" target="#b4">(Dempster, Laird, &amp; Rubin 1977)</ref>. We use a factored, semi-conjugate prior distribution <ref type="bibr">(Gel- man et al. 2004</ref>) on θ: <ref type="figure" target="#fig_2">s 2 )</ref>, k = 1, 2. Our priors are fairly benign: w k is uniform over its range, and µ k has a non-informative prior, making no assumption on what it might be. σ 2 k has a scaled inverse-χ 2 distribution with scale s 2 and ν degrees of freedom, which is equivalent to ν pseudo observations with average squared deviation s 2 . This prevents degeneracy in Gaussian variances. In our experiment we set ν = 1, and s 2 = 25 12 which is the variance of the uniform distribution over the range [−2.5, 2.5].</p><formula xml:id="formula_2">p(θ) = 2 k=1 p(w k )p(µ k )p(σ 2 k ), with w k ∼ Uniform[0, 1], µ k ∼ N(0, ∞), and σ 2 k ∼ Inv−χ 2 (ν,</formula><p>We want to find θ that maximizes the posterior, which is equivalent to maximizing log p(θ)p(D|θ). The latter equals</p><formula xml:id="formula_3">log p(θ) + l i=1 log p(x i , y i |θ) + λ n i=l+1 log p(x i |θ). (2)</formula><p>This objective is 'semi-supervised' because unlabeled data helps learning through the last term. To account for the possibility that an unlabeled example is perceptually 'worth less' than a labeled example, we introduced a weight λ above that can down-scale the contribution of unlabeled data. Such weight is common in prior work <ref type="bibr" target="#b3">(Corduneanu &amp; Jaakkola 2001;</ref><ref type="bibr" target="#b12">Nigam et al. 2000)</ref>.</p><p>The objective <ref type="formula">(2)</ref> is difficult to optimize directly because the parameters are coupled in the log p(x i |θ) term. It is, however, not hard to derive the EM updates for our specific model. The derivation is standard and omitted for space considerations. We introduce hidden label distributions for each unlabeled example: q i (k) = p(y i = k|x i , θ) for i = l + 1, . . . , n and k = 1, 2. EM consists of iterating between the E-step and the M-step until convergence, which is guaranteed since our prior is log-concave. The Estep finds the expected distribution on hidden labels, given current model parameters θ:</p><formula xml:id="formula_4">q i (k) ∝ w k N(x i ; µ k , σ 2 k ), i = l + 1, . . . , n; k = 1, 2. (3)</formula><p>The M-step updates the model parameters, given q i (k) above:</p><formula xml:id="formula_5">µ k = l i=1 δ(y i , k)x i + λ n i=l+1 q i (k)x i l i=1 δ(y i , k) + λ n i=l+1 q i (k) σ 2 k = νs 2 + l i=1 δ(y i , k)e ik + λ n i=l+1 q i (k)e ik ν + 2 + l i=1 δ(y i , k) + λ n i=l+1 q i (k) w k = l i=1 δ(y i , k) + λ n i=l+1 q i (k) l + λ(n − l) ,<label>(4)</label></formula><p>where δ(y i , k) = 1 if y i = k, and 0 otherwise; e ik = (x i − µ k ) 2 . Once the MAP θ is found through EM, prediction can be made with the Bayes rule,</p><formula xml:id="formula_6">p(y|x) = wyN(x;µy,σ 2 y ) P k=1,2 w k N(x;µ k ,σ 2 k )</formula><p>. The corresponding decision boundary x can be found through the equation w 1 N(x; µ 1 , σ 2 1 ) − w 2 N(x; µ 2 , σ 2 2 ) = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Fitting Results</head><p>The model predicts decision boundary shift. To model the participants' behavior on block test-1, we fit a GMM with EM on labeled and unlabeled data in blocks 1,2 (with initial parameters w k = 0.5, µ k = 0, σ 2 k = 1, and unlabeled data weight λ = 0.06, see below). This corresponds to a hypothetical subject who just saw blocks 1,2 6 . The GMM is 0.5N(−0.97, 0.17) + 0.5N(0.97, 0.17), whose classification is shown as the dotted curve in <ref type="figure" target="#fig_6">Fig- ure 5(a)</ref>, which corresponds to the empirical data (also dotted curve) in <ref type="figure" target="#fig_4">Figure 4(a)</ref>. Then for the behavior on block test-2, we fit two GMMs on blocks 1-6 (results on blocks 1-5 are similar): For L-subjects who saw leftshifted unlabeled data in blocks 3,4,5, the fitted GMM is  <ref type="figure" target="#fig_0">49N(1.26, 0.18)</ref>. These two GMMs thus predict shifts of the decision boundary after seeing unlabeled data. We show their classification curves (solid and dashed) in <ref type="figure" target="#fig_6">Figure 5</ref>(a), which qualitatively explains the empirical behavior in <ref type="figure" target="#fig_4">Figure 4</ref>(a). Unlabeled example weight λ controls the amount of decision boundary shift. The predicted amount of decision boundary shift is controlled by λ, the unlabeled example weight. By assigning an unlabeled example a small weight (λ &lt; 1 in <ref type="formula">(2)</ref>), the shift is reduced as in <ref type="figure" target="#fig_6">Figure 5</ref>(b). This makes intuitive sense: As λ → 0, the effect of unlabeled blocks diminishes, and both GMMs converge to the GMM trained on block 1 only. To account for the observed distance of 0.58 between L, R decision boundaries in <ref type="figure" target="#fig_4">Figure 4(a)</ref>, λ ≈ 0.06. This seems to indicate that people treat unlabeled examples less importantly than labeled examples. The model explains reaction time. We model the reaction time with a sum of two parts: The first part is a base reaction time which decreases with experience. Let it be b 1 at block test-1, and a smaller b 2 later at test-2. The second part is proportional to the difficulty of each particular example. We assume if p(y|x) is close to 0 or 1, the example x is easy because the classification is clear; x is difficult if p(y|x) is close to 0.5. A natural measure of difficulty is the entropy of the prediction h(x) = − 2 k=1 p(y = k|x) log p(y = k|x), which is zero for p(y|x) = 0 or 1, and one for p(y|x) = 0.5. Our reaction time model is thus ah(x) + b i for block test-i. We find the parameters a = 168, b 1 = 688, b 2 = 540 with least squares from the empirical data in <ref type="figure" target="#fig_4">Figure 4(b)</ref>. Our reaction time model is plotted in <ref type="figure" target="#fig_6">Figure 5(c)</ref>, which explains the empirical peaks before and after seeing unlabeled data in <ref type="figure" target="#fig_4">Figure 4</ref>(b).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions and Discussion</head><p>We have designed and conducted a behavioral experiment that clearly demonstrates a form of semi-supervised learning in humans. Participants quickly learned from labeled data and set a stable category boundary midway between the labeled items. After exposure to a set of unlabeled examples, however, the category boundaries shifted to reflect the distributions from which the unlabeled examples were drawn. The boundary-shifts were reflected both in the categorization decisions and in the mean reaction times. We have also suggested that the boundary-shifts are well accounted for by a Gaussian mixture model of semisupervised learning that has been successfully applied in machine learning. The GMM suggests that mental representations of categories consist of both the central tendency and the spread, and that these parameters are estimated from both labeled and unlabeled data.</p><p>One aspect of the behavioral data is not well explained by the GMM: decision curves after exposure to the unlabeled data were noticeably flatter than predicted. This apparent flattening is not an artifact of averaging across subjects-the slope of the logistic function estimated separately for each subject was significantly steeper before exposure to the unlabeled data than afterward (F(1,18) = 5.3, p &lt; 0.04). In fact this flattening effect would be expected if participants systematically over-estimated the variance associated with each category. This interesting discrepancy in model and human behavior may therefore indicate important differences in human and machine memory. For instance, the current model retains a faithful representation of all past examples, and uses this perfect record to generate optimal estimates of the corresponding distributions. In human memory, traces of individual examples may degrade with time or may be subject to interference, so that decisions in the moment strongly weight more recent experiences. Future work will investigate these possibilities.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The additional knowledge of unlabeled data produces a better decision boundary.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Data used in our behavioral experiment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Our experiment uses a large number of 3D shape visual stimuli, parameterized by a continuous scalar x. A few examples are shown above with the corresponding x values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Block 4, 5 (unlabeled- 2 , 3 )</head><label>523</label><figDesc>are identical to Block 3, each with the same 21 range examples, but with a different 230 random samples from the Gaussian mixture in Block 3. Blocks 3,4,5 are always all left-shifted or all right-shifted. Block 6 (test-2) is identical to Block 2, consisting of 21 unlabeled examples evenly spaced in [−1, 1]. They are used to test whether the participant's decision boundary has changed after seeing the unlabeled blocks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: (a) Unlabeled data helps classification. The curves are fitted logistic regression functions p(y = 2|x). Clearly the test-2 decision boundaries shift toward the expected directions. Symbols represent empirical fraction of participants classifying a particular x as class 2, within: L-subjects in test-1 (△), R-subjects in test-1 (•), L-subjects in test-2 (), and R-subjects in test-2 (•). (b) Seeing unlabeled data shifts the perception of 'difficult stimuli', as revealed by reaction time. The difficult stimuli in each case correspond well with the decision boundaries.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>0 .</head><label>0</label><figDesc>49N(−1.26, 0.20)+0.51N(0.71, 0.21). For R-subjects the GMM is 0.51N(−0.74, 0.20) + 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Our semi-supervised Gaussian mixture models (GMMs) explain experimental data.</figDesc></figure>

			<note place="foot" n="1"> We use stimulus and example interchangeably.</note>

			<note place="foot" n="3"> Data from 2 additional participants in the right-shift condition were lost when the computer crashed halfway through the experiment.</note>

			<note place="foot" n="4"> It is not exactly zero because of small sample size, and potentially because the perceptual distance along the x-axis is not completely uniform. This, however, does not affect our conclusions.</note>

			<note place="foot" n="5"> This GMM is a cognitive model, not to be confused with the unlabeled-data-generating GMM in Blocks 3,4,5.</note>

			<note place="foot" n="6"> Alternatively, we can fit a GMM on block 1 only, the result is similar and not reported here. We can also fit a sequence of GMMs per subject one example at a time, following the exact randomized data stream in the blocks. Such detailed modeling gives very similar results here and below, and is not reported.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Probabilistic modeling for face orientation discrimination: Learning from labeled and unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baluja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The relative value of labeled and unlabeled samples in pattern recognition with an unknown mixing parameter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Castelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Information Theory</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2101" to="2117" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Stable mixing of complete and incomplete information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Corduneanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">;</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cozman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cirelo</surname></persName>
		</author>
		<idno>AIM-2001- 030</idno>
	</analytic>
	<monogr>
		<title level="m">ICML-03</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
<note type="report_type">Technical Report</note>
	<note>Semi-supervised learning of mixture models</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rubin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society, Series B</title>
		<imprint>
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Bayesian data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Carlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Chapman &amp; Hall/CRC</publisher>
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A generic geometric transformation that unifies a wide range of natural and abstract shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gielis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Botany</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="333" to="338" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Can infants map meaning to newly segmented words? Statistical segmentation and word learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Graf Estes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Alibali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Saffran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Intelligent behavior in humans and machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Langley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Comparing supervised and unsupervised category learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Love</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="829" to="835" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The discipline of machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
		<idno>CMU-ML-06-108</idno>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Context effects in category learning: An investigation of four probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mozer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shettel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Text classification from labeled and unlabeled documents using EM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2/3</biblScope>
			<biblScope unit="page" from="103" to="134" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Learning from a mixture of labeled and unlabeled examples with parametric side information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ratsaby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
		<respStmt>
			<orgName>COLT</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Classification learning from both classified and unclassified examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Stromsten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Cognitive Science Society</title>
		<editor>Ph.D. Dissertation, Stanford. Tenenbaum, J. B., and Xu, F.</editor>
		<meeting>Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note>Word learning as Bayesian inference</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">A Bayesian framework for concept learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
	<note>Ph.D. Dissertation, MIT</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Semi-supervised learning literature survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<idno>1530</idno>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
		<respStmt>
			<orgName>Univ. Wisconsin-Madison</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
