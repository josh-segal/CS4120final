<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:51+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unsupervised Learning of Soft Patterns for Generating Definitions from Online News</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Cui</surname></persName>
							<email>cuihang@comp.nus.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science School of Computing</orgName>
								<orgName type="institution">National University of Singapore Singapore</orgName>
								<address>
									<postCode>117543</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science School of Computing</orgName>
								<orgName type="institution">National University of Singapore Singapore</orgName>
								<address>
									<postCode>117543</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
							<email>chuats@comp.nus.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science School of Computing</orgName>
								<orgName type="institution">National University of Singapore Singapore</orgName>
								<address>
									<postCode>117543</postCode>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Unsupervised Learning of Soft Patterns for Generating Definitions from Online News</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H33 [Information Systems]: Information Search and Retrieval - Relevance feedback</term>
					<term>Retrieval models</term>
					<term>Search process</term>
					<term>Selection process General Terms Algorithms</term>
					<term>Experimentation Keywords Definition generation</term>
					<term>definitional question answering</term>
					<term>soft patterns</term>
					<term>pseudo-relevance feedback</term>
					<term>unsupervised learning</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Breaking news often contains timely definitions and descriptions of current terms, organizations and personalities. We utilize such web sources to construct definitions for such terms. Previous work has identified definitions using hand-crafted rules or supervised learning that constructs rigid, hard text patterns. In contrast, we demonstrate a new approach that uses flexible, soft matching patterns to characterize definition sentences. Our soft patterns are able to effectively accommodate the diversity of definition sentence structure exhibited in news. We use pseudo-relevance feedback to automatically label sentences for use in soft pattern generation. The application of our unsupervised method significantly improves baseline systems on both the standardized TREC corpus as well as crawled online news articles by 27% and 30%, respectively, in terms of F measure. When applied to a state-of-art definition generation system recently fielded in the TREC 2003 definitional question answering task, it improves the performance by 14%.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>With the rapid expansion and ubiquity of the Web, the public often learns about breaking stories and developments in online news. New terms and personalities, such as Enron, Clay Aiken and SARS, which are of great interest to the public, are often described in such media. These emerging and constant changing terms and personalities can often be found only in breaking news web sites, but not in authoritative sources of definitions, such as dictionaries or encyclopedias. Traditional web searching is only part of the solution: on such a topic, a search can retrieve relevant web pages from news sites, but cannot filter these pages down to a single, coherent definition. To synthesize a complete definition of any such entity requires the identification and collation of definition sentences across relevant articles.</p><p>We focus on identifying definition sentences from relevant news articles for recent terms for which structured knowledge bases (i.e., WordNet, Internet-accessible glossary, or machine readable dictionary) have no definition. A definition sentence contains descriptive information that can be included in an extended definition of the term. Such an "extended definition" answers not only "what/who is X?", but also "what/who is X like?" <ref type="bibr" target="#b7">[7]</ref>. To create a final coherent definition, sentence editing and re-ordering may be employed, but are beyond the scope of this paper.</p><p>Most approaches applicable to our problem formulation use some form of pattern matching to identify definition sentences. <ref type="bibr" target="#b5">[5]</ref> employed a simple method which defines several manuallyconstructed definition patterns to extract definition phrases. <ref type="bibr" target="#b17">[17]</ref> and <ref type="bibr" target="#b1">[2]</ref> summarized syntactic components, such as appositives and predicates, using generic rules learned from annotated corpus. <ref type="bibr" target="#b9">[9]</ref> proposed to mine topic-specific definitions using hand-crafted rules to find definition sentences in web pages. These approaches have two shortcomings that we have identified and address in this work:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1.</head><p>Pattern inflexibility: Whether using corpus-based learning techniques or manually creating patterns, to our knowledge all previous systems create hard-coded rules that require strict matching (i.e., matching slot by slot). Although such hard patterns are widely used in information extraction <ref type="bibr" target="#b10">[10]</ref>, we feel that definition sentences display more variation and syntactic flexibility that may not be captured by hard patterns. In contrast, we propose a novel method which utilizes soft-matching patterns. Soft patterns take each slot as a vector of words and syntactic classes with their distributions, rather than generalizing specific instances to induce rules. This allows us to match test instances against the patterns using a probabilistic similarity measure. The learned soft patterns are used to judge whether sentences are definitional.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>Manual labor: Manually constructed definition patterns are also limited by the ability of the developer to exhaustively enumerate all applicable patterns, known to be a difficult problem. Lack of pattern coverage results directly in low recall. Supervised learning can compensate for this weakness to some extent, but is limited by the availability of annotated corpora, which requires intensive labor and hinders the portability to other domains. In contrast, our soft patterns can be learned in an unsupervised manner. While our approach to soft pattern learning is robust to noise, we apply pseudo-relevance feedback (PRF) to boost the quality of the initial retrieval set of definition sentences. By applying PRF before soft pattern induction, we can skip the laborious tasks of corpus annotation and pattern construction.</p><p>To demonstrate the effectiveness of our techniques, we have implemented a fully-functional definition generation system which constructs definitions for terms or person names by extracting definition sentences from relevant input news articles.</p><p>That system can also be treated as a definitional QA system <ref type="bibr" target="#b20">[20]</ref> because it provides direct answers to definition questions. We carry out a series of extrinsic evaluations to assess the performance of soft pattern matching and pseudo relevance feedback, and to assess their portability to the web. Our experiments used the TREC corpus to test our system in a community-standardized evaluation, and on a corpus of crawled news articles from eight news sites to demonstrate the applicability to the web. Both experiments show significant improvement over baseline systems.</p><p>We discuss our method of soft pattern generalization and matching in the next section. Section 3 describes the architecture of our definition generation system, including details of our application of PRF to automatically label the training data for soft pattern generalization. We describe our experiments with the system framework in Section 4 and complete the paper with a discussion of related work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">SOFT MATCHING PATTERNS</head><p>At the heart of many definition generation systems is a process of identifying and selecting definition sentences. Many of these systems base their sentence selection either wholly or partially on pattern matching. In previous work, hand-crafted <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b9">9]</ref> or machine learned <ref type="bibr" target="#b1">[2]</ref> rules played a crucial role. Definition patterns also exist in news articles. This is supported by the observation that journalists often give explanations to those terms or people unfamiliar to the public and that they write such introductions in a regular manner. For example, appositives are a common pattern used to introduce a term or a person in news (e.g., "Gunter Bloebel, a cellular and molecular biologist, …"). To make their writing more appealing to the public, news writers often exhibit great variations in wording and structuring of such definitions. Traditional hard matching rules are too rigid to accommodate such diversified patterns in definition sentences.</p><p>In this study, we augment the soft matching method advocated by Nahm and Mooney <ref type="bibr" target="#b11">[11]</ref> and apply it to the problem of extracting definition patterns. They represented patterns by simple lexical tokens and employed cosine similarity to match patterns, similar to the technique employed by Agichtein and Gravano <ref type="bibr" target="#b0">[1]</ref>. We augment their approach by: a) combining lexical tokens alongside part-of-speech classes and punctuations; and b) adopting a probabilistic framework that combines slot content and sequential fidelity in computing the degree of pattern match.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Generalizing Pattern Instances</head><p>Given a group of potential definition sentences, our system learns local contextual patterns surrounding the given search term. We do not handle long-distance dependencies, as our observations show that definition sentences are identified mainly by adjacent words and punctuations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. Illustration of generalizing soft definition patterns</head><p>The process of generalizing pattern instances is presented in <ref type="figure">Figure 1</ref>. The labeled definition sentences are first processed with part-of-speech (POS) tagging and chunking by a natural language tagger and chunker 1 . We then perform selective substitution of certain lexical items by their syntactic classes in order to generate representative patterns. The substitution attempts to replace words that are specifically related to the search term with more general tags so that the patterns can be applied to other sentences.</p><p>The substitution rules that we use and some examples are listed in <ref type="table" target="#tab_0">Table 1</ref>. In <ref type="table" target="#tab_0">Table 1</ref>, centroid words are those words that are highly correlated to the search term, as judged by mutual information. We explain this in depth in Section 3.1. The lexical forms of these words are too specific to the search term to help form general definition patterns and hence are replaced by their part-of-speech. Likewise, we perform the same substitution to noun phrases identified by chunking as different scenarios usually do not share the same noun phrase instances. Finally, we combine the adjacent syntactic tags of the same type into one. All other general words and punctuations are left unchanged.</p><p>Our algorithm is designed specifically to capture obscure patterns.</p><p>To demonstrate this, we give an example of a definition pattern that is not likely to be covered by previous work. The example does not describe a direct definition but indicates some important properties of the search term, which should be included in its extended definition. Given a definition sentence for "Iqra":</p><p>The channel Iqra is owned by the Arab Radio and Television company and is the brainchild of the Saudi millionaire, Saleh Kamel.</p><p>the sentence is transformed into a token sequence comprising syntactic tags, words and punctuations as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DT$ NN &lt;SCH_TERM&gt; BE$ owned by DT$ NP and BE$ DT$ brainchild of NP.</head><p>In order to generate general patterns, we need to consider the "context" around the &lt;SCH_TERM&gt;. The context is modeled as a window centered on &lt;SCH_TERM&gt; according to the pre-defined size w, i.e. the number of slots (or tokens) on both sides of &lt;SCH_TERM&gt;. Thus we get fragments with size 2w+1 including the search term. We refer to such fragments as pattern instances on which the generic soft patterns are generated. For example, the pattern instance from the above sentence is (w=3):</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DT$ NN &lt;SCH_TERM&gt; BE$ owned by</head><p>Accumulating all the pattern instances extracted from the definition sentences and aligning them according to the positions of &lt;SCH_TERM&gt;, we obtain a virtual vector representing the soft definition patterns. The pattern vector Pa is denoted as:</p><formula xml:id="formula_0">&lt;Slot -w , ……, Slot -2 , Slot -1 , SCH_TERM , Slot 1 , Slot 2 , …… Slot w : Pa&gt;</formula><p>where Slot i contains a vector of tokens with their probabilities of occurrence:</p><formula xml:id="formula_1">&lt;(token i1 , weight i1 ), (token i2 , weight i2 ) ……(token im , weight im ) : Slot i &gt;</formula><p>Here token ij denotes any word, punctuation or syntactic tag contained in Slot i ; and weight ij gives the importance of the j th token to the i th slot. weight ij can be expressed as the conditional probability of the token occurring in that slot. Thus it can be approximated by:</p><formula xml:id="formula_2">∑ = = m s is ij i ij token f token f Slot token 1 ) ( ) ( ) | Pr( (1)</formula><p>where f(token is ) stands for the number of occurrences of token is within Slot i . As syntactic classes occur more frequently than lexical tokens, we discount the occurrences of syntactic classes and punctuations by a factor accounting for the proportion of words to syntactic tags. This discounting factor is used to achieve a good balance in the distribution and is empirically set to 0.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Soft Pattern Matching</head><p>What results from the generalization process is a virtual vector Pa with a set of associated probabilities for slot fillers at each slot. The soft pattern vector Pa is then used to calculate the degree to which a test sentence matches the sentences used to construct the soft patterns. The test sentences are first preprocessed with the identical procedures of POS tagging and chunking, as well as substitution as we did to the labeled definition sentences. Using the same window size w, the token fragment S surrounding the &lt;SCH_TERM&gt; is retrieved:</p><formula xml:id="formula_3">&lt;token -w , ……, token -2 , token -1 , SCH_TERM, token 1 , token 2 , …… token w : S&gt;</formula><p>The matching degree of the test sentence to the generalized definition patterns is measured by the similarity between the vector S and the virtual soft pattern vector Pa. The matching degree is calculated in two parts. The first part calculates the degree of similarity between individual slots, while the second part examines sequence fidelity. In the first part, we compute Pa_weight Slots by assuming that all slots are independent to each other. We use Naïve Bayes to calculate the matching score:</p><formula xml:id="formula_4">∏ − = = = w w i i i Slots Slot token Pa S weight Pa ) | Pr( ) | Pr( _ (2)</formula><p>Specifically, we combine all the weights calculated in Equation <ref type="formula">(1)</ref> to derive the similarity for independent slots. This equation is very flexible in matching the soft patterns because it considers only individual slots. Even if some slots are missing, it still can give a similarity measure to the definition patterns.</p><p>The second part of the matching metric considers the sequence of tokens, to filter out unlikely token sequences to increase precision.</p><p>We adopt a bigram model to formulate this sequence measure. Specifically, given a token sequence T, we calculate the conditional probability of Pr(T|Pa) which models how likely the sequence occurs according to the underlying soft patterns. We calculate the sequence probability for the left and the right sequences starting from &lt;SCH_TERM&gt;. The probability of the right sequence is calculated as follows:</p><formula xml:id="formula_5">) | ( ) | ( ) ( ) | , Pr( ) | _ Pr( 1 1 2 1 2 1 − = = w w w token token P token token P token P Pa token token token Pa seq right L L (3)</formula><p>where P(token i |token i-1 ) is estimated by counting the occurrences of the bigram &lt;token i-1 token i &gt; and the unigram token i-1 as:</p><formula xml:id="formula_6">) ( ) ( ) | ( 1 1 1 − − − &gt; &lt; = i i i i i token f token token f token token P (4)</formula><p>The process for calculating the probability of the left sequence is formally identical. In addition, P(token -1 ) and P(token 1 ) can be estimated based on the proportion of occurrences of the token in Who is Aaron Copland?</p><p>Some composers, like Aaron Copland, Virgil Thomson, George Gershwin, and Leonard Bernstein set out quite self-consciously to create an`` an``American'' music; other American composers, like Roger Sessions, resisted such impulses and tried to compose in an``an``international'' vein _ although, with distance, it is hardly possible to hear Sessions as any less`` less``American'' than Copland.</p><p>Gore took about an hour and a half out of his labor supplications to rehearse at Avery Fisher Hall for his nighttime performance, in which he was to narrate Aaron Copland's 1942 classic, ``Lincoln Portrait,'' accompanied by the American Symphony Orchestra, under the direction of Leon Botstein.</p><p>``Appalachian Spring' <ref type="bibr">' (1944)</ref>, the greatest ballet in the Americana genre, found Copland composing his third great ballet score, this time for Martha Graham, resulting in a powerful, evocative paean to American frontier life.</p><p>How often does one get to hear``hear``Connotations'' for orchestra, the beautifully severe 12-tone work that Copland wrote for the 1962 inaugural concert of Philharmonic Hall (now Avery Fisher Hall), which was conducted by Leonard Bernstein, the composer's most ardent disciple.</p><p>Even the best American classical music bears its stamp: witness Aaron Copland, whosè`American-sounding'' music was composed by a Brooklyn-born Jew of Russian lineage who studied in France and salted his scores with jazz-derived syncopations, Mexican folk tunes and cowboy ballads.</p><p>Copland, who died 10 years ago, was one of the first classical composers writing for audiences raised on radio and movie music.</p><p>Aaron Copland, who died in 1990, must have winced a bit when, late in life, he found himself proclaimed America's greatest composer. the immediately left and right slots to &lt;SCH_TERM&gt;. The sequence weight of the token vector for the sentence, denoted by Pa_weight Seq , consists of the weights of its left sequence and right sequence which are calculated by Equation (3):</p><formula xml:id="formula_7">) | _ Pr( ) | _ Pr( ) 1 ( _ Pa seq right Pa seq left weight Pa Seq ⋅ + ⋅ − = α α (5)</formula><p>Based on our observations of definition, the right context of the search term is more important in indicating a definition sentence, thus we set α to 0.7.</p><p>The bigram model may encounter the common problem of sparse data. But it is not a serious issue in our case because: (a) we use it just as a precision device to reduce the weight of those less possible sequences; and (b) we use large training set that we construct automatically using PRF, to be discussed in Section 3.2.</p><p>Finally, the aforementioned two similarity weights determine the overall pattern weight of the given sentence:</p><formula xml:id="formula_8">length fragment weight Pa weight Pa weight Pattern Seq Slots _ _ _ _ × = (6)</formula><p>where the length of the fragment S is used as the normalization factor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DEFINITION GENERATION SYSTEM ARCHITECTURE</head><p>To demonstrate the effectiveness of soft matching patterns, we implemented a definition generation system which constructs definitions by extracting definition sentences from online news articles. The system's architecture and an example output definition for the question "Who is Aaron Copland?" are presented in <ref type="figure" target="#fig_0">Figure 2</ref>.</p><p>The input to the system is a set of relevant documents retrieved in response to a group of questions by an IR system. We then apply anaphora resolution to the documents and conduct passage retrieval to increase precision. The passage retrieval filters out all sentences that are not within a one-sentence window of a search term occurrence.</p><p>The steps in our system are outlined in <ref type="figure">Figure 3</ref>. All input sentences are first ranked statistically by a centroid-based statistical method. The system then takes the top n ranked sentences from the list and deems them as definition sentences (whether they are or not) in a pseudo relevance feedback loop. These automatically labeled sentences are fed into the pattern learning module where the soft patterns are generated. In the second round of ranking, the soft patterns and centroid weights jointly decide whether a sentence is labeled as definitional. Definition sentences from this final pool are selected to create the output definition using a diversity-based sentence selection algorithm. As the system's primary distinction from other definitional QA systems is its use of soft patterns and pseudorelevance feedback, we denote it as SP+PRF in the remainder of the paper.</p><p>As soft pattern generalization and matching have been discussed in Section 2, we detail the remaining steps in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3. Working process of the pipeline system</head><p>Input: a set of questions and corresponding relevant sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1.</head><p>First round of ranking (statistical ranking) -Rank all input sentences statistically. In this work, we employ the centroid based method to accomplish the first round of ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>Pseudo-relevance feedback -Take all the top n ranked sentences (n=10) for each question from the statistical ranking as labeled definition sentences. 3a. Soft pattern generalization -Prepare the pattern instances and generalize the soft pattern vector from the pattern instances (see Section 2.1).</p><p>3b. Second round of ranking (incorporating soft pattern matching) -Re-rank the sentences combining the statistical centroid based weights and pattern matching weights (see Section 2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>Sentence selection -Produce the final definition according to the length requirement. Document summarization techniques are adopted to avoid introducing redundancy in constructing the definition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Step 1: Centroid Words Selection and Statistical Ranking</head><p>Given a set of input documents related to a person or term, our system first ranks its sentences in terms of their likelihood of containing a definition. To ensure recall, i.e., covering most aspects of the term or person, and to provide a basis for performing PRF, we first adopt a data-driven, centroid-based method to perform this ranking.</p><p>We identify a set of highly relevant topical words, which we term as centroid words. Similar to <ref type="bibr" target="#b13">[13]</ref>, we grouped the selected centroid words into a centroid vector, which is utilized to rank input sentences. Radev et al. <ref type="bibr" target="#b13">[13]</ref> uses global TF×IDF weights within documents to select those words which are most representative across the entire documents. However, in our context, these centroid words should bear very specific information describing the search term. As such, we adopt a local centrality metric of words with respect to the search term based on their co-occurrences with the search term within sentences. The rationale is that the search terms tend to appear with their descriptive sentences within news articles. As a news article usually describes multiple terms and persons, descriptive sentences are likely to repeat the search term rather than using other forms of reference. Our sentences have also been processed by an anaphora resolution module. As such, cooccurrence based metric is able to capture the local importance of words to the search terms without losing recall.</p><p>The co-occurrences of words can be measured by using the metrics described in <ref type="bibr" target="#b8">[8]</ref>, which constructs topic signatures for document summarization. We employ mutual information as the measurement of co-occurrences for simplicity. All the words, after removing stop words, are stemmed before calculating their centrality. The equation for calculating the centrality Centrality sch_term (w) of a word w is as follows: </p><formula xml:id="formula_9">) ( ) 1 ) _ ( log( ) 1 ) ( log( ) 1 ) _ , (<label>log( )</label></formula><p>where Co(w, sch_term) denotes the number of sentences where w co-occurs with the search term sch_term; and sf(w) gives the number of sentences containing the word w. We also use the inverted document frequency of w, idf(w), as a measurement of its global importance 2 .</p><p>Centrality scores for all words appearing in the input sentences are calculated and those words whose scores exceed the average plus a standard deviation form a set of centroid words. These centroid words form a centroid vector. Input sentences, which are also represented as vectors after tokenization and stemming, are compared against the centroid vector using cosine similarity. Sentences that rank highly are more likely to be definitional after this first pass.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Step 2: Unsupervised Labeling Using PRF</head><p>In order to perform soft pattern generalization, a set of labeled definition sentences should be provided as training instances, as is done in rule induction based on labeled data <ref type="bibr" target="#b15">[15]</ref>.</p><p>Step 1 automatically ranks sentences from the input documents, using words that are highly correlated with the search terms as indicators. To automatically decide whether a sentence is definitional, we could use a simple cutoff in which sentences that are ranked more highly are considered definitional. This is similar to the work by Sudo et al. <ref type="bibr" target="#b19">[19]</ref> who proposed unsupervised learning method for pattern discovery by utilizing TF-IDF weight to select a set of relevant documents and sentences, and then built patterns from them.</p><p>Similarly, we use a pseudo-relevance feedback (PRF) strategy. In standard pseudo-relevance feedback (also known as blind feedback or local feedback) used in document retrieval, for each query, the top n ranked documents are deemed relevant and used to modify the query to retrieve a new set of documents <ref type="bibr" target="#b3">[3]</ref>. We employ the same technique here: the system takes the top n (n=10) sentences from each question's ranking results and combine all the top ranked sentences for all questions as "blindly" labeled definition sentences. We then conduct the soft pattern generalization process on these sentences.</p><p>It is worth pointing out that we take all the top ranked sentences from a group of questions as a batch of labeled definition sentences which are fed into the pattern generalization module, instead of generalizing patterns from the results of one question. It makes the "blind" labeling process more reliable by constructing large training set to combat data sparseness.</p><p>One assumption here is that the top ranked list actually contains enough definition sentences that can be used to obtain good patterns. The other important assumption for group based PRF to work effectively is that the definition patterns derived from different questions are similar, which is reasonable for the domain of news. Thus, although some of the top ranked sentences for each search term are not definitional, the effects of such errors would be mitigated by performing PRF and pattern generalization over the entire group. Moreover, in journalistic text, descriptive sentences often contain essential information about the search term. Therefore some of the definition sentences will rank high by our centroid based method. This is supported by our experiments on TREC data. We observed that 33% of the top ten ranked sentences over a question set of 50 questions were actually definition sentences (165 of 500). While a 33% accuracy rate may seem low, it is still better than the baseline for performing PRF in <ref type="bibr" target="#b3">[3]</ref>. Our experimental results show that the use of PRF significantly improves the quality of the resulting soft patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Step 3b: Sentence Re-Ranking by Combining the Soft Pattern Matching Weight</head><p>The result of unsupervised pattern learning through PRF is a set of soft patterns as presented in Section 2 (Step 3a). We compute each input sentence's pattern matching weight by using Equation (6). The final score of a sentence incorporates both its centroid based weight and the soft pattern matching weight.</p><formula xml:id="formula_11">) ( _ ) ( _ ) 1 ( ) ( _ stc weight Pattern stc weight Centroid stc Weight Def ⋅ + ⋅ − = δ δ (8)</formula><p>where Centroid_weight denotes the statistical weight obtained by the centroid based method and Pattern_weight is the weight of soft pattern matching. δ represents a tunable parameter to favor either the centroid weight or the pattern weight. After an initial study, we set it to 0.6, in order to give more weight to pattern rules because we believe that definition sentences should be sifted by patterns from the relevant sentences ranked by word statistics. Results shown later in this paper demonstrate that this combination of statistics and soft patterns is much more effective than using only the statistical method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Step 4: Sentence Selection Module</head><p>In order to construct the final definition, one more step should be done to select the top ranked definition sentences according to the definition length requirement and to avoid introducing redundant sentences into the definition. We adopt a variation of Maximal Marginal Relevance (MMR) <ref type="bibr" target="#b4">[4]</ref> to select nonredundant sentences from the top list of sentences ranked by Equation (8). The sentence selection algorithm is presented in <ref type="figure" target="#fig_1">Figure 4</ref>. Different from the approach taken in <ref type="bibr" target="#b4">[4]</ref> that ranked all passages with MMR, our method examines only the top ranked sentences and stops when the length of the definition is satisfied. The reason of our adaptation is that the input sentences from news are very noisy and thus those sentences with lower weights are not reliable for generating definitions. Based on our study of the limited pilot questions provided in TREC-12 QA task, we return 7 sentences for terms ("What is X") and 10 sentences for people ("Who is X"). The heuristic is also employed in our submission to the TREC-12 definitional question answering task. Questions are classified using simple heuristics by looking at the head words <ref type="bibr" target="#b23">[22]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EVALUATION</head><p>In this section, we report on two separate evaluations to show the effectiveness and adaptability of our SP+PRF system on the Web.</p><p>The purpose of our first experiment is to assess the effectiveness of our techniques in finding definitions from plain-text news articles on a publicly available standard corpus. We employ the TREC 2003 definitional question answering data set which includes a question set comprising 50 questions and answer judgments. We feel that the TREC QA corpus 3 is comparable to news articles found on the web, due to three reasons: a) all articles in the corpus are newswire articles; b) it is a corpus with <ref type="bibr" target="#b3">3</ref> The AQUAINT Corpus of English News Text. http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId =LDC2002T31 a broad sample (~1 million articles), covering all kinds of topics; and c) definitions in web-based news articles tend to appear in the plain text of the article, and thus web markup tags and links do not help to distinguish them <ref type="bibr" target="#b9">[9]</ref>. For these reasons, we believe that it is sufficient to use TREC data to justify the effectiveness of our method on the Web.</p><p>The purpose of the second experiment is to show the technique's adaptability to actual Web data and recent questions, as a proof-of-concept.</p><p>We test the generality of our automatically-learned soft patterns. In this evaluation, we present the results obtained by our techniques on recently crawled online news ("Web corpus"). We collected 26 questions about people and events from the Lycos search engine, which were the most popular queries issued by users, during a day in September 2003. Most of the questions can be found in the Lycos 50 4 report. We list the 26 questions in Appendix 2. The questions were submitted to Google 5 to retrieve news articles within eight news sites, including BBC, CNN and USAToday. We set the limit for the number of pages downloaded from each site to 200. The text body of the news pages, embedded between the HTML tags "&lt;P&gt;" and "&lt;/P&gt;", is extracted and preprocessed in the same fashion as was done to the TREC articles. We applied the learned soft patterns derived from the results of the 26 questions as well as those patterns learned from the TREC corpus to re-rank the sentences from the downloaded news articles.</p><p>The definition generation system used in the evaluation is illustrated in <ref type="figure" target="#fig_0">Figure 2</ref>. As we are not aware of a publiclyavailable comparable system, we used the system we developed for the TREC-12's definitional question answering task <ref type="bibr" target="#b23">[22]</ref>. As the system employed hand-crafted rules, we denote it as HCR. The rules (listed in Appendix 1), partly derived from the previous work <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b5">5]</ref>, were carefully constructed for the TREC corpus. Specifically, HCR differs from the SP+PRF system in that: (i) it utilized hand crafted rules as in other existing work, instead of the soft pattern matching described in this work; and (ii) it used regular expressions to match the rules.</p><p>The HCR system achieved an F measure of 0.473 in TREC-12 evaluations. The system was ranked second according to TREC evaluations. Thus we have good reason to believe that HCR is representative of the state-of-the-art system in answering definition questions.</p><p>A careful reader may have noticed that machine learned rules by supervised learning are a good comparison target. We do not include them in our evaluations because the hand crafted rules in HCR were generalized by the developers manually after a long time and hence they can be good approximations of machine learned rules based on large amount of training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation Metrics</head><p>In order to get comparable evaluation results, we adopt the same evaluation metrics as used in TREC definitional question answering task <ref type="bibr" target="#b20">[20]</ref>. For each question from the TREC corpus, there is a list of essential nuggets and acceptable nuggets for answering this question, provided by TREC. Using the given answer nuggets as a gold standard, an individual definition is scored using nugget recall (NR) and an approximation to nugget 4 http://50.lycos.com. <ref type="bibr" target="#b5">5</ref> http://www.google.com.</p><p>(1) All sentences are ordered in descending order by weights.</p><p>(2) Add the first sentence to the definition pool.</p><p>(3) Examine the similarity of the next sentence stc in the remaining sentences to all sentences already in the definition pool. If weight(stc) -average_similarity(stc, def_stc) &lt; weight(next_stc), then skip sentence stc; otherwise add it to the definition pool. We use simple normalized word overlap to compute similarity.</p><p>(4) Repeat from Step 3 until the desired number of definition sentences is reached.</p><p>precision (NP) based on length. These scores are combined using the F measure with recall being five times as important as precision. We list these metrics in Appendix 3.</p><p>As we do not have such standard nugget list for questions from the Web corpus, a total of seven different assessors were asked to mark definition sentences from the sentences returned by both the baseline and our method. For each question, an average of two assessors marked the resulting sentences. The NR, NP and F measures are calculated on the nuggets reflected in any of the definition sentences they have marked.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Effectiveness of the Proposed Techniques on TREC Corpus</head><p>In this evaluation, we compare the performance of our SP+PRF system against the HCR system on the 50 TREC questions. To illustrate the significance of definition patterns, the baseline system uses only the centroid based method (as in Section 3.1) to rank sentences. In the SP+PRF system, 683 pattern instances are extracted from the 500 blindly labeled definition sentences. We vary the window size w from 1 to 5 in soft patterns extraction and matching to study the impact of the distance of contextual slots from the search term. The results of NR, NP and F measures are listed in <ref type="table" target="#tab_3">Tables 2, 3</ref> and 4 respectively. We represent our techniques as "SP+PRF" with different window size settings.</p><p>From <ref type="table" target="#tab_3">Tables 2, 3</ref> and 4, we see significant improvements obtained by both the HCR and SP+PRF systems over the baseline statistical method, with the maximum improvement of 11.52% and 27.20%, respectively, for F measure. It shows that both the hand-crafted hard-coded rules as well as the automatically learned soft pattern rules are effective in selecting definition sentences. This is in line with our assumption that news articles define a term or person using some textual patterns.</p><p>We also see that a window size of 2 performs the best. This shows that definition patterns tend to be restricted to the tokens adjacent to the search term. The performance of our method drops when the window size reaches 4 or greater. Although a larger window size takes more contextual information into account, we believe it also introduces more noise in the distant slots. As phrase chunking and word omission have been done in the soft pattern generation process, we believe that the resulting small windows capture sufficient context. The unsupervised SP+PRF system also outperforms the labor intensive HCR system. Over a man-month of time was used to develop the hand-crafted rules through continuous cycle of system coding and performance analysis. Despite a slight drop in precision for some window size settings, the recall and F measure obtained using our techniques are better than those by HCR, with a maximum improvement of 16.83% for recall and 14.06% for F measure for the window size of 2. A paired t-test gives the p values for the improvements in recall and F measure as 0.069 and 0.108, respectively.</p><p>We attribute such improvement to the soft matching patterns which are more flexible than hard coded crafted rules and are thus more adaptable to diversified patterns reflected in online news. Additional benefit comes from the feasibility of applying PRF to automatically labeling definition sentences for pattern discovery.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluations on Online News in Web Corpus</head><p>In this evaluation, we present the results obtained by our techniques on the Web corpus. We first apply the centroid based method to ranking the sentences from the news pages, which is the baseline in the comparison. In the second configuration, we run the HCR system over the Web corpus. We applied our techniques to deriving 375 pattern instances through the PRF on the web corpus and used them to re-rank the sentences in constructing definitions. We denote this run as "SP+PRF (Lycos patterns)". In addition, we also utilize the 683 pattern instances derived from TREC corpus as soft patterns to re-rank the sentences. This run is represented as "SP+PRF (TREC patterns)".  <ref type="table" target="#tab_6">Table 5</ref> gives the results in terms of NR, NP and F measure for the baseline and our method with different sets of pattern instances. The window size of soft patterns is set to 2. The length of the definitions is the same as in the first evaluation.</p><p>From <ref type="table" target="#tab_6">Table 5</ref>, we see significant improvements in results by our method over the baseline method. The improvements are of statistical significance. With the soft patterns learned from the results of the Lycos questions, the p values for the improvements in NR, NP and F measure are 0.0185, 0.0132 and 0.0161, respectively; while with the soft patterns from TREC corpus, the p values are even smaller, 0.0020, 0.0002 and 0.0013, respectively.</p><p>In addition, we re-affirm that the system employing soft patterns outperforms that with hand-crafted rules. Using soft patterns obtained from the TREC corpus gives the performance 15.52% higher (p=0.017) than that obtained by the HCR system.</p><p>It is noted that by using the soft patterns from the TREC corpus, the system performs better (5% higher in F measure) than that with the patterns learned from the Lycos questions' results. We construe that it is mainly due to the number of the pattern instances used in pattern generalization, which is 683 for the 50 TREC questions. This is twice as many as the 375 pattern instances derived from the 26 Lycos questions. The more pattern instances result in more generic definition patterns which are less affected by data sparseness.</p><p>The significant improvements by using the soft patterns derived from the TREC corpus also show that they are sufficiently portable to other sources of news articles. Pattern generality is largely achieved in our work by the proper substitution of search term specific words, as determined by centroid words. Appropriate window size is another important factor in avoiding introducing too much noise in learning the patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">RELATED WORK</head><p>Our work is most related to three streams of work: soft matching patterns, unsupervised rule induction and definitional question answering.</p><p>Soft matching has been utilized in information retrieval <ref type="bibr" target="#b16">[16]</ref> where documents are matched by specified similarity measures. For textual tasks, such as classification <ref type="bibr" target="#b24">[23]</ref>, soft matching patterns that utilize word frequencies often perform better than hard-coded rules. Nahm and Mooney <ref type="bibr" target="#b11">[11]</ref> proposed learning soft matching rules from text by combining rule-based and instance-based learning. Words in each slot are generalized by traditional rule induction techniques and testing instances are matched to the rules by their cosine similarities.</p><p>Information extraction usually relies on a set of specific rules <ref type="bibr" target="#b10">[10]</ref>. Many supervised techniques have been suggested to learn extraction rules automatically, e.g. <ref type="bibr" target="#b18">[18]</ref>. In order to relieve the labors in annotating corpus, some researchers started to address the problem of adaptive pattern discovery. Riloff <ref type="bibr" target="#b15">[15]</ref> proposed to let users label entire sentences, rather than to tag the specific data to be extracted. The labeled sentences are used to obtain all word combinations in predefined syntactic relations. Similarly, Yangarber et al. <ref type="bibr" target="#b21">[21]</ref> used a set of basic patterns as "seeds" and learn more scenario oriented extraction patterns automatically. Most relevant to our application of PRF, Sudo et al. <ref type="bibr" target="#b19">[19]</ref> put forward an unsupervised learning for pattern discovery. They utilized TF×IDF to get a set of relevant documents and sentences and built patterns from them.</p><p>Answering definition questions is also addressed in previous work, especially in TREC. <ref type="bibr" target="#b12">[12]</ref> used WordNet hyponyms to answer what-is questions. In the FALCON system, Harabagiu et al.</p><p>[5] employed a simple yet widely used approach which defined several manually constructed definition patterns to extract proper phrases. Early TREC systems cannot deal with definition questions well due to the limitations of their simple techniques.</p><p>[17] and <ref type="bibr" target="#b1">[2]</ref> proposed to combine data-driven statistical method and machine learned rules to generate definitions. The former is dedicated to producing biographical summaries for people, i.e. answering "who is" questions. They based the summary mainly on appositives and relative clauses. The latter tries to summarize definitional predicates of the given term to answer such questions. These two works cannot be applied to finding definitions from news because their rules of finding syntactic parts, like appositives and predicates, are too restrictive to be adapted to news articles.</p><p>More recently, the ubiquity of the Web has generated interest on finding definitions. Liu et al. <ref type="bibr" target="#b9">[9]</ref> proposed mining topic specific definitions from the Web, but relied on a set of hand-crafted rules to find definition sentences. There is also work on extracting meaningful semantic components from online glossaries <ref type="bibr" target="#b6">[6]</ref>. Our work differs from the above in that we seek to find the timely definitions for emerging terms and people, which are only present in breaking news and not in the more structured sources of information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSIONS</head><p>In this paper, we have proposed a set of techniques to construct definitions for newly emerging terms and people by extracting precise definition sentences in an unsupervised manner. Applying these techniques showed both an improvement in performance as well as cost saving in development time. Our work makes two significant contributions: First, we use soft matching patterns instead of hard-coded rules to select definition sentences. This technique is better suited to capture the diversity of definition patterns in news. Second, we introduce the application of pseudo-relevance feedback to perform automatic labeling of training instances from ranked results. Our contribution here is to use PRF over a large set of input questions to counter noise and data sparseness. The automatically labeled definition sentences are utilized to generalize soft patterns. Experimental results show that our techniques outperform the state-of-the-art definitional question answering system without the need for an annotated corpus.</p><p>In future work, we plan to explore the application of soft patterns to information extraction and factoid question answering. Textual patterns <ref type="bibr" target="#b14">[14]</ref> provide a simple yet effective way in finding answers for a question answering system. As existing factoid QA systems utilize surface textual rules, we believe soft patterns can improve the performance of such systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">ACKNOWLEDGEMENT</head><p>The first author is grateful to Singapore Millennium Foundation Scholarship for supporting his PhD study <ref type="bibr">(ref no. 2003-SMS- 0230)</ref>. The authors also thank Hwee Tou Ng for his valuable comments on this work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 . The architecture of our SP+PRF definition generation system and a sample sentence-extracted definition.</head><label>2</label><figDesc>Figure 2. The architecture of our SP+PRF definition generation system and a sample sentence-extracted definition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Sentence selection algorithm</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 . Substitution heuristics.</head><label>1</label><figDesc></figDesc><table>Token 
Substitution 
Examples (from the 
example sentence in this 
section) 

Any part of the 
search term 

&lt;SCH_TERM&gt; "Iqra" 񮽙 &lt;SCH_TERM&gt; 

Centroid Words: 
(Topical words 
related to the search 
term, detailed in 
section 3.1) 

Corresponding 
syntactic 
classes 

"channel" 񮽙 NN 

Noun phrases by 
chunking 

NP 

"Arab Radio and Television 

company" 񮽙 NP 

Adjectival and 
adverbial modifiers 

To be deleted 

is, am, are, was, were 
BE$ 
is 񮽙 BE$ 

a, an, the 
DT$ 
"the" 񮽙 DT$ 

(all numeric values) 
CD$ 

All other words and 
punctuations 

no substitution 
"Owned", "by", "of", etc. 
are unchanged. 

1 We used NLProcessor, a commercial parser from Infogistics 
Ltd. http://www.infogistics.com/. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>1 ) Centroid-based ranking</head><label>1</label><figDesc></figDesc><table>Statistically 
ranked sentences 

2) Pseudo-Relevance 
Feedback to label 
instances for pattern 
discovery 

Input relevant 
sentences 

3a) Generalizing 
soft patterns 

3b) Sentences re-
ranking by soft 
pattern matching 

4) Sentence 
selection (anti-
redundancy) 

Definition based 
on extracted 
sentences 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="true"><head>Table 2 . Comparison of NR across the systems (TREC)</head><label>2</label><figDesc></figDesc><table>NR 

% improvement 
(over baseline) 

% improvement 
(over HCR) 

Centroid (Baseline) 0.463 

HCR 
0.514 
11.05% 

SP+PRF (w = 1) 0.561 
21.14% 
9.09% 

SP+PRF (w = 2) 0.601 
29.74% 
16.83% 

SP+PRF (w = 3) 0.579 
25.16% 
12.71% 

SP+PRF (w = 4) 0.551 
19.05% 
7.21% 

SP+PRF (w = 5) 0.557 
20.33% 
8.36% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 .</head><label>3</label><figDesc></figDesc><table>Comparison of NP across the systems (TREC) 

NP 

% improvement 
(over baseline) 

% improvement 
(over HCR) 

Centroid (Baseline) 

0.169 

HCR 
0.206 
22.05% 

SP+PRF (w = 1) 
0.206 
21.78% 
-0.23% 

SP+PRF (w = 2) 
0.221 
30.94% 
7.28% 

SP+PRF (w = 3) 
0.217 
28.24% 
5.07% 

SP+PRF (w = 4) 
0.204 
20.82% 
-1.01% 

SP+PRF (w = 5) 
0.204 
20.45% 
-1.31% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" validated="false"><head>Table 4 .</head><label>4</label><figDesc></figDesc><table>Comparison of F measure across the systems 
(TREC) 

F 
measure 

% improvement 
(over baseline) 

% improvement 
(over HCR) 

Centroid (Baseline) 

0.423 

HCR 
0.472 
11.52% 

SP+PRF (w = 1) 
0.507 
19.65% 
7.29% 

SP+PRF (w = 2) 
0.539 
27.20% 
14.06% 

SP+PRF (w = 3) 
0.531 
25.37% 
12.42% 

SP+PRF (w = 4) 
0.495 
16.97% 
4.88% 

SP+PRF (w = 5) 
0.484 
14.35% 
2.54% 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 .</head><label>5</label><figDesc></figDesc><table>Comparison of NR, NP and F Measure for Web Corpus 

NR 

% improvement 
(over baseline) 

NP 

% improvement 
(over baseline) 

F Measure 

% improvement 
(over baseline) 

Centroid (baseline) 
0.531 
0.229 
0.492 

HCR 
0.598 
12.67% 
0.239 
4.13% 
0.555 
12.82% 

SP+PRF (Lycos patterns) 
0.656 
23.52% 
0.277 
20.82% 
0.611 
24.04% 

SP+PRF (TREC patterns) 
0.682 
28.35% 
0.317 
38.23% 
0.642 
30.33% 

</table></figure>

			<note place="foot" n="2"> We use the statistics from Web Term Document Frequency and Rank site (http://elib.cs.berkeley.edu/docfreq/) to approximate words&apos; IDF.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Snowball: Extracting relations from large plaintext collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agichtein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gravano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th ACM International Conference on Digital Libraries (DL&apos;00)</title>
		<meeting>the 5th ACM International Conference on Digital Libraries (DL&apos;00)</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="85" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Blair-Goldensohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A Hybrid Approach for Answering Definitional Questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schlaikjer</surname></persName>
		</author>
		<idno>CUCS-006-03</idno>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
		<respStmt>
			<orgName>Columbia University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Automatic query expansion using SMART, NIST Special Publication 500-225: The Third Text Retrieval conference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="69" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The use of MMR, diversitybased reranking for reordering documents and producing summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21 st ACM-SIGIR International Conference on Research and Development in Information Retrieval</title>
		<meeting>the 21 st ACM-SIGIR International Conference on Research and Development in Information Retrieval<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="335" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Falcon: Boosting knowledge for answer engines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moldovan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pasca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Rus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Morarescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Ninth Text Retrieval Conference</title>
		<meeting>of Ninth Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="479" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tackling the Internet Glossary Glut: Automatic extraction and Evaluation of Genus Phrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Klavans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Popper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Passonneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Semantic Web Workshop, SIGIR 2003</title>
		<meeting>Semantic Web Workshop, SIGIR 2003<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-08-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lannon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<publisher>HarperCollins Publishers Inc</publisher>
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
<note type="report_type">Technical Writing</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Automated Acquisition of Topic Signatures for Text Summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the COLING Conference</title>
		<meeting>of the COLING Conference<address><addrLine>Strasbourg, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="495" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Mining Topic Specific Concepts and Definitions on the Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C-W</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H-T</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on World Wide Web</title>
		<meeting>International Conference on World Wide Web<address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="251" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Extraction patterns for information extraction tasks: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Muslea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI-99 Workshop on Machine Learning for Information Extraction</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mining softmatching rules from textual data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">Y</forename><surname>Nahm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence (IJCAI-2001)</title>
		<meeting>the Seventeenth International Joint Conference on Artificial Intelligence (IJCAI-2001)</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="979" to="984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Answering WhatIs Questions by Virtual Annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Prager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Czuba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies Conference</title>
		<meeting>Human Language Technologies Conference<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-03" />
			<biblScope unit="page" from="26" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Centroid based summarization of multiple documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Budzikowska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ANLP/NAACL &apos;00 Workshop on Automatic Summarization</title>
		<meeting><address><addrLine>Seattle, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-04" />
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning Surface Text Patterns for a Question Answering System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-07" />
			<biblScope unit="page" from="41" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automatically generating extraction patterns from untagged text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13 th National Conference on Artificial Intelligence (AAAI-96)</title>
		<meeting>the 13 th National Conference on Artificial Intelligence (AAAI-96)</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="1044" to="1049" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Automatic Text Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Producing biographical summaries: Combining linguistic knowledge with corpus statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Concepcion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings European Association for Computational Linguistics</title>
		<meeting>European Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning Information Extraction Rules for SemiStructured and Free Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soderland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning: Special Issue on Natural Language Learning</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="233" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automatic Pattern Acquisition for Japanese Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sekine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. HLT</title>
		<meeting>HLT<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Evaluating Answers to Definition Questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT-NAACL 2003</title>
		<meeting>HLT-NAACL 2003</meeting>
		<imprint>
			<biblScope unit="page" from="109" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yangarber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tapanainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Automatic Acquisition of Domain Knowledge for Information Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huttunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 18 th Int&apos;l Conf. on Computational Linguistics (COLING 2000)</title>
		<meeting>18 th Int&apos;l Conf. on Computational Linguistics (COLING 2000)<address><addrLine>Saarbrucken, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-08" />
			<biblScope unit="page" from="940" to="946" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">QUALIFIER in TREC-12 QA Main Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maslennikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<idno>TREC-12</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Annual Text Retrieval Conference</title>
		<meeting>the Twelfth Annual Text Retrieval Conference</meeting>
		<imprint>
			<date type="published" when="2003-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An evaluation of statistical approaches to text categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="69" to="90" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
