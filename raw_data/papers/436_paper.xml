<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-03-26T16:35+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GUESSING PREFERENCES: A NEW APPROACH TO MULTI-ATTRIBUTE RANKING AND SELECTION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">I</forename><surname>Frazier</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Operations Research &amp; Information Engineering</orgName>
								<orgName type="institution">Cornell University Ithaca</orgName>
								<address>
									<postCode>14853</postCode>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandr</forename><forename type="middle">M</forename><surname>Kazachkov</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Operations Research &amp; Information Engineering</orgName>
								<orgName type="institution">Cornell University Ithaca</orgName>
								<address>
									<postCode>14853</postCode>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">GUESSING PREFERENCES: A NEW APPROACH TO MULTI-ATTRIBUTE RANKING AND SELECTION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We consider an analyst tasked with using simulation to help a decision-maker choose among several decision alternatives. Each alternative has several competing attributes, e.g., cost and quality, that are unknown but can be estimated through simulation. We model this problem in a Bayesian context, where the decision-maker&apos;s preferences are described by a utility function, but this utility function is unknown to the analyst. The analyst must choose how to allocate his simulation budget among the alternatives in the face of uncertainty about both the alternatives&apos; attributes, and the decision-maker&apos;s preferences. Only after simulation is complete are the decision-maker&apos;s preferences revealed. In this context, we calculate the value of the information in simulation samples, and propose a new multi-attribute ranking and selection procedure based on this value. This procedure is able to incorporate prior information about the decision-maker&apos;s preferences to improve sampling efficiency.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>We consider the multi-attribute ranking and selection (R&amp;S) problem, in which we have a number of alternative systems, each of which must be simulated to determine its underlying performance. In the single-attribute R&amp;S problem, there is a single attribute of interest (for example, revenue), and the goal is to find the system for which the expected value of this attribute is largest. In the problem that we consider, there are multiple criteria of interest, and the simulation analyst has no clear way of combining them into a single criterion. Thus, our goal as simulation analysts is not to find the single best alternative, but to allocate the finite simulation budget available to us among the alternatives, in a way that best supports the multi-attribute selection decision that is to be made based on our simulation's results.</p><p>Although previous work has considered the multi-attribute R&amp;S selection problem, we formulate the problem in a novel way. In our formulation, we consider two parties: (1) the simulation analyst and his R&amp;S algorithm; and (2) a decision-maker who will later make a decision about some action to be performed in the real world based on the results of the simulation. We suppose that the decision-maker's decisions are driven by some underlying utility function that does combine the multiple attributes into a single objective function, but her utility function is unknown to the simulation analyst. The task that has been given to the simulation analyst is to use simulation to estimate the attributes' values for each alternative, and then present the results to the analyst, who will then make a decision according to her previously undisclosed preferences.</p><p>Although the simulation analyst does not know the decision-maker's preferences, he may have some prior belief about what they might be, based on previous interaction with the decision-maker or intuition about what is reasonable in the problem, and he can use this prior belief to focus simulation effort in a way that will best support her ultimate selection decision. This prior belief on the decision-maker's preferences allows us to derive a loss function for estimates of the alternatives' attribute values -the loss associated</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Frazier and Kazachkov</head><p>with an estimate is the expected loss in utility suffered by the decision-maker when using the estimated attribute values rather than their true values.</p><p>The problem we study is which simulations the analyst should perform, taking into account his prior probability distribution on the values of the attributes, and on the utility function of the decision-maker. This choice of simulations should best support the decision-maker's final decision by maximizing the utility she can obtain by making a decision based on his results. This formulation is only appropriate when simulation is inexpensive compared to the cost of accurately eliciting the decision-maker's utility function. Although researchers have developed methods for eliciting utility functions over multiple attributes (see, e.g., <ref type="bibr" target="#b3">Borcherding, Eppel, and Von Winterfeldt (1991)</ref>), the successful application of these elicitation methods requires sensitivity and experience on the part of the experimentalist, as well as an investment of time and energy by the decision-maker who is the subject of the experiment (and who may be a high-level executive with a busy schedule). Complicating matters, in some situations the decision-maker is simply unavailable for interview before the decision must be made. Furthermore, even under excellent experimental conditions, the possibility for inaccuracy still exists <ref type="bibr" target="#b21">(Froberg and Kane 1989)</ref>, and residual uncertainty about the decision-maker's preferences may remain. (Indeed, if this residual uncertainty is large enough, we would still require methods like those discussed in this article.) In contrast, if the simulation experiment only requires a few extra hours or days to run without knowing the decision-maker's preferences beforehand, then running the simulation experiment in this way is preferable to requiring her input beforehand.</p><p>Our supposition that the decision-maker has an underlying (but unknown) utility function that combines multiple attributes into one utility holds in only a subset of situations for which multi-attribute R&amp;S is required. For example, if an estimate of the Pareto frontier over multiple attributes is needed to support a multi-party negotiation whose parties have conflicting interests, then other models are more appropriate. We believe, however, our supposition is reasonable when there is only a single decision-maker -previous research on preferences over multiple attributes shows that preferences satisfying certain consistency requirements are necessarily consistent with a multi-attribute utility function having a simple functional form (see, e.g., <ref type="bibr" target="#b25">Keeney and Raiffa (1993)</ref>).</p><p>We use a Bayesian framework to place a prior distribution on the alternatives' attribute values, which we subsequently learn through simulation. Using this Bayesian framework, we calculate the value of sampling information <ref type="bibr" target="#b24">(Howard 1966)</ref> corresponding to the simulation samples that we can take. The simulation decision that we make is then to sample the alternative with the largest value of sampling information. This approach of valuing single samples according to the expected (myopic) value of the information they contain, and then taking the sample with the largest value, has been used by a number of researchers in other versions of the Bayesian R&amp;S problem <ref type="bibr" target="#b23">(Gupta and Miescke 1996</ref><ref type="bibr" target="#b19">, Frazier, Powell, and Dayanik 2008</ref><ref type="bibr" target="#b20">, Frazier, Powell, and Dayanik 2009</ref><ref type="bibr" target="#b10">, Chick, Branke, and Schmidt 2007</ref><ref type="bibr" target="#b11">, Chick, Branke, and Schmidt 2010</ref>, where it has sometimes been called the knowledge-gradient method <ref type="bibr" target="#b16">(Frazier 2009</ref>). The value of information has also been used more broadly in R&amp;S to choose sets of samples to take next <ref type="bibr" target="#b14">(Chick and Inoue 2001b</ref><ref type="bibr" target="#b13">, Chick and Inoue 2001a</ref><ref type="bibr" target="#b12">, Chick and Gans 2009</ref>. This approach has also been used in many problems outside of simulation (see Frazier (2010) for a review).</p><p>A number of other researchers have considered the multi-attribute R&amp;S problem. One related line of research concerns the multiobjective optimal computing budget allocation (MOCBA), studied in Lee, Teng, Chew, Lye, <ref type="bibr" target="#b28">Lendermann, Karimi, Chen, and Koh (2005)</ref>, <ref type="bibr" target="#b26">Lee, Chew, and Teng (2007)</ref>, <ref type="bibr" target="#b9">Chen and Lee (2009)</ref>, <ref type="bibr" target="#b27">Lee, Chew, Teng, and Goldsman (2010)</ref>. Unlike our work, the measure of the quality of an estimate of the Pareto frontier used by MOCBA procedures is not based on the interaction between the simulation analyst and the decision-maker, and does not allow the simulation analyst to incorporate prior information about the decision-maker's preference to improve sampling efficiency. This line of papers resides in a larger body of work on the optimal computing budget allocation <ref type="bibr" target="#b8">(Chen, Lin, Yücesan, and</ref><ref type="bibr" target="#b8">Chick 2000, Chen and</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Frazier and Kazachkov</head><p>Another related line of research on multi-attribute R&amp;S considers the problem of maximizing one attribute subject to a constraint on one or more other attributes. This work includes Andradóttir, Goldsman, and <ref type="bibr" target="#b1">Kim (2005)</ref>, <ref type="bibr" target="#b2">Andradóttir and Kim (2010)</ref>. This use of constraints has been considered by <ref type="bibr" target="#b31">Morrice and Butler (2006)</ref>, <ref type="bibr" target="#b30">Merrick (2009)</ref>, which argues that utility functions are a more appropriate way to handle multiple attributes in many applications.</p><p>Within computer science and decision analysis, a number of papers have used prior distribution on a decision-maker's unknown utility to construct efficient experimental designs for eliciting utility functions. This line of research begins with Chajewska, <ref type="bibr" target="#b6">Koller, and</ref><ref type="bibr" target="#b6">Parr (2000), and</ref><ref type="bibr">includes Boutilier (2002)</ref>, <ref type="bibr" target="#b0">Abbas (2004)</ref>. This line of research shares the modeling technique of placing a prior on a decision-maker's unknown preferences, but differs in the ultimate goal toward which this modeling technique is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PROBLEM FORMULATION</head><p>We begin by giving, in Section 2.1, a statistical model that describes sampling, as well as our Bayesian prior and posterior beliefs on the unknown sampling distributions for each alternative. Then, in Section 2.2, we give a model for the preferences of the decision-maker. In Section 2.3 we discuss how the prior on decision-maker preferences used by this model may be selected.</p><p>The sampling model, which assumes independent normal samples with an independent normal prior on the sampling means and an independent gamma prior on the sampling precisions, is standard, and similar models have been used in other research on Bayesian R&amp;S <ref type="bibr" target="#b14">(Chick and Inoue 2001b</ref><ref type="bibr" target="#b11">, Chick, Branke, and Schmidt 2010</ref> as well as more broadly in Bayesian statistics <ref type="bibr">(DeGroot 1970, Gelman, Carlin, Stern, and</ref><ref type="bibr" target="#b22">Rubin 2004)</ref>. The model of the decision-maker's preferences, however, is novel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Sampling Model</head><p>We suppose that there are a discrete set of alternatives 1, . . . , k, each with m attributes. Each alternative x and attribute j has a corresponding sampling distribution that is normal with mean θ x j and variance λ x j , with samples that are independent across alternatives, objectives, and time. We let θ = {θ x j : x = 1, . . . , k, j = 1, . . . , m} and λ = {λ x j : x = 1 . . . , k, j = 1, . . . , m} be the collections of all sampling means and variances respectively. At each time n = 1, 2, . . . we observe a sample y n j from each attribute j for an alternative x n of our choice, and thus the distribution of y n j conditioned on x n , θ , and λ is</p><formula xml:id="formula_0">y n j |x n , θ , λ ∼ Normal(θ x n j , λ x n j ), j = 1, . . . , m,</formula><p>We emphasize that the y n j are conditionally independent of each other across j, because the sampling distributions are assumed independent across attribute. We let y n = (y n1 , ..., y nm ).</p><p>Neither the sampling means nor the sampling variances are known. We adopt a Bayesian approach, in which we place a prior distribution on their values, and update this prior using observed data to obtain posterior distributions. For ease of analysis, we assume a conjugate prior distribution (see, e.g., <ref type="bibr" target="#b15">(DeGroot 1970)</ref>), which takes the following form. Under the prior,</p><formula xml:id="formula_1">θ x j | λ x j ∼ Normal(µ 0x j , λ x j /ρ 0x j ), 1/λ x j ∼ Gamma(a 0x j , b 0x j ),</formula><p>with independence across x and j, where a 0x j , b 0x j , µ 0x j and ρ 0x j are given parameters. Here, the gamma distribution is parameterized in terms of the inverse scale b 0x j , and not the scale, so that the mean of the gamma distribution is a 0x j /b 0x j and the mode is (a 0x j − 1)/b 0x j when a 0x j ≥ 1 and b 0x j &gt; 0. In practice, one common choice is to set these parameters to</p><formula xml:id="formula_2">a 0x j = − 1 2 , b 0x j = 0, ρ 0x j = 0, µ 0x j = 0</formula><p>, which provides a non-informative prior that can be interpreted as imposing as little subjective prior belief about θ x j and λ x j as possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Frazier and Kazachkov</head><p>The posterior distribution on θ and λ at time n, which is the conditional distribution of θ and λ given observed data x 1 , . . . , x n and y 1 , . . . , y n , has the same form,</p><formula xml:id="formula_3">θ x j | x 1 , . . . , x n , y 1 , . . . , y n , λ x j ∼ Normal(µ nx j , λ x j /ρ nx j ), 1/λ x j | x 1 , . . . , x n , y 1 , . . . , y n ∼ Gamma(a nx j , b nx j ),</formula><p>where the posterior distribution remains independent across x and j, and the parameters a nx j , b nx j , µ nx j and ρ nx j can be calculated recursively. In this recursive calculation, the parameters remain unchanged from n to n + 1 for those x = x n+1 , and are given by the following expressions for x = x n+1 :</p><formula xml:id="formula_4">a n+1,x, j = a nx j + 1/2, b n+1,x, j = b nx j + (1/2)(y n+1, j − µ nx j ) 2 ρ nx j /(ρ nx j + 1), ρ n+1,x, j = ρ nx j + 1, µ n+1,x, j = (ρ nx j µ nx j + y n+1, j )/(ρ nx j + 1).</formula><p>(1)</p><p>In practice, rather than tracking both a nx j and ρ nx j , we need only track the number of samples taken from each alternative x. This is because a nx j is a 0x j plus half the number of samples taken from x, and ρ nx j is ρ 0x j plus the number of samples taken from x. Given this posterior on θ and λ at time n, the marginal posterior distribution on θ x j is independent across x and j and has the Student-t distribution with 2a nx j degrees of freedom, location parameter µ nx j , and precision a nx j ρ nx j /b nx j .</p><p>In Section 3, we use the maximum a posterior estimate λ nx j of λ x j , which is</p><formula xml:id="formula_5">λ nx j = b nx j /(a nx j − 1).<label>(2)</label></formula><p>To ensure that this estimator is well-defined and reasonably accurate, we require a nx j ≥ 2 before using its value. We let λ n = { λ nx j : x = 1 . . . , k, j = 1, . . . , m} be our time-n estimate of all of the sampling variances. Also in Section 3, we use the conditional distribution of µ n+1,x, j given the information available at time n, x n+1 = x, and λ . We calculate this distribution here. Given this information, the conditional distribution of y n+1, j is normal with mean µ nx j and variance λ x j /ρ nx j + λ x j = λ x j (ρ nx j + 1)/ρ xn j . This is because y n+1, j is the sum of θ x j , which is conditionally Normal(µ nx j , λ x j /ρ nx j ), with independent unbiased normally distributed noise with variance λ x j . Then, µ n+1,x, j = (ρ nx j µ nx j + y n+1, j )/(ρ nx j + 1) is a linear transformation of a conditionally normal random variable, and is itself conditionally normal. Its mean and variance is given by</p><formula xml:id="formula_6">E n [µ n+1,x, j | x n+1 = x, λ ] = ρ nx j µ nx j + µ nx j ρ nx j + 1 = µ nx j , Var n [µ n+1,x, j | x n+1 = x, λ ] = Var n [y n+1, j | x n+1 = x, λ ] (ρ nx j + 1) 2 = λ x j ρ nx j (ρ nx j + 1) .</formula><p>where E n and Var n indicate the conditional expectation and conditional variance (respectively) with respect to the information available at time n. In the computation of the variance, we have used that</p><formula xml:id="formula_7">Var n [y n+1, j | x n+1 = x, λ ] = Var n [θ x j | λ ] + λ x j = (λ x j /ρ nx j ) + λ x j = λ x j (ρ nx j + 1)/ρ nx j .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The Decision-Maker's Preferences</head><p>We suppose that there is a decision-maker to whom we will deliver the simulation results, and that she has a utility function U : R m → R. We suppose that this utility function is linear, and so is given by U(θ ) = c · θ = ∑ m j=1 c j θ j , for some vector of preferences c ∈ R m and any vector of attribute valuesθ ∈ R m . Here · indicates the dot product. If the preference vector c were known, then we could use a single-objective ranking &amp; selection strategy, of which several have been developed in the literature (a partial list includes Chen, <ref type="bibr" target="#b8">Lin, Yücesan, and Chick (2000)</ref>, <ref type="bibr" target="#b14">Chick and Inoue (2001b)</ref>, <ref type="bibr" target="#b23">Gupta and Miescke (1996)</ref>, <ref type="bibr" target="#b20">Frazier, Powell, and Dayanik (2009)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Frazier and Kazachkov</head><p>Instead, we suppose that the preference vector c is unknown and we have a prior probability distribution on its value. When the simulation analyst has little information about the preferences of the decision-maker, it may be prudent to specify a non-informative prior on c, as described below in Section 2.3. In other cases, he may have more specific information, and this framework allows incorporating that information into his simulation sample selection.</p><p>Having a prior probability distribution on c can be interpreted as being uncertain about the true preferences of the decision-maker, but having some reasonable guesses based on conversations with the decision-maker, experience with the decision-maker's decisions in previous situations, or intuition about the current problem. For example, in a staffing problem for a small hospital, an employee charged with running simulations might guess that a hospital administrator would feel that saving an average of 15 minutes of waiting time for each patient visiting the emergency room might be worth the salary of 1 additional nurse, but is unlikely to be worth the salary of 10 additional nurses. If the employee had a great deal of previous experience with solving problems for this administrator, or a great deal of experience working with similar problems, that employee might be able to make more refined guesses. In making these guesses, the employee would not feel certain that these guesses were correct, but would feel that they were reasonable.</p><p>We will see that these prior distributions allow one to make better use of one's ability to simulate, in estimating which alternatives will be closest to optimizing the decision-maker's true preferences.</p><p>After taking a number of samples N (this number of samples can be fixed a priori, or can be chosen adaptively by the policy), we suppose that the simulation analyst provides to the decision maker a collection of alternatives and their estimated characteristics. The decision-maker then chooses the best alternative according to the estimated attribute values and her underlying and previously unobserved preferences encoded in the preference vector c. The choice that she makes is arg max</p><formula xml:id="formula_8">x E N [U(θ x ) | U] = arg max x c · E N [θ x ] = arg max x c · µ Nx<label>(3)</label></formula><p>where θ x = (θ x1 , . . . , θ xm ) is the vector of true attributes of alternative x, and</p><formula xml:id="formula_9">µ Nx = E N [θ x ]</formula><p>is the conditional expectation of θ x under our posterior belief at time N.</p><p>The linearity of the utility function implies that the variance at the final time N of our posterior belief about θ plays no role in the choice made by the decision-maker. This corresponds to the decision-maker's lack of aversion to the risk in not knowing the true distribution of the chosen alternative. This is risk that could be addressed by more simulation. Additionally, the decision-maker does not consider the sampling variances λ when making her decision, which corresponds to a lack of aversion to the risk from the randomness that will appear when implementing her chosen alternative in the real world. In future work we plan to consider the role of risk aversion. The posterior and sampling variances at earlier times play a role in the choice of which alternative to sample.</p><p>With the choice (3) by the decision-maker, the value she obtains at the final time is max x c · µ Nx , and the expected value obtained by a measurement policy π is</p><formula xml:id="formula_10">E π max x c · µ Nx .<label>(4)</label></formula><p>The simulation analyst's goal is then to use a measurement policy that maximizes the quantity (4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">The Choice of Prior Distribution</head><p>In this section we discuss how the simulation analyst might choose the prior distribution on c.</p><p>We first observe that the simulation analyst may often know the sign of the decision-maker's preference for each attribute, sign(c j ), even if he does not know the preference vector itself. For example, in the hospital staffing problem, we know that the sign of the attribute corresponding to cost is negative (less cost is preferred), as is the sign of the attribute corresponding to patient waiting time (less waiting time is <ref type="bibr">Frazier and Kazachkov preferred)</ref>. In this case, the prior on c can be restricted to that part of R m that has the correct set of signs. In the rest of this section, we suppose without loss of generality that the sign of each c j is positive (if not, we simply flip the sign of samples of attribute j).</p><p>Second, we observe that the preference order over alternatives induced by a preference vector c is identical to that induced by c/a for any scalar a. Thus, for specifying a prior on the order of the decisionmaker's preference over alternatives, it is enough to specify a prior on the vector with unit magnitude, c/||c||. One can then make the simplifying assumption that ||c|| = 1. In the case where there are m = 2 attributes, all that is then required is to specify a prior on an angle between 0 and π/2. More generally, with m ≥ 2, one must specify a prior on the intersection of the unit sphere and the positive orthant.</p><p>This assumption that ||c|| = 1 is not without loss of generality. Even though dividing c by a scalar does not change the decision-maker's preference order, choosing a prior that places weight on several different magnitudes ||c|| affects the value of sampling information discussed in Section 3.1. In m = 2, such a prior might correspond to the belief that the overall magnitude of the decision-maker's preferences are large when the angle of the preferences c/||c|| takes one value, while the overall magnitude is lower when it takes other values. While this might be occasionally useful, and is allowed by our framework, we feel that in most situations this additional flexibility is not needed, and we recommend specifying priors with ||c|| = 1.</p><p>When the simulation analyst has little information about the preferences of the decision-maker, it may be prudent to specify a non-informative prior on c. One convenient non-informative prior is the one that is uniform on the intersection of the unit sphere and the positive orthant. When m = 2, this prior is the one that is uniform on the angles [0, π/2].</p><p>In Section 3 we provide exact expressions for the value of information and the knowledge-gradient policy when the prior on c is discrete. Thus, for computational convenience, we recommend approximating continuous priors through discretization. When m = 2 and one has a non-informative prior on c, a convenient discrete prior is c = (cos(α ), sin(α )), α = π 2 ( − 1)/(L − 1), for = 1, . . . , L, and P{c = c } = 1/L.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">KNOWLEDGE-GRADIENT POLICY</head><p>The knowledge-gradient (KG) policy is a one-step lookahead method based on a value of information calculation. It supposes that the current opportunity to sample is the last that will be allowed, and that immediately afterward the simulation analyst must provide results to the decision-maker. In the KG policy, we make the decision that would be optimal in this case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Derivation of the Knowledge-Gradient Policy</head><p>To calculate this KG decision, we calculate the expected incremental value that would be obtained by showing results to the decision-maker after sampling alternative x, as opposed to showing results to the decision-maker before sampling x. We call this quantity the KG factor for alternative x. The KG policy tells us to measure the alternative with the largest KG factor. To make calculation of the KG factor analytically tractable, we suppose, only for the purposes of this calculation, that the sampling variances λ are given to us. When using the KG policy in problems with unknown sampling variance, we take the current maximum a posteriori estimate λ nx j of λ nx j from (2), and substitute this for the true sampling variance when calculating KG factors. After each sample we update these estimates of the sampling variances.</p><p>With the assumption that the sampling variances λ are known, the KG factor for sampling alternative x at time n is denoted ν nx (λ ) and is defined to be,</p><formula xml:id="formula_11">ν nx (λ ) = E n max x c · µ n+1,x − max x c · µ n,x | x n+1 = x, λ .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Frazier and Kazachkov</head><p>We now calculate this more explicitly. We condition on c and use the tower property of conditional expectation to obtain</p><formula xml:id="formula_12">ν nx (λ ) = E n E n max x c · µ n+1,x − max x c · µ n,x | c, x n+1 = x | x n+1 = x, λ = E n [ν nx (c, λ ) | x n+1 = x, λ ] = E n [ν nx (c, λ ) | λ ] ,</formula><p>where ν nx (c, λ ) is defined to be ν nx (c, λ ) = E n max x c · µ n+1,x − max x c · µ n,x | c, x n+1 = x, λ , and the last equality follows because ν nx (c, λ ) does not depend upon x n+1 . The last expectation is over our uncertainty about c. The quantity ν nx (c, λ ) is the expected incremental improvement from sampling x that we would obtain if we also knew the decision-makers preferences c. We do not know these preferences, and so we must take an expectation over this uncertainty.</p><p>The quantity ν nx (λ , c) is computed more explicitly in the following proposition. Its proof may be found in the appendix.</p><formula xml:id="formula_13">Proposition 1 ν nx (c, λ ) = σ nx (c, λ ) f −∆ nx (c) σ nx (c,λ )</formula><p>, where</p><formula xml:id="formula_14">( σ nx (c, λ )) 2 = m ∑ j=1 c 2 j λ x j ρ nx j (ρ nx j + 1) , f (d) = dΦ(d) + ϕ(d), ∆ nx (c) = c · µ nx − max x =x c · µ nx ,</formula><p>Φ is the normal cumulative distribution function, and ϕ is the normal probability density function. Proposition 1 implies that the KG factor for sampling alternative x is</p><formula xml:id="formula_15">ν nx (λ ) = E n σ nx (c, λ ) f −∆ nx (c) σ nx (c, λ ) | λ ,</formula><p>where the expectation is over c. The posterior on c is the same as the prior because we obtain no information about the decisionmaker's preferences until the final time. If the prior on c is discrete over a set c 1 , . . . , c L , with probabilities p = P{c = c } that c is equal to each of these values, then this expectation may be computed exactly as:</p><formula xml:id="formula_16">ν nx (λ ) = ∑ p σ nx (c , λ ) f −∆ nx (c ) σ nx (c , λ ) .<label>(5)</label></formula><p>When the sampling variances are known, the KG policy tells us to measure the alternative x with the largest such value, x n+1 ∈ arg max x ν nx (λ ). When the sampling variances are unknown, we substitute the maximum a posteriori estimate λ n for the sampling variances λ , and the KG policy is</p><formula xml:id="formula_17">x n+1 ∈ arg max x ν nx ( λ n ).<label>(6)</label></formula><p>Together, (5) and (6) define the KG policy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Summary of the Knowledge-Gradient Policy</head><p>We now summarize the way in which samples are collected and inference is performed in the KG policy:</p><p>1. Initialization: Choose the parameters of the prior distribution, a number of initial samples n 0 , and an overall number of samples N &gt; kn 0 . If we have no strong prior beliefs about the sampling means and variances, use the non-informative prior:</p><formula xml:id="formula_18">a 0x j = −1/2, b 0x j = 0, ρ 0x j = 0, µ 0x j = 0. Choose a discrete prior on c, p = P{c = c } for = 1, . . . , L.</formula><p>Frazier and Kazachkov 2. Initial Sampling: Choose the number of initial samples n 0 satisfying a 0x j + n 0 ≥ 2 for each x and j. Collect n 0 samples from each alternative and let n = kn 0 . Calculate the parameters a nx j , b nx j , ρ nx j , µ nx j for all x, j from the data collected using the recursive expression (1). 3. Calculate KG Factors: For each alternative x, (a) Calculate</p><formula xml:id="formula_19">λ nx j = b nx j /(a nx j − 1) for j = 1, . . . , m. (b) Calculate σ (c , λ n ) = ∑ m j=1 c 2 j λ nx j / (ρ nx j (ρ nx j + 1)) 1/2 for = 1, . . . , L. (c) Calculate ∆ nx (c ) = c · µ nx − max x =x c · µ nx for = 1, . . . , L. (d) Calculate the KG factor using f (d) = dΦ(d) + ϕ(d) and ν nx = L ∑ =1 p σ nx (c , λ ) f −∆ nx (c ) σ nx (c , λ ) ,</formula><p>4. Sample: Sample alternative x n+1 ∈ arg max x ν nx ( λ n ) and observe y n+1, j for each j = 1, . . . , m. 5. Update Posterior: Update the parameters a n+1,x, j , b n+1,x, j , ρ n+1,x, j , µ n+1,x, j of the posterior over all attributes j and all alternatives x. For x = x n+1 , the updated parameters are computed from y n+1, j via (1), and for x = x n+1 the parameters are unchanged from time n. 6. Loop: Let n = n + 1. If n = N, stop sampling. Otherwise go to Step 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EMPIRICAL RESULTS</head><p>We performed computational experiments to assess the effectiveness of the KG policy and to illustrate how the prior on decision maker preferences influences its behavior.</p><p>In <ref type="figure" target="#fig_0">Figure 1</ref>, we compared the expected performance of the KG policy against that of the equal allocation policy, which allocates the same number of samples to each point in round-robin fashion. The problem considered has k = 20 alternatives, each with m = 2 attributes, with a sampling budget of N = 600, including the n 0 = 5 initial samples per alternative. We assumed a known sampling variance of λ x j = 1 across all alternatives and attributes. The KG policy began with a non-informative prior on the sampling means. There were L = 5 possible values c for c, equidistant from each other on the unit quarter circle in the first quadrant. That is, c = (cos(α ), sin(α )) where α = π 2 ( − 1)/4 with = 1, . . . , 5. Our prior on c placed equal probability on each c , so p = 1/5.</p><p>Performance was averaged over 1000 replications. In each replication, we sampled a new set of sampling means θ from an independent standard normal distribution. At each iteration n ≥ 100 after the initial stage of sampling, we calculated the expected value the decision-maker would receive if N were equal to n, based on the true sampling means θ and the prior on c. This value is ∑ L =1 p (c · θ x * (n,c) ), where x * (n, c) ∈ arg max x c · µ nx is the alternative that the decision-maker would choose at time n as given in (3). The expected value of this performance measure is identical to the expected value of a performance measure calculated by also randomly sampling one hidden true value of c on each replication. <ref type="figure" target="#fig_0">Figure 1</ref> plots this average performance as a function of n for n &gt; kn 0 , i.e., after KG completes its initial stage of sampling. During this initial stage, KG uses the equal allocation policy, and the performance of the two policies is identical. The maximum standard error of the average performance (which is as an estimate of expected performance), under both KG and equal allocation and over all n, was 0.011. <ref type="figure" target="#fig_0">Figure 1</ref> shows that the KG policy performs well against equal allocation in this experiment. This is not surprising, since the equal allocation policy is known to underperform more sophisticated adaptive sampling policies in a number of other R&amp;S problems. It demonstrates, however, that the behavior of the KG policy is reasonable. In future work, we plan to compare the performance of the KG policy against other more sophisticated multi-attribute R&amp;S procedures, both using the new measure of quality of a multi-attribute sampling procedure, and more traditional measures of quality.  <ref type="formula" target="#formula_10">(4)</ref>) is plotted. Here, k = 20, λ x j = 1, µ 0x j = 0, n 0 = 5. There were five possible values of c, and they were all equiprobable. The maximum standard error was 0.011.</p><p>In <ref type="figure" target="#fig_1">Figure 2</ref>, we consider k = 50 alternatives with m = 2 attributes each, whose sampling means were again generated from a standard normal distribution. The KG policy began with a non-informative prior, with n 0 = 5 samples taken from each alternative, and a known sampling variance of λ x j = 1. Rather than averaging over many replications, we display the results from one replication after N = 600 samples, where each alternative's true sampling mean θ x = (θ x1 , θ x2 ) is plotted as a filled black square, and the posterior mean is plotted as an an open diamond. The sampling mean and posterior mean are connected by a line, and the length of this line illustrates the posterior variance and the number of times that the alternative was sampled -shorter lines usually correspond to alternatives that were sampled more often. We use the same L = 5 possible values c as in <ref type="figure" target="#fig_0">Figure 1</ref>, but with two different priors on these values. In the left panel, the prior places more weight on those c preferring large values of θ 1 at the expense of θ 2 , while in the right panel the prior places more weight on those c preferring large values of θ 2 at the expense of θ 1 . This prior was</p><formula xml:id="formula_20">p = 2 L−+1 ∑ L i=1 2 L−i+1 (left panel), p = 2 ∑ L i=1 2 i (right panel), = 1, . . . , L.</formula><p>In both panels, the KG policy has sampled more often from those alternatives on the Pareto front (those alternatives up or to the right), and less often from those alternatives away from the Pareto front. Additionally, the KG policy has sampled more from the alternatives that performed better in the attribute that was considered more important. The alternatives with a larger value on the horizontal axis show a smaller variance in <ref type="figure" target="#fig_1">Figure 2</ref>(a) than in <ref type="figure" target="#fig_1">Figure 2</ref>(b), while those with a larger value on the vertical axis show a smaller variance in <ref type="figure" target="#fig_1">Figure 2</ref>(b) than in <ref type="figure" target="#fig_1">Figure 2(a)</ref>. Although the KG policy spends more effort on the attribute believed to be more important, it does also spend some effort on the attributes believed to be less important, as evidenced in <ref type="figure" target="#fig_1">Figure 2(</ref>  In the left panel, the horizontal axis is likely to be more important. In the right panel, the vertical axis is likely to be more important. In each panel, for each alternative x, lines connect a square at the true sampling mean θ x = (θ x1 , θ x2 ) with its posterior mean µ Nx = (µ Nx1 , µ Nx2 ). In these figures, k = 50.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>We have considered the multi-attribute Bayesian R&amp;S problem from a new viewpoint, in which the decision-maker has a single utility function, but this utility function is unknown to the simulation analyst. Within this framework, we have developed a new procedure for choosing which alternative to sample next. This procedure myopically maximizes the value of the information obtained. By using the prior on the preferences of the decision-maker, we can influence the algorithm to spend more time estimating the attributes of those alternatives that are more important for the decision-maker's final selection.</p><p>A number of possible extensions present themselves for future work. One might extend the model to allow for correlated samples across criteria for a single alternative, or across alternatives through the use of common random numbers. One might also explore non-myopic or batch algorithms, which have the potential for providing better performance within this framework. One might also study the role that the decision-maker's risk aversion plays in the decisions that the simulation analyst should make. One might also consider correlated prior distributions, allowing us to learn about unsampled alternatives from the sampling results of related alternatives, and enabling us to solve large-scale problems in which the number of alternatives far exceeds the number of available samples.</p><p>Another interesting direction for future work is to enhance the model of interaction between the simulation analyst and the decision-maker to allow some feedback on preferences during simulation. In this extension, the simulation analyst could ask the decision-maker for feedback about interim or hypothetical results in order to reduce the amount of simulation. In this enhanced model, the analyst could show the decision-maker interim or hypothetical results and ask her which of them she would prefer. This would allow the decision-maker to obtain some partial information about the decision-maker's preferences, which the algorithm could then use to focus its sampling effort. This interaction could be considered a form of prior elicitation. This interaction would be modeled as bearing some cost (because it occupies the decision-maker's time), and so the analyst would be led to to use this interaction only when it would significantly decrease the amount of simulation effort required to accurately support the decision-maker's ultimate decision.</p><p>The overarching goal of this work has been to more accurately model the way in which simulation is used as an aid to human decision-making. We hope that the model described in this paper will contribute Frazier and Kazachkov to the progress being made in the larger literature toward this goal, and that better models will lead to even more productive use of simulation by society at large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A PROOF OF PROPOSITION 1</head><p>First c · µ n+1,x = c · µ n,x for x = x = x n+1 . Now consider c · µ n+1,x . We observed in Section 2.1 that, conditional on the information available at time n, x n+1 = x, and λ , µ n+1,x, j ∼ Normal <ref type="formula">(</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Bayes performance of the KG and equal allocation policies as a function of the number of samples taken after the initial stage of experiments completes (the iteration, n − kn 0 ). For each value of n and each policy, an estimate of the expected Bayes reward (equation (4)) is plotted. Here, k = 20, λ x j = 1, µ 0x j = 0, n 0 = 5. There were five possible values of c, and they were all equiprobable. The maximum standard error was 0.011.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Illustration of the true values θ and posterior estimates µ Nx under the KG policy after exhausting the sampling budget, with five different values of c. In the left panel, the horizontal axis is likely to be more important. In the right panel, the vertical axis is likely to be more important. In each panel, for each alternative x, lines connect a square at the true sampling mean θ x = (θ x1 , θ x2 ) with its posterior mean µ Nx = (µ Nx1 , µ Nx2 ). In these figures, k = 50.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>µ nx j , λ x j /(ρ nx j (ρ nx j + 1))) with independence across j. This shows that the conditional distribution of c · µ nx is Normal(c · µ nx , m ∑ j=1 c 2 j λ x j /(ρ nx j (ρ nx j + 1))). Observe that ( σ nx (c, λ )) 2 = ∑ m j=1 c 2 j λ x j /(ρ nx j (ρ nx j + 1)) is the variance of the distribution. Let Z be an independent standard normal random variable, so max x c · µ n+1,x is equal in conditional distribution to max{max x =x c · µ nx , c · µ nx + σ nx (c, λ )Z}. In general we have for a 1 , a 2 , b ∈ R that, E [max{a 1 , a 2 + bZ}] = max(a 1 , a 2 ) + E [max{0, − |a 1 − a 2 | + bZ}] = max(a 1 , a 2 ) + bE max{0, − |a 1 − a 2 | b + Z} = max(a 1 , a 2 ) + b f − |a 1 − a 2 | b where f (d) = E [max{0, d + Z}] = ∞ −∞ ϕ(z) max{0, d + z} dz = ∞ −d ϕ(z)(d + z) dz = d ∞ −d ϕ(z) dz + ∞ −d ϕ(z)z dz = dΦ(d) + ϕ(d). Thus, with a 1 = max x =x c · µ nx , a 2 = c · µ nx , and b = σ nx (c, λ ), we have max(a 1 , a 2 ) = max x c · µ nx , and E n max x c · µ n+1,x = max x c · µ nx + σ nx (c, λ ) f −∆ nx (c) σ nx (c, λ ) , where ∆ nx (c) = |a 1 − a 2 | = c · µ nx − max x =x c · µ nx and ν nx (c, λ ) = σ nx (c, λ ) f −∆ nx (c) σ nx (c,λ .</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>Peter Frazier was supported by AFOSR YIP FA9550-11-1-0083.</p></div>
			</div>

			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Entropy methods for adaptive utility elicitation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abbas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Systems, Man and Cybernetics, Part A: Systems and Humans</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="169" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Finding the best in the presence of a stochastic constraint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Andradóttir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Goldsman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 Winter Simulation Conference</title>
		<editor>M. E. Kuhl, N. M. Steiger, F. B. Armstrong, and J. A. Joines</editor>
		<meeting>the 2005 Winter Simulation Conference<address><addrLine>Piscataway, New Jersey</addrLine></address></meeting>
		<imprint>
			<publisher>Institute of Electrical and Electronics Engineers, Inc</publisher>
			<date type="published" when="2005-12" />
			<biblScope unit="page" from="732" to="738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fully sequential procedures for comparing constrained systems via simulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Andradóttir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Naval Research Logistics (NRL)</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="403" to="421" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Comparison of weighting judgements in multiattribute utility measurement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Borcherding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Eppel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Von Winterfeldt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1603" to="1619" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazachkov</forename><surname>Frazier</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A POMDP formulation of preference elicitation problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Boutilier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Conference on Artificial Intelligence</title>
		<editor>K. Ford</editor>
		<meeting>the National Conference on Artificial Intelligence<address><addrLine>Menlo Park, CA; Cambridge, MA; London</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="239" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Making rational decisions using adaptive utility elicitation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Chajewska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Parr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Conference on Artificial Intelligence</title>
		<editor>K. Ford</editor>
		<meeting>the National Conference on Artificial Intelligence<address><addrLine>Menlo Park, CA; Cambridge, MA; London</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="363" to="369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Stochastic simulation optimization: an optimal computing budget allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>World Scientific Pub Co Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Simulation Budget Allocation for Further Enhancing the Efficiency of Ordinal Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yücesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Event Dynamic Systems</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="251" to="270" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A multi-objective selection procedure of determining a Pareto set</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Operations Research</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1872" to="1879" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">New greedy myopic and existing asymptotic sequential selection procedures: preliminary empirical results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Winter Simulation Conference</title>
		<editor>S. G. Henderson, B. Biller, M.-H. Hsieh, J. Shortle, J. D. Tew, and R. R. Barton</editor>
		<meeting>the 2007 Winter Simulation Conference<address><addrLine>Piscataway, New Jersey</addrLine></address></meeting>
		<imprint>
			<publisher>Institute of Electrical and Electronics Engineers, Inc</publisher>
			<date type="published" when="2007-12" />
			<biblScope unit="page" from="289" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sequential Sampling to Myopically Maximize the Expected Value of Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Branke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">INFORMS Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="80" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Economic Analysis of Simulation Selection Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="421" to="437" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">New Procedures to Select the Best Simulated System Using Common Random Numbers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Inoue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1133" to="1149" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">New Two-Stage and Sequential Procedures for Selecting the Best Simulated System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Inoue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="732" to="743" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Optimal Statistical Decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Degroot</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970" />
			<publisher>McGraw Hill</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Knowledge-Gradient Methods for Statistical Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frazier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>Princeton University</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph. D. thesis</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Wiley Encyclopedia of Operations Research and Management Science, Chapter Learning with Dynamic Programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frazier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The Knowledge-Gradient Stopping Rule for Ranking and Selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frazier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Powell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Winter Simulation Conference</title>
		<editor>S. J. Mason, R. R. Hill, L. Moench, O. Rose, T. Jefferson, and J. W. Fowler</editor>
		<meeting>the 2008 Winter Simulation Conference<address><addrLine>Piscataway, New Jersey</addrLine></address></meeting>
		<imprint>
			<publisher>Institute of Electrical and Electronics Engineers, Inc</publisher>
			<date type="published" when="2008-12" />
			<biblScope unit="page" from="305" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A Knowledge Gradient Policy for Sequential Information Collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frazier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dayanik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Control and Optimization</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2410" to="2439" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The Knowledge Gradient Policy for Correlated Normal Beliefs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frazier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dayanik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">INFORMS Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="599" to="613" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Methodology for measuring health-state preferences-II: Scaling methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Froberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Clinical Epidemiology</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="459" to="471" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Bayesian data analysis. second ed</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rubin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>CRC Press</publisher>
			<pubPlace>Boca Raton, FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Bayesian look ahead one-stage sampling allocations for selection of the best population</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Miescke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of statistical planning and inference</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="229" to="244" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Information Value Theory&quot;. Systems Science and Cybernetics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Howard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="26" />
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Decisions with multiple objectives: Preferences and value tradeoffs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Keeney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Raiffa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
		<respStmt>
			<orgName>Cambridge Univ Pr</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Finding the pareto set for multi-objective simulation models by minimization of expected opportunity cost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Teng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Winter Simulation Frazier and Kazachkov</title>
		<meeting>the 2007 Winter Simulation Frazier and Kazachkov</meeting>
		<imprint>
			<date type="published" when="2007-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Finding the non-dominated pareto set for multi-objective simulation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><forename type="middle">S G</forename><surname>Conference</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Biller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Shortle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Tew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barton ; Inc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Goldsman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IIE Transactions</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="656" to="674" />
			<date type="published" when="2010" />
			<publisher>Institute of Electrical and Electronics Engineers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Application of multi-objective simulation-optimization techniques to inventory management problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lendermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Koh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2005 Winter Simulation Conference</title>
		<editor>M. E. Kuhl, N. M. Steiger, F. B</editor>
		<meeting>the 2005 Winter Simulation Conference</meeting>
		<imprint>
			<date type="published" when="2005-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Armstrong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Joines</surname></persName>
		</author>
		<imprint>
			<publisher>Institute of Electrical and Electronics Engineers, Inc</publisher>
			<biblScope unit="page" from="1684" to="1691" />
			<pubPlace>Piscataway, New Jersey</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Bayesian Simulation and Decision Analysis: An Expository Survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Merrick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision Analysis</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="222" to="238" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Ranking and Selection with Multiple Targets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Morrice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Butler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Winter Simulation Conference</title>
		<editor>L. F. Perrone, F. P. Wieland, J. Liu, B. G</editor>
		<meeting>the 2006 Winter Simulation Conference</meeting>
		<imprint>
			<date type="published" when="2006-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Lawson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Nicol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fujimoto</surname></persName>
		</author>
		<imprint>
			<publisher>Institute of Electrical and Electronics Engineers, Inc</publisher>
			<biblScope unit="page" from="222" to="230" />
			<pubPlace>Piscataway, New Jersey</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
