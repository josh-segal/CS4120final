<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>the complexity of predicting atomicity violations</p>
    <p>Azadeh Farzan Univ of Toronto</p>
    <p>P. Madhusudan Univ of Illinois at Urbana Champaign</p>
    <p>.</p>
  </div>
  <div class="page">
    <p>Motivation: Interleaving explosion problem</p>
    <p>Testing is the main technique for correctness in the industry</p>
    <p>Fundamentally challenged for concurrent programs:  Given even a single test input for a concurrent</p>
    <p>program, testing is hard!  Too many interleavings to check thoroughly</p>
    <p>Idea: Select a small subset of interleavings to test that are likely to expose concurrency bugs</p>
  </div>
  <div class="page">
    <p>How to select schedules cleverly  CHESS: Microsoft Research</p>
    <p>Explores all possible interleavings with at most k context-switches, for a small k. We believe atomicity errors will constitute a far smaller but more interesting</p>
    <p>class of runs to test.</p>
    <p>A bunch of tools that try to somehow come up with interleavings that may have errors  Eg. ConTest: IBM</p>
    <p>Our view: Dont look randomly for schedules! Look systematically for interesting patterns of thread interaction that are more likely to have errors.</p>
  </div>
  <div class="page">
    <p>In this talk: Atomicity Atomicity : One particular high-level pattern that gets violated</p>
    <p>in many concurrency bugs:</p>
    <p>A local piece of code needs to access shared data without (real) interference from other threads.</p>
    <p>Extremely common intention, the violation of which leads to many errors.</p>
    <p>In concurrency bug studies, we as well as others (Lu-Park-Seo-Zhou08) have found that the majority of</p>
    <p>errors (~70%) are due to atomicity violations.  Hence finding executions that violate atomicity and testing them is a good way to prune the interleavings to test!</p>
  </div>
  <div class="page">
    <p>https://bugzilla.mozilla.org/show_bug.cgi?id=290446</p>
    <p>Summary: Update of remote calendar does not use WebDAV locking (concurrency control)</p>
    <p>When updating/inserting a new event in a remote WebDAV calendar, the calendar file is not locked. In order to avoid losing data the concurrency control of WebDAV should be used (Locking).</p>
    <p>Steps to Reproduce:  1. User A starts creating a new event in the remote calendar  2. User B starts creating a new event in the remote calendar  3. Users A and B read-modify-write operations are interleaved incorrectly</p>
    <p>Actual Results: The actual sequence could/would be: 1. User A - GET test.ics 2. User B GET test.ics 3. User A - PUT test.ics 4. User B - PUT test.ics</p>
    <p>In this case the new event posted by user A is lost.</p>
    <p>Atomicity error: example</p>
  </div>
  <div class="page">
    <p>Atomicity</p>
    <p>An execution r of a concurrent program P is atomic if there exists an equivalent run of P in which every transaction is non-interleaved.</p>
    <p>Transaction: sequential logical unit of computation: syntactically identified: small methods, procedures, etc.</p>
    <p>execution</p>
    <p>equivalent serial execution</p>
  </div>
  <div class="page">
    <p>Application: Finding bugs while testing</p>
    <p>Run concurrent program on test input</p>
    <p>Concurrent Program Annotate (heuristically) blocks of code that we</p>
    <p>suspect should execute atomically Example: Annotate all methods/procedures in a</p>
    <p>Java program</p>
    <p>BUGS Test input</p>
    <p>under a test harness that</p>
    <p>checks for errors</p>
    <p>Obtain one execution (respects transaction</p>
    <p>boundaries)</p>
    <p>Predict alternate schedules</p>
    <p>that violate atomicity</p>
    <p>Run alternate schedules against</p>
    <p>test harness</p>
  </div>
  <div class="page">
    <p>Main problem</p>
    <p>Given programs P1 || P2 ||. Pn where  Each Pi is be a straight-line program</p>
    <p>(useful when attacking the testing problem)</p>
    <p>Each Pi is be a regular program (modeled as finite automata; useful in abstracted pgms)</p>
    <p>Each Pi is a recursive program (modeled as PDS; for abstracted pgms with recursion)</p>
    <p>Question: Is there any interleaved run that violates atomicity?</p>
  </div>
  <div class="page">
    <p>Atomicity based on Serializability; When are two runs equivalent?</p>
    <p>Concurrent Run: sequence of events.</p>
    <p>Events: { T:begin, T:end } U { T:read(x) , T:write(x) | x is a shared var }</p>
    <p>Dependence/ Conflicting events:</p>
    <p>Serial Run: all transactions are executed noninterleaved.</p>
    <p>Atomic (Serializable) Run: there exists an equivalent serial run.</p>
    <p>Equivalence of Runs: two runs are equivalent if conflicting events are not reordered</p>
    <p>r ~ r' iff for every e1 D e2, r  {e1, e2 }= r'</p>
    <p>{e1, e2 }</p>
  </div>
  <div class="page">
    <p>Atomicity based on Serializability</p>
    <p>T1: T1: read(x) T1: read (y) T2: T2: write(y) T2: write(x) T2: T1: write(z1)</p>
    <p>T1:</p>
    <p>Ind</p>
  </div>
  <div class="page">
    <p>Atomicity based on Serializability</p>
    <p>T1: T1: read(x) T1: read (y) T2: T2: write(y)</p>
    <p>T1: write(z1) T1:</p>
    <p>T2: write(x) T2:</p>
    <p>Ind</p>
  </div>
  <div class="page">
    <p>Atomicity based on Serializability</p>
    <p>T1: T1: read(x) T1: read (y)</p>
    <p>T1: write(z1) T1:</p>
    <p>T2: T2: write(y) T2: write(x) T2:</p>
  </div>
  <div class="page">
    <p>Before we predict, can we monitor atomicity efficiently?</p>
    <p>Monitoring: Given an execution r, is r atomic?</p>
    <p>An extremely satisfactory solution [Farzan-Madhusudan: CAV08]</p>
    <p>We can build sound and complete monitoring algorithms that keeps track of: - a set of vars for each thread - a graph with vertices as threads</p>
    <p>If #vars = V, # threads = n, then algorithm uses O(n2 + nV) space.</p>
    <p>Efficient streaming algorithm. Independent of length of run!</p>
  </div>
  <div class="page">
    <p>Predicting Atomicity Violations</p>
    <p>Example:</p>
    <p>Given programs P1 and P2 (here straight-line) check whether there is an interleaving that violates atomicity.</p>
    <p>T1: begin T1: acq (l) T1: read(Amount) T1: rel (l)</p>
    <p>T2: begin T2: acq (l) T2: read(Amount) T2: rel (l) T2: acq(l) T2: write(Amount) T2: rel(l) T2: end</p>
    <p>T1: acq(l) T1: write(Amount) T1: rel(l) T1: end</p>
    <p>T1: begin T1: acq (l) T1: read(Amount) T1: rel (l) T1: acq(l) T1: write(Amount) T1: rel(l) T1: end</p>
    <p>T2: begin T2: acq (l) T2: read(Amount) T2: rel (l) T2: acq(l) T2: write(Amount) T2: rel(l) T2: end</p>
    <p>P1:</p>
    <p>P2:</p>
    <p>Interleaved execution of P1 and P2 that violates atomicity</p>
  </div>
  <div class="page">
    <p>Prediction Model</p>
    <p>Given an execution r, look at the local executions</p>
    <p>each thread executes r1, r2,  rn</p>
    <p>Can we find another execution r that is obtained by recombining this set of local runs such</p>
    <p>that r is non-atomic?</p>
    <p>Predicted runs could  respect no synchronization constraints (less accurate)  respect concurrency control constraints such as locking (more accurate)</p>
    <p>The run r may not be actually feasible!  Conditionals in programs may lead the program to different code  Certain operations on datastructures may disable other operations .</p>
    <p>Key requirement: We should not enumerate all interleavings!</p>
    <p>Must be more efficient.</p>
    <p>r1 r2 . rn</p>
  </div>
  <div class="page">
    <p>Predicting atomicity violations How to predict atomicity violations for st-line or regular programs?</p>
    <p>Nave algorithm:  Explore all interleavings and monitor each for atomicity violations</p>
    <p>Runs in time O(kn) for n-length runs and k threads --- infeasible in practice!</p>
    <p>Better algorithm: Dynamic programming using the monitoring algm</p>
    <p>Predicting from a single run with a constant number of variables, can be done in time</p>
    <p>O(nk 2k2) ---- better than nk , the number of interleavings</p>
    <p>But even nk is huge! Too large to work in practice even for k=2! (m is 100 million events! k=2,..10,..)</p>
    <p>Also, exponential dependence in k is unavoidable (problem is NP-hard).</p>
    <p>We want to avoid the k being on the exponent of m</p>
    <p>Main question of the paper: Can we solve in time linear in m? (like n+2k) i.e. can we remove the exponent k from n?</p>
  </div>
  <div class="page">
    <p>Main results - I</p>
    <p>Good news: If prediction need not respect any synchronization constraint (no locks)</p>
    <p>Predicting from a single run with a constant number of variables, can be done in time</p>
    <p>O(n + kck) n=length of runs; k= # threads  Regular programs also can be solved in time O(n + kck) where n=size of each local program, k = #threads</p>
    <p>Recursive programs are also (surprisingly) decidable. O(n3 + kck) where n=size of each local program, k = #threads</p>
  </div>
  <div class="page">
    <p>Main results - II</p>
    <p>Bad news: If prediction needs to respect locking, existence of prediction algorithm for regular programs running in time linear in m is unlikely. In fact, algorithms for regular programs that take time a fixed</p>
    <p>polynomial in n is unlikely. i.e. O(poly(m). f(k) ) for any function f() is unlikely!</p>
    <p>The problem is W[1]-hard.</p>
    <p>Also, prediction for concurrent recursive programs in the presence of locks is undecidable.</p>
  </div>
  <div class="page">
    <p>Prediction without synchronization constraints</p>
    <p>Idea: Compositional reasoning  Extract from each local thread run a small amount</p>
    <p>of information (in time linear in the run)  Combine the information across threads to check</p>
    <p>for atomicity violations</p>
    <p>Information needed from each local run is called a profile.</p>
  </div>
  <div class="page">
    <p>Profiles  Key idea: If there is a serializability violation, then there are really only two events in each thread that are important! Also, we need to know if these events occur in the same</p>
    <p>transaction or not. Let r be a local run of a thread T. Profiles of r are:  T:beg T:a T:end event a occurs in r  T:beg T:a T:b T:end a occurs followed by b</p>
    <p>within the same transaction  T:beg T:a T:end T:beg T:b T:end a occurs followed by b</p>
    <p>but in different transactions</p>
  </div>
  <div class="page">
    <p>Reasoning atomicity using profiles</p>
    <p>Key lemma:</p>
    <p>A set of programs with no locks (straight-line, regular or recursive) has a non-serializable execution if</p>
    <p>there is a profile of each local program such that the profiles, viewed as a program, have a non-serializable execution.</p>
    <p>Proof idea: skeleton of a serializability violation:</p>
    <p>Only two events per thread are needed to witness cycle for non-serializability</p>
  </div>
  <div class="page">
    <p>Prediction without synchronization constraints</p>
    <p>Straight-line and regular programs: O(n+kck) time  Extract profiles from each local program</p>
    <p>O(n) time --- constant number of profiles  Check if the profiles have a serializability violation</p>
    <p>O(kck) time  check all possible interleavings of profiles for serializability violations</p>
    <p>Recursive programs: O(n3+kck) time  Extract profiles from each local thread using PDS reachability</p>
    <p>O(n3) time  Check if profiles have a serializability violation O(kck) time</p>
  </div>
  <div class="page">
    <p>Prediction with locking constraints</p>
    <p>Consider a set of regular programs P1 || P2 ||. Pn  Then it is unlikely that the atomicity prediction problem is solvable in time O(poly(n). f(k)) for any function f ! i.e. we cannot remove the exponent k from n</p>
    <p>How do we prove this?  Using parameterized complexity theory  The problem is W[1]-hard (with parameter k).</p>
  </div>
  <div class="page">
    <p>Prediction with locking constraints</p>
    <p>Parameterized complexity theory:  Consider an algorithmic problem where input is of length n, but every instance has a parameter k associated with it.  A problem is fixed-parameter tractable (FPT) over parameter k if it is solvable in time O(poly(n). f(k)) where f() is any function.  I.e. solved in a fixed-polynomial time in n, for any k.</p>
    <p>W[1]-hard problems  No fixed-parameter algorithms known  Believed not to be FPT.</p>
    <p>Example:  Vertex cover is FPT in parameter k=number of colors  Independent-set is W[1]-hard in parameter k = number of sets</p>
  </div>
  <div class="page">
    <p>Prediction with locking constraints</p>
    <p>Prediction of atomicity violations in regular programs is W[1]-hard  Hence an algorithm that runs in time O(poly(n).f(k)) is unlikely (let alone an algorithm that runs linear in n).</p>
    <p>Proof is by a (parameterized) reduction from the finite-state automata intersection problem (where the parameter is the number of automata), which is known to be W[1]-hard.</p>
    <p>Note:  Prediction of atomicity violations in straight-line programs is still open!</p>
    <p>Prediction of atomicity violations in recursive programs is undecidable  not surprising as locks can be used to communicate (Kahlon et al)</p>
  </div>
  <div class="page">
    <p>Current and future directions</p>
    <p>Key project:  Testing tool that executes alternate schedules that violate atomicity</p>
    <p>in order to find bugs.</p>
    <p>More recent work has shown that nested locking yields tractable algorithms! (using ideas from Kahlon et al)</p>
    <p>For non-nested locking, in practice, one can do more coarse analysis simply using locksets, and this yields reasonably good prediction algorithms.</p>
    <p>Open problem:  Atomicity for straight-line programs with locks still open.</p>
  </div>
</Presentation>
