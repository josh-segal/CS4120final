<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Generating Realistic Datasets</p>
    <p>for Deduplication Analysis</p>
    <p>Vasily Tarasov1, Amar Mudrankit1, Will Buik2,</p>
    <p>Philip Shilane3, Geoff Kuenning2, Erez Zadok1</p>
  </div>
  <div class="page">
    <p>Overview</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>Deduplication</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>Deduplication</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>Deduplication</p>
    <p>Wait, deduplication performance depends on the data Everyone uses different datasets</p>
  </div>
  <div class="page">
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Deduplication Basics</p>
    <p>Original data:</p>
    <p>Coarse-grained data compression technique:</p>
  </div>
  <div class="page">
    <p>Deduplication Basics</p>
    <p>Original data:</p>
    <p>Duplicates (3 of 10)</p>
    <p>Coarse-grained data compression technique:</p>
  </div>
  <div class="page">
    <p>Deduplication Basics</p>
    <p>Deduplicated data:</p>
    <p>Original data:</p>
    <p>Duplicates (3 of 10)</p>
    <p>Mapping:</p>
    <p>Coarse-grained data compression technique:</p>
  </div>
  <div class="page">
    <p>Deduplication Basics</p>
    <p>Deduplicated data:</p>
    <p>Original data:</p>
    <p>Duplicates (3 of 10)</p>
    <p>Mapping:</p>
    <p>savings</p>
    <p>Coarse-grained data compression technique:</p>
  </div>
  <div class="page">
    <p>Index:</p>
    <p>Mapping:</p>
    <p>Typical Ingest Datapath 1. Chunking</p>
    <p>Determine boundaries in the data  File boundaries</p>
    <p>Fixed-size chunking</p>
    <p>Variable chunking using Rabin fingerprints</p>
    <p>More intelligent ways, e.g., content-type-aware</p>
    <p>Collision-resistant</p>
    <p>Cryptographic</p>
    <p>SHA256, MD5 (plus byte-by-byte comparison)</p>
    <p>Create mapping entries</p>
    <p>x1 x2 x3 x4</p>
    <p>Disk</p>
  </div>
  <div class="page">
    <p>Index:</p>
    <p>Mapping:</p>
    <p>Typical Ingest Datapath 1. Chunking</p>
    <p>Determine boundaries in the data  File boundaries</p>
    <p>Fixed-size chunking</p>
    <p>Variable chunking using Rabin fingerprints</p>
    <p>More intelligent ways, e.g., content-type-aware</p>
    <p>Collision-resistant</p>
    <p>Cryptographic</p>
    <p>SHA256, MD5 (plus byte-by-byte comparison)</p>
    <p>Create mapping entries</p>
    <p>x1 x2 x3 x4</p>
    <p>x1 Disk</p>
  </div>
  <div class="page">
    <p>Index:</p>
    <p>Mapping:</p>
    <p>Typical Ingest Datapath 1. Chunking</p>
    <p>Determine boundaries in the data  File boundaries</p>
    <p>Fixed-size chunking</p>
    <p>Variable chunking using Rabin fingerprints</p>
    <p>More intelligent ways, e.g., content-type-aware</p>
    <p>Collision-resistant</p>
    <p>Cryptographic</p>
    <p>SHA256, MD5 (plus byte-by-byte comparison)</p>
    <p>Create mapping entries</p>
    <p>x1 x2 x3 x4</p>
    <p>x1 x2 Disk</p>
  </div>
  <div class="page">
    <p>Index:</p>
    <p>Mapping:</p>
    <p>Typical Ingest Datapath 1. Chunking</p>
    <p>Determine boundaries in the data  File boundaries</p>
    <p>Fixed-size chunking</p>
    <p>Variable chunking using Rabin fingerprints</p>
    <p>More intelligent ways, e.g., content-type-aware</p>
    <p>Collision-resistant</p>
    <p>Cryptographic</p>
    <p>SHA256, MD5 (plus byte-by-byte comparison)</p>
    <p>Create mapping entries</p>
    <p>x1 x2 x3 x4</p>
    <p>x1 x2 x3 Disk</p>
  </div>
  <div class="page">
    <p>Index:</p>
    <p>Mapping:</p>
    <p>Typical Ingest Datapath 1. Chunking</p>
    <p>Determine boundaries in the data  File boundaries</p>
    <p>Fixed-size chunking</p>
    <p>Variable chunking using Rabin fingerprints</p>
    <p>More intelligent ways, e.g., content-type-aware</p>
    <p>Collision-resistant</p>
    <p>Cryptographic</p>
    <p>SHA256, MD5 (plus byte-by-byte comparison)</p>
    <p>Create mapping entries</p>
    <p>x1 x2 x3 x4</p>
    <p>x1 x2 x3 x4 Disk</p>
  </div>
  <div class="page">
    <p>How Efficient is Deduplication?</p>
    <p>High deduplication ratios for certain datasets</p>
    <p>Backups: 15 [Wallace2012]</p>
    <p>Virtual machine images: 7 [Smith2008]</p>
    <p>Multi-tenant shared storage: 3 [Meyer2011]</p>
    <p>Fastest growing segment of storage industry [NetApp/IDC 2011]</p>
    <p>80%+ of corporations are exploring deduplication [IDC 2011]</p>
    <p>Challenges:</p>
    <p>Performance  Computationally intensive</p>
    <p>Out of RAM indexes</p>
    <p>Fragmentation</p>
    <p>Manageability, reliability</p>
  </div>
  <div class="page">
    <p>How Efficient is Deduplication?</p>
    <p>High deduplication ratios for certain datasets</p>
    <p>Backups: 15 [Wallace2012]</p>
    <p>Virtual machine images: 7 [Smith2008]</p>
    <p>Multi-tenant shared storage: 3 [Meyer2011]</p>
    <p>Fastest growing segment of storage industry [NetApp/IDC 2011]</p>
    <p>80%+ of corporations are exploring deduplication [IDC 2011]</p>
    <p>Challenges:</p>
    <p>Performance  Computationally intensive</p>
    <p>Out of RAM indexes</p>
    <p>Fragmentation</p>
    <p>Manageability, reliability</p>
    <p>Variety of optimizations:</p>
    <p>Intelligent caching</p>
    <p>Intelligent prefetching</p>
    <p>Bloom filters</p>
    <p>Content-aware chunking</p>
  </div>
  <div class="page">
    <p>Survey of Datasets  33 research papers</p>
    <p>FAST, ATC, MSST, SYSTOR conferences</p>
    <p>120 datasets</p>
  </div>
  <div class="page">
    <p>Survey of Datasets  33 research papers</p>
    <p>FAST, ATC, MSST, SYSTOR conferences</p>
    <p>120 datasets</p>
    <p>Private</p>
    <p>Public, but hardly</p>
    <p>possible to reproduce</p>
    <p>Public, less than 1GB</p>
    <p>Synthetic, simplistic</p>
    <p>OS Images</p>
  </div>
  <div class="page">
    <p>Survey of Datasets  33 research papers</p>
    <p>FAST, ATC, MSST, SYSTOR conferences</p>
    <p>120 datasets</p>
    <p>Private</p>
    <p>Public, but hardly</p>
    <p>possible to reproduce</p>
    <p>Public, less than 1GB</p>
    <p>Synthetic, simplistic</p>
    <p>OS Images</p>
  </div>
  <div class="page">
    <p>Survey of Datasets  33 research papers</p>
    <p>FAST, ATC, MSST, SYSTOR conferences</p>
    <p>120 datasets</p>
    <p>Private</p>
    <p>Public, but hardly</p>
    <p>possible to reproduce</p>
    <p>Public, less than 1GB</p>
    <p>Synthetic, simplistic</p>
    <p>OS Images</p>
  </div>
  <div class="page">
    <p>Survey of Datasets  33 research papers</p>
    <p>FAST, ATC, MSST, SYSTOR conferences</p>
    <p>120 datasets</p>
    <p>Private</p>
    <p>Public, but hardly</p>
    <p>possible to reproduce</p>
    <p>Public, less than 1GB</p>
    <p>Synthetic, simplistic</p>
    <p>OS Images</p>
  </div>
  <div class="page">
    <p>Survey of Datasets  33 research papers</p>
    <p>FAST, ATC, MSST, SYSTOR conferences</p>
    <p>120 datasets</p>
    <p>Private</p>
    <p>Public, but hardly</p>
    <p>possible to reproduce</p>
    <p>Public, less than 1GB</p>
    <p>Synthetic, simplistic</p>
    <p>OS Images</p>
  </div>
  <div class="page">
    <p>Survey of Datasets  33 research papers</p>
    <p>FAST, ATC, MSST, SYSTOR conferences</p>
    <p>120 datasets</p>
    <p>Private</p>
    <p>Public, but hardly</p>
    <p>possible to reproduce</p>
    <p>Public, less than 1GB</p>
    <p>Synthetic, simplistic</p>
    <p>OS Images</p>
  </div>
  <div class="page">
    <p>Survey of Datasets  33 research papers</p>
    <p>FAST, ATC, MSST, SYSTOR conferences</p>
    <p>120 datasets</p>
    <p>Private</p>
    <p>Public, but hardly</p>
    <p>possible to reproduce</p>
    <p>Public, less than 1GB</p>
    <p>Synthetic, simplistic</p>
    <p>OS Images</p>
  </div>
  <div class="page">
    <p>The Need for Datasets</p>
    <p>Accessible</p>
    <p>Realistic</p>
    <p>Sufficiently large</p>
    <p>Easy to distribute</p>
    <p>With controllable characteristics</p>
    <p>To perform true, versatile, and easy evaluation</p>
    <p>and comparison of deduplication systems</p>
    <p>Generate</p>
    <p>datasets</p>
    <p>Requirements:</p>
  </div>
  <div class="page">
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Insight</p>
    <p>time time time</p>
    <p>Original</p>
    <p>FS Tree</p>
    <p>Original</p>
    <p>FS Tree</p>
    <p>User 2</p>
    <p>time</p>
    <p>time</p>
    <p>time</p>
    <p>changes changes changes</p>
    <p>Updated</p>
    <p>FS Tree Updated</p>
    <p>FS Tree</p>
    <p>Updated</p>
    <p>FS Tree</p>
    <p>changes</p>
    <p>changes</p>
    <p>changes</p>
    <p>Complete Dataset</p>
    <p>Complete Dataset</p>
  </div>
  <div class="page">
    <p>Insight</p>
    <p>time time time</p>
    <p>Original</p>
    <p>FS Tree</p>
    <p>Original</p>
    <p>FS Tree</p>
    <p>User 2</p>
    <p>time</p>
    <p>time</p>
    <p>time</p>
    <p>changes changes changes</p>
    <p>Updated</p>
    <p>FS Tree Updated</p>
    <p>FS Tree</p>
    <p>Updated</p>
    <p>FS Tree</p>
    <p>changes</p>
    <p>changes</p>
    <p>changes</p>
    <p>Complete Dataset</p>
    <p>Complete Dataset</p>
    <p>File System Mutation</p>
  </div>
  <div class="page">
    <p>Framework Objects</p>
    <p>FSTREE</p>
    <p>Per-snapshot</p>
    <p>In-memory</p>
    <p>DIRECTORY</p>
    <p>FILE</p>
    <p>CHUNK</p>
    <p>Chunk identifiers</p>
    <p>Roughly correspond to hashes</p>
    <p>Per-file lists of chunks</p>
  </div>
  <div class="page">
    <p>Framework Objects</p>
    <p>FSTREE</p>
    <p>Per-snapshot</p>
    <p>In-memory</p>
    <p>DIRECTORY</p>
    <p>FILE</p>
    <p>CHUNK</p>
    <p>Chunk identifiers</p>
    <p>Roughly correspond to hashes</p>
    <p>Per-file lists of chunks</p>
  </div>
  <div class="page">
    <p>Framework Objects</p>
    <p>FSTREE</p>
    <p>Per-snapshot</p>
    <p>In-memory</p>
    <p>DIRECTORY</p>
    <p>FILE</p>
    <p>CHUNK</p>
    <p>Chunk identifiers</p>
    <p>Roughly correspond to hashes</p>
    <p>Per-file lists of chunks</p>
  </div>
  <div class="page">
    <p>Framework Objects</p>
    <p>FSTREE</p>
    <p>Per-snapshot</p>
    <p>In-memory</p>
    <p>DIRECTORY</p>
    <p>FILE</p>
    <p>CHUNK</p>
    <p>Chunk identifiers</p>
    <p>Roughly correspond to hashes</p>
    <p>Per-file lists of chunks</p>
    <p>Total: 1PB dataset</p>
    <p>still 64GB of RAM</p>
  </div>
  <div class="page">
    <p>Mutation Conveyor</p>
    <p>FSTREE</p>
    <p>FS-MUTATE</p>
    <p>profile</p>
    <p>FSTREE</p>
    <p>FS-MUTATE</p>
    <p>profile</p>
    <p>FSTREE</p>
    <p>FS-MUTATE</p>
    <p>profile</p>
    <p>FSTREE</p>
    <p>FS-CREATE</p>
    <p>FS-CREATE</p>
    <p>FS-CREATE</p>
    <p>FS-CREATE</p>
  </div>
  <div class="page">
    <p>Mutation Conveyor</p>
    <p>FSTREE</p>
    <p>FS-MUTATE</p>
    <p>profile</p>
    <p>FSTREE</p>
    <p>FS-MUTATE</p>
    <p>profile</p>
    <p>FSTREE</p>
    <p>FS-MUTATE</p>
    <p>profile</p>
    <p>FSTREE</p>
    <p>FS-CREATE</p>
    <p>FS-CREATE</p>
    <p>FS-CREATE</p>
    <p>FS-CREATE</p>
  </div>
  <div class="page">
    <p>Mutation Conveyor</p>
    <p>FSTREE</p>
    <p>FS-MUTATE</p>
    <p>profile</p>
    <p>FSTREE</p>
    <p>FS-MUTATE</p>
    <p>profile</p>
    <p>FSTREE</p>
    <p>FS-MUTATE</p>
    <p>profile</p>
    <p>FSTREE</p>
    <p>FS-CREATE</p>
    <p>On-disk file system</p>
    <p>Tar-like files</p>
    <p>Incremental backups</p>
    <p>FS-CREATE</p>
    <p>FS-CREATE</p>
    <p>FS-CREATE</p>
  </div>
  <div class="page">
    <p>Initial File System Tree</p>
    <p>FS-SCAN FSTREE</p>
    <p>FS-PROFILE</p>
    <p>Content profile</p>
    <p>Meta profile FS-IMPRESSION</p>
    <p>empty</p>
    <p>FSTREE FS-POPULATE</p>
    <p>/some/file/system</p>
    <p>/some/file/system</p>
  </div>
  <div class="page">
    <p>Initial File System Tree</p>
    <p>FS-SCAN FSTREE</p>
    <p>FS-PROFILE</p>
    <p>Content profile</p>
    <p>Meta profile FS-IMPRESSION</p>
    <p>empty</p>
    <p>FSTREE FS-POPULATE</p>
    <p>/some/file/system</p>
    <p>/some/file/system Using existing file system</p>
  </div>
  <div class="page">
    <p>Initial File System Tree</p>
    <p>FS-SCAN FSTREE</p>
    <p>FS-PROFILE</p>
    <p>Content profile</p>
    <p>Meta profile FS-IMPRESSION</p>
    <p>empty</p>
    <p>FSTREE FS-POPULATE</p>
    <p>/some/file/system</p>
    <p>/some/file/system</p>
    <p>Using profile</p>
  </div>
  <div class="page">
    <p>Initial File System Tree</p>
    <p>FS-SCAN FSTREE</p>
    <p>FS-PROFILE</p>
    <p>Content profile</p>
    <p>Meta profile FS-IMPRESSION</p>
    <p>empty</p>
    <p>FSTREE FS-POPULATE</p>
    <p>/some/file/system</p>
    <p>/some/file/system</p>
    <p>Using profile</p>
  </div>
  <div class="page">
    <p>Initial File System Tree</p>
    <p>FS-SCAN FSTREE</p>
    <p>FS-PROFILE</p>
    <p>Content profile</p>
    <p>Meta profile FS-IMPRESSION</p>
    <p>empty</p>
    <p>FSTREE FS-POPULATE</p>
    <p>/some/file/system</p>
    <p>/some/file/system</p>
    <p>Using profile</p>
  </div>
  <div class="page">
    <p>Initial File System Tree</p>
    <p>FS-SCAN FSTREE</p>
    <p>FS-PROFILE</p>
    <p>Content profile</p>
    <p>Meta profile FS-IMPRESSION</p>
    <p>empty</p>
    <p>FSTREE FS-POPULATE</p>
    <p>/some/file/system</p>
    <p>/some/file/system</p>
    <p>Using profile</p>
  </div>
  <div class="page">
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Main Idea</p>
    <p>Consecutive snapshots of real datasets</p>
    <p>Scan live file systems periodically</p>
    <p>Use existing backup data</p>
    <p>Software or data releases (e.g., Linux kernels)</p>
    <p>Observe statistics of changes</p>
    <p>Markov Model</p>
    <p>Multi-dimensional distribution</p>
  </div>
  <div class="page">
    <p>Markov Model: File States</p>
    <p>New Deleted</p>
    <p>Modified</p>
    <p>Unmodif.</p>
  </div>
  <div class="page">
    <p>Markov Model: File States</p>
    <p>New Deleted p(N)</p>
    <p>p(ND)</p>
    <p>p(NM)</p>
    <p>p(MM)</p>
    <p>p(MD)</p>
    <p>p(MU) p(UM)</p>
    <p>p(UU)</p>
    <p>p(NU) p(UD)</p>
    <p>p(DN)</p>
    <p>p(D)</p>
    <p>Modified</p>
    <p>Unmodif.</p>
  </div>
  <div class="page">
    <p>Markov Model: File States</p>
    <p>New Deleted p(N)</p>
    <p>p(ND)</p>
    <p>p(NM)</p>
    <p>p(MM)</p>
    <p>p(MD)</p>
    <p>p(MU) p(UM)</p>
    <p>p(UU)</p>
    <p>p(NU) p(UD)</p>
    <p>p(DN)</p>
    <p>p(D)</p>
    <p>modified</p>
    <p>modified</p>
    <p>P(MM) = 80%</p>
    <p>Modified</p>
    <p>Unmodif.</p>
    <p>s1 s2 s3</p>
  </div>
  <div class="page">
    <p>Markov Model: File States Home</p>
    <p>Directories</p>
    <p>New Deleted p(N)</p>
    <p>p(ND)</p>
    <p>p(NM)</p>
    <p>p(MM)</p>
    <p>p(MD)</p>
    <p>p(MU) p(UM)</p>
    <p>p(UU)</p>
    <p>p(NU) p(UD)</p>
    <p>p(DN)</p>
    <p>p(D)</p>
    <p>modified</p>
    <p>modified</p>
    <p>P(MM) = 80%</p>
    <p>Modified</p>
    <p>Unmodif.</p>
    <p>s1 s2 s3</p>
  </div>
  <div class="page">
    <p>Markov Model: File States Home</p>
    <p>Directories</p>
    <p>New Deleted p(N)</p>
    <p>p(ND)</p>
    <p>p(NM)</p>
    <p>p(MM)</p>
    <p>p(MD)</p>
    <p>p(MU) p(UM)</p>
    <p>p(UU)</p>
    <p>p(NU) p(UD)</p>
    <p>p(DN)</p>
    <p>p(D)</p>
    <p>modified</p>
    <p>modified</p>
    <p>P(MM) = 80%</p>
    <p>Modified</p>
    <p>Unmodif.</p>
    <p>s1 s2 s3</p>
  </div>
  <div class="page">
    <p>Markov Model: File States Home</p>
    <p>Directories</p>
    <p>New Deleted p(N)</p>
    <p>p(ND)</p>
    <p>p(NM)</p>
    <p>p(MM)</p>
    <p>p(MD)</p>
    <p>p(MU) p(UM)</p>
    <p>p(UU)</p>
    <p>p(NU) p(UD)</p>
    <p>p(DN)</p>
    <p>p(D)</p>
    <p>modified</p>
    <p>modified</p>
    <p>P(MM) = 80%</p>
    <p>Modified</p>
    <p>Unmodif.</p>
    <p>s1 s2 s3</p>
  </div>
  <div class="page">
    <p>Multi-dimensional Distribution: New Files</p>
    <p>Dimensions:</p>
    <p>Directory Depth</p>
    <p>File Extension</p>
    <p>Size (in chunks)</p>
    <p>Unique chunks</p>
    <p>Chunks with 1 duplicate</p>
    <p>Chunks with 2 duplicates</p>
    <p>Compared to</p>
    <p>previous snapshot</p>
    <p>s1 s2</p>
  </div>
  <div class="page">
    <p>Multi-dimensional Distribution: New Files</p>
    <p>Dimensions:</p>
    <p>Directory Depth</p>
    <p>File Extension</p>
    <p>Size (in chunks)</p>
    <p>Unique chunks</p>
    <p>Chunks with 1 duplicate</p>
    <p>Chunks with 2 duplicates</p>
    <p>Compared to</p>
    <p>previous snapshot</p>
    <p>Mnew(depth, ext, size_chunks, uniq, dup1,dup2)</p>
    <p>Mnew: number of new files with corresponding properties</p>
    <p>Example: Mnew(2, .c, 7, 3, 2,2) = 10</p>
    <p>s1 s2</p>
  </div>
  <div class="page">
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Datasets</p>
    <p>Name Snapshot</p>
    <p>number</p>
    <p>Files per</p>
    <p>snapshot</p>
    <p>(1000)</p>
    <p>Snapshot</p>
    <p>size</p>
    <p>(GB)</p>
    <p>Total</p>
    <p>Files</p>
    <p>(1000)</p>
    <p>Total</p>
    <p>Size</p>
    <p>(GB)</p>
    <p>Kernels (2.6.*) 40 23 0.3 903 13</p>
    <p>CentOS (5.*) 8 195 4.5 1,559 36</p>
    <p>Home 15 weekly 1,023 227 15,352 3,482</p>
    <p>MacOS 71 daily 1,173 59 83,220 4,080</p>
    <p>System Logs 8 weekly 334 78 2,672 626</p>
    <p>Sources 8 weekly 139 162 1,112 1,331</p>
  </div>
  <div class="page">
    <p>Datasets</p>
    <p>Name Snapshot</p>
    <p>number</p>
    <p>Files per</p>
    <p>snapshot</p>
    <p>(1000)</p>
    <p>Snapshot</p>
    <p>size</p>
    <p>(GB)</p>
    <p>Total</p>
    <p>Files</p>
    <p>(1000)</p>
    <p>Total</p>
    <p>Size</p>
    <p>(GB)</p>
    <p>Kernels (2.6.*) 40 23 0.3 903 13</p>
    <p>CentOS (5.*) 8 195 4.5 1,559 36</p>
    <p>Home 15 weekly 1,023 227 15,352 3,482</p>
    <p>MacOS 71 daily 1,173 59 83,220 4,080</p>
    <p>System Logs 8 weekly 334 78 2,672 626</p>
    <p>Sources 8 weekly 139 162 1,112 1,331</p>
  </div>
  <div class="page">
    <p>Datasets</p>
    <p>Name Snapshot</p>
    <p>number</p>
    <p>Files per</p>
    <p>snapshot</p>
    <p>(1000)</p>
    <p>Snapshot</p>
    <p>size</p>
    <p>(GB)</p>
    <p>Total</p>
    <p>Files</p>
    <p>(1000)</p>
    <p>Total</p>
    <p>Size</p>
    <p>(GB)</p>
    <p>Kernels (2.6.*) 40 23 0.3 903 13</p>
    <p>CentOS (5.*) 8 195 4.5 1,559 36</p>
    <p>Home 15 weekly 1,023 227 15,352 3,482</p>
    <p>MacOS 71 daily 1,173 59 83,220 4,080</p>
    <p>System Logs 8 weekly 334 78 2,672 626</p>
    <p>Sources 8 weekly 139 162 1,112 1,331</p>
  </div>
  <div class="page">
    <p>Methodology</p>
    <p>parameters and real parameters</p>
  </div>
  <div class="page">
    <p>File Number and Total Size</p>
    <p>Files (thousands)</p>
    <p>Kernels in the dataset (2.6.0 - 2.6.39)</p>
    <p>Real Synthesized</p>
    <p>Chunks (thousands)</p>
    <p>Kernels in the dataset (2.6.0 - 2.6.39)</p>
    <p>Real Synthesized</p>
  </div>
  <div class="page">
    <p>File Number and Total Size</p>
    <p>Files (thousands)</p>
    <p>Kernels in the dataset (2.6.0 - 2.6.39)</p>
    <p>Real Synthesized</p>
    <p>Chunks (thousands)</p>
    <p>Kernels in the dataset (2.6.0 - 2.6.39)</p>
    <p>Real Synthesized</p>
    <p>Error:</p>
    <p>(for all datasets)</p>
  </div>
  <div class="page">
    <p>Chunk Duplicates: MacOS</p>
    <p>Chunks (log)</p>
    <p>Snapshots in the dataset</p>
    <p>Real Synthesized</p>
    <p>Chunks (log)</p>
    <p>Snapshots in the dataset</p>
    <p>Real Synthesized</p>
    <p>Chunks (log)</p>
    <p>Snapshots in the dataset</p>
    <p>Real Synthesized</p>
    <p>Unique chunks</p>
    <p>Chunks with 1 duplicate</p>
    <p>Chunks with 2 duplicates</p>
  </div>
  <div class="page">
    <p>Chunk Duplicates: MacOS</p>
    <p>Chunks (log)</p>
    <p>Snapshots in the dataset</p>
    <p>Real Synthesized</p>
    <p>Chunks (log)</p>
    <p>Snapshots in the dataset</p>
    <p>Real Synthesized</p>
    <p>Chunks (log)</p>
    <p>Snapshots in the dataset</p>
    <p>Real Synthesized</p>
    <p>Unique chunks</p>
    <p>Chunks with 1 duplicate</p>
    <p>Chunks with 2 duplicates</p>
    <p>Error:</p>
    <p>(for all datasets)</p>
  </div>
  <div class="page">
    <p>Chunk Duplicates: MacOS</p>
    <p>Chunks (log)</p>
    <p>Snapshots in the dataset</p>
    <p>Real Synthesized</p>
    <p>Chunks (log)</p>
    <p>Snapshots in the dataset</p>
    <p>Real Synthesized</p>
    <p>Chunks (log)</p>
    <p>Snapshots in the dataset</p>
    <p>Real Synthesized</p>
    <p>Unique chunks</p>
    <p>Chunks with 1 duplicate</p>
    <p>Chunks with 2 duplicates</p>
    <p>Error:</p>
    <p>(for all datasets)</p>
    <p>Profile sizes:</p>
  </div>
  <div class="page">
    <p>Performance vs. Size</p>
    <p>Mutation Time (minutes)</p>
    <p>Dataset Size (TB)</p>
    <p>Kernel CentOS</p>
    <p>System Logs</p>
    <p>Sources</p>
    <p>MacOS</p>
    <p>Homes</p>
    <p>Intel Xeon 3.3GHz</p>
  </div>
  <div class="page">
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Summary  First technique for generating deduplication datasets</p>
    <p>Realistic properties</p>
    <p>Fair comparison of different deduplication techniques</p>
    <p>Sharing among researchers</p>
    <p>Emulate file system changes</p>
    <p>Generic framework</p>
    <p>Flexible, versatile, and extensible</p>
    <p>Statistical implementation</p>
    <p>Markov Model</p>
    <p>Multi-dimensional statistics</p>
    <p>High accuracy, small model size, high performance</p>
  </div>
  <div class="page">
    <p>Future work</p>
    <p>Study existing deduplication systems</p>
    <p>Create exhaustive list of parameters</p>
    <p>E.g., local chunk compression control</p>
    <p>Initial file system generation</p>
    <p>Convenient usage</p>
    <p>Detect global trend lines</p>
    <p>Statistical clustering</p>
    <p>Analyze other datasets</p>
  </div>
  <div class="page">
    <p>Generating Realistic Datasets for</p>
    <p>Deduplication Analysis</p>
    <p>Vasily Tarasov1, Amar Mudrankit1, Will Buik2,</p>
    <p>Philip Shilane3, Geoff Kuenning2, Erez Zadok1</p>
    <p>Q&amp;A https://avatar.fsl.cs.sunysb.edu/groups/deduplicationpublic/</p>
    <p>Download sources and profiles:</p>
  </div>
</Presentation>
