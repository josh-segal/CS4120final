<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>A DoS-Resilient Information System for Dynamic Data</p>
    <p>Management</p>
    <p>Stefan Schmid &amp; Christian Scheideler</p>
    <p>Dept. of Computer Science</p>
    <p>University of Paderborn</p>
    <p>Matthias Baumgart</p>
    <p>Dept. of Computer Science</p>
    <p>Technische Universitt Mnchen</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>In 2007, a major DoS attack was launched</p>
    <p>against the root servers of the DNS system</p>
    <p>Internet Internet</p>
    <p>d</p>
    <p>d d</p>
    <p>d</p>
    <p>d d</p>
  </div>
  <div class="page">
    <p>DoS-resistant Information System</p>
    <p>Problem: DNS-approach of full replication not feasible in large information systems</p>
    <p>Internet Internet</p>
    <p>off-the-shelf servers</p>
  </div>
  <div class="page">
    <p>DoS-resistant Information System</p>
    <p>Scalable information system: storage overhead limited to logarithmic factor</p>
    <p>Internet Internet</p>
    <p>d</p>
    <p>d</p>
    <p>d</p>
  </div>
  <div class="page">
    <p>DoS-resistant Information System</p>
    <p>storage overhead limited to log factor: scalable put und get operations possible</p>
    <p>Internet Internet</p>
    <p>d</p>
    <p>d</p>
    <p>d</p>
  </div>
  <div class="page">
    <p>DoS-resistant Information System</p>
    <p>storage overhead limited to log factor: but how to be robust against DoS attacks?</p>
    <p>Internet Internet</p>
    <p>d</p>
    <p>d</p>
    <p>d</p>
  </div>
  <div class="page">
    <p>Fundamental Dilemma</p>
    <p>Scalability: minimize replication of information  Robustness: maximize resources needed by</p>
    <p>attacker</p>
    <p>Internet Internet</p>
    <p>d</p>
    <p>d</p>
    <p>d</p>
  </div>
  <div class="page">
    <p>Fundamental Dilemma</p>
    <p>Limitation to legal attacks / information hiding  Information hiding difficult under insider attacks</p>
    <p>Internet Internet</p>
    <p>d</p>
    <p>d</p>
    <p>d</p>
  </div>
  <div class="page">
    <p>DoS-resistant Information System</p>
    <p>Past-Insider-Attack: Attacker knows everything about system till (unknown) time t0</p>
    <p>Goal: scalable information system so that everything that was inserted after t0 is safe (w.h.p.) against any past-insider DoS attack that can shut down any -fraction of the servers, for some &gt;0, and create any legal set of put and get requests</p>
    <p>You are fired!</p>
  </div>
  <div class="page">
    <p>Formal Model</p>
    <p>We are given a static set of n reliable servers.</p>
    <p>-bounded attacker:  knows entire system till time t0 (unknown to system)  can block any -fraction of servers  can generate any set of put/get requests, one per server</p>
    <p>Goals:  Scalability: every server spends at most polylog time and</p>
    <p>work on put and get requests  Robustness: every get request to a data item inserted or</p>
    <p>updated after t0 is served correctly  Correctness: every get request to a data item is served</p>
    <p>correctly if the system is not under DoS-attack</p>
  </div>
  <div class="page">
    <p>DoS-resilient Information System</p>
    <p>Dilemma:  just polylog copies allowed per data item to be</p>
    <p>scalable</p>
    <p>deterministic placement</p>
    <p>??? ???</p>
    <p>randomized placement</p>
  </div>
  <div class="page">
    <p>DoS-resilient Information System</p>
    <p>Basic strategy:  choose suitable hash functions h1,..,hc:DV</p>
    <p>(D: name space of data, V: set of servers)  Store copy of item d for every i and j randomly in a</p>
    <p>set of servers of size 2j that contains hi(d)</p>
    <p>hi(d)</p>
    <p>easy to block</p>
    <p>difficult to block</p>
    <p>easy to find</p>
    <p>difficult to find</p>
  </div>
  <div class="page">
    <p>DoS-resilient Information System</p>
    <p>Tie sufficient for get requests [DISC 07]:  Most get requests can access close-by copies, only</p>
    <p>a few get requests have to find distant copies  Work for each server altogether just polylog(n) for</p>
    <p>any set of n get requests, one per server</p>
    <p>hi(d)</p>
  </div>
  <div class="page">
    <p>DoS-resilient Information System</p>
    <p>Tie sufficient for get requests [DISC 07]:</p>
    <p>BUT for get requests to work, all areas must have up-to-date copies, so put requests may fail under DoS attack</p>
    <p>hi(d)</p>
  </div>
  <div class="page">
    <p>DoS-resilient Information System</p>
    <p>Chameleon system:  Permanent distributed hash table (p-store)</p>
    <p>h1,..,hc fixed, must satisfy expansion properties (that hold w.h.p. for random hash functions)</p>
    <p>Temporary distributed hash table (t-store) hash function h continuously changes</p>
    <p>p-store</p>
    <p>t-store</p>
  </div>
  <div class="page">
    <p>DoS-resilient Information System</p>
    <p>Phase of Chameleon system:</p>
    <p>p-store</p>
    <p>t-store</p>
    <p>Internet</p>
  </div>
  <div class="page">
    <p>Stage 2: Build new t-store</p>
    <p>t-store: distributed hash table (DHT) (de Bruijn network + consistent hashing)</p>
    <p>New t-store:  Join protocol: Every node chooses new random</p>
    <p>location in de Bruijn network, searches for neighbors in p-store</p>
    <p>Insert protocol: Data items in old t-store are stored in new t-store (just O(n) items w.h.p.)</p>
    <p>O(log n) time and congestion w.h.p.</p>
    <p>p-store</p>
  </div>
  <div class="page">
    <p>Stage 3: Process puts in t-store</p>
    <p>t-put protocol: de-Bruijn routing with combining to store data in new t-store</p>
    <p>O(log n) time and O(log2 n) congestion</p>
  </div>
  <div class="page">
    <p>Stage 4: Process get Requests</p>
    <p>t-get protocol: de Bruijn routing with combining to lookup data in t-store (O(log n) time and O(log2 n) congestion)</p>
    <p>p-get protocol (related to [DISC 07]):  Preprocessing stage: determine blocked areas in p-store via</p>
    <p>sampling (O(1) time and O(log2 n) congestion)</p>
    <p>Contraction stage: try to get as close as possible to hash-based positions (O(log n) time and O(log3 n) congestion)</p>
    <p>Expansion stage: look for copies at successively wider areas (O(log2 n) time and O(log3 n) congestion)</p>
  </div>
  <div class="page">
    <p>Contraction Stage</p>
    <p>hi(x)</p>
    <p>log n</p>
  </div>
  <div class="page">
    <p>Expansion Stage</p>
    <p>hi(x)</p>
    <p>log n</p>
    <p>inactive</p>
  </div>
  <div class="page">
    <p>Stage 5: data from t-store to p-store</p>
    <p>p-put protocol:  Preprocessing stage: determine blocked areas and</p>
    <p>average load in p-store via sampling (O(1) time and O(log2 n) congestion)</p>
    <p>Contraction stage: try to get to sufficiently many hash-based positions in p-store (O(log n) time and O(log3 n) congestion)</p>
    <p>Permanent storage stage: for each successful data item, store new copies and delete as many old ones as possible (O(log n) time and O(log2 n) congestion)</p>
  </div>
  <div class="page">
    <p>DoS-resistant Information System</p>
    <p>Theorem: Under any -bounded past-insider attack (for some constant &gt;0), the Chameleon system can serve any set of requests (one per server) in O(log2 n) time s.t. every get request to a data item inserted or updated after t0 is served correctly, w.h.p.</p>
    <p>No degradation over time:  O(log2 n) copies per data item  fair distribution of data among servers</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>Many scalable information systems:  Chord, CAN, Pastry, Tapestry,</p>
    <p>But many of these designs not even robust against flash crowds</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>Caching strategies against flash crowds:  CoopNet, Backlash, PROOFS,  Naor&amp;Wieder 03</p>
    <p>But not robust against adaptive lookup attacks</p>
    <p>a</p>
    <p>b</p>
    <p>c</p>
    <p>d</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>Systems robust against DoS-attacks:  SOS, WebSOS, Mayday, III,  Basic strategy: indirection infrastructure to</p>
    <p>hide original location of data</p>
    <p>Does not work against past insiders</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>Awerbuch &amp; Sch. (DISC 07): DoS-resistent information system that can only handle get requests under DoS attack</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Applications: DoS-resistant platform for ecommerce or critical information services</p>
    <p>Open problems:  More light-weight solution  DoS-resistant system with bounded</p>
    <p>degree</p>
  </div>
  <div class="page">
    <p>Any Questions?</p>
  </div>
</Presentation>
