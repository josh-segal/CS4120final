<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>MatrixKV: Reducing Write Stalls and Write Amplification in LSM-tree</p>
    <p>Based KV Stores with a Matrix Container in NVM</p>
    <p>Ting Yao1, Yiwen Zhang1, Jiguang Wan1, Qiu Cui2, Liu Tang2, Hong Jiang3,</p>
    <p>Changsheng Xie1, and Xubin He4</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Background and Motivations</p>
    <p>MatrixKV</p>
    <p>Evaluation</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>LSM-tree based Key-value stores</p>
    <p>Log-structured merge tree (LSM-tree)  Write intensive scenarios</p>
    <p>Applications :</p>
    <p>Properties:</p>
    <p>Batched sequential writes: high write throughput</p>
    <p>Fast read</p>
    <p>Fast range queries</p>
  </div>
  <div class="page">
    <p>LSM-tree and RocksDB</p>
    <p>Systems with DRAM-SSD storage</p>
    <p>Exponentially increased level sizes (AF)</p>
    <p>Operations</p>
    <p>L0-L1 compaction</p>
    <p>L1-L2 compaction</p>
    <p>Compaction</p>
    <p>SSD based RocksDB</p>
    <p>L0</p>
    <p>L1</p>
    <p>Ln</p>
    <p>MemTable</p>
    <p>Immutable MemTable</p>
    <p>Flush</p>
    <p>Insert</p>
    <p>DRAM</p>
    <p>SSD</p>
  </div>
  <div class="page">
    <p>Challenge 1: Write stall</p>
    <p>Write stall: Application throughput</p>
    <p>periodically drop to nearly zero.</p>
    <p>Unpredictable performance.</p>
    <p>Long tail latency.</p>
    <p>Random write an 80 GB Dataset to an SSD based RocksDB. (20 million KV items, 16byte-4KB)</p>
    <p>L0-L1 compaction!</p>
  </div>
  <div class="page">
    <p>Root cause of write stall: L0-L1 compaction</p>
    <p>L2</p>
    <p>L1</p>
    <p>Ln</p>
    <p>L0</p>
    <p>Memory</p>
    <p>Disk</p>
    <p>Cm</p>
    <p>SSTable</p>
    <p>R e</p>
    <p>a d</p>
    <p>Merge &amp; Sort</p>
    <p>L0-L1 compaction: The all-to-all coarse-grained compaction</p>
    <p>SSD bandwidth.CPU cycle.</p>
  </div>
  <div class="page">
    <p>Challenge 2: write amplification</p>
    <p>Random write an 80 GB Dataset to an SSD based RocksDB. (20 million KV items, 16byte-4KB)</p>
    <p>Write amplification: Average</p>
    <p>throughput decreases gradually.</p>
    <p>Decreased performance.</p>
    <p>Increased LSM depth!</p>
    <p>More compaction and higher WA</p>
  </div>
  <div class="page">
    <p>Root cause of increased write amplification</p>
    <p>L2</p>
    <p>L1</p>
    <p>Ln</p>
    <p>L0</p>
    <p>Memory</p>
    <p>Disk</p>
    <p>Cm</p>
    <p>SSTable</p>
    <p>Level by level compactions: Write amplification increases with the depth of LSM-trees.</p>
    <p>WA=AF * N;</p>
    <p>AF is the amplification factor of adjacent two levels. (AF=10)</p>
    <p>N is the number of levels.</p>
  </div>
  <div class="page">
    <p>State-of-art solution with NVM NVM is byte-addressable, persistent, and fast!</p>
    <p>NoveLSM: Adopting NVM to store large mutable MemTable.</p>
    <p>1.7x higher random write performance but more severe write stalls!</p>
    <p>NoveLSM</p>
    <p>MemTable</p>
    <p>Immutable MemTable</p>
    <p>L0</p>
    <p>L1</p>
    <p>Ln</p>
    <p>MemTable</p>
    <p>Immutable MemTable</p>
    <p>DRAM NVM</p>
    <p>SSD</p>
    <p>*Sudarsun Kannan, Nitish Bhat, Ada Gavrilovska, Andrea Arpaci-Dusseau, and Remzi Arpaci-Dusseau. Redesigning lsms for nonvolatile memory with novelsm. In 2018 USENIX Annual Technical Conference (ATC18), 2018.</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Decreased performance</p>
    <p>Write stall Higher write amplification</p>
    <p>Unstable performance</p>
    <p>MatrixKV: Reducing Write Stalls and Write Amplification in LSM-tree Based KV Stores by exploiting NVM</p>
    <p>All-to-all L0-L1 compaction Increased depth</p>
  </div>
  <div class="page">
    <p>Outline Background and Motivations</p>
    <p>MatrixKV</p>
    <p>Evaluation</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Overall Architecture</p>
    <p>DRAM</p>
    <p>LSM-trees with reduced levels</p>
    <p>L1, L2,</p>
    <p>Matrix Container (L0 of LSM-trees)</p>
    <p>mem</p>
    <p>imm</p>
    <p>Posix</p>
    <p>PMDK</p>
    <p>SSD</p>
    <p>NVM</p>
    <p>Flush</p>
    <p>Column compaction</p>
    <p>Put</p>
    <p>C ro</p>
    <p>ss-ro w</p>
    <p>h in</p>
    <p>ts</p>
    <p>Compactor</p>
    <p>Receiver</p>
  </div>
  <div class="page">
    <p>Matrix Container Matrix container includes a receiver and a compactor.</p>
    <p>Receiver stores flushed data row by row and organized in RowTable.</p>
    <p>A: A receiver turns into a compactor once filled with RowTables</p>
    <p>Compactor compacts data from L0 to L1 on SSD column by column.</p>
    <p>B: NVM pages of a column are freed and available for receiver to accept new data after the column compaction.</p>
    <p>Receiver</p>
    <p>Compactor</p>
    <p>NVM</p>
    <p>SSD</p>
    <p>SSTables on L1</p>
    <p>A B</p>
    <p>a-c c-e e-n n-o u-z</p>
    <p>ca d e g h n o</p>
    <p>Flush from DRAM</p>
    <p>RowTable</p>
    <p>ca</p>
  </div>
  <div class="page">
    <p>RowTable</p>
    <p>...</p>
    <p>MetadataData blocks</p>
    <p>... Meta</p>
    <p>block n MetaIndex</p>
    <p>block Index block</p>
    <p>Meta block 0</p>
    <p>footer</p>
    <p>Data block 0 Data block n</p>
    <p>k0 v0 ... kn vn</p>
    <p>(b) SSTable structure</p>
    <p>k0 v0 ...k1 v1 kn vn</p>
    <p>Metadata: a sorted arrayData: sorted kv items</p>
    <p>P0</p>
    <p>k0</p>
    <p>P1</p>
    <p>K1</p>
    <p>P...</p>
    <p>K...</p>
    <p>Page0</p>
    <p>Offset</p>
    <p>Page0</p>
    <p>Offset</p>
    <p>Page...</p>
    <p>Offset Pn</p>
    <p>kn</p>
    <p>Pagen</p>
    <p>Offset</p>
    <p>(a) RowTable structure  Consisting of data and metadata.  Data region: serialized KV items from the immutable MemTable  Metadata region: a sorted array.</p>
    <p>Key  page number  offset in the page  forward pointer (i.e., $p_n$)</p>
  </div>
  <div class="page">
    <p>Fine grained column compaction</p>
    <p>The non-overlapped L1 is a key space with multiple contiguous key ranges.</p>
    <p>Example: 1. Range 0-3. 2. The amount of compaction data VS.</p>
    <p>the threshold of compaction. 3. Add the next subrange 3-5 -&gt; Range</p>
    <p>Start column compaction</p>
    <p>...</p>
    <p>L1 (SSD)</p>
    <p>Compactor ( NVM)</p>
  </div>
  <div class="page">
    <p>Fine grained column compaction</p>
    <p>The non-overlapped L1 is a key space with multiple contiguous key ranges.</p>
    <p>Example: 1. Range 0-3. 2. The amount of compaction data VS.</p>
    <p>the threshold of compaction. 3. Add the next subrange 3-5 -&gt; Range</p>
    <p>Start column compaction</p>
    <p>...</p>
    <p>L1 (SSD)</p>
    <p>Compactor ( NVM)</p>
  </div>
  <div class="page">
    <p>Fine grained column compaction</p>
    <p>The non-overlapped L1 is a key space with multiple contiguous key ranges.</p>
    <p>Example: 1. Range 0-3. 2. The amount of compaction data VS.</p>
    <p>the threshold of compaction. 3. Add the next subrange 3-5 -&gt; Range</p>
    <p>Start column compaction</p>
    <p>...</p>
    <p>L1 (SSD)</p>
    <p>Compactor ( NVM)</p>
    <p>Range [0-8] Range (8-30] Range ...</p>
  </div>
  <div class="page">
    <p>Reducing LSM-tree depth</p>
    <p>WA=AF * N</p>
    <p>Flattening LSM-trees with wider levels</p>
    <p>Make the AF unchanged</p>
    <p>Reduce N</p>
    <p>Increased unsorted L0</p>
    <p>Column compaction</p>
    <p>Decrease search efficiency in L0</p>
    <p>Cross-row hint search</p>
    <p>L0 256MB</p>
    <p>L1 256 MB</p>
    <p>L2 2.56 GB</p>
    <p>L3 25.6 GB</p>
    <p>L4 256 GB</p>
    <p>L5 2.56 TB</p>
    <p>L1 8 GB</p>
    <p>L2 80 GB</p>
    <p>L0 8 GB</p>
    <p>SSD NVM</p>
    <p>SSD</p>
    <p>Conventional LSM-tree Flattened LSM-tree in MatrixKV</p>
    <p>L3 800 GB</p>
    <p>L4 8 TB</p>
  </div>
  <div class="page">
    <p>RowTable3</p>
    <p>RowTable2</p>
    <p>RowTable1</p>
    <p>RowTable0</p>
    <p>Cross-Row hint search</p>
    <p>Constructing with forward pointer</p>
    <p>RowTable i key x</p>
    <p>RowTable i-1, key y</p>
    <p>y  x</p>
    <p>Search process with forward pointer</p>
    <p>E.g., fetch key=12</p>
  </div>
  <div class="page">
    <p>Evaluation Setup Comparisons RocksDB-SSD: SSD based RocksDB</p>
    <p>RocksDB-L0-NVM: placing L0 in NVM, system with DRAM, NVM, and SSD (8GB NVM)</p>
    <p>NoveLSM: a heterogeneous system of DRAM, NVM, and SSD (8GB NVM)</p>
    <p>MatrixKV: a heterogeneous system of DRAM, NVM, and SSD (8GB NVM)</p>
    <p>Test environment</p>
    <p>Linux 64-bit Linux 4.13.9</p>
    <p>CPU 2 * Genuine Intel(R) 2.20GHz processors</p>
    <p>Memory 32 GB</p>
    <p>NVM 128 GB * 2 Intel Optane DC PMM FIO 4 KB (MB/s) Random: 2346(R), 1363(W) Sequential: 2567(R),1444(W)</p>
    <p>SSD 800GB Intel SSDSC2BB800G7 FIO 4 KB (MB/s) Random: 250(R), 68(W) Sequential: 445(R),354(W)</p>
  </div>
  <div class="page">
    <p>Random Write Throughput</p>
    <p>MatrixKV obtains the best performance in different value sizes</p>
    <p>E.g. 4 KB value size MatrixKV outperforms RocksDBL0-NVM and NoveLSM by 3.6x and 2.6x.</p>
  </div>
  <div class="page">
    <p>Write stalls</p>
  </div>
  <div class="page">
    <p>Tail Latency</p>
    <p>Latency (us) avg. 90% 99% 99.9%</p>
    <p>RocksDB-SSD 974 566 11055 17983</p>
    <p>NoveLSM 450 317 2080 2169</p>
    <p>RocksDB-L0-NVM 477 528 786 1112</p>
    <p>MatrixKV 263 247 405 663</p>
    <p>MatrixKV obtains the shortest latency in all cases.</p>
    <p>E.g. 99% latency of MatrixKV is 27x, 5x, and 1.9x lower than RocksDB-SSD, NoveLSM, and RocksDB-L0-NVM respectively.</p>
  </div>
  <div class="page">
    <p>Fine granularity column compaction</p>
    <p>Why MatrixKV reduces write stalls  467 times column compaction  0.33 GB each</p>
  </div>
  <div class="page">
    <p>Write amplification</p>
    <p>The WA of randomly writing 80 GB dataset.</p>
    <p>WA = Amount of data written to SSDs / Amount of data written by users</p>
    <p>MatrixKV WA is 3.43x.</p>
    <p>MatrixKV reduces the number of compactions with flattened LSM-trees.</p>
  </div>
  <div class="page">
    <p>Summary Conventional SSD-based KV stores  unpredictable performance due to write stalls</p>
    <p>sacrificed performance due to WA</p>
    <p>MatrixKV: an LSM-tree based KV store on systems with DRAM, NVM, and SSD storages  Matrix container in NVM</p>
    <p>Column compaction</p>
    <p>Hint search</p>
    <p>Reducing levels on SSD</p>
    <p>Reduce write stalls and improves write performance.</p>
  </div>
  <div class="page">
    <p>Thanks!</p>
    <p>Open-source code: https://github.com/PDS-Lab/MatrixKV Email: tingyao@hust.edu.cn</p>
  </div>
</Presentation>
