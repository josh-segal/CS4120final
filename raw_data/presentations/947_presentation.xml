<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>VESPA: Portable, Scalable, and Flexible FPGA-Based Vector Processors</p>
    <p>Peter Yiannacouras Univ. of Toronto</p>
    <p>J. Gregory Steffan Univ. of Toronto</p>
    <p>Jonathan Rose Univ. of Toronto</p>
  </div>
  <div class="page">
    <p>Soft Processors in FPGA Systems</p>
    <p>HDL +</p>
    <p>CAD</p>
    <p>C +</p>
    <p>Compiler</p>
    <p>Easier  Faster  Smaller  Less Power</p>
    <p>Data-level parallelism  soft vector processors</p>
    <p>Configurable  how can we make use of this?</p>
  </div>
  <div class="page">
    <p>Vector Processing Primer</p>
    <p>// C code for(i=0;i&lt;16; i++) b[i]+=a[i]</p>
    <p>// Vectorized code set vl,16 vload vr0,b vload vr1,a vadd vr0,vr0,vr1 vstore vr0,b</p>
    <p>Each vector instruction holds many units of independent operations</p>
    <p>b[0]+=a[0] b[1]+=a[1] b[2]+=a[2]</p>
    <p>b[4]+=a[4] b[3]+=a[3]</p>
    <p>b[5]+=a[5] b[6]+=a[6] b[7]+=a[7] b[8]+=a[8] b[9]+=a[9]</p>
    <p>b[10]+=a[10] b[11]+=a[11] b[12]+=a[12] b[13]+=a[13] b[14]+=a[14] b[15]+=a[15]</p>
    <p>vadd</p>
  </div>
  <div class="page">
    <p>Vector Processing Primer</p>
    <p>// C code for(i=0;i&lt;16; i++) b[i]+=a[i]</p>
    <p>// Vectorized code set vl,16 vload vr0,b vload vr1,a vadd vr0,vr0,vr1 vstore vr0,b</p>
    <p>Each vector instruction holds many units of independent operations</p>
    <p>vadd</p>
    <p>b[0]+=a[0] b[1]+=a[1] b[2]+=a[2]</p>
    <p>b[4]+=a[4] b[3]+=a[3]</p>
    <p>b[5]+=a[5] b[6]+=a[6] b[7]+=a[7] b[8]+=a[8] b[9]+=a[9]</p>
    <p>b[10]+=a[10] b[11]+=a[11] b[12]+=a[12] b[13]+=a[13] b[14]+=a[14] b[15]+=a[15]</p>
  </div>
  <div class="page">
    <p>Soft Vector Processor Benefits</p>
    <p>Eg. Number of lanes  HW: Can be implemented on any FPGA architecture</p>
    <p>Eg. Number of lanes, width of lanes, etc.</p>
    <p>Parallelism can scale with Moores law</p>
    <p>How would this fit in with current FPGA design flow?</p>
  </div>
  <div class="page">
    <p>Conventional FPGA Design Flow</p>
    <p>Memory Interface</p>
    <p>Custom Accelerator</p>
    <p>Peripherals</p>
    <p>Soft Proc</p>
    <p>Custom AcceleratorCustom Accelerator</p>
    <p>Software Routine Software Routine Software Routine</p>
    <p>Is the soft processor the bottleneck?</p>
    <p>yes, find hot code</p>
    <p>Three options: 1) Manual hardware design 2) Acquire RTL IP-core 3) High level synthesis</p>
    <p>Eg. Altera C2H  Push button  Code dependent</p>
  </div>
  <div class="page">
    <p>Proposed Soft Vector Processor System Design Flow</p>
    <p>Memory Interface</p>
    <p>Custom Accelerator</p>
    <p>Peripherals</p>
    <p>Soft Proc</p>
    <p>Vector Lane 1 Vector Lane 2</p>
    <p>Is the soft processor the bottleneck?</p>
    <p>yes, increase lanes</p>
    <p>www.fpgavendor.com</p>
    <p>We propose adding vector extensions to existing soft processors</p>
    <p>Vector Lane 3 Vector Lane 4</p>
    <p>User Code +</p>
    <p>Portable, Flexible, Scalable</p>
    <p>Vectorized Software Routine</p>
    <p>Vectorized Software Routine</p>
    <p>Vectorized Software Routine</p>
    <p>Portable, Easy-to-use</p>
    <p>Vectorized Software Routine</p>
    <p>Vectorized Software Routine</p>
    <p>Vectorized Software Routine</p>
  </div>
  <div class="page">
    <p>Our Goals</p>
  </div>
  <div class="page">
    <p>Current Infrastructure</p>
    <p>Vectorized assembly</p>
    <p>subroutines</p>
    <p>GNU as +</p>
    <p>Vector support</p>
    <p>ELF Binary</p>
    <p>Instruction Set</p>
    <p>Simulation +</p>
    <p>SPREE +</p>
    <p>Vector support</p>
    <p>scalar P</p>
    <p>+ vpu</p>
    <p>VC RF</p>
    <p>VS RF</p>
    <p>VC W B</p>
    <p>VS W B</p>
    <p>Logic</p>
    <p>Decode Replicate</p>
    <p>Hazard check</p>
    <p>VR RF</p>
    <p>A L U</p>
    <p>Mem Unit</p>
    <p>x &amp; satur.</p>
    <p>VR W B</p>
    <p>M U X</p>
    <p>Saturate</p>
    <p>Rshift</p>
    <p>VR RF</p>
    <p>A L U</p>
    <p>x &amp; satur.</p>
    <p>VR W B</p>
    <p>M U X</p>
    <p>Saturate</p>
    <p>Rshift</p>
    <p>EEMBC C Benchmarks</p>
    <p>RTL Simulation</p>
    <p>SOFTWARE HARDWARE Verilog</p>
    <p>CAD Software</p>
    <p>cycles area, frequency</p>
    <p>GCC</p>
    <p>ld</p>
    <p>verification verification</p>
    <p>Manually designed coprocessor</p>
    <p>TM4</p>
    <p>Vector Extended Soft Processor Architecture</p>
  </div>
  <div class="page">
    <p>VESPA Architecture Design</p>
    <p>Scalar Pipeline 3-stage</p>
    <p>Vector Control Pipeline 3-stage</p>
    <p>Vector Pipeline 6-stage</p>
    <p>Icache Dcache</p>
    <p>Decode RF A L U</p>
    <p>M U X</p>
    <p>WB</p>
    <p>VC RF</p>
    <p>VS RF</p>
    <p>VC WB</p>
    <p>VS WB</p>
    <p>Logic</p>
    <p>Decode Replicate</p>
    <p>Hazard check</p>
    <p>VR RF A</p>
    <p>L U</p>
    <p>x &amp; satur.</p>
    <p>VR WB</p>
    <p>M U X</p>
    <p>Saturate</p>
    <p>Rshift</p>
    <p>VR RF A</p>
    <p>L U</p>
    <p>x &amp; satur.</p>
    <p>VR WB</p>
    <p>M U X</p>
    <p>Saturate</p>
    <p>Rshift</p>
    <p>Mem Unit</p>
    <p>Decode</p>
    <p>Supports integer and fixed-point operations, and predication</p>
    <p>Shared Dcache</p>
  </div>
  <div class="page">
    <p>Experiment #1: Vector Lane Exploration</p>
    <p>Vary the number of vector lanes implemented  Using parameterized vector core</p>
    <p>Measure speedup on 6 EEMBC benchmarks  Directly on Stratix I 1S80C6 clocked at 50 MHz</p>
    <p>Was designed for Stratix III, runs at 135 MHz</p>
    <p>Using 32KB direct-mapped level 1 cache  DDR 133MHz =&gt; 10 cycle miss penalty</p>
    <p>Measure area cost  Equate silicon area of all resources used</p>
    <p>Report in units of Equivalent LEs</p>
  </div>
  <div class="page">
    <p>Performance Scaling Across Vector Lanes</p>
    <p>Good scaling  average of 1.85x for 2 lanes to 6.3x for 16 lanes</p>
    <p>C yc</p>
    <p>le S</p>
    <p>p e</p>
    <p>e d u</p>
    <p>p</p>
    <p>N o rm</p>
    <p>a liz</p>
    <p>e d t</p>
    <p>o 1</p>
    <p>L a n</p>
    <p>e</p>
    <p>Scaling past 16 limited by number of multipliers in Stratix 1S80</p>
  </div>
  <div class="page">
    <p>Design Characteristics on Stratix III</p>
    <p>Lanes 1 2 4 8 16 32 64</p>
    <p>Clock Frequency (MHz)</p>
    <p>Logic Used (ALMs)</p>
    <p>Mulipliers Used (18-bit DSPs)</p>
    <p>Block RAMs Used (M9Ks)</p>
    <p>Clock Frequency steady  until 64 lanes</p>
    <p>ALMs grow by 570 ALMs/lane</p>
    <p>DSPs grow by 4(1+L)</p>
    <p>Block RAMs unaffected  until 32 lanes when port width dominates</p>
    <p>Device: 3S200C2</p>
  </div>
  <div class="page">
    <p>Application-Specific Vector Processing  Customize to the application if:</p>
    <p>Observations: Not all applications 1. Operate on 32-bit data types</p>
    <p>Eliminate unused hardware (reduce area)  Reduce cost (buy smaller FPGA)  Re-invest area savings into more lanes  Speed up clock (nets span shorter distances)</p>
  </div>
  <div class="page">
    <p>Opportunity for Customization</p>
    <p>Benchmark Largest Data Type Size</p>
    <p>Percentage of Vector ISA used</p>
    <p>autcor 4 bytes 9.6%</p>
    <p>conven 1 byte 5.9%</p>
    <p>fbital 2 bytes 14.1%</p>
    <p>viterb 2 bytes 13.3%</p>
    <p>rgbcmyk 1 byte 5.9%</p>
    <p>rgbyiq 2 bytes 8.1%</p>
    <p>Lots of opportunity to customize width &amp; ISA support</p>
    <p>0% reduction</p>
    <p>up to 75% reduction</p>
    <p>&lt;15% utilization</p>
  </div>
  <div class="page">
    <p>Customizing the Vector Processor</p>
    <p>Parameterized core can very easily change:  L - Number of Vector Lanes  W - Bit-width of the vector lanes  M  Size of memory crossbar  MVL  Maximum Vector Length</p>
    <p>Instruction set automatically subsetted  Each vector instruction individually enabled/disabled</p>
    <p>Control logic &amp; datapath hardware automatically removed</p>
  </div>
  <div class="page">
    <p>Experiment #2: Reducing Area by Reducing Vector Width</p>
    <p>Up to 54% of vector coprocessor area eliminated</p>
    <p>u tc</p>
    <p>o r</p>
    <p>(4 )</p>
    <p>co n</p>
    <p>ve n</p>
    <p>(1 )</p>
    <p>fb ita</p>
    <p>l ( 2</p>
    <p>)</p>
    <p>vi te</p>
    <p>rb (</p>
    <p>rg b</p>
    <p>cm y k</p>
    <p>(1 )</p>
    <p>rg b</p>
    <p>yi q</p>
    <p>( 2</p>
    <p>)</p>
    <p>V P</p>
    <p>U A</p>
    <p>re a</p>
    <p>( W</p>
    <p>id th</p>
    <p>-S p</p>
    <p>e c</p>
    <p>if ic</p>
    <p>)</p>
    <p>.</p>
    <p>Savings increase with more lanes =&gt; better scalability</p>
    <p>N o</p>
    <p>rm a</p>
    <p>liz e d</p>
    <p>V e ct</p>
    <p>o r</p>
    <p>C o</p>
    <p>p ro</p>
    <p>ce ss</p>
    <p>o r</p>
    <p>A re</p>
    <p>a</p>
    <p>largest data type size (in bytes)</p>
  </div>
  <div class="page">
    <p>Experiment #3: Reducing Area by Subsetting Instruction Set</p>
    <p>Up to 55% of VPU area eliminated, 46% on average</p>
    <p>a u</p>
    <p>tc o</p>
    <p>r</p>
    <p>co n</p>
    <p>ve n</p>
    <p>fb ita</p>
    <p>l</p>
    <p>vi te</p>
    <p>rb</p>
    <p>rg b</p>
    <p>cm y k</p>
    <p>rg b</p>
    <p>yi q</p>
    <p>G M</p>
    <p>E A</p>
    <p>N</p>
    <p>N o</p>
    <p>rm a</p>
    <p>liz e</p>
    <p>d A</p>
    <p>re a</p>
    <p>`</p>
    <p>N o</p>
    <p>rm a</p>
    <p>liz e d</p>
    <p>V e ct</p>
    <p>o r</p>
    <p>C o</p>
    <p>p ro</p>
    <p>ce ss</p>
    <p>o r</p>
    <p>A re</p>
    <p>a</p>
    <p>Again, savings increase with more lanes =&gt; better scalability</p>
  </div>
  <div class="page">
    <p>Experiment #4: Combined Width Reduction and Instruction Set Subsetting</p>
    <p>A re</p>
    <p>a (</p>
    <p>E q</p>
    <p>u iv</p>
    <p>a le</p>
    <p>n t</p>
    <p>L E</p>
    <p>s )</p>
    <p>`</p>
    <p>Full Vector Coprocessor</p>
    <p>Average Application-Specific Vector Coprocessor 61% 70%</p>
    <p>Performance scaling (seen previously) at almost 1/3 the area cost</p>
  </div>
  <div class="page">
    <p>Re-Invest Area Savings into Lanes (Improved VESPA)</p>
    <p>Area savings can be converted into better performance</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Evaluated soft vector processors  Real hardware, memory, and benchmarks</p>
    <p>Observed significant performance scaling  Average of 6.3x with 16 lanes  Further scaling possible on newer devices</p>
    <p>Explored measures to reduce area cost  Reducing vector width  Reducing supported instruction set  Combining width and instruction set reduction</p>
    <p>61% area reduction on average, up to 70%</p>
    <p>Soft vector processors provide a portable, flexible, and scalable framework for exploiting data level parallelism that is easier to use than</p>
    <p>designing custom FPGA hardware</p>
  </div>
  <div class="page">
    <p>Backup Slides</p>
  </div>
  <div class="page">
    <p>Future Work</p>
    <p>Improve scalability bottlenecks  Memory system</p>
    <p>Evaluate scaling past 16 lanes  Port to platform with newer FPGA</p>
    <p>Compare against hardware  What do we pay for simpler design?</p>
  </div>
  <div class="page">
    <p>Performance Impact of Cache Size</p>
    <p>Measure impact of cache size on 16 lane VPU</p>
    <p>autcor conven fbital viterb rgbcmy rgbyiq</p>
    <p>S p</p>
    <p>e e d</p>
    <p>u p</p>
    <p>.</p>
    <p>StreamingStreaming</p>
    <p>Streaming =&gt; prefetching could be fruitful</p>
  </div>
  <div class="page">
    <p>Combined Width Reduction and Instruction Set Subsetting</p>
    <p>Close to 70% area reduction</p>
    <p>u tc</p>
    <p>o r</p>
    <p>(4 )</p>
    <p>co n</p>
    <p>ve n</p>
    <p>(1 )</p>
    <p>fb it a</p>
    <p>l (2</p>
    <p>)</p>
    <p>vi te</p>
    <p>rb (</p>
    <p>rg b</p>
    <p>cm y k</p>
    <p>(1 )</p>
    <p>rg b</p>
    <p>y iq</p>
    <p>( 2</p>
    <p>)V P</p>
    <p>U A</p>
    <p>re a</p>
    <p>( W</p>
    <p>id th</p>
    <p>+ S</p>
    <p>u b</p>
    <p>s e</p>
    <p>tt in</p>
    <p>g )</p>
    <p>.</p>
  </div>
  <div class="page">
    <p>Performance vs Scalar (C) Code</p>
    <p>autcor 1.3 2.6 4.7 8.1 11.4</p>
    <p>conven 6.9 12.5 21.4 32.9 43.6</p>
    <p>fbital 1.2 2.2 3.7 5.5 6.9</p>
    <p>viterb 1.0 1.8 2.8 3.6 3.9</p>
    <p>rgbcmyk 1.0 1.8 2.4 3.2 3.8</p>
    <p>rgbyiq 2.4 4.2 6.7 9.6 12.0</p>
    <p>GEOMEAN 1.8 3.1 5.1 7.4 9.2</p>
  </div>
</Presentation>
