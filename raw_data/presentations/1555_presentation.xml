<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Evolving Ext4 for Shingled Disks</p>
    <p>Abutalib Aghayev Theodore Tso (Google), Garth Gibson,</p>
    <p>Peter Desnoyers (Northeastern University)</p>
    <p>PARALLEL DATA LABORATORY Carnegie Mellon University</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 2</p>
    <p>Shingled Magnetic Recording (SMR): high capacity at low cost</p>
    <p>Complements advanced techniques, not going away any time soon</p>
    <p>Two kinds of SMR disks: drive-managed and host-managed</p>
    <p>Millions of drive-managed SMR disks have shipped</p>
    <p>For this talk: SMR disk  drive-managed, CMR disk  conventional</p>
    <p>SMR disks use Shingle Translation Layer (STL) like FTL in SSDs</p>
    <p>STL exposes a block interface on top of device constraints</p>
    <p>Shingled Magnetic Recording (SMR) increases disk capacity with a small change to current technology</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 3</p>
    <p>Capacity increase comes with a cost: On SMR disks, continuous random writes lead to ultra-low throughput</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 4</p>
    <p>Eliminate major source of random writes: metadata writeback</p>
    <p>Ext4 + journaling code ~ 50,000 LOC</p>
    <p>Small change: ~40 LOC modified, ~600 LOC added in new files</p>
    <p>On metadata-light workload (&lt;1%): 1.7-5.4x improvement on SMR disks</p>
    <p>On metadata-heavy workload: 2-13x improvement on SMR and CMR disks</p>
    <p>Fix ext4 bottleneck resulting on 40x improvement on certain workloads</p>
    <p>Our contribution: A small change to ext4 that results in a big impact on SMR and CMR disks</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 5</p>
    <p>Introduction</p>
    <p>Background</p>
    <p>Mechanism</p>
    <p>Evaluation on CMR</p>
    <p>Evaluation on SMR</p>
    <p>Conclusion</p>
    <p>Agenda</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 6</p>
    <p>On SMR, naive handling of random writes results in expensive RMW operation for each write</p>
    <p>An SMR disk consists of sequence of bands</p>
    <p>A band must be written sequentially, like erase block in NAND flash</p>
    <p>Sectors are mapped to bands statically or dynamically</p>
    <p>Random write of a sector requires RMW of a band</p>
    <p>RMW becomes RWW with static mapping</p>
    <p>4 KiB random write  90 MiB w/ static mapping, 60 MiB w/ dynamic mapping</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 7</p>
    <p>STLs in SMR disks use persistent cache to absorb random writes, deferring their cost until the cache fills</p>
    <p>SMR disks have a large persistent cache invisible to host</p>
    <p>STL can detect sequential writes, bypass persistent cache</p>
    <p>Random writes go to persistent cache, dirtying bands</p>
    <p>Dirty bands cleaned in idle times (or in the background)</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 8</p>
    <p>With a full persistent cache, the range of random writes determines the disk throughput</p>
    <p>Band k</p>
    <p>Band k+1</p>
    <p>Band k+2</p>
    <p>Persistent Cache</p>
    <p>Persistent Cache</p>
    <p>Band k 30 MiB</p>
    <p>STL needs 3 RMW operations to free space for the next 3 random writes</p>
    <p>Assume RMW is 1 second  Throughput is 1 blocks/sec</p>
    <p>Assume RMW is 1 second  Throughput is 3 blocks/sec</p>
    <p>Range of random writes  Dirty bands  Cleaning load  Throughput</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 9</p>
    <p>Agenda</p>
    <p>Introduction</p>
    <p>Background</p>
    <p>Mechanism</p>
    <p>Evaluation on CMR</p>
    <p>Evaluation on SMR</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 10</p>
    <p>On ext4, metadata writes dirty bands in addition to those required by the user workload</p>
    <p>Partition made up of flex_bgs: 16MiB metadata, the rest is data</p>
    <p>A write to data region results in small writes to metadata region</p>
    <p>4,000 flex_bgs on 8TB partition; metadata maps to 4,000 bands</p>
    <p>Touching all flex_bgs  360 GiB of cleaning load for just for metadata</p>
    <p>Avoid metadata writes  Dirty bands   Cleaning load   Throughput</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 11</p>
    <p>On ext4, metadata is written twice: sequentially to the journal and randomly to file system</p>
    <p>Ext4 uses journaling for metadata consistency</p>
    <p>Journaling implemented in a generic kernel layer JBD2</p>
    <p>Small (128 MiB) journal, managed like a circular log</p>
    <p>JBD2 writes metadata to location J in the journal and marks it dirty</p>
    <p>After dirty timer expires, writeback thread writes block to static location S</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 12</p>
    <p>Ext4-lazy: Ext4 with Lazy Writeback Journaling</p>
    <p>JBD2 writes metadata to location J in the journal and marks it clean</p>
    <p>JBD2 inserts a tuple to an in-memory map that maps S to J</p>
    <p>Large (10 GiB) journal with LFS-style cleaning</p>
    <p>Metadata reads in ext4 go through the map</p>
    <p>On mount, reconstruct in-memory map from journal</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 13</p>
    <p>Agenda</p>
    <p>Introduction</p>
    <p>Background</p>
    <p>Mechanism</p>
    <p>Evaluation on CMR</p>
    <p>Evaluation on SMR</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 14</p>
    <p>On metadata-write heavy workloads, ext4-lazy is 2x faster on the CMR disk</p>
    <p>Benchmark: Create directories</p>
    <p>800,000 directories</p>
    <p>Tree depth 10</p>
    <p>8 threads</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 15</p>
    <p>Creating directories: The disk perspective</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 16</p>
    <p>Notoriously slow operation: Massive directory traversal</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 17</p>
    <p>On massive directory traversal workloads, ext4-lazy is 4x faster on the CMR disk</p>
    <p>Benchmark: Remove directories</p>
    <p>800,000 directories</p>
    <p>Tree depth 10</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 18</p>
    <p>Removing directories: The disk perspective</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 19</p>
    <p>Agenda</p>
    <p>Introduction</p>
    <p>Background</p>
    <p>Mechanism</p>
    <p>Evaluation on CMR</p>
    <p>Evaluation on SMR</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 20</p>
    <p>On pure metadata workloads, ext4-lazy results in ~zero cleaning load on the SMR disk</p>
    <p>Benchmark: Create directories</p>
    <p>800,000 directories</p>
    <p>Tree depth 10</p>
    <p>8 threads</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 21</p>
    <p>On metadata-light (&lt;1% of writes) workload, ext4-lazy achieves a large (1.7-5.4x) speedup on SMR disks</p>
    <p>Benchmark: Emulate a file server</p>
    <p>10,000 files in 25,000 dirs</p>
    <p>File size up to 1 MiB</p>
    <p>100,000 transactions</p>
    <p>I/O size 1 MiB</p>
    <p>38 GiB writes, 31 GiB reads</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 22</p>
    <p>Ext4-lazy reduces the number of dirtied bands achieving higher throughput with full persistent cache</p>
  </div>
  <div class="page">
    <p>Abutalib Aghayev  Mar 1, 2017http://www.pdl.cmu.edu/ 23</p>
    <p>Conclusion</p>
    <p>Ext4-lazy separates metadata from data and manages it as a log</p>
    <p>Consolidating metadata is not new:</p>
    <p>MFS[SOSP91], DualFS[ICS02], hFS[EuroSys07], TableFS[ATC13]</p>
    <p>Ext4-lazy is an evolution of a production file system</p>
    <p>Evaluates metadata separation idea for SMR disks</p>
    <p>Reducing the number of dirtied bands is a good rule of thumb for SMR</p>
    <p>Spreading metadata was invented 30 years ago. Time to revisit?</p>
    <p>Explicit assumption: Random Read cost is high</p>
    <p>Implicit assumption: Random Read cost == Random Write cost</p>
    <p>Assumptions do not hold anymore: read/write costs are asymmetric</p>
  </div>
</Presentation>
