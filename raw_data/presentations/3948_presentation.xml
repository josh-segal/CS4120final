<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Working Set Model for Multithreaded Programs (short paper)</p>
    <p>TRIOS'14</p>
    <p>Kishore Kumar Pusukuri Oracle Inc.</p>
  </div>
  <div class="page">
    <p>Motivation  Working Set Size (WSS):</p>
    <p>#pages referenced over a time interval * page size</p>
    <p>Effectively consolidating Java fusion applications on Oracle cloud servers</p>
    <p>Approximating WSS: simulations, program traces (exiting techniques, single threaded programs)</p>
    <p>Solaris on SPARC T4-4 (PARSEC, SPEC OMP 2012): Measuring overhead is high: 80 msec to 2.5 hours</p>
    <p>Dynamically optimizing resources?</p>
  </div>
  <div class="page">
    <p>Modeling Working Set Size  Several factors affect WSS</p>
    <p>Varies application to application (4 MB to 21 GB)</p>
    <p>Identifying factors that correlate to WSS</p>
    <p>Using statistical models based on machine learning</p>
  </div>
  <div class="page">
    <p>Outline  Identifying Factors Correlate with Working Set Size</p>
    <p>Developing Models for Working Set Size</p>
    <p>Working Set Aware Scheduling (Future Work)</p>
  </div>
  <div class="page">
    <p>Experimental Setup  20 multithreaded programs from PARSEC &amp; SPEC</p>
    <p>OMP 2012</p>
    <p>pthreads, stress CPU and Main Memory</p>
  </div>
  <div class="page">
    <p>Identifying Factors Resident Set Size (RSS)</p>
    <p>Imagick (SPEC OMP2012)</p>
    <p>Fluidanimate (PARSEC)</p>
    <p>Facesim (PARSEC)</p>
    <p>#Threads</p>
  </div>
  <div class="page">
    <p>Identifying Factors (cont...)</p>
    <p>Last-level Cache (LLC) Miss Rate</p>
    <p>TLB reach: (#TLB entries * page size)</p>
    <p>TLB reach is critical for the performance</p>
    <p>Multithreaded Programs (data parallelism): higher the #threads, smaller the TLB miss rate</p>
    <p>TLB Miss Rate &amp; Number of Threads</p>
    <p>Thread Migrations  Load Balancing</p>
    <p>Thread Migrations  Data Locality  LLC miss rate</p>
  </div>
  <div class="page">
    <p>The Factors  Resident Set Size (RSS)</p>
    <p>TLB Miss Rate</p>
    <p>Number of Threads</p>
    <p>LLC Miss Rate</p>
  </div>
  <div class="page">
    <p>Developing Models</p>
    <p>Run the 20 programs with 16, 32, 64, 128 threads</p>
    <p>Predictors: RSS, #threads, TLB misses per instruction, TLB misses per second, LLC misses per instruction, LLC misses per second</p>
    <p>WSS is the target parameter</p>
    <p>80 data points, 7-tuple data point,</p>
    <p>Data Collection (training data)</p>
  </div>
  <div class="page">
    <p>Developing Models (cont...)</p>
    <p>Prediction Accuracy vs Cost of Approximation</p>
    <p>Forward and Backward Input Selection Techniques (AIC - Akaike Information Criterion)</p>
    <p>Over-fitting problem</p>
    <p>Multicollinearity Problem</p>
    <p>More robust model</p>
    <p>Finding Important Factors</p>
    <p>RSS &amp; TLB Misses per Instruction</p>
  </div>
  <div class="page">
    <p>The Models  Linear Regression (LR)</p>
    <p>K Nearest Neighbour (KNN)</p>
    <p>Regression Tree (RT)</p>
  </div>
  <div class="page">
    <p>Model Selection  10-fold cross-validation (CV) test</p>
    <p>Normalized Root Mean Squared Error (NRMSE)</p>
    <p>F i  Forecast Value</p>
    <p>A i  Actual Value</p>
    <p>Prediction Accuracy = (100 - NRMSE)</p>
    <p>The KNN model as the WSS model</p>
  </div>
  <div class="page">
    <p>Further Evaluation  Prediction accuracies of the WSS model for</p>
    <p>memcached (Data Cache of Cloud Suite) and SPECjbb 2005 are 93% and 88%.</p>
    <p>Overhead of the WSS model</p>
    <p>24 microseconds</p>
    <p>The WSS model vs the existing techniques: (microseconds vs hours)</p>
  </div>
  <div class="page">
    <p>Overall Approach</p>
  </div>
  <div class="page">
    <p>Outline  Identifying Factors Correlate with Working Set Size</p>
    <p>Developing Models for Working Set Size</p>
    <p>Working Set Aware Scheduling (Future Work)</p>
  </div>
  <div class="page">
    <p>Working Set Aware Scheduling  Grouping vs Spreading: running the threads on a few</p>
    <p>multicore sockets compared to spreading threads uniformly across all the sockets.</p>
    <p>Grouping  Programs with small WSS e.g., 31% performance improvement for bodytrack (PARSEC)</p>
    <p>Spreading  Programs with large WSS e.g., 24% performance improvement for streamcluster</p>
    <p>Consider WSS and other factors such as lock contention</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Identifies important factors that correlate with WSS of multithreaded applications</p>
    <p>Demonstrates the usage of machine learning for developing simple models for approximating WSS</p>
    <p>Overhead is negligible and can be used for dynamically optimizing resources</p>
  </div>
  <div class="page">
    <p>Acknowledgments</p>
    <p>Dave Dice, Darryl Gove, Blake Jones, Tim Farkas, Darrin Johnson</p>
    <p>Prof. Lorenzo Alvisi</p>
  </div>
</Presentation>
