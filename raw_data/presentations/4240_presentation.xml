<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Zeyang Lei , Yujiu Yang, Min Yang, Yi Liu</p>
    <p>A Multi-sentiment-resource Enhanced Attention</p>
    <p>Network for Sentiment Classification</p>
    <p>Graduate School at Shenzhen, Tsinghua University</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction</p>
    <p>The proposed method</p>
    <p>Experiments</p>
    <p>Summary and future work</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction</p>
    <p>The proposed method</p>
    <p>Experiments</p>
    <p>Summary and future work</p>
  </div>
  <div class="page">
    <p>Task Description</p>
    <p>Sentence-level Sentiment Classification</p>
    <p>Positive/ negative/neutral  More fine-grained classes</p>
    <p>Given a sentence</p>
    <p>Examples</p>
    <p>The food is very delicious.</p>
    <p>The movie is so boring.</p>
    <p>....</p>
    <p>Positive</p>
    <p>Negative</p>
    <p>Sentiment Polarity</p>
  </div>
  <div class="page">
    <p>Early Methods</p>
    <p>Neural Networks</p>
    <p>Incorporating Linguistic Knowledge with Neural Networks</p>
    <p>Machine learning based---SVM (Pang et al., 2002)</p>
    <p>Linguistic knowledge based-----Sentiment lexicon [Turney, 2002; Taboada et</p>
    <p>al., 2011]</p>
    <p>Recursive Neural Network [Socher et al. 2011]  Convolutional Neural Network [Kim, 2014]  Recurrent Neural Network/LSTM [Hochreiter and Schmidhuber,</p>
    <p>Linguistically regularized LSTM [Qian et al., 2017]  Lexicon integrated CNN models with attention [Bonggun et al., 2017]</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Sentiment linguistic knowledge (e.g. sentiment words, intensity words, negation words) play important roles in sentiment detection.</p>
    <p>By attention mechanism, we can integrate various sentiment resource information into neural networks to boost the performance.</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>The proposed method</p>
    <p>Experiments and analysis</p>
    <p>Summary and future work</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Our Model</p>
    <p>The overall framework of our model</p>
  </div>
  <div class="page">
    <p>Coupled word Embedding</p>
  </div>
  <div class="page">
    <p>Multi-sentiment-resource attention module</p>
  </div>
  <div class="page">
    <p>Context-sentiment correlation modeling</p>
    <p>Note that in proceeding version, there are some typos in this part. The updated version can be obtained via arxiv.org: https://arxiv.org/abs/1807.04990</p>
    <p>The implementation of context-intensity correlation modeling and contextnegation correlation modeling are the same as the context-sentiment correlation modeling.</p>
  </div>
  <div class="page">
    <p>Multi-sentiment-resource attention</p>
    <p>Sentiment word attention</p>
    <p>Intensity attention and Negation attention are computed via the similar methods with the sentiment word attention</p>
    <p>Finally, the multi-sentiment-resource enhanced sentence representation:</p>
  </div>
  <div class="page">
    <p>Training</p>
    <p>The predicted sentiment polarity distribution can be obtained via a fully connected layer with softmax.</p>
    <p>Loss function:</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>The proposed method</p>
    <p>Experiments</p>
    <p>Summary and future work</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Experiments</p>
    <p>Datasets  Movie Review (MR)---5331 positive/ 5331 negative,</p>
    <p>training/validation/test split is the same as (Qian et al., 2017) ;  Stanford Sentiment Treebank (SST)---8545 training/1101</p>
    <p>validation/ 2210 test</p>
    <p>Sentiment Resources  Sentiment words-----combined from (Hu and Liu, 2004) and</p>
    <p>(Qian et al., 2017), containing 10899 words;  Intensity words and Negation words manually collected</p>
    <p>due to the limited number.</p>
  </div>
  <div class="page">
    <p>Experiments----Results</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>The proposed method</p>
    <p>Experiments and analysis</p>
    <p>Summary and future work</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Summary and Future work</p>
    <p>Integrating sentiment resources into neural networks is effective to improve the performance of sentence-level sentiment classification.</p>
    <p>How to deign the more effective information-fusion methods is still challenging, such as regularization, attention, .</p>
    <p>In future work, we can consider employing position embedding to automatically detecting various sentiment resource words.</p>
  </div>
  <div class="page">
    <p>Thanks for your attention! Supplementary Materials:</p>
    <p>https://drive.google.com/open?id=1KNBy50lBD7CMjack_9--M4N7EzeRmJDl</p>
    <p>Q&amp;A</p>
  </div>
</Presentation>
