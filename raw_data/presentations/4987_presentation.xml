<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Cognitive Models of Test-Item Effects in Human Category Learning</p>
    <p>Xiaojin Zhu, Bryan R. Gibson, Kwang-Sung Jun, Timothy T. Rogers, Joseph Harrison, Chuck Kalish</p>
    <p>Departments of Computer Sciences, Psychology, &amp; Educational Psychology</p>
    <p>University of Wisconsin-Madison</p>
    <p>ICML 2010</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 1 / 17</p>
  </div>
  <div class="page">
    <p>A Typical Human Category Learning Experiment</p>
    <p>training:</p>
    <p>key key . . .</p>
    <p>stimulus x</p>
    <p>f (x) feedback y</p>
    <p>test: key key . . .</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 2 / 17</p>
  </div>
  <div class="page">
    <p>A Typical Human Category Learning Experiment</p>
    <p>training: key</p>
    <p>key . . .</p>
    <p>stimulus x f (x)</p>
    <p>feedback y</p>
    <p>test: key key . . .</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 2 / 17</p>
  </div>
  <div class="page">
    <p>A Typical Human Category Learning Experiment</p>
    <p>training: key</p>
    <p>key . . .</p>
    <p>stimulus x f (x) feedback y</p>
    <p>test: key key . . .</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 2 / 17</p>
  </div>
  <div class="page">
    <p>A Typical Human Category Learning Experiment</p>
    <p>training: key</p>
    <p>key . . .</p>
    <p>stimulus x f (x) feedback y</p>
    <p>test: key key . . .</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 2 / 17</p>
  </div>
  <div class="page">
    <p>A Typical Human Category Learning Experiment</p>
    <p>training: key key</p>
    <p>. . .</p>
    <p>stimulus x f (x) feedback y</p>
    <p>test: key key . . .</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 2 / 17</p>
  </div>
  <div class="page">
    <p>A Typical Human Category Learning Experiment</p>
    <p>training: key key</p>
    <p>. . .</p>
    <p>stimulus x f (x) feedback y</p>
    <p>test: key key . . .</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 2 / 17</p>
  </div>
  <div class="page">
    <p>A Typical Human Category Learning Experiment</p>
    <p>training: key key . . . stimulus x f (x) feedback y</p>
    <p>test: key key . . .</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 2 / 17</p>
  </div>
  <div class="page">
    <p>A Typical Human Category Learning Experiment</p>
    <p>training: key key . . . stimulus x f (x) feedback y</p>
    <p>test: key key . . .</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 2 / 17</p>
  </div>
  <div class="page">
    <p>A Typical Human Category Learning Experiment</p>
    <p>training: key key . . . stimulus x f (x) feedback y</p>
    <p>test: key key . . .</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 2 / 17</p>
  </div>
  <div class="page">
    <p>One Goal of Cognitive Psychology</p>
    <p>. . . is to identify the algorithm in our mind</p>
    <p>CogSci Machine Learning</p>
    <p>stimulus feature vector x category feedback class y</p>
    <p>stimulus with feedback labeled data (x, y) stimulus without feedback unlabeled data x</p>
    <p>response classification f (x)</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 3 / 17</p>
  </div>
  <div class="page">
    <p>Human Semi-Supervised Learning?</p>
    <p>training: key key . . . stimulus x feedback</p>
    <p>A computer can hold a trained classifier f fixed during testing.</p>
    <p>A human may not</p>
    <p>test: key key . . .</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 4 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect</p>
    <p>This work answers two questions: 1 Will unlabeled test items change the classifier in humans mind?</p>
    <p>(yes) I Two identical people A, B receiving exactly the same training data I The test data (without label feedback) is different I Because of this difference, they disagree on certain test items</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 5 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect</p>
    <p>This work answers two questions: 1 Will unlabeled test items change the classifier in humans mind? (yes)</p>
    <p>I Two identical people A, B receiving exactly the same training data I The test data (without label feedback) is different I Because of this difference, they disagree on certain test items</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 5 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect</p>
    <p>This work answers two questions: 1 Will unlabeled test items change the classifier in humans mind? (yes)</p>
    <p>I Two identical people A, B receiving exactly the same training data</p>
    <p>I The test data (without label feedback) is different I Because of this difference, they disagree on certain test items</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 5 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect</p>
    <p>This work answers two questions: 1 Will unlabeled test items change the classifier in humans mind? (yes)</p>
    <p>I Two identical people A, B receiving exactly the same training data I The test data (without label feedback) is different</p>
    <p>I Because of this difference, they disagree on certain test items</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 5 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect</p>
    <p>This work answers two questions: 1 Will unlabeled test items change the classifier in humans mind? (yes)</p>
    <p>I Two identical people A, B receiving exactly the same training data I The test data (without label feedback) is different I Because of this difference, they disagree on certain test items</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 5 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect</p>
    <p>This work answers two questions: 1 Will unlabeled test items change the classifier in humans mind? (yes)</p>
    <p>I Two identical people A, B receiving exactly the same training data I The test data (without label feedback) is different I Because of this difference, they disagree on certain test items</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 5 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect</p>
    <p>This work answers two questions: 1 Will unlabeled test items change the classifier in humans mind? (yes)</p>
    <p>I Two identical people A, B receiving exactly the same training data I The test data (without label feedback) is different I Because of this difference, they disagree on certain test items</p>
    <p>(3 semi-supervised models)</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 5 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect</p>
    <p>This work answers two questions: 1 Will unlabeled test items change the classifier in humans mind? (yes)</p>
    <p>I Two identical people A, B receiving exactly the same training data I The test data (without label feedback) is different I Because of this difference, they disagree on certain test items</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 5 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect 1: Order of Test Items</p>
    <p>I L to R: test item -2,-1.95,-1.9, . . . , 2 I R to L: reverse order.</p>
    <p>2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1 |x</p>
    <p>)</p>
    <p>L to R R to L</p>
    <p>Subjects in L to R classify more test items as y = 0, and vice versa. For test items in [-1.2, 0.1], a majority-vote among subjects will classify them in opposite ways in these two conditions.</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 6 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect 1: Order of Test Items</p>
    <p>Two conditions, 20 subjects each: I L to R: test item -2,-1.95,-1.9, . . . , 2 I R to L: reverse order.</p>
    <p>2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1 |x</p>
    <p>)</p>
    <p>L to R R to L</p>
    <p>Subjects in L to R classify more test items as y = 0, and vice versa. For test items in [-1.2, 0.1], a majority-vote among subjects will classify them in opposite ways in these two conditions.</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 6 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect 1: Order of Test Items</p>
    <p>I L to R: test item -2,-1.95,-1.9, . . . , 2 I R to L: reverse order.</p>
    <p>2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1 |x</p>
    <p>)</p>
    <p>L to R R to L</p>
    <p>Subjects in L to R classify more test items as y = 0, and vice versa. For test items in [-1.2, 0.1], a majority-vote among subjects will classify them in opposite ways in these two conditions.</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 6 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect 1: Order of Test Items</p>
    <p>I L to R: test item -2,-1.95,-1.9, . . . , 2 I R to L: reverse order.</p>
    <p>2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1 |x</p>
    <p>)</p>
    <p>L to R R to L</p>
    <p>Subjects in L to R classify more test items as y = 0, and vice versa.</p>
    <p>For test items in [-1.2, 0.1], a majority-vote among subjects will classify them in opposite ways in these two conditions.</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 6 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect 1: Order of Test Items</p>
    <p>I L to R: test item -2,-1.95,-1.9, . . . , 2 I R to L: reverse order.</p>
    <p>2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1 |x</p>
    <p>)</p>
    <p>L to R R to L</p>
    <p>Subjects in L to R classify more test items as y = 0, and vice versa. For test items in [-1.2, 0.1], a majority-vote among subjects will classify them in opposite ways in these two conditions.</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 6 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect 2: Distribution of Test Items [AAAI 07]</p>
    <p>Same feature space</p>
    <p>I L shifted: GMM 1 = 1.43, 2 = 0.57 I R shifted: GMM 1 = 0.57, 2 = 1.43</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1 |x</p>
    <p>)</p>
    <p>early Lshifted early Rshifted late Lshifted late Rshifted</p>
    <p>Early (in first 50 test items) decision boundaries the same</p>
    <p>Late (after 700 test items) boundaries shifted according to condition</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 7 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect 2: Distribution of Test Items [AAAI 07]</p>
    <p>Same feature space</p>
    <p>I L shifted: GMM 1 = 1.43, 2 = 0.57 I R shifted: GMM 1 = 0.57, 2 = 1.43</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x P</p>
    <p>(y =</p>
    <p>)</p>
    <p>early Lshifted early Rshifted late Lshifted late Rshifted</p>
    <p>Early (in first 50 test items) decision boundaries the same</p>
    <p>Late (after 700 test items) boundaries shifted according to condition</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 7 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect as Semi-Supervised Learning</p>
    <p>Standard human category learning models in psychology cannot explain test-item effects</p>
    <p>We propose semi-supervised extensions to these models</p>
    <p>incremental (online) learning to better fit human experience</p>
    <p>minimum number of parameters to prevent overfitting</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 8 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect as Semi-Supervised Learning</p>
    <p>Standard human category learning models in psychology cannot explain test-item effects</p>
    <p>We propose semi-supervised extensions to these models</p>
    <p>incremental (online) learning to better fit human experience</p>
    <p>minimum number of parameters to prevent overfitting</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 8 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect as Semi-Supervised Learning</p>
    <p>Standard human category learning models in psychology cannot explain test-item effects</p>
    <p>incremental (online) learning to better fit human experience</p>
    <p>minimum number of parameters to prevent overfitting</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 8 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect as Semi-Supervised Learning</p>
    <p>Standard human category learning models in psychology cannot explain test-item effects</p>
    <p>We propose semi-supervised extensions to these models</p>
    <p>incremental (online) learning to better fit human experience</p>
    <p>minimum number of parameters to prevent overfitting</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 8 / 17</p>
  </div>
  <div class="page">
    <p>Test-Item Effect as Semi-Supervised Learning</p>
    <p>Standard human category learning models in psychology cannot explain test-item effects</p>
    <p>We propose semi-supervised extensions to these models</p>
    <p>incremental (online) learning to better fit human experience</p>
    <p>minimum number of parameters to prevent overfitting</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 8 / 17</p>
  </div>
  <div class="page">
    <p>Model 1: Semi-Supervised Exemplar Model</p>
    <p>Extends the generalized context model (Nosofsky, 1986)</p>
    <p>Self-training Nadaraya-Watson kernel estimator</p>
    <p>Parameter: kernel bandwidth h for n = 1, 2, . . . do</p>
    <p>Receive xn, predict its label by thresholding</p>
    <p>r(xn) = n1</p>
    <p>i=1 K(</p>
    <p>xnxi h</p>
    <p>)Pn1 j=1 K(</p>
    <p>xnxj h</p>
    <p>) yi at 0.5</p>
    <p>Receive yn (may be unlabeled), update model: if yn is unlabeled then</p>
    <p>yn = r(xn) else</p>
    <p>yn = yn end if</p>
    <p>end for</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 9 / 17</p>
  </div>
  <div class="page">
    <p>Model 1: Semi-Supervised Exemplar Model</p>
    <p>Extends the generalized context model (Nosofsky, 1986)</p>
    <p>Self-training Nadaraya-Watson kernel estimator</p>
    <p>Parameter: kernel bandwidth h for n = 1, 2, . . . do</p>
    <p>Receive xn,</p>
    <p>predict its label by thresholding</p>
    <p>r(xn) = n1</p>
    <p>i=1 K(</p>
    <p>xnxi h</p>
    <p>)Pn1 j=1 K(</p>
    <p>xnxj h</p>
    <p>) yi at 0.5</p>
    <p>Receive yn (may be unlabeled), update model: if yn is unlabeled then</p>
    <p>yn = r(xn) else</p>
    <p>yn = yn end if</p>
    <p>end for</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 9 / 17</p>
  </div>
  <div class="page">
    <p>Model 1: Semi-Supervised Exemplar Model</p>
    <p>Extends the generalized context model (Nosofsky, 1986)</p>
    <p>Self-training Nadaraya-Watson kernel estimator</p>
    <p>Parameter: kernel bandwidth h for n = 1, 2, . . . do</p>
    <p>Receive xn, predict its label by thresholding</p>
    <p>r(xn) = n1</p>
    <p>i=1 K(</p>
    <p>xnxi h</p>
    <p>)Pn1 j=1 K(</p>
    <p>xnxj h</p>
    <p>) yi at 0.5</p>
    <p>Receive yn (may be unlabeled), update model: if yn is unlabeled then</p>
    <p>yn = r(xn) else</p>
    <p>yn = yn end if</p>
    <p>end for</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 9 / 17</p>
  </div>
  <div class="page">
    <p>Model 1: Semi-Supervised Exemplar Model</p>
    <p>Extends the generalized context model (Nosofsky, 1986)</p>
    <p>Self-training Nadaraya-Watson kernel estimator</p>
    <p>Parameter: kernel bandwidth h for n = 1, 2, . . . do</p>
    <p>Receive xn, predict its label by thresholding</p>
    <p>r(xn) = n1</p>
    <p>i=1 K(</p>
    <p>xnxi h</p>
    <p>)Pn1 j=1 K(</p>
    <p>xnxj h</p>
    <p>) yi at 0.5</p>
    <p>Receive yn (may be unlabeled), update model: if yn is unlabeled then</p>
    <p>yn = r(xn) else</p>
    <p>yn = yn end if</p>
    <p>end for</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 9 / 17</p>
  </div>
  <div class="page">
    <p>Model 2: Semi-Supervised Prototype Model</p>
    <p>Extends prototype models (Posner &amp; Keele, 1968)</p>
    <p>Incremental EM on GMM (Neal &amp; Hinton, 1998), but without revisiting old items</p>
    <p>Track parameters of GMM via sufficient statistics I If input (x, y) labeled, its contribution to sufficient statistics is</p>
    <p>(x, y) = (1  y, (1  y)x, (1  y)x2, y, yx, yx2) I If input x unlabeled, it is</p>
    <p>Eyq[(x, y)] =</p>
    <p>y=0,1</p>
    <p>q(y)(x, y)</p>
    <p>where q(y) = p(y|x, ) is the label posterior under the current model I Initialize sufficient statistics as  = (n0, 0, n0, n0, 0, n0): n0 pseudo</p>
    <p>items with mean 0 and variance 1. I n0 is the only parameter.</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 10 / 17</p>
  </div>
  <div class="page">
    <p>Model 2: Semi-Supervised Prototype Model</p>
    <p>Extends prototype models (Posner &amp; Keele, 1968)</p>
    <p>Incremental EM on GMM (Neal &amp; Hinton, 1998), but without revisiting old items</p>
    <p>Track parameters of GMM via sufficient statistics I If input (x, y) labeled, its contribution to sufficient statistics is</p>
    <p>(x, y) = (1  y, (1  y)x, (1  y)x2, y, yx, yx2)</p>
    <p>I If input x unlabeled, it is</p>
    <p>Eyq[(x, y)] =</p>
    <p>y=0,1</p>
    <p>q(y)(x, y)</p>
    <p>where q(y) = p(y|x, ) is the label posterior under the current model I Initialize sufficient statistics as  = (n0, 0, n0, n0, 0, n0): n0 pseudo</p>
    <p>items with mean 0 and variance 1. I n0 is the only parameter.</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 10 / 17</p>
  </div>
  <div class="page">
    <p>Model 2: Semi-Supervised Prototype Model</p>
    <p>Extends prototype models (Posner &amp; Keele, 1968)</p>
    <p>Incremental EM on GMM (Neal &amp; Hinton, 1998), but without revisiting old items</p>
    <p>Track parameters of GMM via sufficient statistics I If input (x, y) labeled, its contribution to sufficient statistics is</p>
    <p>(x, y) = (1  y, (1  y)x, (1  y)x2, y, yx, yx2) I If input x unlabeled, it is</p>
    <p>Eyq[(x, y)] =</p>
    <p>y=0,1</p>
    <p>q(y)(x, y)</p>
    <p>where q(y) = p(y|x, ) is the label posterior under the current model</p>
    <p>I Initialize sufficient statistics as  = (n0, 0, n0, n0, 0, n0): n0 pseudo items with mean 0 and variance 1.</p>
    <p>I n0 is the only parameter.</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 10 / 17</p>
  </div>
  <div class="page">
    <p>Model 2: Semi-Supervised Prototype Model</p>
    <p>Extends prototype models (Posner &amp; Keele, 1968)</p>
    <p>Incremental EM on GMM (Neal &amp; Hinton, 1998), but without revisiting old items</p>
    <p>Track parameters of GMM via sufficient statistics I If input (x, y) labeled, its contribution to sufficient statistics is</p>
    <p>(x, y) = (1  y, (1  y)x, (1  y)x2, y, yx, yx2) I If input x unlabeled, it is</p>
    <p>Eyq[(x, y)] =</p>
    <p>y=0,1</p>
    <p>q(y)(x, y)</p>
    <p>where q(y) = p(y|x, ) is the label posterior under the current model I Initialize sufficient statistics as  = (n0, 0, n0, n0, 0, n0): n0 pseudo</p>
    <p>items with mean 0 and variance 1. I n0 is the only parameter.</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 10 / 17</p>
  </div>
  <div class="page">
    <p>Model 3: Semi-Supervised Rational Model of Categorization (RMC)</p>
    <p>Extends RMC (Anderson 1990, Griffiths et al. 2008)</p>
    <p>Dirichlet Process Mixture Model (DPMM) marginalizd over y</p>
    <p>I stack [x; y] and use a single global DPMM (key difference to Aclass (Mansinghka et al. 2007))</p>
    <p>I G  DP (G0, 2) F base measure G0 = Normal-Gamma  Beta (conjugate priors for</p>
    <p>Normal and binomial) F 2 is the only parameter</p>
    <p>I 1 . . . n  G, where  = (, , p) F ,  the mean and precision of a Gaussian for the x component F p the head probability for the y component</p>
    <p>I (xi, yi)  F (x, y|i), F = Gaussian  Bernoulli</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 11 / 17</p>
  </div>
  <div class="page">
    <p>Model 3: Semi-Supervised Rational Model of Categorization (RMC)</p>
    <p>Extends RMC (Anderson 1990, Griffiths et al. 2008)</p>
    <p>Dirichlet Process Mixture Model (DPMM) marginalizd over y I stack [x; y] and use a single global DPMM (key difference to Aclass</p>
    <p>(Mansinghka et al. 2007))</p>
    <p>I G  DP (G0, 2) F base measure G0 = Normal-Gamma  Beta (conjugate priors for</p>
    <p>Normal and binomial) F 2 is the only parameter</p>
    <p>I 1 . . . n  G, where  = (, , p) F ,  the mean and precision of a Gaussian for the x component F p the head probability for the y component</p>
    <p>I (xi, yi)  F (x, y|i), F = Gaussian  Bernoulli</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 11 / 17</p>
  </div>
  <div class="page">
    <p>Model 3: Semi-Supervised Rational Model of Categorization (RMC)</p>
    <p>Extends RMC (Anderson 1990, Griffiths et al. 2008)</p>
    <p>Dirichlet Process Mixture Model (DPMM) marginalizd over y I stack [x; y] and use a single global DPMM (key difference to Aclass</p>
    <p>(Mansinghka et al. 2007)) I G  DP (G0, 2)</p>
    <p>F base measure G0 = Normal-Gamma  Beta (conjugate priors for Normal and binomial)</p>
    <p>F 2 is the only parameter</p>
    <p>I 1 . . . n  G, where  = (, , p) F ,  the mean and precision of a Gaussian for the x component F p the head probability for the y component</p>
    <p>I (xi, yi)  F (x, y|i), F = Gaussian  Bernoulli</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 11 / 17</p>
  </div>
  <div class="page">
    <p>Model 3: Semi-Supervised Rational Model of Categorization (RMC)</p>
    <p>Extends RMC (Anderson 1990, Griffiths et al. 2008)</p>
    <p>Dirichlet Process Mixture Model (DPMM) marginalizd over y I stack [x; y] and use a single global DPMM (key difference to Aclass</p>
    <p>(Mansinghka et al. 2007)) I G  DP (G0, 2)</p>
    <p>F base measure G0 = Normal-Gamma  Beta (conjugate priors for Normal and binomial)</p>
    <p>F 2 is the only parameter</p>
    <p>I 1 . . . n  G, where  = (, , p) F ,  the mean and precision of a Gaussian for the x component F p the head probability for the y component</p>
    <p>I (xi, yi)  F (x, y|i), F = Gaussian  Bernoulli</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 11 / 17</p>
  </div>
  <div class="page">
    <p>Model 3: Semi-Supervised Rational Model of Categorization (RMC)</p>
    <p>Extends RMC (Anderson 1990, Griffiths et al. 2008)</p>
    <p>Dirichlet Process Mixture Model (DPMM) marginalizd over y I stack [x; y] and use a single global DPMM (key difference to Aclass</p>
    <p>(Mansinghka et al. 2007)) I G  DP (G0, 2)</p>
    <p>F base measure G0 = Normal-Gamma  Beta (conjugate priors for Normal and binomial)</p>
    <p>F 2 is the only parameter</p>
    <p>I 1 . . . n  G, where  = (, , p) F ,  the mean and precision of a Gaussian for the x component F p the head probability for the y component</p>
    <p>I (xi, yi)  F (x, y|i), F = Gaussian  Bernoulli</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 11 / 17</p>
  </div>
  <div class="page">
    <p>Particle Filtering for Semi-Supervised RMC</p>
    <p>Introduce cluster index z Integrate out  and G via particle filtering Each particle is a vector of indices z1:n1 Grow particle by zn, weight proportional to likelihood</p>
    <p>P (yn1 | z1:n1, y1:n2)P (zn | z1:n1)P (xn | zn, z1:n1, x1:n1)</p>
    <p>For semi-supervised DPMM, the y term is a beta-binomial with marginalization</p>
    <p>P (yn1 | z1:n1, y1:n2) = c1 + 1</p>
    <p>c0 + c1 + 1 + 1</p>
    <p>I If yn1 unlabeled, define the probability to be 1 I If some of y1:n2 unlabeled, skip them in counting</p>
    <p>c1 = n2 i=1</p>
    <p>(zi, zn1)(yi, 1) c0 = n2 i=1</p>
    <p>(zi, zn1)(yi, 0)</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 12 / 17</p>
  </div>
  <div class="page">
    <p>Particle Filtering for Semi-Supervised RMC Introduce cluster index z</p>
    <p>Integrate out  and G via particle filtering Each particle is a vector of indices z1:n1 Grow particle by zn, weight proportional to likelihood</p>
    <p>P (yn1 | z1:n1, y1:n2)P (zn | z1:n1)P (xn | zn, z1:n1, x1:n1)</p>
    <p>For semi-supervised DPMM, the y term is a beta-binomial with marginalization</p>
    <p>P (yn1 | z1:n1, y1:n2) = c1 + 1</p>
    <p>c0 + c1 + 1 + 1</p>
    <p>I If yn1 unlabeled, define the probability to be 1 I If some of y1:n2 unlabeled, skip them in counting</p>
    <p>c1 = n2 i=1</p>
    <p>(zi, zn1)(yi, 1) c0 = n2 i=1</p>
    <p>(zi, zn1)(yi, 0)</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 12 / 17</p>
  </div>
  <div class="page">
    <p>Particle Filtering for Semi-Supervised RMC Introduce cluster index z Integrate out  and G via particle filtering</p>
    <p>Each particle is a vector of indices z1:n1 Grow particle by zn, weight proportional to likelihood</p>
    <p>P (yn1 | z1:n1, y1:n2)P (zn | z1:n1)P (xn | zn, z1:n1, x1:n1)</p>
    <p>For semi-supervised DPMM, the y term is a beta-binomial with marginalization</p>
    <p>P (yn1 | z1:n1, y1:n2) = c1 + 1</p>
    <p>c0 + c1 + 1 + 1</p>
    <p>I If yn1 unlabeled, define the probability to be 1 I If some of y1:n2 unlabeled, skip them in counting</p>
    <p>c1 = n2 i=1</p>
    <p>(zi, zn1)(yi, 1) c0 = n2 i=1</p>
    <p>(zi, zn1)(yi, 0)</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 12 / 17</p>
  </div>
  <div class="page">
    <p>Particle Filtering for Semi-Supervised RMC Introduce cluster index z Integrate out  and G via particle filtering Each particle is a vector of indices z1:n1</p>
    <p>Grow particle by zn, weight proportional to likelihood</p>
    <p>P (yn1 | z1:n1, y1:n2)P (zn | z1:n1)P (xn | zn, z1:n1, x1:n1)</p>
    <p>For semi-supervised DPMM, the y term is a beta-binomial with marginalization</p>
    <p>P (yn1 | z1:n1, y1:n2) = c1 + 1</p>
    <p>c0 + c1 + 1 + 1</p>
    <p>I If yn1 unlabeled, define the probability to be 1 I If some of y1:n2 unlabeled, skip them in counting</p>
    <p>c1 = n2 i=1</p>
    <p>(zi, zn1)(yi, 1) c0 = n2 i=1</p>
    <p>(zi, zn1)(yi, 0)</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 12 / 17</p>
  </div>
  <div class="page">
    <p>Particle Filtering for Semi-Supervised RMC Introduce cluster index z Integrate out  and G via particle filtering Each particle is a vector of indices z1:n1 Grow particle by zn, weight proportional to likelihood</p>
    <p>P (yn1 | z1:n1, y1:n2)P (zn | z1:n1)P (xn | zn, z1:n1, x1:n1)</p>
    <p>For semi-supervised DPMM, the y term is a beta-binomial with marginalization</p>
    <p>P (yn1 | z1:n1, y1:n2) = c1 + 1</p>
    <p>c0 + c1 + 1 + 1</p>
    <p>I If yn1 unlabeled, define the probability to be 1 I If some of y1:n2 unlabeled, skip them in counting</p>
    <p>c1 = n2 i=1</p>
    <p>(zi, zn1)(yi, 1) c0 = n2 i=1</p>
    <p>(zi, zn1)(yi, 0)</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 12 / 17</p>
  </div>
  <div class="page">
    <p>Particle Filtering for Semi-Supervised RMC Introduce cluster index z Integrate out  and G via particle filtering Each particle is a vector of indices z1:n1 Grow particle by zn, weight proportional to likelihood</p>
    <p>P (yn1 | z1:n1, y1:n2)P (zn | z1:n1)P (xn | zn, z1:n1, x1:n1)</p>
    <p>For semi-supervised DPMM, the y term is a beta-binomial with marginalization</p>
    <p>P (yn1 | z1:n1, y1:n2) = c1 + 1</p>
    <p>c0 + c1 + 1 + 1</p>
    <p>I If yn1 unlabeled, define the probability to be 1</p>
    <p>I If some of y1:n2 unlabeled, skip them in counting</p>
    <p>c1 = n2 i=1</p>
    <p>(zi, zn1)(yi, 1) c0 = n2 i=1</p>
    <p>(zi, zn1)(yi, 0)</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 12 / 17</p>
  </div>
  <div class="page">
    <p>Particle Filtering for Semi-Supervised RMC Introduce cluster index z Integrate out  and G via particle filtering Each particle is a vector of indices z1:n1 Grow particle by zn, weight proportional to likelihood</p>
    <p>P (yn1 | z1:n1, y1:n2)P (zn | z1:n1)P (xn | zn, z1:n1, x1:n1)</p>
    <p>For semi-supervised DPMM, the y term is a beta-binomial with marginalization</p>
    <p>P (yn1 | z1:n1, y1:n2) = c1 + 1</p>
    <p>c0 + c1 + 1 + 1</p>
    <p>I If yn1 unlabeled, define the probability to be 1 I If some of y1:n2 unlabeled, skip them in counting</p>
    <p>c1 = n2 i=1</p>
    <p>(zi, zn1)(yi, 1) c0 = n2 i=1</p>
    <p>(zi, zn1)(yi, 0)</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 12 / 17</p>
  </div>
  <div class="page">
    <p>Parameter Tuning for All Three Models</p>
    <p>Divide subjects into training and test groups</p>
    <p>Maximize training group human prediction likelihood:</p>
    <p>= arg max</p>
    <p>`tr()   str</p>
    <p>n</p>
    <p>log P (f (xn) [s] | x[s]1:n, y</p>
    <p>[s] 1:n1, )</p>
    <p>where  is h, n0, 2 for the three models, respectively.</p>
    <p>7000</p>
    <p>6000</p>
    <p>5000</p>
    <p>h</p>
    <p>l tr</p>
    <p>exemplar</p>
    <p>7000</p>
    <p>6000</p>
    <p>5000</p>
    <p>n 0</p>
    <p>l tr</p>
    <p>prototype</p>
    <p>2 0 2 8000</p>
    <p>7000</p>
    <p>6000</p>
    <p>5000</p>
    <p>log( 2 )</p>
    <p>l tr</p>
    <p>RMC</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 13 / 17</p>
  </div>
  <div class="page">
    <p>Parameter Tuning for All Three Models</p>
    <p>Divide subjects into training and test groups</p>
    <p>Maximize training group human prediction likelihood:</p>
    <p>= arg max</p>
    <p>`tr()   str</p>
    <p>n</p>
    <p>log P (f (xn) [s] | x[s]1:n, y</p>
    <p>[s] 1:n1, )</p>
    <p>where  is h, n0, 2 for the three models, respectively.</p>
    <p>7000</p>
    <p>6000</p>
    <p>5000</p>
    <p>h</p>
    <p>l tr</p>
    <p>exemplar</p>
    <p>7000</p>
    <p>6000</p>
    <p>5000</p>
    <p>n 0</p>
    <p>l tr prototype</p>
    <p>2 0 2 8000</p>
    <p>7000</p>
    <p>6000</p>
    <p>5000</p>
    <p>log( 2 )</p>
    <p>l tr</p>
    <p>RMC</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 13 / 17</p>
  </div>
  <div class="page">
    <p>Model Fitting Results</p>
    <p>Performance comparison on test group:</p>
    <p>SSL SSL SSL exemplar prototype RMC</p>
    <p>h = 0.6 n0 = 12 2 = 0.3 `te() -3727 -2460 -2169</p>
    <p>Semi-supervised RMC has the best fit, semi-supervised exemplar model the worst.</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 14 / 17</p>
  </div>
  <div class="page">
    <p>Model Predictions</p>
    <p>human 2 1 0 1 20 0.2</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>L to R R to L</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>early Lshifted early Rshifted late Lshifted late Rshifted</p>
    <p>SSL exemplar 2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>h = 0.6 h = 0.6</p>
    <p>SSL prototype 2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>n0 = 12 n  0 = 12</p>
    <p>SSL RMC 2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>2 = 0.3   2 = 0.3</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 15 / 17</p>
  </div>
  <div class="page">
    <p>Model Predictions</p>
    <p>human 2 1 0 1 20 0.2</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>L to R R to L</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>early Lshifted early Rshifted late Lshifted late Rshifted</p>
    <p>SSL exemplar 2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>h = 0.6 h = 0.6</p>
    <p>SSL prototype 2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>n0 = 12 n  0 = 12</p>
    <p>SSL RMC 2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>2 = 0.3   2 = 0.3</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 15 / 17</p>
  </div>
  <div class="page">
    <p>Model Predictions</p>
    <p>human 2 1 0 1 20 0.2</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>L to R R to L</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>early Lshifted early Rshifted late Lshifted late Rshifted</p>
    <p>SSL exemplar 2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>h = 0.6 h = 0.6</p>
    <p>SSL prototype 2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>n0 = 12 n  0 = 12</p>
    <p>SSL RMC 2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>2 = 0.3   2 = 0.3</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 15 / 17</p>
  </div>
  <div class="page">
    <p>Model Predictions</p>
    <p>human 2 1 0 1 20 0.2</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>L to R R to L</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>early Lshifted early Rshifted late Lshifted late Rshifted</p>
    <p>SSL exemplar 2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>h = 0.6 h = 0.6</p>
    <p>SSL prototype 2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>n0 = 12 n  0 = 12</p>
    <p>SSL RMC 2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>2 = 0.3   2 = 0.3</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 15 / 17</p>
  </div>
  <div class="page">
    <p>Model Predictions</p>
    <p>human 2 1 0 1 20 0.2</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>L to R R to L</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>early Lshifted early Rshifted late Lshifted late Rshifted</p>
    <p>SSL exemplar 2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>h = 0.1 h = 0.6 h = 1 h = 0.1 h = 0.6 h = 1</p>
    <p>SSL prototype 2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>2 1 0 1 2 0.2</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>n0 = 1 n0 = 12 n0 = 20 n0 = 1 n  0 = 12 n0 = 20</p>
    <p>SSL RMC 2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>2 = 0.03 2 = 0.3 2 = 3 2 = 0.03   2 = 0.3 2 = 3</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 16 / 17</p>
  </div>
  <div class="page">
    <p>Attempts to Save Semi-Supervised Exemplar Model What if we down-weight unlabeled items?</p>
    <p>r(x) = n</p>
    <p>i=1</p>
    <p>wiK( xxi</p>
    <p>h )n</p>
    <p>j=1 wiK( xxj</p>
    <p>h ) yi</p>
    <p>wi = 1 if xi labeled, wi = w otherwise</p>
    <p>Learned w = 0.2. Test group loglik -2934, still worse.</p>
    <p>8000</p>
    <p>6000</p>
    <p>w (fix h=0.6)</p>
    <p>l tr</p>
    <p>weighted exemplar</p>
    <p>7000</p>
    <p>6000</p>
    <p>5000</p>
    <p>h</p>
    <p>l tr</p>
    <p>exemplar</p>
    <p>7000</p>
    <p>6000</p>
    <p>5000</p>
    <p>n 0</p>
    <p>l tr</p>
    <p>prototype</p>
    <p>2 0 2 8000</p>
    <p>7000</p>
    <p>6000</p>
    <p>5000</p>
    <p>log( 2 )</p>
    <p>l tr</p>
    <p>RMC</p>
    <p>Model predictions still qualitatively poor:</p>
    <p>2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 17 / 17</p>
  </div>
  <div class="page">
    <p>Attempts to Save Semi-Supervised Exemplar Model What if we down-weight unlabeled items?</p>
    <p>r(x) = n</p>
    <p>i=1</p>
    <p>wiK( xxi</p>
    <p>h )n</p>
    <p>j=1 wiK( xxj</p>
    <p>h ) yi</p>
    <p>wi = 1 if xi labeled, wi = w otherwise Learned w = 0.2. Test group loglik -2934, still worse.</p>
    <p>8000</p>
    <p>6000</p>
    <p>w (fix h=0.6)</p>
    <p>l tr</p>
    <p>weighted exemplar</p>
    <p>7000</p>
    <p>6000</p>
    <p>5000</p>
    <p>h</p>
    <p>l tr exemplar</p>
    <p>7000</p>
    <p>6000</p>
    <p>5000</p>
    <p>n 0</p>
    <p>l tr</p>
    <p>prototype</p>
    <p>2 0 2 8000</p>
    <p>7000</p>
    <p>6000</p>
    <p>5000</p>
    <p>log( 2 )</p>
    <p>l tr</p>
    <p>RMC</p>
    <p>Model predictions still qualitatively poor:</p>
    <p>2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1</p>
    <p>|x )</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 17 / 17</p>
  </div>
  <div class="page">
    <p>Attempts to Save Semi-Supervised Exemplar Model What if we down-weight unlabeled items?</p>
    <p>r(x) = n</p>
    <p>i=1</p>
    <p>wiK( xxi</p>
    <p>h )n</p>
    <p>j=1 wiK( xxj</p>
    <p>h ) yi</p>
    <p>wi = 1 if xi labeled, wi = w otherwise Learned w = 0.2. Test group loglik -2934, still worse.</p>
    <p>8000</p>
    <p>6000</p>
    <p>w (fix h=0.6)</p>
    <p>l tr</p>
    <p>weighted exemplar</p>
    <p>7000</p>
    <p>6000</p>
    <p>5000</p>
    <p>h</p>
    <p>l tr exemplar</p>
    <p>7000</p>
    <p>6000</p>
    <p>5000</p>
    <p>n 0</p>
    <p>l tr</p>
    <p>prototype</p>
    <p>2 0 2 8000</p>
    <p>7000</p>
    <p>6000</p>
    <p>5000</p>
    <p>log( 2 )</p>
    <p>l tr</p>
    <p>RMC</p>
    <p>Model predictions still qualitatively poor:</p>
    <p>2 1 0 1 2 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1 |x</p>
    <p>)</p>
    <p>1 0.5 0 0.5 1 0</p>
    <p>x</p>
    <p>P (y</p>
    <p>= 1 |x</p>
    <p>)</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 17 / 17</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Contributions</p>
    <p>Test-item effects in humans</p>
    <p>Semi-supervised extension of exemplar, prototype, and ration model of categorization</p>
    <p>I All three models exhibit test-item effects I Semi-supervised RMC the best</p>
    <p>Take home message: cognitive psychology ideal application for machine learning.</p>
    <p>I Coming soon: Cognitive Modeling Repository http://www.cmr.osu.edu/</p>
    <p>This work is supported in part by AFOSR FA9550-09-1-0313, NSF IIS-0916038, IIS-0953219,</p>
    <p>DLS/DRM-0745423, and the Wisconsin Alumni Research Foundation.</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 18 / 17</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Contributions</p>
    <p>Test-item effects in humans</p>
    <p>Semi-supervised extension of exemplar, prototype, and ration model of categorization</p>
    <p>I All three models exhibit test-item effects I Semi-supervised RMC the best</p>
    <p>Take home message: cognitive psychology ideal application for machine learning.</p>
    <p>I Coming soon: Cognitive Modeling Repository http://www.cmr.osu.edu/</p>
    <p>This work is supported in part by AFOSR FA9550-09-1-0313, NSF IIS-0916038, IIS-0953219,</p>
    <p>DLS/DRM-0745423, and the Wisconsin Alumni Research Foundation.</p>
    <p>Zhu et al. (Wisconsin) Cognitive Models of Test-Item Effects 18 / 17</p>
  </div>
</Presentation>
