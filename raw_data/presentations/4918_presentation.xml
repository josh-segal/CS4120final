<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>UW-Madison Computer Sciences Multifacet Group  2010</p>
    <p>Forwardflow A Scalable Core for</p>
    <p>Power-Constrained CMPs Dan Gibson and David A. Wood</p>
    <p>ISCA 2010 SAINT-MALO FRANCE</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 2</p>
    <p>Executive Summary [1/2]</p>
    <p>Future CMPs will need Scalable Cores  Scale UP for single-thread performance</p>
    <p>Exploit ILP</p>
    <p>Scale DOWN for multiple threads  Save power  Exploit TLP</p>
    <p>Hard with traditional Arch</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 3</p>
    <p>Executive Summary [2/2]</p>
    <p>Our Contribution: Forwardflow  New Scalable Core Arch</p>
    <p>Uses pointers to eliminate associative search  Distributes values, no PRF  Scales to large instruction window sizes  Full window scheduler  No IQ clog</p>
    <p>Scales dynamically  Variable-sized instruction window</p>
    <p>~20% power/performance range</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 4</p>
    <p>Ancient History: The Memory Wall</p>
    <p>1994: Processors get faster faster than DRAM gets faster</p>
    <p>[Wulf94] (24 years ago)</p>
    <p>2010: Processors are a lot faster than DRAM  1 DRAM Access = ~100s</p>
    <p>cycles</p>
    <p>IMAGE: Prise de la Bastille (Storming the Bastille)</p>
    <p>By Jen-Pierre-Louis-Laurent Houel</p>
    <p>Solutions: More Caches, Superscalar, OoO, etc.</p>
    <p>P6, 166MHz PIV, 4000MHz</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 5</p>
    <p>Device Counts Continue to Grow</p>
    <p>In 1965, Gordon Moore sketched out his prediction of the pace of silicon technology. Decades later, Moores Law remains true, driven largely by Intels unparalleled silicon expertise.</p>
    <p>Copyright  2005 Intel Corporation.</p>
    <p>Rock, 65nm [JSSC2009] Rock16, 16nm [ITRS2007]</p>
    <p>More Transistors</p>
    <p>More Threads? (~512)</p>
    <p>More Cache?</p>
    <p>Moores Law Endures (Obligatory Slide)</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 6</p>
    <p>Amdahls Law Endures</p>
    <p>Parallel Speedup Limited by Parallel Fraction  i.e., Only ~10x</p>
    <p>speedup at N=512, f=90%</p>
    <p>Everyone knows Amdahls law, but quickly forgets it. -Thomas Puzak</p>
    <p>f = 90%f = 95%f = 99%</p>
    <p>[ ](1 - f ) + f</p>
    <p>N</p>
    <p>-1</p>
    <p>[Hill08]</p>
    <p>Takeaway:</p>
    <p>No TLP = No Speedup</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 7</p>
    <p>Utilization Wall (aka SAF)</p>
    <p>Simultaneously Active Fraction (SAF): Fraction of devices in a fixed-area design that can be active at the same time, while still remaining within a fixed power budget.</p>
    <p>Takeaway: More Transistors  Lots of them have to be off</p>
    <p>[Venkatesh2009]</p>
    <p>D yn</p>
    <p>a m</p>
    <p>ic S</p>
    <p>A F</p>
    <p>LP DevicesHP Devices</p>
    <p>[Chakraborty2008]</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 8</p>
    <p>Walls, Laws, and Threads</p>
    <p>Power prevents all of the chip from operating all of the time</p>
    <p>Many applications are single-threaded  Need ILP</p>
    <p>Emerging Solution: Scalable Cores</p>
    <p>Some applications are multi-threaded  Need TLP</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 9</p>
    <p>Scalable Cores</p>
    <p>Scale UP for Performance  Use more resources for more</p>
    <p>performance  (e.g., 2 Strong Oxen)</p>
    <p>Scale DOWN for Energy Conservation  Exploit TLP with many small cores  (e.g., 1024 Chickens)</p>
    <p>If you were plowing a field, which would you rather use: Two strong oxen or 1024 chickens?</p>
    <p>-Attributed to Seymour Cray</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 10</p>
    <p>Core Scaling</p>
    <p>$ $ $$</p>
    <p>Core CoreCore Core</p>
    <p>$</p>
    <p>Core</p>
    <p>Core</p>
    <p>$</p>
    <p>Core</p>
    <p>$</p>
    <p>Core</p>
    <p>$</p>
    <p>Core</p>
    <p>Core</p>
    <p>$</p>
    <p>Core</p>
    <p>$</p>
    <p>Core</p>
    <p>$</p>
    <p>Core</p>
    <p>$</p>
    <p>Core</p>
    <p>$</p>
    <p>Core</p>
    <p>$</p>
    <p>Core</p>
    <p>$</p>
    <p>Core</p>
    <p>$</p>
    <p>Many Threads for TLP</p>
    <p>One Thread for ILP</p>
    <p>Assume SAF = 50%</p>
    <p>Core Core Core Core</p>
    <p>$ $ $ $</p>
    <p>$ $ $ $</p>
    <p>CoreCoreCoreCore</p>
    <p>Baseline 8-Core CMP</p>
    <p>Scale Down</p>
    <p>Scale Up</p>
    <p>Hard to do with a traditional core design (not impossible)</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 11</p>
    <p>Microarchitecture for Scalable Cores</p>
    <p>Conventional OoO:  Interdependent structures scaled together</p>
    <p>Some structures easy to scale, some hard</p>
    <p>Scaling up means scaling to large sizes  Hard to tolerate search operations in large structures</p>
    <p>This Work:  Single, integrated structure  Wire-delay tolerant design  Avoid associative search</p>
    <p>RAM-based Disaggregated Instruction Window</p>
    <p>Pointers instead</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 12</p>
    <p>Forwardflow  Forward Pointers</p>
    <p>Use Pointers to explicitly define data movement  Every Operand has a Next Use</p>
    <p>Pointer  Register names not needed</p>
    <p>+ No search operation  No associative search (ever)</p>
    <p>Serialized Wakeup  Usually OK: Most ops have few</p>
    <p>successors [Ramirez04,Sassone07]</p>
    <p>S1 S2 Dst</p>
    <p>ld R4 4 R1</p>
    <p>add R1 R3 R3</p>
    <p>sub R4 16 R4</p>
    <p>st R3 R8</p>
    <p>breq R4 R3</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 13</p>
    <p>Forwardflow  Dataflow Queue (DQ)</p>
    <p>Combination Scheduler, ROB, and Register File  Schedules instructions  Holds data values for all</p>
    <p>operands</p>
    <p>Op1 Op2 Dest</p>
    <p>Dataflow Queue (DQ)</p>
    <p>breq R35-S1R4 4-S1R3</p>
    <p>R2</p>
    <p>R4</p>
    <p>R3</p>
    <p>R2</p>
    <p>R1</p>
    <p>Register Consumer Table (RCT)</p>
    <p>R4</p>
    <p>Next Instruction: breq R4 R3</p>
    <p>R3=0</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 14</p>
    <p>Logical DQ Organization Physical DQ Organization</p>
    <p>DQ Bank Group  Fundamental Unit of Scaling</p>
    <p>Physical Organization</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 15</p>
    <p>Scaling a Forwardflow Core</p>
    <p>Fully-provisioned Forwardflow Core  4 Bank Groups</p>
    <p>128-entry DQ ea.  2 IALU ea.  2 FPALU ea.</p>
    <p>Scale the core by scaling the DQ  BGs power on/off</p>
    <p>independently</p>
    <p>L 1 -D</p>
    <p>L 1 -I</p>
    <p>ARF</p>
    <p>RCTRCTRCT</p>
    <p>BP</p>
    <p>Frontend Backend</p>
    <p>F-4: BGs: 4 DQ: 512-entry IALU: 8 FPALU: 8 DMEM: 2</p>
    <p>F-2: BGs: 2 DQ: 256-entry IALU: 4 FPALU: 4 DMEM: 2</p>
    <p>F-1: BGs: 1 DQ: 128-entry IALU: 2 FPALU: 2 DMEM: 2</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 16</p>
    <p>Evaluation: Questions</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 17</p>
    <p>Evaluation: Target Machine</p>
    <p>8-Core CMP  32KB L1s, 1MB L2s, 8MB</p>
    <p>shared L3  NoSQ [Sha06]  OoO Baseline  SPARCv9 +</p>
    <p>L3B4</p>
    <p>L2</p>
    <p>L1-D</p>
    <p>Core4</p>
    <p>L1-I</p>
    <p>Core0</p>
    <p>L1-D</p>
    <p>L1-I</p>
    <p>L2</p>
    <p>L3B0</p>
    <p>Core1</p>
    <p>L1-D</p>
    <p>L1-I</p>
    <p>L2</p>
    <p>L3B1</p>
    <p>Core2</p>
    <p>L1-D</p>
    <p>L1-I</p>
    <p>L2</p>
    <p>L3B2</p>
    <p>Core3</p>
    <p>L1-D</p>
    <p>L1-I</p>
    <p>L2</p>
    <p>L3B3</p>
    <p>L3B5</p>
    <p>L2</p>
    <p>L1-D</p>
    <p>Core5</p>
    <p>L1-I</p>
    <p>L3B6</p>
    <p>L2</p>
    <p>L1-D</p>
    <p>Core6</p>
    <p>L1-I</p>
    <p>L3B7</p>
    <p>L2</p>
    <p>L1-D</p>
    <p>Core7</p>
    <p>L1-I</p>
    <p>D R</p>
    <p>A M</p>
    <p>D R</p>
    <p>A M</p>
    <p>Running One Thread  7 Cores Off, 1 On  specCPU + Com (1)</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 18</p>
    <p>Results: OoO-like Performance</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d R</p>
    <p>u n</p>
    <p>ti m</p>
    <p>e</p>
    <p>SPEC INT 2006 SPEC FP 2006 Commercial Workloads</p>
    <p>Overall, Forwardflow (F1) performance is close to that of same-size OoO</p>
    <p>Some good cases (e.g., libquantum): OoO suffers from IQ Clog</p>
    <p>Some bad cases (e.g., bzip2): Not enough misses to cover serialized wakeup</p>
    <p>F-1</p>
    <p>G M</p>
    <p>e a</p>
    <p>n</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 19</p>
    <p>Results: Performance Scaling</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d R</p>
    <p>u n</p>
    <p>ti m</p>
    <p>e</p>
    <p>F-1 F-2 F-4</p>
    <p>SPEC INT 2006 SPEC FP 2006 Commercial Workloads</p>
    <p>G M</p>
    <p>e a</p>
    <p>n</p>
    <p>Runtime Reduction compared to F-1:</p>
    <p>F-2: 12%</p>
    <p>Takeaway: Forwardflows Backend Scaling Scales Core Performance</p>
    <p>Some great cases, some non-great cases F-4: 21%</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 20</p>
    <p>Results: Power Scaling</p>
    <p>F-1 consumes 10% less power than OoO  Most of the difference</p>
    <p>comes from the finegrained DQ accesses and smaller RF</p>
    <p>OoO F-1 F-2 F-4</p>
    <p>Configuration</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d P</p>
    <p>o w</p>
    <p>e r</p>
    <p>FrontendBackend CachesOtherStatic</p>
    <p>+16%</p>
    <p>+14%</p>
    <p>+13% +14%</p>
    <p>+12% +11%</p>
    <p>Backend consumption scales reasonably (30%)</p>
    <p>Scaling up increases power consumption in unscaled components  Larger windows better</p>
    <p>utilize caches and frontend</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 21</p>
    <p>Concluding Remarks</p>
    <p>Future CMPs will need Scalable Cores  Scale UP for single-thread performance  Scale DOWN to run multiple threads</p>
    <p>Forwardflow Core:  New Arch for scaling the instruction</p>
    <p>window  ~20% power/performance</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 22</p>
    <p>This looks familiar Didnt I just see a talk on this topic from the same institution?</p>
    <p>-75% of the audience (the waking portion)</p>
    <p>Approximates In-Order</p>
    <p>Full-Window Scheduling</p>
    <p>Pointers, DQ, OoOSteering, In-Order</p>
    <p>Mechanism</p>
    <p>Scalable CoresScalable CoresVision</p>
    <p>Forwardflow [Gibson10]</p>
    <p>WiDGET [Watanabe10]</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 23</p>
    <p>Acknowledgments / Q&amp;A</p>
    <p>NSF CCR-0324878, CNS-0551401, CNS0720565 for financial support (e.g., keeping me alive in graduate school, buying cluster nodes, etc.) Multifacet and Multiscalar groups for years of guidance and advice. Yasuko Watanabe for simulator contributions. UW Computer Architecture Affiliates for many discussions, suggestions, and encouraging remarks. ACM/SIGARCH+IEEE/TCCA for part of a trip to France. Megan Gibson for the rest. Anonymous reviewers are also swell people and their advice made this work better.</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 24</p>
    <p>INDEX OF BACKUP SLIDES</p>
    <p>Multithreaded Workloads  Using DVFS to Scale  Mispredictions  ARF  More vs. WiDGET  A Day In the Life of a Forwardflow Op</p>
    <p>Decode  Dispatch  Wakeup  Issue  Writeback  Commit</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 25</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 26</p>
    <p>Related Work</p>
    <p>Scalable Schedulers  Direct Instruction Wakeup [Ramirez04]:</p>
    <p>Scheduler has a pointer to the first successor  Secondary table for matrix of successors</p>
    <p>Hybrid Wakeup [Huang02]:  Scheduler has a pointer to the first successor  Each entry has a broadcast bit for multiple</p>
    <p>successors</p>
    <p>Half Price [Kim02]:  Slice the scheduler in half  Second operand often unneeded</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 27</p>
    <p>Related Work</p>
    <p>Dataflow &amp; Distributed Machines  Tagged-Token [Arvind90]</p>
    <p>Values (tokens) flow to successors</p>
    <p>TRIPS [Sankaralingam03]:  Discrete Execution Tiles: X, RF, $, etc.  EDGE ISA</p>
    <p>Clustered Designs [e.g. Palacharla97]  Independent execution queues</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 28</p>
    <p>Results: Multiple Threads specOMP Power/Performance</p>
    <p>Speedup</p>
    <p>N o</p>
    <p>rm a li</p>
    <p>z e d</p>
    <p>P o</p>
    <p>w e r applu</p>
    <p>apsi</p>
    <p>equake</p>
    <p>swim</p>
    <p>wupwise</p>
    <p>Most benchmarks trade off power/performance with different Forwardflow configurations Some do not</p>
    <p>Feasible operating points depends on available power, e.g.:</p>
    <p>at Y=15, nearly all can run F-4</p>
    <p>at Y=8, 9 of 14 can run without DVFS</p>
    <p>Back to Index</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 29</p>
    <p>Shutting Off Cores (or DVFS)</p>
    <p>Assume SAF = 50%</p>
    <p>Core Core Core Core</p>
    <p>$ $ $ $</p>
    <p>$ $ $ $</p>
    <p>CoreCoreCoreCore</p>
    <p>Baseline 8-Core CMP</p>
    <p>Shut off 50%</p>
    <p>Shutting off cores is too much</p>
    <p>Limits TLP: Not enough cores</p>
    <p>Limits ILP: Cores arent aggressive enough</p>
    <p>Core Core Core Core</p>
    <p>$ $ $ $</p>
    <p>$ $ $ $</p>
    <p>CoreCoreCoreCore</p>
    <p>Back to Index</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 30</p>
    <p>Forwardflow  Resolving Branches</p>
    <p>Op1 Op2 Dest Dataflow Queue On Branch Pred.:</p>
    <p>Checkpoint RCT  Checkpoint Pointer</p>
    <p>Valid Bits</p>
    <p>Checkpoint Restore  Restores RCT  Invalidates Bad</p>
    <p>Pointers</p>
    <p>Back to Index</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 31</p>
    <p>Forwardflow  ARF [1/2]</p>
    <p>Architectural Register File (ARF)  Read at Dispatch  Written at Commit</p>
    <p>Op1 Op2 Dest</p>
    <p>Dataflow Queue (DQ)</p>
    <p>mov5-S1R4</p>
    <p>R2</p>
    <p>R4</p>
    <p>R3</p>
    <p>R2</p>
    <p>R1</p>
    <p>Register Consumer Table (RCT)</p>
    <p>R2</p>
    <p>Next Instruction: mov R2  R5</p>
    <p>: Read from ARF</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 32</p>
    <p>Forwardflow  ARF [2/2]</p>
    <p>Architectural Register File (ARF)  Read at Dispatch  Written at Commit</p>
    <p>Op1 Op2 Dest</p>
    <p>Dataflow Queue (DQ)</p>
    <p>mov R2</p>
    <p>Next Commit: ld [R4+4]  R1</p>
    <p>R1=44</p>
    <p>Write R1 = 44 to ARF</p>
    <p>Back to Index</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 33</p>
    <p>WiDGET vs. FF [1/3]</p>
    <p>Forwardflow  Full-window</p>
    <p>scheduling, clog-free  Good for Lookahead  Good for MLP</p>
    <p>Pointer-based dependences</p>
    <p>Serialized Wakeup  Bad for serial uses of</p>
    <p>same value</p>
    <p>WiDGET  Steering-based</p>
    <p>scheduling  Simple steering,</p>
    <p>simple execution logic  Can clog</p>
    <p>Some centralization  PRF</p>
    <p>Scales down to inorder</p>
    <p>Back to Index</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 34</p>
    <p>EU 0</p>
    <p>IB 0 IB 1</p>
    <p>EU 1</p>
    <p>IB 0 IB 1</p>
    <p>WiDGET</p>
    <p>WiDGET vs. FF [2/3] ld [R1+R2]R3</p>
    <p>indep. R2</p>
    <p>br -8</p>
    <p>Ample MLP, many forward slices</p>
    <p>ld [R1+R2]R3</p>
    <p>indep. R2</p>
    <p>br -8</p>
    <p>ld [R1+R2]R3</p>
    <p>indep. R2</p>
    <p>br -8</p>
    <p>ld [R1+R2]R3</p>
    <p>indep. R2</p>
    <p>br -8</p>
    <p>ldR3</p>
    <p>? R2</p>
    <p>ldR3</p>
    <p>? R2</p>
    <p>ldR3</p>
    <p>? R2</p>
    <p>ldR3</p>
    <p>? R2</p>
    <p>ldR3</p>
    <p>? R2</p>
    <p>Cannot Steer: Stall</p>
    <p>Entire Window</p>
    <p>Forwardflow</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 35</p>
    <p>EU 0</p>
    <p>IB 0 IB 1</p>
    <p>EU 1</p>
    <p>IB 0 IB 1</p>
    <p>WiDGET</p>
    <p>WiDGET vs. FF [3/3] ld [R1+R2]R3</p>
    <p>mul R5 R3 R2</p>
    <p>add R5 R3 R4</p>
    <p>shr R3 4 R9</p>
    <p>Serial use of R3</p>
    <p>Forwardflow</p>
    <p>ld [R1+R2]R3</p>
    <p>mul R5 R3 R2</p>
    <p>add R5 R3 R4</p>
    <p>shr R3 4 R9</p>
    <p>Artificial Serialization</p>
    <p>mulR2</p>
    <p>ld R3 addR4 shrR9</p>
    <p>Back to Index</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 36</p>
    <p>add</p>
    <p>A Day in the Life of a Forwardflow Instruction: Decode</p>
    <p>R3</p>
    <p>R2</p>
    <p>R1@7D</p>
    <p>R3=0</p>
    <p>add R1 R3 R3</p>
    <p>Back to Index</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 37</p>
    <p>A Day in the Life of a Forwardflow Instruction: Dispatch</p>
    <p>R3R1add</p>
    <p>R14R4ld</p>
    <p>Op1 Op2 Dest Dataflow Queue</p>
    <p>add R1@7D R3=0</p>
    <p>Implicit -- Not actually written</p>
    <p>Back to Index</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 38</p>
    <p>A Day in the Life of a Forwardflow Instruction: Wakeup</p>
    <p>Op1 Op2 DestDataflow Queue</p>
    <p>DQ7 Result is 0!</p>
    <p>Update HW</p>
    <p>value 0</p>
    <p>DestPtr.Read(7)</p>
    <p>DestVal.Write(7,0)</p>
    <p>Back to Index</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 39</p>
    <p>A Day in the Life of a Forwardflow Instruction: Issue (and Execute)</p>
    <p>Op1 Op2 DestDataflow Queue</p>
    <p>S2Val.Read(8)</p>
    <p>Meta.Read(8)</p>
    <p>Update HW</p>
    <p>value 0</p>
    <p>S1Ptr.Read(8)</p>
    <p>S1Val.Write(8,0)</p>
    <p>add 0</p>
    <p>add 0 + 0  DQ8</p>
    <p>Back to Index</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 40</p>
    <p>A Day in the Life of a Forwardflow Instruction: Writeback</p>
    <p>R8R3st</p>
    <p>R416R4sub</p>
    <p>R30R1add</p>
    <p>Op1 Op2 DestDataflow Queue</p>
    <p>Update HW</p>
    <p>value 0</p>
    <p>DestPtr.Read(8)</p>
    <p>DestVal.Write(8,0)</p>
    <p>Back to Index</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 41</p>
    <p>A Day in the Life of a Forwardflow Instruction: Commit</p>
    <p>R8R3st</p>
    <p>R416R4sub</p>
    <p>Op1 Op2 DestDataflow Queue</p>
    <p>Meta.Read(8)</p>
    <p>DestVal.Read(8)</p>
    <p>add R3:0</p>
    <p>ARF.Write(R3,0)</p>
    <p>Back to Index</p>
  </div>
  <div class="page">
    <p>ISCA 2010 - 42</p>
    <p>R2</p>
    <p>DQ Q&amp;A</p>
    <p>Op1 Op2 Dest Dataflow Queue</p>
    <p>Register Consumer Table</p>
    <p>R2</p>
  </div>
</Presentation>
