<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>STOW: Spatially and Temporally Optimized Write Caching Algorithm</p>
    <p>Binny S. Gill, Michael Ko, Biplob Debnath, Wendy Belluomini IBM Almaden Research Center, University of Minnesota</p>
  </div>
  <div class="page">
    <p>An eviction problem (like read caches)  Goal: Keep the disk heads busy for the least time  Some exploit temporal locality</p>
    <p>To reduce number of destages  LRU, CLOCK, FBR, LRU-2, 2Q, LRFU, LIRS, MQ, ARC, CAR</p>
    <p>Some exploit spatial locality  Apply temporal locality rules to larger units  Tracks (multiple pages), stripes (multiple tracks)</p>
    <p>Some create spatial locality via reordering  To reduce the average cost of destages  SSTF, SATF, SCAN, CSCAN, LOOK, VSCAN, GSTF, WSTF</p>
    <p>Some do all of the above: WOW (earlier work)</p>
    <p>Prior Art: Write Cache Algorithms</p>
    <p>A B Track t</p>
  </div>
  <div class="page">
    <p>WOW Algorithm</p>
    <p>CLOCK CSCAN</p>
    <p>WOW</p>
  </div>
  <div class="page">
    <p>Is there more to it?</p>
    <p>The 5 properties a good write cache serving disks needs to have:</p>
    <p>Harness temporal locality</p>
    <p>Create spatial locality</p>
    <p>Maintain free space</p>
    <p>Distribute the write load uniformly over time</p>
    <p>Also serve read hits</p>
  </div>
  <div class="page">
    <p>What about the Destage Rate?</p>
    <p>Most cache research revolves around the eviction or destage order problem</p>
    <p>Destage rate is under-studied, but surprisingly is extremely important for performance</p>
    <p>If you can tame the destage rate, there is another gold mine beyond the benefits of WOW</p>
    <p>We had to invent a new destage order (STOW) to control the destage rate</p>
    <p>STOW becomes the first write caching algorithm to explicitly allow a good destage order and a good destage rate = a powerful combination</p>
  </div>
  <div class="page">
    <p>Write Cache Tutorial: How to get it wrong?</p>
    <p>Ignore RAID Parity Groups while destaging  We need to destage all members of the same parity group</p>
    <p>together to the RAID array, not spread out in time</p>
    <p>Simple but important  WOW already groups based on RAID stripes</p>
  </div>
  <div class="page">
    <p>Tutorial: Destage rate = as quickly as you can</p>
    <p>Destage Order = WOW</p>
    <p>SPC1- Like Workload</p>
  </div>
  <div class="page">
    <p>Tutorial: Destage rate = as quickly as you can only when the cache occupancy reaches a fixed Threshold</p>
    <p>Fixed Threshold</p>
    <p>Destage Order = WOW</p>
    <p>Destage rate toggles between none and full force</p>
    <p>SPC1- Like Workload</p>
    <p>WOW</p>
  </div>
  <div class="page">
    <p>Tutorial: Destage with Linear Thresholding</p>
  </div>
  <div class="page">
    <p>Tutorial: Destaging with Linear Threshold</p>
    <p>Linear threshold cannot keep cache away from 100% full</p>
    <p>Spikes are due to long time spent in sequential and random regions</p>
    <p>Time spent at 100% is bad. Spikes make write burst absorption and destage rate suffer.</p>
  </div>
  <div class="page">
    <p>Separate Random and Sequential data</p>
    <p>Spikes are gone .. now there are two active areas on the disk platters =&gt; destage order suffers</p>
  </div>
  <div class="page">
    <p>Getting Warmer: Add hysteresis to the destages</p>
    <p>RanQ SeqQ</p>
    <p>Disks</p>
    <p>HysteresisCount = 128 * number of spindles</p>
    <p>in RAID array</p>
    <p>Focus on one region of the disk platters for some time before moving to the next region =&gt;minimize the negative impact on destage order</p>
    <p>But what if workload has no sequential or random?</p>
    <p>Split 50-50</p>
  </div>
  <div class="page">
    <p>STOW: Adapting the size of RanQ and SeqQ</p>
    <p>Queue sizes are adapted according to workload  DesiredSeqQSize - - :</p>
    <p>Whenever a second write happens in a RAID stripe in RanQ</p>
    <p>DesiredSeqQSize += n * |RanQ|/|SeqQ| :  Where, n = number of spindles in array  Whenever there is a break in the LBA sequence of destages</p>
    <p>from SeqQ</p>
    <p>If |SeqQ| &gt; DesiredSeqQSize, then destage from SeqQ, else destage from RanQ</p>
  </div>
  <div class="page">
    <p>STOW vs Competition</p>
    <p>RanQ SeqQ</p>
    <p>Sizes are dynamically</p>
    <p>adapted according to real-time</p>
    <p>marginal utilities</p>
  </div>
  <div class="page">
    <p>Experimental Setup</p>
    <p>Full Backend = All Disk Capacity Targeted</p>
    <p>Partial Backend = Outer 1% of disk capacity targeted</p>
    <p>SPC-1 Like Benchmark</p>
  </div>
  <div class="page">
    <p>STOW: No more spikes in cache occupancy</p>
    <p>RAID 5 Partial Backend: target 3500 IOPS, threshold: 70/40</p>
  </div>
  <div class="page">
    <p>Full Backend : Throughput vs. Response Time</p>
    <p>RAID 5</p>
  </div>
  <div class="page">
    <p>Partial Backend: Throughput vs. Response Time</p>
    <p>RAID 5</p>
  </div>
  <div class="page">
    <p>Vary the spread between high and low thresholds</p>
    <p>RAID 5, Full Backend: Target: 1200 IOPS</p>
  </div>
  <div class="page">
    <p>Vary the cache size</p>
    <p>RAID 5, Full Backend: Target 1050 IOPS ; H/L : 90/80</p>
  </div>
  <div class="page">
    <p>Tackling both destage order and destage rate = powerful write cache algorithm</p>
    <p>Summary</p>
    <p>STOW  Leverages temporal locality  Creates spatial locality  Maintains steady free space to absorb write bursts  Destages uniformly  Protects Random data from Sequential bursts  Dynamically adapts the sizes of the sequential and</p>
    <p>random portions of the cache to maximize throughput</p>
    <p>STOW &gt; WOW &gt; (LRW, CSCAN)</p>
    <p>Is there still more to it? :)</p>
    <p>RanQ SeqQ</p>
    <p>Thank You!</p>
  </div>
</Presentation>
