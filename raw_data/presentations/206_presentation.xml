<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Designing Energy Efficient Communication Runtime Support for</p>
    <p>Data Centric Programming Models</p>
    <p>Abhinav Vishnu1, Shuaiwen Song2,</p>
    <p>Andres Marquez1, Kevin Barker1,</p>
    <p>Darren J. Kerbyson1, Kirk Cameron2, Pavan Balaji3</p>
  </div>
  <div class="page">
    <p>Power is becoming the Key Challenge for the future</p>
    <p>Ever increasing computational requirements of scientific domains</p>
    <p>Significantly rising to future 10-, 100-, 1000-petaflop systems</p>
    <p>System energy consumption is not scalable Roadrunner (1.4PF) ~2.4MW, nave scaling not possible</p>
    <p>Aim for US DOE is a 1000x increase in computational performance with only a 10x increase in power consumption from present day</p>
    <p>Energy efficiency important at all levels: Hardware, algorithms, programming models, system stack</p>
    <p>We focus here on the communication runtime stack of Programming Models</p>
  </div>
  <div class="page">
    <p>Questions posed for Energy Efficient Communication Runtime</p>
    <p>How should an energy efficient one-sided communication runtime system for modern interconnects be designed ?</p>
    <p>What are the design challenges?</p>
    <p>What are the energy savings on todays machines ?</p>
    <p>What is the impact on performance ?</p>
    <p>What can we expect from future systems?</p>
  </div>
  <div class="page">
    <p>Programming models and Communications: Two-sided and One-sided</p>
    <p>Example: Global Arrays</p>
    <p>Two-Sided: Message requires cooperation on both sides.</p>
    <p>Useful for tightly coupled applications</p>
    <p>MPI common place with verylarge application base</p>
    <p>One-sided: Asynchronous Get, Put &amp; atomic operations (accumulate) on data.</p>
    <p>Useful for applications with irregular communication characteristics</p>
    <p>Global Arrays: application base centered on Computational Chemistry, Subsurface modeling</p>
    <p>P0 P1P0 P1</p>
    <p>Example: MPI</p>
  </div>
  <div class="page">
    <p>Global Arrays: Programming Model that Provides Easy Access to Distributed Data</p>
    <p>Aims: provide easy global access to distributed data</p>
    <p>Traditionally has suited to irregular access to dense arrays</p>
    <p>Application domains include Chemistry, Bio-informatics, subsurface modeling</p>
    <p>Use of one-sided communication</p>
    <p>Active development @ PNNL Arbitrary distributed data structures</p>
    <p>Fault Tolerance</p>
    <p>Task based execution</p>
    <p>Global Address Space</p>
    <p>Physically distributed data</p>
  </div>
  <div class="page">
    <p>Global Arrays (cont.)</p>
    <p>Example: Obtaining a sub-region from a distributed array</p>
    <p>Global Arrays:</p>
    <p>if (me = P0) NGA_Get(g_a, lo, hi, buffer, ld);</p>
    <p>Global Array handle</p>
    <p>}</p>
    <p>Global upper and lower indices of data patch</p>
    <p>Local buffer and array of strides</p>
    <p>}</p>
    <p>Message Passing:</p>
    <p>identify size and location of data</p>
    <p>loop over processors: if (m e = P_N) then</p>
    <p>pack data in local m essage buffer send block of data to m essage buffer on P0</p>
    <p>else if (m e = P0) then receive block of data from P_N in m essage buffer unpack data from m essage buffer to local buffer</p>
    <p>endif end loop</p>
    <p>copy local data on P0 to local buffer</p>
    <p>P0 P1</p>
    <p>P2 P3</p>
    <p>P0</p>
  </div>
  <div class="page">
    <p>ARMCI: underlying communication runtime for Global Arrays</p>
    <p>Aggregate Remote Memory Copy Interface (ARMCI) Provides one-sided communication primitives</p>
    <p>Put, Get, Accumulate, Atomic Memory Operations</p>
    <p>Abstract network interfaces</p>
    <p>Established &amp; available on all leading platforms Cray XTs, XE</p>
    <p>IBM Blue Gene L | P</p>
    <p>Commodity interconnects (InfiniBand, Ethernet etc)</p>
    <p>Further upcoming platforms IBM BlueWaters, Blue Gene Q</p>
    <p>Cray Cascade</p>
  </div>
  <div class="page">
    <p>Asynchronous Agent for One-sided Communication</p>
    <p>Asynchronous agent used for multiple purposes Accumulate and atomic memory operations</p>
    <p>Non-contiguous data transfer</p>
    <p>Needs to be active only during active communication</p>
    <p>Default operation: Blocks/polls on a network event</p>
    <p>Asynchronous Agent Thread</p>
    <p>Application Process</p>
    <p>Node1 Coherency Domain</p>
    <p>Node2</p>
  </div>
  <div class="page">
    <p>Energy Efficiency Mechanisms for Communications</p>
    <p>Get Data Get Data</p>
    <p>Get Data Get Data</p>
    <p>Interrupt</p>
    <p>DVFS scaling</p>
    <p>DVFS No Yes</p>
    <p>Interrupt</p>
    <p>Polling</p>
    <p>Default</p>
    <p>Energy Saving &amp; increase in time</p>
    <p>Dynamic Voltage/Frequency Scaling (DVFS) Scale down during communication, Freq (core), Voltage (socket)</p>
    <p>But may lead to increased latency</p>
    <p>Interrupt Driven Execution Yield CPU &amp; wake up on network event, BUT may increase latency</p>
  </div>
  <div class="page">
    <p>Handling Different Data Transfer Types Leads to Differences in Possible Gains</p>
    <p>Contiguous data transfer Request DVFS scale down after data transfer request initiated</p>
    <p>Interrupt driven execution also requested at this point</p>
    <p>DVFS scale up after data transfer has been completed</p>
    <p>Non-contiguous (e.g. strided) data transfer Requires data copy in intermediate buffers</p>
    <p>DVFS/Interrupt based execution performed after data transfer request initiation</p>
    <p>Result is less potential gain on non-contiguous transfers</p>
  </div>
  <div class="page">
    <p>Experimental Test-Bed: The Energy Smart Data Center at PNNL</p>
    <p>ESDC Developed with high energy efficiency in mind</p>
    <p>Integrated power monitoring Node level (some), Rack level, machine room level</p>
    <p>Also used to explore cooling techniques (spray cooling)</p>
    <p>InfiniBand 4xDDR Fat-tree</p>
    <p>DVFS possible: Enabled DFS scaling: 2.33 GHz &amp;1.9 GHz</p>
    <p>Upper bound on expected benefits is only 20%</p>
    <p>Voltage scaling not available</p>
  </div>
  <div class="page">
    <p>Evaluation Methodology</p>
    <p>All-to-all personalized communication using ARMCI one-sided communication primitives</p>
    <p>Accumulate/Get/Put Strided benchmarks</p>
    <p>Metrics Normalized Energy consumed/Mbyte</p>
    <p>Normalized latency</p>
    <p>w.r.t. default (polling/no DFS)</p>
    <p>For I = 0 to iterations do For j = 1 to nprocs-1 do Dest = myid + j Put(data) to dest Fence to dest End for End for</p>
    <p>TimePower</p>
    <p>Timers: start &amp; end (in code) Power: sampled &amp; averaged</p>
  </div>
  <div class="page">
    <p>Results: ARMCI Get Performance</p>
    <p>Combinations of Interrupt and DVFS approaches compared For small message:</p>
    <p>Default (polling only) outperforms in latency and Energy/Mbytes</p>
    <p>For large messages (&gt; 32KB): Interrupt+DVFS improves Energy/Mbytes by ~6% with a small increase in latency (up to 5%)</p>
  </div>
  <div class="page">
    <p>Results: ARMCI Put Performance</p>
    <p>Interrupt+DVFS improves Energy/MBytes by up to 10% compared to default (polling only) Negligible increase in latency (up to 5%)</p>
  </div>
  <div class="page">
    <p>Results: ARMCI Accumulate Performance</p>
    <p>Interrupt+DVFS improves Energy/MBytes by up to 5% compared to default (polling only) Negligible increase in latency (up to 3%)</p>
  </div>
  <div class="page">
    <p>Results: ARMCI Put Strided Performance</p>
    <p>Interrupt+DVFS improves Energy/MBytes by up to 6% compared to default (polling only) Negligible increase in latency (up to 3%)</p>
  </div>
  <div class="page">
    <p>Summary of Results</p>
    <p>Min Message Size (KB)</p>
    <p>Increase (%) in Latency (@256KB)</p>
    <p>Decrease (%) in Energy (@256KB)</p>
    <p>Get 32 5 6</p>
    <p>Put 16 5 9</p>
    <p>Accumulate 16 3 5</p>
    <p>Strided Put 16 2 6</p>
    <p>Consistent results across different communication types Recall maximum energy saving is &lt; 20%</p>
    <p>Only two frequencies available: 2.3 &amp; 1.9 GHz Results show that a significant portion of this saving can be achieved</p>
    <p>E.g. for Get, the Energy saving is 6% (from a max of 20%)</p>
  </div>
  <div class="page">
    <p>Results show limited improvements and for large transfers, BUT</p>
    <p>Results show that approach can result in energy reduction</p>
    <p>Limited by both speed of DVFS, &amp; freq levels (on testbed)</p>
    <p>Expect greater potential from future processors</p>
    <p>Greater impact of DVFS Testbed limited to 2 frequencies (1.9 vs. 2.3 GHz)</p>
    <p>Less overheads for DVFS (?)</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>We presented the mechanisms for energy efficiency provided by modern processors and networks We leveraged these mechanisms to design a communication runtime system for a data centric programming model Our evaluation shows:</p>
    <p>Up to 10% reduction in Energy/Mbytes with negligible performance penalty</p>
    <p>Up to 50% of achievable improvement possible in our testbed</p>
    <p>Approach should have greater impact on upcoming processor architectures</p>
  </div>
  <div class="page">
    <p>Future Work</p>
    <p>This is a part of active work: Exploring the interplay between Performance and Power</p>
    <p>Significant focus on applications</p>
    <p>Modeling of Performance / Power / Reliability in concert</p>
    <p>Looking at the co-design for future large-scale systems</p>
    <p>Our thanks go to: eXtreme Scale Computing Initiative (XSCI) @PNNL</p>
    <p>US DOE Office of Science</p>
    <p>Energy Smart Data Center</p>
  </div>
</Presentation>
