<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Size-aware sharding for improving tail latencies in</p>
    <p>in-memory key-value stores</p>
    <p>Diego Didona (EPFL), Willy Zwaenepoel (University of Sydney)</p>
  </div>
  <div class="page">
    <p>Contributions</p>
    <p>(1) Size-aware sharding Improve tail latencies of in-memory key-value stores</p>
    <p>with heterogeneous item sizes</p>
    <p>(2) Minos in-memory key-value store Order-of-magnitude lower 99th percentile latency</p>
  </div>
  <div class="page">
    <p>BACKGROUND</p>
  </div>
  <div class="page">
    <p>Tail latencies in high fan-out applications</p>
    <p>Slowest reply determines request latency SLO: N-th percentile of resp. time &lt; X</p>
  </div>
  <div class="page">
    <p>In-memory key-value stores (KV)</p>
    <p>Widespread solution to deliver low latency</p>
    <p>Caches / non-persistent data repositories</p>
  </div>
  <div class="page">
    <p>State-of-the-art KVs: design</p>
    <p>High-bandwidth, multi-queue NICs +</p>
    <p>Kernel-bypassing network stacks</p>
    <p>Run-to-completion model +</p>
    <p>Ad hoc data structures and CC</p>
  </div>
  <div class="page">
    <p>State-of-the-art KVs: performance</p>
    <p>sec-scale latencies @ several Mops/sec</p>
  </div>
  <div class="page">
    <p>State-of-the-art KVs: performance</p>
    <p>sec-scale latencies @ several Mops/sec</p>
    <p>But high tail latencies with heterogeneous item sizes</p>
  </div>
  <div class="page">
    <p>Facebook [SIGMETRICS12] Wikipedia [ISCA13]</p>
    <p>Flickr [ISCA13] Memcachier [NSDI19]</p>
    <p>Heterogeneous item sizes are common</p>
  </div>
  <div class="page">
    <p>Facebook [SIGMETRICS12] Wikipedia [ISCA13]</p>
    <p>Flickr [ISCA13] Memcachier [NSDI19]</p>
    <p>Heavy tail: few large requests but very costly</p>
    <p>Heterogeneous item sizes are common</p>
  </div>
  <div class="page">
    <p>Why high tail latencies?</p>
  </div>
  <div class="page">
    <p>Head-of-line blocking</p>
    <p>Small requests enqueued behind a large</p>
  </div>
  <div class="page">
    <p>Convoy effect</p>
    <p>Burst of large requests may take most (or all) cores</p>
  </div>
  <div class="page">
    <p>SIZE-AWARE SHARDING</p>
  </div>
  <div class="page">
    <p>Size-aware sharding</p>
  </div>
  <div class="page">
    <p>Size-aware sharding in operation</p>
    <p>Small cores</p>
    <p>Large cores</p>
  </div>
  <div class="page">
    <p>Size-aware sharding in operation</p>
    <p>Small cores</p>
    <p>Large cores</p>
  </div>
  <div class="page">
    <p>Size-aware sharding in operation</p>
    <p>Small cores</p>
    <p>Large cores</p>
  </div>
  <div class="page">
    <p>Size-aware sharding in operation</p>
    <p>Small cores</p>
    <p>Large cores</p>
  </div>
  <div class="page">
    <p>Size-aware sharding in operation</p>
    <p>Small cores</p>
    <p>Large cores</p>
  </div>
  <div class="page">
    <p>Size-aware sharding in operation</p>
    <p>Small cores</p>
    <p>Large cores</p>
  </div>
  <div class="page">
    <p>Size-aware sharding in operation</p>
    <p>Small cores</p>
    <p>Large cores</p>
  </div>
  <div class="page">
    <p>Trade-off: large requests take longer</p>
  </div>
  <div class="page">
    <p>Trade-off: large requests take longer</p>
  </div>
  <div class="page">
    <p>Trade-off: large requests take longer</p>
    <p>WITHOUT size-aware sharding</p>
  </div>
  <div class="page">
    <p>MINOS IN-MEMORY KV</p>
  </div>
  <div class="page">
    <p>Implementation</p>
    <p>Single-node, PUT-GET</p>
    <p>Commodity hardware</p>
    <p>No data durability</p>
  </div>
  <div class="page">
    <p>Small vs large threshold</p>
    <p>Core partitioning</p>
    <p>Request dispatch</p>
    <p>Minos design challenges</p>
  </div>
  <div class="page">
    <p>Small vs large threshold</p>
    <p>Core partitioning</p>
    <p>Request dispatch</p>
    <p>Minos design challenges</p>
  </div>
  <div class="page">
    <p>Main insight</p>
    <p>Improve N-th percentile of latencies</p>
    <p>Improve latencies of N% smallest requests</p>
  </div>
  <div class="page">
    <p>Example with 99th percentile</p>
    <p>Obtain at runtime the CDF of the sizes of accessed items</p>
  </div>
  <div class="page">
    <p>Example with 99th percentile</p>
    <p>Obtain at runtime the CDF of the sizes of accessed items</p>
  </div>
  <div class="page">
    <p>Example with 99th percentile</p>
    <p>Obtain at runtime the CDF of the sizes of accessed items</p>
    <p>To large coresTo small cores 32</p>
  </div>
  <div class="page">
    <p>Small vs large threshold</p>
    <p>Core partitioning</p>
    <p>Request dispatch</p>
    <p>Minos design challenges</p>
  </div>
  <div class="page">
    <p>Improve small requests</p>
    <p>Avoid overloading large cores</p>
    <p>Goal</p>
  </div>
  <div class="page">
    <p>Load-proportional core allocation</p>
    <p>K% of the load for small requests</p>
    <p>K% of small cores</p>
  </div>
  <div class="page">
    <p>Measuring the load of a request</p>
    <p>Load of a request = # processed network packets</p>
  </div>
  <div class="page">
    <p>Dynamic core allocation</p>
    <p>LO AD</p>
  </div>
  <div class="page">
    <p>Dynamic core allocation</p>
    <p>Small size threshold</p>
    <p>LO AD</p>
  </div>
  <div class="page">
    <p>Dynamic core allocation</p>
    <p>Small size threshold</p>
    <p>LO AD</p>
  </div>
  <div class="page">
    <p>Small vs large threshold</p>
    <p>Core partitioning</p>
    <p>Request dispatch</p>
    <p>Minos design challenges</p>
  </div>
  <div class="page">
    <p>SMALL</p>
    <p>LARGE</p>
    <p>RX queues</p>
    <p>Request size unknown a priori</p>
    <p>Reduce software dispatch</p>
  </div>
  <div class="page">
    <p>Only small cores read from the NIC</p>
  </div>
  <div class="page">
    <p>Operation of small cores on a request</p>
    <p>Size &lt; threshold?</p>
    <p>Obtain size</p>
    <p>Dispatch to large coreProcess request</p>
  </div>
  <div class="page">
    <p>Operation of small cores on a request</p>
    <p>Size &lt; threshold?</p>
    <p>Obtain size</p>
    <p>Dispatch to large coreProcess request</p>
    <p>GET: do lookup PUT: in header</p>
  </div>
  <div class="page">
    <p>Operation of small cores on a request</p>
    <p>Small size?</p>
    <p>Obtain size</p>
    <p>Dispatch to large coreProcess request</p>
  </div>
  <div class="page">
    <p>Operation of small cores on a request</p>
    <p>Small size?</p>
    <p>Obtain size</p>
    <p>Dispatch to large core</p>
    <p>Process request</p>
  </div>
  <div class="page">
    <p>Operation of small cores on a request</p>
    <p>Small size?</p>
    <p>Obtain size</p>
    <p>To large coreProcess request</p>
  </div>
  <div class="page">
    <p>Operation of small cores on a request</p>
    <p>Small size?</p>
    <p>Obtain size</p>
    <p>To large coreProcess request</p>
    <p>SOFTWARE DISPATCH ONLY FOR FEW LARGE 48</p>
  </div>
  <div class="page">
    <p>EVALUATION</p>
  </div>
  <div class="page">
    <p>Test-bed</p>
    <p>Server: 8 cores, 40Gbps NIC, DPDK stack</p>
    <p>Wkld ~ ETC Facebook [SIGMETRICS12]  &lt; 1 % large requests [1.5, 500] KB</p>
    <p>95:5 GET:PUT ratio</p>
    <p>Skewed accesses (zipf 0.99) 50</p>
  </div>
  <div class="page">
    <p>Competitors</p>
  </div>
  <div class="page">
    <p>Early binding (MICA, NSDI2014)</p>
    <p>Request -&gt; core based on key-hash of target item</p>
    <p>RX Buffer</p>
    <p>GET(k)</p>
    <p>H as</p>
    <p>h( k)</p>
  </div>
  <div class="page">
    <p>Early binding (MICA, NSDI2014)</p>
    <p>Request -&gt; core based on key-hash of target item</p>
    <p>GET(k)</p>
    <p>H as</p>
    <p>h( k)</p>
    <p>RX Buffer</p>
  </div>
  <div class="page">
    <p>Early binding (MICA, NSDI2014)</p>
    <p>Request -&gt; core based on key-hash of target item</p>
    <p>GET(k)</p>
    <p>H as</p>
    <p>h( k)</p>
    <p>RX Buffer</p>
  </div>
  <div class="page">
    <p>Early binding + stealing (ZygOS SOSP17)</p>
    <p>Idle cores steal requests from other queues/buffers</p>
    <p>GET(k)</p>
    <p>H as</p>
    <p>h( k)</p>
    <p>RX Buffer</p>
  </div>
  <div class="page">
    <p>Late binding (RAMCloud TOCS15)</p>
    <p>One core receives all requests dispatches them to idle cores</p>
    <p>GET(k)</p>
    <p>RX Buffer</p>
  </div>
  <div class="page">
    <p>Throughput vs overall 99th latency</p>
    <p>p (</p>
    <p>s e</p>
    <p>c ,</p>
    <p>lo g</p>
    <p>)</p>
    <p>Throughput (Mops/s)</p>
    <p>Lo w</p>
    <p>er is</p>
    <p>b et</p>
    <p>te r</p>
    <p>More to the right is better 57</p>
  </div>
  <div class="page">
    <p>Minos vs early binding</p>
    <p>p (</p>
    <p>s e</p>
    <p>c ,</p>
    <p>lo g</p>
    <p>)</p>
    <p>Throughput (Mops/s)</p>
    <p>Minos Early</p>
  </div>
  <div class="page">
    <p>Lower latency</p>
    <p>p (</p>
    <p>s e</p>
    <p>c ,</p>
    <p>lo g</p>
    <p>)</p>
    <p>Throughput (Mops/s)</p>
    <p>Minos Early</p>
  </div>
  <div class="page">
    <p>Why? No head-of-line blocking</p>
    <p>p (</p>
    <p>s e</p>
    <p>c ,</p>
    <p>lo g</p>
    <p>)</p>
    <p>Throughput (Mops/s)</p>
    <p>Minos Early</p>
  </div>
  <div class="page">
    <p>Same maximum throughput</p>
    <p>s e c , lo</p>
    <p>g )</p>
    <p>Throughput (Mops/s)</p>
    <p>Minos Early</p>
  </div>
  <div class="page">
    <p>Why? Low dispatch overhead</p>
    <p>s e c , lo</p>
    <p>g )</p>
    <p>Throughput (Mops/s)</p>
    <p>Minos Early</p>
  </div>
  <div class="page">
    <p>Minos vs stealing</p>
    <p>p (</p>
    <p>s e</p>
    <p>c ,</p>
    <p>lo g</p>
    <p>)</p>
    <p>Throughput (Mops/s)</p>
    <p>Minos Early Stealing</p>
  </div>
  <div class="page">
    <p>Lower latency</p>
    <p>p (</p>
    <p>s e</p>
    <p>c ,</p>
    <p>lo g</p>
    <p>)</p>
    <p>Throughput (Mops/s)</p>
    <p>Minos Early Stealing</p>
  </div>
  <div class="page">
    <p>Why? Higher load lower stealing</p>
    <p>p (</p>
    <p>s e</p>
    <p>c ,</p>
    <p>lo g</p>
    <p>)</p>
    <p>Throughput (Mops/s)</p>
    <p>Minos Early Stealing</p>
  </div>
  <div class="page">
    <p>Minos vs late binding</p>
    <p>s e c , lo</p>
    <p>g )</p>
    <p>Throughput (Mops/s)</p>
    <p>Minos Early Stealing Late</p>
  </div>
  <div class="page">
    <p>Lower latency</p>
    <p>s e c , lo</p>
    <p>g )</p>
    <p>Throughput (Mops/s)</p>
    <p>Minos Early Stealing Late</p>
  </div>
  <div class="page">
    <p>Why? No convoy effect</p>
    <p>s e c , lo</p>
    <p>g )</p>
    <p>Throughput (Mops/s)</p>
    <p>Minos Early Stealing Late</p>
  </div>
  <div class="page">
    <p>s e c , lo</p>
    <p>g )</p>
    <p>Throughput (Mops/s)</p>
    <p>Minos Early Stealing Late</p>
    <p>Higher throughput</p>
  </div>
  <div class="page">
    <p>s e c , lo</p>
    <p>g )</p>
    <p>Throughput (Mops/s)</p>
    <p>Minos Early Stealing Late</p>
    <p>Why? No dispatch bottleneck</p>
  </div>
  <div class="page">
    <p>Trade-off: 99th latency of large operations</p>
    <p>p (</p>
    <p>s e</p>
    <p>c ,</p>
    <p>lo g</p>
    <p>)</p>
    <p>Throughput (Mops/s)</p>
    <p>Minos Stealing</p>
  </div>
  <div class="page">
    <p>Other results in the paper</p>
    <p>More item size distributions</p>
    <p>Dynamic workload</p>
    <p>Write intensive workload</p>
    <p>Scalability 72</p>
  </div>
  <div class="page">
    <p>Conclusion: size-aware sharding</p>
    <p>Improve tail latency in in-memory key-value stores</p>
    <p>Serve small and large requests on different cores</p>
    <p>Minos in-memory KV: 10x lower 99th percentile latency</p>
  </div>
  <div class="page">
    <p>THANK YOU</p>
    <p>ANY QUESTIONS?</p>
  </div>
</Presentation>
