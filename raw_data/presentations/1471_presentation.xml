<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Yiying Zhang Gokul Soundararajan</p>
    <p>Mark W. Storer</p>
    <p>Lakshmi N. Bairavasundaram</p>
    <p>Sethuraman Subbiah</p>
    <p>Andrea C. Arpaci-Dusseau</p>
    <p>Remzi H. Arpaci-Dusseau</p>
    <p>Warming up Storage-level Caches with Bonfire</p>
  </div>
  <div class="page">
    <p>Does on-demand cache warmup still work ?</p>
  </div>
  <div class="page">
    <p>M e</p>
    <p>m o</p>
    <p>ry (</p>
    <p>C a</p>
    <p>ch e</p>
    <p>) S</p>
    <p>iz e</p>
    <p>( G</p>
    <p>B )</p>
    <p>Year</p>
    <p>&lt; 10 GB</p>
    <p>. . .</p>
    <p>+ idle time</p>
    <p>Random: 6 days</p>
    <p>Sequential: 2.5 hours</p>
  </div>
  <div class="page">
    <p>R e</p>
    <p>a d</p>
    <p>H it</p>
    <p>R a</p>
    <p>te (</p>
    <p>% )</p>
    <p>Time (hour)</p>
    <p>Always-warm</p>
    <p>Cold</p>
    <p>How Long Does On-demand Warmup Take?</p>
    <p>* Simulation results from a project server trace</p>
    <p>Read hit rate difference between warm cache and on-demand</p>
    <p>On-demand</p>
    <p>On-demand warmup takes hours to days</p>
  </div>
  <div class="page">
    <p>Caches are critical  Key component to meet application SLAs</p>
    <p>Reduce storage server I/O load</p>
    <p>Cache warmup happens often  Storage server restart</p>
    <p>Storage server take-over</p>
    <p>Dynamic caching [Narayanan08, Bairavasundaram12]</p>
    <p>To Make Things Worse</p>
  </div>
  <div class="page">
    <p>Bonfire  Monitors and logs I/Os</p>
    <p>Load warmup data in bulk</p>
    <p>Challenges  What to monitor &amp; log? Effective</p>
    <p>How to monitor &amp; log? Efficient</p>
    <p>How to load warmup data? Fast  General solution</p>
    <p>On-demand Warmup Doesnt Work Anymore What Can We Do?</p>
    <p>Bonfire Monitor</p>
    <p>Storage System</p>
    <p>Warmup Information</p>
    <p>Logging Volume</p>
    <p>I/O</p>
  </div>
  <div class="page">
    <p>Trace analysis for storage-level cache warmup  Temporal and spatial patterns of reaccesses</p>
    <p>Cache warmup algorithm design and simulation</p>
    <p>Implementation and evaluation of Bonfire  Up to 100% warmup time improvement over on-demand</p>
    <p>Up to 200% more server I/O load reduction</p>
    <p>Up to 5 times lower read latency  Low overhead</p>
    <p>Summary of Contributions</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>Trace analysis for cache warmup</p>
    <p>Cache warmup algorithm study with simulation</p>
    <p>Bonfire architecture</p>
    <p>Evaluation results</p>
    <p>Conclusion</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>MSR-Cambridge [Narayanan08]  36 one-week block-level traces from MSR-Cambridge data center servers</p>
    <p>Filter out write-intensive, small working set, and low reaccess-rate</p>
    <p>Workload Study  Trace Selection</p>
    <p>Server Function #volumes</p>
    <p>mds Media server 1</p>
    <p>prn Print server 1</p>
    <p>proj Project directories 3</p>
    <p>src1 Source control 1</p>
    <p>usr User home directories 2</p>
    <p>web Web/SQL server 1</p>
    <p>Reaccesses: Read After Reads and Read After Writes</p>
  </div>
  <div class="page">
    <p>Questions for Trace Study</p>
    <p>Time Space</p>
    <p>Relative Q1: Whats the temporal distance? Q3: Whats the spatial distance?</p>
    <p>Any clustering of reaccesses?</p>
    <p>Absolute Q2: When do reaccesses happen</p>
    <p>(in terms of wall clock time)?</p>
    <p>Q4: Where do reaccesses</p>
    <p>happen (in terms of LBA)?</p>
    <p>LB A</p>
  </div>
  <div class="page">
    <p>Q1: What is the Temporal Distance?</p>
    <p>A m</p>
    <p>o u</p>
    <p>n t</p>
    <p>o f</p>
    <p>R e</p>
    <p>a cc</p>
    <p>e ss</p>
    <p>e s</p>
    <p>(% )</p>
    <p>Temporal Distance (Hour)</p>
    <p>Time b/w Reaccesses for All Traces</p>
    <p>Within an hour: Hourly</p>
  </div>
  <div class="page">
    <p>Q1: What is the Temporal Distance?</p>
    <p>A1: Two main reaccess patterns: Hourly &amp; Daily</p>
    <p>mds_1 proj_1 proj_4 usr_1 src1_1 web_2 prn_1 proj_2 usr_2</p>
    <p>A m</p>
    <p>o u</p>
    <p>n t</p>
    <p>o f</p>
    <p>R e</p>
    <p>a cc</p>
    <p>e se</p>
    <p>s (%</p>
    <p>)</p>
    <p>Hourly Daily Other</p>
    <p>Hourly Dominated</p>
    <p>Daily Dominated Other</p>
    <p>In an hour, recent blocks more likely reaccessed</p>
  </div>
  <div class="page">
    <p>Q2: When Do Reaccesses Happen (Wall Clock Time)?</p>
    <p>D a</p>
    <p>il y</p>
    <p>R e</p>
    <p>a cc</p>
    <p>e ss</p>
    <p>e s</p>
    <p>(% )</p>
    <p>Time (day)</p>
    <p>src11 web2</p>
    <p>A2: Daily reaccesses at same time every day</p>
  </div>
  <div class="page">
    <p>Q3: What is the Spatial Distance?</p>
    <p>A3: Spatial distance usually small for hourly</p>
    <p>sometimes small for other reaccesses</p>
    <p>mds1 proj1 proj4 usr1 src11 web2 prn1 proj2 usr2A m</p>
    <p>o u</p>
    <p>n t</p>
    <p>o f</p>
    <p>R e</p>
    <p>a cc</p>
    <p>e ss</p>
    <p>e s</p>
    <p>(% )</p>
    <p>&lt;10MB 10MB-1GB 1-10GB 10-100GB &gt;100GB</p>
    <p>Hourly Dominated Daily Dominated Other</p>
  </div>
  <div class="page">
    <p>Percentage of 1MB regions that have reaccesses</p>
    <p>Q3: Any spatial clustering among reaccesses?</p>
    <p>A3: Daily reaccesses more spatially clustered</p>
    <p>mds_1 proj_1 proj_4 usr_1 src1_1 web_2 prn_1 proj_2 usr_2</p>
    <p>P ce</p>
    <p>n ta</p>
    <p>g e</p>
    <p>o f</p>
    <p>R e</p>
    <p>a cc</p>
    <p>e se</p>
    <p>s in</p>
    <p>M B</p>
    <p>R e</p>
    <p>g io</p>
    <p>n (</p>
    <p>% )</p>
    <p>Hourly</p>
    <p>Daily</p>
    <p>Other</p>
  </div>
  <div class="page">
    <p>A1 Hourly: Use recently accessed blocks</p>
    <p>A1 and A2 Daily: Use same period from previous day</p>
    <p>A3 Small spatial distance: Size of monitoring buffer is small</p>
    <p>Trace Analysis Summary and Implications</p>
    <p>Time Space</p>
    <p>Relative</p>
    <p>A1: Reaccesses have two main</p>
    <p>temporal patterns:</p>
    <p>within 1 hour, around 1 day</p>
    <p>A3: Hourly reaccesses are</p>
    <p>close in spatial distance.</p>
    <p>Daily reaccesses exhibit</p>
    <p>spatial clustering.</p>
    <p>Absolute A2: Daily reaccesses correlate</p>
    <p>with wall clock time</p>
    <p>A4: No hot spot of</p>
    <p>reaccesses in LBA space</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>Trace analysis for cache warmup</p>
    <p>Cache warmup algorithm study with simulation</p>
    <p>Bonfire architecture</p>
    <p>Evaluation results</p>
    <p>Conclusion</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Warmup period: Hit-rate convergence time</p>
    <p>R e</p>
    <p>a d</p>
    <p>H it</p>
    <p>R a</p>
    <p>te (</p>
    <p>% )</p>
    <p>Time</p>
    <p>Always-warm cache</p>
    <p>New cache</p>
    <p>Metrics: Warmup Time</p>
    <p>Converge time strictConverge time loose</p>
  </div>
  <div class="page">
    <p>Storage server I/O load reduction</p>
    <p>/</p>
    <p>/ during convergence time</p>
    <p>Improvement in server I/O load reduction</p>
    <p>/</p>
    <p>Metrics: Server I/O Reduction</p>
  </div>
  <div class="page">
    <p>Last-K: Last K regions accessed in the trace</p>
    <p>First-K: First K regions in the past 24 hours</p>
    <p>Top-K: K most frequent regions</p>
    <p>Random-K: Random K regions</p>
    <p>Cache Warmup Algorithms</p>
    <p>LF</p>
    <p>I/Os</p>
    <p>Time</p>
    <p>RT</p>
    <p>cache starts</p>
    <p>Region: granularity of monitoring and logging e.g., 1MB</p>
  </div>
  <div class="page">
    <p>LRU cache simulator with four warmup algorithms</p>
    <p>Convergence time  Improves 14% to 100%</p>
    <p>Server I/O load reduction  Improves 44% to 228%</p>
    <p>In general, Last-K is the best</p>
    <p>First-K works for special case (known patterns)</p>
    <p>Simulation Results - Overall</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>Trace analysis for cache warmup</p>
    <p>Cache warmup algorithm study with simulation</p>
    <p>Bonfire architecture</p>
    <p>Evaluation results</p>
    <p>Conclusion</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Design principles  Low overhead monitoring and logging (efficient)</p>
    <p>Bulk loading useful warmup data (effective and fast)</p>
    <p>General design applicable to a range of scenarios</p>
    <p>Techniques  Last-K</p>
    <p>Monitors I/O below the server buffer cache</p>
    <p>Performance snapshot</p>
    <p>Bonfire Design</p>
  </div>
  <div class="page">
    <p>Bonfire Architecture: Monitoring</p>
    <p>Performance Snapshot</p>
    <p>Bonfire Monitor</p>
    <p>Storage System</p>
    <p>n</p>
    <p>Metadata</p>
    <p>Buffer Cache</p>
    <p>Logging Volume</p>
    <p>I/O</p>
    <p>I/O Warmup Data</p>
    <p>In-memory Staging Buffer</p>
    <p>Data Volumes</p>
    <p>I/O</p>
    <p>Only store warmup metadata: metadata-only</p>
    <p>Store warmup metadata and data: metadata+data</p>
  </div>
  <div class="page">
    <p>Bonfire Architecture: Bulk Cache Warmup</p>
    <p>Performance Snapshot</p>
    <p>Bonfire Monitor</p>
    <p>Storage System</p>
    <p>n</p>
    <p>Metadata</p>
    <p>Buffer Cache</p>
    <p>Logging Volume</p>
    <p>I/O</p>
    <p>I/O Warmup Data</p>
    <p>Data Volumes</p>
    <p>In-mem n n-1 k..</p>
    <p>Sorted by LBA</p>
    <p>New Cache</p>
    <p>Warmup Data</p>
    <p>New Cache</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>Trace analysis for cache warmup</p>
    <p>Cache warmup algorithm study with simulation</p>
    <p>Bonfire architecture</p>
    <p>Evaluation results</p>
    <p>Conclusion</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Implemented Bonfire as a trace replayer  Always-warm, on-demand, and Bonfire</p>
    <p>Metadata-only and metadata+data</p>
    <p>Replay traces using sync I/Os</p>
    <p>Workloads  Synthetic workloads</p>
    <p>MSR-Cambridge traces</p>
    <p>Metrics  Benefits and overheads</p>
    <p>Evaluation Set Up</p>
    <p>On-demand</p>
    <p>Bonfire Always-warm</p>
  </div>
  <div class="page">
    <p>R e</p>
    <p>a d</p>
    <p>H it</p>
    <p>R a</p>
    <p>te (</p>
    <p>% )</p>
    <p>Num of I/Os (x1000000)</p>
    <p>Always-warm</p>
    <p>Cold</p>
    <p>Bonfire</p>
    <p>Benefit Results - Read Hit Rate of MSR Trace</p>
    <p>On-demand converges</p>
    <p>Bonfire</p>
    <p>converges</p>
    <p>* Results of a project server trace from MSR-Cambridge trace set</p>
    <p>Cache Starts</p>
    <p>Day 5 Day 6</p>
    <p>Higher read hit rate =&gt; less server I/O load</p>
    <p>On-demand</p>
  </div>
  <div class="page">
    <p>R e</p>
    <p>a d</p>
    <p>L a</p>
    <p>te n</p>
    <p>cy (</p>
    <p>m s)</p>
    <p>Num of I/Os (x1000000)</p>
    <p>Always-warm</p>
    <p>Cold</p>
    <p>Bonfire</p>
    <p>Benefit Results - Read Latency of MSR Trace</p>
    <p>Lower read latency =&gt; better application-perceived performance</p>
    <p>* Results of a project server trace from MSR-Cambridge trace set</p>
    <p>Cache Starts</p>
    <p>Day 5 Day 6</p>
    <p>On-demand</p>
  </div>
  <div class="page">
    <p>Overhead Results</p>
    <p>Performance Snapshot</p>
    <p>Bonfire Monitor</p>
    <p>Storage System</p>
    <p>Warmup Metadata</p>
    <p>Buffer Cache</p>
    <p>Logging Volume</p>
    <p>I/O</p>
    <p>I/O Warmup Data</p>
    <p>In-memory Staging Buffer</p>
    <p>Data Volumes</p>
    <p>n</p>
    <p>In-memory Staging Buffer</p>
    <p>Performance Snapshot</p>
  </div>
  <div class="page">
    <p>Overhead Results</p>
    <p>Performance Snapshot</p>
    <p>Bonfire Monitor</p>
    <p>Storage System</p>
    <p>Warmup Metadata</p>
    <p>Buffer Cache</p>
    <p>Logging Volume</p>
    <p>I/O</p>
    <p>I/O Warmup Data</p>
    <p>In-memory Staging Buffer</p>
    <p>Data Volumes</p>
    <p>n</p>
    <p>Warmup Data</p>
    <p>New Cache</p>
    <p>Performance Snapshot</p>
    <p>Proper Bonfire scheme and configuration</p>
    <p>Staging Buffer</p>
  </div>
  <div class="page">
    <p>Faster cache warmup  59% to 100% improvement over on-demand</p>
    <p>Less storage server I/O load  38% to 200% more reduction than on-demand</p>
    <p>Better application-perceived latency  Avg read latency 1/5 to 2/3 of on-demand</p>
    <p>Small controllable overhead</p>
    <p>Summary of Results</p>
  </div>
  <div class="page">
    <p>On-demand warmup doesnt work anymore  Warm up terabytes of caches take days</p>
    <p>Bonfire and beyond  Client-side cache warmup</p>
    <p>Application-aware warmup</p>
    <p>In need for more long big public traces !</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Thank You</p>
    <p>Questions?</p>
    <p>http://wisdom.cs.wisc.edu/home</p>
    <p>http://research.cs.wisc.edu/adsl</p>
  </div>
</Presentation>
