<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018</p>
    <p>Jingjing Xu, Xu Sun, Qi Zeng, Xuancheng Ren, Xiaodong Zhang, Houfeng Wang, Wenjie Li</p>
    <p>MOE Key Lab of Computational Linguistics, School of EECS, Peking University</p>
    <p>Department of Computing, Hong Kong Polytechnic University</p>
    <p>jingjingxu@pku.edu.cn</p>
    <p>Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement Learning Approach</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 2 of 34</p>
    <p>Introduction</p>
    <p>Task</p>
    <p>Challenge</p>
    <p>Background</p>
    <p>State-of-the-Art Approaches</p>
    <p>Approach</p>
    <p>Overview</p>
    <p>Neutralization Module</p>
    <p>Emotionalization Module</p>
    <p>Reinforcement Learning</p>
    <p>Outline</p>
    <p>Experiment</p>
    <p>Dataset</p>
    <p>Details</p>
    <p>Results</p>
    <p>Analysis</p>
    <p>Incremental Analysis</p>
    <p>Error Analysis</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Introduction</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 4 of 34</p>
    <p>Examples:</p>
    <p>Sentiment-to-Sentiment Translation</p>
    <p>Definition</p>
    <p>The goal of sentiment-to-sentiment translation is to change the underlying sentiment of a sentence while keeping its content. The parallel data is usually lacked.</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 5 of 34</p>
    <p>Applications: Dialogue Systems</p>
    <p>Refined Answer: Im sorry to see that the badminton player B defeats A.</p>
    <p>The badminton player B defeats A. Congratulations!</p>
    <p>I am sad about the failure of the badminton player A.</p>
    <p>sentiment-to-sentiment translation</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 6 of 34</p>
    <p>Applications: Personalized News Writing</p>
    <p>News for fans of the visiting team: The players of the home team performed badly, and lost this game.</p>
    <p>The visiting team defeated the home team</p>
    <p>News for fans of the home team: Although the players of the home team have tried their best, they lost this game regretfully.</p>
    <p>Sentiment-to-sentiment translation can save a lot of human labor!</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 7 of 34</p>
    <p>The simple replacement of emotional words causes low-quality sentences.</p>
    <p>Challenge: Can a sentiment dictionary handle this task?</p>
    <p>The food is terrible like rock The food is delicious like rock</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 8 of 34</p>
    <p>For some emotional words, word sense disambiguation is necessary.  For example, good has three antonyms: evil, bad, and ill in WordNet. Choosing which</p>
    <p>word needs to be decided by the semantic meaning of good based on the given content.</p>
    <p>Challenge: Can a sentiment dictionary handle this task?</p>
    <p>evil badill</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 9 of 34</p>
    <p>Some common emotional words do not have antonyms.  For example, we find that WordNet does not annotate the antonym of delicious.</p>
    <p>Challenge: Can a sentiment dictionary handle this task?</p>
  </div>
  <div class="page">
    <p>Background</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 11 of 34</p>
    <p>Background: State-of-the-Art Methods</p>
    <p>Key Idea</p>
    <p>Advantage: The models can automatically generate appropriate emotional antonyms based on the nonemotional context.</p>
    <p>Drawback: Due to the lack of supervised data, most existing models only change the underlying sentiment and fail in keeping the semantic content.</p>
    <p>The food is delicious What a bad movie</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 12 of 34</p>
    <p>Background: State-of-the-Art Methods</p>
    <p>Key Idea</p>
    <p>Advantage: The models can automatically generate appropriate emotional antonyms based on the nonemotional context.</p>
    <p>Drawback: Due to the lack of supervised data, most existing models only change the underlying sentiment and fail in keeping the semantic content.</p>
    <p>The food is delicious What a bad movie</p>
  </div>
  <div class="page">
    <p>Approach</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 14 of 34</p>
    <p>Approach: Overview</p>
    <p>Neutralization module</p>
    <p>Extract non-emotional semantic information</p>
    <p>Emotionalization module</p>
    <p>Add sentiment to the neutralized semantic content</p>
    <p>Cycled reinforcement learning</p>
    <p>Combine and train two modules.</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 15 of 34</p>
    <p>Neutralization Module</p>
    <p>Long-Short Term Memory Network</p>
    <p>Generate the probability of being neutral or being polar</p>
    <p>Pre-train</p>
    <p>The learned attention are the supervisory signal.  The cross entropy loss is computed as</p>
    <p>=</p>
    <p>=1</p>
    <p>(|)</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 16 of 34</p>
    <p>Emotionalization Module</p>
    <p>Bi-decoder based encoder-decoder network</p>
    <p>The encoder compresses the context</p>
    <p>The decoder generates sentences</p>
    <p>Pre-train</p>
    <p>The input is the neutralized input sequence</p>
    <p>The supervisory signal is the original sentence</p>
    <p>The cross entropy loss is computed as</p>
    <p>=</p>
    <p>=1</p>
    <p>(| ,)</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 17 of 34</p>
    <p>semantic content.</p>
    <p>sentiment.</p>
    <p>reconstruct loss.</p>
    <p>learning.</p>
    <p>Cycled Reinforcement Learning</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 18 of 34</p>
    <p>semantic content.</p>
    <p>sentiment.</p>
    <p>reconstruct loss.</p>
    <p>learning.</p>
    <p>Cycled Reinforcement Learning</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 19 of 34</p>
    <p>semantic content.</p>
    <p>original sentence by adding the source sentiment.</p>
    <p>reconstruct loss.</p>
    <p>learning.</p>
    <p>Cycled Reinforcement Learning</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 20 of 34</p>
    <p>semantic content.</p>
    <p>original sentence by adding the source sentiment.</p>
    <p>emotionalization module.</p>
    <p>learning.</p>
    <p>Cycled Reinforcement Learning</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 21 of 34</p>
    <p>Reward</p>
    <p>Add different sentiment to the semantic content</p>
    <p>Positive</p>
    <p>Negative</p>
    <p>Use the quality of the generated text as reward</p>
    <p>The confidence score of a sentiment classifier</p>
    <p>BLEU</p>
  </div>
  <div class="page">
    <p>Experiment</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 23 of 34</p>
    <p>Yelp Review Dataset (Yelp)</p>
    <p>Yelp Dataset Challenge.</p>
    <p>Amazon Food Review Dataset (Amazon)</p>
    <p>Provided by McAuley and Leskovec (2013). It consists of amounts of food</p>
    <p>reviews from Amazon.</p>
    <p>Dataset</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 24 of 34</p>
    <p>Cross-Alignment Auto-Encoder (CAAE)</p>
    <p>Refined alignment of latent.</p>
    <p>Multi-Decoder with Adversarial Learning (MDAL)</p>
    <p>A multi-decoder model with adversarial.</p>
    <p>Baselines</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 25 of 34</p>
    <p>Automatic Evaluation</p>
    <p>Accuracy</p>
    <p>BLEU</p>
    <p>G-score</p>
    <p>Human Evaluation</p>
    <p>The annotators are asked to score the transformed text in terms of sentiment and semantic</p>
    <p>similarity.</p>
    <p>Evaluation Metrics</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 26 of 34</p>
    <p>Automatic Evaluation</p>
    <p>Accuracy</p>
    <p>BLEU</p>
    <p>G-score</p>
    <p>Human Evaluation</p>
    <p>sentiment and semantic similarity.</p>
    <p>Evaluation Metrics</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 27 of 34</p>
    <p>Results</p>
    <p>Yelp ACC BLEU G-score</p>
    <p>CAAE 93.22 1.17 10.44</p>
    <p>MDAL 85.65 1.64 11.85</p>
    <p>Proposed Method 80.00 22.46 42.38</p>
    <p>Amazon ACC BLEU G-score</p>
    <p>CAAE 84.19 0.56 6.87</p>
    <p>MDAL 70.50 0.27 4.36</p>
    <p>Proposed Method 70.37 14.06 31.45</p>
    <p>Automatic evaluations of the proposed method and baselines.</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 28 of 34</p>
    <p>Results</p>
    <p>Yelp Sentiment Semantic G-score</p>
    <p>CAAE 7.67 3.87 5.45</p>
    <p>MDAL 7.12 3.68 5.12</p>
    <p>Proposed Method 6.99 5.08 5.96</p>
    <p>Amazon Sentiment Semantic G-score</p>
    <p>CAAE 8.61 3.15 5.21</p>
    <p>MDAL 7.93 3.22 5.05</p>
    <p>Proposed Method 7.92 4.67 6.08</p>
    <p>Human evaluations of the proposed method and baselines.</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 29 of 34</p>
    <p>Input: I would strongly advise against</p>
    <p>using this company.</p>
    <p>CAAE: I love this place for a great</p>
    <p>experience here.</p>
    <p>MDAL: I have been a great place was</p>
    <p>great.</p>
    <p>Proposed Method: I would love using</p>
    <p>this company.</p>
    <p>and best.</p>
    <p>Generated Examples</p>
    <p>Input: Worst cleaning job ever! CAAE: Great food and great service! MDAL: Great food, food! Proposed Method: Excellent outstanding job ever! Input: Most boring show Ive ever been. CAAE: Great place is the best place in town. MDAL: Great place Ive ever ever had. Proposed Method: Most amazing show Ive ever been.</p>
  </div>
  <div class="page">
    <p>Analysis</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 31 of 34</p>
    <p>Michael is absolutely wonderful.</p>
    <p>I would strongly advise against using this company.</p>
    <p>Horrible experience!</p>
    <p>Worst cleaning job ever!</p>
    <p>Most boring show i ve ever been.</p>
    <p>Hainan chicken was really good.</p>
    <p>I really dont understand all the negative reviews for this dentist.</p>
    <p>Smells so weird in there.</p>
    <p>The service was nearly non-existent and extremely rude.</p>
    <p>Analysis of the neutralization module</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 32 of 34</p>
    <p>Sentiment-conflicted sentences  Outstanding and bad service</p>
    <p>Neutral sentences  Our first time to the bar</p>
    <p>Error Analysis</p>
    <p>The service here is very good Outstanding and bad service</p>
    <p>Its our first time to the bar and it is totally amazing Its our first time to the bar</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 33 of 34</p>
    <p>A. Enable training with unpaired data.</p>
    <p>B. Tackle the bottleneck of keeping semantic.</p>
    <p>C. State-of-the-art results.</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>A Cycled Reinforcement Learning ApproachUnpaired Sentiment-to-Sentiment Translation: 15-07-2018 34 of 34</p>
    <p>Thank You!</p>
    <p>If you have any question, please send an e-mail to jingjingxu@pku.edu.cn</p>
  </div>
</Presentation>
