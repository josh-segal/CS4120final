<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>T H E</p>
    <p>U N I V E R S</p>
    <p>I T Y</p>
    <p>O F</p>
    <p>E D I N B U</p>
    <p>R G H</p>
    <p>Le Zhang &lt;zhang.le@ed.ac.uk&gt;</p>
    <p>Paul Anderson &lt;dcspaul@ed.ac.uk&gt;</p>
    <p>LISA 2010</p>
    <p>Fast and Secure Laptop Backups with Encrypted De-duplication</p>
  </div>
  <div class="page">
    <p>Laptop Backup Options</p>
    <p>External Hard Drive</p>
    <p>No offsite storage ? What if I have a break-in? Or there is a fire?</p>
    <p>I need a very large capacity to handle archival storage as well ...</p>
  </div>
  <div class="page">
    <p>Laptop Backup Options</p>
    <p>Recordable CD/DVD</p>
    <p>I have to make multiple copies if I want offsite storage ...</p>
    <p>DVDs are only small - I can only backups subsets of files ...</p>
  </div>
  <div class="page">
    <p>Laptop Backup Options</p>
    <p>Cloud Storage</p>
    <p>Broadband upload speeds are slow - 30 DAYS to upload 300Gb to cloud storage is typical ...</p>
    <p>Often, there is a transfer cost as well as a storage cost ...</p>
  </div>
  <div class="page">
    <p>Laptop Backup Options</p>
    <p>External Hard Drive</p>
    <p>Recordable CD/DVD</p>
    <p>Cloud Storage</p>
  </div>
  <div class="page">
    <p>What do people do?</p>
    <p>Store no vital data Regular full backups Partial backups Keep copy on University machine Dont do backups Dont use laptop</p>
    <p>When people bother keeping backups, they are mostly ad-hoc and usually only involve handselected subsets</p>
  </div>
  <div class="page">
    <p>What kind of data?</p>
    <p>User files Applications System files</p>
    <p>Perhaps a lot of the system files and application files (at least) are common?</p>
    <p>From our sample of academic Mac laptop users</p>
  </div>
  <div class="page">
    <p>Shared Data</p>
    <p>It seems like there is a good deal of duplication among the system and application files.</p>
    <p>And this increases with the number of machines</p>
    <p>But it is interesting that a good many files are not common! So is it a good idea not to back up these categories?</p>
    <p>Number of machines added</p>
    <p>S to</p>
    <p>ra g</p>
    <p>e (</p>
    <p>T B</p>
    <p>)</p>
    <p>Overall Storage Saving</p>
    <p>Actual Storage (TB) Saved Storage (TB)</p>
    <p>Number of machines added</p>
    <p>S Y</p>
    <p>S S</p>
    <p>to ra</p>
    <p>g e</p>
    <p>( T</p>
    <p>B )</p>
    <p>SYS Storage Saving</p>
    <p>Actual Storage (TB) Saved Storage (TB)</p>
    <p>Number of machines added</p>
    <p>A P</p>
    <p>P S</p>
    <p>to ra</p>
    <p>g e</p>
    <p>( T</p>
    <p>B )</p>
    <p>APP Storage Saving</p>
    <p>Actual Storage (TB) Saved Storage (TB)</p>
    <p>Number of machines added</p>
    <p>U S</p>
    <p>R S</p>
    <p>to ra</p>
    <p>g e</p>
    <p>( T</p>
    <p>B )</p>
    <p>USR Storage Saving</p>
    <p>Actual Storage (TB) Saved Storage (TB)</p>
    <p>Number of machines added</p>
    <p>S to</p>
    <p>ra g e (</p>
    <p>T B</p>
    <p>)</p>
    <p>Overall Storage Saving</p>
    <p>Actual Storage (TB) Saved Storage (TB)</p>
    <p>Number of machines added</p>
    <p>S Y</p>
    <p>S S</p>
    <p>to ra</p>
    <p>g e (</p>
    <p>T B</p>
    <p>)</p>
    <p>SYS Storage Saving</p>
    <p>Actual Storage (TB) Saved Storage (TB)</p>
    <p>Number of machines added</p>
    <p>A P</p>
    <p>P S</p>
    <p>to ra</p>
    <p>g e (</p>
    <p>T B</p>
    <p>)</p>
    <p>APP Storage Saving</p>
    <p>Actual Storage (TB) Saved Storage (TB)</p>
    <p>Number of machines added</p>
    <p>U S</p>
    <p>R S</p>
    <p>to ra</p>
    <p>g e (</p>
    <p>T B</p>
    <p>)</p>
    <p>USR Storage Saving</p>
    <p>Actual Storage (TB) Saved Storage (TB)</p>
  </div>
  <div class="page">
    <p>Shared Data Obviously, there is less sharing among the user data - but the overall saving is still significant</p>
    <p>And we might expect a higher degree of sharing among the user data for different communities for example, common music files would make a big difference ...</p>
    <p>Number of machines added</p>
    <p>S to</p>
    <p>ra g</p>
    <p>e (</p>
    <p>T B</p>
    <p>)</p>
    <p>Overall Storage Saving</p>
    <p>Actual Storage (TB) Saved Storage (TB)</p>
    <p>Number of machines added</p>
    <p>S Y</p>
    <p>S S</p>
    <p>to ra</p>
    <p>g e</p>
    <p>( T</p>
    <p>B )</p>
    <p>SYS Storage Saving</p>
    <p>Actual Storage (TB) Saved Storage (TB)</p>
    <p>Number of machines added</p>
    <p>A P</p>
    <p>P S</p>
    <p>to ra</p>
    <p>g e</p>
    <p>( T</p>
    <p>B )</p>
    <p>APP Storage Saving</p>
    <p>Actual Storage (TB) Saved Storage (TB)</p>
    <p>Number of machines added</p>
    <p>U S</p>
    <p>R S</p>
    <p>to ra</p>
    <p>g e</p>
    <p>( T</p>
    <p>B )</p>
    <p>USR Storage Saving</p>
    <p>Actual Storage (TB) Saved Storage (TB)</p>
    <p>Number of machines added</p>
    <p>S to</p>
    <p>ra g e (</p>
    <p>T B</p>
    <p>)</p>
    <p>Overall Storage Saving</p>
    <p>Actual Storage (TB) Saved Storage (TB)</p>
    <p>Number of machines added</p>
    <p>S Y</p>
    <p>S S</p>
    <p>to ra</p>
    <p>g e (</p>
    <p>T B</p>
    <p>)</p>
    <p>SYS Storage Saving</p>
    <p>Actual Storage (TB) Saved Storage (TB)</p>
    <p>Number of machines added</p>
    <p>A P</p>
    <p>P S</p>
    <p>to ra</p>
    <p>g e (</p>
    <p>T B</p>
    <p>)</p>
    <p>APP Storage Saving</p>
    <p>Actual Storage (TB) Saved Storage (TB)</p>
    <p>Number of machines added</p>
    <p>U S</p>
    <p>R S</p>
    <p>to ra</p>
    <p>g e (</p>
    <p>T B</p>
    <p>)</p>
    <p>USR Storage Saving</p>
    <p>Actual Storage (TB) Saved Storage (TB)</p>
  </div>
  <div class="page">
    <p>Deduplication Deduplication is becoming very popular for saving space when storing multiple copies of the same file</p>
    <p>A hash (digital signature) is generated from the contents of the file</p>
    <p>Two files with the same content will have the same hash</p>
    <p>Two files with different contents have a very high chance of having different hashes</p>
    <p>Use the hash as the name of the stored file</p>
  </div>
  <div class="page">
    <p>Block sizes</p>
    <p>x 10 6</p>
    <p>File size distribution (in log10 domain)</p>
    <p>F re</p>
    <p>q u e n c y</p>
    <p>D u p lic</p>
    <p>a ti o n R</p>
    <p>a te</p>
    <p>%</p>
    <p>a. Data duplication rate vs block size</p>
    <p>A c tu</p>
    <p>a l S</p>
    <p>to ra</p>
    <p>g e (</p>
    <p>T B</p>
    <p>)</p>
    <p>b. Actual storage needed vs block size</p>
    <p>M ill</p>
    <p>io n O</p>
    <p>b je</p>
    <p>c ts</p>
    <p>c. Number of backup objects vs block size</p>
    <p>All Objs Stored Objs</p>
    <p>Deduplicating at the block level is more efficient than the file level.</p>
    <p>What is an appropriate block size?</p>
  </div>
  <div class="page">
    <p>Deduplication problems? Most de-duplication systems work at the storage level</p>
    <p>This has two problems in our application ..</p>
    <p>If the data is encrypted at source (with different keys) then the deduplication is defeated (the cipher text will be different)</p>
    <p>The full data still has to be transmitted to the server - and this time is a more significant problem than the storage!</p>
  </div>
  <div class="page">
    <p>Convergent Encryption Convergent Encryption neatly solves the first problem ...</p>
    <p>Files are encrypted using the hash of the data as the key</p>
    <p>Files containing the same data will encrypt to the same cypher text and hence deduplication continues to work</p>
    <p>File owners will have the key (because they originally had the data) and will be able to decrypt the data - others wont</p>
  </div>
  <div class="page">
    <p>Managing keys Each (unique) file now has a separate key which we need to manage</p>
    <p>Our solution creates a data object for each directory which contains the keys for the children, as well as their metadata</p>
    <p>The directory object is then encoded and stored in the same was as a normal file</p>
    <p>The user only has to record the key for the root object</p>
    <p>Entire duplicate subtrees can be detected</p>
  </div>
  <div class="page">
    <p>Avoiding Transmission To avoid transmitting data which already exists on the server, we need to do the deduplication on the source system</p>
    <p>Many services (eg. Amazon) dont provide the necessary interfaces for the client to communicate directly</p>
    <p>There are several approaches to this, depending on specific application ...  A private server  A local caching server for a remote cloud service</p>
  </div>
  <div class="page">
    <p>A Protoype Local Disk</p>
    <p>FS Events</p>
    <p>Backup Manager</p>
    <p>Data Compression (Optional)</p>
    <p>Symmetric Encryption with key generated from block content</p>
    <p>Upload Queue</p>
    <p>Backup Server</p>
    <p>Upload threads</p>
    <p>Files</p>
    <p>Changed les</p>
    <p>Local Meta DB</p>
    <p>Meta Update</p>
    <p>Backup status update</p>
    <p>List of les to backup</p>
    <p>Encrypted blocks</p>
    <p>A Mac OsX client</p>
    <p>A local (departmental, home) server which performs hash checking, authentication and high-speed caching before forwarding unique blocks to the cloud</p>
  </div>
  <div class="page">
    <p>Where next? Performance depends heavily on the characteristics of the data itself, and the underlying network/storage (eg. latency)  We would like to study this more</p>
    <p>We would like to develop a production quality client, and investigate a possible service in a datacentre  we are looking for possible funding/partners</p>
  </div>
  <div class="page">
    <p>T H E</p>
    <p>U N I V E R S</p>
    <p>I T Y</p>
    <p>O F</p>
    <p>E D I N B U</p>
    <p>R G H</p>
    <p>Le Zhang &lt;zhang.le@ed.ac.uk&gt;</p>
    <p>Paul Anderson &lt;dcspaul@ed.ac.uk&gt;</p>
    <p>LISA 2010</p>
    <p>Fast and Secure Laptop Backups with Encrypted De-duplication</p>
  </div>
</Presentation>
