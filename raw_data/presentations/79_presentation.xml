<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>mir Vigfsson Gregory Chockler Yoav Tock</p>
    <p>Rx for Data Center Communication Scalability</p>
    <p>Hussam Abu-Libdeh Robert Burgess Ken Birman Haoyuan Li</p>
    <p>Mahesh Balakrishnan</p>
    <p>IBM Research, Haifa Labs</p>
    <p>Cornell University Microsoft Research, Silicon Valley</p>
  </div>
  <div class="page">
    <p>Useful</p>
    <p>IPMC is fast, and widely supported</p>
    <p>Multicast and pub/sub often used implicitly</p>
    <p>Lots of redundant traffic in data centers</p>
    <p>[Anand et al. SIGMETRICS 09]</p>
    <p>Rarely used</p>
    <p>IP Multicast has scalability problems!</p>
    <p>IP Multicast in Data Centers</p>
  </div>
  <div class="page">
    <p>IP Multicast in Data Centers</p>
    <p>Switching hierarchies</p>
  </div>
  <div class="page">
    <p>IP Multicast in Data Centers</p>
    <p>Switches have limited state space</p>
    <p>Switch model (10Gbps) Group capacity</p>
    <p>Alcatel-Lucent OmniSwitch OS6850-4 260</p>
    <p>Cisco Catalyst 3750E-48PD-EF 1,000</p>
    <p>D-Link DGS-3650 864</p>
    <p>Dell PowerConnect 6248P 69</p>
    <p>Extreme Summit X450a-48t 792</p>
    <p>Foundry FastIron Edge X 448+2XG 511</p>
    <p>HP ProCurve 3500yl 1,499</p>
  </div>
  <div class="page">
    <p>IP Multicast in Data Centers</p>
  </div>
  <div class="page">
    <p>IP Multicast in Data Centers</p>
    <p>NICs also have limited state space</p>
    <p>E.g. 16 exact addresses 512-bit Bloom filter</p>
  </div>
  <div class="page">
    <p>IP Multicast in Data Centers</p>
  </div>
  <div class="page">
    <p>IP Multicast in Data Centers</p>
    <p>Kernel has to filter out unwanted packets!</p>
  </div>
  <div class="page">
    <p>Packet loss triggers further problems</p>
    <p>Reliability layer may aggravate loss</p>
    <p>Major companies have suffered multicast storms</p>
    <p>IPMC has dangerous</p>
    <p>scalability issues</p>
    <p>IP Multicast in Data Centers</p>
  </div>
  <div class="page">
    <p>Key ideas</p>
    <p>Treat IPMC groups as a scarce resource  Limit the number of physical IPMC groups  Translate logical IPMC groups into either physical</p>
    <p>IPMC groups or multicast by iterated unicast.</p>
    <p>Merge similar groups together</p>
    <p>Dr. Multicast</p>
  </div>
  <div class="page">
    <p>Transparent: Standard IPMC interface to user, standard IGMP interface to network.</p>
    <p>Robust: Distributed, fault-tolerant service.</p>
    <p>Optimizes resource use: Merges similar multicast groups together.</p>
    <p>Scalable in number of groups: Limits number of physical IPMC groups.</p>
    <p>Dr. Multicast</p>
  </div>
  <div class="page">
    <p>Dr. Multicast</p>
    <p>Library maps logical IPMC to physical IPMC or iterated unicast</p>
    <p>Transparent to the application</p>
    <p>IPMC calls intercepted and modified</p>
    <p>Transparent to the network</p>
    <p>Ordinary IPMC/IGMP traffic</p>
  </div>
  <div class="page">
    <p>Transparent: Standard IPMC interface to user, standard IGMP interface to network.</p>
    <p>Robust: Distributed, fault-tolerant service.</p>
    <p>Optimizes resource use: Merges similar multicast groups together.</p>
    <p>Scalable in number of groups: Limits number of physical IPMC groups.</p>
    <p>Dr. Multicast</p>
  </div>
  <div class="page">
    <p>Dr. Multicast</p>
    <p>Per-node agent maintains global group membership and mapping</p>
    <p>Library consults local agent</p>
    <p>Leader agent periodically computes new mapping (see later).</p>
    <p>State reconciled via gossip</p>
  </div>
  <div class="page">
    <p>Library Layer Overhead</p>
    <p>Experiment measuring sends/sec at one sender  Sending to r addresses realizes roughly 1/r ops/sec  Insignificant overhead when mapping logical IPMC group to</p>
    <p>physical IPMC group.</p>
  </div>
  <div class="page">
    <p>Network Overhead and Robustness</p>
    <p>Experiment on 90 Emulab nodes</p>
    <p>Nodes introduced 10 at a time. Total network traffic grows linearly.</p>
    <p>Average traffic received per-node. Robust to major correlated failure</p>
    <p>Half of the nodes die</p>
  </div>
  <div class="page">
    <p>Transparent: Standard IPMC interface to user, standard IGMP interface to network.</p>
    <p>Robust: Distributed, fault-tolerant service.</p>
    <p>Optimizes resource use: Merges similar multicast groups together.</p>
    <p>Scalable in number of groups: Limits number of physical IPMC groups.</p>
    <p>Dr. Multicast</p>
  </div>
  <div class="page">
    <p>Optimization questions</p>
    <p>BLACK</p>
    <p>Multicast</p>
    <p>Users GroupsUsers Groups</p>
  </div>
  <div class="page">
    <p>Optimization Questions</p>
    <p>Assign IPMC and unicast addresses s.t.  Min. receiver filtering  Min. network traffic  Min. # IPMC addresses   yet deliver all messages to interested parties</p>
  </div>
  <div class="page">
    <p>Optimization Questions</p>
    <p>Assign IPMC and unicast addresses s.t.  receiver filtering  network traffic  # IPMC addresses (hard)M</p>
    <p>)1(</p>
    <p>Knob to control relative costs of CPU filtering and of duplicate traffic.</p>
    <p>Both and are part of administrative policy.</p>
    <p>M</p>
  </div>
  <div class="page">
    <p>MCMD Heuristic</p>
    <p>Groups in `userinterest space</p>
    <p>GRAD STUDENTS FREE FOOD</p>
    <p>(1,1,1,1,1,0,1,0,1,0,1,1)(0,1,1,1,1,1,1,0,0,1,1,1)</p>
  </div>
  <div class="page">
    <p>MCMD Heuristic</p>
    <p>Groups in `userinterest space</p>
    <p>Grow M meta-groups around the groups greedily while cost decreases</p>
  </div>
  <div class="page">
    <p>MCMD Heuristic</p>
    <p>Groups in `userinterest space</p>
    <p>Grow M meta-groups around the groups greedily while cost decreases</p>
  </div>
  <div class="page">
    <p>MCMD Heuristic</p>
    <p>Groups in `userinterest space</p>
    <p>Unicast</p>
    <p>Unicast</p>
  </div>
  <div class="page">
    <p>Social:</p>
    <p>Yahoo! Groups</p>
    <p>Amazon Recommendations</p>
    <p>Wikipedia Edits</p>
    <p>LiveJournal Communities</p>
    <p>Mutual Interest Model</p>
    <p>Data sets/models</p>
    <p>Users Groups</p>
  </div>
  <div class="page">
    <p>MCMD Heuristic</p>
    <p>Total cost on samples of 1000 logical groups.</p>
    <p>Costs drop exponentially with more IPMC addresses</p>
  </div>
  <div class="page">
    <p>Social:</p>
    <p>Yahoo! Groups</p>
    <p>Amazon Recommendations</p>
    <p>Wikipedia Edits</p>
    <p>LiveJournal Communities</p>
    <p>Mutual Interest Model</p>
    <p>Systems:</p>
    <p>IBM Websphere</p>
    <p>Data sets/models</p>
    <p>Users Groups</p>
  </div>
  <div class="page">
    <p>MCMD Heuristic</p>
    <p>Total cost on IBM Websphere data set (simulation)</p>
    <p>Negligible costs when using only 4 IPMC addresses</p>
  </div>
  <div class="page">
    <p>Transparent: Standard IPMC interface to user, standard IGMP interface to network.</p>
    <p>Robust: Distributed, fault-tolerant service.</p>
    <p>Optimizes resource use: Merges similar multicast groups together.</p>
    <p>Scalable in number of groups: Limits number of physical IPMC groups.</p>
    <p>Dr. Multicast</p>
  </div>
  <div class="page">
    <p>Group Scalability</p>
    <p>Experiment on Emulab with 1 receiver, 9 senders  MCMD prevents ill-effects when the # of groups scales up</p>
  </div>
  <div class="page">
    <p>IPMC is useful, but has scalability problems</p>
    <p>Dr. Multicast treats IPMC groups as scarce and sensitive resources</p>
    <p>Transparent, backward-compatible</p>
    <p>Scalable in the number of groups</p>
    <p>Robust against failures</p>
    <p>Optimizes resource use by merging similar groups</p>
    <p>Enables safe and scalable use of multicast</p>
    <p>Dr. Multicast</p>
  </div>
  <div class="page"/>
</Presentation>
