<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Impression Store: Compressive Sensing-based Storage for Big Data Analytics</p>
    <p>Jiaxing Zhang, Ying Yan, Liang Jeff Chen, Minjie Wang,</p>
    <p>Thomas Moscibroda &amp; Zheng Zhang</p>
    <p>Microsoft Research</p>
  </div>
  <div class="page">
    <p>The Curse of O(N) in Big Data Era</p>
    <p>In the old days, an ()algorithm was efficient  But what if  is increasing fast?</p>
    <p>Parallelism is only a partial solution</p>
    <p>Its an illusion that we can compute against all the data  What we collect is always a sample</p>
    <p>By the time we finish computing, new data has generated</p>
    <p>()</p>
    <p>: # of machines</p>
    <p>Approximate Results Suffice!</p>
  </div>
  <div class="page">
    <p>Impression Store</p>
    <p>Provides an abstraction of big data vectors  Support retrieval of big data components</p>
    <p>Store impression information rather than raw data</p>
    <p>Improvements the performance  Save storage capacity</p>
    <p>Save IO bandwidth</p>
    <p>High scalability</p>
  </div>
  <div class="page">
    <p>System Design</p>
    <p>Node</p>
    <p>Query Top-K/Outlier-K</p>
    <p>Node 1</p>
    <p>Update Synchronization Eventually consistent</p>
    <p>Node 2 Node 1</p>
    <p>Synchronization</p>
    <p>Compression</p>
    <p>Uncompressing big components only</p>
    <p>Key technique: Compressive Sensing</p>
    <p>( ) ( ) (  )</p>
    <p>(  )</p>
  </div>
  <div class="page">
    <p>M</p>
    <p>Introduction of Compressive Sensing</p>
    <p>Measurement</p>
    <p>=</p>
    <p>Recovery Algorithms: Orthogonal Matching Pursuit (OMP)</p>
    <p>Recovered Data Vector</p>
    <p>compression</p>
    <p>decompression</p>
    <p>Random Projection,  is a random matrix</p>
    <p>1</p>
    <p>Data Vector (Sparse)</p>
    <p>=</p>
    <p>Length N</p>
    <p>Length M y    N</p>
    <p>N</p>
    <p>M</p>
  </div>
  <div class="page">
    <p>Compressive Sensing vs. Compression</p>
    <p>Decomposable Compression:  =1+2 == 1+2 =1+2=1+2</p>
    <p>1 2</p>
    <p>1=1 2=2</p>
    <p>=1+2</p>
    <p>Node 1 Node 2</p>
    <p>Distributed Aggregation</p>
    <p>0</p>
    <p>1=0 2=</p>
    <p>=1+2</p>
    <p>Base data Update</p>
    <p>Continuous Updated Data</p>
    <p>Data: 1+2 Data: 0+</p>
    <p>Recovery Algorithm (OMP)/Our BOMP Big components have more precision</p>
  </div>
  <div class="page">
    <p>Architecture</p>
    <p>Impression Store</p>
    <p>Impression Store API</p>
    <p>Client</p>
    <p>Accumulated Update 1</p>
    <p>Node</p>
    <p>Query Top-K/Outlier-K</p>
    <p>Recovery: fromMeasurement:  =1</p>
    <p>Node 1</p>
    <p>Update Synchronization</p>
    <p>Node 2</p>
    <p>+</p>
    <p>QueryUpdate</p>
    <p>=1 2</p>
    <p>Node 1</p>
    <p>=1 1</p>
    <p>+=3  =2</p>
    <p>Oracle Measurement</p>
    <p>==1</p>
    <p>Issue to any node</p>
  </div>
  <div class="page">
    <p>Client</p>
    <p>Impression Store</p>
    <p>Impression Store API</p>
    <p>Client</p>
    <p>Accumulated Update 1</p>
    <p>Node</p>
    <p>Query Top-K/Outlier-K</p>
    <p>Recovery: fromMeasurement:  =1</p>
    <p>Node 1</p>
    <p>Update Synchronization</p>
    <p>Node 2</p>
    <p>+</p>
    <p>QueryUpdate</p>
    <p>=1 2</p>
    <p>Node 1</p>
    <p>=1 1</p>
    <p>+=3  =2</p>
    <p>Oracle Measurement</p>
    <p>==1</p>
    <p>Issue to any node</p>
    <p>Vector</p>
  </div>
  <div class="page">
    <p>Architecture</p>
    <p>Impression Store</p>
    <p>Impression Store API</p>
    <p>Client</p>
    <p>Accumulated Update 1</p>
    <p>Node</p>
    <p>Query Top-K/Outlier-K</p>
    <p>Recovery: fromMeasurement:  =1</p>
    <p>Node 1</p>
    <p>Update Synchronization</p>
    <p>Node 2</p>
    <p>+ =1 2</p>
    <p>Node 1</p>
    <p>=1 1</p>
    <p>+=3  =2</p>
    <p>Oracle Measurement</p>
    <p>==1</p>
    <p>Issue to any node</p>
    <p>Top(K): returns top-k Outlier(K): returns outlier-k and mode</p>
    <p>Update (,)</p>
  </div>
  <div class="page">
    <p>Query Processing</p>
    <p>Impression Store</p>
    <p>Impression Store API</p>
    <p>Client</p>
    <p>Accumulated Update 1</p>
    <p>Node</p>
    <p>Query Top-K/Outlier-K</p>
    <p>Recovery: fromMeasurement:  =1</p>
    <p>Node 1</p>
    <p>Update Synchronization</p>
    <p>Node 2</p>
    <p>+</p>
    <p>QueryUpdate</p>
    <p>=1 2</p>
    <p>Node 1</p>
    <p>=1 1</p>
    <p>+=3  =2</p>
    <p>Oracle Measurement</p>
    <p>==1</p>
    <p>Issue to any node</p>
    <p>Each node continuously works on three tasks:</p>
    <p>Update Synchronization</p>
    <p>Accumulated Update 1</p>
    <p>Recovery: from Measurement:  =1</p>
    <p>Top/outlier-K Recovery Top/outlier-K Recovery</p>
  </div>
  <div class="page">
    <p>Update Synchronization</p>
    <p>Impression Store</p>
    <p>Impression Store API</p>
    <p>Client</p>
    <p>Accumulated Update 1</p>
    <p>Node</p>
    <p>Query Top-K/Outlier-K</p>
    <p>Recovery: fromMeasurement:  =1</p>
    <p>Node 1</p>
    <p>Update Synchronization</p>
    <p>Node 2</p>
    <p>+</p>
    <p>QueryUpdate</p>
    <p>=1 2</p>
    <p>Node 1</p>
    <p>=1 1</p>
    <p>+=3  =2</p>
    <p>Oracle Measurement</p>
    <p>==1</p>
    <p>Issue to any node</p>
    <p>+ =1 2 =1</p>
    <p>1</p>
    <p>+=3  =2</p>
    <p>Randomly issue to any node</p>
    <p>Goal:  converges to  quickly</p>
  </div>
  <div class="page">
    <p>Update Synchronization</p>
    <p>Node  Node l</p>
    <p>Synchronization policy</p>
    <p>Loop-free topology</p>
    <p>Master-Slave tree structure  Small latency  Load is not balanced</p>
    <p>Line structure  Long latency  Load is balanced</p>
    <p>Topology in between - trade off</p>
    <p>=+</p>
    <p>()</p>
    <p>Send to p: =+ ()=</p>
    <p>Each pair of Send-Receive copies my not be the same all the time! The policy is proved to achieve eventual consistency.</p>
  </div>
  <div class="page">
    <p>Optimizations</p>
    <p>Speed up the recoveryO(2)  GPU: 30~40X speed-up</p>
    <p>For continuous updates  Optimizing the recover algorithm by keeping the positions of the last recovery</p>
    <p>Reduce the complexity to O(3)</p>
  </div>
  <div class="page">
    <p>Error metrics</p>
    <p>Experiment Setup</p>
    <p>Key Value</p>
    <p>Key Value</p>
    <p>Ground truth Approximation Example</p>
    <p>=1 4</p>
    <p>=3.88%</p>
    <p>Workload:  Revenue on Ads entries in Bing Search</p>
    <p>engine Group by 6 attributes (Market, Vertical, QueryClass)</p>
    <p>Totally N=12,891 user-interested entries in the vector</p>
  </div>
  <div class="page">
    <p>Preliminary Results (1)</p>
    <p>Effect of M and N on Recover Quality</p>
  </div>
  <div class="page">
    <p>Preliminary Results (2)</p>
    <p>Bigger value can be recovered much more accurate with smaller M</p>
  </div>
  <div class="page">
    <p>Preliminary Results (3)</p>
    <p>Compare with traditional Top-K only approach (K=M)</p>
    <p>1 2</p>
    <p>Top-K in 1</p>
    <p>Merge</p>
    <p>Data: 1+2</p>
    <p>Top-K in 2</p>
    <p>Approximated 1+2 (top-K)</p>
    <p>Traditional Top-K Approach</p>
    <p>1 2</p>
    <p>1=1 2=2</p>
    <p>=1+2</p>
    <p>Compressive Sensing Approach</p>
    <p>Approximated 1+2 (top-K)</p>
    <p>Recovery Algorithm</p>
  </div>
  <div class="page">
    <p>Ongoing and Future work</p>
    <p>Support more sophisticated queries  Exploring CS and other techniques</p>
    <p>Work together with sampling  Multiple parallel queries to different nodes can improve confidence</p>
  </div>
  <div class="page">
    <p>Thanks!</p>
  </div>
</Presentation>
