<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Matrix Achieving Predictable Virtual Machine Performance in the Clouds</p>
    <p>Ron C. Chiang, Jinho Hwang+, H. Howie Huang, and Timothy Wood</p>
    <p>The George Washington University</p>
    <p>IBM T.J. Watson Research Center+</p>
    <p>ICAC14</p>
    <p>June 18 2014</p>
  </div>
  <div class="page">
    <p>The Intangible VM Performance</p>
    <p>Try it in store Buy online</p>
    <p>Can I buy a VM that performs the same as my local machine?  Not easy. Why?</p>
    <p>Virtualization overhead  Resource contention  Limited control</p>
    <p>The same performance The same look and feel</p>
  </div>
  <div class="page">
    <p>Relative Performance (RP)</p>
    <p>d</p>
    <p>VM</p>
    <p>P</p>
    <p>P RP</p>
    <p>Challenging to know the best tradeoff between cost and performance</p>
    <p>Instances micro small medium large</p>
    <p>Cost (cents/hour) 2 6 12 24</p>
    <p>Pd1 Pd2</p>
    <p>R P</p>
    <p>t1.micro</p>
    <p>m1.small</p>
    <p>m1.medium</p>
    <p>m1.large</p>
    <p>Price chart of Amazon EC2 instances</p>
  </div>
  <div class="page">
    <p>Challenges</p>
    <p>Keep desired performance with the best costefficiency?</p>
    <p>Characterize a new workload?  A set of representative workloads (gene app)</p>
    <p>Soft boundary classification with probability estimates</p>
    <p>Handle various cloud environments?  Construct and verify models on a variety of clouds</p>
  </div>
  <div class="page">
    <p>Use Cases of Matrix</p>
    <p>Automatic VM configuration  Maintain desired performance with the best cost-efficiency</p>
    <p>VM instance recommendation  Recommend VM instance that is best suited for specific</p>
    <p>applications</p>
    <p>Cloud provider recommendation  Choose an appropriate VM from different cloud providers</p>
  </div>
  <div class="page">
    <p>Gene APP VM</p>
    <p>Profiling domain</p>
    <p>Workload signatures</p>
    <p>Configure SVM</p>
    <p>Train models</p>
    <p>Training basic models (offline)</p>
    <p>Clustering model</p>
    <p>Basic RP model</p>
    <p>Monitoring domain</p>
    <p>New workload signatures</p>
    <p>RP modeling</p>
    <p>Workload composition</p>
    <p>Predicting RP and adapting resources (online)</p>
    <p>New APP VM</p>
    <p>RP models</p>
    <p>Adapting resources</p>
    <p>Analyze data</p>
    <p>RP</p>
    <p>New resource configuration</p>
    <p>Matrix Architecture</p>
  </div>
  <div class="page">
    <p>Gene App and Workload Signatures</p>
    <p>As diverse as possible  from CPU intensive to</p>
    <p>data-intensive</p>
    <p>problem sizes also shall vary from small to large</p>
    <p>The signature of a VM  Resource allocation: Number of VCPUs, VMs, Memory, etc.</p>
    <p>Resource demand: Mean and C.O.V. of CPU, Memory, I/O, and Network usage</p>
    <p>Interference: Number of background applications and their signatures</p>
  </div>
  <div class="page">
    <p>Classifiers with Probability Estimates  Why probability estimates?</p>
    <p>Countless workload signature combinations</p>
    <p>No perfect cluster for all applications</p>
    <p>To analyze and represent a new application (the testing set) with genes (the training set)</p>
    <p>For example:</p>
    <p>A</p>
    <p>C</p>
    <p>B</p>
    <p>CBAX 3.02.05.0</p>
    <p>X</p>
  </div>
  <div class="page">
    <p>Generate New Apps Performance Models</p>
    <p>Performance modeling by nu-SVR with RBF (Radial basis function) kernel</p>
    <p>The performance model</p>
    <p>of a gene app Wi</p>
    <p>Workload composition</p>
    <p>vector: (p1, , pn)  E.g., (0.5, 0.2, 0.3)</p>
    <p>ii rRf</p>
    <p>n</p>
    <p>i</p>
    <p>i</p>
    <p>n</p>
    <p>i</p>
    <p>iinew</p>
    <p>p</p>
    <p>RfpRf</p>
    <p>),()(</p>
    <p>The performance model of a new workload Wnew</p>
  </div>
  <div class="page">
    <p>Keep RP=1 With Min Cost</p>
    <p>},,1{ },,,1{</p>
    <p>},10|{</p>
    <p>,1</p>
    <p>,1)()( subject to</p>
    <p>)( minimize</p>
    <p>mjni</p>
    <p>xxr</p>
    <p>p</p>
    <p>RfpRf</p>
    <p>rCRF</p>
    <p>j</p>
    <p>n</p>
    <p>i</p>
    <p>i</p>
    <p>i</p>
    <p>n</p>
    <p>i</p>
    <p>inew</p>
    <p>j</p>
    <p>m</p>
    <p>j</p>
    <p>jc R</p>
    <p>Let Cj be the cost of resource j</p>
    <p>Because of the RBF kernel f is continuous and differentiable Apply Lagrange algorithm to find R</p>
  </div>
  <div class="page">
    <p>Experiment Settings and Applications  Testing Environments</p>
    <p>Each local host has two six-core Intel Xeon CPUs, Linux 2.6, Xen 4.0  For tests on public clouds, we use Amazon EC2 and Rackspace</p>
    <p>Testing Applications  CloudStone, a performance measurement framework for Web 2.0  Wikipedia with Database dumps from Wikimedia foundation and</p>
    <p>real request traces from the Wikibench  Darwin, an open source version of Apples QuickTime video</p>
    <p>streaming server  Cloud9 makes use of cloud resources to provide a high quality on</p>
    <p>demand software testing service  YCSB (Yahoo! Coud Serving Benchmark), a performance</p>
    <p>measurement framework for cloud serving systems  Five workload characteristics YCSB1~YCSB5</p>
  </div>
  <div class="page">
    <p>Workload Composition Example</p>
    <p>The legend shows the training set  The Y-axis shows the testing applications  Darwin, a video streaming server, is not 100% like the video</p>
    <p>server from FileBench because the video server only emulates I/O operations</p>
    <p>The missing CPU activities are represented by other CPUintensive apps.</p>
    <p>Cloudstone</p>
    <p>Wiki</p>
    <p>YCSB1</p>
    <p>YCSB2</p>
    <p>Darwin</p>
    <p>Cloud9</p>
    <p>video server web server file server OLTP mcf hmmer soplex canneal</p>
  </div>
  <div class="page">
    <p>Performance Prediction</p>
    <p>Accuracy = 1 - |predicted value  actual value|/ (actual value)</p>
    <p>X-axis shows VM configurations</p>
    <p>Most of the results are higher than 80%</p>
    <p>The overall average is 90.15%</p>
    <p>t1.micro m1.small</p>
    <p>m1.medium m1.large</p>
    <p>c1.xlarge m2.xlarge</p>
    <p>m3.xlarge m3.xlarge</p>
    <p>-HVM</p>
    <p>m3.2xlarge m3.2xlarge</p>
    <p>-HVM</p>
    <p>RS1 RS2 RS3 RS4 RS5 RS6 RS7</p>
    <p>A cc</p>
    <p>u ra</p>
    <p>cy (%</p>
    <p>)</p>
    <p>Local private servers Amazon EC2 Rackspace cloud servers</p>
  </div>
  <div class="page">
    <p>Keep Desired Performance</p>
    <p>Running YCSB2 for one hour and change workload intensities every ten minutes</p>
    <p>Matrix adapts resource allocation to accommodate the changes</p>
    <p>The average RP over the whole testing time is 1.06</p>
    <p>Time (min)</p>
    <p>VCPU</p>
    <p>Mem (GB)</p>
    <p>RP</p>
  </div>
  <div class="page">
    <p>Choose VMs and Providers</p>
    <p>Applications Workload Intensities</p>
    <p>Light Medium Heavy</p>
    <p>CloudStone RS3 RS3 m1.large</p>
    <p>YCSB1 m1.small m1.medium m1.medium</p>
    <p>YCSB2 RS2 m1.medium m1.medium</p>
    <p>Light CloudStone uses RS3 because it gives higher RP with the same price</p>
    <p>Light YCSB1 chooses m1.small against RS2 because its memory space is larger and YCSB1 is sensitive to the heap size</p>
    <p>Medium YCSB1 and YCSB2 choose m1.medium against RS4 because it costs less although RS4 performs better</p>
    <p>Heavy CloudStone chooses m1.large against RS4 because of the higher performance with the same price</p>
  </div>
  <div class="page">
    <p>Cost Efficiency</p>
    <p>RP-Cost product (RPC)  Defined as |RP-1|X (VM cost)  The dollars waste on extra or insufficient performance  The smaller the better</p>
    <p>Performance Per Cost (PPC)  Defined as RP / (VM cost)  How much RP can you buy per dollar  The bigger the better</p>
    <p>Normalized to Matrixs values</p>
    <p>Matrix 4Xm1.small 4Xm1.medium 4Xm1.large</p>
    <p>RPC 1 24.00 20.41 143.02</p>
    <p>PPC 1 0.84 0.47 0.33</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>DejaVu and JustRunIt  Adapt resources to suit new demands</p>
    <p>Require dedicated sandbox machines to clone and profile VMs</p>
    <p>DeepDive  Utilize mathematical models and clustering methods</p>
    <p>to detect interference</p>
    <p>Require comparing the performance from VM clones in dedicated machines</p>
  </div>
  <div class="page">
    <p>Conclusion and Future Work</p>
    <p>Clustering methods with probability estimates can be used to classify new cloud workloads and recommend instance types</p>
    <p>Better cost-efficiency is achieved with an approximate optimization algorithm</p>
    <p>Future work  Including the price of data usage in the cost model</p>
    <p>Heterogeneous machines and clusters</p>
  </div>
  <div class="page">
    <p>E-mail: cchiang@stthomas.edu</p>
    <p>Web: https://sites.google.com/site/chilungchiang/</p>
  </div>
</Presentation>
