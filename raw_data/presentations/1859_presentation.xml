<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Lab of Real-Time Systems 1</p>
    <p>Suppor=ng Dynamic GPU Compu=ng Result Reuse in the Cloud</p>
    <p>Husheng Zhou, Yangchun Fu and Cong Liu {husheng.zhou, yangchun.fu, cong}@utdallas.edu</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>Graphics Processing Units</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>GPU vs CPU Peak Performance</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>General Purpose Compu=ng on GPU in t he cloud</p>
    <p>Scientific Simulation</p>
    <p>Big Data Cloud Gaming</p>
    <p>Economic Modeling</p>
    <p>Computer Vision</p>
    <p>Supercomputing</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>GPU in the cloud</p>
    <p>Hypervisor</p>
    <p>Display &amp;GPGPU</p>
    <p>GPU</p>
    <p>VM1</p>
    <p>Cloud</p>
    <p>App1</p>
    <p>Graphics driver</p>
    <p>Display &amp;GPGPU</p>
    <p>GPU</p>
    <p>VM2</p>
    <p>App2</p>
    <p>Graphics driver</p>
    <p>Display &amp;GPGPU</p>
    <p>VM3</p>
    <p>App3</p>
    <p>Graphics driver</p>
    <p>q GPU passthrough q One GPU to a VM q No Mul=plexing</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>GPU in the cloud</p>
    <p>Hypervisor</p>
    <p>Display &amp;GPGPU</p>
    <p>GPU</p>
    <p>VM1</p>
    <p>Cloud</p>
    <p>App1</p>
    <p>Graphics driver</p>
    <p>Display &amp;GPGPU</p>
    <p>VM2</p>
    <p>App2</p>
    <p>Graphics driver</p>
    <p>Display &amp;GPGPU</p>
    <p>VM3</p>
    <p>App3</p>
    <p>Graphics driver</p>
    <p>GPUvm</p>
    <p>q GPU virtualiza=on q Allow GPU sharing</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>GPU in the cloud</p>
    <p>Hypervisor</p>
    <p>Display &amp;GPGPU</p>
    <p>GPU</p>
    <p>VM1</p>
    <p>Cloud</p>
    <p>App1</p>
    <p>Graphics driver</p>
    <p>Display &amp;GPGPU</p>
    <p>VM2</p>
    <p>App2</p>
    <p>Graphics driver</p>
    <p>Display &amp;GPGPU</p>
    <p>VM3</p>
    <p>App3</p>
    <p>Graphics driver</p>
    <p>GPUvm</p>
    <p>QuesGons:</p>
    <p>for real world cloud applicaGons.</p>
    <p>q GPU virtualiza=on q Allow GPU sharing</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>GPU Compu=ng</p>
    <p>Host Memory Device Memory</p>
    <p>CMD_HtoD</p>
    <p>Kernel Code</p>
    <p>Input Data</p>
    <p>Result Data</p>
    <p>Kernel Code</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>GPU Compu=ng</p>
    <p>Host Memory Device Memory</p>
    <p>CMD_HtoD</p>
    <p>Input Data</p>
    <p>Result Data</p>
    <p>Kernel Code</p>
    <p>Input Data</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>GPU Compu=ng</p>
    <p>Host Memory Device Memory</p>
    <p>Input Data</p>
    <p>Result Data</p>
    <p>Kernel Code</p>
    <p>CMD_Launch</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>GPU Compu=ng</p>
    <p>Host Memory Device Memory</p>
    <p>Input Data</p>
    <p>Result Data</p>
    <p>Kernel Code</p>
    <p>Result Data</p>
    <p>CMD_DtoH</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>GPU Compu=ng</p>
    <p>Host Memory Device Memory</p>
    <p>Input Data</p>
    <p>Result Data</p>
    <p>Kernel Code</p>
    <p>Result Data</p>
    <p>CMD_DtoH</p>
    <p>The blackbox feature of GPU processing makes GPU a natural choice for implemen=ng the result reuse idea.</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>Case Study</p>
    <p>#Launch Uniq Exe Redundant Identical R1 (10 min) 173,766 24 22.31s 24.71% 47.12% R2 (10 min) 123,175 19 17.10s 25.63% 66.47%</p>
    <p>Two runs, each for 10 minutes  Collect GPU compuGng trace</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>Objec=ve  Goal:</p>
    <p>Transparently allow GPU result memoiza=on and reuse in the cloud</p>
    <p>Approach:  IntercepGng GPU commands at hypervisor level  Cache and reuse previous computed GPU results</p>
    <p>Related Work:  hardware-based task level memoizaGon. (ISCA14, Arnau et. al)  Pa[ern-based approximaGon (ASPLOS14, Samadi et.al)</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>GRU(Gpu Result re-Use) Ecosystem</p>
    <p>Domain U</p>
    <p>Driver</p>
    <p>Aggregator</p>
    <p>Domain 0</p>
    <p>Reuse Engine</p>
    <p>GPU Xen</p>
    <p>Hypervisor</p>
    <p>Emulated</p>
    <p>GPU Model</p>
    <p>QEMU-Xen</p>
    <p>Emulated GPU Model</p>
    <p>Driver</p>
    <p>Domain U</p>
    <p>IPC</p>
    <p>Qemu-Xen : collects the MMIO operations and forwards GPU commands Aggregator : interprets the parameters of GPU requests and manages the GPU memory; Reuse engine : uses LUT to identify cached results and stores computation results in a &quot;shadow result memory&quot;</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>Workflow</p>
    <p>GPU cmd parser &amp; Hash Func=on</p>
    <p>Input requests</p>
    <p>GPU status parser &amp; Result Management</p>
    <p>GPU</p>
    <p>Miss! Issue requests to physical GPU</p>
    <p>Output response</p>
    <p>Hit! Return results &amp; skip computa=on Probe LUT</p>
    <p>Raw GPU status trans Tag LRU Kernel Inputs Results</p>
    <p>Update LUT</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>Overhead  Throughput performance</p>
    <p>Experiment Setup</p>
    <p>Device Intel Core i7  4790K NVIDIA Quadro 6000</p>
    <p>Memory (B/W) 16 GB DDR3 (12.8 GB/s) 6 GB GDDR5 (133.9 GB/s)</p>
    <p>Avg Perf. 177 GFlops 1,345 GFlops PCIe 3.0 x16 15.76 GB/s</p>
    <p>Dom0 Ubuntu 12.04 - 3.6.5 + Gdev DomU Ubuntu 12.04 - 3.6.5 + Gdev + CUDA tool kit 4.2</p>
    <p>Hypervisor Xen-4.2 + xen tool + GRU</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>Benchmarks</p>
    <p>Applica=on Descrip=on</p>
    <p>chess Chinese Chess game with naive AI madd Matrix addi=on mmul Matrix mul=plica=on srad Speckle reducing anisotropic diffusion srad2 Another version of srad with pseudo-inputs backprop Back propaga=on hotspot Physics simula=on lud LU Decomposi=on</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>Overhead</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>Speedup</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>Conclusion and Ongoing work  We present the first system solu=on for the idea of GPU</p>
    <p>result memoiza=on and result reuse in the cloud  Stabilize and generalize GRU</p>
    <p>Support complicated applicaGons with dependent kernels  Support par=al result reuse</p>
    <p>Introducing reuse-measuring metrics  Compiler-assisted approach</p>
    <p>Enlarge reusability  Approximate compuGng</p>
    <p>Scheduling:  Reuse-oriented scheduling</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>Ongoing Evalua=ons  We are evalua=ng some popular GPGPU cloud applica=ons</p>
    <p>Deep-learning for image recogniGon  MoGfs detecGon tool for DNA  GPU accelerated MapReduce and database query</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>Discussion</p>
    <p>Thanks</p>
  </div>
  <div class="page">
    <p>Lab of Real-Time Systems</p>
    <p>Discussion  How to iden=fy par=al reusable result  Reduce overhead for data hashing  Representa=ve cloud applica=ons</p>
  </div>
</Presentation>
