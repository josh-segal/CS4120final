<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Arachne: Core Aware Thread Management</p>
    <p>Henry Qin, Qian Li, Jacqueline Speiser, Peter Kraft, John Ousterhout</p>
  </div>
  <div class="page">
    <p>Latency Conflicts With Throughput</p>
    <p>Task lifetimes getting shorter in the data center  Memcached service time: 10 s  RAMCloud service time: 2 s</p>
    <p>Low Latency  Poor Core Utilization  Low Throughput</p>
  </div>
  <div class="page">
    <p>Today: Applications lack visibility and control over cores</p>
    <p>Arachne: Core Aware Thread Management</p>
    <p>App1</p>
    <p>Kernel</p>
    <p>Core</p>
    <p>Thread-Based API</p>
    <p>Thread</p>
    <p>App2</p>
  </div>
  <div class="page">
    <p>Today: Applications lack visibility and control over cores</p>
    <p>Arachne: Core Aware Thread Management</p>
    <p>App1</p>
    <p>Kernel</p>
    <p>Core</p>
    <p>Kernel Core-Based APIThread-Based API</p>
    <p>Arachne: Core Awareness for Applications</p>
    <p>Thread</p>
    <p>App2 App1 App2</p>
  </div>
  <div class="page">
    <p>Today: Applications lack visibility and control over cores</p>
    <p>Arachne: Core Aware Thread Management</p>
    <p>Better combination of latency and throughput  Memcached: 4  43x reduction in tail latency</p>
    <p>Efficient threads implementation: 100 - 300 ns thread primitives</p>
    <p>App1</p>
    <p>Kernel</p>
    <p>Core</p>
    <p>Kernel Core-Based APIThread-Based API</p>
    <p>Arachne: Core Awareness for Applications</p>
    <p>Thread</p>
    <p>App2 App1 App2</p>
  </div>
  <div class="page">
    <p>Problem: Kernel Threads Inefficient</p>
    <p>One kernel thread per request? Too Slow!</p>
    <p>Kernel Threads</p>
    <p>Incoming Requests</p>
  </div>
  <div class="page">
    <p>The Solution of Todays Applications</p>
    <p>Multiplex requests across long-lived kernel threads.</p>
    <p>Kernel Threads</p>
    <p>Incoming Requests</p>
  </div>
  <div class="page">
    <p>Problem: Matching Parallelism to Resources</p>
    <p>Multiplex requests across long-lived kernel threads.</p>
    <p>Kernel Threads</p>
    <p>Incoming Requests</p>
    <p>How many threads?</p>
  </div>
  <div class="page">
    <p>Problem: Matching Parallelism to Resources</p>
    <p>Kernel Threads</p>
    <p>Too Few Threads</p>
    <p>Cores</p>
    <p>Too Many Threads</p>
    <p>Kernel MultiplexingWasted Core</p>
    <p>Goal: # of threads = # of cores, but dont know # of allocated cores</p>
    <p>Incoming Requests</p>
    <p>How many threads?</p>
    <p>Multiplex requests across long-lived kernel threads.</p>
  </div>
  <div class="page">
    <p>Problem: Must Choose Waste or Interference</p>
    <p>Owning entire machine is wasteful.</p>
    <p>Kernel Threads</p>
    <p>Cores</p>
    <p>Sharing causes competition for cores.</p>
    <p>Incoming Requests</p>
    <p>Multiple Tenants</p>
    <p>Kernel Multiplexing</p>
  </div>
  <div class="page">
    <p>Arachne: Core-Aware Thread Management</p>
    <p>Give applications more knowledge/control over cores  Application requests cores, not threads  Application knows the exact cores it owns  Application has exclusive use of cores  eliminates interference</p>
    <p>Move thread management to userspace  Multiplex threads on allocated cores  Very fast threading primitives (100 - 300 ns)</p>
  </div>
  <div class="page">
    <p>System Overview</p>
    <p>Core Arbiter</p>
    <p>Application</p>
    <p>Arachne Runtime</p>
    <p>Core Policy 1</p>
    <p>Application</p>
    <p>Arachne Runtime</p>
    <p>Core Policy 2</p>
    <p>Allocates cores</p>
  </div>
  <div class="page">
    <p>System Overview</p>
    <p>Core Arbiter</p>
    <p>Application</p>
    <p>Arachne Runtime</p>
    <p>Core Policy 1</p>
    <p>Application</p>
    <p>Arachne Runtime</p>
    <p>Core Policy 2</p>
    <p>Allocates cores</p>
    <p>Thread primitives  Core scaling</p>
  </div>
  <div class="page">
    <p>System Overview</p>
    <p>Core Arbiter</p>
    <p>Application</p>
    <p>Arachne Runtime</p>
    <p>Core Policy 1</p>
    <p>Application</p>
    <p>Arachne Runtime</p>
    <p>Core Policy 2</p>
    <p>Allocates cores</p>
    <p>Thread primitives  Core scaling</p>
    <p>Thread placement  Core estimation</p>
  </div>
  <div class="page">
    <p>Core Allocation</p>
  </div>
  <div class="page">
    <p>One Kernel Thread Per Managed Core</p>
    <p>Arachne App 1 Arachne App 2 Traditional Applications</p>
    <p>Managed Cores Unmanaged Cores</p>
  </div>
  <div class="page">
    <p>Leverage Linux cpusets</p>
    <p>Cpusets</p>
    <p>Managed Cores Unmanaged Cores</p>
    <p>Arachne App 1 Arachne App 2 Traditional Applications</p>
  </div>
  <div class="page">
    <p>Granting a Core</p>
    <p>Arachne App 1 Arachne App 2 Traditional Applications</p>
    <p>Managed Cores Unmanaged Cores</p>
    <p>Cpusets</p>
  </div>
  <div class="page">
    <p>Granting a Core</p>
    <p>Arachne App 1 Arachne App 2 Traditional Applications</p>
    <p>Managed Cores Unmanaged Cores</p>
    <p>Cpusets</p>
  </div>
  <div class="page">
    <p>Life of an Arachne Application</p>
  </div>
  <div class="page">
    <p>Application Startup</p>
    <p>Want 2 Cores</p>
    <p>Core Arbiter</p>
    <p>Application</p>
    <p>Core Policy Arachne Runtime</p>
  </div>
  <div class="page">
    <p>Application Startup</p>
    <p>Core Arbiter</p>
    <p>Application</p>
    <p>Core Policy Arachne Runtime</p>
  </div>
  <div class="page">
    <p>Multiplex User Threads</p>
    <p>Core Arbiter</p>
    <p>Application</p>
    <p>Core Policy Arachne Runtime</p>
  </div>
  <div class="page">
    <p>Core Estimation</p>
    <p>Core Arbiter</p>
    <p>Application</p>
    <p>Core Policy</p>
    <p>Want 3 Cores</p>
    <p>Statistics  Utilization  Runnable Threads</p>
  </div>
  <div class="page">
    <p>Core Grant</p>
    <p>Core Arbiter</p>
    <p>Application</p>
    <p>Core Policy</p>
  </div>
  <div class="page">
    <p>Core Grant</p>
    <p>Core Arbiter</p>
    <p>Application</p>
    <p>Core Policy</p>
  </div>
  <div class="page">
    <p>Core Preemption</p>
    <p>Core Arbiter</p>
    <p>Application</p>
    <p>Core Policy</p>
    <p>Please return this core.</p>
  </div>
  <div class="page">
    <p>User Thread Migration</p>
    <p>Core Arbiter</p>
    <p>Application</p>
    <p>Core Policy</p>
  </div>
  <div class="page">
    <p>Core Preemption Respected</p>
    <p>Core Arbiter</p>
    <p>Application</p>
    <p>Core Policy</p>
    <p>Returning this core.</p>
  </div>
  <div class="page">
    <p>Arachne Runtime: Cache-Optimized</p>
  </div>
  <div class="page">
    <p>Cache-Optimized Design</p>
    <p>Threading performance dominated by cache operations  Basic operations not compute heavy</p>
    <p>Context switch: only 14 instructions  Cost comes from cache coherency operations</p>
    <p>Need to move data between caches  Cache miss: 100-200 cycles</p>
    <p>Arachne runtime designed around cache as bottleneck  Eliminate cache misses where possible  Overlap unavoidable cache misses</p>
  </div>
  <div class="page">
    <p>Cache-Optimized Design</p>
    <p>Concurrent misses  Read load information from multiple cores in parallel</p>
    <p>No run queues; dispatcher scans context Runnable flags</p>
    <p>Dispatcher</p>
    <p>Stack</p>
    <p>Runnable</p>
    <p>Function + Arguments</p>
    <p>Thread Context</p>
    <p>Stack</p>
    <p>Runnable</p>
    <p>Function + Arguments</p>
    <p>Thread Context</p>
    <p>Stack</p>
    <p>Runnable</p>
    <p>Function + Arguments</p>
    <p>Thread Context</p>
    <p>Total time to create a new thread, with load balancing: 4 cache misses</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>Configuration (CloudLab m510)  8-Core (16 HT) Xeon D-1548 @ 2.0 Ghz  64 GB DDR4-2133 @ 2400 Mhz  Dual-port Mellanox ConnectX-3 10 Gb  HPE Moonshot-45XGc</p>
    <p>Experiments  Threading primitives  Latency vs Throughput  Changing Load and Background Applications</p>
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>What is cost of thread operations?</p>
    <p>Operation Arachne Go uThreads std::thread</p>
    <p>Thread Creation 320 ns 444 ns 6132 ns 13329 ns</p>
    <p>Condition Variable Notify 272 ns 483 ns 4976 ns 4962 ns</p>
  </div>
  <div class="page">
    <p>What is cost of thread operations?</p>
    <p>Operation Arachne Go uThreads std::thread</p>
    <p>Thread Creation 320 ns 444 ns 6132 ns 13329 ns</p>
    <p>Condition Variable Notify 272 ns 483 ns 4976 ns 4962 ns</p>
    <p>Child on different core, with load balancing Child on same core</p>
  </div>
  <div class="page">
    <p>Memcached Integration</p>
    <p>Worker ThreadsClients C C C C C C C</p>
    <p>W</p>
    <p>W</p>
    <p>W</p>
    <p>W</p>
    <p>Before: Static Connection Assignment</p>
    <p>Fixed pool of threads</p>
  </div>
  <div class="page">
    <p>Memcached Integration</p>
    <p>Worker ThreadsClients C C C C C C C</p>
    <p>W</p>
    <p>W</p>
    <p>W</p>
    <p>W</p>
    <p>Clients C C C C C C C</p>
    <p>Request Dispatcher</p>
    <p>D</p>
    <p>Worker Cores</p>
    <p>W</p>
    <p>W Thread Creation</p>
    <p>Before: Static Connection Assignment After: One Thread Per Request</p>
    <p>Cores vary with loadFixed pool of threads</p>
  </div>
  <div class="page">
    <p>Memcached: Facebook ETC trace</p>
  </div>
  <div class="page">
    <p>Memcached: Facebook ETC trace</p>
  </div>
  <div class="page">
    <p>Memcached: Facebook ETC trace</p>
  </div>
  <div class="page">
    <p>Memcached: Facebook ETC trace</p>
    <p>Better throughput at low latency</p>
  </div>
  <div class="page">
    <p>Changing Load and Colocation</p>
    <p>Does Arachne scale well with changing load?</p>
    <p>Does Arachne enable high core utilization?  Background app absorb unused resources  Background app doesnt interfere with memcached performance</p>
  </div>
  <div class="page">
    <p>Changing Load</p>
    <p>Modified memtier</p>
    <p>Poisson arrival rate</p>
  </div>
  <div class="page">
    <p>Changing Load</p>
    <p>Cores scale with load</p>
    <p>Nearly constant</p>
    <p>median and tail latency</p>
  </div>
  <div class="page">
    <p>Changing Load</p>
    <p>Tail latency increases</p>
    <p>with load 9x higher than Arachne</p>
    <p>at load</p>
  </div>
  <div class="page">
    <p>Colocated with x264 Video Encoder</p>
    <p>Memcached latency rises</p>
    <p>Arachne latency unchanged.</p>
  </div>
  <div class="page">
    <p>Colocated with x264 Video Encoder</p>
    <p>x264 throughput drops at high memcached load</p>
  </div>
  <div class="page">
    <p>Additional Experiments</p>
    <p>Memcached under a skewed workload  RAMCloud write throughput  RAMCloud under YCSB workload  Thread creation scalability  Comparison with a ready queue  Arachne runtime without dedicated cores  Cost of signaling a blocked thread  Cost of allocating a core</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Arachne: core awareness for applications  Applications request cores, not threads  Application knows the exact cores it owns</p>
    <p>Benefits  Better combination of latency and throughput  Efficient thread implementation</p>
    <p>Kernel Core-Based API</p>
    <p>App1 App2</p>
  </div>
  <div class="page">
    <p>Questions? github.com/PlatformLab/Arachne</p>
    <p>github.com/PlatformLab/memcached-A</p>
    <p>Poster #27</p>
  </div>
</Presentation>
