<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Fast Software Cache Design for Network Appliances</p>
    <p>Dong Zhou, Huacheng Yu, Michael Kaminsky, David G. Andersen</p>
  </div>
  <div class="page">
    <p>Flow Caching in Open vSwitch</p>
    <p>Microflow Cache Exact Match</p>
    <p>Single Hash Table</p>
  </div>
  <div class="page">
    <p>Flow Caching in Open vSwitch</p>
    <p>srcAddr=10.1.2.3, dstAddr=12.4.5.6, srcPort=15213, dstPort=80  output: 1 srcAddr=12.4.5.6, dstAddr=10.1.2.3, srcPort=80, dstPort=15213  output: 2</p>
    <p>srcAddr=12.4.5.6, dstPort=13.1.2.3, srcPort=80, dstPort=15213  drop</p>
    <p>Microflow Cache Exact Match</p>
    <p>Single Hash Table</p>
  </div>
  <div class="page">
    <p>Flow Caching in Open vSwitch</p>
    <p>Megaflow Cache Wildcard Match without Priority</p>
    <p>Multiple Masked Tables</p>
    <p>Miss</p>
    <p>Microflow Cache Exact Match</p>
    <p>Single Hash Table</p>
  </div>
  <div class="page">
    <p>Flow Caching in Open vSwitch</p>
    <p>srcAddr=10.0.0.0/8, dstAddr=12.0.0.0/8, srcPort=*, dstPort=*  output: 1 srcAddr=12.0.0.0/8, dstAddr=10.0.0.0/8, srcPort=*, dstPort=*  output: 2</p>
    <p>srcAddr=*, dstPort=13.0.0.0/8, srcPort=*, dstPort=*  drop</p>
    <p>Megaflow Cache Wildcard Match without Priority</p>
    <p>Multiple Masked Tables</p>
    <p>Miss</p>
    <p>Microflow Cache Exact Match</p>
    <p>Single Hash Table</p>
  </div>
  <div class="page">
    <p>Flow Caching in Open vSwitch</p>
    <p>Packet Classifier Multiple OpenFlow Tables</p>
    <p>Miss</p>
    <p>Megaflow Cache Wildcard Match without Priority</p>
    <p>Multiple Masked Tables</p>
    <p>Miss</p>
    <p>Microflow Cache Exact Match</p>
    <p>Single Hash Table</p>
  </div>
  <div class="page">
    <p>Flow Caching in Open vSwitch</p>
    <p>Packet Classifier Multiple OpenFlow Tables</p>
    <p>Miss</p>
    <p>Match Action</p>
    <p>srcAddr==10.0.0.0/8, dstAddr==12.0.0.0/8</p>
    <p>output:1</p>
    <p>srcAddr==12.0.0.0/8, dstAddr==10.0.0.0/8</p>
    <p>output:2</p>
    <p>Megaflow Cache Wildcard Match without Priority</p>
    <p>Multiple Masked Tables</p>
    <p>Miss</p>
    <p>Microflow Cache Exact Match</p>
    <p>Single Hash Table</p>
  </div>
  <div class="page">
    <p>Flow Caching in Open vSwitch</p>
    <p>Packet Classifier Multiple OpenFlow Tables</p>
    <p>Miss</p>
    <p>Megaflow Cache Wildcard Match without Priority</p>
    <p>Multiple Masked Tables</p>
    <p>Miss</p>
    <p>Microflow Cache Exact Match</p>
    <p>Single Hash Table</p>
    <p>Cache Hit Rate  Lookup Latency</p>
  </div>
  <div class="page">
    <p>Basic Cache Design k</p>
    <p>h(k)</p>
    <p>oversubscription factor  = # keys / # entries</p>
    <p>Assumption  uniform workload  random eviction   = 0.95</p>
    <p>81% cache hit rate4-way set-associative bucket 9</p>
  </div>
  <div class="page">
    <p>Cache Design: Increase Set-Associativity</p>
    <p>k</p>
    <p>h(k)</p>
  </div>
  <div class="page">
    <p>Cache Design: More Candidate Buckets</p>
    <p>k</p>
    <p>h1(k)</p>
    <p>h2(k)</p>
    <p>Cuckoo hashing</p>
  </div>
  <div class="page">
    <p>Our Solution: Bounded Linear Probing (BLP)</p>
    <p>k</p>
    <p>h(k)</p>
    <p>k h(k)</p>
    <p>overlapped bucket</p>
  </div>
  <div class="page">
    <p>Qualitative Comparison</p>
    <p>Design Lookup Speed (cache line reads)</p>
    <p>Hit Rate</p>
  </div>
  <div class="page">
    <p>Qualitative Comparison</p>
    <p>Design Lookup Speed (cache line reads)</p>
    <p>Hit Rate</p>
  </div>
  <div class="page">
    <p>Why BLP is Better Than Set-Assoc.?</p>
    <p>occupancy = 0.71875</p>
    <p>occupancy = 0.75</p>
  </div>
  <div class="page">
    <p>Qualitative Comparison</p>
    <p>Design Lookup Speed (cache line reads)</p>
    <p>Hit Rate</p>
  </div>
  <div class="page">
    <p>Qualitative Comparison</p>
    <p>Design Lookup Speed (cache line reads)</p>
    <p>Hit Rate</p>
  </div>
  <div class="page">
    <p>Better Cache Replacement</p>
    <p>Traditional LRU  High space overhead  CLOCK: 1 bit / key</p>
    <p>Our Solution: Probabilistic Bubble LRU (PBLRU)</p>
  </div>
  <div class="page">
    <p>PBLRU: Bubbling</p>
    <p>D</p>
    <p>h(D)</p>
    <p>A B C D A B D C</p>
    <p>Promotion</p>
  </div>
  <div class="page">
    <p>PBLRU: Bubbling</p>
    <p>X</p>
    <p>h(X)</p>
    <p>A B D C A B D X</p>
    <p>Eviction</p>
  </div>
  <div class="page">
    <p>PBLRU</p>
    <p>Basic bubbling  Combines both recency and frequency information</p>
    <p>Probabilistic bubbling  We only promote every n-th cache hit to reduce the</p>
    <p>number of memory writes</p>
    <p>Applying to 2-4 BLP  We choose a random bucket to apply bubbling</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Traffic Generator Virtual Switch</p>
    <p>Port 0</p>
    <p>TX cores</p>
    <p>RX cores Port 1</p>
    <p>Ethernet</p>
  </div>
  <div class="page">
    <p>Th ro</p>
    <p>ug hp</p>
    <p>ut (M</p>
    <p>pp s)</p>
    <p>Uniform 4-way 4-way w/ SIMD 8-way w/ SIMD 2-4 cuckoo-lite 2-4 BLP w/ PBLRU</p>
    <p>Throughput (Uniform)</p>
  </div>
  <div class="page">
    <p>Lo ok</p>
    <p>up L</p>
    <p>at en</p>
    <p>cy (C</p>
    <p>yc le</p>
    <p>s)</p>
    <p>C ac</p>
    <p>he H</p>
    <p>it R</p>
    <p>at e</p>
    <p>Lookup Latency and Hit Rate</p>
    <p>cache hit rate improvement is not enough to compensate for its higher lookup latency</p>
    <p>better better</p>
  </div>
  <div class="page">
    <p>Th ro</p>
    <p>ug hp</p>
    <p>ut (M</p>
    <p>pp s)</p>
    <p>Throughput (Skewed)</p>
  </div>
  <div class="page">
    <p>Lookup Latency and Hit Rate</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Bounded Linear Probing</p>
    <p>Probabilistic Bubble LRU</p>
    <p>Balance between Cache Hit Rate and Lookup Latency</p>
  </div>
  <div class="page">
    <p>Thank You!</p>
  </div>
</Presentation>
