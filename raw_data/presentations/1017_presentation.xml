<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Log-Structured Non-Volatile Main Memory Qingda Hu*, Jinglei Ren, Anirudh Badam, and Thomas Moscibroda Microsoft Research *Tsinghua University</p>
  </div>
  <div class="page">
    <p>Non-volatile memory is coming</p>
    <p>Data storage</p>
    <p>Read: ~50ns Write: ~10GB/s</p>
    <p>Read: ~10s Write: ~100MB/s</p>
    <p>Read: ~100ns Write: ~1GB/s</p>
    <p>PCM</p>
  </div>
  <div class="page">
    <p>Background: Impact of NVM</p>
    <p>Architecture:</p>
    <p>Data persistence as a bottleneck</p>
    <p>10+x application performance improvement</p>
    <p>DRAM</p>
    <p>SSD</p>
    <p>DRAM NVM</p>
    <p>Non-Volatile Main Memory (NVMM)</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Solution: Log-structured memory management for NVMM.</p>
    <p>Evaluation: 7x less memory waste; 90% higher write throughput.</p>
    <p>Application</p>
    <p>Library</p>
    <p>Executive Summary</p>
    <p>Application</p>
    <p>Library</p>
    <p>DRAM</p>
    <p>SSD</p>
    <p>NVMM</p>
    <p>Inefficient use of memory space</p>
    <p>Inefficient support for crash consistency</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation</p>
    <p>Log-Structured NVMM</p>
    <p>Tree-Based Address Mapping</p>
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>Motivation I</p>
    <p>Inefficient use of memory space  Reason: Traditional DRAM allocators incur high memory fragmentation.</p>
    <p>Explanation:</p>
    <p>Internal fragmentation:</p>
    <p>External fragmentation:</p>
    <p>Waste 32B24B</p>
  </div>
  <div class="page">
    <p>Motivation I</p>
    <p>Inefficient use of memory space (cont.)</p>
    <p>Fragmentation is a more severe issue for NVM!</p>
    <p>process process</p>
    <p>DRAM NVMM</p>
    <p>processprocess processprocess</p>
  </div>
  <div class="page">
    <p>NVMM</p>
    <p>Home</p>
    <p>b</p>
    <p>a</p>
    <p>Motivation II</p>
    <p>Inefficient support for crash consistency  Reason: Write-twice in log and home.</p>
    <p>Explanation: Redo logging for example.</p>
    <p>transaction { a += 1; b -= 1;</p>
    <p>}</p>
    <p>Log</p>
    <p>a b</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation</p>
    <p>Log-Structured NVMM</p>
    <p>Tree-Based Address Mapping</p>
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>Process (user space)</p>
    <p>Log-Structured NVMM</p>
    <p>Library and architecture</p>
    <p>Allocated Available</p>
    <p>Memory management: An append-only log</p>
    <p>Home addr. Log addr.</p>
    <p>&amp;a</p>
    <p>&amp;b</p>
    <p>Address mapping (DRAM)</p>
    <p>a translate(&amp;a)</p>
    <p>Application X NVM device</p>
    <p>mmap()</p>
    <p>Transaction</p>
    <p>a a</p>
  </div>
  <div class="page">
    <p>Log-Structured NVMM</p>
    <p>Low fragmentation  For internal fragmentation: Compact append</p>
    <p>For external fragmentation: Log cleaning</p>
    <p>Allocated Available</p>
    <p>No internal fragmentation</p>
    <p>Allocated Available</p>
    <p>a</p>
    <p>a a</p>
  </div>
  <div class="page">
    <p>Log-Structured NVMM</p>
    <p>Efficient crash-consistent update  No separate areas. Write only once.</p>
    <p>Header: size, checksum, etc.</p>
    <p>Allocated Available</p>
    <p>Home addr. Log addr.</p>
    <p>&amp;a</p>
    <p>&amp;b</p>
    <p>Address mapping</p>
    <p>b</p>
    <p>transaction { a += 1; b -= 1;</p>
    <p>}</p>
    <p>a a b</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation</p>
    <p>Log-Structured NVMM</p>
    <p>Tree-Based Address Mapping</p>
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>Tree-Based Address Mapping</p>
    <p>Unique challenges to NVMM  Pervasive and highly frequent memory accesses.</p>
    <p>Allocation granularity  access granularity  No O(1) lookup.</p>
    <p>Filesystems: hash(block number) as the index.</p>
    <p>Databases: hash(key or tuple ID) as the index.</p>
    <p>Main memory: hash(address)? That maps every address!</p>
    <p>Tree-based mapping made performant.</p>
    <p>...</p>
    <p>? 0xABC8</p>
  </div>
  <div class="page">
    <p>Tree-Based Address Mapping</p>
    <p>Two-layer mapping</p>
    <p>Tree for a small partition (4KB)</p>
    <p>Partition index: (1)</p>
    <p>(log )</p>
    <p>Improves transaction throughput by 39.6% on average.</p>
  </div>
  <div class="page">
    <p>Tree-Based Address Mapping</p>
    <p>Skip list</p>
    <p>A probabilistically balanced tree. No complex balancing operations  No locking for readonly operations.</p>
    <p>Improves transaction throughput by 48.9% with four threads.</p>
  </div>
  <div class="page">
    <p>Tree-Based Address Mapping</p>
    <p>Group update</p>
    <p>Within each transaction, all writes are first buffered in DRAM.</p>
    <p>Writes with contiguous addresses are combined on transaction commit.</p>
    <p>Improves transaction throughput by 42.3% on average.</p>
  </div>
  <div class="page">
    <p>Tree-Based Address Mapping</p>
    <p>Hot tree node cache  A thread-local cache that references recently accessed nodes of the trees.</p>
    <p>A special hash table design: Deliberately high collision.</p>
    <p>Motivation: Addresses within a cached node are not hit due to random distribution of their hash values.</p>
    <p>Solution: Use high-order bits of an address as its hash value.</p>
    <p>Improves transaction throughput by 30.1% on average.</p>
    <p>? 0xABC08</p>
    <p>Collison and found!</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation</p>
    <p>Log-Structured NVMM</p>
    <p>Tree-Based Address Mapping</p>
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Environment:  8-core Intel Xeon CPU E5-2637 v3 (3.5 GHz), 64 GB DRAM</p>
    <p>64-bit Linux kernel version 4.2.3</p>
    <p>NVM emulation: write latency = max{500ns, _</p>
    <p>Part I: How effective are individual optimizations?  Already shown.</p>
    <p>Part II: How does LSNVMM perform against traditional systems?</p>
    <p>Part III: What are the inherent costs of the log-structured approach?</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Fragmentation: Compared to Hoard and jemalloc</p>
    <p>Workloads 1 ~ 3 collected from [S. Rumble, FAST 14].</p>
    <p>Hoard/jemalloc produces 25.3%/35.0% fragmentation on average.</p>
    <p>Log-structured NVM (LSNVMM) produces 4.5% fragmentation on average.</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Transaction throughput compared to Mnemosyne</p>
    <p>With 4 threads, log-structured NVMM performs 44.7% and 80.8% better than Mnemosyne and Mnemosyne-Undo, respectively, on average.</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Cost of log cleaning</p>
    <p>The performance degradation due to log cleaning is 8% at 90% memory utilization.</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Takeaway I: Applying the log-structured approach to NVMM can largely reduce memory fragmentation and improve system performance.</p>
    <p>Takeaway II: A tree-based address mapping mechanism can be made efficient to serve log-structured NVMM.</p>
    <p>Thank you!</p>
    <p>Q &amp; A</p>
  </div>
  <div class="page">
    <p>Backup</p>
    <p>Recovery time (10GB logs)</p>
  </div>
  <div class="page">
    <p>Backup</p>
    <p>DRAM footprint (1GB data)</p>
  </div>
</Presentation>
