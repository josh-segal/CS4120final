<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>DupHunter:</p>
    <p>Flexible High-Performance Deduplication</p>
    <p>for Docker Registries</p>
    <p>Nannan Zhao, Hadeel Albahar, Subil Abraham,</p>
    <p>Keren Chen, Vasily Tarasov, Dimitrios Skourtis,</p>
    <p>Lukas Rupprecht, Ali Anwar, and Ali R. Butt</p>
  </div>
  <div class="page">
    <p>Containers are ubiquitous</p>
    <p>OS Database Web server Cache</p>
    <p>Serverless Deep learning Big data Languages</p>
  </div>
  <div class="page">
    <p>Application containerization is becoming a significant market player</p>
  </div>
  <div class="page"/>
  <div class="page"/>
  <div class="page">
    <p>Docker image dataset is growing fast!</p>
  </div>
  <div class="page">
    <p>How to efficiently manage the ever-growing image dataset for Docker registries?</p>
    <p>Docker image dataset is growing fast!</p>
  </div>
  <div class="page">
    <p>Our contribution: DupHuntera framework to deduplicate images in</p>
    <p>Docker registries  We make two key observations:</p>
    <p>We design DupHunter to work with compressed images and</p>
    <p>provide layer deduplication and reduce layer restore overhead.</p>
    <p>We evaluate DupHunter with representative real world workloads.</p>
    <p>Compared to the state of the art, DupHunter:</p>
    <p>reduces storage space by up to 6.9x.</p>
    <p>reduces the GET layer latency up to 2.8x.</p>
  </div>
  <div class="page">
    <p>Overview of Docker</p>
    <p>Docker container is a self-contained executable</p>
    <p>package, that is:</p>
    <p>Lightweight</p>
    <p>Portable</p>
    <p>Provides Isolation</p>
    <p>Docker registry:</p>
    <p>Stores Docker images</p>
    <p>Supports fast distribution</p>
    <p>Facilitates easy</p>
    <p>deployment</p>
    <p>Docker host</p>
    <p>R/W layer</p>
    <p>PHP MySQL</p>
    <p>Base image: Ubuntu</p>
    <p>Image layers</p>
    <p>(Read only)</p>
    <p>Container layer</p>
    <p>Docker daemon Host OS</p>
    <p>Container Container Container</p>
    <p>Hardware</p>
    <p>Docker client</p>
    <p>docker build docker run</p>
    <p>docker push</p>
    <p>docker push image</p>
    <p>docker pull</p>
    <p>docker pull image</p>
    <p>Docker hub</p>
  </div>
  <div class="page">
    <p>Key observation I: Image dataset has large amount of redundant files</p>
    <p>Container images have a lot of redundancy.  97% of files across layers are duplicates!</p>
    <p>Existing technologies such as Jdupes, VDO, Btrfs, ZFS, and Ceph are unable to harness this redundancy.</p>
    <p>Compressed layer</p>
    <p>dataset</p>
    <p>Does not help!</p>
  </div>
  <div class="page">
    <p>Key observation I: Image dataset has large amount of redundant files</p>
    <p>Container images have a lot of redundancy.  97% of files across layers are duplicates!</p>
    <p>Existing technologies such as Jdupes, VDO, Btrfs, ZFS, and Ceph are unable to harness this redundancy.</p>
    <p>Decompress</p>
    <p>Compressed layer</p>
    <p>dataset</p>
    <p>Does not help!</p>
  </div>
  <div class="page">
    <p>Key observation I: Image dataset has large amount of redundant files</p>
    <p>Container images have a lot of redundancy.  97% of files across layers are duplicates!</p>
    <p>Existing technologies such as Jdupes, VDO, Btrfs, ZFS, and Ceph are unable to harness this redundancy.</p>
    <p>Decompress</p>
    <p>Compressed layer</p>
    <p>dataset Uncompressed</p>
    <p>layer dataset</p>
    <p>Does not help!</p>
  </div>
  <div class="page">
    <p>Key observation I: Image dataset has large amount of redundant files</p>
    <p>Container images have a lot of redundancy.  97% of files across layers are duplicates!</p>
    <p>Existing technologies such as Jdupes, VDO, Btrfs, ZFS, and Ceph are unable to harness this redundancy.</p>
    <p>Decompress</p>
    <p>Compressed layer</p>
    <p>dataset Uncompressed</p>
    <p>layer dataset</p>
    <p>Does not help!</p>
    <p>Unpack</p>
  </div>
  <div class="page">
    <p>Key observation I: Image dataset has large amount of redundant files</p>
    <p>Container images have a lot of redundancy.  97% of files across layers are duplicates!</p>
    <p>Existing technologies such as Jdupes, VDO, Btrfs, ZFS, and Ceph are unable to harness this redundancy.</p>
    <p>Decompress</p>
    <p>Compressed layer</p>
    <p>dataset Uncompressed</p>
    <p>layer dataset</p>
    <p>Does not help!</p>
    <p>Unpack</p>
    <p>Deduplicate</p>
  </div>
  <div class="page">
    <p>Key observation I: Image dataset has large amount of redundant files</p>
    <p>Container images have a lot of redundancy.  97% of files across layers are duplicates!</p>
    <p>Existing technologies such as Jdupes, VDO, Btrfs, ZFS, and Ceph are unable to harness this redundancy.</p>
    <p>Decompress</p>
    <p>Compressed layer</p>
    <p>dataset Uncompressed</p>
    <p>layer dataset</p>
    <p>Does not help!</p>
    <p>Unpack</p>
    <p>Deduplicate</p>
  </div>
  <div class="page">
    <p>Key observation I: Image dataset has large amount of redundant files</p>
    <p>Container images have a lot of redundancy.  97% of files across layers are duplicates!</p>
    <p>Existing technologies such as Jdupes, VDO, Btrfs, ZFS, and Ceph are unable to harness this redundancy.</p>
    <p>Decompress</p>
    <p>Compressed layer</p>
    <p>dataset Uncompressed</p>
    <p>layer dataset</p>
    <p>Does not help!</p>
    <p>Unpack</p>
    <p>Deduplicate</p>
    <p>Reduces space by up</p>
    <p>to 4X</p>
  </div>
  <div class="page">
    <p>Key observation I: Image dataset has large amount of redundant files</p>
    <p>Container images have a lot of redundancy.  97% of files across layers are duplicates!</p>
    <p>Existing technologies such as Jdupes, VDO, Btrfs, ZFS, and Ceph are unable to harness this redundancy.</p>
    <p>Decompress</p>
    <p>Compressed layer</p>
    <p>dataset Uncompressed</p>
    <p>layer dataset</p>
    <p>Does not help!</p>
    <p>Unpack</p>
    <p>Deduplicate</p>
    <p>Reduces space by up</p>
    <p>to 4X</p>
    <p>Layer restore incurs considerable overhead for layer pulling latency up to 98x!</p>
  </div>
  <div class="page">
    <p>Key observation II: Predictable user access pattern</p>
    <p>We observe a consistent user pulling pattern: Pull manifest first, then layers, but not all of the layers will be pulled.</p>
    <p>We performed a quantitive study using a 75-day IBM Cloud Registry workload with 7 availability zones.</p>
    <p>GET Layer count</p>
    <p>L a y</p>
    <p>e rs</p>
    <p>r a ti</p>
    <p>o</p>
    <p>Dal</p>
    <p>Dev</p>
    <p>Fra</p>
    <p>Lon</p>
    <p>Pre</p>
    <p>Sta</p>
    <p>Syd</p>
  </div>
  <div class="page">
    <p>Key observation II: Predictable user access pattern</p>
    <p>We observe a consistent user pulling pattern: Pull manifest first, then layers, but not all of the layers will be pulled.</p>
    <p>We performed a quantitive study using a 75-day IBM Cloud Registry workload with 7 availability zones.</p>
    <p>GET Layer count</p>
    <p>L a y</p>
    <p>e rs</p>
    <p>r a ti</p>
    <p>o</p>
    <p>Dal</p>
    <p>Dev</p>
    <p>Fra</p>
    <p>Lon</p>
    <p>Pre</p>
    <p>Sta</p>
    <p>Syd</p>
  </div>
  <div class="page">
    <p>Key observation II: Predictable user access pattern</p>
    <p>We observe a consistent user pulling pattern: Pull manifest first, then layers, but not all of the layers will be pulled.</p>
    <p>We performed a quantitive study using a 75-day IBM Cloud Registry workload with 7 availability zones.</p>
    <p>GET Layer count</p>
    <p>L a y</p>
    <p>e rs</p>
    <p>r a ti</p>
    <p>o</p>
    <p>Dal</p>
    <p>Dev</p>
    <p>Fra</p>
    <p>Lon</p>
    <p>Pre</p>
    <p>Sta</p>
    <p>Syd</p>
    <p>Majority of layers are only fetched once by the same client.</p>
  </div>
  <div class="page">
    <p>Repulling probability</p>
    <p>li e n ts</p>
    <p>r a ti</p>
    <p>o</p>
    <p>Dal</p>
    <p>Dev</p>
    <p>Fra</p>
    <p>Pre</p>
    <p>Sta</p>
    <p>Syd</p>
    <p>Lon</p>
    <p>Key observation II-b: User repulling pattern can also be predicted</p>
  </div>
  <div class="page">
    <p>Repulling probability</p>
    <p>li e n ts</p>
    <p>r a ti</p>
    <p>o</p>
    <p>Dal</p>
    <p>Dev</p>
    <p>Fra</p>
    <p>Pre</p>
    <p>Sta</p>
    <p>Syd</p>
    <p>Lon</p>
    <p>Half of the clients have a repull probability less than 0.2  many clients pull a layer only once.</p>
    <p>Key observation II-b: User repulling pattern can also be predicted</p>
  </div>
  <div class="page">
    <p>Repulling probability</p>
    <p>li e n ts</p>
    <p>r a ti</p>
    <p>o</p>
    <p>Dal</p>
    <p>Dev</p>
    <p>Fra</p>
    <p>Pre</p>
    <p>Sta</p>
    <p>Syd</p>
    <p>Lon</p>
    <p>Key observation II-b: User repulling pattern can also be predicted</p>
  </div>
  <div class="page">
    <p>Repulling probability</p>
    <p>li e n ts</p>
    <p>r a ti</p>
    <p>o</p>
    <p>Dal</p>
    <p>Dev</p>
    <p>Fra</p>
    <p>Pre</p>
    <p>Sta</p>
    <p>Syd</p>
    <p>Lon</p>
    <p>Key observation II-b: User repulling pattern can also be predicted</p>
  </div>
  <div class="page">
    <p>Repulling probability</p>
    <p>li e n ts</p>
    <p>r a ti</p>
    <p>o</p>
    <p>Dal</p>
    <p>Dev</p>
    <p>Fra</p>
    <p>Pre</p>
    <p>Sta</p>
    <p>Syd</p>
    <p>Lon</p>
    <p>Key observation II-b: User repulling pattern can also be predicted</p>
    <p>User repulling pattern is either pull-once or always-pull  we can predict which layers to pull.</p>
  </div>
  <div class="page">
    <p>Key observation II-c: Layer preconstruction is possible</p>
  </div>
  <div class="page">
    <p>Layer preconstruction can significantly reduce layer restore overhead.</p>
    <p>Key observation II-c: Layer preconstruction is possible</p>
  </div>
  <div class="page">
    <p>DupHunter architecture</p>
    <p>Clients</p>
    <p>Server C</p>
    <p>Server A</p>
    <p>Server D</p>
    <p>storage cluster</p>
    <p>Server B</p>
    <p>Distributed metadata</p>
    <p>database</p>
    <p>Local storage system</p>
    <p>Registry REST API</p>
    <p>Registry REST API</p>
  </div>
  <div class="page">
    <p>Reducing overhead in DupHunter</p>
  </div>
  <div class="page">
    <p>DupHunter supports multiple replica deduplication modes</p>
    <p>B-mode n: Basic deduplication mode n  Keep n layer replicas intact.</p>
    <p>Deduplicate the remaining R-n layer replicas (R = layer replication level).</p>
    <p>S-mode: Selective deduplication mode  The number of intact layer replicas proportional to the layers popularity.</p>
    <p>Hot layers have more intact replicas.</p>
  </div>
  <div class="page">
    <p>DupHunter supports multiple replica deduplication modes</p>
    <p>B-mode n: Basic deduplication mode n  Keep n layer replicas intact.</p>
    <p>Deduplicate the remaining R-n layer replicas (R = layer replication level).</p>
    <p>S-mode: Selective deduplication mode  The number of intact layer replicas proportional to the layers popularity.</p>
    <p>Hot layers have more intact replicas.</p>
    <p>File store</p>
    <p>Layer store</p>
    <p>Layer stage area</p>
    <p>Tier 1 Primary cluster</p>
    <p>Tier 2 Deduplication cluster</p>
    <p>Storage cluster Local storage system</p>
    <p>Registry REST API</p>
    <p>Registry REST API</p>
    <p>Clients</p>
    <p>D-server C</p>
    <p>P-server A</p>
    <p>D-server D</p>
    <p>P-server B</p>
    <p>Distributed metadata</p>
    <p>database</p>
  </div>
  <div class="page">
    <p>DupHunter facilitates parallel layer reconstruction</p>
    <p>Slice: Set of all the files on a server belonging to a layer.  Distributed evenly across the cluster.</p>
    <p>Speed up layer reconstruction via parallel processing of slices.</p>
    <p>Distributed</p>
    <p>metadata</p>
    <p>database</p>
    <p>Clients</p>
    <p>D-server C</p>
    <p>P-server A</p>
    <p>D-server D</p>
    <p>storage cluster</p>
    <p>P-server B</p>
    <p>Tier 1 Primary cluster</p>
    <p>Tier 2 Deduplication cluster</p>
    <p>Local storage system</p>
    <p>File store</p>
    <p>Layer stage area</p>
    <p>Registry REST API</p>
    <p>Layer recipe Id: L</p>
    <p>Slice recipe</p>
    <p>Id: L1::A::P</p>
  </div>
  <div class="page">
    <p>DupHunter enables prefetching/preconstruction of layers</p>
    <p>Prefetch cache to prefetch layers and hide disk I/Os.</p>
    <p>Preconstruct cache to store preconstruct layers and hide layer restore overhead.</p>
    <p>ILmap</p>
    <p>ULmap</p>
    <p>Id: U</p>
    <p>Clients</p>
    <p>D-server C</p>
    <p>P-server A</p>
    <p>D-server D</p>
    <p>Storage cluster</p>
    <p>P-server B</p>
    <p>Tier 1 Primary cluster</p>
    <p>Tier 2 Deduplication cluster</p>
    <p>Distributed</p>
    <p>metadata</p>
    <p>database</p>
    <p>Local storage system</p>
    <p>File store</p>
    <p>Layer store</p>
    <p>Layer stage area</p>
    <p>Registry REST API</p>
    <p>Registry REST API</p>
    <p>ILmap</p>
    <p>ULmap</p>
    <p>Id: U</p>
    <p>Prefetch cache</p>
    <p>Preconstruct cache</p>
  </div>
  <div class="page">
    <p>Deduplicating layers</p>
    <p>Content</p>
    <p>fingerprint Header</p>
    <p>f1</p>
    <p>f2</p>
    <p>f3</p>
    <p>f4</p>
    <p>f5</p>
    <p>f6</p>
    <p>Layer</p>
    <p>tar</p>
    <p>archive L1</p>
    <p>File entries</p>
    <p>h1</p>
    <p>h2</p>
    <p>h3</p>
    <p>h4</p>
    <p>h5</p>
    <p>h6</p>
  </div>
  <div class="page">
    <p>Deduplicating layers</p>
    <p>Content</p>
    <p>fingerprint Header</p>
    <p>f1</p>
    <p>f2</p>
    <p>f3</p>
    <p>f4</p>
    <p>f5</p>
    <p>f6</p>
    <p>Layer</p>
    <p>tar</p>
    <p>archive L1</p>
    <p>File entries</p>
    <p>h1</p>
    <p>h2</p>
    <p>h3</p>
    <p>h4</p>
    <p>h5</p>
    <p>h6</p>
    <p>File index</p>
    <p>Id</p>
    <p>f1</p>
    <p>f2</p>
    <p>r2r1</p>
    <p>A:/../..</p>
    <p>B:/../..</p>
    <p>B:/../..</p>
    <p>C:/../..</p>
  </div>
  <div class="page">
    <p>Deduplicating layers</p>
    <p>Duplicate /</p>
    <p>Shared files</p>
    <p>Unique</p>
    <p>files</p>
    <p>Content</p>
    <p>fingerprint Header</p>
    <p>f1</p>
    <p>f2</p>
    <p>f3</p>
    <p>f4</p>
    <p>f5</p>
    <p>f6</p>
    <p>Layer</p>
    <p>tar</p>
    <p>archive L1</p>
    <p>File entries</p>
    <p>h1</p>
    <p>h2</p>
    <p>h3</p>
    <p>h4</p>
    <p>h5</p>
    <p>h6</p>
    <p>File index</p>
    <p>Id</p>
    <p>f1</p>
    <p>f2</p>
    <p>r2r1</p>
    <p>A:/../..</p>
    <p>B:/../..</p>
    <p>B:/../..</p>
    <p>C:/../..</p>
  </div>
  <div class="page">
    <p>Deduplicating layers</p>
    <p>Duplicate /</p>
    <p>Shared files</p>
    <p>Unique</p>
    <p>files</p>
    <p>Stored</p>
    <p>file</p>
    <p>replicas</p>
    <p>D-server BD-server A</p>
    <p>f3 f2f1</p>
    <p>f1 f2 f3</p>
    <p>D-server C</p>
    <p>Content</p>
    <p>fingerprint Header</p>
    <p>f1</p>
    <p>f2</p>
    <p>f3</p>
    <p>f4</p>
    <p>f5</p>
    <p>f6</p>
    <p>Layer</p>
    <p>tar</p>
    <p>archive L1</p>
    <p>File entries</p>
    <p>h1</p>
    <p>h2</p>
    <p>h3</p>
    <p>h4</p>
    <p>h5</p>
    <p>h6</p>
    <p>File index</p>
    <p>Id</p>
    <p>f1</p>
    <p>f2</p>
    <p>r2r1</p>
    <p>A:/../..</p>
    <p>B:/../..</p>
    <p>B:/../..</p>
    <p>C:/../..</p>
  </div>
  <div class="page">
    <p>Deduplicating layers</p>
    <p>f4</p>
    <p>f5 f6</p>
    <p>f6 f5</p>
    <p>Newly</p>
    <p>added file</p>
    <p>replicas</p>
    <p>f4</p>
    <p>Duplicate /</p>
    <p>Shared files</p>
    <p>Unique</p>
    <p>files</p>
    <p>Stored</p>
    <p>file</p>
    <p>replicas</p>
    <p>D-server BD-server A</p>
    <p>f3 f2f1</p>
    <p>f1 f2 f3</p>
    <p>D-server C</p>
    <p>Content</p>
    <p>fingerprint Header</p>
    <p>f1</p>
    <p>f2</p>
    <p>f3</p>
    <p>f4</p>
    <p>f5</p>
    <p>f6</p>
    <p>Layer</p>
    <p>tar</p>
    <p>archive L1</p>
    <p>File entries</p>
    <p>h1</p>
    <p>h2</p>
    <p>h3</p>
    <p>h4</p>
    <p>h5</p>
    <p>h6</p>
    <p>File index</p>
    <p>Id</p>
    <p>f1</p>
    <p>f2</p>
    <p>r2r1</p>
    <p>A:/../..</p>
    <p>B:/../..</p>
    <p>B:/../..</p>
    <p>C:/../..</p>
  </div>
  <div class="page">
    <p>Deduplicating layers</p>
    <p>f4</p>
    <p>f5 f6</p>
    <p>f6 f5</p>
    <p>Newly</p>
    <p>added file</p>
    <p>replicas</p>
    <p>f4</p>
    <p>Duplicate /</p>
    <p>Shared files</p>
    <p>Unique</p>
    <p>files</p>
    <p>Stored</p>
    <p>file</p>
    <p>replicas</p>
    <p>D-server BD-server A</p>
    <p>f3 f2f1</p>
    <p>f1 f2 f3</p>
    <p>D-server C</p>
    <p>Content</p>
    <p>fingerprint Header</p>
    <p>f1</p>
    <p>f2</p>
    <p>f3</p>
    <p>f4</p>
    <p>f5</p>
    <p>f6</p>
    <p>Layer</p>
    <p>tar</p>
    <p>archive L1</p>
    <p>File entries</p>
    <p>h1</p>
    <p>h2</p>
    <p>h3</p>
    <p>h4</p>
    <p>h5</p>
    <p>h6</p>
    <p>File index</p>
    <p>Id</p>
    <p>f1</p>
    <p>f2</p>
    <p>r2r1</p>
    <p>A:/../..</p>
    <p>B:/../..</p>
    <p>B:/../..</p>
    <p>C:/../..</p>
  </div>
  <div class="page">
    <p>Deduplicating layers</p>
    <p>f4</p>
    <p>f5 f6</p>
    <p>f6 f5</p>
    <p>Newly</p>
    <p>added file</p>
    <p>replicas</p>
    <p>f4</p>
    <p>Duplicate /</p>
    <p>Shared files</p>
    <p>Unique</p>
    <p>files</p>
    <p>Slice recipe Id: L1::A::P</p>
    <p>Header</p>
    <p>h2</p>
    <p>h5</p>
    <p>f2</p>
    <p>f5</p>
    <p>Content</p>
    <p>pointer</p>
    <p>Stored</p>
    <p>file</p>
    <p>replicas</p>
    <p>D-server BD-server A</p>
    <p>f3 f2f1</p>
    <p>f1 f2 f3</p>
    <p>D-server C</p>
    <p>Content</p>
    <p>fingerprint Header</p>
    <p>f1</p>
    <p>f2</p>
    <p>f3</p>
    <p>f4</p>
    <p>f5</p>
    <p>f6</p>
    <p>Layer</p>
    <p>tar</p>
    <p>archive L1</p>
    <p>File entries</p>
    <p>h1</p>
    <p>h2</p>
    <p>h3</p>
    <p>h4</p>
    <p>h5</p>
    <p>h6</p>
    <p>File index</p>
    <p>Id</p>
    <p>f1</p>
    <p>f2</p>
    <p>r2r1</p>
    <p>A:/../..</p>
    <p>B:/../..</p>
    <p>B:/../..</p>
    <p>C:/../..</p>
  </div>
  <div class="page">
    <p>Deduplicating layers</p>
    <p>Layer recipe Id: L1</p>
    <p>Master: A</p>
    <p>Workers: [A, B,</p>
    <p>C]</p>
    <p>f4</p>
    <p>f5 f6</p>
    <p>f6 f5</p>
    <p>Newly</p>
    <p>added file</p>
    <p>replicas</p>
    <p>f4</p>
    <p>Duplicate /</p>
    <p>Shared files</p>
    <p>Unique</p>
    <p>files</p>
    <p>Slice recipe Id: L1::A::P</p>
    <p>Header</p>
    <p>h2</p>
    <p>h5</p>
    <p>f2</p>
    <p>f5</p>
    <p>Content</p>
    <p>pointer</p>
    <p>Stored</p>
    <p>file</p>
    <p>replicas</p>
    <p>D-server BD-server A</p>
    <p>f3 f2f1</p>
    <p>f1 f2 f3</p>
    <p>D-server C</p>
    <p>Content</p>
    <p>fingerprint Header</p>
    <p>f1</p>
    <p>f2</p>
    <p>f3</p>
    <p>f4</p>
    <p>f5</p>
    <p>f6</p>
    <p>Layer</p>
    <p>tar</p>
    <p>archive L1</p>
    <p>File entries</p>
    <p>h1</p>
    <p>h2</p>
    <p>h3</p>
    <p>h4</p>
    <p>h5</p>
    <p>h6</p>
    <p>File index</p>
    <p>Id</p>
    <p>f1</p>
    <p>f2</p>
    <p>r2r1</p>
    <p>A:/../..</p>
    <p>B:/../..</p>
    <p>B:/../..</p>
    <p>C:/../..</p>
  </div>
  <div class="page">
    <p>Restoring layers</p>
    <p>concatenate</p>
    <p>Slice</p>
    <p>stream</p>
    <p>Layer A</p>
    <p>Layer constructor</p>
    <p>File I/O stream Tar stream</p>
    <p>archive compressA</p>
    <p>Slice constructor</p>
    <p>archive compressB</p>
    <p>archive compressC</p>
  </div>
  <div class="page">
    <p>Caching and preconstructing layers</p>
    <p>ILmap: Maps image to its containing layer set.</p>
    <p>ULmap: Maps user to the layers that the user has accessed and the corresponding pull count.</p>
  </div>
  <div class="page">
    <p>Caching and preconstructing layers</p>
    <p>ILmap: Maps image to its containing layer set.</p>
    <p>ULmap: Maps user to the layers that the user has accessed and the corresponding pull count.</p>
    <p>image</p>
  </div>
  <div class="page">
    <p>Caching and preconstructing layers</p>
    <p>ILmap: Maps image to its containing layer set.</p>
    <p>ULmap: Maps user to the layers that the user has accessed and the corresponding pull count.</p>
    <p>image</p>
    <p>Will pull</p>
  </div>
  <div class="page">
    <p>Caching and preconstructing layers</p>
    <p>ILmap: Maps image to its containing layer set.</p>
    <p>ULmap: Maps user to the layers that the user has accessed and the corresponding pull count.</p>
    <p>image</p>
    <p>Will pull</p>
    <p>user</p>
  </div>
  <div class="page">
    <p>Caching and preconstructing layers</p>
    <p>ILmap: Maps image to its containing layer set.</p>
    <p>ULmap: Maps user to the layers that the user has accessed and the corresponding pull count.</p>
    <p>image</p>
    <p>Will pull</p>
    <p>user</p>
  </div>
  <div class="page">
    <p>Caching and preconstructing layers</p>
    <p>ILmap: Maps image to its containing layer set.</p>
    <p>ULmap: Maps user to the layers that the user has accessed and the corresponding pull count.</p>
    <p>image</p>
    <p>Will pull</p>
    <p>user</p>
  </div>
  <div class="page">
    <p>Caching and preconstructing layers</p>
    <p>ILmap: Maps image to its containing layer set.</p>
    <p>ULmap: Maps user to the layers that the user has accessed and the corresponding pull count.</p>
    <p>image image</p>
    <p>Will pull</p>
    <p>user</p>
  </div>
  <div class="page">
    <p>Caching and preconstructing layers</p>
    <p>ILmap: Maps image to its containing layer set.</p>
    <p>ULmap: Maps user to the layers that the user has accessed and the corresponding pull count.</p>
    <p>image image</p>
    <p>Will pull</p>
    <p>user user</p>
  </div>
  <div class="page">
    <p>Caching and preconstructing layers</p>
    <p>ILmap: Maps image to its containing layer set.</p>
    <p>ULmap: Maps user to the layers that the user has accessed and the corresponding pull count.</p>
    <p>image image</p>
    <p>Will pull</p>
    <p>user user</p>
    <p>May pull</p>
  </div>
  <div class="page">
    <p>Caching and preconstructing layers</p>
    <p>ILmap: Maps image to its containing layer set.</p>
    <p>ULmap: Maps user to the layers that the user has accessed and the corresponding pull count.</p>
    <p>image image</p>
    <p>Will pull</p>
    <p>user user</p>
    <p>May pull</p>
  </div>
  <div class="page">
    <p>Caching and preconstructing layers</p>
    <p>ILmap: Maps image to its containing layer set.</p>
    <p>ULmap: Maps user to the layers that the user has accessed and the corresponding pull count.</p>
    <p>image image</p>
    <p>Will pull</p>
    <p>user user</p>
    <p>May pull</p>
  </div>
  <div class="page">
    <p>Tier 1</p>
    <p>Primary</p>
    <p>cluster</p>
    <p>P-server A P-server B</p>
    <p>Cache handling in tiered storage</p>
  </div>
  <div class="page">
    <p>D-server C D-server D</p>
    <p>Tier 2</p>
    <p>Deduplication</p>
    <p>cluster</p>
    <p>Tier 1</p>
    <p>Primary</p>
    <p>cluster</p>
    <p>P-server A P-server B</p>
    <p>Cache handling in tiered storage</p>
  </div>
  <div class="page">
    <p>D-server C D-server D</p>
    <p>Tier 2</p>
    <p>Deduplication</p>
    <p>cluster</p>
    <p>Tier 1</p>
    <p>Primary</p>
    <p>cluster</p>
    <p>P-server A P-server B</p>
    <p>Cache handling in tiered storage</p>
    <p>L1 Prefetch cacheCacheCache</p>
  </div>
  <div class="page">
    <p>D-server C D-server D</p>
    <p>Tier 2</p>
    <p>Deduplication</p>
    <p>cluster</p>
    <p>Tier 1</p>
    <p>Primary</p>
    <p>cluster</p>
    <p>P-server A P-server B</p>
    <p>Cache handling in tiered storage</p>
    <p>L1 Prefetch cacheCacheCache</p>
    <p>Layer storeLayer store L2 Layer store</p>
  </div>
  <div class="page">
    <p>D-server C D-server D</p>
    <p>Tier 2</p>
    <p>Deduplication</p>
    <p>cluster</p>
    <p>Tier 1</p>
    <p>Primary</p>
    <p>cluster</p>
    <p>P-server A P-server B</p>
    <p>Cache handling in tiered storage</p>
    <p>L1 Prefetch cacheCacheCache</p>
    <p>L3 Layer stage areaStage area Stage area</p>
    <p>Layer storeLayer store L2 Layer store</p>
  </div>
  <div class="page">
    <p>D-server C D-server D</p>
    <p>Tier 2</p>
    <p>Deduplication</p>
    <p>cluster</p>
    <p>Tier 1</p>
    <p>Primary</p>
    <p>cluster</p>
    <p>P-server A P-server B</p>
    <p>Cache handling in tiered storage</p>
    <p>L1 Prefetch cacheCacheCache</p>
    <p>L3 Layer stage areaStage area Stage area</p>
    <p>Layer storeLayer store L2 Layer store</p>
  </div>
  <div class="page">
    <p>D-server C D-server D</p>
    <p>Tier 2</p>
    <p>Deduplication</p>
    <p>cluster</p>
    <p>Tier 1</p>
    <p>Primary</p>
    <p>cluster</p>
    <p>P-server A P-server B</p>
    <p>Cache handling in tiered storage</p>
    <p>L1 Prefetch cacheCacheCache</p>
    <p>L3 Layer stage areaStage area Stage area</p>
    <p>L4 Preconstruct cacheCacheCache</p>
    <p>Layer storeLayer store L2 Layer store</p>
  </div>
  <div class="page">
    <p>D-server C D-server D</p>
    <p>Tier 2</p>
    <p>Deduplication</p>
    <p>cluster</p>
    <p>Tier 1</p>
    <p>Primary</p>
    <p>cluster</p>
    <p>P-server A P-server B</p>
    <p>Cache handling in tiered storage</p>
    <p>L1 Prefetch cacheCacheCache</p>
    <p>L3 Layer stage areaStage area Stage area</p>
    <p>L4 Preconstruct cacheCacheCache</p>
    <p>Layer storeLayer store L2 Layer store</p>
    <p>File storeFile store L5 File store</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Workloads used:  Traces from IBM registries: Dal, Fra, Lon, and Syd availability zones</p>
    <p>Dataset from Docker Hub</p>
    <p>Schemes studied:  Baseline: No deduplication</p>
    <p>B-mode n: n (1-3) replicas are preserved; 3  n deduplicated</p>
    <p>S-mode: intact layer replicas proportional to the layers popularity</p>
    <p>B-mode 0: deduplicate all layer replicas, under a given replication policy</p>
    <p>GF-R: global file-level deduplication</p>
    <p>GF+LB-R: global file-level deduplication and local block-level deduplication</p>
    <p>GB-EC: global block-level deduplication under erasure coding</p>
  </div>
  <div class="page">
    <p>Deduplication ratio vs. performance</p>
  </div>
  <div class="page">
    <p>Deduplication ratio vs. performance</p>
  </div>
  <div class="page">
    <p>Deduplication ratio vs. performance</p>
  </div>
  <div class="page">
    <p>Deduplication ratio vs. performance</p>
  </div>
  <div class="page">
    <p>Deduplication ratio vs. performance</p>
  </div>
  <div class="page">
    <p>Deduplication ratio vs. performance</p>
  </div>
  <div class="page">
    <p>Deduplication ratio vs. performance</p>
  </div>
  <div class="page">
    <p>Deduplication ratio vs. performance</p>
  </div>
  <div class="page">
    <p>Prefetch cache hit ratio</p>
    <p>Dal Fra Lon Syd Dal Fra Lon Syd Dal Fra Lon Syd</p>
    <p>H it</p>
    <p>r a ti</p>
    <p>o</p>
    <p>LRU ARC ARC+P-PUT ARC+P-UB</p>
    <p>DupHunter</p>
    <p>Cache size</p>
    <p>State of the art</p>
  </div>
  <div class="page">
    <p>Prefetch cache hit ratio</p>
    <p>Dal Fra Lon Syd Dal Fra Lon Syd Dal Fra Lon Syd</p>
    <p>H it</p>
    <p>r a ti</p>
    <p>o</p>
    <p>LRU ARC ARC+P-PUT ARC+P-UB</p>
    <p>DupHunter</p>
    <p>Cache size</p>
    <p>State of the art</p>
    <p>Duphunter can provide high hit ratio while reducing tail latency.</p>
  </div>
  <div class="page">
    <p>G F</p>
    <p>-R</p>
    <p>G F</p>
    <p>+ L</p>
    <p>B -R</p>
    <p>G B</p>
    <p>-E C</p>
    <p>G F</p>
    <p>-R</p>
    <p>G F</p>
    <p>+ L</p>
    <p>B -R</p>
    <p>G B</p>
    <p>-E C</p>
    <p>G F</p>
    <p>-R</p>
    <p>G F</p>
    <p>+ L</p>
    <p>B -R</p>
    <p>G B</p>
    <p>-E C</p>
    <p>G F</p>
    <p>-R</p>
    <p>G F</p>
    <p>+ L</p>
    <p>B -R</p>
    <p>G B</p>
    <p>-E C</p>
    <p>Dal Fra Lon Syd</p>
    <p>% o</p>
    <p>f G</p>
    <p>E T</p>
    <p>l a</p>
    <p>y e r r</p>
    <p>e q</p>
    <p>u e st</p>
    <p>s Hit Wait Miss</p>
    <p>Preconstruct cache hit ratio</p>
  </div>
  <div class="page">
    <p>G F</p>
    <p>-R</p>
    <p>G F</p>
    <p>+ L</p>
    <p>B -R</p>
    <p>G B</p>
    <p>-E C</p>
    <p>G F</p>
    <p>-R</p>
    <p>G F</p>
    <p>+ L</p>
    <p>B -R</p>
    <p>G B</p>
    <p>-E C</p>
    <p>G F</p>
    <p>-R</p>
    <p>G F</p>
    <p>+ L</p>
    <p>B -R</p>
    <p>G B</p>
    <p>-E C</p>
    <p>G F</p>
    <p>-R</p>
    <p>G F</p>
    <p>+ L</p>
    <p>B -R</p>
    <p>G B</p>
    <p>-E C</p>
    <p>Dal Fra Lon Syd</p>
    <p>% o</p>
    <p>f G</p>
    <p>E T</p>
    <p>l a</p>
    <p>y e r r</p>
    <p>e q</p>
    <p>u e st</p>
    <p>s Hit Wait Miss</p>
    <p>Preconstruct cache hit ratio</p>
    <p>Global file level dedeuplication also has the</p>
    <p>lowest wait and miss ratios.</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>DupHunter exploits the redundancy in container images along with predictable user access patterns to achieve high space savings with low layer restore overhead.  It supports multiple replica deduplication modes.</p>
    <p>It facilitates parallel layer reconstruction.</p>
    <p>It offers proactive layer prefetching/preconstruction.</p>
    <p>DupHunter reduces storage space needs by up to 6.9x and can reduce the GET layer latency up to 2.8x compared to the state of the art.</p>
    <p>DupHunter is available at https://github.com/nnzhaocs/DupHunter.</p>
  </div>
  <div class="page">
    <p>THANK YOU</p>
    <p>Questions: Nannan Zhao znannan1@vt.edu</p>
    <p>DSSL@VT: http://dssl.cs.vt.edu</p>
  </div>
</Presentation>
