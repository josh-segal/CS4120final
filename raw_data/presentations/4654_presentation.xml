<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>RankClus: Integrating Clustering with</p>
    <p>Ranking for Heterogeneous</p>
    <p>Information Network Analysis</p>
    <p>Yizhou Sun, Jiawei Han, Peixiang Zhao, Zhijun Yin,</p>
    <p>Hong Cheng, Tianyi Wu</p>
    <p>Department of Computer Science</p>
    <p>University of Illinois at Urbana-Champaign</p>
    <p>EDBT09, St.-Petersburg, Russia, March 2009</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Background</p>
    <p>Motivation</p>
    <p>The RankClus Algorithm</p>
    <p>Experiments</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Information Networks Are Ubiquitos</p>
    <p>Conference-Author NetworkCo-author Network</p>
  </div>
  <div class="page">
    <p>Two Kinds of Information Networks</p>
    <p>Homogeneous Network  Objects belong to single type  E.g., co-author network, internet, friendship</p>
    <p>network, gene interaction network, and so on  Most current studies are on homogeneous networks</p>
    <p>Heterogeneous Network  Objects belong to several types  E.g., conference-author network, paper-conference</p>
    <p>author-topic network, movie-user network, webpage-tag-user network, and so on</p>
    <p>Most real networks are heterogeneous networks, and many homogeneous networks are extracted from a more complex network</p>
  </div>
  <div class="page">
    <p>How to Better Understand Information Networks?</p>
    <p>Problem: Hard to understand large, raw networks</p>
    <p>Huge number of objects</p>
    <p>Links are in a mess</p>
    <p>Solution: Extracting aggregate information from networks</p>
    <p>Ranking</p>
    <p>Clustering</p>
  </div>
  <div class="page">
    <p>Ranking</p>
    <p>Goal  Evaluate importance of objects in the network  A ranking function: map an object into a real</p>
    <p>non-negative score  Algorithms</p>
    <p>PageRank (for homogeneous networks)  HITS (for homogeneous networks)  PopRank (for heterogeneous networks)</p>
  </div>
  <div class="page">
    <p>Clustering</p>
    <p>Goal  Group similar objects together and obtain the</p>
    <p>cluster label for each object  Algorithms</p>
    <p>Spectral clustering: Min-Cut, N-Cut, and MinMaxCut (for homogeneous networks)</p>
    <p>Density-based clustering: SCAN (for homogeneous networks)</p>
    <p>How to cluster heterogeneous networks?  Use SimRank to first extract pair-wise similarity</p>
    <p>for target objects (but time complexity is high)  Combined with spectral clustering</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Background</p>
    <p>Motivation</p>
    <p>The RankClus Algorithm</p>
    <p>Experiments</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Why RankClus?</p>
    <p>More meaningful cluster  Within each cluster, ranking score for every</p>
    <p>object is available as well</p>
    <p>More meaningful ranking  Ranking within a cluster is more meaningful than</p>
    <p>in the whole network</p>
    <p>Address the problem of clustering in heterogeneous networks  No need to compute pair-wise similarity of objects  Mapping each object into a low measure space</p>
  </div>
  <div class="page">
    <p>Global Ranking vs. Within-Cluster Ranking in a Toy Example</p>
    <p>Two areas: 10 conferences and 100 authors in each area</p>
  </div>
  <div class="page">
    <p>Difficulties in Clustering Heterogeneous Networks</p>
    <p>What type of objects to be clustered?</p>
    <p>Clustering on one specific type of objects (called</p>
    <p>target objects): specified by user</p>
    <p>Clustering of target objects can induce a sub</p>
    <p>network of the original network</p>
    <p>Efficient algorithm of clustering</p>
    <p>How to avoid calculating pair-wise similarities</p>
    <p>among target objects?</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Background</p>
    <p>Motivation</p>
    <p>The RankClus Algorithm</p>
    <p>Experiments</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Algorithm Framework - Illustration</p>
    <p>Sub-Network Ranking</p>
    <p>Clustering</p>
  </div>
  <div class="page">
    <p>Algorithm FrameworkPhilosophy</p>
    <p>Ranking and clustering can be mutually improved  Ranking: Once a cluster becomes more</p>
    <p>accurate, ranking will be more reasonable for such a cluster and will be the distinguished feature of the cluster</p>
    <p>Clustering: Once ranking is more distinguished from each other, the clusters can be adjusted and get more accurate results</p>
    <p>Objects preserve similarity under new measure space  E.g., consider VLDB and SIGMOD</p>
  </div>
  <div class="page">
    <p>Algorithm Framework - Summary</p>
    <p>Step 0. Initialization</p>
    <p>Randomly partition target objects into K clusters</p>
    <p>Step 1. Ranking</p>
    <p>Ranking for each sub-network induced from each cluster, which serves as feature for each cluster</p>
    <p>Step 2. Generating new measure space</p>
    <p>Estimate mixture model coefficients for each target object</p>
    <p>Step 3. Adjusting cluster</p>
    <p>Step 4. Repeat Step 1-3 until stable</p>
  </div>
  <div class="page">
    <p>Focus on A Bi-type Network Case</p>
    <p>Conference-author network, links can exist between  Conference (X) and author (Y)  Author (Y) and author (Y)</p>
    <p>Use W to denote the links and there weights</p>
    <p>W =</p>
  </div>
  <div class="page">
    <p>Step 1: Feature Extraction  Ranking</p>
    <p>Simple Ranking  Proportional to degree counting for objects  E.g., number of publications of authors  Considers only immediate neighborhood in the network</p>
    <p>Authority Ranking  Extension to HITS in weighted bi-type network  Rules:</p>
    <p>Rule 1: Highly ranked authors publish many papers in highly ranked conferences</p>
    <p>Rule 2: Highly ranked conferences attract many papers from many highly ranked authors</p>
    <p>Rule 3: The rank of an author is enhanced if he or she coauthors with many authors or many highly ranked authors</p>
  </div>
  <div class="page">
    <p>Rules in Authority Ranking</p>
    <p>Rule 1: Highly ranked authors publish many papers in highly ranked conferences</p>
    <p>Rule 2: Highly ranked conferences attract many papers from many highly ranked authors</p>
    <p>Rule 3: The rank of an author is enhanced if he or she co-authors with many authors or many highly ranked authors</p>
  </div>
  <div class="page">
    <p>Philosophy in Authority Ranking</p>
    <p>Ranking score propagated by iterations using rules 2 and 1, or rules 2 and 3  The authority ranking of X and Y turned out to</p>
    <p>be primary eigenvectors of some symmetric matrix</p>
    <p>Considers the impact from the overall network  Should be better than simple ranking</p>
  </div>
  <div class="page">
    <p>Example: Authority Ranking in the 2-Area Conference-Author</p>
    <p>Network  Given the correct cluster, the ranking of authors are quite</p>
    <p>distinct from each other</p>
  </div>
  <div class="page">
    <p>Step 2: Generate New Measure Space A Naive Method</p>
    <p>Mapping target object to a K-dimensional vector</p>
    <p>directly by considering a sub-network induced by it</p>
    <p>r(Y|x) vs. r(Y|k)</p>
    <p>Cosine similarity or KL-Divergence can be used</p>
    <p>E.g., (cos(r(Y|x), r(Y|1)), , cos(r(Y|x), r(Y|K)))</p>
  </div>
  <div class="page">
    <p>Step 2: Generate New Measure Space A Mixture Model Method</p>
    <p>Consider each target objects links are generated under a mixture distribution of ranking from each cluster  Consider ranking as a distribution: r(Y)  p(Y)</p>
    <p>Each target object xi is mapped into a K-vector (i,k)</p>
    <p>Parameters are estimated using the EM algorithm  Maximize the log-likelihood given all the</p>
    <p>observations of links</p>
  </div>
  <div class="page">
    <p>Example: 2-D Coefficients in the 2Area Conference-Author Network</p>
    <p>The conferences are well separated in the new measure space</p>
  </div>
  <div class="page">
    <p>Step 3: Cluster Adjustment in New Measure Space</p>
    <p>Cluster center in new measure space</p>
    <p>Vector mean of objects in the cluster (K</p>
    <p>dimensional)</p>
    <p>Cluster adjustment</p>
    <p>Distance measure: 1- Cosine similarity</p>
    <p>Assign to the cluster with the nearest center</p>
  </div>
  <div class="page">
    <p>A Running Case Illustration for 2Area Conf-Author Network</p>
    <p>Initially, ranking distributions are mixed together</p>
    <p>Two clusters of objects mixed together, but preserve similarity somehowImproved a little</p>
    <p>Two clusters are almost well separated</p>
    <p>Improved significantly</p>
    <p>Stable</p>
    <p>Well separated</p>
  </div>
  <div class="page">
    <p>Ranking Function Analysis</p>
    <p>Why Authority Ranking is better than Simple Ranking?  For authority ranking, each objects score is</p>
    <p>determined by  The number of objects linking to it  The strength of these links (weight of link)  The quality of these objects (score)</p>
    <p>For simple ranking, each objects score is determined by</p>
    <p>The number of objects linking to it  The strength of these links (weight of link)  The quality of these objects are equal</p>
  </div>
  <div class="page">
    <p>Re-examine the Rules</p>
    <p>Rule 1: Highly ranked authors publish many papers in highly ranked conferences  An author publishing many papers in junk conferences</p>
    <p>will be ranked low  Rule 2: Highly ranked conferences attract many papers</p>
    <p>from many highly ranked authors  A conference accepting most papers from lowly ranked</p>
    <p>authors will be ranked low  Rule 3: The rank of an author is enhanced if he or she co</p>
    <p>authors with many authors or many highly ranked authors  A highly ranked author in an area usually has many co</p>
    <p>operations with others</p>
  </div>
  <div class="page">
    <p>Why Better Ranking Function Derives Better Clustering?</p>
    <p>Consider the measure space generation process</p>
    <p>For naive method, highly ranked objects in a</p>
    <p>cluster play a more important role to decide a</p>
    <p>target objects new measure</p>
    <p>For mixture model, the same</p>
    <p>Intuitively, if we can find the highly ranked objects</p>
    <p>in a cluster, equivalently, we get the right cluster</p>
  </div>
  <div class="page">
    <p>Time Complexity Analysis</p>
    <p>At each iteration, |E|: edges in network, m: number of target objects, K: number of clusters  Ranking for sparse network</p>
    <p>~O(|E|)  Mixture model estimation</p>
    <p>~O(K|E|+mK)  Cluster adjustment</p>
    <p>~O(mK^2)  In all, linear to |E|</p>
    <p>~O(K|E|)</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Background</p>
    <p>Motivation</p>
    <p>The RankClus Algorithm</p>
    <p>Experiments</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Case Study: Dataset: DBLP</p>
    <p>All the 2676 conferences and 20,000 authors with most publications, from the time period of year 1998 to year 2007.</p>
    <p>Both conference-author relationships and coauthor relationships are used.</p>
    <p>K=15</p>
  </div>
  <div class="page">
    <p>Accuracy Study</p>
    <p>Dataset: synthetic dataset  Simulate a bipartite network similar to conf-author network  P: control the node number of attribute objects  T: transition probability matrix, to control the overlap</p>
    <p>between clusters  K: fix to 3</p>
    <p>Generating parameters for the five synthetic datasets Data1: medium separated and medium density</p>
    <p>P = [1000, 1500, 2000], T = [0.8, 0.05, 0.15; 0.1, 0.8, 0.1; 0.1, 0.05, 0.85]</p>
    <p>Data2: medium separated and low density P = [800, 1300, 1200], T = [0.8, 0.05, 0.15; 0.1, 0,8, 0.1; 0.1, 0.05, 0.85]</p>
    <p>Data3: medium separated and high density P = [2000, 3000, 4000], T = [0.8, 0.05, 0.15; 0.1, 0.8, 0.1; 0.1, 0.05, 0.85]</p>
    <p>Data4: highly separated and medium density P = [1000, 1500, 2000], T = [0.9, 0.05, 0.05; 0.05, 0.9, 0.05; 0.1, 0.05, 0.85]</p>
    <p>Data5: poorly separated and medium density P = [1000, 1500, 2000], T = [0.7, 0.15, 0.15; 0.15, 0.7, 0.15; 0.15, 0.15, 0.7]</p>
  </div>
  <div class="page">
    <p>Accuracy Study (Cont.)</p>
    <p>5 (synthetic) dataset settings, 4 methods  For each setting, generate 10 datasets, run</p>
    <p>each method for each dataset 100 times  RankClus with authority ranking is the best</p>
    <p>overall</p>
  </div>
  <div class="page">
    <p>Efficiency Study</p>
    <p>Varying size of attribute type of objects (2)</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Background</p>
    <p>Motivation</p>
    <p>The RankClus Algorithm</p>
    <p>Experiments</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Conclusions  A general framework is proposed in which ranking</p>
    <p>and clustering are successfully combined to analyze information networks</p>
    <p>Formally study how ranking and clustering can mutually reinforce each other in information network analysis</p>
    <p>A novel algorithm, RankClus, is proposed and its correctness and effectiveness are verified</p>
    <p>A thorough experimental study on both synthetic and real datasets in comparison with the state-of-the-art algorithms, and the experimental results demonstrate the accuracy and efficiency of RankClus</p>
  </div>
</Presentation>
