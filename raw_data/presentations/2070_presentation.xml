<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>A Template Library to Integrate</p>
    <p>Thread Scheduling and Locality Management</p>
    <p>for NUMA Multiprocessors</p>
    <p>Zoltn Maj Thomas R. Gross Computer Science Department ETH Zurich, Switzerland</p>
  </div>
  <div class="page">
    <p>Non-uniform memory architecture</p>
    <p>Local memory accesses</p>
    <p>bandwidth: 10.1 GB/s</p>
    <p>latency: 190 cycles</p>
    <p>Remote memory accesses</p>
    <p>bandwidth: 6.3 GB/s</p>
    <p>latency: 310 cycles</p>
    <p>Processor 1</p>
    <p>Core 4 Core 5</p>
    <p>Core 6 Core 7</p>
    <p>IC MC</p>
    <p>DRAM</p>
    <p>Processor 0</p>
    <p>Core 0 Core 1</p>
    <p>Core 2 Core 3</p>
    <p>MC IC</p>
    <p>DRAM</p>
    <p>Key to good performance: data locality</p>
    <p>All data based on experimental evaluation of Intel Xeon 5500 (Hackenberg [MICRO 09], Molka [PACT 09])</p>
    <p>Core 0</p>
  </div>
  <div class="page">
    <p>Remote memory references (2 processors)</p>
    <p>Subset of the PARSEC benchmark suite</p>
    <p>Remote memory references / total memory references [%]</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction</p>
    <p>Ferret</p>
    <p>Memory behavior</p>
    <p>Optimizing for data locality</p>
    <p>Evaluation</p>
    <p>Template library</p>
    <p>Concluding remarks</p>
  </div>
  <div class="page">
    <p>Experimental setup</p>
    <p>2-processor 8-core Intel Xeon</p>
    <p>Nehalem microarchitecture</p>
    <p>Linux + perfmon2</p>
    <p>First-touch page placement</p>
    <p>Ferret: pipeline parallelism</p>
    <p>Stage 1 Stage 4 Input Output Stage 3 Stage 2</p>
    <p>T1 T1</p>
    <p>T1 T1</p>
    <p>T1 T1</p>
    <p>T1 T1</p>
    <p>T2 T2</p>
    <p>T2 T2</p>
    <p>T2 T2</p>
    <p>T2 T2</p>
    <p>T3 T3</p>
    <p>T3 T3</p>
    <p>T3 T3</p>
    <p>T3 T3</p>
    <p>T4 T4</p>
    <p>T4 T4</p>
    <p>T4 T4</p>
    <p>T4 T4</p>
    <p>T-OUT T-IN</p>
    <p>Processor 1</p>
    <p>DRAM</p>
    <p>Processor 0</p>
    <p>DRAM</p>
  </div>
  <div class="page">
    <p>Profiling memory accesses</p>
    <p>Data address profiling</p>
    <p>Based on hardware-performance monitoring</p>
    <p>Consider only heap accesses</p>
    <p>Profile</p>
    <p>Page 0 : 1000 accesses by Processor 0</p>
    <p>Page 1 : 3000 accesses by Processor 1</p>
    <p>Processor 1</p>
    <p>DRAM</p>
    <p>Processor 0</p>
    <p>DRAM</p>
    <p>Page 0 Page 1</p>
  </div>
  <div class="page">
    <p>Profiling memory accesses</p>
    <p>Data address profiling</p>
    <p>Based on hardware-performance monitoring</p>
    <p>Consider only heap accesses</p>
    <p>Profile</p>
    <p>Page 0 : 1000 accesses by Processor 0</p>
    <p>Page 1 : 3000 accesses by Processor 1</p>
    <p>Processor 1</p>
    <p>DRAM</p>
    <p>Processor 0</p>
    <p>DRAM</p>
    <p>Page 2 : 4000 accesses by Processor 0 5000 accesses by Processor 1</p>
    <p>Page 2</p>
    <p>Ferret: 41% of profiled pages inter-processor shared</p>
  </div>
  <div class="page">
    <p>Index</p>
    <p>Detailed look</p>
    <p>Ferret: similarity search of images</p>
    <p>Input: set of images</p>
    <p>O utput: list of images similar to input</p>
    <p>Index stage: most memory system intensive</p>
    <p>Produces 90% of total memory bandwidth</p>
    <p>Segment Extract Output Rank Input</p>
    <p>img/butterfly.jpg img/mountain.jpg img/flower.jpg img/rose.jpg img/flower.jpg img/egg.jpg</p>
    <p>Image database</p>
    <p>query candidate set</p>
    <p>Index</p>
  </div>
  <div class="page">
    <p>Database System</p>
    <p>Image ID Features</p>
    <p>Locality-sensitive hashing</p>
    <p>Image data</p>
    <p>Hash value</p>
    <p>Data index</p>
    <p>Index</p>
    <p>N ...</p>
  </div>
  <div class="page">
    <p>Database System</p>
    <p>Image ID Features</p>
    <p>Hash value</p>
    <p>Data index</p>
    <p>Index</p>
    <p>N ...</p>
    <p>Locality-sensitive hashing</p>
    <p>Index</p>
    <p>Image data</p>
    <p>N-1 ...</p>
  </div>
  <div class="page">
    <p>Bad data locality</p>
    <p>Data accesses and parallelization decoupled</p>
    <p>Database interface hides details about internal structure</p>
    <p>All threads running the indexing phase access database</p>
    <p>Optimizing for data locality</p>
    <p>Precise control of data and computation allocation within database</p>
    <p>Example: 2-processor system</p>
  </div>
  <div class="page">
    <p>Database System</p>
    <p>Image ID Features</p>
    <p>Optimizing for data locality</p>
    <p>Image data</p>
    <p>Hash value</p>
    <p>Data Index</p>
  </div>
  <div class="page">
    <p>Database System</p>
    <p>Image ID Features</p>
    <p>Optimizing for data locality</p>
    <p>Image data: CPU 0</p>
    <p>Hash value</p>
    <p>Data Index</p>
    <p>Image ID Features</p>
    <p>N/2 + 1 ... ... ... N-1 ... N ...</p>
    <p>Image data: CPU 1</p>
    <p>Thread pool</p>
    <p>T0 T0</p>
    <p>T0 T0</p>
    <p>CPU 0</p>
    <p>T1 T1</p>
    <p>T1 T1</p>
    <p>CPU 1</p>
  </div>
  <div class="page">
    <p>Database System</p>
    <p>Image ID Features</p>
    <p>Optimizing for data locality</p>
    <p>Image data: CPU 0</p>
    <p>Hash value</p>
    <p>Data Index</p>
    <p>Image ID Features</p>
    <p>N/2 + 1 ... ... ... N-1 ... N ...</p>
    <p>Image data: CPU 1</p>
    <p>Thread pool</p>
    <p>T0 T0</p>
    <p>T0 T0</p>
    <p>CPU 0</p>
    <p>T1 T1</p>
    <p>T1 T1</p>
    <p>CPU 1</p>
    <p>Query dispatch</p>
    <p>Index</p>
    <p>W0 W1</p>
    <p>N/2 ...</p>
    <p>N/2 + 1 ...</p>
    <p>N ...</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Two machines</p>
    <p>2-processor 8-core Intel Nehalem (Xeon E5520)</p>
    <p>4-processor 32-core Intel Westmere (Xeon E7-4830)</p>
    <p>Two image database sizes</p>
    <p>small: ~60 K images</p>
    <p>large: ~744 K images</p>
    <p>3500 image queries in both cases</p>
    <p>Compare two configurations</p>
    <p>default: first-touch page allocation, affinity scheduling</p>
    <p>NUMA-aware memory allocation and computation scheduling</p>
  </div>
  <div class="page">
    <p>Data locality</p>
    <p>small large small large</p>
    <p>default</p>
    <p>NUMA-aware</p>
    <p>Remote memory references / total memory references [%]</p>
  </div>
  <div class="page">
    <p>Performance</p>
    <p>-10%</p>
    <p>small large small large</p>
    <p>Performance improvement of NUMA-aware over default [%]</p>
  </div>
  <div class="page">
    <p>Optimizing for data locality  summary</p>
    <p>Optimizing data locality in ferret difficult</p>
    <p>System developer: internals of shared database must be understood</p>
    <p>Database developer: system must be understood</p>
    <p>Data structures often key to good NUMA performance</p>
    <p>Template library: basis for NUMA-aware data structures</p>
  </div>
  <div class="page">
    <p>Template library</p>
    <p>Base class</p>
    <p>Per-processor data allocation</p>
    <p>Locality-aware task dispatch</p>
    <p>SplittableData&lt;Data,Result&gt;</p>
    <p>Data newAtProcessor(p:Processor)</p>
    <p>Result dispatch(queryTask:Task)</p>
  </div>
  <div class="page">
    <p>abstract class SplittableData&lt;Data,Result&gt; {</p>
    <p>ThreadPool threadPool;</p>
    <p>Map&lt;Processor,Data&gt; map;</p>
    <p>Data newAtProcessor(Processor p) {</p>
    <p>// new Data instance at Processor p</p>
    <p>// record mapping Processor  Data</p>
    <p>}</p>
    <p>Result dispatch(Task queryTask) {</p>
    <p>List&lt;Result&gt; results;</p>
    <p>Data localData;</p>
    <p>for (Processor p : processors) {</p>
    <p>localData = map.get(p);</p>
    <p>threadPool.submit(queryTask, p, localData);</p>
    <p>}</p>
    <p>for (Processor p : processors)</p>
    <p>results.add(threadPool.get(p));</p>
    <p>return Result.merge(results);</p>
    <p>}</p>
    <p>}</p>
    <p>Template library</p>
  </div>
  <div class="page">
    <p>Concluding remarks</p>
    <p>Some parallel programs NUMA-unfriendly by construction</p>
    <p>Good performance: programmer intervention required</p>
    <p>Template library to abstract low-level system details</p>
  </div>
  <div class="page">
    <p>Thank you for your attention!</p>
  </div>
</Presentation>
