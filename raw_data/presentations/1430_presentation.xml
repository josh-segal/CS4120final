<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Towards Adversarial Phishing Detection T. K. Panum, K. Hageman, R. R. Hansen, J. M. Pedersen</p>
    <p>Long Paper (Position)  August 10, 2020</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Phishing Attacks Advances in technical security measures cause users to be victims of exploits Phishing attacks have exploited users for over two decades Numerous counter-measures have been developed to fight the problem</p>
    <p>Contradictory Effectiveness (Marchal et al., 2018) Multiple reports claim frequency of attacks remain high (or increasing) State-of-the-art detection solutions report impressive evaluation measures1</p>
    <p>Causes: Biased evaluations and infeasible deployment</p>
    <p>Adversarial Robustness Few methods evaluate their performance on attacks that seek to actively evade the proposed detection solution</p>
  </div>
  <div class="page">
    <p>Adversarial Robustness</p>
    <p>Adaptive attacks Adaptive phishing attacks are attacks that remain undetected for a certain detection solution, yet maintain the functional properties of phishing attacks</p>
    <p>Exists due to discrepancy between model and reality</p>
    <p>Adversarial Robustness Given solutions are likely to face adaptive attacks in a practical setting, evaluations should seek quantify their performance towards these (Ho et al., 2019)</p>
    <p>: Observed attacks</p>
    <p>: Adaptive attacks</p>
    <p>Set of phishing attacks (detection solution)</p>
    <p>Set of phishing attacks (true)</p>
    <p>Motivation Thomas Kobber Panum 2 / 13</p>
  </div>
  <div class="page">
    <p>Phishing Environments</p>
    <p>Attacks have existed across multiple environments We formalize the shared properties of such environments as:</p>
    <p>Environment for Phishing Attacks A messaging environment for which messages within this environment can fulfill the three axioms:</p>
    <p>Impersonating, Inducive, and Scalable.</p>
    <p>Messaging Environment An environment for which messages can be exchanged using a channel across multiple senders and recipients</p>
    <p>Message Contains some content and relate to a sender and recipient</p>
    <p>Formalization Thomas Kobber Panum 3 / 13</p>
  </div>
  <div class="page">
    <p>Axioms1</p>
    <p>Lastdrager et al.s Definition of Phishing Attacks</p>
    <p>Phishing is a scalable act of deception whereby impersonation is used to obtain information from a target.</p>
    <p>Impersonating Should deceive the recipient into trusting the fake identity of the sender</p>
    <p>Inducive Should induce some form of action that yields the attacker to obtain information</p>
    <p>Scalable Crafting the attack should be inexpensive (time, $)</p>
    <p>Formalization Thomas Kobber Panum 4 / 13</p>
  </div>
  <div class="page">
    <p>Assessment of Adversarial Robustness</p>
    <p>Examine the extend of which existing detection solutions have accounted for adversarial robustness Selected work cover influential- and recent publications</p>
    <p>Derived a four of commonly used strategies for detecting attacks: Visual Similarity, Reverse Search Credibility, Channel Meta-information, Statistical Modeling</p>
    <p>Discuss these strategies and their ability to account for the identified axioms Demonstrate techniques for creating perturbations that enable attacks to avoid detection</p>
    <p>Assessment Thomas Kobber Panum 5 / 13</p>
  </div>
  <div class="page">
    <p>Visual Similarity</p>
    <p>similar?</p>
    <p>Phishing Attribute Sharing visual identity with an already observed benign message</p>
    <p>while originating from a different source.</p>
    <p>Axioms X Impersonating  Inducive XScalable</p>
    <p>Based on reflecting human perception in a computational setting Known to be a challenging and unsolved problem Incomplete coverage of axioms</p>
    <p>Assessment Thomas Kobber Panum 6 / 13</p>
  </div>
  <div class="page">
    <p>Example: Normalized Compression Distance (Chen et al.)</p>
    <p>Compare visual similarity as intersection over union of byte compressions</p>
    <p>Simple attack 1 Use a color space that align closely with human color perception 2 Perturb all colors by small steps (1%)</p>
    <p>Our attack is remain imperceptible yet effectively breaks NCD:</p>
    <p>NCD(x, x)NCD(x, x) = 0.960.01</p>
    <p>Assessment Thomas Kobber Panum 7 / 13</p>
  </div>
  <div class="page">
    <p>Reverse Search Credibility</p>
    <p>example.com</p>
    <p>Search Engine</p>
    <p>signature</p>
    <p>test, document, demo search results</p>
    <p>if found  not phishing else  phishing</p>
    <p>Phishing Attribute Absence of a given website in the most relevant search results</p>
    <p>returned by querying search engines with a signature derived from the given website.</p>
    <p>Relies credit scoring using search engines Search engines are black boxes  Uncertainty</p>
    <p>Axioms ? Impersonating ? Inducive XScalable</p>
    <p>Assessment Thomas Kobber Panum 8 / 13</p>
  </div>
  <div class="page">
    <p>Channel Meta-information</p>
    <p>Strategy Constrain information used for inference to only be within the scope of the channel, ignoring the content of the respective messages.</p>
    <p>Phishing Attribute (case: Web) URLs resembling a URL from a known benign source.</p>
    <p>Given: Inducive  Content of messages Predictiveness using this strategy signal bias Incomplete coverage of axioms</p>
    <p>Axioms (X) Impersonating  Inducive XScalable</p>
    <p>Assessment Thomas Kobber Panum 9 / 13</p>
  </div>
  <div class="page">
    <p>Statistical Modeling</p>
    <p>Strategy Given a dataset containing information related to messages, and the presence of attacks within them, approximate a function f (x) that can detect attacks.</p>
    <p>Axioms (X) Impersonating (X) Inducive XScalable</p>
    <p>Highly dynamic strategy, delimited by the information of the used dataset Selecting a model is often a trade-off between complexity and interpretability Parameters are selected using empirical performance</p>
    <p>Assuming generalization to out-of-distribution inputs</p>
    <p>Complex functions can be in the magnitude of millions of parameters WhiteNet (Abdelnabi et al., 2019):  100M</p>
    <p>Assessment Thomas Kobber Panum 10 / 13</p>
  </div>
  <div class="page">
    <p>WhiteNet (Abdelnabi et al., 2019) Model Unperturbed  = 0.005  = 0.01</p>
    <p>Traditional Training</p>
    <p>WhiteNet 81.0% 72.8% 62.5% WhiteNet (replica) 87.8% 30.0% 24.6%</p>
    <p>Adversarial Training</p>
    <p>WhiteNet 81.0% 79.0% 73.1% WhiteNet (replica) 90.3% 33.3% 30.8%</p>
    <p>Table: Precision (closest match) for WhiteNet and our replica model across perturbations created using the FGSM attack for various threat models .</p>
    <p>Model: Siamese Deep Neural Network (DNN) with  100M parameters. Given two visual representations of web sites yield a similarity measure Adversarial examples (AE) are a known vulnerability to DNNs Found that stated robustness towards AE to be inaccurate</p>
    <p>Likely due to under-sampling during the creation of attacks</p>
    <p>Assessment Thomas Kobber Panum 11 / 13</p>
  </div>
  <div class="page">
    <p>Design Guidelines We introduce a set of design guidelines for future detection solutions to follow:</p>
    <p>Accessible Provide a widely available implementation</p>
    <p>Statistical Models: Weights and/or dataset.</p>
    <p>Benefit: Allow for continuous evaluations (both empirical and adaptive)</p>
    <p>Explicit Attributes Clarify how information from the input space is used to infer attacks</p>
    <p>(Complex) Statistical Models: Attribution Methods</p>
    <p>Align with Axioms Focus on using functional properties of attacks for detection Absence: Predictiveness stemming from bias (symptoms not cause)</p>
    <p>Design Guidelines Thomas Kobber Panum 12 / 13</p>
  </div>
  <div class="page">
    <p>Thank you!</p>
    <p>Thanks for listening!</p>
    <p>Thomas Kobber Panum tkp@es.aau.dk</p>
    <p>PhD Student Department of Electronic Systems</p>
    <p>Aalborg University, Denmark</p>
    <p>Closing Thomas Kobber Panum 13 / 13</p>
  </div>
</Presentation>
