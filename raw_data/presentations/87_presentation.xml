<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Exploiting Query History for Document Ranking in Interactive</p>
    <p>IR</p>
    <p>Xuehua Shen ChengXiang Zhai University of Illinois at Urbana</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>In interactive IR, user interacts with system several times</p>
    <p>Lots of context information such as query history</p>
    <p>Exploiting these context information can improve retrieval performance</p>
  </div>
  <div class="page">
    <p>Exploit Query History</p>
    <p>Query history instead of terms from top retrieved documents</p>
    <p>Automatic query expansion instead of interactive query expansion</p>
    <p>Can be combined with pseudo feedback</p>
  </div>
  <div class="page">
    <p>Ranking algorithm</p>
    <p>KL Divergence retrieval model</p>
    <p>Model-based Feedback (Mixture Model)</p>
    <p>Query sequences q1, q2,, qn 1</p>
    <p>( , )1 ( | ,..., )</p>
    <p>| |</p>
    <p>k i</p>
    <p>k i i</p>
    <p>c w q p w q q</p>
    <p>k q</p>
    <p>( , ) ( | ,... ) log(1 ) log</p>
    <p>( | ) | | k</p>
    <p>w</p>
    <p>c w d p w q q</p>
    <p>p w C d</p>
  </div>
  <div class="page">
    <p>Experiment Design</p>
    <p>TREC-7 and TREC-8 Data, 25 Hardest Topics</p>
    <p>Query History Collection: for each topic, a subject iteratively improve the query during the interaction with Lemur retrieval system</p>
    <p>Evaluation metrics: Mean Average Precision and Precision@N documents</p>
  </div>
  <div class="page">
    <p>Experiment Result</p>
  </div>
  <div class="page">
    <p>Conclusion and Future Work</p>
    <p>Using query history to expand query improves retrieval performance</p>
    <p>Term Sequence Analysis and Unequal Weighting of different queries</p>
    <p>Use other context information such as clickthrough data</p>
  </div>
</Presentation>
