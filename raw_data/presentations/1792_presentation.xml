<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Modeling Real Graphs using Kronecker Multiplication</p>
    <p>Jure Leskovec, Christos Faloutsos Machine Learning Department</p>
  </div>
  <div class="page">
    <p>Modeling large networks</p>
    <p>Large networks (e.g., web, internet, on-line social networks) with millions of nodes</p>
    <p>Need statistical methods and models to quantify large networks</p>
  </div>
  <div class="page">
    <p>The problem</p>
    <p>We want to generate realistic networks</p>
    <p>What are the relevant properties?  What is a good analytically tractable model?  How can we fit the model (estimate</p>
    <p>parameters)?</p>
    <p>Some statistical property, e.g., degree distribution</p>
    <p>Given a large real network</p>
    <p>Generate a synthetic network</p>
    <p>this talk</p>
  </div>
  <div class="page">
    <p>Why is this important?</p>
    <p>Gives insight into the graph formation process</p>
    <p>Anomaly detection  abnormal behavior, evolution</p>
    <p>Predictions  predicting future from the past</p>
    <p>Simulations of new algorithms where real graphs are hard/impossible to collect</p>
    <p>Graph sampling  many real world graphs are too large to deal with</p>
    <p>What if scenarios</p>
  </div>
  <div class="page">
    <p>Statistical properties of networks  Features that are common to networks of</p>
    <p>different types:  Small-world effect [Milgram, Watts&amp;Strogatz]  Degree distributions [Faloutsos et al]  Spectral properties [Chakrabarti et al]  Transitivity or clustering [Watts&amp;Strogatz]  Community structure [Girvan&amp;Newman, and others]</p>
    <p>These properties are shared across many real world networks:  World wide web [Barabasi]  On-line communities [Holme, Edling, Liljeros]  Who call whom telephone networks [Cortes]  Internet backbone  routers [Faloutsos et al]</p>
  </div>
  <div class="page">
    <p>Small-world effect</p>
    <p>Distribution of shortest path lengths</p>
    <p>Microsoft Messenger network  180 million people</p>
    <p>1.3 billion edges</p>
    <p>Edge if two people exchanged at least one message in one month period</p>
    <p>Distance (Hops)</p>
    <p>lo g</p>
    <p>N u m</p>
    <p>b e</p>
    <p>r o</p>
    <p>f n</p>
    <p>o d e</p>
    <p>s</p>
    <p>Pick a random node, count how many</p>
    <p>nodes are at distance</p>
    <p>Distances in MSN messenger network</p>
  </div>
  <div class="page">
    <p>Heavy-tailed degree distributions</p>
    <p>Let pk denote a number (fraction) of nodes with degree k</p>
    <p>We can plot a histogram of pk vs. k</p>
    <p>Degrees in real networks are heavily skewed to the right</p>
    <p>Distribution has a long tail of values that are far above the mean</p>
    <p>Power law:</p>
    <p>Degree distribution of a blog network</p>
    <p>lo g</p>
    <p>(p k)</p>
    <p>log(k)</p>
  </div>
  <div class="page">
    <p>Spectral properties</p>
    <p>Eigenvalues of graph adjacency matrix follow a power law</p>
    <p>Network values (components of principal eigenvector) also follow a power-law</p>
    <p>log Rank</p>
    <p>l o g</p>
    <p>E ig</p>
    <p>en v al</p>
    <p>u e</p>
    <p>Eigenvalue distribution in online social network</p>
  </div>
  <div class="page">
    <p>Models of graph generation  Given graph properties  How can we design generative models that</p>
    <p>explain them?  Lots of work:</p>
    <p>Random graph [Erdos and Renyi, 60s]  Preferential Attachment [Albert and Barabasi, 1999]  Copying model [Kleinberg et al, 1999]  Forest Fire model [Leskovec et al, 2005]</p>
    <p>But all of these:  Do not obey all the properties (aim to model</p>
    <p>(explain) just one of the properties at a time)  Or are analytically intractable</p>
  </div>
  <div class="page">
    <p>The model: Kronecker graphs</p>
    <p>Kronecker graphs are analytically tractable  We prove [with Chakrabarti, Kleinberg</p>
    <p>Kleinberg, Faloutsos in PKDD05] that Kronecker graphs have rich properties:  Static Patterns</p>
    <p>Power Law Degree Distribution  Small Diameter  Power Law Eigenvalue and Eigenvector Distribution</p>
    <p>Temporal Patterns  Densification Power Law  Shrinking/Constant Diameter</p>
  </div>
  <div class="page">
    <p>Intuition: self-similarity leads to power-laws  Try to mimic recursive graph / community</p>
    <p>growth  There are many obvious (but wrong) ways:</p>
    <p>Kronecker Product is a way of generating self-similar matrices</p>
    <p>Idea: Recursive graph generation</p>
    <p>Initial graph Recursive expansion</p>
  </div>
  <div class="page">
    <p>Adjacency matrix</p>
    <p>Kronecker product: Graph</p>
    <p>Intermediate stage</p>
    <p>Adjacency matrix</p>
    <p>(9x9)(3x3)</p>
  </div>
  <div class="page">
    <p>Kronecker product: Definition</p>
    <p>The Kronecker product of matrices A and B is given by</p>
    <p>We define a Kronecker product of two graphs as a Kronecker product of their adjacency matrices</p>
    <p>N x M K x L</p>
    <p>N*K x M*L</p>
  </div>
  <div class="page">
    <p>Kronecker graphs  We create the self-similar graphs recursively</p>
    <p>Start with a initiator graph G1 on N1 nodes and E1 edges</p>
    <p>The recursion will then product larger graphs G2, G3, Gk on N1k nodes</p>
    <p>We obtain a growing sequence of graphs by iterating the Kronecker product</p>
  </div>
  <div class="page">
    <p>Kronecker product: Graph</p>
    <p>Continuing multypling with G1 we obtain G4 and so on</p>
    <p>G4 adjacency matrix</p>
  </div>
  <div class="page">
    <p>Stochastic Kronecker graphs</p>
    <p>Create N1N1 probability matrix 1  Compute the kth Kronecker power k  For each entry puv of k include an</p>
    <p>edge (u,v) with probability puv</p>
    <p>1</p>
    <p>Instance</p>
    <p>matrix K2</p>
    <p>2=11</p>
    <p>For each puv flip Bernoulli</p>
    <p>coin</p>
    <p>Kronecker</p>
    <p>multiplication</p>
    <p>Probability of edge puv</p>
  </div>
  <div class="page">
    <p>Kronecker graphs: Intuition</p>
    <p>nodes from different communities</p>
    <p>[likes ice cream, likes chocolate]  u=[1,0], v=[1, 1]</p>
    <p>Parameter matrix gives the linking probability  p(u,v) = 0.5 * 0.1 = 0.05</p>
    <p>1</p>
  </div>
  <div class="page">
    <p>Properties of Kronecker graphs</p>
    <p>We prove that Kronecker multiplication generates graphs that obey [PKDD05]  Properties of static networks</p>
    <p>Power Law Degree Distribution Power Law eigenvalue and eigenvector distribution Small Diameter</p>
    <p>Properties of dynamic networks Densification Power Law Shrinking/Stabilizing Diameter</p>
    <p>Good news: Kronecker graphs have the necessary expressive power</p>
    <p>But: How do we choose the parameters to match all of these at once?</p>
  </div>
  <div class="page">
    <p>Model estimation: approach</p>
    <p>Maximum likelihood estimation  Given real graph G  Estimate Kronecker initiator graph  (e.g., )</p>
    <p>which</p>
    <p>We need to (efficiently) calculate</p>
    <p>And maximize over  (e.g., using gradient descent)</p>
    <p>)|( GP</p>
    <p>)|(maxarg</p>
    <p>GP</p>
  </div>
  <div class="page">
    <p>Fitting Kronecker graphs  Given a graph G and Kronecker matrix  we</p>
    <p>calculate probability that  generated G P(G|)</p>
    <p>k</p>
    <p>G P(G|)</p>
    <p>]),[1(],[)|( ),(),(</p>
    <p>vuvuGP k Gvu</p>
    <p>k Gvu</p>
    <p>G</p>
  </div>
  <div class="page">
    <p>Nodes are unlabeled</p>
    <p>Graphs G and G should have the same probability</p>
    <p>P(G|) = P(G|)</p>
    <p>One needs to consider all node correspondences</p>
    <p>All correspondences are a priori equally likely</p>
    <p>There are O(N!) correspondences</p>
    <p>Challenge 1: Node correspondence</p>
    <p>)(),|()|(</p>
    <p>PGPGP   1 0 1 1</p>
    <p>G</p>
    <p>G</p>
    <p>P(G|) = P(G|)</p>
    <p>k</p>
  </div>
  <div class="page">
    <p>Challenge 2: calculating P(G|,)</p>
    <p>Assume we solved the correspondence problem</p>
    <p>Calculating</p>
    <p>Takes O(N2) time</p>
    <p>Infeasible for large graphs (N ~ 105) 0.25 0.10 0.10 0.04</p>
    <p>node labeling</p>
    <p>G P(G|, )</p>
    <p>kc</p>
    <p>]),[1(],[)|( ),(),(</p>
    <p>vuk Gvu</p>
    <p>vuk Gvu</p>
    <p>GP</p>
  </div>
  <div class="page">
    <p>Model estimation: solution</p>
    <p>Navely estimating the Kronecker initiator takes O(N!N2) time:  N! for graph isomorphism</p>
    <p>Metropolis sampling: N!  (big) const</p>
    <p>N2 for traversing the graph adjacency matrix  Properties of Kronecker product and sparsity</p>
    <p>(E &lt;&lt; N2): N2 E</p>
    <p>We can estimate the parameters of Kronecker graph in linear time O(E)</p>
  </div>
  <div class="page">
    <p>Solution 1: Node correspondence</p>
    <p>Log-likelihood</p>
    <p>Gradient of log-likelihood</p>
    <p>Sample the permutations from P(| G,) and average the gradients</p>
  </div>
  <div class="page">
    <p>Sampling node correspondences  Metropolis sampling:</p>
    <p>Start with a random permutation  Do local moves on the permutation  Accept the new permutation</p>
    <p>If new permutation is better (gives higher likelihood)  If new is worse accept with probability proportional to</p>
    <p>the ratio of likelihoods</p>
    <p>Swap node labels 1 and 4</p>
    <p>Can compute efficiently: Only need to account for changes in 2 rows / columns</p>
    <p>Re-evaluate the likelihood</p>
  </div>
  <div class="page">
    <p>Solution 2: Calculating P(G|,)</p>
    <p>Calculating naively P(G|,) takes O(N2)</p>
    <p>Idea:  First calculate likelihood of empty graph, a</p>
    <p>graph with 0 edges</p>
    <p>Correct the likelihood for edges that we observe in the graph</p>
    <p>By exploiting the structure of Kronecker product we obtain closed form for likelihood of an empty graph</p>
  </div>
  <div class="page">
    <p>Solution 2: Calculating P(G|,)</p>
    <p>We approximate the likelihood:</p>
    <p>The sum goes only over the edges  Evaluating P(G|,) takes O(E) time  Real graphs are sparse, E &lt;&lt; N2</p>
    <p>No-edge likelihood Edge likelihoodEmpty graph</p>
  </div>
  <div class="page">
    <p>Experiments: synthetic data</p>
    <p>Can gradient descent recover true parameters?</p>
    <p>Optimization problem is not convex  How nice (without local minima) is</p>
    <p>optimization space?  Generate a graph from random parameters  Start at random point and use gradient</p>
    <p>descent  We recover true parameters 98% of the times</p>
  </div>
  <div class="page">
    <p>Convergence of properties  How does algorithm converge to true</p>
    <p>parameters with gradient descent iterations?</p>
    <p>D ia</p>
    <p>m e</p>
    <p>te r</p>
    <p>Gradient descent iterations</p>
    <p>ig e</p>
    <p>n va</p>
    <p>lu e</p>
    <p>L o</p>
    <p>g -l</p>
    <p>ik e lih</p>
    <p>o o d</p>
    <p>A vg</p>
    <p>a b</p>
    <p>s e</p>
    <p>rr o r</p>
    <p>Gradient descent iterations</p>
  </div>
  <div class="page">
    <p>Experiments: real networks</p>
    <p>Experimental setup:  Given real graph  Stochastic gradient descent from random</p>
    <p>initial point  Obtain estimated parameters  Generate synthetic graphs  Compare properties of both graphs</p>
    <p>We do not fit the properties themselves  We fit the likelihood and then compare the</p>
    <p>graph properties</p>
  </div>
  <div class="page">
    <p>AS graph (N=6500, E=26500)</p>
    <p>Autonomous systems (internet)</p>
    <p>We search the space of ~1050,000 permutations  Fitting takes 20 minutes</p>
    <p>AS graph is undirected and estimated parameter matrix is symmetric:</p>
  </div>
  <div class="page">
    <p>Generate synthetic graph using estimated parameters</p>
    <p>Compare the properties of two graphs</p>
    <p>AS: comparing graph properties</p>
    <p>Degree distribution Hop plot</p>
    <p>log degree</p>
    <p>lo g</p>
    <p>c o u n t</p>
    <p>number of hops</p>
    <p>lo g #</p>
    <p>o f</p>
    <p>re a ch</p>
    <p>ab le</p>
    <p>p a ir</p>
    <p>s diameter=4</p>
  </div>
  <div class="page">
    <p>AS: comparing graph properties</p>
    <p>Network valueScree plot</p>
    <p>log rank</p>
    <p>lo g</p>
    <p>e ig</p>
    <p>en va</p>
    <p>lu e</p>
    <p>log rank</p>
    <p>lo g v</p>
    <p>a lu</p>
    <p>e</p>
    <p>Spectral properties of graph adjacency matrices</p>
  </div>
  <div class="page">
    <p>Epinions graph (N=76k, E=510k)</p>
    <p>We search the space of ~101,000,000 permutations</p>
    <p>Fitting takes 2 hours</p>
    <p>The structure of the estimated parameter gives insight into the structure of the graph</p>
    <p>Degree distribution Hop plot</p>
    <p>log degree</p>
    <p>lo g c</p>
    <p>o u n t</p>
    <p>number of hops</p>
    <p>lo g #</p>
    <p>o f</p>
    <p>re a ch</p>
    <p>a b le</p>
    <p>p a ir</p>
    <p>s</p>
  </div>
  <div class="page">
    <p>Epinions graph (N=76k, E=510k)</p>
    <p>Network valueScree plot</p>
    <p>log rank</p>
    <p>lo g e</p>
    <p>ig en</p>
    <p>va lu</p>
    <p>e</p>
    <p>log rank</p>
  </div>
  <div class="page">
    <p>Scalability</p>
    <p>Fitting scales linearly with the number of edges</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Kronecker Graph model has  provable properties  small number of parameters</p>
    <p>We developed scalable algorithms for fitting Kronecker Graphs</p>
    <p>We can efficiently search large space (~101,000,000) of permutations</p>
    <p>Kronecker graphs fit well real networks using few parameters</p>
    <p>We match graph properties without a priori deciding on which ones to fit</p>
  </div>
  <div class="page">
    <p>References</p>
    <p>Graphs over Time: Densification Laws, Shrinking Diameters and Possible Explanations, by Jure Leskovec, Jon Kleinberg, Christos Faloutsos, ACM KDD 2005</p>
    <p>Graph Evolution: Densification and Shrinking Diameters, by Jure Leskovec, Jon Kleinberg and Christos Faloutsos, ACM TKDD 2007</p>
    <p>Realistic, Mathematically Tractable Graph Generation and Evolution, Using Kronecker Multiplication, by Jure Leskovec, Deepay Chakrabarti, Jon Kleinberg and Christos Faloutsos, PKDD 2005</p>
    <p>Scalable Modeling of Real Graphs using Kronecker Multiplication, by Jure Leskovec and Christos Faloutsos, ICML 2007</p>
    <p>Acknowledgements: Christos Faloutsos, Jon Kleinberg, Zoubin Gharamani, Pall Melsted, Alan Frieze, Larry Wasserman, Carlos Guestrin, Deepay Chakrabarti</p>
  </div>
</Presentation>
