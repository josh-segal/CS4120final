<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>GPUnet: networking abstractions for GPU programs</p>
    <p>Mark Silberstein Technion  Israel Institute of Technology</p>
    <p>Amir Wated Technion</p>
    <p>Sangman Kim, Seonggu Huh, Xinya Zhang Yige Hu, Emmett Witchel University of Texas at Austin</p>
  </div>
  <div class="page">
    <p>What A socket API for programs running on GPU</p>
    <p>Why GPU-accelerated servers are hard to build</p>
    <p>Results</p>
    <p>GPU vs. CPU 50% throughput, 60% latency,  LOC</p>
  </div>
  <div class="page">
    <p>Motivation: GPU-accelerated networking applications</p>
    <p>Data processing server Data processing server</p>
    <p>GPU GPUGPU</p>
    <p>MapReduceMapReduce</p>
    <p>GPU</p>
    <p>GPU</p>
    <p>GPU</p>
    <p>GPU</p>
  </div>
  <div class="page">
    <p>Recent GPU-accelerated networking applications</p>
    <p>SSLShader (Jang 2011), GPU MapReduce (Stuart 2011), Deep Neural Networks (Coates 2013), Dandelion (Rossbach 2013), Rhythm (Agrawal 2014) ...</p>
  </div>
  <div class="page">
    <p>required heroic efforts</p>
    <p>SSLShader (Jang 2011), GPU MapReduce (Stuart 2011), Deep Neural Networks (Coates 2013), Dandelion (Rossbach 2013), Rhythm (Agrawal 2014) ...</p>
    <p>Recent GPU-accelerated networking applications</p>
  </div>
  <div class="page">
    <p>GPU-accelerated networking apps: Recurring themes</p>
    <p>Request batching</p>
    <p>NIC-GPU interaction</p>
    <p>Pipelining and</p>
    <p>buffer management</p>
  </div>
  <div class="page">
    <p>GPU-accelerated networking apps: Recurring themes</p>
    <p>Request batching</p>
    <p>CPU-GPU-NIC Pipelining</p>
    <p>NIC-GPU interaction</p>
    <p>We will sidestep these problems</p>
  </div>
  <div class="page">
    <p>The real problem: CPU is the only boss</p>
    <p>GPU</p>
    <p>NIC</p>
    <p>Storage</p>
    <p>CPU</p>
  </div>
  <div class="page">
    <p>Example: CPU server</p>
    <p>CPU</p>
    <p>NIC Memory</p>
    <p>compute()</p>
    <p>recv()</p>
    <p>send()</p>
  </div>
  <div class="page">
    <p>Inside a GPU-accelerated server</p>
    <p>CPU GPU</p>
    <p>NIC Memory Memory</p>
    <p>PCIe bus</p>
    <p>GPU_compute()</p>
    <p>recv()</p>
    <p>send()</p>
    <p>Theory</p>
    <p>GPU_compute()</p>
    <p>recv()</p>
    <p>send()</p>
    <p>Theory</p>
  </div>
  <div class="page">
    <p>Inside a GPU-accelerated server</p>
    <p>CPU GPU</p>
    <p>NIC Memory Memory</p>
    <p>recv();</p>
    <p>recv(); batch();</p>
    <p>GPU_compute()</p>
    <p>recv()</p>
    <p>send()</p>
    <p>Theory</p>
  </div>
  <div class="page">
    <p>Inside a GPU-accelerated server</p>
    <p>CPU GPU</p>
    <p>NIC Memory Memory</p>
    <p>transfer();</p>
    <p>recv(); batch(); optimize(); transfer();</p>
    <p>GPU_compute()</p>
    <p>recv()</p>
    <p>send()</p>
    <p>Theory</p>
  </div>
  <div class="page">
    <p>Inside a GPU-accelerated server</p>
    <p>CPU</p>
    <p>NIC Memory Memory</p>
    <p>invoke();</p>
    <p>recv(); batch(); optimize(); transfer(); balance();</p>
    <p>GPU_compute(); GPU_compute()</p>
    <p>recv()</p>
    <p>send()</p>
    <p>GPU_compute()</p>
    <p>Theory</p>
  </div>
  <div class="page">
    <p>Inside a GPU-accelerated server</p>
    <p>CPU GPU</p>
    <p>NIC Memory Memory</p>
    <p>transfer();</p>
    <p>recv(); batch(); optimize(); transfer(); balance();</p>
    <p>GPU_compute(); transfer(); cleanup();</p>
    <p>GPU_compute()</p>
    <p>recv()</p>
    <p>send()</p>
    <p>GPU_compute()</p>
    <p>Theory</p>
  </div>
  <div class="page">
    <p>Inside a GPU-accelerated server</p>
    <p>CPU GPU</p>
    <p>NIC Memory Memory</p>
    <p>send();</p>
    <p>recv(); batch(); optimize(); transfer(); balance();</p>
    <p>transfer(); cleanup(); dispatch();</p>
    <p>send();</p>
    <p>GPU_compute()</p>
    <p>recv()</p>
    <p>send()</p>
    <p>GPU_compute()</p>
    <p>Theory</p>
  </div>
  <div class="page">
    <p>Inside a GPU-accelerated server</p>
    <p>CPU</p>
    <p>NIC Memory Memory</p>
    <p>Aggressive pipelining Double buffering, asynchrony, multithreading</p>
    <p>recv(); batch(); optimize(); transfer(); balance();</p>
    <p>GPU_compute(); transfer(); cleanup(); dispatch();</p>
    <p>send();</p>
    <p>recv(); batch(); optimize(); transfer(); balance();</p>
    <p>GPU_compute(); transfer(); cleanup(); dispatch();</p>
    <p>send();</p>
    <p>recv(); batch(); optimize(); transfer(); balance();</p>
    <p>GPU_compute(); transfer(); cleanup(); dispatch();</p>
    <p>send();</p>
    <p>recv(); batch(); optimize(); transfer(); balance();</p>
    <p>GPU_compute(); transfer(); cleanup(); dispatch();</p>
    <p>send();</p>
    <p>GPU_compute()GPU_compute()</p>
    <p>recv()</p>
    <p>send()</p>
  </div>
  <div class="page">
    <p>recv(); batch(); optimize(); transfer(); balance();</p>
    <p>GPU_compute(); transfer(); cleanup(); dispatch();</p>
    <p>send();</p>
    <p>recv(); batch(); optimize(); transfer(); balance();</p>
    <p>GPU_compute(); transfer(); cleanup(); dispatch();</p>
    <p>send();</p>
    <p>recv(); batch(); optimize(); transfer(); balance();</p>
    <p>GPU_compute(); transfer(); cleanup(); dispatch();</p>
    <p>send();</p>
    <p>GPU_compute()</p>
    <p>This code is for a CPU to manage a GPU</p>
    <p>batch(); optimize(); transfer(); balance();</p>
    <p>transfer(); cleanup(); dispatch();</p>
  </div>
  <div class="page">
    <p>GPUs are not co-processors</p>
    <p>GPUs are peer-processors</p>
    <p>They need I/O abstractions</p>
    <p>File system I/O  [GPUfs ASPLOS13] Network I/O  this work</p>
  </div>
  <div class="page">
    <p>GPUnet: socket API for GPUs Application view</p>
    <p>socket(AF_INET,SOCK_STREAM); connect(node0:2340);</p>
    <p>socket(AF_INET,SOCK_STREAM); connect(node0:2340)</p>
    <p>GPUnet</p>
    <p>GPU nativenative client</p>
    <p>socket(AF_INET,SOCK_STREAM); listen(:2340)</p>
    <p>GPU nativenative server</p>
    <p>node0.technion.ac.il</p>
    <p>GPUnet</p>
    <p>CPU client</p>
    <p>Network</p>
  </div>
  <div class="page">
    <p>GPU-accelerated server with GPUnet</p>
    <p>CPU GPU</p>
    <p>NIC Memory Memory</p>
    <p>PCIe bus</p>
    <p>CPU not involved</p>
    <p>GPU_compute()</p>
    <p>recv()</p>
    <p>send()</p>
  </div>
  <div class="page">
    <p>GPU-accelerated server with GPUnet</p>
    <p>GPU</p>
    <p>NIC Memory</p>
    <p>PCIe bus</p>
    <p>GPU_compute()</p>
    <p>recv()</p>
    <p>send()</p>
  </div>
  <div class="page">
    <p>GPU-accelerated server with GPUnet</p>
    <p>NIC Memory</p>
    <p>send() recv()</p>
    <p>No request batching</p>
    <p>GPU_compute()</p>
    <p>recv()</p>
    <p>send() GPU_compute()</p>
    <p>recv()</p>
    <p>send() GPU_compute()</p>
    <p>recv()</p>
    <p>send()</p>
  </div>
  <div class="page">
    <p>GPU-accelerated server with GPUnet</p>
    <p>NIC Memory</p>
    <p>send() recv()</p>
    <p>Automatic request pipelining</p>
    <p>Automatic buffer managementGPU_compute()</p>
    <p>recv()</p>
    <p>send() GPU_compute()</p>
    <p>recv()</p>
    <p>send() GPU_compute()</p>
    <p>recv()</p>
    <p>send()</p>
  </div>
  <div class="page">
    <p>Building a socket abstraction for GPUs</p>
  </div>
  <div class="page">
    <p>Goals</p>
    <p>CPU GPU recv()</p>
    <p>NIC Memory Memory</p>
    <p>PCIe bus</p>
    <p>Simplicity Reliable streaming</p>
    <p>abstraction for GPUs</p>
    <p>Performance NIC  GPU</p>
    <p>data path optimizations</p>
  </div>
  <div class="page">
    <p>Memory</p>
    <p>Design option 1: Transport layer processing on CPU</p>
    <p>CPU GPU recv()</p>
    <p>NIC</p>
    <p>Network buffers</p>
    <p>Transport processing GPU controls</p>
    <p>the flow of data</p>
  </div>
  <div class="page">
    <p>Memory</p>
    <p>Design option 1: Transport layer processing on CPU</p>
    <p>CPU GPU recv()</p>
    <p>NIC Extra CPU-GPU memory transfers</p>
    <p>Network buffers</p>
    <p>Transport processing</p>
  </div>
  <div class="page">
    <p>Design option 2: Transport layer processing on GPU</p>
    <p>CPU GPU</p>
    <p>NIC</p>
    <p>Memory</p>
    <p>P2P DMAP2P DMA</p>
    <p>recv()</p>
    <p>Network buffers</p>
    <p>Transport processing</p>
  </div>
  <div class="page">
    <p>Design option 2: Transport layer processing on GPU</p>
    <p>CPU GPU</p>
    <p>NIC</p>
    <p>P2P DMA</p>
    <p>recv()</p>
    <p>CPU applications access network through GPU?</p>
    <p>TCP/IP on GPU?Network</p>
    <p>buffers</p>
    <p>Transport processing</p>
  </div>
  <div class="page">
    <p>Not CPU, Not GPU</p>
    <p>We need help from NIC hardware</p>
  </div>
  <div class="page">
    <p>RDMA: offloading transport layer processing to NIC</p>
    <p>CPU GPU</p>
    <p>NIC</p>
    <p>Message buffers</p>
    <p>Message buffers</p>
    <p>Streaming</p>
    <p>Reliable RDMA</p>
    <p>Streaming</p>
  </div>
  <div class="page">
    <p>GPUnet layers</p>
    <p>Reliable channel</p>
    <p>Reliable in-order streaming</p>
    <p>GPU Socket API</p>
    <p>Non-RDMA Transports UNIX Domain Socket, TCP/IP</p>
    <p>RDMA Transports Infiniband</p>
  </div>
  <div class="page">
    <p>GPUnet layers</p>
    <p>Reliable channel</p>
    <p>Reliable in-order streaming</p>
    <p>GPU Socket API</p>
    <p>GPU</p>
    <p>NIC CPU</p>
    <p>Simplicity</p>
    <p>Performance</p>
    <p>Non-RDMA Transports UNIX Domain Socket, TCP/IP</p>
    <p>RDMA Transports Infiniband</p>
  </div>
  <div class="page">
    <p>See the paper for</p>
    <p>Coalesced API calls  Latency-optimized GPU-CPU flow control  Memory management  Bounce buffers  Non-RDMA support  GPU performance optimizations</p>
  </div>
  <div class="page">
    <p>Implementation</p>
    <p>Standard API calls, blocking/nonblocking  libGPUnet.a: AF_INET, Streaming over</p>
    <p>Infiniband RDMA  Fully compatible with CPU rsocket library</p>
    <p>libUNIXnet.a: AF_LOCAL: Unix Domain Sockets support for inter GPU/CPU-GPU</p>
  </div>
  <div class="page">
    <p>Implementation</p>
    <p>GPU GPU application</p>
    <p>GPUnet socket library</p>
    <p>CPU</p>
    <p>Network buffers</p>
    <p>Flow control</p>
    <p>GPUnet proxy</p>
    <p>Bounce buffers</p>
    <p>GPU memoryNIC CPU memory</p>
    <p>fallback</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Analysis of GPU-native server design  Matrix product server</p>
    <p>In-GPU-memory MapReduce  Face verification server</p>
  </div>
  <div class="page">
    <p>In-GPU-memory MapReduce</p>
    <p>Sort Reduce</p>
    <p>Map</p>
    <p>GPU</p>
    <p>GPUnet</p>
    <p>GPUfs</p>
    <p>Map</p>
    <p>GPU</p>
    <p>Receiver Receiver</p>
    <p>Sort Reduce</p>
  </div>
  <div class="page">
    <p>In-GPU-memory MapReduce: Scalability</p>
    <p>K-means 5.6 sec 1.6 sec (3.5x)</p>
    <p>Word-count 29.6 sec 10 sec (2.9x)</p>
    <p>GPUnet enables scale-out for GPU  accelerated systems</p>
  </div>
  <div class="page">
    <p>Face verification server</p>
    <p>= ?</p>
    <p>memcached (unmodified) via rsocket</p>
    <p>GPU server (GPUnet)</p>
    <p>CPU client (unmodified) via rsocket</p>
    <p>recv() features() query_DB() compare() send()</p>
    <p>Infiniband</p>
    <p>GPU_features()</p>
    <p>GPU_compare()</p>
  </div>
  <div class="page">
    <p>Face verification: Different implementations</p>
    <p>CPU 6 cores</p>
    <p>L a</p>
    <p>te n</p>
    <p>cy</p>
    <p>( se</p>
    <p>c)</p>
    <p>Throughput (KReq/sec)</p>
    <p>Median</p>
  </div>
  <div class="page">
    <p>Face verification: Different implementations</p>
    <p>CPU 6 cores</p>
    <p>L a</p>
    <p>te n</p>
    <p>cy</p>
    <p>( se</p>
    <p>c)</p>
    <p>Throughput (KReq/sec)</p>
    <p>Median</p>
    <p>LOC</p>
  </div>
  <div class="page">
    <p>Face verification: Different implementations</p>
    <p>CPU 6 cores</p>
    <p>L a</p>
    <p>te n</p>
    <p>cy</p>
    <p>( se</p>
    <p>c)</p>
    <p>Throughput (KReq/sec)</p>
    <p>Median</p>
  </div>
  <div class="page">
    <p>Face verification on all processors 2xGPU + 10xCPU</p>
    <p>L a</p>
    <p>te n</p>
    <p>cy</p>
    <p>( se</p>
    <p>c)</p>
    <p>Latency optimized</p>
    <p>Throughput (KReq/sec)</p>
    <p>Similar latency 4.5x throughput CPU</p>
    <p>Throughput optimized</p>
  </div>
  <div class="page">
    <p>Set GPUs free!</p>
    <p>mark@ee.technion.ac.il</p>
    <p>CPU</p>
    <p>GPU</p>
    <p>CPU GPUGPUnet</p>
    <p>GPUnet is a library providing networking abstractions for GPUs</p>
    <p>https://github.com/ut-osa/gpunet</p>
  </div>
</Presentation>
