<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Impact of High Performance Sockets on Data Intensive</p>
    <p>Applications</p>
    <p>Pavan Balaji, Jiesheng Wu,</p>
    <p>D.K. Panda,</p>
    <p>CIS Department</p>
    <p>The Ohio State University</p>
    <p>Tahsin Kurc, Umit Catalyurek,</p>
    <p>Joel Saltz,</p>
    <p>BMI Department</p>
    <p>The Ohio State University</p>
  </div>
  <div class="page">
    <p>Presentation Layout</p>
    <p>Motivation and Background</p>
    <p>Sockets Implementations</p>
    <p>DataCutter Library</p>
    <p>Experimental Results</p>
    <p>Conclusions and Future Work</p>
  </div>
  <div class="page">
    <p>Background</p>
    <p>Data Intensive Applications  Communication Intensive; I/O Intensive</p>
    <p>Require Guarantees in Performance</p>
    <p>Scalability with guarantees</p>
    <p>Adaptability to Heterogeneous Networks</p>
    <p>Several of them are built over TCP/IP</p>
    <p>Times have changed  Faster networks available (cLAN, InfiniBand)</p>
    <p>Faster protocols available (VIA, EMP)</p>
  </div>
  <div class="page">
    <p>Motivation  High Performance Sockets Layers</p>
    <p>Take advantage of faster networks [balaji02, shah99]  No changes to the applications  Bottleneck: Design of Applications based on TCP/IP Communication</p>
    <p>Questions  Can a high performance substrate allow the implementation of a scalable interactive</p>
    <p>data-intensive application with performance guarantees to the end user?</p>
    <p>Can a high performance substrate improve the adaptability of data-intensive</p>
    <p>applications to heterogeneous environments?</p>
    <p>High Performance User-Level Sockets over Gigabit Ethernet, Pavan Balaji, Piyush Shivam, Pete Wyckoff and D. K. Panda, Cluster 2002, Chicago</p>
    <p>High Performance Sockets and RPC over Virtual Interface (VI) Architecture, H. V. Shah, C. Pu and R. S. M., CANPC workshop 1999.</p>
  </div>
  <div class="page">
    <p>Latency with Bandwidth Constraint TCP</p>
    <p>B a n d w i d t h</p>
    <p>Message Size</p>
    <p>TCP</p>
    <p>VIA</p>
    <p>L a t e n c y</p>
    <p>Message Size</p>
    <p>01</p>
    <p>Reqd BW</p>
    <p>0</p>
    <p>0</p>
    <p>1</p>
    <p>1</p>
    <p>2</p>
    <p>VIA</p>
    <p>Latency Vs Message Size is studied</p>
    <p>Latency Vs Bandwidth is relevant for performance guarantees</p>
  </div>
  <div class="page">
    <p>An Example</p>
    <p>TCP</p>
    <p>VIA</p>
    <p>01</p>
    <p>Reqd BW</p>
    <p>01</p>
    <p>VIA</p>
    <p>TCP</p>
    <p>Image rendering should be interactive</p>
    <p>Response times should be small</p>
  </div>
  <div class="page">
    <p>Pipelining: Computation/Communication Overlap</p>
    <p>L a t e n c y</p>
    <p>Message Size (log Scale)</p>
    <p>TCP</p>
    <p>VIA</p>
    <p>Computation</p>
    <p>01</p>
    <p>Compute Nodes</p>
    <p>Linear Computation with Message Size</p>
    <p>Root Node</p>
  </div>
  <div class="page">
    <p>An Example</p>
    <p>Root Node</p>
    <p>Linear Computation with Message Size</p>
    <p>Consider for perfect pipelining</p>
    <p>TCP requires 16KB message size</p>
    <p>VIA requires 2KB message size</p>
    <p>Say the computation function takes 1 sec/KB</p>
    <p>Each computation step takes</p>
    <p>16 secs for TCP</p>
    <p>2 secs for VIA</p>
    <p>Compute Nodes</p>
    <p>Say, a node becomes slower by a factor of 2</p>
    <p>Time taken by compute node</p>
    <p>(16 * 2) = 32 secs for TCP</p>
    <p>Increases by 16 seconds</p>
    <p>(2 * 2) = 4 secs for VIA</p>
    <p>Increases by 2 seconds</p>
  </div>
  <div class="page">
    <p>Presentation Layout</p>
    <p>Motivation and Background</p>
    <p>Sockets Implementations</p>
    <p>DataCutter Library</p>
    <p>Experimental Results</p>
    <p>Conclusions and Future Work</p>
  </div>
  <div class="page">
    <p>Sockets Implementations</p>
    <p>NIC</p>
    <p>IP</p>
    <p>TCP</p>
    <p>Sockets</p>
    <p>Application</p>
    <p>VI aware NIC</p>
    <p>IP</p>
    <p>TCP</p>
    <p>Sockets</p>
    <p>Application</p>
    <p>IP-to-VI layer</p>
    <p>GigaNet cLAN NIC</p>
    <p>Sockets over VIA</p>
    <p>Application or Library</p>
    <p>OS Agent</p>
    <p>VIPL</p>
    <p>Pros</p>
    <p>High Compatibility</p>
    <p>Cons</p>
    <p>Kernel Context Switches</p>
    <p>Multiple Copies</p>
    <p>CPU Resources</p>
    <p>Traditional Berkeley Sockets</p>
    <p>GigaNet Sockets (LANE)</p>
    <p>SocketVIA</p>
    <p>Kernel Context Switches</p>
    <p>Multiple Copies</p>
    <p>CPU Resources</p>
    <p>High Performance</p>
  </div>
  <div class="page">
    <p>Experimental Setup</p>
    <p>16 Dell Precision 420 Nodes  Dual 1 GHz PIII Processors</p>
    <p>32bit 33MHz PCI bus</p>
    <p>512MB SDRAM and 256K L2-level cache</p>
    <p>Linux kernel version 2.2.17</p>
    <p>GigaNet cLAN NICs  cLAN 1000 Host Adapters</p>
    <p>cLAN 5300 Cluster switches</p>
  </div>
  <div class="page">
    <p>Performance of SocketVIA Vs TCP</p>
    <p>Latency: TCP (45us), VIA (9us), SocketVIA (9.5us)</p>
    <p>Bandwidth: TCP (510Mbps), VIA (790Mbps), SocketVIA (763Mbps)</p>
  </div>
  <div class="page">
    <p>Presentation Layout</p>
    <p>Motivation and Background</p>
    <p>Sockets Implementations</p>
    <p>DataCutter Library</p>
    <p>Experimental Results</p>
    <p>Conclusions and Future Work</p>
  </div>
  <div class="page">
    <p>DataCutter Software Support for Data Driven Applications</p>
    <p>Component Framework for Combined Task/Data Parallelism</p>
    <p>User defines sequence of pipelined components (filters and filter groups)  Stream based communication</p>
    <p>User directive tells preprocessor/runtime system to generate and instantiate copies of filters</p>
    <p>Flow control between transparent filter copies  Replicated individual filters  Transparent: single stream illusion</p>
    <p>http://www.datacutter.org</p>
  </div>
  <div class="page">
    <p>DataCutter Library</p>
    <p>NIC</p>
    <p>IP</p>
    <p>TCP</p>
    <p>Sockets</p>
    <p>DataCutter Library</p>
    <p>Applications</p>
    <p>GigaNet cLAN NIC</p>
    <p>Sockets over VIA</p>
    <p>DataCutter Library</p>
    <p>OS Agent</p>
    <p>VIPL</p>
    <p>Applications</p>
  </div>
  <div class="page">
    <p>Virtual Microscope Server</p>
    <p>decompress clip subsample</p>
    <p>View</p>
    <p>Pipelining of various stages: data reading, decompress, clipping, subsampling operations can be realized as a chain of filters.</p>
    <p>Replication of filters to obtain parallelism</p>
    <p>read</p>
  </div>
  <div class="page">
    <p>Software Load Balancing Data Reading</p>
    <p>Load Balancer</p>
    <p>Slower Node</p>
  </div>
  <div class="page">
    <p>Presentation Layout</p>
    <p>Motivation and Background</p>
    <p>Sockets Implementations</p>
    <p>DataCutter Library</p>
    <p>Experimental Results</p>
    <p>Conclusions and Future Work</p>
  </div>
  <div class="page">
    <p>Experiments Conducted  Optimal Block Size</p>
    <p>Guarantee on Updates per Second (Complete Image)</p>
    <p>Guarantee on Latency of Partial Update (Moving the Image)</p>
    <p>Round Robin Load Balancing</p>
    <p>Demand Driven Load Balancing</p>
  </div>
  <div class="page">
    <p>Effects of Guarantees on Updates per Second (Complete Images)</p>
    <p>SocketVIA performs better  TCP cant give guarantees &gt; 3.25</p>
    <p>but  Limited improvement</p>
    <p>Design Decisions are bottlenecks</p>
    <p>Re-sizing of data blocks  Try to alleviate the bottlenecks</p>
    <p>Only concern is Updates per Second</p>
    <p>Achievable at low block sizes</p>
    <p>No application changes (in this case)</p>
    <p>Significant performance improvement</p>
  </div>
  <div class="page">
    <p>Effects of Guarantees on Latency of Partial Updates (Moving the Image)</p>
    <p>For High latency guarantees  Blindly using is good enough</p>
    <p>Bandwidth Saturation</p>
    <p>Pre-tuned applications</p>
    <p>For Low latency guarantees</p>
    <p>TCP is no longer in the picture</p>
    <p>Blindly using SocketVIA is not OK</p>
    <p>Resizing of blocks can help</p>
  </div>
  <div class="page">
    <p>Effect of Heterogeneous Clusters on Round Robin (RR) Scheduling</p>
    <p>Dynamic Heterogeneity  Shared Processors</p>
    <p>Process Swapping</p>
    <p>Perfect Pipelining  Complete overlap of comm. with comp.</p>
    <p>Occurs at 16KB for TCP</p>
    <p>At 2KB for VIA</p>
    <p>Scope of Error  A larger chunk to a slower node</p>
    <p>More time for complete the chunk</p>
    <p>More time for the load balancer to react</p>
  </div>
  <div class="page">
    <p>Effect of Heterogeneous Clusters on Demand Driven (DD) Scheduling</p>
    <p>Demand Driven Scheduling  Additional Latency Cost</p>
    <p>SocketVIA should perform better (?)</p>
    <p>Natural overlap of comm. with comp.</p>
    <p>Use of SocketVIA or TCP makes no diff.</p>
  </div>
  <div class="page">
    <p>Presentation Layout</p>
    <p>Motivation and Background</p>
    <p>Sockets Implementations</p>
    <p>DataCutter Library</p>
    <p>Experimental Results</p>
    <p>Conclusions and Future Work</p>
  </div>
  <div class="page">
    <p>Conclusions and Future Work  High Performance Sockets are good !</p>
    <p>Its your friend  But, use it wisely</p>
    <p>Minor changes can make a major impact  Order of magnitude performance improvement  Sustained Performance Guarantees  Fine grained Load-Balancing</p>
    <p>Higher Adaptability to Heterogeneous Networks</p>
    <p>Benefits of Parallelization over Pipelining with SocketVIA for large clusters</p>
    <p>High Performance Sockets Implementations  TCP Termination (for the DataCenter environment)  Use in DSM, DataCenter and Storage Server environments</p>
  </div>
  <div class="page">
    <p>For more information, please visit the</p>
    <p>http://nowlab.cis.ohio-state.edu</p>
    <p>Network Based Computing Group,</p>
    <p>The Ohio State University</p>
    <p>Thank You!</p>
    <p>NBC Home Page</p>
  </div>
</Presentation>
