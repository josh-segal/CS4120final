<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>2011 IBM Corporation</p>
    <p>Retrofitted Parallelism Considered Grossly Sub-Optimal</p>
    <p>HotPar '12: 4th USENIX Workshop on Hot Topics in Parallelism</p>
    <p>Paul E. McKenney, IBM Distinguished Engineer, Linux Technology Center</p>
    <p>June 8, 2012</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 2</p>
    <p>Labirinto do Outeiro do Cribo, A Armenteira, Meis, Pontevedra, Galicia, Spain. Possibly dating from as early as the Bronze Age (though rock carvings are notoriously difficult to date with certainty). 10 October 2006, Froaringus</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 3</p>
    <p>But Now We Use Computers To Solve Mazes</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 4</p>
    <p>Goals</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 5</p>
    <p>Goals (Why Was I Messing With Mazes???)</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 6</p>
    <p>Goals (Why Was I Messing With Mazes???)</p>
    <p>An example of near-perfect partitioning for Is Parallel Programming Hard, And If So, What Can You Do About It?</p>
    <p>Use case for RCU-protected union-find data structure</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 7</p>
    <p>But First, A Sequential Maze Solver</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 8</p>
    <p>Sequential Maze Solving (SEQ)</p>
    <p>Start</p>
    <p>End</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 9</p>
    <p>Sequential Maze Solving</p>
    <p>Start</p>
    <p>End</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 10</p>
    <p>Sequential Maze Solving</p>
    <p>Start</p>
    <p>End</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 11</p>
    <p>Sequential Maze Solving</p>
    <p>Start</p>
    <p>End</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 12</p>
    <p>Parallel Maze Solving: Work-Queue Approach</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 13</p>
    <p>Parallel Work Queue (PWQ)</p>
    <p>Start</p>
    <p>End</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 14</p>
    <p>Parallel Work Queue</p>
    <p>Start</p>
    <p>End</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 15</p>
    <p>Parallel Work Queue</p>
    <p>Start</p>
    <p>End</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 16</p>
    <p>Parallel Work Queue: Saved An Iteration!!!</p>
    <p>Start</p>
    <p>End</p>
    <p>But can you see the weak point?</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 17</p>
    <p>Performance Comparison: PWQ vs. SEQ</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 18</p>
    <p>Performance Comparison: PWQ vs. SEQ (Two Threads)</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 19</p>
    <p>Everything I Need to Know, I Learned in Kindergarten</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 20</p>
    <p>Everything I Need to Know, I Learned in Kindergarten</p>
    <p>In this case, when solving a maze, start at both ends!!!</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 21</p>
    <p>Partitioned Parallel Solution (PART)</p>
    <p>Start</p>
    <p>End</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 22</p>
    <p>Partitioned Parallel Solution</p>
    <p>Start</p>
    <p>End</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 23</p>
    <p>Performance Comparison: SEQ vs. PWQ vs. PART</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 24</p>
    <p>Performance Comparison: SEQ vs. PWQ vs. PART: Two Threads</p>
    <p>Lots of overlap  are these really different???</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 25</p>
    <p>Performance Comparison: SEQ vs. PWQ vs. PART</p>
    <p>The CDFs assume independence</p>
    <p>This is not true: data is highly correlated  Test script generates a maze, then runs all solvers on that same maze  CDFs lose the relationship between those solutions</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 26</p>
    <p>Performance Comparison: SEQ vs. PWQ vs. PART</p>
    <p>The CDFs assume independence</p>
    <p>This is not true: data is highly correlated  Test script generates a maze, then runs all solvers on that same maze  CDFs lose the relationship between those solutions</p>
    <p>Preserve this relationship by taking CDF of ratios  SEQ/PWQ and SEQ/PART</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 27</p>
    <p>Performance Comparison: SEQ/PWQ vs. PWQ/PART: Two Threads</p>
    <p>Anything odd about this graph?</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 28</p>
    <p>What is Going on Here???</p>
    <p>Median speedup of 4x on only two threads!!!</p>
    <p>Individual data points show speedups of up to 40x!!!</p>
    <p>This is not merely embarrassingly parallel  Embarrassingly parallel: Adding threads does not significantly</p>
    <p>increase the aggregate amount of work, resulting in linear scaling</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 29</p>
    <p>What is Going on Here???</p>
    <p>Median speedup of 4x on only two threads!!!</p>
    <p>Individual data points show speedups of up to 40x!!!</p>
    <p>This is not merely embarrassingly parallel  Embarrassingly parallel: Adding threads does not significantly</p>
    <p>increase the aggregate amount of work, resulting in linear scaling</p>
    <p>This is humiliatingly parallel</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 30</p>
    <p>What is Going on Here???</p>
    <p>Median speedup of 4x on only two threads!!!</p>
    <p>Individual data points show speedups of up to 40x!!!</p>
    <p>This is not merely embarrassingly parallel  Embarrassingly parallel: Adding threads does not significantly</p>
    <p>increase the aggregate amount of work, resulting in linear scaling</p>
    <p>This is humiliatingly parallel  Humiliatingly parallel: Adding threads significantly decreases the</p>
    <p>aggregate amount of work, resulting in superlinear scaling</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 31</p>
    <p>What is Going on Here???</p>
    <p>Median speedup of 4x on only two threads!!!</p>
    <p>Individual data points show speedups of up to 40x!!!</p>
    <p>This is not merely embarrassingly parallel  Embarrassingly parallel: Adding threads does not significantly</p>
    <p>increase the aggregate amount of work, resulting in linear scaling</p>
    <p>This is humiliatingly parallel  Humiliatingly parallel: Adding threads significantly decreases the</p>
    <p>aggregate amount of work, resulting in superlinear scaling</p>
    <p>Yeah, yeah, it is great to have a definition, but how is this happening???</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 32</p>
    <p>What is Going on Here???</p>
    <p>First assumption: there is a bug in either the solver or the data-reduction scripts</p>
    <p>There probably still is, but the solutions and times checked out</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 33</p>
    <p>What is Going on Here???</p>
    <p>First assumption: there is a bug in either the solver or the data-reduction scripts</p>
    <p>There probably still is, but the solutions and times checked out</p>
    <p>The solver also prints the fraction of cells visited  SEQ and PWQ never visited fewer than 9% for 500x500 maze</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 34</p>
    <p>What is Going on Here???</p>
    <p>First assumption: there is a bug in either the solver or the data-reduction scripts</p>
    <p>There probably still is, but the solutions and times checked out</p>
    <p>The solver also prints the fraction of cells visited  SEQ and PWQ never visited fewer than 9% for 500x500 maze  But PART sometimes visited fewer than 2%!!!</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 35</p>
    <p>Visit Fraction vs. Solution Time Correlation</p>
    <p>But correlation is not causation, nor is it why...</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 36</p>
    <p>Partitioned Parallel Solution</p>
    <p>Start</p>
    <p>End</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 37</p>
    <p>Partitioned Parallel Solution</p>
    <p>Start</p>
    <p>End</p>
    <p>The threads get in each others' way!</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 38</p>
    <p>But Why The Separation Between PWQ and PART?</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 39</p>
    <p>PWQ Has Many Potential Contention Points: Contention is Expensive</p>
    <p>Start</p>
    <p>End</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 40</p>
    <p>Does PART Always Achieve Humiliating Parallelism?</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 41</p>
    <p>Does PART Always Achieve Humiliating Parallelism?</p>
    <p>Start</p>
    <p>End</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 42</p>
    <p>Partitioning is a Powerful Parallelization Tool</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 43</p>
    <p>Partitioning is a Powerful Parallelization Tool But Let's Not Forget Sequential Optimizations!!!</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 44</p>
    <p>Partitioning is a Powerful Parallelization Tool But Let's Not Forget Sequential Optimizations!!!</p>
    <p>-O3 much better than PWQ, almost as good as PART!</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 45</p>
    <p>Compiler Optimizations Beat PWQ!!!</p>
    <p>Yes, PART is even better, but if all you need is a 2x improvement (rather than optimality), compiler optimization is an extremely attractive option</p>
    <p>These results indicate that parallel-programming research making use of high-level/overhead languages is vulnerable to invalidation given improvements in optimization</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 46</p>
    <p>And The Threads Will Get In Each Other's Way Even If They Are Running on One CPU... (Coroutines!!!)</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 47</p>
    <p>And The Threads Will Get In Each Other's Way Even If They Are Running on One CPU... (Coroutines!!!)</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 48</p>
    <p>Effect Of Maze Size</p>
    <p>Back to merely modest speedups!</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 49</p>
    <p>Effect Of Increasing Numbers of Threads</p>
    <p>Larger, older, less tightly integrated HW: Smaller speedups</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 50</p>
    <p>Summary and Conclusions</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 51</p>
    <p>How Did I Do Against My Goals?</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 52</p>
    <p>How Did I Do Against My Goals?</p>
    <p>An example of near-perfect partitioning for Is Parallel Programming Hard, And If So, What Can You Do About It</p>
    <p>Not so good!  From modestly scalable to humiliatingly parallel and back again</p>
    <p>Use case for RCU-protected union-find data structure  Not so good!  No need for RCU in this problem</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 53</p>
    <p>How Did I Do Against My Goals?</p>
    <p>An example of near-perfect partitioning for Is Parallel Programming Hard, And If So, What Can You Do About It</p>
    <p>Not so good!  From modestly scalable to humiliatingly parallel and back again</p>
    <p>Use case for RCU-protected union-find data structure  Not so good!  No need for RCU in this problem</p>
    <p>On the other hand, this problem turned out to be interesting in its own unexpected way!</p>
    <p>And a nice change of pace from Linux kernel's RCU implementation</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 54</p>
    <p>Open Questions</p>
    <p>Can other human-maze-solver techniques be applied?  Follow walls to exclude portions of maze  Choosing internal starting points based on traversal</p>
    <p>Do these results apply to unsolvable or cyclic mazes?</p>
    <p>Do other problems exhibit humiliating parallelism?</p>
    <p>Does humiliating parallelism always lead to a more-efficient sequential solution?</p>
    <p>How much current parallel-programming research can stand up to improved optimization?</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 55</p>
    <p>Open Questions</p>
    <p>Can other human-maze-solver techniques be applied?  Follow walls to exclude portions of maze  Choosing internal starting points based on traversal</p>
    <p>Do these results apply to unsolvable or cyclic mazes?</p>
    <p>Do other problems exhibit humiliating parallelism?</p>
    <p>Does humiliating parallelism always lead to a more-efficient sequential solution? (No, it does not.)</p>
    <p>How much current parallel-programming research can stand up to improved optimization?</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 56</p>
    <p>Conjecture</p>
    <p>Conjecture (Due to Jon Walpole):  Thinking from a parallel perspective leads to a much more efficient</p>
    <p>search strategy.  It is not the parallelism of the implementation that is important, but</p>
    <p>rather the parallelism of the strategy.</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 57</p>
    <p>Parting Words of Advice</p>
    <p>Apply parallelism as a first-class optimization technique  Apply at as high a level as possible, to full application  Often simplifies solution  Usually reduces synchronization overhead, thereby improving both</p>
    <p>performance and scalability</p>
    <p>In contrast, retrofitted parallelism is likely to be grossly suboptimal</p>
    <p>Especially when applied as a low-level after-the-fact optimization  Might be OK in some situations, but we can do much better</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 58</p>
    <p>Legal Statement</p>
    <p>This work represents the view of the author and does not necessarily represent the view of IBM.</p>
    <p>IBM and IBM (logo) are trademarks or registered trademarks of International Business Machines Corporation in the United States and/or other countries.</p>
    <p>Linux is a registered trademark of Linus Torvalds.</p>
    <p>Other company, product, and service names may be trademarks or service marks of others.</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation 59</p>
    <p>Questions?</p>
  </div>
</Presentation>
