<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Sparsh Mittal, Jeffrey S. Vetter</p>
    <p>EqualChance: Addressing Intraset Write Variation to Increase Lifetime of Non-volatile Caches</p>
    <p>I N F L O W</p>
    <p>O C T O B E R , 2 0 1 4</p>
    <p>C O L O R A D O , U S A</p>
  </div>
  <div class="page">
    <p>Executive Summary  Limited write endurance is a crucial limitation of NVMs</p>
    <p>Write-variation exacerbates this issue even further.</p>
    <p>We propose EqualChance, a technique to mitigate intraset write-variation in on-chip last-level caches.</p>
    <p>It periodically changes the physical block location of a data-item to achieve wear-leveling.</p>
    <p>Single core experiments, SPEC2006 and HPC workloads</p>
    <p>Results: EqualChance improves cache lifetime by 4.29X</p>
    <p>It has very small implementation and performance overhead</p>
  </div>
  <div class="page">
    <p>Motivation: Processor Design Trends</p>
    <p>Core-count is increasing</p>
    <p>LLC size is increasing</p>
    <p>Intels 32nm Sandy Bridge Core i7-3960X 15MB LLC</p>
  </div>
  <div class="page">
    <p>Motivation: Need of SRAM Alternatives</p>
    <p>SRAM Limitations</p>
    <p>Scalability challenges</p>
    <p>Huge leakage power consumption</p>
    <p>Low density</p>
    <p>SRAM caches consume huge chip area and leakage power</p>
    <p>Power consumption restricts performance scaling</p>
    <p>We need SRAM alternatives!</p>
  </div>
  <div class="page">
    <p>NVMs vis--vis SRAM and eDRAM</p>
    <p>SRAM eDRAM STT-RAM</p>
    <p>(NVM) ReRAM (NVM)</p>
    <p>PCM (NVM)</p>
    <p>Cell-size (F2) 120-200 60-100 6-50 4-10 4-12</p>
    <p>Write Endurance 1016 1016 4*1012 1011 108-109</p>
    <p>Speed Very fast Fast Fast read, slow</p>
    <p>write Fast read, slow write</p>
    <p>Slow read, very slow</p>
    <p>write</p>
    <p>Leakage Power High Medium Low Low Low</p>
    <p>Retention Period N/A 30-100 s N/A (unless</p>
    <p>relaxed) N/A N/A</p>
  </div>
  <div class="page">
    <p>NVMs vis--vis SRAM and eDRAM</p>
    <p>SRAM eDRAM STT-RAM</p>
    <p>(NVM) ReRAM (NVM)</p>
    <p>PCM (NVM)</p>
    <p>Cell-size (F2) 120-200 60-100 6-50 4-10 4-12</p>
    <p>Write Endurance 1016 1016 4*1012 1011 108-109</p>
    <p>Speed Very fast Fast Fast read, slow</p>
    <p>write Fast read, slow write</p>
    <p>Slow read, very slow</p>
    <p>write</p>
    <p>Leakage Power High Medium Low Low Low</p>
    <p>Retention Period N/A 30-100 s N/A (unless</p>
    <p>relaxed) N/A N/A</p>
    <p>The write endurance of NVMs is orders of magnitude smaller than that of SRAM/eDRAM!</p>
  </div>
  <div class="page">
    <p>Write-variation issue in caches</p>
    <p>Conventional cache management policies</p>
    <p>Optimize performance and energy.</p>
    <p>Do not account for limited write-endurance</p>
    <p>May lead to high write-variation</p>
  </div>
  <div class="page">
    <p>Write-variation issue in caches</p>
    <p>Conventional cache management policies</p>
    <p>Optimize performance and energy.</p>
    <p>Do not account for limited write-endurance</p>
    <p>May lead to high write-variation</p>
    <p>Example: on using LRU replacement policy, repeated writes happen to a hot-block</p>
    <p>This block may fail much early than remaining blocks</p>
    <p>Thus, actual lifetime may be much shorter than expected lifetime with uniform write distribution</p>
  </div>
  <div class="page">
    <p>An example from SPEC06 suite</p>
    <p>Lbm is most write-intensive among SPEC06 apps</p>
    <p>Povray has the highest intra-set and inter-set writevariation</p>
    <p>Write-magnitude of Lbm = 41X that of Povray</p>
    <p>Worst-case writes with Lbm = 1/20X that of Povary</p>
    <p>Clearly, variation in writes is more crucial issue than magnitude of writes.</p>
  </div>
  <div class="page">
    <p>EqualChance: Addressing Intra-set Write Variation to Increase</p>
    <p>Lifetime of Non-volatile Caches</p>
  </div>
  <div class="page">
    <p>EqualChance: Key Idea</p>
    <p>Conventional cache management policies aim to keep hot-data in cache as much as possible</p>
    <p>Issue: This increases writes to blocks storing those data</p>
  </div>
  <div class="page">
    <p>EqualChance: Key Idea</p>
    <p>Conventional cache management policies aim to keep hot-data in cache as much as possible</p>
    <p>Issue: This increases writes to blocks storing those data</p>
    <p>Idea: Periodically change block-location of those data</p>
    <p>Use counters to record writes on each set. After certain number of writes, swap hot data with another cold data</p>
    <p>The candidate for swap may be invalid (called Ishifting) or clean (called C-shifting)</p>
    <p>We do not swap with dirty data since this may itself be frequently written</p>
  </div>
  <div class="page">
    <p>EqualChance Wear-leveling Algorithm</p>
  </div>
  <div class="page">
    <p>Wear-leveling Algorithm 1 of 3</p>
    <p>z= way-index of write-hit block if( FlagBit[setId] is ON) { p = way-index of least recent invalid block in setId</p>
    <p>if(p is found) {</p>
    <p>Swap data of ways z and p . Do not update LRU-information } else {</p>
    <p>q = way-index of least recent clean block in setId if(q is found)</p>
    <p>Swap data of ways z and q . Do not update LRU-information else</p>
    <p>ItIsNormalWrite = TRUE }</p>
    <p>} else</p>
    <p>ItIsNormalWrite = TRUE</p>
  </div>
  <div class="page">
    <p>Wear-leveling Algorithm 2 of 3</p>
    <p>z= way-index of write-hit block if(FlagBit[setId] is ON) { p = way-index of least recent invalid block in setId</p>
    <p>if(p is found) {</p>
    <p>Swap data of ways z and p. Do not update LRU-information } else {</p>
    <p>q = way-index of least recent clean block in setId if(q is found)</p>
    <p>Swap data of ways z and q. Do not update LRU-information else</p>
    <p>ItIsNormalWrite = TRUE }</p>
    <p>} else</p>
    <p>ItIsNormalWrite = TRUE</p>
    <p>I-shifting</p>
  </div>
  <div class="page">
    <p>Wear-leveling Algorithm 3 of 3</p>
    <p>z= way-index of write-hit block if(FlagBit[setId] is ON) { p = way-index of least recent invalid block in setId</p>
    <p>if(p is found) {</p>
    <p>Swap data of ways z and p. Do not update LRU-information } else {</p>
    <p>q = way-index of least recent clean block in setId if(q is found)</p>
    <p>Swap data of ways z and q. Do not update LRU-information else</p>
    <p>ItIsNormalWrite = TRUE }</p>
    <p>} else</p>
    <p>ItIsNormalWrite = TRUE</p>
    <p>C-shifting</p>
  </div>
  <div class="page">
    <p>a0 a1 I a2 a3 a4 a5 I</p>
    <p>a0 I I a2 a3 a4 a5 a1</p>
    <p>a0 a1 I a2 a3 a4 a5 I</p>
    <p>If (write to a1 AND FlagBit ON)</p>
    <p>If (write to a1 AND</p>
    <p>FlagBit OFF) I-shifting (z=1, p=7)</p>
    <p>Normal Write (z=1)</p>
    <p>CASE 1</p>
    <p>a7</p>
    <p>LEGEND</p>
    <p>I</p>
    <p>LRU-age (0: MRU,7:LRU)</p>
    <p>Dont care (if data are invalid)</p>
    <p>Dirty/Clean (D/C) Valid/Invalid (V/I)</p>
    <p>Invalid data</p>
  </div>
  <div class="page">
    <p>a0 a1 I a2 a3 a4 a5 I</p>
    <p>a0 I I a2 a3 a4 a5 a1</p>
    <p>a0 a1 I a2 a3 a4 a5 I</p>
    <p>If (write to a1 AND FlagBit ON)</p>
    <p>If (write to a1 AND</p>
    <p>FlagBit OFF)</p>
    <p>a0 a1 a6 a2 a3 a4 a5 a7</p>
    <p>a0 a1 a5 a2 a3 a4 a6 a7</p>
    <p>If (write to a6 AND FlagBit ON)</p>
    <p>I-shifting (z=1, p=7)</p>
    <p>Normal Write (z=1)</p>
    <p>C-shifting (z=2, q=6)</p>
    <p>CASE 1</p>
    <p>CASE 2</p>
  </div>
  <div class="page">
    <p>Overhead Estimation</p>
    <p>Overhead comes due to extra counters and swap-buffer (used for data-transfer)</p>
    <p>Let N= number of sets, M = associativity, L= block size, G= # of tag-bits</p>
    <p>Overhead is &lt; 0.15% of L2 cache size</p>
    <p>A small increase in LLC latency can be easily hidden</p>
  </div>
  <div class="page">
    <p>Salient Features</p>
    <p>Can be easily integrated with write-minimization techniques</p>
    <p>No offline profiling is required.</p>
    <p>Does not increase DRAM traffic, unlike datainvalidation techniques [1] ==&gt; does not harm performance or energy</p>
    <p>Wear-leveling has the side benefit of reducing thermal density</p>
    <p>[1]. J. Wang et al. i2WAP: Improving non-volatile cache lifetime by reducing inter-and intraset write variations, HPCA 2013.</p>
  </div>
  <div class="page">
    <p>Experiments</p>
    <p>Sniper x86-64 simulator, 300M instruction</p>
    <p>Single core simulations using 4MB L2.</p>
    <p>ReRAM (resistive RAM) L2, parameters from NVsim.</p>
    <p>Baseline: Shared LRU cache with no wear-leveling</p>
    <p>We measure energy of L2 cache, main memory and algorithm.</p>
  </div>
  <div class="page">
    <p>Evaluation Metrics</p>
    <p>We show results on:</p>
    <p>Relative lifetime, relative performance and percentage energy loss</p>
    <p>Coefficient of inter-set write-variation (InterV) and intra-set write-variation (IntraV) [1]</p>
  </div>
  <div class="page">
    <p>Workloads</p>
    <p>As(astar), Bw(bwaves), Bz(bzip2), Cd(cactusADM), Ca(calculix) Dl(dealII), Ga(gamess), Gc(gcc), Gm(gemsFDTD), Gk(gobmk) Gr(gromacs), H2(h264ref), Hm(hmmer), Lb(lbm), Ls(leslie3d) Lq(libquantum), Mc(mcf), Mi(milc), Nd(namd), Om(omnetpp)</p>
    <p>Pe(perlbench), Po(povray), Sj(sjeng), So(soplex), Sp(sphinx) To(tonto), Wr(wrf), Xa(xalancbmk), Ze(zeusmp), Am(amg2013)</p>
    <p>Co(CoMD), Lu(LULESH), Mk(MCCK), Ne(Nekbone)</p>
  </div>
  <div class="page">
    <p>Results</p>
  </div>
  <div class="page">
    <p>Large IntraV in several workloads</p>
    <p>Corresponding lifetime improvement</p>
    <p>Performance and energy losses are negligible</p>
  </div>
  <div class="page">
    <p>Result Analysis</p>
    <p>EqualChance improves lifetime by 4.29X and reduces IntraV significantly</p>
    <p>Lifetime improvement depends on the intra-set write variation present in baseline program.</p>
    <p>Some programs show &gt; 10X lifetime improvement.</p>
    <p>Performance close to baseline and energy loss &lt; 2%.</p>
    <p>Parameter sensitivity results show that it works well for wide range of algorithm and system parameters.</p>
  </div>
  <div class="page">
    <p>Conclusion and Future Work</p>
    <p>We presented EqualChance for improving lifetime of NVM caches.</p>
    <p>Future Work</p>
    <p>Integration with other techniques, e.g. writeminimization.</p>
    <p>Extending to processors with tens of cores</p>
    <p>Evaluation with multithreaded workloads.</p>
  </div>
  <div class="page">
    <p>Thanks a lot!</p>
    <p>http://ft.ornl.gov</p>
    <p>mittals@ornl.gov</p>
  </div>
  <div class="page">
    <p>Extra Slides</p>
  </div>
  <div class="page"/>
  <div class="page"/>
</Presentation>
