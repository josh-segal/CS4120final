<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Application Placement and Demand Distribution in a Global Elastic Cloud: A Unified Approach</p>
  </div>
  <div class="page">
    <p>Outline Introduction  System Environment</p>
    <p>Unified Policy Computation  Assumptions  Algorithm</p>
    <p>Evaluation  Simulation  Prototype testing (not discussed  see paper)</p>
    <p>Summary</p>
  </div>
  <div class="page">
    <p>Geo-Distributed Cloud Platforms  Cloud providers deploy multiple data centers (DCs) around the world</p>
    <p>(Amazon/Google/Microsoft, etc.)  Cloud Customers (i.e., application providers) deploy applications in the</p>
    <p>cloud</p>
    <p>Unpredictable load of the hosted applications: location/volume 3</p>
    <p>e.g., DNS</p>
  </div>
  <div class="page">
    <p>Application Placement and Demand Distribution</p>
    <p>Resource auto-scaling in the cloud  Application placement  when/where to deploy an application instance  Demand distribution - how to distribute client requests among the instances  Only DC-level decisions  do not care about the number of application</p>
    <p>instances or request distribution inside data centers</p>
    <p>Existing approaches  address the two problems in isolation  Place applications assuming client requests go to closest data centers  Distribute client requests given the location of application instances  Do not consider back-end databases.</p>
    <p>Our approach  Unified: consider two problems together  Consider back-end databases  Address the scalability problem of computing a policy</p>
  </div>
  <div class="page">
    <p>Objectives</p>
    <p>Minimize overall user perceived response time  Minimize the overall network latency  Avoid data center overloading</p>
    <p>Minimize the number of application instances  Save resources and customer costs</p>
    <p>Minimize the number of placement changes  Reduce redeployment cost  Better cache behavior</p>
  </div>
  <div class="page">
    <p>Outline Introduction  System Environment</p>
    <p>Unified Policy Computation  Assumptions  Algorithm</p>
    <p>Evaluation  Simulation  Prototype testing (not discussed  see paper)</p>
    <p>Summary</p>
  </div>
  <div class="page">
    <p>Computing the Unified Policy for App Placement and Request Distribution</p>
    <p>Step I - optimal request distribution with full deployment  Full deployment - each application is deployed at each data center  Optimal request distribution - min-cost algorithm to solve centrally</p>
    <p>Step II - application placement policy  Calculate the amount of demand each data center receives for each</p>
    <p>application (from step I)  Remove underutilized instances (below some threshold)</p>
    <p>Step III  request distribution policy  Reassign demand for removed instances  Aggregate with demand for instances not removed in step II</p>
  </div>
  <div class="page">
    <p>Assumptions</p>
    <p>Client Clusters (CC): group of clients sharing the same BGP prefix (~400K, network-aware clustering [SIGCOMM2000])</p>
    <p>Fixed back-end database location  Aggregate distance -- simply sum up, though can easily be</p>
    <p>extended to more complex options  Request rate as a metric for demand and data center load and</p>
    <p>capacity  Given demand pattern -- set of request rates from each client cluster for</p>
    <p>each application  Normalized request rate for different applications  As a measurement of data center capacity</p>
    <p>Notation: A - number of applications, C - number of client clusters, D  number of data centers</p>
  </div>
  <div class="page">
    <p>I - Optimal Request Distribution with Full Deployment</p>
    <p>Minimize overall network latency  Avoid data center overloading  Limit the amount of total demand each data center receives (capacity</p>
    <p>limitation)</p>
    <p>Min-cost flow model  Source node, sink node, pair nodes (application, CC) and data center</p>
    <p>nodes  All nodes are balanced except the source and sink node  Minimize the cost when pushing all demands from source node to</p>
    <p>sink node</p>
  </div>
  <div class="page">
    <p>Simple Example</p>
    <p>Edge: cost, capacity  Supply node: generate flow (node N1)  Demand node: consume flow (node N4)  Balance node: neither (node N2 and N3)</p>
    <p>N1</p>
    <p>N2</p>
    <p>N3</p>
    <p>N4</p>
    <p>Generate 6 flow units</p>
    <p>Consume 6 flow units</p>
  </div>
  <div class="page">
    <p>Flow Model for Optimal Request Distribution</p>
    <p>Pair node (Yam)  requests from client cluster m for application a (ram )  Total amount of flow: R =</p>
    <p>=1</p>
    <p>=1</p>
    <p>Move flow R from node S to node T with the minimum cost</p>
    <p>R</p>
  </div>
  <div class="page">
    <p>Permutation Prefix Clustering</p>
    <p>Scalability issue: A*C=100*400K=4*107 pair nodes  Each pair node has permutation of preference of data centers</p>
    <p>{1,3,10,5,2,9,6,8,4,7}  Merging pair nodes sharing prefix of certain length L of their</p>
    <p>permutations - if merge Y1C and Yam to Y  Merged capacity: r=r1C+ ram  Merged cost: dn=(d1cn* r1C+ damn * ram)/( r1C+ ram )</p>
    <p>Trade-off between scalability and performance  Number of pair nodes:  (  )1=0  Performance penalty</p>
  </div>
  <div class="page">
    <p>Merged Min-Cost Flow Model</p>
    <p>Total number of pair nodes: 20  19  18 = 6840,   = 3   = 20</p>
  </div>
  <div class="page">
    <p>II - Application Placement</p>
    <p>Flow fna : amount of requests DC n receives for each application a (obtained from step I)</p>
    <p>Deletion Threshold (DT): amount of requests worthy to deploy an application instance in the data centers.</p>
    <p>Normal flows: if fna  DT  Tiny flows: if fna &lt; DT  Placement policy  Deploy application a at data center n for normal flow</p>
    <p>Remove tiny flows unless it is the only instance for the applications</p>
  </div>
  <div class="page">
    <p>Reducing Placement Changes</p>
    <p>Hysteresis placement: add stickiness to previously deployed application instances  Smaller Deletion Threshold makes it harder to remove instances</p>
    <p>Hysteresis ratio (HR): real Deletion Threshold = (Deletion Threshold) / (Hysteresis rate )</p>
    <p>High HR for previously deployed application instances (&gt;1)</p>
  </div>
  <div class="page">
    <p>III  Demand Distribution</p>
    <p>Redistribute the tiny flows (e.g., residual demand) to the data centers calculated placement policy</p>
    <p>Integrate the distribution of normal flows and tiny flows to get the final demand distribution policy</p>
  </div>
  <div class="page">
    <p>Outline Introduction  System Environment</p>
    <p>Unified Policy Computation  Assumptions  Algorithm</p>
    <p>Evaluation  Simulation  Prototype testing (not discussed  see paper)</p>
    <p>Summary</p>
  </div>
  <div class="page">
    <p>Cloud Model</p>
    <p>Gnutella clients to mimic client clusters (~100K)  Planetlab nodes (selected according to the distribution of</p>
    <p>clients) to mimic data centers (20)  Planetlab nodes (randomly selected) to mimic back-end</p>
    <p>databases (100)  ping network latency for the proximity among entities  Each data center can deal with 10,000 req/s (200,000 req/s</p>
    <p>for all data centers)</p>
  </div>
  <div class="page">
    <p>Experiment Setup</p>
    <p>Load factor, e.g., 0.5 (100,000 requests/s)  Demand of different applications follows power law</p>
    <p>distribution with parameter 1  Load generation (high-level)  For each request, select the application with power law</p>
    <p>Select the client cluster it comes from</p>
    <p>CSIM: a discrete-event simulation tool</p>
  </div>
  <div class="page">
    <p>Prefix Clustering Evaluation</p>
    <p>Performance VS scalability: prefix length 3 is a good trade-off</p>
  </div>
  <div class="page">
    <p>Scalability</p>
    <p>Execution time vs. number of applications and data centers  Keep other parameters fixed</p>
  </div>
  <div class="page">
    <p>Policy Performance  Compare with an existing method, which addressed both problems</p>
    <p>heuristically but in isolation  Update policy every 30 sec, and 900 seconds for the whole experiment  Workload changes randomly between +-% from cycle to cycle (150 seconds)</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>A unified approach to deal with the application placement and demand distribution problems together based on min-cost flow model</p>
    <p>Clustering technique to deal with the scalability issue  Evaluations show that this approach is scalable and very</p>
    <p>effective</p>
  </div>
  <div class="page">
    <p>Thank you!</p>
  </div>
</Presentation>
