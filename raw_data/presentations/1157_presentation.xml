<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>QZFS: QAT Accelerated Compression in File System for Application Agnostic and Cost Efficient Data Storage</p>
    <p>Xiaokang Hu1,2, Fuzong Wang1,2, Weigang Li2, Jian Li1, Haibing Guan1</p>
  </div>
  <div class="page">
    <p>Background</p>
    <p>NVMe SSDs</p>
    <p>Accelerators (GPU, FPGA, ASIC)</p>
    <p>High-speed</p>
    <p>Storage I/O</p>
    <p>High-performance</p>
    <p>Computing (HPC) Offloading to</p>
    <p>free up CPU</p>
    <p>Space efficiency</p>
    <p>for lower TCO</p>
  </div>
  <div class="page">
    <p>Compression in different system layers</p>
    <p>Data Compression Acceleration</p>
    <p>Application layer</p>
    <p>most common</p>
    <p>e.g., Nginx, Hadoop</p>
    <p>File system layer</p>
    <p>benefit all applications</p>
    <p>e.g., ZFS, BTRFS</p>
    <p>Block layer</p>
    <p>file system agnostic</p>
    <p>e.g. RedHat VDO</p>
    <p>Our work: ASIC-based compression offloading</p>
    <p>Intel QuickAssist Technology (QAT)</p>
    <p>Modern ASIC for cryptography and compression</p>
    <p>Type: PCIe adapter, chipset, SOC</p>
    <p>Performance: up to 100Gbps</p>
    <p>Price: low to $32 after put into chipset</p>
  </div>
  <div class="page">
    <p>Features</p>
    <p>QZFS (QAT-Accelerated ZFS)</p>
    <p>Design highlights</p>
    <p>Seamless integration of QAT-accelerated gzip</p>
    <p>Vectored I/O for data reconstruction (memory zero copy)</p>
    <p>HW/SW switch that considers offload cost</p>
    <p>Compressibility-dependent offloading to save QAT resources</p>
    <p>ASYNC offload framework (maybe in future): further performance enhancement</p>
    <p>Transparently</p>
    <p>benefit ALL apps</p>
    <p>High</p>
    <p>performance</p>
    <p>High space</p>
    <p>efficiency</p>
    <p>Low CPU</p>
    <p>utilization</p>
    <p>Cost efficiency</p>
  </div>
  <div class="page">
    <p>ATC '19, Renton, WA, USA</p>
    <p>on July 10th</p>
  </div>
</Presentation>
