<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>One Hop Lookups for Peer-to-Peer Overlays</p>
    <p>Anjali Gupta, Barbara Liskov, Rodrigo Rodrigues</p>
    <p>Laboratory for Computer Science, MIT</p>
  </div>
  <div class="page">
    <p>Peer-to-Peer Systems</p>
    <p>n Large scale dynamic network n Overlay infrastructure :</p>
    <p>Scalable  Self configuring  Fault tolerant</p>
    <p>n Every node responsible for some objects n Find node having desired object n Challenge : Efficient Routing</p>
  </div>
  <div class="page">
    <p>Routing in Current P2P Systems</p>
    <p>n Routing state size logarithmic in the number of overlay nodes</p>
    <p>n Membership changes frequent n Small routing table Less bookkeeping n Logarithmic overlay hops per lookup,</p>
    <p>high latency n Amortized cost unacceptable for storing</p>
    <p>and retrieving small objects</p>
    <p>fi</p>
  </div>
  <div class="page">
    <p>Our Thesis It is feasible to :</p>
    <p>n Keep full routing state on every node</p>
    <p>n Route in one overlay hop</p>
    <p>n Achieve high lookup success rate</p>
    <p>Thus we can :</p>
    <p>n Enable a large class of applications for peer-to-peer systems</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>n Structured Peer-to-Peer Overlay</p>
    <p>n Goals</p>
    <p>n Design</p>
    <p>n Analysis</p>
    <p>n Future Work</p>
  </div>
  <div class="page">
    <p>Structured Overlay</p>
    <p>Objects and nodes have identifiers A specific node is responsible for each object Different data placement algorithms, e.g.,</p>
    <p>consistent hashing Successor node</p>
    <p>Node</p>
    <p>Object</p>
  </div>
  <div class="page">
    <p>Dynamic Membership</p>
    <p>n Nodes join and leave</p>
    <p>n Gnutella study (Saroiu et al) :</p>
    <p>average node session time 2.9 hours</p>
    <p>n Rate of change Number of nodes</p>
    <p>n For 100,000 nodes, approximately 20 membership changes per second</p>
  </div>
  <div class="page">
    <p>Goals</p>
  </div>
  <div class="page">
    <p>Routing Goal</p>
    <p>n How does node N find object O?  Finds successor S(O) by looking in its own table</p>
    <p>Sends a message to S(O)</p>
    <p>If S(O) is current successor of O, responds with success message</p>
    <p>n Lookup success:  Object found in first attempt</p>
    <p>n Achieve high lookup success rate, e.g., 99%</p>
  </div>
  <div class="page">
    <p>Design Goals</p>
    <p>n Information about a node joining or leaving the system must reach all nodes rapidly</p>
    <p>n Bandwidth requirement should be feasible</p>
    <p>n Should be scalable</p>
    <p>n Hierarchical Scheme!</p>
  </div>
  <div class="page">
    <p>Design</p>
  </div>
  <div class="page">
    <p>Hierarchical Scheme</p>
    <p>Ring is divided statically into slices</p>
    <p>(i.e., slices are just identifier intervals)</p>
    <p>node</p>
  </div>
  <div class="page">
    <p>Hierarchical Scheme</p>
    <p>Successor of midpoint of slice is slice leader</p>
    <p>node</p>
  </div>
  <div class="page">
    <p>Hierarchical Scheme</p>
    <p>Each slice is divided statically into units</p>
    <p>Again, units are just intervals</p>
    <p>Successor of midpoint of unit is unit leader</p>
  </div>
  <div class="page">
    <p>Base Communication</p>
    <p>n Node exchanges frequent keep-alive messages with predecessor and successor</p>
    <p>n Detects change in successor : event n Recent event log n Piggyback event log on keep-alive</p>
    <p>messages n Is this fast enough?</p>
  </div>
  <div class="page">
    <p>Flow of Information : Inter-slice</p>
    <p>Step 1: Event detected by node N</p>
    <p>N</p>
  </div>
  <div class="page">
    <p>Flow of Information : Inter-slice</p>
    <p>Step 2: N notifies its slice leader</p>
    <p>N Slice leader</p>
  </div>
  <div class="page">
    <p>Flow of Information : Inter-slice</p>
    <p>Step 3: Ns slice leader collects events for some time, then notifies other slice leaders</p>
    <p>N Slice leader</p>
  </div>
  <div class="page">
    <p>Is this fast enough?</p>
    <p>n Slices may be large!</p>
    <p>n Piggybacking on keep-alive messages can take a long time</p>
  </div>
  <div class="page">
    <p>Flow of Information : Intra-slice</p>
    <p>Step 4: Slice leaders notify their respective unit leaders periodically</p>
    <p>N Slice leader</p>
    <p>Unit leader</p>
  </div>
  <div class="page">
    <p>Analysis</p>
  </div>
  <div class="page">
    <p>Speed of Propagation</p>
    <p>n Units kept small to spread information quickly</p>
    <p>n Possible frequency of communications :  Slice leaders communicate with each other once</p>
    <p>every 30 seconds</p>
    <p>Slice leader communicates with its unit leaders once every 5 seconds</p>
    <p>Nodes exchange keep-alive messages every second</p>
  </div>
  <div class="page">
    <p>Speed of Propagation</p>
    <p>n If (expected) unit size is 20, the time taken to reach farthest nodes is:  Node to Slice leader : 0 s</p>
    <p>Slice leader to other slice leaders : 30 s</p>
    <p>Slice leader to unit leaders : 5 s</p>
    <p>Unit leader to edge of unit : 10 s</p>
    <p>n Total time : 45 seconds!</p>
  </div>
  <div class="page">
    <p>Time Constraint n Recall : Goal of 99% lookup success rate n If f : acceptable lookup failure rate n : number of overlay nodes r : rate of membership change n Then: All nodes must be notified about an event</p>
    <p>within</p>
    <p>n e.g.: For f = 0.01, n = 100000, r = 20 changes/second time interval = 50 seconds</p>
    <p>sec r</p>
    <p>nf</p>
  </div>
  <div class="page">
    <p>Bandwidth Use</p>
  </div>
  <div class="page">
    <p>Bandwidth Use</p>
    <p>n Number of slices (k) chosen to minimize total bandwidth use. We prove that</p>
    <p>n For an overlay having 100,000 nodes:  Per node: 4 kbps (up, down)</p>
    <p>Per unit leader: 4 kbps (up, down)</p>
    <p>Per slice leader: 240 kbps (upstream), 4 kbps (down)</p>
    <p>nk</p>
  </div>
  <div class="page">
    <p>Slice Leaders</p>
    <p>n Important to choose slice leaders correctly</p>
    <p>n Super-node scheme</p>
    <p>n Sufficient number of well-provisioned nodes</p>
    <p>n Incentives for maintaining ring: Application dependent</p>
  </div>
  <div class="page">
    <p>Fault Tolerance</p>
    <p>n Unit leader failure : easy recovery</p>
    <p>n Slice leader failure  Contact unit leaders</p>
    <p>Contact other slice leaders</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>n Design of a Robust P2P system - R. Rodrigues et al</p>
    <p>n Kelips - I. Gupta et al</p>
    <p>n Controlling the Cost of Reliability in P2P Overlays</p>
    <p>- R. Mahajan et al</p>
  </div>
  <div class="page">
    <p>Future Work</p>
    <p>n System implementation almost complete</p>
    <p>n Experiments to see actual system behavior</p>
    <p>n Systems larger than a million nodes  Two hop scheme</p>
  </div>
</Presentation>
