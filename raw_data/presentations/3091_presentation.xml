<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA</p>
    <p>James Kwok Brian Mak Simon Ho</p>
    <p>Department of Computer Science</p>
    <p>Hong Kong University of Science and Technology</p>
    <p>Hong Kong</p>
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 1</p>
  </div>
  <div class="page">
    <p>Speaker Adaptation</p>
    <p>A well-trained speaker-dependent (SD) model generally achieves a significantly lower word error rate than a speaker-independent (SI)</p>
    <p>model on recognizing speech from the specific speaker</p>
    <p>Hard to acquire a large amount of data from a user to train the SD model</p>
    <p>adapt the SI model with a relatively small amount of SD speech  maximum a posteriori (MAP) adaptation  maximum likelihood linear regression (MLLR) adaptation</p>
    <p>when the amount of available adaptation speech is really small (e.g., only a few seconds): eigenvoice -based adaptation</p>
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 2</p>
  </div>
  <div class="page">
    <p>Eigenvoice vs Kernel Eigenvoice</p>
    <p>Eigenvoice (EV)</p>
    <p>use principal component analysis (PCA) to find the eigenvoices  represent the new speaker as a linear combination of the leading</p>
    <p>eigenvoices</p>
    <p>estimate the (small) set of weights by using maximum likelihood  linear PCA  captures only linear relationships</p>
    <p>Kernel eigenvoice (KEV)</p>
    <p>kernel PCA  issues:  do all computations rely only on kernel evaluations?  how to compute the observation likelihood?</p>
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 3</p>
  </div>
  <div class="page">
    <p>PCA</p>
    <p>w</p>
    <p>w1</p>
    <p>M</p>
    <p>PC1</p>
    <p>PC2</p>
    <p>adaptation data supervector</p>
    <p>PCM</p>
    <p>ML</p>
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 4</p>
  </div>
  <div class="page">
    <p>Eigenvoice: Training</p>
    <p>A set of speaker-dependent (SD) acoustic hidden Markov models (HMMs) are trained from each speaker</p>
    <p>in general, the HMM states are GMMs</p>
    <p>A speakers voice is represented by a speaker supervector that is composed by concatenating the mean vectors of all his HMM</p>
    <p>Gaussian distributions</p>
    <p>R states in each HMM  xi = [xi1, . . . , x</p>
    <p>iR]</p>
    <p>PCA is then performed on a set of training speaker supervectors and the resulting eigenvectors are called eigenvoices</p>
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 5</p>
  </div>
  <div class="page">
    <p>Eigenvoice: Adaptation</p>
    <p>The new speakers supervector s is assumed to be a linear combination of the M leading eigenvoices {v1, . . . , vM}</p>
    <p>s = s(ev) = M</p>
    <p>m=1</p>
    <p>wmvm</p>
    <p>Given the adaptation data O = {o1, o2, . . . , oT}, estimate the eigenvoice weights (w = [w1, . . . , wm]) by maximum likelihood</p>
    <p>max w</p>
    <p>Q(w)   1 2</p>
    <p>R r=1</p>
    <p>T t=1</p>
    <p>t(r)ot  sr(w)2Cr</p>
    <p>t(r): posterior probability of observation sequence being at state r at time t</p>
    <p>Cr: covariance matrix of the Gaussian at state r  sr: rth constituent of s</p>
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 6</p>
  </div>
  <div class="page">
    <p>Kernel Principal Component Analysis</p>
    <p>input space</p>
    <p>feature space</p>
    <p>Kernel PCA: linear PCA in the feature space</p>
    <p>Given {x1, . . . , xN}, construct K = [k(xi, xj)] = [(xi)(xj)]</p>
    <p>K = UU (assume that {(x1), . . . , (xN )} has been centered)  U = [1, . . . , N ] with i = [i1, . . . , iN ]</p>
    <p>= diag(1, . . . , N )</p>
    <p>kth orthonormal eigenvector: vk = N</p>
    <p>i=1 ki</p>
    <p>k (xi)</p>
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 7</p>
  </div>
  <div class="page">
    <p>Problem</p>
    <p>Estimation of the eigenvoice weights requires the evaluation of the distances between adaptation data ot and Gaussian means of the new speaker in the observation space</p>
    <p>EV: breaks up the speaker-adapted (SA) model found by EV adaptation into its constituent HMM Gaussians</p>
    <p>s(ev)  s(ev)1 , . . . , s (ev) R  Gaussian means</p>
    <p>KEV: the SA model found by KEV adaptation resides in the feature space, not in the input speaker supervector space</p>
    <p>cannot access each constituent Gaussian directly</p>
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 8</p>
  </div>
  <div class="page">
    <p>Composite Kernel</p>
    <p>k(xi, xj) = f (k1(xi1, xj1), . . . , kR(xiR, xjR))</p>
    <p>k(x i , x j)</p>
    <p>xi</p>
    <p>x j</p>
    <p>feature space</p>
    <p>input space</p>
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 9</p>
  </div>
  <div class="page">
    <p>Examples</p>
    <p>Direct sum kernel:</p>
    <p>k(xi, xj) = R</p>
    <p>r=1</p>
    <p>kr(xir, xjr)</p>
    <p>corresponding feature: (xi) = [1(xi1), . . . , R(xiR)]</p>
    <p>Tensor product kernel:</p>
    <p>k(xi, xj) = R</p>
    <p>r=1</p>
    <p>kr(xir, xjr)</p>
    <p>If kr(, )s are valid Mercer kernels, so is k(, )</p>
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 10</p>
  </div>
  <div class="page">
    <p>New Speaker in the Feature Space</p>
    <p>(s) = M</p>
    <p>m=1</p>
    <p>wmvm = M</p>
    <p>m=1</p>
    <p>N i=1</p>
    <p>wmmi m</p>
    <p>(xi)</p>
    <p>rth constituent: r(sr) = M</p>
    <p>m=1</p>
    <p>N i=1</p>
    <p>wmmi m</p>
    <p>r(xir)</p>
    <p>Similarity between r(sr) and r(ot):</p>
    <p>kr(sr, ot) = r(sr)  r(ot) = A(r, t) +</p>
    <p>M m=1</p>
    <p>wm m</p>
    <p>B(m, r, t)</p>
    <p>A(r, t) = 1 N</p>
    <p>N j=1 kr(xjr, ot)</p>
    <p>B(m, r, t) = (N</p>
    <p>i=1 mikr(xir, ot) )  A(r, t)</p>
    <p>(N i=1 mi</p>
    <p>) Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 11</p>
  </div>
  <div class="page">
    <p>Maximum Likelihood Adaptation</p>
    <p>kr(, ): e.g., isotropic kernels kr(sr, ot) = (ot  sr2Cr)</p>
    <p>e.g., Gaussian kernels: kr(sr, ot) = exp(ot  sr2Cr)  if  is invertible, ot sr2Cr  function of kr(sr, ot)  function</p>
    <p>of w</p>
    <p>Substitute back to Q(w) and differentiate to obtain Q/wj</p>
    <p>No closed form solution for the optimal w</p>
    <p>use generalized EM algorithm (GEM)</p>
    <p>w(0): eigenvoice weights of the supervector composed from the speaker-independent model x(si)</p>
    <p>wm(0) = vm(x (si)) (can be obtained from kernel evaluations)</p>
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 12</p>
  </div>
  <div class="page">
    <p>Incorporate the SI Model</p>
    <p>Interpolate (s) with the -mapped SI supervector (x(si)) to obtain the final SA model (in the feature space):</p>
    <p>(rkev)(s) = w0(x(si)) + (1  w0)(s), 0  w0  1</p>
    <p>w0 estimated in the same manner as the other wms  robust kernel eigenvoice</p>
    <p>(rkev)(s) contains components in (x(si)) from eigenvectors beyond the M selected kernel eigenvoices for adaptation</p>
    <p>preserve the speaker-independent projections on the remaining less important but robust eigenvoices in the final speaker-adapted</p>
    <p>model</p>
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 13</p>
  </div>
  <div class="page">
    <p>Experimental Setup: Data Set and HMM Models</p>
    <p>TIDIGITS corpus  163 speakers (of both genders) in each (training and test) set,</p>
    <p>each pronouncing 77 utterances of 1-7 digits (out of: 0, 1,</p>
    <p>. . ., 9, and oh)</p>
    <p>12 mel-frequency cepstral coefficients and the normalized frame energy from each speech frame of 25 ms at every 10 ms</p>
    <p>Digit model  strictly left-to-right HMM with 16 states  one Gaussian with diagonal covariance per state</p>
    <p>A 3-state sil model to capture silence speech and a 1-state sp model to capture short pauses between digits</p>
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 14</p>
  </div>
  <div class="page">
    <p>Adaptation</p>
    <p>SD digit model</p>
    <p>one for each training speaker  variances and transition matrices are borrowed from SI models</p>
    <p>(only the Gaussian means are estimated)</p>
    <p>The sil and sp models are simply copied to the SD model</p>
    <p>5, 10, 20 digits for adaptation (' 2.1s, 4.1s, and 9.6s of speech)</p>
    <p>Results are averages of 5-fold cross-validation over all test speakers</p>
    <p>(Testing) word accuracy of SI model: 96.25%</p>
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 15</p>
  </div>
  <div class="page">
    <p>Experiment 1: Number of Kernel Eigenvoices</p>
    <p>W o rd</p>
    <p>R e co</p>
    <p>g n iti</p>
    <p>o n A</p>
    <p>cc u ra</p>
    <p>cy (</p>
    <p>% )</p>
    <p>Number of Kernel Eigenvoices</p>
    <p>SI model</p>
    <p>KEV (2.1s)</p>
    <p>KEV (9.6s)</p>
    <p>robust KEV (2.1s)</p>
    <p>robust KEV (9.6s)</p>
    <p>KEV outperforms the SI model even with only two eigenvoices</p>
    <p>Robust KEV significantly improves KEV</p>
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 16</p>
  </div>
  <div class="page">
    <p>Experiment 2: KEV vs. EV</p>
    <p>W o</p>
    <p>rd R</p>
    <p>e co</p>
    <p>g n</p>
    <p>iti o</p>
    <p>n A</p>
    <p>cc u</p>
    <p>ra cy</p>
    <p>( %</p>
    <p>)</p>
    <p>Amount of Adaptation Data (in seconds)</p>
    <p>robust KEV</p>
    <p>KEV</p>
    <p>robust EV</p>
    <p>EV</p>
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 17</p>
  </div>
  <div class="page">
    <p>(Robust) KEV always performs better than (robust) EV</p>
    <p>When only 2.1s or 4.1s of adaptation data are available EV ' MAP ' MLLR &lt; SI ' robust EV &lt; KEV &lt; robust KEV</p>
    <p>With 9.6s of adaptation data</p>
    <p>MLLR works marginally better than robust KEV (by an absolute 0.06%)</p>
    <p>Word error rate reduction over SI</p>
    <p>KEV robust KEV</p>
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 18</p>
  </div>
  <div class="page">
    <p>-4</p>
    <p>-3</p>
    <p>-2</p>
    <p>-1</p>
    <p>-3 -2.5 -2 -1.5 -1 -0.5 0 0.5 1 1.5 2 2.5</p>
    <p>V a l u e s o n t h e f i r s t e i g e n v o i c e</p>
    <p>Values on the second eigenvoice</p>
    <p>&quot;ev.train.man&quot; &quot;ev.train.woman&quot; &quot;ev.train.boy&quot; &quot;ev.train.girl&quot;</p>
    <p>-1</p>
    <p>V a l u e s o n t h e f i r s t e i g e n v o i c e</p>
    <p>Values on the second eigenvoice</p>
    <p>&quot;gau.train.man&quot; &quot;gau.train.woman&quot; &quot;gau.train.boy&quot; &quot;gau.train.girl&quot;</p>
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 19</p>
  </div>
  <div class="page">
    <p>Conclusion and Future Work  (Nonlinear) kernel PCA + composite kernel</p>
    <p>better eigenvoices  improved speaker adaptation</p>
    <p>Interpolate the SI model with the speaker model found by KEV</p>
    <p>In the TIDIGITS task</p>
    <p>standard EV does not help  KEV outperforms SI by 1621% (word error rate reduction)  robust KEV: 2833% word error rate reduction over SI</p>
    <p>Disadvantage: KEV is slower than EV</p>
    <p>online computation of many kernel functions required during subsequent speech recognition</p>
    <p>currently investigating speed-up techniques</p>
    <p>Eigenvoice Speaker Adaptation via Composite Kernel PCA NIPS 2003 20</p>
  </div>
</Presentation>
