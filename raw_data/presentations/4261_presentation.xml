<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Deep Keyphrase Generation</p>
    <p>Rui Meng, Sanqiang Zhao, Shuguang Han, Daqing He, Peter Brusilovsky, Yu Chi School of Computing and Information University of Pittsburgh</p>
  </div>
  <div class="page">
    <p>Keyphrase</p>
    <p>Keyphrase o Short texts highly summarize the</p>
    <p>significant content of a document o Applications</p>
    <p>o Knowledge mining (concept) o Information retrieval (indexing term) o Summarization</p>
    <p>o Provided by authors/editors</p>
    <p>This work aims to o obtain keyphrases from scientific papers</p>
    <p>(title+abstract) automatically</p>
    <p>Introduction</p>
    <p>TITLE</p>
  </div>
  <div class="page">
    <p>Previous Approaches</p>
    <p>Recommender systems play an important role in reducing the negative impact of information overload on those websites where users have the possibility of voting for their preferences on items</p>
    <p>3-step process</p>
    <p>Source Text</p>
    <p>recommender systems, important role, negative impact, information overload, websites, users, possibility of voting, preferences, items</p>
    <p>recommender systems (0.733), important role (0.019), negative impact (0.057), information overload (0.524), websites (0.132), users (0.014), possibility of voting (0.104), preferences (0.197), items (0.027)</p>
    <p>source text.</p>
    <p>Only able to predict phrases appear in text</p>
    <p>&amp;</p>
    <p>simple features can hardly represent</p>
    <p>deep semantics</p>
    <p>neither flexible nor scalable</p>
    <p>Issues: Recommender systems play an important role in reducing the negative impact of information overload on those websites where users have the possibility of voting for their preferences on items</p>
    <p>Background</p>
    <p>Dataset % Present % Absent Inspec 73.62% 26.38%</p>
    <p>Krapivin 54.33% 45.67% NUS 45.63% 54.37%</p>
    <p>SemEval 55.66% 44.34%</p>
    <p>Performance Upper Bound</p>
  </div>
  <div class="page">
    <p>meaningful phrases</p>
    <p>How do humans assign keyphrases?</p>
    <p>Can machine simulate this process?</p>
    <p>Recurrent Neural Networks [Step 1-3]</p>
    <p>Copy Mechanism [Step 4]</p>
    <p>Revisit Keyphrase Generation Motivation</p>
    <p>Memory trackingtopic</p>
    <p>native</p>
    <p>multilingual</p>
    <p>language hypothesis</p>
    <p>Read &amp; Understand</p>
    <p>Write Keyphrase</p>
    <p>miningtext</p>
  </div>
  <div class="page">
    <p>Recurrent Neural Networks Methodology</p>
    <p>Input Text</p>
    <p>Memory</p>
    <p>Output Text Read Write</p>
    <p>Encoder RNN</p>
    <p>Decoder RNN</p>
    <p>Context Vector</p>
    <p>Output Text</p>
    <p>topic</p>
    <p>multiple</p>
    <p>multilingual</p>
    <p>text</p>
    <p>latent</p>
    <p>Prob=0.257</p>
    <p>Prob=0.122</p>
    <p>Prob=0.119</p>
    <p>Prob=0.101</p>
    <p>Prob=0.093</p>
    <p>Encoder-decoder model (Seq2seq)</p>
    <p>o One and one</p>
    <p>o Gated recurrent units (GRU) cell</p>
    <p>o Decoder generates multiple short sequences by beam search</p>
    <p>model</p>
    <p>allocation</p>
    <p>tracking</p>
    <p>language</p>
    <p>mining</p>
    <p>analysis</p>
    <p>dirichlet</p>
    <p>Prob=0.027</p>
    <p>Prob=0.022</p>
    <p>Prob=0.010</p>
    <p>Prob=0.014</p>
    <p>Prob=0.013</p>
    <p>Prob=0.003</p>
  </div>
  <div class="page">
    <p>Recurrent Neural Networks Methodology</p>
    <p>Input Text</p>
    <p>Memory</p>
    <p>Output Text Read Write</p>
    <p>Encoder RNN</p>
    <p>Decoder RNN</p>
    <p>Context Vector</p>
    <p>Output Text</p>
    <p>multilingual Prob=0.122</p>
    <p>Encoder-decoder model (Seq2seq)</p>
    <p>o One and one</p>
    <p>o Gated recurrent units (GRU) cell</p>
    <p>o Decoder generates multiple short sequences by beam search</p>
    <p>o Rank them and return the top K results</p>
    <p>topic tracking Prob=0.027</p>
    <p>latent allocationdirichlet Prob=0.010</p>
    <p>text mining Prob=0.014</p>
    <p>multiple language Prob=0.013</p>
    <p>Prob=0.022modeltopic</p>
    <p>analysis Prob=0.003text</p>
  </div>
  <div class="page">
    <p>Recurrent Neural Networks Methodology</p>
    <p>Input Text</p>
    <p>Context</p>
    <p>Output Text Read Write</p>
    <p>Encoder RNN</p>
    <p>Decoder RNN</p>
    <p>Context Vector</p>
    <p>Output Text</p>
    <p>topic</p>
    <p>multiple</p>
    <p>multilingual</p>
    <p>tracking</p>
    <p>language</p>
    <p>Problem of  Keep everything in memory</p>
    <p>Only train vectors for top 50k high-frequency words</p>
    <p>Long-tail words are replaced with an unknown symbol &lt;unk&gt; o Unable to predict long-tail words</p>
    <p>o Many keyphrases contain long-tail words (2%)</p>
    <p>unk unk unk</p>
    <p>unk</p>
    <p>unk unk</p>
    <p>RNN model</p>
    <p>topic</p>
    <p>multilingual language</p>
    <p>text multiple</p>
    <p>RNN Dictionary</p>
  </div>
  <div class="page">
    <p>Copy Mechanism Methodology</p>
    <p>Input Text</p>
    <p>Context</p>
    <p>Output Text Read Write</p>
    <p>Encoder RNN</p>
    <p>Decoder RNN</p>
    <p>Context Vector</p>
    <p>Output Text</p>
    <p>topic</p>
    <p>multiple</p>
    <p>multilingual</p>
    <p>tracking</p>
    <p>language</p>
    <p>CopyRNN Model</p>
    <p>o Copy words from input text</p>
    <p>o Locate the words of interest by contextual</p>
    <p>features</p>
    <p>o Copy corresponding part to output</p>
    <p>o Enhance the RNN with extractive ability</p>
    <p>unk unk unk</p>
    <p>native language hypothesis</p>
    <p>unk</p>
    <p>unk unk</p>
    <p>topic</p>
    <p>multilingual language</p>
    <p>text multiple</p>
    <p>RNN Dictionary</p>
  </div>
  <div class="page">
    <p>Dataset  All data are scientific papers in Computer Science domain  Training Data</p>
    <p>Collected from Elsevier, ACM Digital Library, Web of Science etc. o # (Paper) = 571,267 o # (Phrase) = 3,011,651 o # (Unique word) = 324,163</p>
    <p>Testing Data  Four commonly used datasets, only use abstract text  Overlapping papers are removed from training dataset</p>
    <p>Dataset # Paper # All (Avg) # Present # Absent % Absent Inspec 500 4,913 (9.82) 3,617 1,296 26.38%</p>
    <p>Krapivin 400 2,461 (6.15) 1,337 1,124 45.67% NUS 211 1,466 (6.94) 669 797 54.37%</p>
    <p>SemEval 100 2,339 (23.39) 1,302 1,037 44.34% KP20k 20,000 105,471 (5.27) 66,221 39,250 37.21%</p>
    <p>Experiment</p>
  </div>
  <div class="page">
    <p>#(Unique Keyphrase)=324,163</p>
    <p>Length of Terms</p>
    <p>Number of Frequency</p>
    <p>Percentag e</p>
    <p>&gt;5 0.73%</p>
    <p>Length of Keyphrase</p>
    <p>N U M BE</p>
    <p>R O F KE</p>
    <p>YP H RA</p>
    <p>SE</p>
    <p>Dataset Experiment</p>
  </div>
  <div class="page">
    <p>Experiment Setup</p>
    <p>Evaluation Methods  Process ground-truth and predicted phrases with Porter stemmer</p>
    <p>Macro-average of precision, recall and F-measure @5,@10</p>
    <p>Experiment</p>
    <p>Tasks 1. Present phrases prediction</p>
    <p>o Compare to previous studies: Tf-Idf, TextRank, SingleRank, ExpandRank, KEA, Maui</p>
    <p>o No baseline comparison</p>
  </div>
  <div class="page">
    <p>Dataset Inspec Krapivin NUS SemEval KP20k Method F@5 F@10 F@5 F@10 F@5 F@10 F@5 F@10 F@5 F@10 Tf-Idf 0.221 0.313 0.129 0.160 0.136 0.184 0.128 0.194 0.102 0.126</p>
    <p>TextRank 0.223 0.281 0.189 0.162 0.195 0.196 0.176 0.187 0.175 0.147 SingleRank 0.214 0.306 0.110 0.153 0.140 0.173 0.135 0.176 0.096 0.119</p>
    <p>ExpandRank 0.210 0.304 0.110 0.152 0.132 0.164 0.139 0.170 - KEA 0.098 0.126 0.123 0.134 0.069 0.084 0.025 0.026 0.171 0.154 Maui 0.040 0.042 0.249 0.216 0.249 0.268 0.044 0.039 0.270 0.230</p>
    <p>Take-away 1. Nave RNN model fails to compete with baseline models</p>
    <p>information in source text.</p>
    <p>Task 1 - Predict Present Keyphrase Result</p>
    <p>RNN 0.085 0.064 0.135 0.088 0.169 0.127 0.157 0.124 0.179 0.189</p>
    <p>CopyRNN 0.278 (24.7%) 0.342 (9.3%)</p>
  </div>
  <div class="page">
    <p>[Title] Nonlinear Extrapolation Algorithm for Realization of a Scalar Random Process [Abstract] A method of construction of a nonlinear extrapolation algorithm is proposed. This method makes it possible to take into account any nonlinear random dependences that exist in an investigated process and are described by mixed central moment functions. The method is based on the V. S. Pugachev canonical decomposition apparatus. As an example, the problem of nonlinear extrapolation is solved for a moment function of third order. [Ground-truth] 6 ground-truth phrases</p>
    <p>moment function nonlinear extrapolation algorithm canonical decomposition apparatus scalar random process nonlinear random dependences mixed central moment functions</p>
    <p>[Prediction]</p>
    <p>Result Example - Phraseness</p>
    <p>nonlinear extrapol moment function canon decomposit extrapol algorithm scalar random process random process central moment function nonlinear extrapol algorithm mix central moment function central moment mix central moment random depend investig process nonlinear random depend scalar random</p>
    <p>account example method mixed central moment functions moment function nonlinear extrapolation nonlinear extrapolation algorithm nonlinear random dependences problem process pugachev canonical decomposition apparatus realization s scalar random process third order</p>
    <p>Tf-Idf CopyRNN</p>
  </div>
  <div class="page">
    <p>[Title] Meta-level Coordination for Solving Distributed Negotiation Chains in Semi-cooperative Multi-agent Systems [Abstract] A negotiation chain is formed when multiple related negotiations are spread over multiple agents. In order to appropriately order and structure the negotiations occurring in the chain so as to optimize the expected utility, we present an extension to a single-agent concurrent negotiation framework. This work is aimed at semi-cooperative multi-agent systems, where each agent has its own goals and works to maximize its local utility; however, the performance of each individual agent is tightly related to other agents cooperation and the systems overall performance. We introduce a pre-negotiation phase that allows agents to transfer meta-level information. Using this information, the agent can improve the accuracy of its local model about how other agents would react to the negotiations  [Ground-truth] 7 ground-truth phrases</p>
    <p>multipl agent; negoti framework; negoti chain; semi cooper multi agent system; pre negoti; agent; flexibl; [Prediction]</p>
    <p>Result Example  Failure of RNN</p>
    <p>multi agent system negoti chain multiag system concurr negoti artifici intellig pre negoti multi agent semi cooper multi agent system multipl agent expect util distribut artifici intellig global negoti meta level coordin semi cooper</p>
    <p>pre negoti phase semi cooper multi agent system system s overal perform negoti negoti chain individu agent other agent s cooper concurr negoti framework cooper multi agent system multipl relat negoti negoti chain meta level coordin negoti solut global negoti chain context</p>
    <p>Tf-Idf CopyRNNmulti agent system multi agent multiag system agent system multipl agent artifici intellig cooper multi agent system cooper multi agent</p>
    <p>RNN</p>
  </div>
  <div class="page">
    <p>[Title] Full-screen ultrafast video modes over-clocked by simple VESA routines and registers reprogramming under MS-DOS.</p>
    <p>[Abstract] Fast full-screen presentation of stimuli is necessary in psychological research. Although Spitczok von Brisinski (1994) introduced a method that achieved ultrafast display by reprogramming the registers, he could not produce an acceptable full-screen display. In this report, the author introduces a new method combining VESA routine calling with registers reprogramming that can yield a display at 640  480 resolution, with a refresh rate of about 150 Hz.</p>
    <p>[GROUND-TRUTH] 6 ground-truth phrases vesa routine calling; fast full screen stimuli presentation; ms dos; full screen ultrafast video modes; psychological research ; register reprogramming;</p>
    <p>[PREDICTION] 1. register reprogramming 2. video modes 3. ultrafast display 4. screen display 5. ultrafast video 6. vesa routine [copied] 7. refresh rate 8. routine calling 9. ultrafast video modes 10. psychological research 11. vesa routine calling [copied] 12. spitczok von[copied] 13. video modes over clocked 14. spitczok von brisinski[copied]</p>
    <p>Result Example  Phrases with OOD words</p>
  </div>
  <div class="page">
    <p>Task 2 - Predict Absent Keyphrase</p>
    <p>Dataset RNN CopyRNN+</p>
    <p>Recall @10</p>
    <p>Recall @50</p>
    <p>Recall @10</p>
    <p>Recall @50</p>
    <p>Inspec 0.0309 0.0610 0.0471 0.0995</p>
    <p>Krapivin 0.0945 0.1562 0.1128 0.2015</p>
    <p>NUS 0.0498 0.0890 0.0578 0.1157</p>
    <p>SemEval 0.0414 0.0602 0.0427 0.0665</p>
    <p>KP20k 0.0833 0.1441 0.1253 0.2108</p>
    <p>Same five test datasets, only use absent keyphrases as ground-truth</p>
    <p>Evaluate with recall@10 and recall@50</p>
    <p>Result</p>
  </div>
  <div class="page">
    <p>[Title] Towards content-based relevance ranking for video search [Abstract] Most existing web video search engines index videos by file names, URLs, and surrounding texts. These types of video metadata roughly describe the whole video in an abstract level without taking the rich content, such as semantic content descriptions and speech within the video, into consideration. Therefore the relevance ranking of the video search results is not satisfactory as the details of video contents are ignored. In this paper we propose a novel relevance ranking approach for Web-based video search using both video metadata and the rich content contained in the videos. To leverage real content into ranking, the videos are segmented into shots, which are smaller and more semantic-meaningful retrievable units, and then more detailed information of video content such as semantic descriptions and speech of each shots are used to improve the retrieval and ranking performance. With video metadata and content information of shots, we developed an integrated ranking approach, which achieves improved ranking performance. We also introduce machine learning into the ranking system, and compare them with IR-model (information retrieval model) based method. The evaluation results demonstrate the effectiveness of the proposed ranking methods. [Ground-truth] 10 absent phrases</p>
    <p>video segmentation, ir model, content based approach, content based ranking, neutral network based ranking, video index, learning based ranking, ir model based ranking, machine learning model, video retrieval</p>
    <p>[Predictions]</p>
    <p>Result Task 2 - Predict Absent Keyphrase</p>
  </div>
  <div class="page">
    <p>Task 3  Transfer to News Articles</p>
    <p>So far training and testing are only about scientific papers  What if transfer it to a completely unseen domain</p>
    <p>o Does model learn any universal feature?</p>
    <p>Test the CopyRNN on DUC-2001 o 308 news articles and 2,488 keyphrases o CopyRNN recalls 766 keyphrases. 14.3% contain out-of-vocabulary words o Many names of persons and places are correctly predicted.</p>
    <p>Result</p>
    <p>Model F1-score TFIdf 0.270</p>
    <p>TextRank 0.097 SingleRank 0.256</p>
    <p>ExpandRank 0.269 KeyCluster 0.140</p>
    <p>CopyRNN@10 0.164</p>
  </div>
  <div class="page">
    <p>Example  Transfer to News Articles Result</p>
    <p>[Article] anti maoists threaten prosecutor. a death squad opposed to the shining path guerrillas has threatened to kill a district attorney if he investigates charges that soldiers massacred dozens of peasants , his office said tuesday . police said members of shining path , a maoist group , killed two policemen and wounded three in jungle raids . the rodrigo franco command , which has vowed to kill a shining path member or sympathizer for every person slain by guerrillas , issued the threat against district attorney carlos escobar on monday , according to his office in andean city of ayacucho . escobar is investigating charges that troops rounded up dozens of peasants , accused them of being shining path members and killed them . the alleged massacre occurred in may near cayara , a farming village &lt;digit&gt; miles south of ayacucho . officials said the rebel raids occurred sunday , at a police post and telephone relay station near the jungle city of pucallpa , &lt;digit&gt; miles northeast of lima . shining path guerrillas began fighting eight years ago . the government says more than &lt;digit&gt; , &lt;digit&gt; people have been killed and puts the property damage at &lt;digit&gt; billion . the rodrigo franco group is named for an official of the government party killed the shining path killed last year . it became known in july when it claimed responsibility for killing the lawyer for osman morote . he is suspected of being the shining path second in command and is in jail on terrorism charges .</p>
    <p>[Ground-truth] 8 present phrases shining path guerrillas; police post; rebel raids; death squad; property damage; rodrigo franco command; district attorney carlos escobar; osman morote;</p>
    <p>[Predictions] 1. shining path 2. death squad[correct] 3. district attorney 4. rebel raids[correct] 5. osman morote[correct] 6. jungle raids 7. rodrigo franco 8. terrorism charges 9. relay station 10. anti maoists 11. massacred dozens 12. andean city</p>
  </div>
  <div class="page">
    <p>Keyphrase generation study based on deep learning methods</p>
    <p>o First work concerns absent keyphrase prediction</p>
    <p>o RNN + Copy mechanism</p>
    <p>o Able to learn cross-domain features</p>
    <p>Conclusion &amp; Future Work</p>
    <p>Better model on capturing contextual information</p>
    <p>Multiple-output optimization</p>
    <p>Long documents, length &amp; diversity penalties on output sequences</p>
  </div>
  <div class="page">
    <p>THANKS!</p>
    <p>Any question?</p>
  </div>
</Presentation>
