<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>RAIDShield: Characterizing, Monitoring, and</p>
    <p>Proactively Protecting Against Disk Failures</p>
    <p>Ao Ma</p>
    <p>Fred Douglis</p>
    <p>Guanlin Lu</p>
    <p>Darren Sawyer</p>
    <p>EMC</p>
    <p>Surendar Chandra</p>
    <p>Windsor Hsu</p>
    <p>Datrium</p>
  </div>
  <div class="page">
    <p>Disk failures are commonplace</p>
    <p>Whole-disk failure</p>
    <p>Partial failure</p>
    <p>RAID is widely deployed</p>
    <p>Protect data against failures with redundancy</p>
    <p>Pervasive RAID Protection</p>
  </div>
  <div class="page">
    <p>Storage system is evolving</p>
    <p>Escalated use of less reliable drives causes more</p>
    <p>whole-disk failures</p>
    <p>Increasing disk capacity results in more sector errors</p>
    <p>Solution</p>
    <p>Add extra redundancy (RAID5, RAID6, )</p>
    <p>Ensure data reliability at the cost of storage efficiency</p>
    <p>RAID Overview</p>
    <p>Is adding extra redundancy an efficient solution?</p>
  </div>
  <div class="page">
    <p>Analyzed 1 million SATA disks and revealed</p>
    <p>Failure modes degrading RAID reliability</p>
    <p>Reallocated sectors reflect disk reliability deterioration</p>
    <p>Disk failure is predictable</p>
    <p>Built RAIDSHIELD, an active defense mechanism</p>
    <p>Reconstruct failing disk before its too late!</p>
    <p>PLATE: single-disk proactive protection</p>
    <p>Deployment eliminates 70% of RAID failures</p>
    <p>ARMOR: disk group proactive protection</p>
    <p>Recognize vulnerable RAID groups</p>
    <p>What We Did</p>
  </div>
  <div class="page">
    <p>Background</p>
    <p>Disk failure analysis</p>
    <p>RAIDSHIELD:</p>
    <p>Identify failure indicator</p>
    <p>Reallocated Sector (RS) characterization</p>
    <p>Single disk proactive protection</p>
    <p>Disk group proactive protection</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Disk failure does not follow a fail-stop model</p>
    <p>The production systems studied define failure as</p>
    <p>Connection is lost</p>
    <p>An operation exceeds the timeout threshold</p>
    <p>Write fails</p>
    <p>Whole-disk Failure Definition</p>
  </div>
  <div class="page">
    <p>Each disk drive model is denoted as &lt;family-capacity&gt;</p>
    <p>Relative sizes within a family are ordered by the capacity number  E.g. A-2 is larger than A-1</p>
    <p>Disk Model Population (Thousands)</p>
    <p>First Deployment</p>
    <p>Log Length (Months)</p>
    <p>A-1 34 06/2008 60</p>
    <p>A-2 165 11/2008 60</p>
    <p>B-1 100 06/2008 48</p>
    <p>C-1 93 10/2010 36</p>
    <p>C-2 253 12/2010 36</p>
    <p>D-1 384 09/2011 21</p>
    <p>Disk Data Collection</p>
  </div>
  <div class="page">
    <p>What Do Real Disk Failures Look Like?</p>
  </div>
  <div class="page">
    <p>A-2</p>
    <p>Month</p>
    <p>Distribution of Lifetime of Failed Drives</p>
    <p>A-1</p>
    <p>Month</p>
    <p>A large fraction of failed drives are found at a similar age</p>
    <p>P</p>
    <p>e rc</p>
    <p>e n</p>
    <p>ta g</p>
    <p>e (%</p>
    <p>)</p>
    <p>P</p>
    <p>e rc</p>
    <p>e n</p>
    <p>ta g</p>
    <p>e (%</p>
    <p>)</p>
  </div>
  <div class="page">
    <p>The number of affected disks keep growing</p>
    <p>About 10% of disks get sector errors at the 3rd year</p>
    <p>Sector error numbers increase continuously</p>
    <p>Average error count increases 25% to 300% year</p>
    <p>over year</p>
    <p>Increasing Frequency of Sector Errors</p>
  </div>
  <div class="page">
    <p>Drive failing at a similar age</p>
    <p>Failure rate is not constant</p>
    <p>A high risk of multiple simultaneous failures</p>
    <p>Increasing frequency of sector errors</p>
    <p>Exacerbate risk of reconstruction failures</p>
    <p>Passive Redundancy is Inefficient</p>
    <p>Ensuring reliability in the worst case requires</p>
    <p>adding considerable extra redundancy, making it</p>
    <p>unattractive from a cost perspective</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Ensure data safety with minimal redundancy</p>
    <p>Proactively recognize impending failures and</p>
    <p>migrate vulnerable data in advance</p>
    <p>Methodology</p>
    <p>Identify indicator of impending failure</p>
    <p>Indicator characterization</p>
    <p>Proactive protection</p>
    <p>RAIDSHIELD, The Proactive Protection</p>
  </div>
  <div class="page">
    <p>Potential indicators</p>
    <p>Various disk errors</p>
    <p>Criteria of a good indicator</p>
    <p>It happens much more frequently on failed</p>
    <p>disks rather than working disks</p>
    <p>Approach</p>
    <p>Quantify the discrimination between error</p>
    <p>value on failed disks and working ones</p>
    <p>Deciles comparison is used</p>
    <p>Identify Failure Indicator</p>
  </div>
  <div class="page">
    <p>Failed disks have more media errors than working ones</p>
    <p>The discrimination is not significant enough</p>
    <p>Media Error Comparison</p>
    <p>failed disk working disk</p>
    <p>Deciles</p>
    <p>A-2 M</p>
    <p>e d</p>
    <p>ia E</p>
    <p>r r o</p>
    <p>r C</p>
    <p>o u</p>
    <p>n t</p>
  </div>
  <div class="page">
    <p>failed disk working disk</p>
    <p>A-2</p>
    <p>Deciles</p>
    <p>R e</p>
    <p>a ll</p>
    <p>o ca</p>
    <p>te d</p>
    <p>S e</p>
    <p>ct o</p>
    <p>r C</p>
    <p>o u</p>
    <p>n t</p>
    <p>A-2</p>
    <p>Deciles</p>
    <p>RS is strongly correlated with disk failures</p>
    <p>Reallocated Sector (RS) Comparison</p>
  </div>
  <div class="page">
    <p>Most failed drives tend to have a larger number of</p>
    <p>RS than working ones</p>
    <p>RS is strongly correlated with whole-disk failures,</p>
    <p>followed by media errors, pending sector errors</p>
    <p>and uncorrectable sector errors</p>
    <p>Correlation Between Sector Errors</p>
    <p>And Whole-disk Failure</p>
    <p>RS is a strong indicator of impending disk failure</p>
  </div>
  <div class="page">
    <p>Larger RS count implies higher failure rate in</p>
    <p>two-month observation window</p>
    <p>Disk Failure Rate Given Different RS Count</p>
    <p>D is</p>
    <p>k F</p>
    <p>a il</p>
    <p>u re</p>
    <p>R a</p>
    <p>te (</p>
    <p>% )</p>
    <p>RS count</p>
    <p>A-2</p>
    <p>RS Characterization (1)</p>
  </div>
  <div class="page">
    <p>Larger RS count, faster to fail</p>
    <p>median</p>
    <p>RS Count</p>
    <p>T im</p>
    <p>e M</p>
    <p>a rg</p>
    <p>in (D</p>
    <p>a y</p>
    <p>s) Disk Failure Time Given Different RS Count</p>
    <p>RS Characterization (2)</p>
  </div>
  <div class="page">
    <p>RS count indicates the degree of disk</p>
    <p>reliability deterioration</p>
    <p>Use the RS count to predict impending</p>
    <p>disk failure in advance</p>
    <p>PLATE: Single Disk Proactive Protection</p>
  </div>
  <div class="page">
    <p>failures predicted</p>
    <p>false positive</p>
    <p>P e</p>
    <p>rc e</p>
    <p>n ta</p>
    <p>g e</p>
    <p>( %</p>
    <p>)</p>
    <p>Both the predicted failure and false positive rates decrease as the threshold increases</p>
    <p>Simulation Result: Failures Captured Rate Given Different RS Threshold</p>
    <p>RS threshold</p>
  </div>
  <div class="page">
    <p>Without Proactive Protection With Proactive Protection</p>
    <p>Hardware Failures Others Triple Failures Eliminated Triple Failures</p>
    <p>Single proactive protection reduces about 70% of RAID failures, equivalent to 88% of the triple-disk failures</p>
    <p>PLATE Deployment Result: Causes of Recovery Incidents</p>
    <p>P e</p>
    <p>rc e</p>
    <p>n ta</p>
    <p>g e</p>
    <p>( %</p>
    <p>)</p>
  </div>
  <div class="page">
    <p>PLATE misses RAID failures caused by multiple less reliable</p>
    <p>drives, whose RS counts havent exceed the threshold</p>
    <p>Triage</p>
    <p>Prioritize disk groups with highest risk</p>
    <p>Motivation of ARMOR:</p>
    <p>The RAID Group Proactive Protection</p>
  </div>
  <div class="page">
    <p>?</p>
    <p>X</p>
    <p>X</p>
    <p>X X</p>
    <p>?</p>
    <p>?</p>
    <p>?</p>
    <p>?</p>
    <p>Threat of Failure</p>
    <p>Imminent Failure</p>
    <p>Good Disk</p>
    <p>Healthy DG1</p>
    <p>Imminent Failure of DG2</p>
    <p>Protected DG3</p>
    <p>Possible Failure of DG4</p>
    <p>Single disk protection: Replace 2-3, 2-4, 3-4 (PLATE) Cant identify DG4 nor the difference between DG2 and DG3</p>
    <p>Group protection: Replace DG4 or increase redundancy (ARMOR) Protect DG4 and recognize the difference between DG2 and DG3</p>
    <p>Disk Group Protection Example</p>
  </div>
  <div class="page">
    <p>Calculate the single disk failure probability</p>
    <p>Conditional probability through Bayes Theorem</p>
    <p>Calculate the probability of a vulnerable RAID</p>
    <p>Combination of those single disk probabilities through joint probability</p>
    <p>ARMOR Methodology</p>
  </div>
  <div class="page">
    <p>The discrimination shows ARMOR is effective to recognize endangered DGs</p>
    <p>In practice, it identifies most DG failures that are not predicted by PLATE</p>
    <p>P ro</p>
    <p>b a</p>
    <p>b il</p>
    <p>it y</p>
    <p>Deciles distribution</p>
    <p>Evaluation</p>
    <p>Groups with more than one failure Groups without failure</p>
  </div>
  <div class="page">
    <p>Google reports SMART metrics such as reallocated sector strongly suggest an impending failure, but they also determine that half of the failed disks show no such errors [Pinheiro07]</p>
    <p>Different workload and RAID rewrite</p>
    <p>Disk failure prediction</p>
    <p>Average maximum latency [Goldszmidt12]</p>
    <p>SMART failure prediction [Murray05, Hughes02]</p>
    <p>Related Work</p>
  </div>
  <div class="page">
    <p>We analyzed 1 million SATA drives</p>
    <p>Observe failure modes degrading RAID reliability</p>
    <p>Reveal RS count reflects the disk reliability deterioration</p>
    <p>Disk failure is predictable</p>
    <p>We built RAIDSHIELD, an active defense mechanism</p>
    <p>PLATE: single disk proactive protection  Deployment eliminates 70% of RAID failures</p>
    <p>ARMOR: disk group proactive protection  Recognize vulnerable RAID groups</p>
    <p>Hope to deploy in future</p>
    <p>Is adding extra redundancy an efficient solution?</p>
    <p>Use as much redundancy as needed to ensure availability</p>
    <p>Proactive replacement should decrease the level needed</p>
    <p>Summary</p>
  </div>
  <div class="page">
    <p>RAIDShield: Characterizing, Monitoring, and</p>
    <p>Proactively Protecting Against Disk Failures</p>
    <p>Questions?</p>
    <p>Acknowledgement Andrea Arpaci-Dusseau and Remzi Arpaci-Dusseau</p>
    <p>Data Domain engineer team, members of AD and CTO office, Stephen Manley</p>
    <p>Contact: ao.ma@emc.com</p>
  </div>
</Presentation>
