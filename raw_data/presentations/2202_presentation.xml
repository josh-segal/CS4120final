<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Efficient Collective Operations using Remote Memory Operations on VIA-Based Clusters</p>
    <p>Rinku Gupta Dell Computers</p>
    <p>Rinku_Gupta@Dell.Com</p>
    <p>Dhabaleswar Panda The Ohio State University panda@cis.ohio-state.edu</p>
    <p>Pavan Balaji The Ohio State University balaji@cis.ohio-state.edu</p>
    <p>Jarek Nieplocha Pacific Northwest National Lab</p>
    <p>jarek.nieplocha@pnl.com</p>
  </div>
  <div class="page">
    <p>Contents</p>
    <p>Motivation</p>
    <p>Design Issues</p>
    <p>RDMA-based Broadcast</p>
    <p>RDMA-based All Reduce</p>
    <p>Conclusions and Future Work</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Communication Characteristics of Parallel Applications</p>
    <p>Point-to-Point Communication o Send and Receive primitives</p>
    <p>Collective Communication  Barrier, Broadcast, Reduce, All Reduce</p>
    <p>Built over Send-Receive Communication primitives</p>
    <p>Communication Methods for Modern Protocols</p>
    <p>Send and Receive Model</p>
    <p>Remote Direct Memory Access (RDMA) Model</p>
  </div>
  <div class="page">
    <p>Remote Direct Memory Access</p>
    <p>Remote Direct Memory Access (RDMA) Model  RDMA Write</p>
    <p>RDMA Read (Optional)</p>
    <p>Widely supported by modern protocols and architectures  Virtual Interface Architecture (VIA)</p>
    <p>InfiniBand Architecture (IBA)</p>
    <p>Open Questions</p>
    <p>Can RDMA be used to optimize Collective Communication? [rin02]</p>
    <p>Do we need to rethink algorithms optimized for Send-Receive?</p>
    <p>[rin02]: Efficient Barrier using Remote Memory Operations on VIA-based Clusters, Rinku Gupta, V. Tipparaju, J. Nieplocha, D. K. Panda. Presented at Cluster 2002, Chicago, USA</p>
  </div>
  <div class="page">
    <p>Send-Receive and RDMA Communication Models</p>
    <p>User buffer</p>
    <p>Registered</p>
    <p>S R</p>
    <p>Registered</p>
    <p>NIC</p>
    <p>User buffer</p>
    <p>NIC</p>
    <p>descriptor descriptor</p>
    <p>User buffer</p>
    <p>Registered</p>
    <p>S R</p>
    <p>NIC</p>
    <p>Registered User buffer</p>
    <p>NIC</p>
    <p>descriptor</p>
    <p>Send/Recv RDMA Write</p>
  </div>
  <div class="page">
    <p>Benefits of RDMA</p>
    <p>RDMA gives a shared memory illusion</p>
    <p>Receive operations are typically expensive</p>
    <p>RDMA is Receiver transparent</p>
    <p>Supported by VIA and InfiniBand architecture</p>
    <p>A novel unexplored method</p>
  </div>
  <div class="page">
    <p>Contents</p>
    <p>Motivation</p>
    <p>Design Issues  Buffer Registration</p>
    <p>Data Validity at Receiver End</p>
    <p>Buffer Reuse</p>
    <p>RDMA-based Broadcast</p>
    <p>RDMA-based All Reduce</p>
    <p>Conclusions and Future Work</p>
  </div>
  <div class="page">
    <p>Buffer Registration</p>
    <p>Static Buffer Registration</p>
    <p>Contiguous region in memory for every communicator</p>
    <p>Address exchange is done during initialization time</p>
    <p>Dynamic Buffer Registration - Rendezvous</p>
    <p>User buffers, registered during the operation, when needed</p>
    <p>Address exchange is done during the operation</p>
  </div>
  <div class="page">
    <p>Data Validity at Receiver End</p>
    <p>Interrupts</p>
    <p>Too expensive; might not be supported</p>
    <p>Use Immediate field of VIA descriptor</p>
    <p>Consumes a receive descriptor</p>
    <p>RDMA write a Special byte to a pre-defined location</p>
  </div>
  <div class="page">
    <p>Buffer Reuse</p>
    <p>Static Buffer Registration</p>
    <p>Buffers need to be reused</p>
    <p>Explicit notification has to be sent to sender</p>
    <p>Dynamic Buffer Registration</p>
    <p>No buffer Reuse</p>
  </div>
  <div class="page">
    <p>Contents</p>
    <p>Motivation</p>
    <p>Design Issues</p>
    <p>RDMA-based Broadcast  Design Issues</p>
    <p>Experimental Results</p>
    <p>Analytical Models</p>
    <p>RDMA-based All Reduce</p>
    <p>Conclusions and Future Work</p>
  </div>
  <div class="page">
    <p>Buffer Registration and Initialization</p>
    <p>Static Registration Scheme (for size &lt;= 5K bytes)</p>
    <p>P0 P1 P2 P3</p>
    <p>Constant Block size</p>
    <p>Notify Buffer</p>
    <p>-1</p>
    <p>-1</p>
    <p>-1</p>
    <p>-1</p>
    <p>-1</p>
    <p>-1</p>
    <p>-1</p>
    <p>-1</p>
    <p>-1</p>
    <p>-1</p>
    <p>-1</p>
    <p>-1</p>
    <p>Dynamic Registration Scheme (for size &gt; 5K) -- Rendezvous scheme</p>
  </div>
  <div class="page">
    <p>-11-1 -11 1</p>
    <p>Data Validity at Receiver End</p>
    <p>P0 P1 P2 P3</p>
    <p>-1</p>
    <p>-1</p>
    <p>-1</p>
    <p>-1</p>
    <p>-1</p>
    <p>-1</p>
    <p>-1</p>
    <p>-1</p>
    <p>Constant Block size</p>
    <p>Broadcast counter = 1 (First Broadcast with Root P0)</p>
    <p>Data size</p>
    <p>Broadcast counter</p>
    <p>Notify Buffer</p>
  </div>
  <div class="page">
    <p>Buffer Reuse</p>
    <p>P0 P1 P2 P3</p>
    <p>Broadcast Buffer</p>
    <p>P0 P1 P2 P3</p>
  </div>
  <div class="page">
    <p>Performance Test Bed</p>
    <p>Machines connected using GigaNet cLAN 5300 switch.</p>
    <p>MVICH Version : mvich-1.0</p>
    <p>Integration with MVICH-1.0</p>
    <p>MPI_Send modified to support RDMA Write</p>
    <p>Timings were taken for varying block sizes</p>
    <p>Tradeoff between number of blocks and size of blocks</p>
  </div>
  <div class="page">
    <p>RDMA Vs Send-Receive Broadcast (16 nodes)</p>
    <p>Improvement ranging from 14.4% (large messages) to 19.7% (small messages)</p>
    <p>Block size of 3K is performing the best</p>
  </div>
  <div class="page">
    <p>Anal. and Exp. Comparison (16 nodes) Broadcast</p>
    <p>Error difference of lesser than 7%</p>
  </div>
  <div class="page">
    <p>RDMA Vs Send-Receive for Large Clusters (Analytical Model Estimates: Broadcast)</p>
    <p>Estimated Improvement ranging from 16% (small messages) to 21% (large messages) for large clusters of sizes 512 nodes and 1024 nodes</p>
  </div>
  <div class="page">
    <p>Contents</p>
    <p>Motivation</p>
    <p>Design Issues</p>
    <p>RDMA-based Broadcast</p>
    <p>RDMA-based All Reduce  Degree-K tree</p>
    <p>Experimental Results (Binomial &amp; Degree-K)</p>
    <p>Analytical Models (Binomial &amp; Degree-K)</p>
    <p>Conclusions and Future Work</p>
  </div>
  <div class="page">
    <p>Degree-K tree-based Reduce</p>
    <p>P1 P2 P3 P4 P5 P6 P7P0</p>
    <p>[ 1 ] [ 1 ] [ 1 ] [ 1 ]</p>
    <p>[ 3 ]</p>
    <p>[ 2 ] [ 2 ]</p>
    <p>P1 P2 P3 P4 P5 P6 P7P0</p>
    <p>[ 1 ] [ 1 ]</p>
    <p>[ 2 ]</p>
    <p>P1 P2 P3 P4 P5 P6 P7P0</p>
    <p>[ 1 ]K = 1K = 3K = 7</p>
  </div>
  <div class="page">
    <p>Experimental Evaluation</p>
    <p>Integrated into MVICH-1.0</p>
    <p>Reduction Operation = MPI_SUM</p>
    <p>Data type = 1 INT (data size = 4 bytes)</p>
    <p>Count = 1 (4 bytes) to 1024 (4096) bytes</p>
    <p>Finding the optimal Degree-K</p>
    <p>Experimental Vs Analytical (best case &amp; worst case)</p>
    <p>Exp. and Anal. comparison of Send-Receive with RDMA</p>
  </div>
  <div class="page">
    <p>Degree-7</p>
    <p>Degree-3 Degree-3 Degree-1</p>
    <p>Degree-3 Degree-1</p>
    <p>Degree-3 Degree-1</p>
    <p>Choosing the Optimal Degree-K for All Reduce</p>
    <p>For lower message sizes, higher degrees perform better than degree-1 (binomial)</p>
  </div>
  <div class="page">
    <p>Degree-K RDMA-based All Reduce Analytical Model</p>
    <p>Experimental timings fall between the best case and the worst case analytical estimates</p>
    <p>For lower message sizes, higher degrees perform better than degree-1 (binomial)</p>
    <p>Degree-7</p>
    <p>Degree-3 Degree-3 Degree-1</p>
    <p>Degree-3 Degree-1</p>
    <p>Degree-3 Degree-1</p>
    <p>Degree-3 Degree-3 Degree-1</p>
    <p>Degree-3 Degree-3 Degree-1 1024 nodes</p>
    <p>Experimental Vs Analytical (Degree 3: 16 nodes)</p>
    <p>Message Size (bytes)</p>
    <p>L at en</p>
    <p>cy ( u s)</p>
    <p>Analytical (Best)</p>
    <p>Analytical (Worst)</p>
    <p>Experimental</p>
  </div>
  <div class="page">
    <p>Binomial Send-Receive Vs Optimal &amp; Binomial Degree-K RDMA (16 nodes) All Reduce</p>
    <p>Improvement ranging from 9% (large messages) to 38.13% (small messages) for the optimal degree-K RDMA-based All Reduce compared to Binomial Send-Receive</p>
  </div>
  <div class="page">
    <p>Binomial Send-Receive Vs Binomial &amp; Optimal Degree-K All Reduce for large clusters</p>
    <p>Improvement ranging from 14% (large messages) to 35-40% (small messages) for the optimal degree-K RDMA-based All Reduce compared to Binomial Send-Receive</p>
  </div>
  <div class="page">
    <p>Contents</p>
    <p>Motivation</p>
    <p>Design Issues</p>
    <p>RDMA-based Broadcast</p>
    <p>RDMA-based All Reduce</p>
    <p>Conclusions and Future Work</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Novel method to implement the collective communication</p>
    <p>library</p>
    <p>Degree-K algorithm to exploit the benefits of RDMA  Implemented the RDMA-based Broadcast and All Reduce  Broadcast: 19.7% improvement for small and 14.4% for large messages</p>
    <p>(16nodes)  All Reduce: 38.13% for small messages, 9.32% for large messages</p>
    <p>(16nodes)</p>
    <p>Analytical models for Broadcast and All Reduce  Estimate Performance benefits of large clusters  Broadcast: 16-21% for 512 and 1024 node clusters  All Reduce: 14-40% for 512 and 1024 node clusters</p>
  </div>
  <div class="page">
    <p>Future Work</p>
    <p>Exploit the RDMA Read feature if available  Round-trip cost design issues</p>
    <p>Extend to MPI-2.0  One sided Communication</p>
    <p>Extend framework to emerging InfiniBand architecture</p>
  </div>
  <div class="page">
    <p>For more information, please visit the</p>
    <p>http://nowlab.cis.ohio-state.edu</p>
    <p>Network Based Computing Group,</p>
    <p>The Ohio State University</p>
    <p>Thank You!</p>
    <p>NBC Home Page</p>
  </div>
  <div class="page">
    <p>Backup Slides</p>
  </div>
  <div class="page">
    <p>Receiver Side Best for Large messages (Analytical Model)</p>
    <p>P3</p>
    <p>P2</p>
    <p>P1 Tt ToTn Ts</p>
    <p>= ( Tt * k ) + Tn + Ts + To + Tc k - No of Sending nodes</p>
    <p>Tt ToTn Ts</p>
    <p>Tt ToTn Ts</p>
  </div>
  <div class="page">
    <p>P3</p>
    <p>P2</p>
    <p>P1</p>
    <p>To</p>
    <p>Tt Tn Ts To</p>
    <p>To</p>
    <p>Receiver Side Worst for Large messages (Analytical Model)</p>
    <p>= ( Tt * k ) + Tn + Ts + ( To * k ) + Tc k - No of Sending nodes</p>
    <p>Tt Tn Ts</p>
    <p>Tt Tn Ts</p>
  </div>
  <div class="page">
    <p>Buffer Registration and Initialization</p>
    <p>Static Registration Scheme (for size &lt;= 5K)</p>
    <p>P0 P1 P2 P3</p>
    <p>Constant Block size (5K+1)</p>
    <p>P1</p>
    <p>P2</p>
    <p>P3</p>
    <p>Each block is of size 5K+1. Every process has N blocks, where N is the number of processes in the communicator</p>
  </div>
  <div class="page">
    <p>Data Validity at Receiver End</p>
    <p>P0 P1 P2 P3</p>
    <p>P0 P1 P2 P3</p>
    <p>Computed Data</p>
    <p>P0 P1 P2 P3</p>
    <p>Data 1</p>
    <p>Data 2 9 1</p>
    <p>P0 P1 P2 P3</p>
    <p>Computed Data</p>
  </div>
</Presentation>
