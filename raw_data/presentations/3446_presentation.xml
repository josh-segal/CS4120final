<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Split and Rephrase: Better Evaluation and a Stronger Baseline</p>
    <p>Roee Aharoni and Yoav Goldberg NLP Lab, Bar Ilan University, Israel</p>
    <p>ACL 2018</p>
  </div>
  <div class="page">
    <p>Motivation</p>
  </div>
  <div class="page">
    <p>Motivation  Processing long, complex sentences is hard!</p>
  </div>
  <div class="page">
    <p>Motivation  Processing long, complex sentences is hard!  Children, people with reading disabilities, L2</p>
    <p>learners</p>
  </div>
  <div class="page">
    <p>Motivation  Processing long, complex sentences is hard!  Children, people with reading disabilities, L2</p>
    <p>learners</p>
    <p>Sentence level NLP systems:</p>
  </div>
  <div class="page">
    <p>Motivation  Processing long, complex sentences is hard!  Children, people with reading disabilities, L2</p>
    <p>learners</p>
    <p>Sentence level NLP systems:  Dependency Parsers</p>
    <p>McDonald &amp; Nivre, 2011</p>
  </div>
  <div class="page">
    <p>Motivation  Processing long, complex sentences is hard!  Children, people with reading disabilities, L2</p>
    <p>learners</p>
    <p>Sentence level NLP systems:  Dependency Parsers  Neural Machine Translation</p>
    <p>Koehn &amp; Knowles, 2017</p>
  </div>
  <div class="page">
    <p>Motivation  Processing long, complex sentences is hard!  Children, people with reading disabilities, L2</p>
    <p>learners</p>
    <p>Sentence level NLP systems:  Dependency Parsers  Neural Machine Translation</p>
    <p>Can we automatically break a complex sentence into several simple ones while preserving its meaning?</p>
    <p>Koehn &amp; Knowles, 2017</p>
  </div>
  <div class="page">
    <p>The Split and Rephrase Task</p>
  </div>
  <div class="page">
    <p>The Split and Rephrase Task  Narayan, Gardent, Cohen &amp; Shimorina, EMNLP 2017</p>
  </div>
  <div class="page">
    <p>The Split and Rephrase Task  Narayan, Gardent, Cohen &amp; Shimorina, EMNLP 2017  Dataset, evaluation method, baseline models</p>
  </div>
  <div class="page">
    <p>The Split and Rephrase Task  Narayan, Gardent, Cohen &amp; Shimorina, EMNLP 2017  Dataset, evaluation method, baseline models  Task definition: complex sentence -&gt; several simple sentences with the same meaning</p>
  </div>
  <div class="page">
    <p>The Split and Rephrase Task  Narayan, Gardent, Cohen &amp; Shimorina, EMNLP 2017  Dataset, evaluation method, baseline models  Task definition: complex sentence -&gt; several simple sentences with the same meaning</p>
    <p>Alan Bean joined NASA in 1963 where he became a member of the Apollo 12 mission along with Alfred Worden as back up pilot and David Scott as commander .</p>
  </div>
  <div class="page">
    <p>The Split and Rephrase Task  Narayan, Gardent, Cohen &amp; Shimorina, EMNLP 2017  Dataset, evaluation method, baseline models  Task definition: complex sentence -&gt; several simple sentences with the same meaning</p>
    <p>Alan Bean joined NASA in 1963 where he became a member of the Apollo 12 mission along with Alfred Worden as back up pilot and David Scott as commander .</p>
  </div>
  <div class="page">
    <p>The Split and Rephrase Task  Narayan, Gardent, Cohen &amp; Shimorina, EMNLP 2017  Dataset, evaluation method, baseline models  Task definition: complex sentence -&gt; several simple sentences with the same meaning</p>
    <p>Alan Bean served as a crew member of Apollo 12 . Alfred Worden was the backup pilot of Apollo 12 . Apollo 12 was commanded by David Scott . Alan Bean was selected by Nasa in 1963 .</p>
    <p>Alan Bean joined NASA in 1963 where he became a member of the Apollo 12 mission along with Alfred Worden as back up pilot and David Scott as commander .</p>
  </div>
  <div class="page">
    <p>The Split and Rephrase Task  Narayan, Gardent, Cohen &amp; Shimorina, EMNLP 2017  Dataset, evaluation method, baseline models  Task definition: complex sentence -&gt; several simple sentences with the same meaning  Requires (a) identifying independent semantic units (b) rephrasing those units to single</p>
    <p>sentences</p>
    <p>Alan Bean served as a crew member of Apollo 12 . Alfred Worden was the backup pilot of Apollo 12 . Apollo 12 was commanded by David Scott . Alan Bean was selected by Nasa in 1963 .</p>
    <p>Alan Bean joined NASA in 1963 where he became a member of the Apollo 12 mission along with Alfred Worden as back up pilot and David Scott as commander .</p>
  </div>
  <div class="page">
    <p>This Work</p>
  </div>
  <div class="page">
    <p>This Work</p>
    <p>We show that simple neural models seem to perform very on the original benchmark due to memorization of the training set</p>
  </div>
  <div class="page">
    <p>This Work</p>
    <p>We show that simple neural models seem to perform very on the original benchmark due to memorization of the training set</p>
    <p>We propose a more challenging data split for the task to discourage memorization</p>
  </div>
  <div class="page">
    <p>This Work</p>
    <p>We show that simple neural models seem to perform very on the original benchmark due to memorization of the training set</p>
    <p>We propose a more challenging data split for the task to discourage memorization</p>
    <p>We perform automatic evaluation and error analysis on the new benchmark, showing that the task is still far from being solved</p>
  </div>
  <div class="page">
    <p>WebSplit Dataset Construction (Narayan et al. 2017)</p>
  </div>
  <div class="page">
    <p>WebSplit Dataset Construction (Narayan et al. 2017)</p>
    <p>&lt;Alan_Bean | NASA selection | 1963&gt;</p>
    <p>Simple RDF Triples (facts from DBpedia)</p>
    <p>&lt;Alan_Bean | nationality | United_States&gt;</p>
    <p>&lt;Alan_Bean | mission | Apollo_12&gt;</p>
  </div>
  <div class="page">
    <p>WebSplit Dataset Construction (Narayan et al. 2017)</p>
    <p>&lt;Alan_Bean | NASA selection | 1963&gt;</p>
    <p>Simple RDF Triples (facts from DBpedia)</p>
    <p>&lt;Alan_Bean | nationality | United_States&gt;</p>
    <p>&lt;Alan_Bean | mission | Apollo_12&gt;</p>
    <p>Alan Bean is a US national.</p>
    <p>Simple Sentences</p>
    <p>Alan Bean was on the crew of Apollo 12.</p>
    <p>Alan Bean was hired by NASA in 1963.</p>
    <p>Alan Bean is a US national.</p>
    <p>Alan Bean was on the crew of Apollo 12.</p>
    <p>Alan Bean was hired by NASA in 1963.</p>
    <p>Alan Bean is a US national.</p>
    <p>Alan Bean was on the crew of Apollo 12.</p>
    <p>Alan Bean was hired by NASA in 1963.</p>
  </div>
  <div class="page">
    <p>WebSplit Dataset Construction (Narayan et al. 2017)</p>
    <p>&lt;Alan_Bean | nationality | United_States, Alan_Bean | mission | Apollo_12,</p>
    <p>Alan_Bean | NASA selection | 1963&gt;</p>
    <p>Sets of RDF triples</p>
    <p>&lt;Alan_Bean | NASA selection | 1963&gt;</p>
    <p>Simple RDF Triples (facts from DBpedia)</p>
    <p>&lt;Alan_Bean | nationality | United_States&gt;</p>
    <p>&lt;Alan_Bean | mission | Apollo_12&gt;</p>
    <p>Alan Bean is a US national.</p>
    <p>Simple Sentences</p>
    <p>Alan Bean was on the crew of Apollo 12.</p>
    <p>Alan Bean was hired by NASA in 1963.</p>
    <p>Alan Bean is a US national.</p>
    <p>Alan Bean was on the crew of Apollo 12.</p>
    <p>Alan Bean was hired by NASA in 1963.</p>
    <p>Alan Bean is a US national.</p>
    <p>Alan Bean was on the crew of Apollo 12.</p>
    <p>Alan Bean was hired by NASA in 1963.</p>
  </div>
  <div class="page">
    <p>WebSplit Dataset Construction (Narayan et al. 2017)</p>
    <p>&lt;Alan_Bean | nationality | United_States, Alan_Bean | mission | Apollo_12,</p>
    <p>Alan_Bean | NASA selection | 1963&gt;</p>
    <p>Sets of RDF triples</p>
    <p>&lt;Alan_Bean | NASA selection | 1963&gt;</p>
    <p>Simple RDF Triples (facts from DBpedia)</p>
    <p>&lt;Alan_Bean | nationality | United_States&gt;</p>
    <p>&lt;Alan_Bean | mission | Apollo_12&gt;</p>
    <p>Alan Bean, born in the United States, was selected by NASA in 1963 and served as a crew member of</p>
    <p>Apollo 12.</p>
    <p>Complex Sentences</p>
    <p>Alan Bean, born in the United States, was selected by NASA in 1963 and served as a crew member of</p>
    <p>Apollo 12.</p>
    <p>Alan Bean, born in the United States, was selected by NASA in 1963 and served as a crew member of</p>
    <p>Apollo 12.</p>
    <p>Alan Bean is a US national.</p>
    <p>Simple Sentences</p>
    <p>Alan Bean was on the crew of Apollo 12.</p>
    <p>Alan Bean was hired by NASA in 1963.</p>
    <p>Alan Bean is a US national.</p>
    <p>Alan Bean was on the crew of Apollo 12.</p>
    <p>Alan Bean was hired by NASA in 1963.</p>
    <p>Alan Bean is a US national.</p>
    <p>Alan Bean was on the crew of Apollo 12.</p>
    <p>Alan Bean was hired by NASA in 1963.</p>
  </div>
  <div class="page">
    <p>WebSplit Dataset Construction (Narayan et al. 2017)</p>
    <p>&lt;Alan_Bean | nationality | United_States, Alan_Bean | mission | Apollo_12,</p>
    <p>Alan_Bean | NASA selection | 1963&gt;</p>
    <p>Sets of RDF triples</p>
    <p>&lt;Alan_Bean | NASA selection | 1963&gt;</p>
    <p>Simple RDF Triples (facts from DBpedia)</p>
    <p>&lt;Alan_Bean | nationality | United_States&gt;</p>
    <p>&lt;Alan_Bean | mission | Apollo_12&gt;</p>
    <p>Alan Bean, born in the United States, was selected by NASA in 1963 and served as a crew member of</p>
    <p>Apollo 12.</p>
    <p>Complex Sentences</p>
    <p>Alan Bean, born in the United States, was selected by NASA in 1963 and served as a crew member of</p>
    <p>Apollo 12.</p>
    <p>Alan Bean, born in the United States, was selected by NASA in 1963 and served as a crew member of</p>
    <p>Apollo 12.</p>
    <p>Alan Bean is a US national.</p>
    <p>Simple Sentences</p>
    <p>Alan Bean was on the crew of Apollo 12.</p>
    <p>Alan Bean was hired by NASA in 1963.</p>
    <p>Alan Bean is a US national.</p>
    <p>Alan Bean was on the crew of Apollo 12.</p>
    <p>Alan Bean was hired by NASA in 1963.</p>
    <p>Alan Bean is a US national.</p>
    <p>Alan Bean was on the crew of Apollo 12.</p>
    <p>Alan Bean was hired by NASA in 1963.</p>
    <p>Matching via RDFs</p>
  </div>
  <div class="page">
    <p>WebSplit Dataset Construction (Narayan et al. 2017)</p>
    <p>&lt;Alan_Bean | nationality | United_States, Alan_Bean | mission | Apollo_12,</p>
    <p>Alan_Bean | NASA selection | 1963&gt;</p>
    <p>Sets of RDF triples</p>
    <p>&lt;Alan_Bean | NASA selection | 1963&gt;</p>
    <p>Simple RDF Triples (facts from DBpedia)</p>
    <p>&lt;Alan_Bean | nationality | United_States&gt;</p>
    <p>&lt;Alan_Bean | mission | Apollo_12&gt;</p>
    <p>Alan Bean, born in the United States, was selected by NASA in 1963 and served as a crew member of</p>
    <p>Apollo 12.</p>
    <p>Complex Sentences</p>
    <p>Alan Bean, born in the United States, was selected by NASA in 1963 and served as a crew member of</p>
    <p>Apollo 12.</p>
    <p>Alan Bean, born in the United States, was selected by NASA in 1963 and served as a crew member of</p>
    <p>Apollo 12.</p>
    <p>Alan Bean is a US national.</p>
    <p>Simple Sentences</p>
    <p>Alan Bean was on the crew of Apollo 12.</p>
    <p>Alan Bean was hired by NASA in 1963.</p>
    <p>Alan Bean is a US national.</p>
    <p>Alan Bean was on the crew of Apollo 12.</p>
    <p>Alan Bean was hired by NASA in 1963.</p>
    <p>Alan Bean is a US national.</p>
    <p>Alan Bean was on the crew of Apollo 12.</p>
    <p>Alan Bean was hired by NASA in 1963.</p>
    <p>Matching via RDFs ~1M examples</p>
  </div>
  <div class="page">
    <p>Preliminary Experiments</p>
  </div>
  <div class="page">
    <p>Preliminary Experiments  ~1M training examples</p>
  </div>
  <div class="page">
    <p>Preliminary Experiments  ~1M training examples  Vanilla LSTM seq2seq with attention</p>
    <p>comp lex sen ten ce</p>
  </div>
  <div class="page">
    <p>Preliminary Experiments  ~1M training examples  Vanilla LSTM seq2seq with attention  Shared vocabulary between the encoder and the decoder</p>
    <p>comp lex sen ten ce</p>
  </div>
  <div class="page">
    <p>Preliminary Experiments  ~1M training examples  Vanilla LSTM seq2seq with attention  Shared vocabulary between the encoder and the decoder  Simple sentences predicted as a single sequence</p>
    <p>comp lex sen ten ce</p>
  </div>
  <div class="page">
    <p>Preliminary Experiments  ~1M training examples  Vanilla LSTM seq2seq with attention  Shared vocabulary between the encoder and the decoder  Simple sentences predicted as a single sequence  Evaluated using single-sentence, multi-reference BLEU as in Narayan et al. 2017</p>
    <p>comp lex sen ten ce</p>
  </div>
  <div class="page">
    <p>Preliminary Results</p>
  </div>
  <div class="page">
    <p>Preliminary Results</p>
    <p>Our simple seq2seq baseline outperform all but one of the baselines from Narayan et al. 2017</p>
    <p>seq2seq (ours) hybrid seq2seq multi-seq2seq split-multi split-seq2seq</p>
  </div>
  <div class="page">
    <p>Preliminary Results</p>
    <p>Our simple seq2seq baseline outperform all but one of the baselines from Narayan et al. 2017</p>
    <p>Their best baselines were using the RDF structures as additional information</p>
    <p>seq2seq (ours) hybrid seq2seq multi-seq2seq split-multi split-seq2seq</p>
    <p>Text Only Text + RDFs</p>
  </div>
  <div class="page">
    <p>Preliminary Results</p>
    <p>Our simple seq2seq baseline outperform all but one of the baselines from Narayan et al. 2017</p>
    <p>Their best baselines were using the RDF structures as additional information</p>
    <p>Do the simple seq2seq model really performs so well?</p>
    <p>seq2seq (ours) hybrid seq2seq multi-seq2seq split-multi split-seq2seq</p>
    <p>Text Only Text + RDFs</p>
  </div>
  <div class="page">
    <p>BLEU can be Misleading</p>
  </div>
  <div class="page">
    <p>BLEU can be Misleading  In spite of the high BLEU scores, our neural models suffer from:</p>
  </div>
  <div class="page">
    <p>BLEU can be Misleading  In spite of the high BLEU scores, our neural models suffer from:  Missing facts - appeared in the input but not in the output</p>
  </div>
  <div class="page">
    <p>BLEU can be Misleading  In spite of the high BLEU scores, our neural models suffer from:  Missing facts - appeared in the input but not in the output  Unsupported facts - appeared in the output but not in the input</p>
  </div>
  <div class="page">
    <p>BLEU can be Misleading  In spite of the high BLEU scores, our neural models suffer from:  Missing facts - appeared in the input but not in the output  Unsupported facts - appeared in the output but not in the input  Repeated facts - appeared several times in the output</p>
  </div>
  <div class="page">
    <p>A Closer Look</p>
  </div>
  <div class="page">
    <p>A Closer Look  Visualizing the attention</p>
    <p>weights we find an unexpected pattern</p>
  </div>
  <div class="page">
    <p>A Closer Look  Visualizing the attention</p>
    <p>weights we find an unexpected pattern</p>
    <p>The network mainly attends to a single token instead of spreading the attention</p>
  </div>
  <div class="page">
    <p>A Closer Look  Visualizing the attention</p>
    <p>weights we find an unexpected pattern</p>
    <p>The network mainly attends to a single token instead of spreading the attention</p>
    <p>This token was usually a part of the first mentioned entity</p>
  </div>
  <div class="page">
    <p>A Closer Look  Visualizing the attention</p>
    <p>weights we find an unexpected pattern</p>
    <p>The network mainly attends to a single token instead of spreading the attention</p>
    <p>This token was usually a part of the first mentioned entity</p>
    <p>Consistent among different input examples</p>
  </div>
  <div class="page">
    <p>A Closer Look  Visualizing the attention</p>
    <p>weights we find an unexpected pattern</p>
    <p>The network mainly attends to a single token instead of spreading the attention</p>
    <p>This token was usually a part of the first mentioned entity</p>
    <p>Consistent among different input examples</p>
  </div>
  <div class="page">
    <p>A Closer Look  Visualizing the attention</p>
    <p>weights we find an unexpected pattern</p>
    <p>The network mainly attends to a single token instead of spreading the attention</p>
    <p>This token was usually a part of the first mentioned entity</p>
    <p>Consistent among different input examples</p>
  </div>
  <div class="page">
    <p>Testing for Over-Memorization</p>
  </div>
  <div class="page">
    <p>Testing for Over-Memorization  In this stage we suspect that the network heavily memorizes entity-fact pairs</p>
  </div>
  <div class="page">
    <p>Testing for Over-Memorization  In this stage we suspect that the network heavily memorizes entity-fact pairs  We test this by introducing it with inputs consisting of repeated entities alone</p>
  </div>
  <div class="page">
    <p>Testing for Over-Memorization  In this stage we suspect that the network heavily memorizes entity-fact pairs  We test this by introducing it with inputs consisting of repeated entities alone  The network indeed generates facts it memorized about those specific</p>
    <p>entities</p>
  </div>
  <div class="page">
    <p>Testing for Over-Memorization  In this stage we suspect that the network heavily memorizes entity-fact pairs  We test this by introducing it with inputs consisting of repeated entities alone  The network indeed generates facts it memorized about those specific</p>
    <p>entities</p>
  </div>
  <div class="page">
    <p>Searching for the Cause: Dataset Artifacts</p>
  </div>
  <div class="page">
    <p>Searching for the Cause: Dataset Artifacts  The original dataset included overlap between the training/development/test sets</p>
  </div>
  <div class="page">
    <p>Searching for the Cause: Dataset Artifacts  The original dataset included overlap between the training/development/test sets  When looking at the complex sentences side, there is no overlap</p>
    <p>Train Complex</p>
    <p>Dev Complex</p>
    <p>Test Complex</p>
    <p>source</p>
  </div>
  <div class="page">
    <p>Searching for the Cause: Dataset Artifacts  The original dataset included overlap between the training/development/test sets  When looking at the complex sentences side, there is no overlap  On the other hand, most of the simple sentences did overlap (~90%)</p>
    <p>Train Complex</p>
    <p>Dev Complex</p>
    <p>Test Complex</p>
    <p>source Train Simple</p>
    <p>Dev Simple</p>
    <p>Test Simple</p>
    <p>target</p>
  </div>
  <div class="page">
    <p>Searching for the Cause: Dataset Artifacts  The original dataset included overlap between the training/development/test sets  When looking at the complex sentences side, there is no overlap  On the other hand, most of the simple sentences did overlap (~90%)  Makes memorization very effective - leakage from train on the target side</p>
    <p>Train Complex</p>
    <p>Dev Complex</p>
    <p>Test Complex</p>
    <p>source Train Simple</p>
    <p>Dev Simple</p>
    <p>Test Simple</p>
    <p>target</p>
  </div>
  <div class="page">
    <p>New Data Split</p>
  </div>
  <div class="page">
    <p>New Data Split</p>
    <p>To remedy this, we construct a new data split by using the RDF information:</p>
  </div>
  <div class="page">
    <p>New Data Split</p>
    <p>To remedy this, we construct a new data split by using the RDF information:  Ensuring that all RDF relation types appear in the training set (enable generalization)</p>
  </div>
  <div class="page">
    <p>New Data Split</p>
    <p>To remedy this, we construct a new data split by using the RDF information:  Ensuring that all RDF relation types appear in the training set (enable generalization)  Ensuring that no RDF triple (fact) appears in two different sets (reduce memorization)</p>
  </div>
  <div class="page">
    <p>New Data Split</p>
    <p>To remedy this, we construct a new data split by using the RDF information:  Ensuring that all RDF relation types appear in the training set (enable generalization)  Ensuring that no RDF triple (fact) appears in two different sets (reduce memorization)</p>
    <p>The resulting dataset has no overlapping simple sentences</p>
    <p>Original Split New Split unique dev simple sentences in train 90.9% 0.09% unique test simple sentences in train 89.8% 0%</p>
    <p>% dev vocabulary in train 97.2% 63% % test vocabulary in train 96.3% 61.7%</p>
  </div>
  <div class="page">
    <p>New Data Split</p>
    <p>To remedy this, we construct a new data split by using the RDF information:  Ensuring that all RDF relation types appear in the training set (enable generalization)  Ensuring that no RDF triple (fact) appears in two different sets (reduce memorization)</p>
    <p>The resulting dataset has no overlapping simple sentences  Has more unknown symbols in dev/test - need better models!</p>
    <p>Original Split New Split unique dev simple sentences in train 90.9% 0.09% unique test simple sentences in train 89.8% 0%</p>
    <p>% dev vocabulary in train 97.2% 63% % test vocabulary in train 96.3% 61.7%</p>
  </div>
  <div class="page">
    <p>Copy Mechanism</p>
  </div>
  <div class="page">
    <p>Copy Mechanism  To help with the increase in unknown words in the harder split, we incorporate a</p>
    <p>copy mechanism</p>
  </div>
  <div class="page">
    <p>Copy Mechanism  To help with the increase in unknown words in the harder split, we incorporate a</p>
    <p>copy mechanism</p>
    <p>Gu et al. 2016, See et al. 2017, Merity et al. 2017</p>
  </div>
  <div class="page">
    <p>Copy Mechanism  To help with the increase in unknown words in the harder split, we incorporate a</p>
    <p>copy mechanism</p>
    <p>Gu et al. 2016, See et al. 2017, Merity et al. 2017  Uses a copy switch - feed-forward NN component with a sigmoid-activated</p>
    <p>scalar output</p>
  </div>
  <div class="page">
    <p>Copy Mechanism  To help with the increase in unknown words in the harder split, we incorporate a</p>
    <p>copy mechanism</p>
    <p>Gu et al. 2016, See et al. 2017, Merity et al. 2017  Uses a copy switch - feed-forward NN component with a sigmoid-activated</p>
    <p>scalar output</p>
    <p>Controls the interpolation of the softmax probabilities and the copy probabilities over the input tokens in each decoder step</p>
    <p>copy switch</p>
    <p>attention weights (copy)</p>
    <p>softmax output</p>
  </div>
  <div class="page">
    <p>Results - New Split</p>
  </div>
  <div class="page">
    <p>Results - New Split</p>
    <p>Baseline seq2seq models completely break (BLEU &lt; 7) on the new split</p>
    <p>original split new split</p>
    <p>seq2seq +copy</p>
  </div>
  <div class="page">
    <p>Results - New Split</p>
    <p>Baseline seq2seq models completely break (BLEU &lt; 7) on the new split</p>
    <p>Copy mechanism helps to generalize</p>
    <p>original split new split</p>
    <p>seq2seq +copy</p>
  </div>
  <div class="page">
    <p>Results - New Split</p>
    <p>Baseline seq2seq models completely break (BLEU &lt; 7) on the new split</p>
    <p>Copy mechanism helps to generalize</p>
    <p>Much lower than the original benchmark - memorization was crucial for the high BLEU</p>
    <p>original split new split</p>
    <p>seq2seq +copy</p>
  </div>
  <div class="page">
    <p>Copying and Attention</p>
  </div>
  <div class="page">
    <p>Copying and Attention No-Copy With-Copy</p>
    <p>The copy-enhanced models spread the attention across the input tokens while improving results</p>
  </div>
  <div class="page">
    <p>Error Analysis</p>
  </div>
  <div class="page">
    <p>Error Analysis  On the original split the</p>
    <p>models did very well (due to memorization) with up to 91% correct simple sentences</p>
    <p>original split new split</p>
    <p>correct repeated missing unsupported</p>
  </div>
  <div class="page">
    <p>Error Analysis  On the original split the</p>
    <p>models did very well (due to memorization) with up to 91% correct simple sentences</p>
    <p>On the new benchmark the best model got only up to 20% correct simple sentences</p>
    <p>original split new split</p>
    <p>correct repeated missing unsupported</p>
  </div>
  <div class="page">
    <p>Error Analysis  On the original split the</p>
    <p>models did very well (due to memorization) with up to 91% correct simple sentences</p>
    <p>On the new benchmark the best model got only up to 20% correct simple sentences</p>
    <p>The task is much more challenging then previously demonstrated</p>
    <p>original split new split</p>
    <p>correct repeated missing unsupported</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Simple neural models seem to perform well due to memorization</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Simple neural models seem to perform well due to memorization  We propose a more challenging data split for the task to discourage this</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Simple neural models seem to perform well due to memorization  We propose a more challenging data split for the task to discourage this</p>
    <p>A similar update was proposed by Narayan et al. in parallel to our work (WebSplit v1.0)</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Simple neural models seem to perform well due to memorization  We propose a more challenging data split for the task to discourage this</p>
    <p>A similar update was proposed by Narayan et al. in parallel to our work (WebSplit v1.0)</p>
    <p>We perform automatic evaluation and error analysis on the new benchmarks, showing that the task is still far from being solved</p>
  </div>
  <div class="page">
    <p>More Broadly</p>
  </div>
  <div class="page">
    <p>More Broadly  Creating datasets is hard!</p>
  </div>
  <div class="page">
    <p>More Broadly  Creating datasets is hard!</p>
    <p>Think how models can cheat&quot;</p>
  </div>
  <div class="page">
    <p>More Broadly  Creating datasets is hard!</p>
    <p>Think how models can cheat&quot;  Create a challenging evaluation environment to capture generalization</p>
  </div>
  <div class="page">
    <p>More Broadly  Creating datasets is hard!</p>
    <p>Think how models can cheat&quot;  Create a challenging evaluation environment to capture generalization  Look for leakage of train to dev/test</p>
  </div>
  <div class="page">
    <p>More Broadly  Creating datasets is hard!</p>
    <p>Think how models can cheat&quot;  Create a challenging evaluation environment to capture generalization  Look for leakage of train to dev/test</p>
    <p>Numbers can be misleading!</p>
  </div>
  <div class="page">
    <p>More Broadly  Creating datasets is hard!</p>
    <p>Think how models can cheat&quot;  Create a challenging evaluation environment to capture generalization  Look for leakage of train to dev/test</p>
    <p>Numbers can be misleading!  Look at the data</p>
  </div>
  <div class="page">
    <p>More Broadly  Creating datasets is hard!</p>
    <p>Think how models can cheat&quot;  Create a challenging evaluation environment to capture generalization  Look for leakage of train to dev/test</p>
    <p>Numbers can be misleading!  Look at the data  Look at the model</p>
  </div>
  <div class="page">
    <p>More Broadly  Creating datasets is hard!</p>
    <p>Think how models can cheat&quot;  Create a challenging evaluation environment to capture generalization  Look for leakage of train to dev/test</p>
    <p>Numbers can be misleading!  Look at the data  Look at the model  Error analysis</p>
  </div>
  <div class="page">
    <p>Thank You!</p>
  </div>
</Presentation>
