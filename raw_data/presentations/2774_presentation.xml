<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>ResQ: Enabling SLOs in Network Function Virtualization</p>
    <p>Amin Tootoonchian* Aurojit Panda Chang Lan Melvin Walls</p>
    <p>Katerina Argyraki Sylvia Ratnasamy Scott Shenker</p>
    <p>*Intel Labs UC Berkeley ICSI NYU Nefeli EPFL</p>
  </div>
  <div class="page">
    <p>Classic approach Dedicated hardware Individual functions</p>
    <p>NFV approach Shared hardware</p>
    <p>Functions in software</p>
    <p>NFV Builds on Resource Sharing</p>
  </div>
  <div class="page">
    <p>Performance depends on neighbors activity.</p>
    <p>Due to sharing of network, server, and processor resources.</p>
    <p>Offering Performance Guarantees Is Challenging</p>
    <p>Cluster</p>
    <p>Pr oc</p>
    <p>es so</p>
    <p>r Processor DDR DDR</p>
    <p>RAM RAM</p>
    <p>PCI-E PCI-E</p>
    <p>N IC</p>
    <p>N IC</p>
    <p>QPI</p>
    <p>Server</p>
    <p>Shared Cache (LLC)</p>
    <p>Memory Controller</p>
    <p>Processor Interconnect I/O Controller</p>
    <p>Core Core</p>
    <p>Core</p>
    <p>Core Core</p>
    <p>Core</p>
    <p>Processor</p>
  </div>
  <div class="page">
    <p>Cluster</p>
    <p>Pr oc</p>
    <p>es so</p>
    <p>r Processor</p>
    <p>DDR DDR</p>
    <p>RAM RAM</p>
    <p>PCI-E PCI-E</p>
    <p>N IC</p>
    <p>N IC</p>
    <p>QPI</p>
    <p>Server</p>
    <p>Shared Cache (LLC)</p>
    <p>Memory Controller</p>
    <p>Processor Interconnect I/O Controller</p>
    <p>Core Core</p>
    <p>Core</p>
    <p>Core Core</p>
    <p>Core</p>
    <p>Processor</p>
    <p>Assumptions on Resource Sharing and Isolation</p>
    <p>Traffic isolation through fabric and NIC QoS mechanisms. Independent NFs do not share the same core.</p>
    <p>But share on-die uncore resources.</p>
    <p>Shared Cache (LLC)</p>
    <p>Memory Controller</p>
    <p>Processor Interconnect I/O Controller</p>
    <p>Core Core</p>
    <p>Core</p>
    <p>Core Core</p>
    <p>Core</p>
  </div>
  <div class="page">
    <p>Does Resource Contention Matter?</p>
    <p>port1 core1</p>
    <p>Traffic Generator</p>
    <p>port2 core2</p>
    <p>port3 core3</p>
    <p>portn coren</p>
    <p>Solo run</p>
    <p>Target NFs throughput Target NFs latency</p>
    <p>Tsolo Lsolo</p>
    <p>port1 core1</p>
    <p>port2 core2</p>
    <p>port3 core3</p>
    <p>portn coren</p>
    <p>port1 core1</p>
    <p>port2 core2</p>
    <p>port3 core3</p>
    <p>portn coren</p>
    <p>port1 core1</p>
    <p>port2 core2</p>
    <p>port3 core3</p>
    <p>portn coren</p>
    <p>Consolidated runs</p>
    <p>T1 L1</p>
    <p>T2 L2</p>
    <p>Tm Lm</p>
    <p>How far off is min(&amp;) and max &amp; from +,-, and +,-,?</p>
  </div>
  <div class="page">
    <p>D eg ra da tio</p>
    <p>n (%</p>
    <p>)</p>
    <p>Throughput Degradation</p>
    <p>Small packets</p>
    <p>Large packets</p>
    <p>Does Resource Contention Matter?</p>
    <p>D eg ra da tio</p>
    <p>n (%</p>
    <p>)</p>
    <p>Latency Degradation</p>
    <p>Small packets</p>
    <p>Large packets</p>
    <p>Significant degradation for most NFs.</p>
  </div>
  <div class="page">
    <p>Prediction (indirect)  Contention-aware placement.  Accurate prediction is hard.  Optimistic  SLO violation.  Conservative  inefficient.</p>
    <p>Algorithmically complex.  No isolation with SLO violations.  May lead to neighbor violations.</p>
    <p>Isolation (direct)  Neighbor-indep. placement.  No need for prediction.  Algorithmically simpler.  Isolation despite SLO violations.  Never affects neighbors SLOs.</p>
    <p>Approaches to Offer Performance SLOs</p>
    <p>Enabler: emergence of hardware resource isolation mechanisms.</p>
  </div>
  <div class="page">
    <p>ResQ: SLO Enforcement by Direct Isolation</p>
  </div>
  <div class="page">
    <p>Direct Performance Isolation</p>
  </div>
  <div class="page">
    <p>Enabler: Hardware Resource Isolation</p>
    <p>Shared Cache (LLC)</p>
    <p>Memory Controller</p>
    <p>Processor Interconnect I/O Controller</p>
    <p>Core Core</p>
    <p>Core</p>
    <p>Core Core</p>
    <p>Core</p>
    <p>Intel Cache Allocation Technology (CAT) for LLC isolation:  Classify cores/threads/VMs.  Assign parts of LLC to classes.</p>
    <p>Is LLC isolation sufficient to ensure NF performance isolation?</p>
  </div>
  <div class="page">
    <p>Achieves a high level of isolation with small packets.</p>
    <p>But up to 15% degradation with large packets.  Despite small-packet traffic being more resource intensive.</p>
    <p>Observed high memory utilization with large-packet traffic.  But, in general, we expect NFs to generate low memory traffic.  Also, NF LLC miss rates with large &amp; small packets are comparable.</p>
    <p>Root cause: high I/O-related mem. traffic due to LLC misses.</p>
    <p>LLC Isolation Is Not Sufficient!</p>
  </div>
  <div class="page">
    <p>NICs do DMA transfers to part of LLC.  Enabled by Intel Data Direct I/O Technology (DDIO).  By default, uses 10% of LLC to allocate buffers.</p>
    <p>Contention for DDIO LLC space.  Large packets require 12x more space than small packets.  CAT does not apply to I/O.</p>
    <p>The Leaky DMA Problem</p>
    <p>Shared Cache (LLC)</p>
    <p>Memory Controller</p>
    <p>Processor Interconnect I/O Controller</p>
    <p>Core Core</p>
    <p>Core</p>
    <p>Core Core</p>
    <p>Core</p>
    <p>RX/TX</p>
    <p>Co nt en</p>
    <p>tio n</p>
    <p>Solution: limit # on-the-fly packets, e.g., buffer sizing.</p>
  </div>
  <div class="page">
    <p>D eg ra da tio</p>
    <p>n (%</p>
    <p>) Throughput Degradation</p>
    <p>Small packets</p>
    <p>Large packets</p>
    <p>D eg ra da tio</p>
    <p>n (%</p>
    <p>)</p>
    <p>Latency Degradation</p>
    <p>Small packets</p>
    <p>Large packets</p>
    <p>D eg ra da tio</p>
    <p>n (%</p>
    <p>) Small packets</p>
    <p>Large packets</p>
    <p>D eg ra da tio</p>
    <p>n (%</p>
    <p>) Small packets</p>
    <p>Large packets</p>
    <p>BE FO</p>
    <p>RE A FT ER</p>
    <p>Accuracy of ResQs Isolation Mechanism</p>
    <p>LLC isolation and buffer sizing ensures performance isolation with a high degree of accuracy (&lt;3% error).</p>
  </div>
  <div class="page">
    <p>Performance SLO Enforcement</p>
  </div>
  <div class="page">
    <p>Reserved SLOs: static allocation.  Input: NF, expected config and traffic profile.  Target: throughput, latency.</p>
    <p>On-demand SLOs: dynamic allocation.  Input: NF.  Target: latency.</p>
    <p>ResQ SLOs</p>
  </div>
  <div class="page">
    <p>Profile NFs.  Construct a performance model.  Fast and scalable.</p>
    <p>Fast greedy allocation.  Deny admission if infeasible.  Compute # of instances.  Compute core &amp; LLC allocation per instance.</p>
    <p>ResQ Admission Process</p>
  </div>
  <div class="page">
    <p>MILP formulation for the optimal solution.  Slow compared to greedy allocation.</p>
    <p>Run in the background (i.e., not in the admission path).  Rearrange NFs if necessary.</p>
    <p>Practical for small clusters.  Takes seconds to minutes.  Larger clusters: divide into smaller ones with independent solvers.</p>
    <p>ResQ Optimal Scheduler</p>
  </div>
  <div class="page">
    <p>Resource Efficiency</p>
    <p>ResQ Optimal ResQ Greedy Dynamic (no isolation)</p>
    <p>Prediction [1] (no isolation)</p>
    <p># Se rv er s</p>
    <p>Insensitive Combination Sensitive</p>
    <p>Only up to 18.5% worse than optimal Cost of hard partitioning is &lt;3%</p>
    <p>compared to greedy.</p>
    <p>Highly inefficient (conservative predictor)</p>
    <p>[1] Mihai Dobrescu, Katerina Argyraki, and Sylvia Ratnasamy. Toward Predictable Performance in Software Packet-Processing Platforms. NSDI12.</p>
  </div>
  <div class="page">
    <p>ResQ achieves better accuracy &amp; efficiency than prior work.  Despite using simple heuristics and algorithms.</p>
    <p>Enabled by direct performance isolation.  Plenty of room for improvement with software mechanisms.</p>
    <p>Code available at https://github.com/netsys/resq  Useful for general NFV experimentation.</p>
    <p>Conclusion</p>
  </div>
</Presentation>
