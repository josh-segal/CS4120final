<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Tick Tock: Building Browser Red Pills from Timing Side Channels</p>
    <p>Grant Ho, Dan Boneh and Lucas Ballard, Niels Provos</p>
    <p>Stanford Google</p>
  </div>
  <div class="page">
    <p>Terminology: Red Pills</p>
    <p>Red Pill: code that distinguishes between a real execution environment vs. emulated/virtualized environment</p>
    <p>Native Red Pills: Red pills that execute at application layer (directly on OS).</p>
    <p>Browser Red Pills: Red pills executed in the browser sandbox (embedded in webpages)</p>
  </div>
  <div class="page">
    <p>Prior Work on Red Pills: Differentiating VMs from Real Machines</p>
    <p>Black Hat 2005: Original Native Red Pill by J. Rutkowska</p>
    <p>Since then, many other papers on native red pills (Chen 2008, Franklin 2008, Kapravelos 2011, Paleari 2009, Shi 2014, etc.)</p>
    <p>Key Problem: Native red pills rely on low-level operations (examining registers, looking for debugging processes, etc.)</p>
    <p>Inaccessible to websites (Javascript in the browser)</p>
    <p>This Talk: Designing browser red pills</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Perspective: Malicious website (e.g. drive-by download)</p>
    <p>Challenge: Anti-malware honeypots (i.e. instrumented VMs)</p>
    <p>Goal: deliver malicious web content to normal users, but act benignly in anti-malware honeypots (VMs).</p>
  </div>
  <div class="page">
    <p>Attack Model</p>
    <p>Malicious Website</p>
    <p>Honeypot (VM)</p>
    <p>?</p>
    <p>Real user</p>
    <p>or</p>
  </div>
  <div class="page">
    <p>Attack Model</p>
    <p>?</p>
  </div>
  <div class="page">
    <p>Attack Model</p>
    <p>Malicious Website</p>
    <p>Real user</p>
    <p>Honeypot (VM)</p>
    <p>Real user detected</p>
    <p>VM detected</p>
  </div>
  <div class="page">
    <p>Design and Implementation of Browser Red Pills</p>
  </div>
  <div class="page">
    <p>Distinguishing VM vs. non-VM from the Browser</p>
    <p>Cant access low-level configuration anomalies, but what about performance anomalies?</p>
    <p>Side effects of a virtualization = altered behavior/performance of certain operations?</p>
    <p>Main Idea: Measure execution time of certain Javascript operations (differential operations) to detect virtualization performance anomalies</p>
  </div>
  <div class="page">
    <p>Constructing Timing-Based Red Pills</p>
    <p>Problem: How do you account for performance differences that results from different hardware or background activity?</p>
    <p>Raw execution times unreliable</p>
    <p>Solution: Use relative timing measurements for red pills</p>
  </div>
  <div class="page">
    <p>Constructing Timing-Based Red Pills</p>
    <p>Idea: Run a simple Javascript operation (baseline operation) to gauge background load/base performance</p>
    <p>Also, baseline operation should not have performance difference between VM and non-VM</p>
    <p>Adjust red pills timing measurement for background load by: dividing the differential operations execution time by this baseline time</p>
    <p>Timing done in Javascript (granularity: 1 millisecond)</p>
  </div>
  <div class="page">
    <p>Browser Red Pills Schematic</p>
    <p>Three steps to browser red pill, which returns a number (timing ratio).</p>
    <p>Browser Red Pill</p>
    <p>Step 1: Execute baseline op and measure execution time</p>
    <p>Step 2: Execute differential op and measure execution time</p>
    <p>Return: differential_op_time /</p>
    <p>baseline_op_time</p>
  </div>
  <div class="page">
    <p>Differential Operations</p>
    <p>Baseline Operations</p>
  </div>
  <div class="page">
    <p>Evaluation and Results</p>
  </div>
  <div class="page">
    <p>Testing Environment</p>
    <p>Windows 7 and Windows 8.1 on real machines, VMWare in binary translation mode, and VMWare in hardware-assisted virtualization mode (6 system environments)</p>
    <p>Chrome 34, Firefox 29, IE 11 (3 browser environments)</p>
    <p>18 Total environments: {Chrome, Firefox, IE} x {Real, VM-BT, VM-HV} x {Win 7, 8}</p>
    <p>Loaded each red pill webpage 100 times w/ 500 ms in-between reloads</p>
  </div>
  <div class="page">
    <p>Evaluation Methodology</p>
    <p>Now we have distributions (100 measurements) of red pill timing ratios</p>
    <p>For each red pill on a given {browser, OS} combination:  Compare distribution of timing ratios for: Real Machine vs. VM-BT  Compare distribution of timing ratios for: Real Machine vs. VM-HV</p>
    <p>Key question: Is there a significant and practical difference between a red pills timing ratios on a VM vs. non-VM?</p>
  </div>
  <div class="page">
    <p>Evaluation Metrics</p>
    <p>Two criteria (both should be satisfied):</p>
  </div>
  <div class="page">
    <p>Criteria 1: Independent, Two-Sample T-Test</p>
    <p>Welchs t-test: two independent samples with unknown population variances</p>
    <p>Is there a statistically significant difference between distribution A (e.g. real machine timing ratios) and distribution B (e.g. VM timing ratios)?</p>
  </div>
  <div class="page">
    <p>Criteria 1: Two-Sample T-Test (Cont.)</p>
    <p>p-value from t-test: probability that there is no statistical difference between the two distributions</p>
    <p>Criteria 1: t-test of average timing ratios of VM vs. non-VM has</p>
    <p>p-value &lt; 0.05 (all our successful red pills have p-value &lt; 0.000001)</p>
  </div>
  <div class="page">
    <p>Criteria 2: Minimally Overlapping Distributions</p>
    <p>Magic-number cut-off: high probability of evading of VMs and targeting of real machines</p>
    <p>VM Avg. Time Ratio</p>
    <p>- VM St. Dev.</p>
    <p>+ VM St. Dev.</p>
    <p>Non-VM Avg. Time Ratio</p>
    <p>+ Non-VM St. Dev.</p>
    <p>- Non-VM St. Dev.</p>
    <p>No overlap</p>
  </div>
  <div class="page">
    <p>Results: Number of Successful Red Pills per Environment</p>
    <p>Chrome IE Firefox</p>
    <p>Windows 8 BT 6 3 4</p>
    <p>Windows 8 HV 6 3 4</p>
    <p>Windows 7 BT 3 5 4</p>
    <p>Windows 7 HV 3 5 4</p>
    <p>BT = Binary Translation VM, HV = Hardware-assisted virtualization VM  Numbers represent sum of successful red pills from both DOM baseline +</p>
    <p>Memory baseline</p>
  </div>
  <div class="page">
    <p>Defenses for Honeypots</p>
  </div>
  <div class="page">
    <p>Distorting Time in the Honeypot</p>
    <p>Replace Javascript timing functions with fake timing  Return random or faster timing measurements</p>
    <p>Replace Javascript/HTML5 operations with fake functions  Cheat on differential operation execution by completing</p>
    <p>early/faking execution</p>
    <p>These are weaker defenses likely induce other anomalies.</p>
  </div>
  <div class="page">
    <p>Detecting Javascript Evasion (Red Pills)</p>
    <p>Detect differential operations  Efficacy unclear for many operations (e.g. Console writing and</p>
    <p>Graphics)</p>
    <p>Detect baseline operations  More practical and effective against current baseline operations</p>
    <p>Compare rendered content in non-VM and VM to find evasive JS (Kapravelos 2013, Kirat 2014)</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Browser red pills are possible via timing side-channels  Timing/performance analysis overcome restricted computing environment</p>
    <p>Baseline operations resolve background load/noise</p>
    <p>Highly effective:  Three major browsers on two latest versions of Windows</p>
    <p>Hardware-assisted virtualization and binary translation</p>
    <p>Detecting baseline operation most promising defense</p>
    <p>Future work: (1) Measure prevalence of existing JS red pills</p>
    <p>(2) Understand JS implementation diffs in good red pills</p>
  </div>
  <div class="page">
    <p>Questions?</p>
  </div>
</Presentation>
