<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>NETWORK VIRTUALIZATION IN</p>
    <p>MULTI-TENANT DATACENTERS Teemu Koponen</p>
    <p>with Keith Amidon, Peter Balland, Martn Casado, Anupam Chanda, Bryan Fulton, Igor Ganichev, Jesse Gross, Natasha Gude, Paul</p>
    <p>Ingram, Ethan Jackson, Andrew Lambeth, Romain Lenglet, Shih-Hao Li, Amar Padmanabhan, Justin Pettit, Ben Pfaff, Rajiv Ramanathan, Scott Shenker, Alan Shieh, Jeremy Stribling, Pankaj Thakkar, Dan Wendlandt, Alexander Yip, and Ronghua Zhang</p>
  </div>
  <div class="page">
    <p>NETWORK VIRTUALIZATION?</p>
    <p>VLAN MPLS</p>
    <p>~1985 1995+ Late 1990s</p>
    <p>VRFNAT</p>
    <p>FlowVisor</p>
    <p>Network Elements as VMs</p>
    <p>~2005</p>
    <p>VLAN NAT MPLS VRF Elements as VMs FlowVisor</p>
    <p>Subnet IP address space Path L3 FIB Elements ASIC</p>
    <p>Plenty of primitives but no network virtualization per se.</p>
  </div>
  <div class="page">
    <p>MULTI-TENANT DATACENTERS</p>
    <p>Compute Virtualization Layer</p>
    <p>Slow provisioning</p>
    <p>Limited VM placement</p>
    <p>Mobility is limited</p>
    <p>Hardware dependent</p>
    <p>Operationally intensive</p>
    <p>Result with the aforementioned primitives:</p>
  </div>
  <div class="page">
    <p>NETWORK HYPERVISOR</p>
    <p>Server Hypervisor Network Hypervisor</p>
    <p>Standard x86 Standard IP connectivity</p>
    <p>VMs Logical Networks</p>
    <p>Decoupled</p>
    <p>A pp</p>
    <p>A pp</p>
    <p>A pp</p>
    <p>A pp</p>
    <p>A pp</p>
    <p>A pp</p>
    <p>A pp</p>
    <p>x86</p>
    <p>W or</p>
    <p>klo ad</p>
    <p>W or</p>
    <p>klo ad</p>
    <p>W or</p>
    <p>klo ad</p>
    <p>W or</p>
    <p>klo ad</p>
    <p>W or</p>
    <p>klo ad</p>
    <p>W or</p>
    <p>klo ad</p>
    <p>W or</p>
    <p>klo ad</p>
    <p>L2, L3, L4-L7 Services</p>
  </div>
  <div class="page">
    <p>AGENDA</p>
    <p>Overall design of NVP network hypervisor.</p>
    <p>Design challenges.</p>
    <p>Hard lessons learnt.</p>
    <p>Whats next in network virtualization?</p>
  </div>
  <div class="page">
    <p>WHAT IS A NETWORK HYPERVISOR?</p>
    <p>! ! ! !</p>
    <p>Network Hypervisor</p>
    <p>Packet Abstraction</p>
    <p>Control Abstraction</p>
    <p>Mgmt</p>
    <p>Mgmt Mgmt</p>
    <p>Packet Abstraction + Control Abstraction = Network Hypervisor</p>
    <p>Logical Network Logical NetworkLogical Network</p>
  </div>
  <div class="page">
    <p>WHAT ARE THE ABSTRACTIONS? Packet abstraction</p>
    <p>Compliance with standard TCP/IP stack is a necessity:</p>
    <p>L2, L3 semantics (unicast, ARP, )</p>
    <p>Control abstraction</p>
    <p>Networking has no single high level control interface.</p>
    <p>Theres a low-level one though!</p>
    <p>Packet In Packet Out ACL L2 L3 ACL</p>
    <p>Tenants Control Plane</p>
    <p>Logical Datapath</p>
  </div>
  <div class="page">
    <p>GENERALITY OF DATAPATH</p>
    <p>ACL L2 L3 ACL Datapath</p>
    <p>Router CPSwitch CP ACL L2 ACL</p>
    <p>Datapath</p>
    <p>Switch CP ACL L2 ACL</p>
    <p>Datapath</p>
    <p>One logical switch 2-tier logical topology Arbitrary logical</p>
    <p>topology</p>
    <p>Faithful reproduction of physical network service model.</p>
  </div>
  <div class="page">
    <p>WHERE TO IMPLEMENT?</p>
    <p>Network Core Independence from physical hardware.</p>
    <p>Programmatic control.  Operational model of</p>
    <p>compute virtualization.</p>
    <p>No extra x86 hops: just the source and destination hypervisor!</p>
    <p>Tenant CP</p>
    <p>Network Hypervisor</p>
  </div>
  <div class="page">
    <p>INSIDE THE VIRTUAL SWITCH ACL L2 L3 ACL</p>
    <p>Datapath</p>
    <p>ACL L2 ACL Datapath</p>
    <p>ACL L2 ACL Datapath</p>
    <p>OFOF OF OF</p>
    <p>Execute 1st logical datapath Determine the next logical datapath</p>
    <p>OF OF OF OF</p>
    <p>OF</p>
    <p>Determine the next</p>
    <p>OF OF OF</p>
    <p>OF</p>
    <p>Send to tunnel</p>
    <p>Logical Topology</p>
    <p>First-hop vSwitch</p>
    <p>OF</p>
    <p>Identify logical ingress port</p>
  </div>
  <div class="page">
    <p>COMPUTATIONAL CHALLENGE</p>
    <p>Forwarding State = F(configuration, VM locations)</p>
    <p>Repeat above as logical configuration or physical configuration (VM placement) changes.</p>
    <p>Challenge: How to compute O(N2) volume of low-level OpenFlow and OVSDB state, when inputs change all the time.</p>
  </div>
  <div class="page">
    <p>STATE COMPUTATION</p>
    <p>Incremental computation and pushing for quick updates.</p>
    <p>Avoid all handwritten finite state machines, machine generated instead.</p>
    <p>Shard the computation across controller cluster.</p>
    <p>Forwarding State = F(configuration, VM locations)</p>
    <p>Datalog based declarative language to program F.</p>
    <p>Declarative RT</p>
  </div>
  <div class="page">
    <p>LESSONS LEARNT: ABSTRACTIONS</p>
    <p>Assumptions about logical network structure often embedded into the workload.</p>
    <p>A single L2 domain sufficient for initial, simple workloads.</p>
    <p>To support more complex workloads without changing them, more complex logical topologies become a necessity.</p>
    <p>A logical switch</p>
    <p>Basic Enterprise App</p>
    <p>Two tier logical network</p>
    <p>Modern App</p>
    <p>Arbitrary logical network</p>
    <p>Bank</p>
  </div>
  <div class="page">
    <p>LESSONS: FAILURE ISOLATION</p>
    <p>Two Channels, No Atomic Updates</p>
    <p>Proactive pushing of all state not enough to decouple controllers from data plane.</p>
    <p>Connection may die while pushing updates.</p>
    <p>One Channel, Atomic Updates</p>
    <p>Atomically applied, batched updates.</p>
    <p>Connection failure does not result in incomplete state.</p>
    <p>Batch 2 Batch 1</p>
    <p>Batch N OpenFlow OVSDB</p>
    <p>Data plane may operate over incomplete state! At most old state.</p>
    <p>Custom Protocol</p>
  </div>
  <div class="page">
    <p>LESSONS: SCALING OPENFLOW IS EXPENSIVE</p>
    <p>Too primitive</p>
    <p>Simple operations take several flow entries.</p>
    <p>For example, tunnel failover, encapsulation header ops.</p>
    <p>Lots of redundancy.</p>
    <p>Too tightly coupled</p>
    <p>Each switch requires some flow customization; cant just blindly replicate flows.</p>
    <p>To compute flow entries, may have to wait for responses from the OVS configuration database.</p>
    <p>Replace a OF &amp; OVSDB with a network virtualization specific protocol.</p>
    <p>OpenFlow becomes a protocol internal to the hypervisor.</p>
  </div>
  <div class="page">
    <p>CONCLUSION: WHATS NEXT</p>
    <p>Without Network Virtualization</p>
    <p>Workload may run on a topology where addresses provide little information.</p>
    <p>For instance, firewall rules defined over exact /32 addresses!</p>
    <p>With Network Virtualization</p>
    <p>New out-of-band header fields without breaking legacy TCP/IP stacks.</p>
    <p>Huge implications to enforcing security policies: groups, users in packet</p>
    <p>Network Hypervisor</p>
    <p>L2</p>
    <p>IP</p>
    <p>L4 Logical headers for</p>
    <p>TCP/IP endpoints in VMs. Logical topology per workload</p>
    <p>requirements.</p>
    <p>TagsNew information, visible only to logical elements. Encapsulation</p>
    <p>header</p>
  </div>
  <div class="page">
    <p>THANK YOU! QUESTIONS?</p>
  </div>
</Presentation>
