<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>A Comprehensive Quality Evaluation of Security and Privacy Advice on the Web</p>
    <p>@eredmil1 eredmiles@cs.umd.edu</p>
    <p>Elissa M. Redmiles, Noel Warford, Amritha Jayanti, and Aravind Koneru, Sean Kross, Miraida Morales, Rock Stevens and Michelle L. Mazurek</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>People must learn a variety of security &amp; privacy behaviors</p>
  </div>
  <div class="page">
    <p>By Elissa Redmiles, May 16, 2017</p>
    <p>Estimates of damage caused by phishing vary widely, ranging from $61 million per year to $3 billion per year of direct losses to victims in the U.S.</p>
    <p>By Jason Hong</p>
    <p>Despite advances on core security problems, user decisions can still lead to significant security risks</p>
  </div>
  <div class="page">
    <p>How do they learn security? Is security education working?</p>
  </div>
  <div class="page">
    <p>Ecosystem-wide quality measurement of one of the most prevalent security education sources: online articles</p>
    <p>Where is the Digital Divide? A Survey of Security, Privacy, and Socioeconomics. CHI2017. How I Learned to be Secure: a Census-Representative Survey of Security Advice Sources and Behavior. CCS2016.</p>
  </div>
  <div class="page">
    <p>Comprehensibility: can users understand the document?</p>
    <p>Actionability: can users follow the advice?</p>
    <p>Accuracy: will following the advice make users more secure?</p>
    <p>Evaluate quality of corpus along three axes</p>
  </div>
  <div class="page">
    <p>User Generated Search Queries (989 docs)</p>
    <p>Expert Recommended Advice (889 docs)</p>
    <p>List 5 search queries for each of 3 digital security topics youre interested in learning more about</p>
    <p>Show up to 6 security &amp; privacy news articles  First one they indicate interest in: ask for 3 search queries</p>
    <p>Collected representative corpus of online security advice</p>
    <p>Step 2: Crowd workers clean corpus Is this document about online privacy/security?</p>
    <p>Step 1: Collect documents based on user-generated searches &amp; expert recommendations</p>
  </div>
  <div class="page">
    <p>Comprehensibility: can users understand the document?</p>
    <p>Actionability: can users follow the advice?</p>
    <p>Accuracy: will following the advice make users more secure?</p>
    <p>Evaluate quality of corpus along three axes</p>
  </div>
  <div class="page">
    <p>Comprehensibility: can users understand the document?</p>
    <p>Actionability: can users follow the advice?</p>
    <p>Accuracy: will following the advice make users more secure?</p>
    <p>Evaluate quality of corpus along three axes</p>
  </div>
  <div class="page">
    <p>What to use when evaluating security documents?</p>
    <p>Domain-Specific Application?</p>
    <p>First-Glance Perception Matters?</p>
    <p>No No YesYes</p>
    <p>Expect Uniform Distribution?</p>
    <p>YesNo</p>
    <p>Cloze</p>
    <p>FRES</p>
    <p>Smart Cloze</p>
    <p>FRES</p>
    <p>Ease</p>
    <p>FRES</p>
    <p>Smart Cloze</p>
    <p>Ease</p>
    <p>Figure Credit: Comparing and Developing Tools to Measure the Readability of Domain-Specific Texts. EMNLP 2019.</p>
  </div>
  <div class="page">
    <p>Smart Cloze tool creates domain-relevant distractors</p>
    <p>Use NLP techniques to generate four grammatically-probable distractors: two distractors drawn from a domain-specific dictionary we generate two from a general dictionary</p>
  </div>
  <div class="page">
    <p>Each document evaluated by three test-takers, who had excellent reliability (ICC&gt;0.90)</p>
    <p>Census-representative sample of test takers</p>
  </div>
  <div class="page">
    <p>Mean = 47.5% Partial comprehension Full comprehension</p>
  </div>
  <div class="page">
    <p>Variance within domain groupings: some government providers far more comprehensible than others</p>
    <p>Partial comprehension</p>
    <p>Full comprehension</p>
  </div>
  <div class="page">
    <p>Evaluate quality of corpus along three axes</p>
    <p>Comprehensibility: measure with Smart Cloze &amp; perceived ease</p>
    <p>Actionability: can users follow the advice?</p>
    <p>Accuracy: will following the advice make users more secure?</p>
  </div>
  <div class="page">
    <p>Evaluate quality of corpus along three axes</p>
    <p>Comprehensibility: measure with Smart Cloze &amp; perceived ease</p>
    <p>Actionability: can users follow the advice?</p>
    <p>Accuracy: will following the advice make users more secure?</p>
  </div>
  <div class="page">
    <p>To measure actionability (and accuracy) need to extract advice imperatives from documents</p>
    <p>Two research assistants manually annotated 1,264 documents to extract imperatives</p>
  </div>
  <div class="page">
    <p>Started with literature-grounded taxonomy of 194 codes, 206 new codes discovered through annotation</p>
    <p>securityadvice.cs.umd.edu</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Evaluate quality of corpus along three axes</p>
    <p>Comprehensibility: measure with Smart Cloze &amp; perceived ease</p>
    <p>Actionability: can users follow the advice?</p>
    <p>Accuracy: will following the advice make users more secure?</p>
  </div>
  <div class="page">
    <p>Four theoretically-grounded actionability sub-metrics</p>
    <p>Time Consumption: how time consuming would it be to follow this advice? economic frameworks (cost)</p>
    <p>Difficulty: how difficult would it be to follow this advice? HiTL (capabilities)</p>
    <p>Confidence: how confident is the user that they can follow the advice? PMT (perceived ability) &amp; HiTL (knowledge acquisition)</p>
    <p>Disruption: how disruptive would it be to follow this advice? economic frameworks (cost)</p>
    <p>Answered on a Likert Scale: Very to Not at All</p>
  </div>
  <div class="page">
    <p>Each piece of advice evaluated by three evaluators, who had good reliability (ICC&gt;0.85)</p>
    <p>Census-representative sample of evaluators</p>
  </div>
  <div class="page">
    <p>Majority of advice rated as actionable</p>
    <p>of advice somewhat+ confident   of advice at most slightly</p>
    <p>time consuming, disruptive, and difficult</p>
  </div>
  <div class="page">
    <p>Evaluate quality of corpus along three axes</p>
    <p>Comprehensibility: measure with Smart Cloze &amp; perceived ease</p>
    <p>Actionability: can users follow the advice?</p>
    <p>Accuracy: will following the advice make users more secure?</p>
    <p>People are somewhat or very confident about implementing   of advice   considered at most slightly time consuming, disruptive, or difficult to implement</p>
  </div>
  <div class="page">
    <p>Evaluate quality of corpus along three axes</p>
    <p>Comprehensibility: measure with Smart Cloze &amp; perceived ease</p>
    <p>Actionability: can users follow the advice?</p>
    <p>Accuracy: will following the advice make users more secure?</p>
    <p>People are somewhat or very confident about implementing   of advice   considered at most slightly time consuming, disruptive, or difficult to implement</p>
  </div>
  <div class="page">
    <p>Recruit security experts to evaluate advice accuracy</p>
    <p>Recruitment Qualification</p>
    <p>CTF, pen testing, secure development</p>
    <p>OR those who are certified</p>
  </div>
  <div class="page">
    <p>Ask experts to evaluate impact on risk &amp; to prioritize</p>
    <p>Perceived accuracy: accurate, useless, harmful</p>
    <p>Risk reduction (or increase): 0-50+%</p>
    <p>Priority: number 1, top 3, top 5, top 10</p>
  </div>
  <div class="page">
    <p>Each piece of advice evaluated by three experts, who had good reliability (ICC&gt;0.85)</p>
    <p>Average of 38 pieces of advice evaluated by each expert</p>
  </div>
  <div class="page">
    <p>Experts perceive 333 pieces of advice (89%) as accurate</p>
    <p>All documents contain at least one piece of accurate advice</p>
  </div>
  <div class="page">
    <p>Experts are a bit more discerning when prioritizing advice but 118 pieces of advice are rated in the top 5</p>
    <p>Used matrix factorization to generate full ranked list across all votes</p>
    <p>#1 Use unique passwords for different accounts #2 Update devices #3 Use anti-malware software #4 Scan attachments you open for viruses</p>
    <p>Top Advice</p>
  </div>
  <div class="page">
    <p>Expert Priority Ranking of Advice</p>
    <p>Reported User Adoption</p>
    <p>User Priority Ranking of Advice Advice Actionability Ratings</p>
    <p>Confidence Time</p>
    <p>Consumption Disruption Difficulty</p>
    <p>r = 0.600r = 0.212</p>
    <p>Users reported adoption of advice correlates with actionability &amp; prioritization</p>
    <p>r =0.391 r =0.305 r =0.355 r =0.367</p>
  </div>
  <div class="page">
    <p>Problem with online security advice: there is too much</p>
    <p>Comprehensibility: average document is partially comprehensible to the average U.S. user</p>
    <p>Actionability: majority of advice rated as actionable and actionability correlates with prioritization &amp; adoption</p>
    <p>Accuracy: 89% of advice rated accurate</p>
    <p>Leaves behind low-literacy users</p>
    <p>Data storage &amp; network security advice not very actionable 20% of documents contain at least one unactionable piece of advice</p>
    <p>Lack of prioritization &amp; falsifiability: experts think (almost) all the advice is great</p>
  </div>
  <div class="page">
    <p>Future of Security Advice Now What?</p>
  </div>
  <div class="page">
    <p>Future of security advice requires falsifiability for security claims and empirical studies to narrow down behaviors</p>
  </div>
  <div class="page">
    <p>A Comprehensive Quality Evaluation of Security and Privacy Advice on the Web</p>
    <p>Collected a corpus of 1,264 security advice documents Through user generated queries and expert recommendations</p>
    <p>Evaluated Quality along three axes Average document is partially comprehensible to the average U.S. user Majority of advice rated actionable; actionability correlated w/ reported behavior 89% of advice rated accurate by experts</p>
    <p>Experts cant narrow down advice; need empirical science Experts struggle to identify the most impactful advice We need more concrete measurement &amp; falsifiability</p>
    <p>Elissa M. Redmiles, Noel Warford, Amritha Jayanti, and Aravind Koneru, Sean Kross, Miraida Morales, Rock Stevens and Michelle L. Mazurek</p>
    <p>@eredmil1 eredmiles@cs.umd.edu</p>
  </div>
</Presentation>
