<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Putting the Micro Back in Microservices</p>
    <p>Sol Boucher, Carnegie Mellon University</p>
    <p>Joint work with: Anuj Kalia</p>
    <p>David G. Andersen Michael Kaminsky, Intel Labs</p>
  </div>
  <div class="page">
    <p>Tech Target</p>
    <p>Wall Street Journal</p>
    <p>The Register</p>
    <p>Hacker Noon</p>
    <p>InfoWorld 2</p>
  </div>
  <div class="page">
    <p>The hope for serverless computing</p>
    <p>Only have to manage code</p>
    <p>Microservices invoked by triggers</p>
    <p>Microservices are stateless</p>
    <p>This makes the system scalable</p>
    <p>Fine-grained billing that scales to zero</p>
  </div>
  <div class="page">
    <p>Median AWS Lambda warm-start latency 25 ms</p>
    <p>Median cold-start latency &gt;160 ms</p>
    <p>Median AWS Lambda warm-start latency 25 ms</p>
    <p>Median cold-start latency &gt;160 ms</p>
    <p>Goal: Reduce microservice invocation latency</p>
    <p>[Yesterday, ATC18]</p>
    <p>Latency between Azure VMs ~10 s [AccelNet, NSDI18]</p>
    <p>Commit ACID transactions in ~20 s [FaRM, SOSP15]</p>
    <p>Latency between Azure VMs ~10 s [AccelNet, NSDI18]</p>
    <p>Commit ACID transactions in ~20 s [FaRM, SOSP15]</p>
  </div>
  <div class="page">
    <p>Speed begets generality</p>
    <p>Make it fast, rather than general or powerful.</p>
    <p>Butler Lampson</p>
  </div>
  <div class="page">
    <p>Worker node</p>
    <p>Current request path</p>
    <p>service</p>
    <p>service</p>
    <p>Dispatcher process service</p>
  </div>
  <div class="page">
    <p>Proposal: Reduce overhead...</p>
    <p>Worker node</p>
    <p>CPU core</p>
    <p>CPU core</p>
    <p>CPU core</p>
    <p>CPU core</p>
    <p>svc svc svc svc svc svc</p>
    <p>svc svc svc svc svc svc</p>
  </div>
  <div class="page">
    <p>Proposal: ...by running code in shared workers...</p>
    <p>Worker node</p>
    <p>CPU core</p>
    <p>CPU core</p>
    <p>CPU core</p>
    <p>CPU core</p>
    <p>Worker process</p>
    <p>service service</p>
    <p>Worker process</p>
    <p>service service</p>
    <p>Worker process</p>
    <p>service service</p>
  </div>
  <div class="page">
    <p>Proposal: ...and distributing work using polling</p>
    <p>Worker node</p>
    <p>CPU core</p>
    <p>CPU core</p>
    <p>CPU core</p>
    <p>CPU core</p>
    <p>Worker process</p>
    <p>service service</p>
    <p>Worker process</p>
    <p>service service</p>
    <p>Worker process</p>
    <p>service service</p>
    <p>Dispatcher process</p>
  </div>
  <div class="page">
    <p>Proposal: ...and distributing work using polling</p>
    <p>Worker node</p>
    <p>CPU core</p>
    <p>CPU core</p>
    <p>CPU core</p>
    <p>CPU core</p>
    <p>Worker process</p>
    <p>service service</p>
    <p>Worker process</p>
    <p>service service</p>
    <p>Worker process</p>
    <p>service service</p>
    <p>Dispatcher process</p>
    <p>But... How do we provide isolation?</p>
  </div>
  <div class="page">
    <p>We use Rust for this, inspired by NetBricks and [OSDI16] [SOSP17]</p>
    <p>How do we achieve isolation similar to processes?</p>
    <p>Language-based isolation: compile-time safety guarantees</p>
    <p>Fine-grained preemption: intra-process task interruption</p>
    <p>User submits Rust code; we verify it</p>
  </div>
  <div class="page">
    <p>Language-based isolation cuts invocation latency</p>
  </div>
  <div class="page">
    <p>Language-based isolation cuts invocation latency</p>
  </div>
  <div class="page">
    <p>Language-based isolation: Use Rust</p>
    <p>Rust is  Strongly typed, compiled  Specified safe subset  No garbage collector</p>
    <p>Memory safety guarantees:  No dereferencing null/dangling pointers  All variables initialized to valid values  Enforced data immutability</p>
  </div>
  <div class="page">
    <p>Worker node</p>
    <p>Language-based isolation: Defense in depth</p>
    <p>Worker process</p>
    <p>service service Blacklisted library functions</p>
    <p>User</p>
    <p>Kernel seccomp() to permit only whitelisted system calls</p>
  </div>
  <div class="page">
    <p>Worker node</p>
    <p>Language-based isolation: Defense in depth</p>
    <p>Worker process</p>
    <p>service service Blacklisted library functions</p>
    <p>User</p>
    <p>Kernel seccomp() to permit only whitelisted system callsBut...</p>
    <p>What if a microservice doesnt yield?</p>
  </div>
  <div class="page">
    <p>CPU timesharing: Fine-grained preemption</p>
    <p>Goal: Recover from microservice that doesnt return quickly</p>
    <p>Implementation: POSIX timers, special cleanup logic</p>
  </div>
  <div class="page">
    <p>Fine-grained preemption</p>
    <p>Preemption interval (s)</p>
    <p>Workload throughput</p>
    <p>(M ops/s)</p>
    <p>Baseline Preemption 90% of Baseline</p>
  </div>
  <div class="page">
    <p>Fine-grained preemption: Aborting and cleanup</p>
    <p>SIGALRM handler: missed deadline?</p>
    <p>Workers main loop catches exception</p>
    <p>Handler returns, microservice</p>
    <p>continuesno</p>
    <p>Handler throws exception,</p>
    <p>unwinding stack</p>
    <p>yes</p>
  </div>
  <div class="page">
    <p>Trust model</p>
    <p>Trusted computing base:</p>
    <p>Rust compiler, standard library  Any allowed unsafe or native dependencies</p>
    <p>Successful compilation indicates microservice is memory safe</p>
    <p>Successful linking indicates all dependencies are trusted</p>
  </div>
  <div class="page">
    <p>Consolidate microservices into shared processes  Improved local invocation latency by orders of magnitude  (Hopefully) better resource utilization</p>
    <p>Current limitations and future work</p>
    <p>Recap</p>
  </div>
  <div class="page">
    <p>Call to malloc()</p>
    <p>Future work: Aborting/cleanup limitations</p>
    <p>Worker process</p>
    <p>service service</p>
  </div>
  <div class="page">
    <p>Call to malloc()</p>
    <p>Future work: Aborting/cleanup limitations</p>
    <p>Worker process</p>
    <p>service service</p>
  </div>
  <div class="page">
    <p>Call to malloc()</p>
    <p>Future work: Aborting/cleanup limitations</p>
    <p>Worker process</p>
    <p>service serviceservice</p>
  </div>
  <div class="page">
    <p>Call to malloc()</p>
    <p>Future work: Aborting/cleanup limitations</p>
    <p>Worker process</p>
    <p>service serviceservice service</p>
  </div>
  <div class="page">
    <p>Upcoming: More general accounting/deallocation scheme</p>
    <p>Operates outside the Rust runtime  Disables preemption during trusted library routines</p>
    <p>Call to malloc()</p>
    <p>Future work: Aborting/cleanup limitations</p>
    <p>Worker process</p>
    <p>service serviceservice service</p>
  </div>
  <div class="page">
    <p>Future work: Side-channel attacks</p>
    <p>Heightened Spectre vulnerability requires hardware mitigation</p>
    <p>Must consider microservices access to:</p>
    <p>Processs proximity to resource limits  Addresses and timings from the dynamic allocator  File descriptor numbers</p>
    <p>Shorter microservice durations make behavior less obscure</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Improved performance by shifting isolation abstraction layer</p>
    <p>Replaced traditional process-based isolation with:</p>
    <p>Language-based isolation  Fine-grained preemption</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Improved performance by shifting isolation abstraction layer</p>
    <p>Replaced traditional process-based isolation with:</p>
    <p>Language-based isolation  Fine-grained preemption</p>
    <p>Questions?</p>
  </div>
  <div class="page">
    <p>Thank you!</p>
  </div>
</Presentation>
