<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Tag line, tag line</p>
    <p>CLUEBOX: A Performance Log Analyzer for Automated Troubleshooting</p>
    <p>Niranjan Thirumale et al.</p>
    <p>NetApp, Inc.</p>
    <p>WASL 2008</p>
  </div>
  <div class="page">
    <p>The Problem</p>
    <p>Complex system deployments have ad-hoc but effective mechanisms for:  Data collection  Monitoring  Alerting</p>
    <p>but do not have good analysis tools  Whats available: detailed performance</p>
    <p>counters. Can we mine that to:  Characterize and identify workload?  help in the performance troubleshooting</p>
    <p>workflow?</p>
  </div>
  <div class="page">
    <p>The Environment</p>
    <p>Aggregates RAID groups</p>
    <p>Flexible Volumes</p>
    <p>Snapshot Copies</p>
    <p>Replica Services</p>
    <p>Clustered Storage Controller</p>
    <p>FC Fabric (FC) Gigabit Ethernet (NFS, CIFS, iSCSI)</p>
    <p>Fiber Channel Loop</p>
    <p>Disk Shelves</p>
    <p>File System Software</p>
  </div>
  <div class="page">
    <p>CLUEBOX Workflow</p>
  </div>
  <div class="page">
    <p>Workload Identification</p>
    <p>Principle Feature Analysis</p>
    <p>Random Forest Classification</p>
    <p>Cluster on increasing subsets of ranked counters {1, 2, 3}, {1, 2, 3, 4}, {1, 2, 3, 4, 5}, etc.</p>
    <p>Workload Signature Profile</p>
    <p>Manually inspect clustering quality</p>
    <p>Reduced set of counters</p>
    <p>Classification into workloads + Ranking of counters by importance to classification</p>
    <p>Not good?</p>
    <p>The set of counters for optimal clustering</p>
    <p>Entire set of counters</p>
  </div>
  <div class="page">
    <p>Workload Identification: Evaluation</p>
    <p>SIO  6 workloads, each with varying read/write ratios</p>
    <p>and sequential/random I/O ratios</p>
    <p>Cthon  5 workloads, each exercising different sets of file</p>
    <p>system metadata operations</p>
    <p>PostMark  2 workloads, each operating on different number</p>
    <p>of files and different file size ranges</p>
    <p>Sysbench  5 workloads, each exercising database-like</p>
    <p>workloads</p>
  </div>
  <div class="page">
    <p>Workload Identification: How Many Counters Do We Really Need?</p>
  </div>
  <div class="page">
    <p>Workload Identification: Results</p>
    <p>S1: Read 80%, Seq 80% S2: Read 20%, Seq 80% S3: Read 30%, Seq 90% S4: Read 30%, Seq 10% S5: Read 80%, Seq 90% S6: Read 80%, Seq 10%</p>
  </div>
  <div class="page">
    <p>Workload Identification: Results</p>
    <p>Known workloads training data contains:  S5: SIO, Seq Reads = 72%, Seq Writes = 18%, Random Reads = 8%,</p>
    <p>Random Writes = 2%  P2: PostMark, # Files = 10^5, File Size = 1KB to 100KB</p>
    <p>Test workload: SIO, Seq Reads = 72%, Seq Writes = 8%, Random Reads = 18%, Random Writes = 2%</p>
  </div>
  <div class="page">
    <p>Workload Identification: Results</p>
    <p>Known workloads training data contains  C2: Cthon Test 8 (symlink, readlink), # files = 1000, #symlinks = 1000  S1: SIO, Seq Reads = 64%, Seq Writes = 16%, Random Reads =</p>
  </div>
  <div class="page">
    <p>Anomaly Detection</p>
    <p>User: the performance of the system was fine at Time T. I havent changed a thing since then, but now the latencies are very high</p>
    <p>Run the cluster medoids and Workload at T through RF and get proximities</p>
    <p>Predict counter values and diff with measured values</p>
    <p>Rank counters in order of variable importance (predictive power of counter for latencies, given by RF)</p>
    <p>Closest Workload</p>
  </div>
  <div class="page">
    <p>Anomaly Detection</p>
    <p>A handful of top-ranked counters were enough  Anomalies in counters + Non-anomalous</p>
    <p>counters were both important</p>
    <p>An expert scanning this list diagnosed the rootcause rapidly  Conducive to a rule-based system at this point?</p>
  </div>
  <div class="page">
    <p>Anomaly Detection: fsck-like load</p>
    <p>Readahead counters have dropped, so not a replication load</p>
    <p>Absence of anomaly in cp_phase_times counter, so no high amount of destaging from cache</p>
    <p>Buf_hash_hit is extremely high, which cannot be explained by repeated mounts and unmounts</p>
    <p>Only an fsck or similar scanner can explain the data</p>
    <p>Counter Deviation from Prediction</p>
    <p>Ifnet:e0:total_packets -99.4%</p>
    <p>Processor0:hard_switches -63.6%</p>
    <p>System:cpu_busy 305.6%</p>
    <p>wafl:restart_msg_cnt:BACK DOOR</p>
    <p>Readahead:total_read_reqs -100%</p>
    <p>Wafl:buf_hash_hit 7088%</p>
    <p>Wafl:new_msg_cnt:BACKD OOR</p>
  </div>
  <div class="page">
    <p>Anomaly Detection: Local I/O load</p>
    <p>system:cpu_busy higher than predicted indicative of some other load</p>
    <p>ifnet:e0:total_packets is not different, so not a network I/O load</p>
    <p>No other significant anomalies, so not a bookkeeping activity</p>
    <p>testaggr:total_transfers higher imples significant amount of new I/O</p>
    <p>Only a separate I/O workload local to the storage controller can explain the symptoms</p>
    <p>Counter Deviation from Prediction</p>
    <p>Testaggr:cp_read_blocks 129%</p>
    <p>Ifnet:e0:total_packets 8.2%</p>
    <p>System:cpu_busy 359.9</p>
    <p>Wafl:buf_hash_hit 3045</p>
    <p>Testaggr:total_transfers 164.2%</p>
  </div>
  <div class="page">
    <p>What Next</p>
    <p>Test CLUEBOX on customer environments  Real performance problems  Real workloads</p>
    <p>Incorporate CLUEBOX into NetApps performance log analysis workflows  AutoSupport Database  Support Case Resolution  Duplicate case/bug report Identification</p>
    <p>Figure out how to avoid re-training if system configurations are changed (e.g., a few more disks added)</p>
  </div>
</Presentation>
