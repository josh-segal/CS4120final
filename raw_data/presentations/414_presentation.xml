<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Sequential Off-line Learning with Knowledge Gradients</p>
    <p>Peter Frazier Warren Powell Savas Dayanik</p>
    <p>Department of Operations Research and Financial Engineering Princeton University</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>Problem Formulation  Knowledge Gradient Policy  Theoretical Results  Numerical Results</p>
  </div>
  <div class="page">
    <p>Measurement Phase</p>
    <p>Alternative 1</p>
    <p>N opportunities to do experiments</p>
    <p>Alternative M</p>
    <p>+1+.2</p>
    <p>-1 +1</p>
    <p>Experimental outcomes</p>
    <p>Alternative 3 -.2</p>
    <p>Alternative 2 -1</p>
  </div>
  <div class="page">
    <p>Implementation Phase</p>
    <p>Alternative 1</p>
    <p>Alternative M</p>
    <p>RewardAlternative 3</p>
    <p>Alternative 2</p>
  </div>
  <div class="page">
    <p>Reward Structure On-line Off-line</p>
    <p>Sequential X BatchS</p>
    <p>am pl</p>
    <p>in g</p>
    <p>Taxonomy of Sampling Problems</p>
  </div>
  <div class="page">
    <p>Example 1</p>
    <p>One common experimental design is to spread measurements equally across the alternatives.</p>
    <p>xn = n (mod M) + 1</p>
    <p>Alternative</p>
    <p>Quality</p>
  </div>
  <div class="page">
    <p>Example 1</p>
    <p>xn = n (mod M) + 1Round Robin Exploration</p>
  </div>
  <div class="page">
    <p>How might we improve round-robin exploration for use with this prior?</p>
    <p>Example 2</p>
    <p>xn = argmaxx nx</p>
  </div>
  <div class="page">
    <p>Example 2</p>
    <p>xn = argmaxx nxLargest Variance Exploration</p>
  </div>
  <div class="page">
    <p>Example 3</p>
    <p>Exploitation: xn = argmaxx  nx</p>
  </div>
  <div class="page">
    <p>Model</p>
    <p>xn is the alternative tested at time n.  Measure the value of alternative xn</p>
    <p>At time n, , independent  Error en+1 is independent N(0,(se)2).  At time N, choose an alternative.  Maximize</p>
    <p>yn+ 1 = Yxn + &quot;n+ 1</p>
    <p>Yx  N( nx ; ( n x ) 2)</p>
    <p>IE[YxN ]= IE  maxx  Nx</p>
  </div>
  <div class="page">
    <p>State Transition</p>
    <p>At time n measure alternative xn. We update our estimate of based on the measurement</p>
    <p>Estimates of other Yx do not change.</p>
    <p>Yxn yn+ 1</p>
    <p>n+ 1x = (nx )</p>
    <p>2 nx + (  ) 2yn+ 1</p>
    <p>(nx ) 2 + ( ) 2</p>
    <p>(n+ 1x )  2 = (nx )</p>
    <p>2 + ( ) 2 for x = xn</p>
    <p>n+ 1x =  n x for x 6= x</p>
    <p>n</p>
    <p>n+ 1x =  n x for x 6= x</p>
    <p>n for x 6= xn</p>
  </div>
  <div class="page">
    <p>At time n, n+1x is a normal random variable with mean nx and variance satisfying</p>
    <p>uncertainty about Yx before the measurement</p>
    <p>uncertainty about Yx after the measurement</p>
    <p>change in best estimate of Yx due to the measurement</p>
    <p>(~n+ 1x ) 2</p>
    <p>(n+ 1x ) 2 = (nx )</p>
    <p>VN ( N ;N ) = max x  Nx</p>
    <p>Vn( n ;n ) = max xn</p>
    <p>IE  Vn+ 1( n+ 1;n+ 1)</p>
    <p>n</p>
    <p>The value of the optimal policy satisfies Bellmans equation</p>
  </div>
  <div class="page">
    <p>Utility of Information</p>
    <p>Consider our utility of information, U( n ;n ) := maxx  nx</p>
    <p>and consider the random change in utility due to a measurement at time n</p>
    <p>Un+ 1 := U( n+ 1;n+ 1)  U( n ;n )</p>
  </div>
  <div class="page">
    <p>Knowledge Gradient Definition</p>
    <p>The knowledge gradient policy chooses the measurement that maximizes this expected increase in utility,</p>
    <p>xn = argmaxx IEn   Un+ 1</p>
  </div>
  <div class="page">
    <p>Knowledge Gradient</p>
    <p>We may compute the knowledge gradient policy via</p>
    <p>IEn   Un+ 1</p>
    <p>:= IEn</p>
    <p>U( n+ 1;n+ 1)  U( n ;n )</p>
    <p>= IEn h max x  n+ 1x</p>
    <p>max</p>
    <p>x  nx i</p>
    <p>= IEn</p>
    <p>n+ 1xn _ max</p>
    <p>x6= xn  nx</p>
    <p>max</p>
    <p>x  nx</p>
    <p>:</p>
    <p>which is the expectation of the maximum of a normal and a constant.</p>
  </div>
  <div class="page">
    <p>Knowledge Gradient</p>
    <p>~(s) := s2= p s2 + ( )2</p>
    <p>nx :=  j n x  max</p>
    <p>x06= x  nx0j=~(</p>
    <p>n x )</p>
    <p>f (z) := z(z) + ' (z)</p>
    <p>The computation becomes argmaxx ~(nx )f (</p>
    <p>n x )</p>
    <p>where F is the normal cdf, j is the normal pdf, and</p>
  </div>
  <div class="page">
    <p>Optimality Results</p>
    <p>If our measurement budget allows only one measurement (N=1), the knowledge gradient policy is optimal.</p>
  </div>
  <div class="page">
    <p>Optimality Results</p>
    <p>The knowledge gradient policy is optimal in the limit as the measurement budget N grows to infinity.</p>
    <p>This is really a convergence result.</p>
  </div>
  <div class="page">
    <p>Optimality Results  The knowledge gradient policy has sub-optimality</p>
    <p>bounded by</p>
    <p>where VKG,n gives the value of the knowledge gradient policy and Vn the value of the optimal policy.</p>
    <p>(2) 1=2(N  n  1)maxx ~(nx )</p>
    <p>Vn( n ;n )  VK G;n ( n ;n )</p>
  </div>
  <div class="page">
    <p>Optimality Results</p>
    <p>If there are exactly 2 alternatives (M=2), the knowledge gradient policy is optimal.</p>
    <p>In this case, the optimal policy reduces to xn = argmaxx nx</p>
  </div>
  <div class="page">
    <p>Optimality Results</p>
    <p>If there is no measurement noise and alternatives may be reordered so that</p>
    <p>then the knowledge gradient policy is optimal.</p>
    <p>01   0 2  : : :</p>
    <p>01   0 2  : : :</p>
  </div>
  <div class="page">
    <p>Numerical Experiments</p>
    <p>100 randomly generated problems</p>
    <p>M Uniform {1,...100}</p>
    <p>N Uniform {M, 3M, 10M}</p>
    <p>0x Uniform [-1,1]  (s0x)2 = 1 with probability 0.9</p>
    <p>= 10-3 with probability 0.1</p>
    <p>se = 1</p>
  </div>
  <div class="page">
    <p>Numerical Experiments</p>
  </div>
  <div class="page">
    <p>Compare alternatives via a linear combination of mean and standard deviation.</p>
    <p>The parameter za/2 controls the tradeoff between exploration and exploitation.</p>
    <p>Interval Estimation</p>
    <p>xn = argmaxx  nx + z=2 n x</p>
  </div>
  <div class="page">
    <p>KG / IE Comparison</p>
  </div>
  <div class="page">
    <p>KG / IE Comparison</p>
    <p>Va lu</p>
    <p>e of</p>
    <p>K G</p>
    <p>Va</p>
    <p>lu e</p>
    <p>of IE</p>
  </div>
  <div class="page">
    <p>IE and Sticking</p>
    <p>= [2:5;0;: : : ;0], = [0;1;: : : ;1]</p>
    <p>Alternative 1 is known perfectly</p>
    <p>xn = argmaxx  nx + z=2 n x ; z=2 = 2:5</p>
  </div>
  <div class="page">
    <p>IE and Sticking</p>
    <p>VI E = 2:5; V = IE[max(2:5;Z1; : : : ;ZM )]% 1 as M % 1</p>
  </div>
  <div class="page">
    <p>Thank You Any Questions?</p>
  </div>
  <div class="page">
    <p>Numerical Example 1</p>
    <p>xn = argmaxx ~nx f ( n x ) = 1</p>
    <p>x  x 2x ~x =  2 x= p 2x + ( )2  x = j x  max</p>
    <p>x06= x  x0j x =   x=~x ~xf (x)</p>
  </div>
  <div class="page">
    <p>Numerical Example 2</p>
    <p>xn = argmaxx ~nx f ( n x ) = 2</p>
    <p>x  x 2x ~x =  2 x= p 2x + ( )2  x = j x  max</p>
    <p>x06= x  x0j x =   x=~x ~xf (x)</p>
  </div>
  <div class="page">
    <p>Numerical Example 3</p>
    <p>xn = argmaxx ~nx f ( n x ) = 2</p>
    <p>x  x 2x ~x =  2 x= p 2x + ( )2  x = j x  max</p>
    <p>x06= x  x0j x =   x=~x ~xf (x)</p>
  </div>
  <div class="page">
    <p>Knowledge Gradient Example</p>
  </div>
  <div class="page">
    <p>Interval Estimation Example</p>
    <p>xn = argmaxx  nx + 3 n x</p>
  </div>
  <div class="page">
    <p>Boltzmann Exploration</p>
    <p>Parameterized by a declining sequence of temperatures (T0,...TN-1).</p>
    <p>IPn fxn = xg = exp( nx =T</p>
    <p>n )P M x 0= 1</p>
    <p>exp( nx 0=Tn )</p>
  </div>
</Presentation>
