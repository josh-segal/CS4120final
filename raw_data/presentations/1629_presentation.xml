<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Write-Optimized Dynamic Hashing for Persistent Memory</p>
    <p>,  ,  ,  .,</p>
    <p>UNIST (Ulsan National Institute of Science and Technology)</p>
    <p>Sungkyunkwan University ()</p>
  </div>
  <div class="page">
    <p>Background  Static Hashing</p>
    <p>Extendible Hashing</p>
    <p>Persistent Memory</p>
    <p>Cacheline-Conscious Extendible Hashing  Challenges and Contributions</p>
    <p>3-Level Structure of CCEH</p>
    <p>Failure-atomic Directory Update</p>
    <p>Evaluation</p>
    <p>Conclusion</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Hash key collision  Full table rehashing  The most expensive operation in hash table</p>
    <p>Background:</p>
    <p>Static Hashing</p>
    <p>&amp;val3</p>
    <p>H(key) =</p>
    <p>key % size</p>
    <p>[0]</p>
    <p>[1]</p>
    <p>[2]</p>
    <p>[3]</p>
    <p>[4]</p>
    <p>[5]</p>
    <p>[6]</p>
    <p>[7]</p>
    <p>[0]</p>
    <p>[1]</p>
    <p>[2]</p>
    <p>[3]</p>
    <p>[4]</p>
    <p>[5]</p>
    <p>[6]</p>
    <p>[7]</p>
    <p>[8]</p>
    <p>[9]</p>
    <p>[A]</p>
    <p>[B]</p>
    <p>[C]</p>
    <p>[D]</p>
    <p>[E]</p>
    <p>[F]</p>
    <p>Rehash</p>
    <p>Hash Collision</p>
  </div>
  <div class="page">
    <p>Linear Probing</p>
    <p>To avoid full table rehashing:  Linear probing  Chaining  Double hashing such as Cuckoo hashing</p>
    <p>Background:</p>
    <p>Static Hashing</p>
    <p>&amp;val3</p>
    <p>H(key) =</p>
    <p>key % size</p>
    <p>[0]</p>
    <p>[1]</p>
    <p>[2]</p>
    <p>[3]</p>
    <p>[4]</p>
    <p>[5]</p>
    <p>[6]</p>
    <p>[7]</p>
  </div>
  <div class="page">
    <p>Chaining</p>
    <p>To avoid full table rehashing:  Linear probing  Chaining  Double hashing such as Cuckoo hashing</p>
    <p>Background:</p>
    <p>Static Hashing</p>
    <p>&amp;val3</p>
    <p>H(key) =</p>
    <p>key % size</p>
    <p>[0]</p>
    <p>[1]</p>
    <p>[2]</p>
    <p>[3]</p>
    <p>[4]</p>
    <p>[5]</p>
    <p>[6]</p>
    <p>[7]</p>
  </div>
  <div class="page">
    <p>To avoid full table rehashing:  Linear probing  Chaining  Double hashing such as Cuckoo hashing</p>
    <p>Background:</p>
    <p>Static Hashing</p>
    <p>&amp;val3</p>
    <p>H(key) =</p>
    <p>key % size</p>
    <p>Cuckoo Displacement</p>
    <p>[0]</p>
    <p>[1]</p>
    <p>[2]</p>
    <p>[3]</p>
    <p>[4]</p>
    <p>[5]</p>
    <p>[6]</p>
    <p>[7]</p>
    <p>Cuckoo Hashing</p>
  </div>
  <div class="page">
    <p>Insertion Latency CDF</p>
    <p>Flat Horizontal Lines</p>
    <p>Because of the expensive full-table rehashing</p>
  </div>
  <div class="page">
    <p>Dynamically splits one bucket or merges two buckets at a time</p>
    <p>Background:</p>
    <p>Disk-based Extendible Hashing</p>
    <p>Directory</p>
    <p>(G=2)</p>
    <p>Buckets</p>
    <p>L=2</p>
    <p>Hash Function: H(key) = key % 2G</p>
    <p>L=2 L=1</p>
  </div>
  <div class="page">
    <p>Background:</p>
    <p>Extendible Hashing  Insertion</p>
    <p>&amp;val3</p>
    <p>H(key) =</p>
    <p>key % 2G</p>
    <p>Value</p>
    <p>Directory</p>
    <p>(G=2)</p>
    <p>Buckets</p>
    <p>Hash Collision</p>
    <p>L=2 L=1 L=2</p>
  </div>
  <div class="page">
    <p>Only overflown bucket is modified</p>
    <p>Background:</p>
    <p>Extendible Hashing  Bucket Split</p>
    <p>&amp;val3</p>
    <p>H(key) =</p>
    <p>key % 2G</p>
    <p>Value</p>
    <p>Directory</p>
    <p>(G=2)</p>
    <p>Buckets</p>
    <p>Bucket SplitL=2 L=1 L=2</p>
  </div>
  <div class="page">
    <p>Background:</p>
    <p>Extendible Hashing  Bucket Split</p>
    <p>&amp;val3</p>
    <p>H(key) =</p>
    <p>key % 2G</p>
    <p>Key</p>
    <p>Value</p>
    <p>Directory</p>
    <p>(G=2)</p>
    <p>Buckets</p>
    <p>Update Directory</p>
    <p>Update Directory  At least two pointers need to be updated</p>
    <p>L=2 L=2</p>
    <p>L=2 L=2</p>
  </div>
  <div class="page">
    <p>Background:</p>
    <p>Extendible Hashing  Directory doubling</p>
    <p>If a single pointer points to overflow bucket  Directory Doubling</p>
    <p>&amp;val27</p>
    <p>H(key) =</p>
    <p>key % 2G</p>
    <p>Value</p>
    <p>Buckets</p>
    <p>Directory</p>
    <p>(G=2)</p>
    <p>Hash Collision</p>
    <p>L=1 L=2 L=2</p>
  </div>
  <div class="page">
    <p>Background:</p>
    <p>Extendible Hashing  Directory doubling</p>
    <p>If a single pointer points to overflow bucket  Directory Doubling</p>
    <p>&amp;val27</p>
    <p>H(key) =</p>
    <p>key % 2G</p>
    <p>Value</p>
    <p>Buckets</p>
    <p>Directory</p>
    <p>(G=2)</p>
    <p>Bucket Split</p>
    <p>L=1 L=2</p>
    <p>L=2</p>
  </div>
  <div class="page">
    <p>If a single pointer points to overflow bucket  Directory Doubling</p>
    <p>Background:</p>
    <p>Extendible Hashing  Directory doubling</p>
    <p>&amp;val27</p>
    <p>H(key) =</p>
    <p>key % 2G</p>
    <p>Value</p>
    <p>Buckets</p>
    <p>Directory</p>
    <p>(G=2)</p>
    <p>Directory</p>
    <p>(G=3)</p>
    <p>Directory Doubling</p>
    <p>L=1 L=2</p>
    <p>L=3 L=3</p>
  </div>
  <div class="page">
    <p>If a single pointer points to overflow bucket  Directory Doubling</p>
    <p>Directory</p>
    <p>(G=3) 0002 0012 0102 0112 1002 1012 1102 1112</p>
    <p>Background:</p>
    <p>Extendible Hashing  Directory doubling</p>
    <p>&amp;val27</p>
    <p>H(key) =</p>
    <p>key % 2G</p>
    <p>Key</p>
    <p>Value</p>
    <p>Buckets</p>
    <p>Update Directory</p>
    <p>L=1 L=2</p>
    <p>L=3 L=3</p>
  </div>
  <div class="page">
    <p>Persistent Memory</p>
    <p>Characteristics  High performance  Comparable to DRAM</p>
    <p>Byte-addressability  As DRAM</p>
    <p>Persistence  As storage devices (HDD/SSD)</p>
    <p>Challenges  Atomic unit of writes  8-bytes</p>
    <p>Data transfer unit between CPU cache and PM  64 byte cacheline</p>
    <p>Order of memory writes is not guaranteed</p>
  </div>
  <div class="page">
    <p>Background  Static Hashing</p>
    <p>Extendible Hashing</p>
    <p>Persistent Memory</p>
    <p>Cacheline-Conscious Extendible Hashing  Challenges and Contributions</p>
    <p>3-Level Structure of CCEH</p>
    <p>Failure-atomic Directory Update</p>
    <p>Evaluation</p>
    <p>Conclusion</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Challenge in In-Memory Extendible Hashing</p>
    <p>Problems</p>
    <p>- Page-sized bucket  64 cacheline accesses per bucket</p>
    <p>Directory</p>
    <p>(G=2)</p>
    <p>Bucket</p>
    <p>Cacheline 1</p>
    <p>Cacheline 2</p>
    <p>Cacheline 64</p>
    <p>Cacheline 3</p>
    <p>Cacheline 1</p>
    <p>Cacheline 2</p>
    <p>Cacheline 64</p>
    <p>Cacheline 3</p>
    <p>Cacheline 1</p>
    <p>Cacheline 2</p>
    <p>Cacheline 64</p>
    <p>Cacheline 3</p>
  </div>
  <div class="page">
    <p>Directory</p>
    <p>(G=20)</p>
    <p>Challenge in In-Memory Extendible Hashing</p>
    <p>Problems</p>
    <p>Cacheline-sized small bucket  a large directory (8 byte pointer per cacheline)</p>
    <p>Cacheline-Size</p>
  </div>
  <div class="page">
    <p>Directory</p>
    <p>(G=2) 0002 0012 0102 0112</p>
    <p>Challenge in Extendible Hashing on PM</p>
    <p>Buckets</p>
    <p>Problems</p>
    <p>Split operation updates multiple pointers  Not Failure-Atomic</p>
  </div>
  <div class="page">
    <p>Lookup via only two cacheline accesses</p>
    <p>Failure-atomic Directory Updates  Introduces the split buddy tree to manage split history</p>
    <p>Failure-atomic Segment Split  Lazy deletion scheme to minimize dirty writes</p>
    <p>Contributions</p>
  </div>
  <div class="page">
    <p>A group of multiple cacheline-sized buckets = Segment</p>
    <p>Segment: Intemediate Level</p>
    <p>Directory</p>
    <p>(G=20)</p>
    <p>Cacheline-Size</p>
  </div>
  <div class="page">
    <p>Segment: Intemediate Level</p>
    <p>Directory</p>
    <p>(G=2)</p>
    <p>Cacheline-Size</p>
    <p>Using intermediate level Segment,</p>
    <p>CCEH reduces directory size while keeping bucket size small</p>
  </div>
  <div class="page">
    <p>Q: With large segments, how can we minimize cacheline accesses?</p>
    <p>Minimize Cacheline Accesses in Segment</p>
    <p>(G=2)</p>
    <p>Segment 102</p>
    <p>Segment 112</p>
    <p>Segment 002</p>
    <p>Hash Key</p>
  </div>
  <div class="page">
    <p>Q: With large segments, how can we minimize cacheline accesses?</p>
    <p>Minimize Cacheline Accesses in Segment</p>
    <p>(G=2)</p>
    <p>Segment 102</p>
    <p>Segment 112</p>
    <p>Segment 002</p>
    <p>Hash Key</p>
  </div>
  <div class="page">
    <p>Minimize Cacheline Accesses in Segment</p>
    <p>(G=2)</p>
    <p>Segment 102</p>
    <p>Segment 112</p>
    <p>Segment 002</p>
    <p>Hash Key</p>
    <p>Segment Index</p>
    <p>Bucket Index</p>
    <p>Q: With large segments, how can we minimize cacheline accesses?</p>
  </div>
  <div class="page">
    <p>Minimize Cacheline Accesses in Segment</p>
    <p>(G=2) 10 012</p>
    <p>Hash Key</p>
    <p>Segment 012</p>
    <p>Segment 112</p>
    <p>Segment 002Use hash key as index for both directory and segment</p>
    <p>No need to access irrelevant buckets</p>
  </div>
  <div class="page">
    <p>Lookup via only two cacheline accesses</p>
    <p>Failure-atomic Directory Updates  Introduces the split buddy tree to manage split history</p>
    <p>Failure-atomic Segment Split  Lazy deletion scheme to minimize dirty writes</p>
    <p>Contributions</p>
  </div>
  <div class="page">
    <p>(G=3) Directory</p>
    <p>L=1</p>
    <p>L=1</p>
    <p>L=1</p>
    <p>L=1</p>
    <p>L=2</p>
    <p>L=2</p>
    <p>L=2</p>
    <p>L=2</p>
    <p>L=2</p>
    <p>L=2</p>
    <p>L=3</p>
    <p>L=3</p>
    <p>S1 S1</p>
    <p>S2</p>
    <p>S1</p>
    <p>S2</p>
    <p>S3 S3</p>
    <p>S4</p>
    <p>Depth: 0 1 2 3</p>
    <p>Global Depth:</p>
    <p>S1</p>
    <p>S1</p>
    <p>S1</p>
    <p>S2</p>
    <p>S3</p>
    <p>S4</p>
    <p>S2</p>
    <p>SPLIT S5</p>
    <p>(1) Update a directory entry</p>
    <p>(2) Update a directory entry</p>
    <p>(3) Update local depth of S1</p>
    <p>S5</p>
    <p>S5</p>
    <p>S1</p>
    <p>Using MSB segment index, split segments are pointed by adjacent directory entries</p>
    <p>Recovery: Split History Buddy Tree in CCEH</p>
  </div>
  <div class="page">
    <p>L=1L=2</p>
    <p>(G=3) Directory</p>
    <p>L=1</p>
    <p>L=1</p>
    <p>L=1</p>
    <p>L=2</p>
    <p>L=2</p>
    <p>L=3</p>
    <p>L=3</p>
    <p>S1S5</p>
    <p>S1</p>
    <p>Suppose a system crashes while S5 splits</p>
    <p>Recovery: Split History Buddy Tree in CCEH</p>
    <p>S1 S1</p>
    <p>S2</p>
    <p>S1</p>
    <p>S2</p>
    <p>S2</p>
    <p>S3</p>
    <p>S1</p>
    <p>S3</p>
    <p>S4</p>
    <p>S1</p>
    <p>S2</p>
    <p>S3</p>
    <p>S4</p>
    <p>S5</p>
    <p>Depth: 0 1 2 3</p>
    <p>Global Depth:</p>
    <p>S2</p>
  </div>
  <div class="page">
    <p>L=2</p>
    <p>L=1</p>
    <p>L=1</p>
    <p>L=1</p>
    <p>L=2</p>
    <p>L=2</p>
    <p>L=3</p>
    <p>L=3</p>
    <p>(G=3) Directory</p>
    <p>S1S5</p>
    <p>S1</p>
    <p>S1 S1</p>
    <p>S2</p>
    <p>S1</p>
    <p>S2</p>
    <p>S2</p>
    <p>S3</p>
    <p>S1</p>
    <p>S3</p>
    <p>S4</p>
    <p>S1</p>
    <p>S2</p>
    <p>S3</p>
    <p>S4</p>
    <p>S5</p>
    <p>Depth: 0 1 2 3</p>
    <p>Global Depth:</p>
    <p>S2</p>
    <p>=</p>
    <p>Each segment must be pointed by  directory entries</p>
    <p>If not, rollback the split</p>
    <p>Global Depth G = 3</p>
    <p>Local Depth L = 1</p>
    <p>Stride = 4</p>
    <p>Recovery: Split History Buddy Tree in CCEH</p>
  </div>
  <div class="page">
    <p>L=2L=1</p>
    <p>L=1</p>
    <p>L=1</p>
    <p>L=1</p>
    <p>L=2</p>
    <p>L=2</p>
    <p>L=3</p>
    <p>L=3</p>
    <p>(G=3) Directory</p>
    <p>S1S5</p>
    <p>S1</p>
    <p>S1 S1</p>
    <p>S2</p>
    <p>S1</p>
    <p>S2</p>
    <p>S2</p>
    <p>S3</p>
    <p>S1</p>
    <p>S3</p>
    <p>S4</p>
    <p>S1</p>
    <p>S2</p>
    <p>S3</p>
    <p>S4</p>
    <p>S5</p>
    <p>Depth: 0 1 2 3</p>
    <p>Global Depth:</p>
    <p>S2</p>
    <p>S1</p>
    <p>=</p>
    <p>Global Depth G = 3</p>
    <p>Local Depth L = 1</p>
    <p>Stride = 4</p>
    <p>Recovery: Split History Buddy Tree in CCEH</p>
    <p>Each segment must be pointed by  directory entries</p>
    <p>If not, rollback the split</p>
  </div>
  <div class="page">
    <p>Lookup via only two cacheline accesses</p>
    <p>Failure-atomic Directory Updates  Introduces the split buddy tree to manage split history</p>
    <p>Failure-atomic Segment Split  Lazy deletion scheme to minimize dirty writes</p>
    <p>Contributions</p>
  </div>
  <div class="page">
    <p>Segment Split: Legacy CoW</p>
    <p>Directory</p>
    <p>Copy-on-Write Split</p>
    <p>Lock-Free Search is enabled 002 012</p>
    <p>Local Depth = 1</p>
    <p>Local Depth = 2</p>
    <p>Local Depth = 2</p>
  </div>
  <div class="page">
    <p>Local Depth = 2</p>
    <p>Local Depth = 1</p>
    <p>&amp;val801000</p>
    <p>Segment Split: Lazy Deletion</p>
    <p>Directory</p>
    <p>Lazy Deletion</p>
    <p>Minimizes dirty writes 002 012</p>
    <p>Single</p>
    <p>Cacheline-flush</p>
    <p>invalidates all the</p>
    <p>migrated data</p>
    <p>Segment 002</p>
    <p>Local Depth = 2</p>
  </div>
  <div class="page">
    <p>Background  Static Hashing</p>
    <p>Extendible Hashing</p>
    <p>Persistent Memory</p>
    <p>Cacheline-Conscious Extendible Hashing  Challenges and Contributions</p>
    <p>3-Level Structure of CCEH</p>
    <p>Failure-atomic Directory Update</p>
    <p>Evaluation</p>
    <p>Conclusion</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Experimental Setup</p>
    <p>20MB L3 cache</p>
    <p>Quartz: A DRAM-based PM latency emulator * To emulate write latency, we inject stall cycle after</p>
    <p>each clflush instructions</p>
    <p>CPU</p>
    <p>Memory</p>
    <p>PM</p>
    <p>Workload 160 Million random number dataset</p>
  </div>
  <div class="page">
    <p>CCEH VS Legacy Extendible Hash</p>
    <p>T h</p>
    <p>ro u</p>
    <p>g h</p>
    <p>p u</p>
    <p>t (O</p>
    <p>p s /m</p>
    <p>s e c )</p>
    <p>Segment Size for CCEH/Bucket Size for Extendible Hash</p>
    <p>Segment Size for CCEH/Bucket Size for Extendible Hash</p>
    <p>A v g</p>
    <p>. # o</p>
    <p>f c lf</p>
    <p>lu s h</p>
    <p>CCEH Extendible Hashing</p>
    <p>CCEH compared to legacy Extendible Hashing</p>
    <p>Cons: Low utilization and more cacheline flushes due to hash collisions</p>
    <p>Pros: Constant number of cacheline accesses with varying directory size</p>
  </div>
  <div class="page">
    <p>Insertion Performance Breakdown</p>
    <p>CCEH CCEH(C) CUCK LEVL PATH</p>
    <p>CCEH CCEH(C) CUCK LEVL PATH</p>
    <p>Write Rehash Cuckoo Displacement</p>
    <p>R:120ns/W:120ns</p>
    <p>(DRAM)</p>
    <p>R:240ns/W:700ns</p>
    <p>A v g</p>
    <p>. E</p>
    <p>x e c .</p>
    <p>T im</p>
    <p>e (</p>
    <p>u s e c )</p>
    <p>CCEH is 70% faster than Level Hashing (OSDI18) on PM</p>
    <p>Fewer # of cacheline accesses</p>
    <p>Lazy deletion  Efficient segment split</p>
  </div>
  <div class="page">
    <p>Load Factor</p>
    <p>Number of Records (k)</p>
    <p>L o</p>
    <p>a d</p>
    <p>F a c to</p>
    <p>r (%</p>
    <p>) CCEH (K=4) CCEH (K=64) Level Hashing</p>
    <p>Level Hashing</p>
    <p>Suffer from full table rehashing like the other static hashing</p>
    <p>CCEH</p>
    <p>Dynamic allocation of small segments  Smooth curves</p>
    <p>CCEH (Optimization)</p>
    <p>K = Linear probing distance in Segment</p>
  </div>
  <div class="page">
    <p>Cacheline-Conscious Extendible Hashing (CCEH)  3-Level Structure</p>
    <p>Introduced an intermediate level, Segment</p>
    <p>Constant Lookup: Only two cacheline accesses  Write-Optimal</p>
    <p>Failure-Atomic Write-Optimal Lazy Deletion  Minimize I/O</p>
    <p>Failure-Atomic Directory Updates  Log-less directory update</p>
    <p>Disk-based hashing needs to be modified for PM to make effective use of cachelines.</p>
    <p>Source Codes: http://github.com/DICL/CCEH</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Question?</p>
  </div>
</Presentation>
