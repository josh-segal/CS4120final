<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Counterfactual Data Augmentation for Mitigating Gender Stereotypes in Languages with Rich Morphology ACL 2019</p>
    <p>Ran Zmigrod, Sebastian J. Mielke, Hanna Wallach, Ryan Cotterell</p>
    <p>University of Cambridge // Johns Hopkins University // Microsoft Research rz279@cam.ac.uk sjmielke@jhu.edu wallach@microsoft.com rdc42@cam.ac.uk</p>
    <p>Twitter: @RanZmigrod  paper and thread pinned! // @sjmielke</p>
  </div>
  <div class="page">
    <p>Gender bias in NLP systems</p>
    <p>Coreference resolution systems are biased:</p>
    <p>Even though the doctor reassured the nurse, she was worried.</p>
    <p>Both are possible... but systems prefer nurse! (Rudinger et al., 2018;Zhao et al., 2018)</p>
    <p>Word embeddings carry biases:</p>
  </div>
  <div class="page">
    <p>Gender bias in NLP systems</p>
    <p>Coreference resolution systems are biased:</p>
    <p>Even though the doctor reassured the nurse, she was worried.</p>
    <p>Both are possible... but systems prefer nurse! (Rudinger et al., 2018;Zhao et al., 2018)</p>
    <p>Word embeddings carry biases:</p>
  </div>
  <div class="page">
    <p>Gender bias in NLP systems</p>
    <p>Coreference resolution systems are biased:</p>
    <p>Even though the doctor reassured the nurse, she was worried.</p>
    <p>Both are possible... but systems prefer nurse! (Rudinger et al., 2018;Zhao et al., 2018)</p>
    <p>Word embeddings carry biases:</p>
  </div>
  <div class="page">
    <p>Gender bias in NLP systems</p>
    <p>Coreference resolution systems are biased:</p>
    <p>Even though the doctor reassured the nurse, she was worried.</p>
    <p>Both are possible...</p>
    <p>but systems prefer nurse! (Rudinger et al., 2018;Zhao et al., 2018)</p>
    <p>Word embeddings carry biases:</p>
  </div>
  <div class="page">
    <p>Gender bias in NLP systems</p>
    <p>Coreference resolution systems are biased:</p>
    <p>Even though the doctor reassured the nurse, she was worried.</p>
    <p>Both are possible... but systems prefer nurse! (Rudinger et al., 2018;Zhao et al., 2018)</p>
    <p>Word embeddings carry biases:</p>
  </div>
  <div class="page">
    <p>Gender bias in NLP systems</p>
    <p>Coreference resolution systems are biased:</p>
    <p>Even though the doctor reassured the nurse, she was worried.</p>
    <p>Both are possible... but systems prefer nurse! (Rudinger et al., 2018;Zhao et al., 2018)</p>
    <p>Word embeddings carry biases:</p>
  </div>
  <div class="page">
    <p>This shouldnt come as a surprise: our data is biased</p>
    <p>Google n-grams frequency counts</p>
    <p>he is a doctor</p>
    <p>she is a doctor</p>
  </div>
  <div class="page">
    <p>Our focus: stereotypes in language modeling (Lu et al., 2018)</p>
    <p>Training data counts are visible as</p>
    <p>likelihoods under a language model:</p>
    <p>stereotype m f</p>
    <p>pronoun m He is a good doctor. He is a good nurse.</p>
    <p>f She is a good doctor. She is a good nurse.</p>
    <p>The solution: Counterfactual Data Augmentation (Lu et al., 2018)</p>
    <p>For every sentence with she/he: e.g., She is a nurse.</p>
    <p>add that sentence with he/she for training: e.g., He is a nurse.</p>
    <p>Now they should yield a balanced model!</p>
  </div>
  <div class="page">
    <p>Our focus: stereotypes in language modeling (Lu et al., 2018)</p>
    <p>Training data counts are visible as</p>
    <p>likelihoods under a language model:</p>
    <p>stereotype m f</p>
    <p>pronoun m He is a good doctor. He is a good nurse.</p>
    <p>f She is a good doctor. She is a good nurse.</p>
    <p>The solution: Counterfactual Data Augmentation (Lu et al., 2018)</p>
    <p>For every sentence with she/he: e.g., She is a nurse.</p>
    <p>add that sentence with he/she for training: e.g., He is a nurse.</p>
    <p>Now they should yield a balanced model!</p>
  </div>
  <div class="page">
    <p>Our focus: stereotypes in language modeling (Lu et al., 2018)</p>
    <p>Training data counts are visible as</p>
    <p>likelihoods under a language model:</p>
    <p>stereotype m f</p>
    <p>pronoun m He is a good doctor. He is a good nurse.</p>
    <p>f She is a good doctor. She is a good nurse.</p>
    <p>The solution: Counterfactual Data Augmentation (Lu et al., 2018)</p>
    <p>For every sentence with she/he: e.g., She is a nurse.</p>
    <p>add that sentence with he/she for training: e.g., He is a nurse.</p>
    <p>Now they should yield a balanced model!</p>
  </div>
  <div class="page">
    <p>Our focus: stereotypes in language modeling (Lu et al., 2018)</p>
    <p>Training data counts are visible as</p>
    <p>likelihoods under a language model:</p>
    <p>stereotype m f</p>
    <p>pronoun m He is a good doctor. He is a good nurse.</p>
    <p>f She is a good doctor. She is a good nurse.</p>
    <p>The solution: Counterfactual Data Augmentation (Lu et al., 2018)</p>
    <p>For every sentence with she/he: e.g., She is a nurse.</p>
    <p>add that sentence with he/she for training: e.g., He is a nurse.</p>
    <p>Now they should yield a balanced model!</p>
  </div>
  <div class="page">
    <p>Our focus: stereotypes in language modeling (Lu et al., 2018)</p>
    <p>Training data counts are visible as</p>
    <p>likelihoods under a language model:</p>
    <p>stereotype m f</p>
    <p>pronoun m He is a good doctor. He is a good nurse.</p>
    <p>f She is a good doctor. She is a good nurse.</p>
    <p>The solution: Counterfactual Data Augmentation (Lu et al., 2018)</p>
    <p>For every sentence with she/he: e.g., She is a nurse.</p>
    <p>add that sentence with he/she for training: e.g., He is a nurse.</p>
    <p>Now they should yield a balanced model!</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Agreement or what if: German</p>
    <p>stereotype m f</p>
    <p>pronoun m Er ist ein guter Arzt. Er ist ein guter Krankenpfleger.</p>
    <p>f Sie ist eine gute rztin. Sie ist eine gute Krankenpflegerin.</p>
    <p>So, uh, can we just... change all words grammatical gender?</p>
    <p>Example: Der Arzt sitzt auf einem Stuhl (The male doctor sits on a chair)</p>
    <p>Swap all: Die rztin sitzt auf einer Stuhl (The female doctor sits on a... what?)</p>
    <p>No, what we need is...</p>
  </div>
  <div class="page">
    <p>Agreement or what if: German</p>
    <p>stereotype m f</p>
    <p>pronoun m Er ist ein guter Arzt. Er ist ein guter Krankenpfleger.</p>
    <p>f Sie ist eine gute rztin. Sie ist eine gute Krankenpflegerin.</p>
    <p>So, uh, can we just... change all words grammatical gender?</p>
    <p>Example: Der Arzt sitzt auf einem Stuhl (The male doctor sits on a chair)</p>
    <p>Swap all: Die rztin sitzt auf einer Stuhl (The female doctor sits on a... what?)</p>
    <p>No, what we need is...</p>
  </div>
  <div class="page">
    <p>Agreement or what if: German</p>
    <p>stereotype m f</p>
    <p>pronoun m Er ist ein guter Arzt. Er ist ein guter Krankenpfleger.</p>
    <p>f Sie ist eine gute rztin. Sie ist eine gute Krankenpflegerin.</p>
    <p>So, uh, can we just... change all words grammatical gender?</p>
    <p>Example: Der Arzt sitzt auf einem Stuhl (The male doctor sits on a chair)</p>
    <p>Swap all: Die rztin sitzt auf einer Stuhl (The female doctor sits on a... what?)</p>
    <p>No, what we need is...</p>
  </div>
  <div class="page">
    <p>Agreement or what if: German</p>
    <p>stereotype m f</p>
    <p>pronoun m Er ist ein guter Arzt. Er ist ein guter Krankenpfleger.</p>
    <p>f Sie ist eine gute rztin. Sie ist eine gute Krankenpflegerin.</p>
    <p>So, uh, can we just... change all words grammatical gender?</p>
    <p>Example: Der Arzt sitzt auf einem Stuhl (The male doctor sits on a chair)</p>
    <p>Swap all: Die rztin sitzt auf einer Stuhl (The female doctor sits on a... what?)</p>
    <p>No, what we need is...</p>
  </div>
  <div class="page">
    <p>Agreement or what if: German</p>
    <p>stereotype m f</p>
    <p>pronoun m Er ist ein guter Arzt. Er ist ein guter Krankenpfleger.</p>
    <p>f Sie ist eine gute rztin. Sie ist eine gute Krankenpflegerin.</p>
    <p>So, uh, can we just... change all words grammatical gender?</p>
    <p>Example: Der Arzt sitzt auf einem Stuhl (The male doctor sits on a chair)</p>
    <p>Swap all: Die rztin sitzt auf einer Stuhl (The female doctor sits on a... what?)</p>
    <p>No, what we need is...</p>
  </div>
  <div class="page">
    <p>Agreement or what if: German</p>
    <p>stereotype m f</p>
    <p>pronoun m Er ist ein guter Arzt. Er ist ein guter Krankenpfleger.</p>
    <p>f Sie ist eine gute rztin. Sie ist eine gute Krankenpflegerin.</p>
    <p>So, uh, can we just... change all words grammatical gender?</p>
    <p>Example: Der Arzt sitzt auf einem Stuhl (The male doctor sits on a chair)</p>
    <p>Swap all: Die rztin sitzt auf einer Stuhl (The female doctor sits on a... what?)</p>
    <p>No, what we need is...</p>
  </div>
  <div class="page">
    <p>Agreement or what if: German</p>
    <p>stereotype m f</p>
    <p>pronoun m Er ist ein guter Arzt. Er ist ein guter Krankenpfleger.</p>
    <p>f Sie ist eine gute rztin. Sie ist eine gute Krankenpflegerin.</p>
    <p>So, uh, can we just... change all words grammatical gender?</p>
    <p>Example: Der Arzt sitzt auf einem Stuhl (The male doctor sits on a chair)</p>
    <p>Swap all: Die rztin sitzt auf einer Stuhl</p>
    <p>No, what we need is...</p>
  </div>
  <div class="page">
    <p>Agreement or what if: German</p>
    <p>stereotype m f</p>
    <p>pronoun m Er ist ein guter Arzt. Er ist ein guter Krankenpfleger.</p>
    <p>f Sie ist eine gute rztin. Sie ist eine gute Krankenpflegerin.</p>
    <p>So, uh, can we just... change all words grammatical gender?</p>
    <p>Example: Der Arzt sitzt auf einem Stuhl (The male doctor sits on a chair)</p>
    <p>Swap all: Die rztin sitzt auf einer Stuhl (The female doctor sits on a... what?)</p>
    <p>No, what we need is...</p>
  </div>
  <div class="page">
    <p>Syntax to the rescue: use dependency parses</p>
    <p>Only words connected in the dependency parse should change!</p>
    <p>Build a MRF over morphological tags along the dependency parse!</p>
    <p>Der gute Arzt sitzt auf einem Stuhl</p>
  </div>
  <div class="page">
    <p>Syntax to the rescue: use dependency parses</p>
    <p>Only words connected in the dependency parse should change!</p>
    <p>Build a MRF over morphological tags along the dependency parse!</p>
    <p>Der gute Arzt sitzt auf einem Stuhl</p>
  </div>
  <div class="page">
    <p>Syntax to the rescue: use dependency parses</p>
    <p>Only words connected in the dependency parse should change!</p>
    <p>Build a MRF over morphological tags along the dependency parse!</p>
    <p>M ; SG;NOM M ; SG; NOM M ;</p>
    <p>SG; NOM</p>
    <p>- M ; SG;DAT M ; SG; DAT</p>
    <p>agreement/concord learned from data,</p>
    <p>neural factors</p>
    <p>manual dampening not learned, boosts tags that staywhat they were before intervention</p>
  </div>
  <div class="page">
    <p>Syntax to the rescue: use dependency parses</p>
    <p>Only words connected in the dependency parse should change!</p>
    <p>Build a MRF over morphological tags along the dependency parse!</p>
    <p>M ; SG;NOM M ; SG; NOM M ;</p>
    <p>SG; NOM</p>
    <p>- M ; SG;DAT M ; SG; DAT</p>
    <p>agreement/concord learned from data,</p>
    <p>neural factors</p>
    <p>manual dampening not learned, boosts tags that staywhat they were before intervention</p>
  </div>
  <div class="page">
    <p>Syntax to the rescue: use dependency parses</p>
    <p>Only words connected in the dependency parse should change!</p>
    <p>Build a MRF over morphological tags along the dependency parse!</p>
    <p>M ; SG;NOM M ; SG; NOM M ;</p>
    <p>SG; NOM</p>
    <p>- M ; SG;DAT M ; SG; DAT</p>
    <p>agreement/concord learned from data,</p>
    <p>neural factors</p>
    <p>manual dampening not learned, boosts tags that staywhat they were before intervention</p>
  </div>
  <div class="page">
    <p>Syntax to the rescue: use dependency parses</p>
    <p>Only words connected in the dependency parse should change!</p>
    <p>Build a MRF over morphological tags along the dependency parse!</p>
    <p>M ; SG;NOM M ; SG; NOM F ;</p>
    <p>SG; NOM</p>
    <p>- M ; SG;DAT M ; SG; DAT</p>
    <p>agreement/concord learned from data,</p>
    <p>neural factors</p>
    <p>manual dampening not learned, boosts tags that staywhat they were before intervention</p>
  </div>
  <div class="page">
    <p>Syntax to the rescue: use dependency parses</p>
    <p>Only words connected in the dependency parse should change!</p>
    <p>Build a MRF over morphological tags along the dependency parse!</p>
    <p>F ; SG;NOM F ; SG; NOM F ;</p>
    <p>SG; NOM</p>
    <p>- M ; SG;DAT M ; SG; DAT</p>
    <p>agreement/concord learned from data,</p>
    <p>neural factors</p>
    <p>manual dampening not learned, boosts tags that staywhat they were before intervention</p>
  </div>
  <div class="page">
    <p>Recap: what is a Markov Random Field (Koller and Friedman, 2009)?</p>
    <p>x y</p>
    <p>z</p>
    <p>Model p(x , y, z) by decomposing into factors ( )!</p>
    <p>Every factor gives a score to certain assignments:</p>
    <p>(x = 2, y = 1)= 0.42 (y = 1)= 1.3 (z = 1)=1</p>
    <p>Add up all factors to obtain global score: score(x = 2, y = 1, z = 4)= (x = 2, y = 1)+ (y = 1)+ (z = 4)</p>
    <p>Get p by global normalization (easy in trees): p(x = 2, y = 1, z = 4)</p>
    <p>exp score(x = 2, y = 1, z = 4)</p>
  </div>
  <div class="page">
    <p>Recap: what is a Markov Random Field (Koller and Friedman, 2009)?</p>
    <p>x y</p>
    <p>z</p>
    <p>Model p(x , y, z) by decomposing into factors ( )!</p>
    <p>Every factor gives a score to certain assignments:</p>
    <p>(x = 2, y = 1)= 0.42 (y = 1)= 1.3 (z = 1)=1</p>
    <p>Add up all factors to obtain global score: score(x = 2, y = 1, z = 4)= (x = 2, y = 1)+ (y = 1)+ (z = 4)</p>
    <p>Get p by global normalization (easy in trees): p(x = 2, y = 1, z = 4)</p>
    <p>exp score(x = 2, y = 1, z = 4)</p>
  </div>
  <div class="page">
    <p>Recap: what is a Markov Random Field (Koller and Friedman, 2009)?</p>
    <p>x y</p>
    <p>z</p>
    <p>Model p(x , y, z) by decomposing into factors ( )! Every factor gives a score to certain assignments:</p>
    <p>(x = 2, y = 1)= 0.42 (y = 1)= 1.3 (z = 1)=1</p>
    <p>Add up all factors to obtain global score: score(x = 2, y = 1, z = 4)= (x = 2, y = 1)+ (y = 1)+ (z = 4)</p>
    <p>Get p by global normalization (easy in trees): p(x = 2, y = 1, z = 4)</p>
    <p>exp score(x = 2, y = 1, z = 4)</p>
  </div>
  <div class="page">
    <p>Recap: what is a Markov Random Field (Koller and Friedman, 2009)?</p>
    <p>x y</p>
    <p>z</p>
    <p>Model p(x , y, z) by decomposing into factors ( )! Every factor gives a score to certain assignments:</p>
    <p>(x = 2, y = 1)= 0.42 (y = 1)= 1.3 (z = 1)=1</p>
    <p>Add up all factors to obtain global score: score(x = 2, y = 1, z = 4)= (x = 2, y = 1)+ (y = 1)+ (z = 4)</p>
    <p>Get p by global normalization (easy in trees): p(x = 2, y = 1, z = 4)</p>
    <p>exp score(x = 2, y = 1, z = 4)</p>
  </div>
  <div class="page">
    <p>Recap: what is a Markov Random Field (Koller and Friedman, 2009)?</p>
    <p>x y</p>
    <p>z</p>
    <p>Model p(x , y, z) by decomposing into factors ( )! Every factor gives a score to certain assignments:</p>
    <p>(x = 2, y = 1)= 0.42 (y = 1)= 1.3 (z = 1)=1</p>
    <p>Add up all factors to obtain global score: score(x = 2, y = 1, z = 4)= (x = 2, y = 1)+ (y = 1)+ (z = 4)</p>
    <p>Get p by global normalization (easy in trees): p(x = 2, y = 1, z = 4)</p>
    <p>exp score(x = 2, y = 1, z = 4)</p>
  </div>
  <div class="page">
    <p>Syntax to the rescue: use dependency parses</p>
    <p>Only words connected in the dependency parse should change!</p>
    <p>Build a MRF over morphological tags along the dependency parse!</p>
    <p>M ; SG;NOM M ; SG; NOM M ;</p>
    <p>SG; NOM</p>
    <p>- M ; SG;DAT M ; SG; DAT</p>
    <p>agreement/concord learned from data,</p>
    <p>neural factors</p>
    <p>manual dampening not learned, boosts tags that staywhat they were before intervention</p>
  </div>
  <div class="page">
    <p>Syntax to the rescue: use dependency parses</p>
    <p>Only words connected in the dependency parse should change!</p>
    <p>Build a MRF over morphological tags along the dependency parse!</p>
    <p>M ; SG;NOM M ; SG; NOM M ;</p>
    <p>SG; NOM</p>
    <p>- M ; SG;DAT M ; SG; DAT</p>
    <p>agreement/concord learned from data,</p>
    <p>neural factors</p>
    <p>manual dampening not learned, boosts tags that staywhat they were before intervention</p>
  </div>
  <div class="page">
    <p>Syntax to the rescue: use dependency parses</p>
    <p>Only words connected in the dependency parse should change!</p>
    <p>Build a MRF over morphological tags along the dependency parse!</p>
    <p>M ; SG;NOM M ; SG; NOM M ;</p>
    <p>SG; NOM</p>
    <p>- M ; SG;DAT M ; SG; DAT</p>
    <p>agreement/concord learned from data,</p>
    <p>neural factors</p>
    <p>manual dampening not learned, boosts tags that staywhat they were before intervention</p>
  </div>
  <div class="page">
    <p>Syntax to the rescue: use dependency parses</p>
    <p>Only words connected in the dependency parse should change!</p>
    <p>Build a MRF over morphological tags along the dependency parse!</p>
    <p>M ; SG;NOM M ; SG; NOM F ;</p>
    <p>SG; NOM</p>
    <p>- M ; SG;DAT M ; SG; DAT</p>
    <p>agreement/concord learned from data,</p>
    <p>neural factors</p>
    <p>manual dampening not learned, boosts tags that staywhat they were before intervention</p>
  </div>
  <div class="page">
    <p>Syntax to the rescue: use dependency parses</p>
    <p>Only words connected in the dependency parse should change!</p>
    <p>Build a MRF over morphological tags along the dependency parse!</p>
    <p>F ; SG;NOM F ; SG; NOM F ;</p>
    <p>SG; NOM</p>
    <p>- M ; SG;DAT M ; SG; DAT</p>
    <p>agreement/concord learned from data,</p>
    <p>neural factors</p>
    <p>manual dampening not learned, boosts tags that staywhat they were before intervention</p>
  </div>
  <div class="page">
    <p>Reinflect tokens to obtain the CDA sentence</p>
    <p>Get the new sentence by performing morphological reinflection where tags changes: (this is a reasonably well-working procedure, established in three shared tasks at SIGMORPHON and CoNLL)</p>
    <p>Der gute Arzt sitzt auf einem Stuhl</p>
    <p>F ; SG;NOM F ; SG; NOM F ;</p>
    <p>SG; NOM</p>
    <p>- M ; SG;DAT M ; SG; DAT</p>
  </div>
  <div class="page">
    <p>Reinflect tokens to obtain the CDA sentence</p>
    <p>Get the new sentence by performing morphological reinflection where tags changes: (this is a reasonably well-working procedure, established in three shared tasks at SIGMORPHON and CoNLL)</p>
    <p>Der gute Arzt sitzt auf einem Stuhl</p>
    <p>F ; SG;NOM F ; SG; NOM F ;</p>
    <p>SG; NOM</p>
    <p>- M ; SG;DAT M ; SG; DAT</p>
    <p>p( | ) p( | ) p( | )</p>
  </div>
  <div class="page">
    <p>Reinflect tokens to obtain the CDA sentence</p>
    <p>Get the new sentence by performing morphological reinflection where tags changes: (this is a reasonably well-working procedure, established in three shared tasks at SIGMORPHON and CoNLL)</p>
    <p>Der gute Arzt sitzt auf einem Stuhl</p>
    <p>F ; SG;NOM F ; SG; NOM F ;</p>
    <p>SG; NOM</p>
    <p>- M ; SG;DAT M ; SG; DAT</p>
    <p>p( | ) p( | ) p( | )</p>
    <p>Die gute rztin</p>
  </div>
  <div class="page">
    <p>Reinflect tokens to obtain the CDA sentence</p>
    <p>Get the new sentence by performing morphological reinflection where tags changes: (this is a reasonably well-working procedure, established in three shared tasks at SIGMORPHON and CoNLL)</p>
    <p>Der gute Arzt sitzt auf einem Stuhl</p>
    <p>F ; SG;NOM F ; SG; NOM F ;</p>
    <p>SG; NOM</p>
    <p>- M ; SG;DAT M ; SG; DAT</p>
    <p>p( | ) p( | ) p( | )</p>
    <p>Die gute rztin sitzt auf einem Stuhl</p>
  </div>
  <div class="page">
    <p>Intrinsic evaluation: how good are we at gender-swapping (Hebrew, Spanish)?</p>
    <p>We manually annotated over 100 sentences for each language and checked performance:</p>
    <p>Tag Form</p>
    <p>P R F 1 Acc Acc</p>
    <p>Hebrew: hardcoded factors 89.04 40.12 55.32 86.88 83.63 Hebrew: linear factors 87.07 62.35 72.66 90.5 86.75 Hebrew: neural factors 87.18 62.96 73.12 90.62 86.25</p>
    <p>Spanish: hardcoded factors 96.97 51.45 67.23 90.21 86.32 Spanish: linear factors 92.74 73.95 82.29 93.79 89.52 Spanish: neural factors 95.34 72.35 82.27 93.91 89.65</p>
  </div>
  <div class="page">
    <p>Intrinsic evaluation: how good are we at gender-swapping (Hebrew, Spanish)?</p>
    <p>We manually annotated over 100 sentences for each language and checked performance:</p>
    <p>Tag Form</p>
    <p>P R F 1 Acc Acc</p>
    <p>Hebrew: hardcoded factors 89.04 40.12 55.32 86.88 83.63</p>
    <p>Hebrew: linear factors 87.07 62.35 72.66 90.5 86.75 Hebrew: neural factors 87.18 62.96 73.12 90.62 86.25</p>
    <p>Spanish: hardcoded factors 96.97 51.45 67.23 90.21 86.32 Spanish: linear factors 92.74 73.95 82.29 93.79 89.52 Spanish: neural factors 95.34 72.35 82.27 93.91 89.65</p>
  </div>
  <div class="page">
    <p>Intrinsic evaluation: how good are we at gender-swapping (Hebrew, Spanish)?</p>
    <p>We manually annotated over 100 sentences for each language and checked performance:</p>
    <p>Tag Form</p>
    <p>P R F 1 Acc Acc</p>
    <p>Hebrew: hardcoded factors 89.04 40.12 55.32 86.88 83.63 Hebrew: linear factors 87.07 62.35 72.66 90.5 86.75</p>
    <p>Hebrew: neural factors 87.18 62.96 73.12 90.62 86.25</p>
    <p>Spanish: hardcoded factors 96.97 51.45 67.23 90.21 86.32 Spanish: linear factors 92.74 73.95 82.29 93.79 89.52 Spanish: neural factors 95.34 72.35 82.27 93.91 89.65</p>
  </div>
  <div class="page">
    <p>Intrinsic evaluation: how good are we at gender-swapping (Hebrew, Spanish)?</p>
    <p>We manually annotated over 100 sentences for each language and checked performance:</p>
    <p>Tag Form</p>
    <p>P R F 1 Acc Acc</p>
    <p>Hebrew: hardcoded factors 89.04 40.12 55.32 86.88 83.63 Hebrew: linear factors 87.07 62.35 72.66 90.5 86.75 Hebrew: neural factors 87.18 62.96 73.12 90.62 86.25</p>
    <p>Spanish: hardcoded factors 96.97 51.45 67.23 90.21 86.32 Spanish: linear factors 92.74 73.95 82.29 93.79 89.52 Spanish: neural factors 95.34 72.35 82.27 93.91 89.65</p>
  </div>
  <div class="page">
    <p>Intrinsic evaluation: how good are we at gender-swapping (Hebrew, Spanish)?</p>
    <p>We manually annotated over 100 sentences for each language and checked performance:</p>
    <p>Tag Form</p>
    <p>P R F 1 Acc Acc</p>
    <p>Hebrew: hardcoded factors 89.04 40.12 55.32 86.88 83.63 Hebrew: linear factors 87.07 62.35 72.66 90.5 86.75 Hebrew: neural factors 87.18 62.96 73.12 90.62 86.25</p>
    <p>Spanish: hardcoded factors 96.97 51.45 67.23 90.21 86.32 Spanish: linear factors 92.74 73.95 82.29 93.79 89.52 Spanish: neural factors 95.34 72.35 82.27 93.91 89.65</p>
  </div>
  <div class="page">
    <p>Extrinsic evaluation: train language models on CDA-balanced data, then evaluate:</p>
    <p>Bias</p>
    <p>log</p>
    <p>x p(Der gute Arzt x)</p>
    <p>x p(Die gute rztin x) m f</p>
    <p>Esp Fra Heb Ita 0</p>
    <p>G en</p>
    <p>d er</p>
    <p>B ia</p>
    <p>s</p>
    <p>Original Swap MRF</p>
    <p>Grammaticality</p>
    <p>log</p>
    <p>x p(Die gute rztin x)</p>
    <p>x p(Der gute rztin x) ok bad</p>
    <p>Esp Fra Heb Ita 0</p>
    <p>G ra</p>
    <p>m m</p>
    <p>at ic</p>
    <p>al it</p>
    <p>y</p>
    <p>Original Swap MRF</p>
  </div>
  <div class="page">
    <p>Extrinsic evaluation: train language models on CDA-balanced data, then evaluate:</p>
    <p>Bias</p>
    <p>log</p>
    <p>x p(Der gute Arzt x)</p>
    <p>x p(Die gute rztin x) m f</p>
    <p>Esp Fra Heb Ita 0</p>
    <p>G en</p>
    <p>d er</p>
    <p>B ia</p>
    <p>s</p>
    <p>Original Swap MRF</p>
    <p>Grammaticality</p>
    <p>log</p>
    <p>x p(Die gute rztin x)</p>
    <p>x p(Der gute rztin x) ok bad</p>
    <p>Esp Fra Heb Ita 0</p>
    <p>G ra</p>
    <p>m m</p>
    <p>at ic</p>
    <p>al it</p>
    <p>y</p>
    <p>Original Swap MRF</p>
  </div>
  <div class="page">
    <p>Extrinsic evaluation: train language models on CDA-balanced data, then evaluate:</p>
    <p>Bias</p>
    <p>log</p>
    <p>x p(Der gute Arzt x)</p>
    <p>x p(Die gute rztin x) m f</p>
    <p>Esp Fra Heb Ita 0</p>
    <p>G en</p>
    <p>d er</p>
    <p>B ia</p>
    <p>s</p>
    <p>Original Swap MRF</p>
    <p>Grammaticality</p>
    <p>log</p>
    <p>x p(Die gute rztin x)</p>
    <p>x p(Der gute rztin x) ok bad</p>
    <p>Esp Fra Heb Ita 0</p>
    <p>G ra</p>
    <p>m m</p>
    <p>at ic</p>
    <p>al it</p>
    <p>y</p>
    <p>Original Swap MRF</p>
  </div>
  <div class="page">
    <p>Extrinsic evaluation: train language models on CDA-balanced data, then evaluate:</p>
    <p>Bias</p>
    <p>log</p>
    <p>x p(Der gute Arzt x)</p>
    <p>x p(Die gute rztin x) m f</p>
    <p>Esp Fra Heb Ita 0</p>
    <p>G en</p>
    <p>d er</p>
    <p>B ia</p>
    <p>s</p>
    <p>Original Swap MRF</p>
    <p>Grammaticality</p>
    <p>log</p>
    <p>x p(Die gute rztin x)</p>
    <p>x p(Der gute rztin x) ok bad</p>
    <p>Esp Fra Heb Ita 0</p>
    <p>G ra</p>
    <p>m m</p>
    <p>at ic</p>
    <p>al it</p>
    <p>y</p>
    <p>Original Swap MRF</p>
  </div>
  <div class="page">
    <p>Extrinsic evaluation: train language models on CDA-balanced data, then evaluate:</p>
    <p>Bias</p>
    <p>log</p>
    <p>x p(Der gute Arzt x)</p>
    <p>x p(Die gute rztin x) m f</p>
    <p>Esp Fra Heb Ita 0</p>
    <p>G en</p>
    <p>d er</p>
    <p>B ia</p>
    <p>s</p>
    <p>Original Swap MRF</p>
    <p>Grammaticality</p>
    <p>log</p>
    <p>x p(Die gute rztin x)</p>
    <p>x p(Der gute rztin x) ok bad</p>
    <p>Esp Fra Heb Ita 0</p>
    <p>G ra</p>
    <p>m m</p>
    <p>at ic</p>
    <p>al it</p>
    <p>y</p>
    <p>Original Swap MRF</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Counterfactual Data Augmentation for Mitigating Gender Stereotypes in Languages with Rich Morphology ACL 2019</p>
    <p>Ran Zmigrod, Sebastian J. Mielke, Hanna Wallach, Ryan Cotterell</p>
    <p>University of Cambridge // Johns Hopkins University // Microsoft Research rz279@cam.ac.uk sjmielke@jhu.edu wallach@microsoft.com rdc42@cam.ac.uk</p>
    <p>Twitter: @RanZmigrod  paper and thread pinned! // @sjmielke</p>
  </div>
</Presentation>
