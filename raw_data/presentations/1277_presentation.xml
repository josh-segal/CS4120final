<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>OSCA: An Online-Model Based Cache Allocation Scheme in Cloud Block Storage Systems</p>
    <p>Yu Zhang, Ping Huang, Ke Zhou, Hua Wang, Jianying Hu, Yongguang Ji, Bin Cheng Huazhong University of Science and Technology</p>
    <p>Intelligent Cloud Storage Joint Research center of HUST and Tencent Temple University</p>
    <p>Tencent Technology (Shenzhen) Co., Ltd.</p>
    <p>USENIX Annual Technical Conference 2020</p>
    <p>USENIX Annual Technical Conference 2020</p>
  </div>
  <div class="page">
    <p>Agenda  Research Background</p>
    <p>Cloud Block storage (CBS)</p>
    <p>Motivation</p>
    <p>OSCA System Design Online Cache modeling Search for the optimal solution</p>
    <p>Evaluation Results</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>June 27, 2020 USENIX Annual Technical Conference 2020 3</p>
    <p>To satisfy the rigorous performance and availability requirements of different tenants, cloud block storage (CBS) systems have been widely deployed by cloud providers.</p>
    <p>Background</p>
    <p>Storage ClusterTenants</p>
    <p>iSCSI, etc.</p>
    <p>Network &amp; Data Forwarding</p>
  </div>
  <div class="page">
    <p>June 27, 2020 USENIX Annual Technical Conference 2020 4</p>
    <p>Cache servers, consisting of multiple cache instances competing for the same pool of resources.</p>
    <p>Cache allocation scheme plays an important role.</p>
    <p>Background</p>
    <p>Cache Server Instance 1 Instance 2</p>
    <p>Storage Server</p>
    <p>Storage Cluster</p>
    <p>Network Client</p>
    <p>Node 1 Node 2</p>
  </div>
  <div class="page">
    <p>&amp; DF KH 5 HT XL UH P HQ W * %</p>
    <p>June 28, 2020 USENIX Annual Technical Conference 2020 5</p>
    <p>Motivation</p>
    <p>(a) (b)</p>
    <p>The highly-skewed cloud workloads cause uneven distribution of hot spots in nodes.  figure (a)</p>
    <p>The currently used even-allocation policy is inappropriate for the cloud environment and induces resource wastage.  figure (b)</p>
    <p>Maximum</p>
    <p>Minimum</p>
    <p>Median</p>
    <p>EH U</p>
    <p>/RZ</p>
    <p>+LJK</p>
  </div>
  <div class="page">
    <p>June 28, 2020 USENIX Annual Technical Conference 2020 6</p>
    <p>Motivation</p>
    <p>To improve this policy via ensuring more appropriate cache allocations, there have been proposed two broad categories of solutions.</p>
    <p>Qualitative methods based on intuition or experience.  Quantitative methods enabled by cache models typically described by Miss Ratio Curves (MRC).</p>
  </div>
  <div class="page">
    <p>June 28, 2020 USENIX Annual Technical Conference 2020 7</p>
    <p>Motivation</p>
    <p>To improve this policy via ensuring more appropriate cache allocations, there have been proposed two broad categories of solutions.</p>
    <p>Qualitative methods based on intuition or experience.  Quantitative methods enabled by cache models typically described by Miss Rate Curves (MRC).</p>
    <p>We propose OSCA, an Online-Model based Scheme for Cache Allocation</p>
  </div>
  <div class="page">
    <p>June 28, 2020 USENIX Annual Technical Conference 2020 8</p>
    <p>Main Ideas</p>
    <p>Obtain the miss ratio curve, which indicates the miss ratio corresponding to different cache sizes.</p>
    <p>Online Cache Modeling</p>
    <p>Define an optimization target.</p>
    <p>Optimization Target Defining</p>
    <p>Based on the cache modeling and defined target mentioned above, our OSCA searches for the optimal configuration scheme.</p>
    <p>Searching for Optimal Configuration</p>
  </div>
  <div class="page">
    <p>June 28, 2020 USENIX Annual Technical Conference 2020 9</p>
    <p>Cache Modeling</p>
    <p>Cache Controller</p>
    <p>IO processing &amp; Obtain Miss Ratio Curve.</p>
    <p>Optimization Target.  Configuration Searching.</p>
    <p>Periodically Reconfigure.</p>
    <p>Instance 1</p>
    <p>Client Read</p>
    <p>Cache Pool</p>
    <p>Client Write</p>
    <p>Storage Server</p>
    <p>IO Partition and Routing</p>
    <p>Cache Controller</p>
    <p>Configuration Searching</p>
    <p>ASYN</p>
    <p>Instance 2</p>
    <p>Periodically Re configuring</p>
    <p>Instance 1 Instance 2</p>
    <p>Miss ratio Curve</p>
    <p>Builder</p>
    <p>Target Defining</p>
    <p>IO 4UBUJTUJDIO statistic</p>
  </div>
  <div class="page">
    <p>June 28, 2020 USENIX Annual Technical Conference 2020 10</p>
    <p>Cache Modeling (cont.)</p>
    <p>Obtain the miss ratio curve, which describes the relationship between hit ratio and cache size.</p>
    <p>Online Cache Modeling</p>
    <p>The hit ratio of the LRU algorithm can be calculated from the discrete integral sum of the reuse distance distribution (from zero to the cache size).</p>
    <p>C</p>
    <p>x 0 hr(C) = rdd(x)</p>
    <p>=</p>
    <p>LQI</p>
  </div>
  <div class="page">
    <p>June 29, 2020 USENIX Annual Technical Conference 2020 11</p>
    <p>Cache Modeling (cont.)</p>
    <p>The reuse distance is the amount of unique data blocks between two consecutive accesses to the same data block.  ABCDBDA  Reuse Distance of block A = 3</p>
    <p>A data block can be hit in the cache only when its reuse distance is smaller than the cache size.</p>
    <p>The hit ratio of the LRU algorithm can be calculated from the discrete integral sum of the reuse distance distribution (from zero to the cache size).</p>
    <p>Reuse Distance</p>
    <p>C</p>
    <p>x 0 hr(C) = rdd(x)</p>
    <p>=</p>
    <p>LQI</p>
  </div>
  <div class="page">
    <p>June 27, 2020 USENIX Annual Technical Conference 2020 12</p>
    <p>Reuse Distance</p>
    <p>However, obtaining the reuse distance distribution has an O(N  M) complexity.</p>
    <p>Recent studies have proposed various ways to decrease the computation complexity to O(N  log(n)). SHARDS further decreases the computation complexity by sampling method.</p>
    <p>We propose Re-access Ratio based Cache Model (RAR-CM), which does not need to collect and process traces, which can be expensive in many scenarios. RAR-CM has an O(1) complexity.</p>
  </div>
  <div class="page">
    <p>June 29, 2020 USENIX Annual Technical Conference 2020 13</p>
    <p>Re-access Ratio</p>
    <p>Re-access ratio (RAR) is defined as the ratio of the re-access traffic to the total traffic during a time interval  after time t.</p>
    <p>RAR can be transferred to Reuse distance.  ABCDBDEFBA  RAR(t,) = 2 / 5 = 40%</p>
    <p>Reuse Distance of Block X = Traffic(t,) * ( 1 RAR(t,)) = 6</p>
    <p>So we can get the reuse distance distribution by obtaining the RAR.</p>
  </div>
  <div class="page">
    <p>June 29, 2020 USENIX Annual Technical Conference 2020 14</p>
    <p>Obtain Re-access Ratio</p>
    <p>RAR(t0,t1-t0) is calculated by dividing the reaccess request count (RC) by the total request count (TC) during [t0,t1].</p>
    <p>To update RC and TC, we first lookup the block request in a hash map to determine whether it is a re-access request.</p>
    <p>Stream of request</p>
    <p>B</p>
    <p>Hash map for the block fast lookup</p>
    <p>t1</p>
    <p>Found in the hash</p>
    <p>map</p>
    <p>Not Found 1. TC  TC + 1 2. Insert B into the hash mapTC  TC + 1</p>
    <p>RC  RC + 1</p>
    <p>t0</p>
    <p>RAR(t0 , t1-t0) = RC / TC t0 : the start timestamp t1 : current timestamp B : the block-level request TC : total request count RC : the re-access-request count</p>
  </div>
  <div class="page">
    <p>June 29, 2020 USENIX Annual Technical Conference 2020 15</p>
    <p>Construct MRC from RAR</p>
    <p>For a request to block B, we first check its history information in a hash map and obtain its last access timestamp (lt) and last access counter (lc, a 64-bit number denoting the block sequence number of the last reference to block B).</p>
    <p>We then use lt, lc and RAR curve to calculate the reuse distance of block B.</p>
    <p>Finally, the resultant reuse distance is used to calculate the miss ratio curve.</p>
    <p>B</p>
    <p>Hash map for block history information</p>
    <p>Reuse distance distribution</p>
    <p>HistoryInformation{ uint64_t lt; uint64_t lc; }</p>
    <p>Stream of request CTlt(B)</p>
    <p>lt(B) : last access timestamp of block B CT: current timestamp B : the block-level request CC : current request count lc(B) : last access counter at block B rd(B) : reuse distance of block B hr(c) : the hit ratio of cache size c mr: miss ratio rdd(x) : the ratio of data with the reuse distance x</p>
    <p>Miss ratio curve</p>
    <p>B</p>
    <p>m r</p>
    <p>c</p>
    <p>hr(c)=rdd(x) c</p>
    <p>x=0</p>
  </div>
  <div class="page">
    <p>June 29, 2020 USENIX Annual Technical Conference 2020 16</p>
    <p>Define the Optimization Target</p>
    <p>Considering our case being cloud server-end caches, in this work we use the overall hit traffic among all nodes as our optimization target.</p>
    <p>The greater the value of E is, the less traffic is sent to the backend HDD storage.</p>
  </div>
  <div class="page">
    <p>June 29, 2020 USENIX Annual Technical Conference 2020 17</p>
    <p>Search for the Optimal Solution</p>
    <p>Based on the cache modeling and defined target mentioned above, our OSCA searches for the optimal configuration scheme.</p>
    <p>Searching for Optimal Configuration</p>
    <p>Configuration searching process tries to find the optimal combination of cache sizes of each cache instance to get the highest overall hit traffic.</p>
    <p>[CacheSize0, CacheSize1, , CacheSizeN]</p>
  </div>
  <div class="page">
    <p>June 29, 2020 USENIX Annual Technical Conference 2020 18</p>
    <p>Dynamical Programming</p>
    <p>The simplest method is the time-consuming exhaustive searching, which will calculate all possible cases.</p>
    <p>To speed up the search process, we use dynamical programming (DP).</p>
  </div>
  <div class="page">
    <p>June 29, 2020 USENIX Annual Technical Conference 2020 19</p>
    <p>System Evaluations  Trace Collection  We have collected I/O traces from a production cloud block storage system.</p>
    <p>We are in the process of making it publicly available via the SNIA IOTTA repository.</p>
    <p>Trace Storage  The traces are stored in a storage server and each thread accesses the traces</p>
    <p>via the network file system (i.e., Tencent CFS).</p>
    <p>Simulation  We have implemented a trace-driven simulator in C++ language for the rapid</p>
    <p>verification of the optimization strategy.</p>
    <p>Counterpart  Even-allocation Policy  Exact MRC Construction  Miniature-Simulation (FAST15, USENIX17)</p>
  </div>
  <div class="page">
    <p>June 29, 2020 USENIX Annual Technical Conference 2020 20</p>
    <p>Miss Ratio Curves</p>
  </div>
  <div class="page">
    <p>June 29, 2020 USENIX Annual Technical Conference 2020 21</p>
    <p>Mean Absolute Error (MAE)</p>
    <p>The MAE averaged across all 20 storage nodes (labeled &quot;Total&quot;) for RAR-CM is smaller than for Mini-Simulation: 0.005 vs 0.017, in addition to being smaller for each of the 17 out of the 20 nodes.</p>
  </div>
  <div class="page">
    <p>June 29, 2020 USENIX Annual Technical Conference 2020 22</p>
    <p>Overall Efficacy</p>
    <p>We compare the efficacy of OSCA in terms of hit ratio and backend traffic.</p>
    <p>The backend traffic is normalized to that of original method.</p>
    <p>On average, OSCA based on RAR-CM can reduce IO traffic to back-end storage server by 13.2%.</p>
    <p>OCSA adjusts the cache space for 20 storage nodes dynamically in response to their respective cache requirements decided by our cache modeling.</p>
    <p>,GHDO 5$5&amp;0 0LQL6LPXODWLRQ 2ULJLQDO</p>
    <p>(a)</p>
    <p>(b)</p>
    <p>(c)</p>
  </div>
  <div class="page">
    <p>Conclusion  Propose an online cache model-based cache allocation</p>
    <p>scheme for CBS systems</p>
    <p>Our approach complements the SHARDS method which adopts sampling but requires much less memory</p>
    <p>We have demonstrated its efficacy via perform simulating experiments with real-world CBS traces</p>
    <p>Publicize the traces to the storage research community</p>
    <p>June 29, 2020 USENIX Annual Technical Conference 2020 23</p>
  </div>
  <div class="page">
    <p>Q&amp;A Thanks</p>
    <p>Contact me : Yu Zhang</p>
    <p>Homepage: yuzhang.pro</p>
    <p>E-mail: mail@yuzhang.pro</p>
  </div>
</Presentation>
