<?xml version="1.0" ?>
<Presentation>
  <div class="page"/>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Tim Harris, Oracle Labs Stefan Kaestle, ETH Zurich 7 July 2015</p>
    <p>Callisto-RTS: Fine-Grain Parallel Loops</p>
  </div>
  <div class="page">
    <p>The following is intended to provide some insight into a line of research in Oracle Labs. It is intended for</p>
    <p>information purposes only, and may not be incorporated into any contract. It is not a commitment to</p>
    <p>deliver any material, code, or functionality, and should not be relied upon in making purchasing decisions.</p>
    <p>Oracle reserves the right to alter its development plans and practices at any time, and the development,</p>
    <p>release, and timing of any features or functionality described in connection with any Oracle product or</p>
    <p>service remains at the sole discretion of Oracle. Any views expressed in this presentation are my own and</p>
    <p>do not necessarily reflect the views of Oracle.</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>parallel_for&lt;uint64_t&gt;(0, G.num_nodes(), [&amp;](uint64_t node) { double val = 0.0; for (edge_t w_idx = G.r_begin[node]; w_idx &lt; G.r_begin[node+1]; w_idx ++) { node_t w = G.r_node_idx [w_idx]; val += G_pg_rank[w] / (G.begin[w+1] - G.begin[w]); } G_pg_rank_nxt[node] = (1 - d) / N + d * val; });</p>
    <p>Setting: parallel loops on shared-memory machines</p>
    <p>for (uint64_t node = 0; node &lt; G.num_nodes(); node++) {</p>
    <p>}</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Setting: parallel loops on shared-memory machines</p>
    <p>parallel_for&lt;uint64_t&gt;(0, G.num_nodes(), [&amp;](uint64_t node) { double val = 0.0; for (edge_t w_idx = G.r_begin[node]; w_idx &lt; G.r_begin[node+1]; w_idx ++) { node_t w = G.r_node_idx [w_idx]; val += G_pg_rank[w] / (G.begin[w+1] - G.begin[w]); } G_pg_rank_nxt[node] = (1 - d) / N + d * val; });</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Setting: parallel loops on shared-memory machines</p>
    <p>parallel_for&lt;uint64_t&gt;(0, G.num_nodes(), [&amp;](uint64_t node) { double val = 0.0; for (edge_t w_idx = G.r_begin[node]; w_idx &lt; G.r_begin[node+1]; w_idx ++) { node_t w = G.r_node_idx [w_idx]; val += G_pg_rank[w] / (G.begin[w+1] - G.begin[w]); } G_pg_rank_nxt[node] = (1 - d) / N + d * val; });</p>
    <p>Loop index type and bounds</p>
    <p>Loop body (C++ lambda)</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Batch size / load imbalance trade-off</p>
    <p>Iteration number</p>
    <p>It e</p>
    <p>ra ti</p>
    <p>o n</p>
    <p>e xe</p>
    <p>cu ti</p>
    <p>o n</p>
    <p>t im</p>
    <p>e Fixed amount</p>
    <p>of work in each iteration</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Batch size / load imbalance trade-off</p>
    <p>Iteration number</p>
    <p>It e</p>
    <p>ra ti</p>
    <p>o n</p>
    <p>e xe</p>
    <p>cu ti</p>
    <p>o n</p>
    <p>t im</p>
    <p>e Fixed amount</p>
    <p>of work in each iteration</p>
    <p>Divide iteration space evenly between threads and get good load balancing</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Batch size / load imbalance trade-off</p>
    <p>Iteration number</p>
    <p>It e</p>
    <p>ra ti</p>
    <p>o n</p>
    <p>e xe</p>
    <p>cu ti</p>
    <p>o n</p>
    <p>t im</p>
    <p>e Variable amount</p>
    <p>of work per iteration</p>
    <p>(Actual data  #out-edges of the top 1000 nodes in the SNAP Twitter dataset)</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Batch size / load imbalance trade-off</p>
    <p>Divide into large batches Reduce contention distributing work Risk load imbalance</p>
    <p>Divide into small batches Increase contention distributing work Achieve better load balance</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Batch size / load imbalance trade-off</p>
    <p>Typically, choose manually  but getting this right</p>
    <p>depends on (1) algorithm, (2) machine, (3) data</p>
    <p>Divide into large batches Reduce contention distributing work Risk load imbalance</p>
    <p>Divide into small batches Increase contention distributing work Achieve better load balance</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Example performance OpenMP static &amp; dynamic loops</p>
    <p>T h re</p>
    <p>a d s</p>
    <p>Batch size</p>
    <p>N o rm</p>
    <p>a liz</p>
    <p>e d e</p>
    <p>x e c u tio</p>
    <p>n tim</p>
    <p>eBest performance: 0.26s</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Batch size / load imbalance trade-off</p>
    <p>Divide into large batches Reduce contention Risk load imbalance</p>
    <p>Divide into small batches Increase contention distributing work Achieve better load balance</p>
    <p>Typically, choose manually  but getting this right</p>
    <p>depends on (1) algorithm, (2) machine, (3) data</p>
    <p>Our approach: support efficient small batches</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>Request combining</p>
    <p>Asynchronous work requests</p>
    <p>Non-work-conserving nested loops</p>
    <p>Results</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>Request combining</p>
    <p>Asynchronous work requests</p>
    <p>Non-work-conserving nested loops</p>
    <p>Results</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Approach, consider a loop 0..65536, batch size 8</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Approach, consider a loop 0..65536, batch size 8</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Approach, consider a loop 0..65536, batch size 8</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Approach, consider a loop 0..65536, batch size 8</p>
    <p>Distribute iterations at start of loop down to per-core counters</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Approach, consider a loop 0..65536, batch size 8</p>
    <p>Distribute iterations at start of loop down to per-core counters</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Approach, consider a loop 0..65536, batch size 8</p>
    <p>Distribute iterations at start of loop down to per-core counters</p>
    <p>Aggregate requests upwards within a core</p>
    <p>Per-core lock Per-thread request flags</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Approach, consider a loop 0..65536, batch size 8</p>
    <p>Distribute iterations at start of loop down to per-core counters</p>
    <p>Aggregate requests upwards within a core</p>
    <p>Per-core lock</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Approach, consider a loop 0..65536, batch size 8</p>
    <p>Distribute iterations at start of loop down to per-core counters</p>
    <p>Aggregate requests upwards within a core</p>
    <p>Per-core lock</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Approach, consider a loop 0..65536, batch size 8</p>
    <p>Distribute iterations at start of loop down to per-core counters</p>
    <p>Aggregate requests upwards within a core</p>
    <p>Per-core lock</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Approach, consider a loop 0..65536, batch size 8</p>
    <p>Distribute iterations at start of loop down to per-core counters</p>
    <p>Aggregate requests upwards within a core</p>
    <p>Per-core lock</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Approach, consider a loop 0..65536, batch size 8</p>
    <p>Distribute iterations at start of loop down to per-core counters</p>
    <p>Aggregate requests upwards within a core</p>
    <p>Per-core lock</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Approach, consider a loop 0..65536, batch size 8</p>
    <p>Distribute iterations at start of loop down to per-core counters</p>
    <p>Aggregate requests upwards within a core</p>
    <p>Per-core lock</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Approach, consider a loop 0..65536, batch size 8</p>
    <p>Distribute iterations at start of loop down to per-core counters</p>
    <p>Aggregate requests upwards within a core</p>
    <p>Per-core lock</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Hierarchical distribution with request combining</p>
    <p>Combining implemented over flags in a single line in the shared L1 D$</p>
    <p>On TSO: no memory fences</p>
    <p>Synchronization remains core-local if work is evenly distributed</p>
    <p>Threads waiting for combining can use mwait</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>Request combining</p>
    <p>Asynchronous work requests</p>
    <p>Non-work-conserving nested loops</p>
    <p>Results</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Asynchronous combining of requests</p>
    <p>Synchronous</p>
    <p>Execute batch</p>
    <p>Set flag</p>
    <p>Wait for / fetch next</p>
    <p>batch</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Asynchronous combining of requests</p>
    <p>Synchronous</p>
    <p>Execute batch</p>
    <p>Set flag</p>
    <p>Wait for / fetch next</p>
    <p>batch</p>
    <p>Asynchronous</p>
    <p>Execute batch</p>
    <p>Set flag</p>
    <p>Wait for / fetch next</p>
    <p>batch</p>
    <p>Intuition: the time taken to execute the current batch provides an opportunity for other cores to service our request without us needing to wait</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>Request combining</p>
    <p>Asynchronous work requests</p>
    <p>Non-work-conserving nested loops</p>
    <p>Results</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Nested loops</p>
    <p>Abundant parallelism, why use nesting?</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Nested loops</p>
    <p>Abundant parallelism, why use nesting?</p>
    <p>Contention between iterations of an outer loop</p>
    <p>E.g., betweenness-centrality:</p>
    <p>Iterate over vertices</p>
    <p>BFS traversal from each vertex (plus additional work)</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Nested loops</p>
    <p>Abundant parallelism, why use nesting?</p>
    <p>Contention between iterations of an outer loop</p>
    <p>E.g., betweenness-centrality:</p>
    <p>Iterate over vertices</p>
    <p>BFS traversal from each vertex (plus additional work)</p>
    <p>Better cache locality within each traversal than between (unrelated) traversals</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Nested loops</p>
    <p>Abundant parallelism, why use nesting?</p>
    <p>Contention between iterations of an outer loop</p>
    <p>E.g., betweenness-centrality:</p>
    <p>Iterate over vertices</p>
    <p>BFS traversal from each vertex (plus additional work)</p>
    <p>Better cache locality within each traversal than between (unrelated) traversals</p>
    <p>Run at most one of these per L2 D$</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Nested loops</p>
    <p>Number loops inside out</p>
    <p>Level 0 =&gt; innermost</p>
    <p>Level 1 =&gt; may contain a level-0 loop</p>
    <p>Each thread also has a level  It will execute iterations &lt;= its own level</p>
    <p>Level 0 thread: only executes inner-most loop iterations</p>
    <p>Controlling thread -&gt; loop allocation</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Nested loops</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Nested loops: non-nested level 0  all threads participate</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Nested loops: outer (level 1)  just 1+5 participate</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Nested loops: inner (level 0) help respective leaders</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>Request combining</p>
    <p>Asynchronous work requests</p>
    <p>Non-work-conserving nested loops</p>
    <p>Results</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Microbenchmark results SPARC T5-8, 1024 threads</p>
    <p>Per-socket counters</p>
    <p>Per-core counters Per-thread counters</p>
    <p>Even work</p>
    <p>(Approx 1k cycles)</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li z e</p>
    <p>d s</p>
    <p>p e</p>
    <p>e d</p>
    <p>u p</p>
    <p>Batch size</p>
    <p>Per-core + asynchronous combining (blue) Per-core + synchronous combining (green)</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Microbenchmark results SPARC T5-8, 1024 threads Per-core + asynchronous combining (blue)</p>
    <p>Per-core + synchronous combining (green)</p>
    <p>Per-socket counters</p>
    <p>Per-core counters Per-thread counters</p>
    <p>Even work</p>
    <p>(Approx 1k cycles)</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li z e</p>
    <p>d s</p>
    <p>p e</p>
    <p>e d</p>
    <p>u p</p>
    <p>Batch size</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li z e</p>
    <p>d s</p>
    <p>p e</p>
    <p>e d</p>
    <p>u p</p>
    <p>Batch size</p>
    <p>Imbalanced work (1024:1)</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>PageRank  SNAP LiveJournal (4.8M vertices, 69M edges)</p>
    <p>OpenMP Callisto-RTS</p>
    <p>T h</p>
    <p>re a</p>
    <p>d s</p>
    <p>Batch size</p>
    <p>h re</p>
    <p>a d</p>
    <p>s</p>
    <p>Batch size</p>
    <p>N o</p>
    <p>rm a</p>
    <p>liz e</p>
    <p>d e</p>
    <p>x e</p>
    <p>c u</p>
    <p>tio n</p>
    <p>tim e</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>h re</p>
    <p>a d</p>
    <p>s</p>
    <p>Batch size</p>
    <p>N o</p>
    <p>rm a</p>
    <p>liz e</p>
    <p>d e</p>
    <p>x e</p>
    <p>c u</p>
    <p>tio n</p>
    <p>tim e</p>
    <p>PageRank  SNAP LiveJournal (4.8M vertices, 69M edges)</p>
    <p>OpenMP Callisto-RTS</p>
    <p>T h</p>
    <p>re a</p>
    <p>d s</p>
    <p>Batch size</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>h re</p>
    <p>a d</p>
    <p>s</p>
    <p>Batch size</p>
    <p>N o</p>
    <p>rm a</p>
    <p>liz e</p>
    <p>d e</p>
    <p>x e</p>
    <p>c u</p>
    <p>tio n</p>
    <p>tim e</p>
    <p>PageRank  SNAP LiveJournal (4.8M vertices, 69M edges)</p>
    <p>OpenMP Callisto-RTS</p>
    <p>T h</p>
    <p>re a</p>
    <p>d s</p>
    <p>Batch size</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Betweenness-centrality SNAP Slashdot data set (82.1K nodes, 948K edges), T5-8</p>
    <p>E x e c u ti o n t im</p>
    <p>e (</p>
    <p>s )</p>
    <p>Threads</p>
    <p>No nesting</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Comparison with Galois SNAP Twitter data set</p>
    <p>Xeon X4-2 SPARC T5-8</p>
    <p>S p e e d u p / s</p>
    <p>e q u</p>
    <p>e n ti a l</p>
    <p>Threads</p>
    <p>Callisto-RTS</p>
    <p>Galois</p>
    <p>S p</p>
    <p>e e</p>
    <p>d u</p>
    <p>p / s</p>
    <p>e q</p>
    <p>u e</p>
    <p>n ti a</p>
    <p>l Threads</p>
    <p>Callisto-RTS</p>
    <p>Per-socket</p>
    <p>Galois</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Comparison with Galois SNAP LiveJournal data set</p>
    <p>Xeon X4-2 SPARC T5-8</p>
    <p>S p e e d u p / s</p>
    <p>e q u</p>
    <p>e n ti a l</p>
    <p>Threads</p>
    <p>Callisto-RTS</p>
    <p>Galois</p>
    <p>S p</p>
    <p>e e</p>
    <p>d u</p>
    <p>p / s</p>
    <p>e q</p>
    <p>u e</p>
    <p>n ti a</p>
    <p>l Threads</p>
    <p>Callisto-RTS</p>
    <p>Per-socket</p>
    <p>Galois</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
    <p>Future work</p>
    <p>Continuing development of the programming model</p>
    <p>Control over data placement as well as threads</p>
    <p>Initial examples from graph workloads generally have random accesses: spread data and threads widely in the machine</p>
    <p>(See Shoal, USENIX ATC 2015)</p>
    <p>Interactions between multiple parallel workloads</p>
    <p>OS/runtime system interaction (ref our prior work at EuroSys 2014)</p>
    <p>Placement in the machine</p>
    <p>Control over degree of parallelism</p>
  </div>
  <div class="page">
    <p>Copyright  2015, Oracle and/or its affiliates. All rights reserved.</p>
  </div>
  <div class="page"/>
</Presentation>
