<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Data Parallel FPGA Workloads: Software Versus Hardware</p>
    <p>Peter Yiannacouras J. Gregory Steffan Jonathan Rose</p>
    <p>FPL 2009</p>
  </div>
  <div class="page">
    <p>FPGA Systems and Soft Processors</p>
    <p>Soft Processor</p>
    <p>Custom HW</p>
    <p>HDL +</p>
    <p>CAD</p>
    <p>Software +</p>
    <p>Compiler</p>
    <p>Easier  Faster  Smaller  Less Power</p>
    <p>Simplify FPGA design: Customize soft processor architecture</p>
    <p>? Configurable COMPETE</p>
    <p>Weeks Months</p>
    <p>Target: Data level parallelism  vector processors</p>
    <p>Used in 25% of designs [source: Altera, 2009]</p>
    <p>Digital System computation</p>
  </div>
  <div class="page">
    <p>Vector Processing Primer</p>
    <p>// C code for(i=0;i&lt;16; i++) c[i]=a[i]+b[i]</p>
    <p>// Vectorized code set vl,16 vload vr0,a vload vr1,b vadd vr2,vr0,vr1 vstore vr2,c</p>
    <p>Each vector instruction holds many units of independent operations</p>
    <p>vr2[0]= vr0[0]+vr1[0] vr2[1]= vr0[1]+vr1[1] vr2[2]= vr0[2]+vr1[2]</p>
    <p>vr2[4]= vr0[4]+vr1[4] vr2[3]= vr0[3]+vr1[3]</p>
    <p>vr2[5]= vr0[5]+vr1[5] vr2[6]= vr0[6]+vr1[6] vr2[7]= vr0[7]+vr1[7] vr2[8]= vr0[8]+vr1[8] vr2[9]= vr0[9]+vr1[9]</p>
    <p>vr2[10]=vr0[10]+vr1[10] vr2[11]=vr0[11]+vr1[11] vr2[12]=vr0[12]+vr1[12] vr2[13]=vr0[13]+vr1[13] vr2[14]=vr0[14]+vr1[14] vr2[15]=vr0[15]+vr1[15]</p>
    <p>vadd</p>
  </div>
  <div class="page">
    <p>Vector Processing Primer</p>
    <p>// C code for(i=0;i&lt;16; i++) c[i]=a[i]+b[i]</p>
    <p>// Vectorized code set vl,16 vload vr0,a vload vr1,b vadd vr2,vr0,vr1 vstore vr2,c</p>
    <p>Each vector instruction holds many units of independent operations</p>
    <p>vadd 16 Vector Lanes</p>
    <p>vr2[0]= vr0[0]+vr1[0] vr2[1]= vr0[1]+vr1[1] vr2[2]= vr0[2]+vr1[2]</p>
    <p>vr2[4]= vr0[4]+vr1[4] vr2[3]= vr0[3]+vr1[3]</p>
    <p>vr2[5]= vr0[5]+vr1[5] vr2[6]= vr0[6]+vr1[6] vr2[7]= vr0[7]+vr1[7] vr2[8]= vr0[8]+vr1[8] vr2[9]= vr0[9]+vr1[9]</p>
    <p>vr2[10]=vr0[10]+vr1[10] vr2[11]=vr0[11]+vr1[11] vr2[12]=vr0[12]+vr1[12] vr2[13]=vr0[13]+vr1[13] vr2[14]=vr0[14]+vr1[14] vr2[15]=vr0[15]+vr1[15]</p>
    <p>Previous Work (on Soft Vector Processors): 1. Scalability 2. Flexibility 3. Portability</p>
  </div>
  <div class="page">
    <p>Soft Vector Processors vs HW</p>
    <p>Custom HW HDL</p>
    <p>+ CAD</p>
    <p>Software +</p>
    <p>Compiler</p>
    <p>Easier  Faster  Smaller  Less Power</p>
    <p>What is the soft vector processor vs FPGA custom HW gap? (also vs scalar soft processor)</p>
    <p>+ Vectorizer</p>
    <p>Lane 1</p>
    <p>Vector Lanes</p>
    <p>Lane 2</p>
    <p>Lane 3</p>
    <p>Lane 4</p>
    <p>Lane 5</p>
    <p>Lane 6</p>
    <p>Lane 7</p>
    <p>Lane 8 16</p>
    <p>How much?</p>
    <p>Soft Vector Processor</p>
    <p>Weeks Months</p>
    <p>Scalable Fine-tunable Customizable</p>
  </div>
  <div class="page">
    <p>Measuring the Gap</p>
    <p>EEMBC Benchmarks</p>
    <p>Scalar Soft</p>
    <p>Processor</p>
    <p>Soft Vector</p>
    <p>Processor</p>
    <p>HW Circuits</p>
    <p>Evaluation Evaluation Evaluation</p>
    <p>Speed Area</p>
    <p>Speed Area</p>
    <p>Speed Area</p>
    <p>Compare Compare</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>VESPA Architecture Design (Vector Extended Soft Processor Architecture)</p>
    <p>Scalar Pipeline 3-stage</p>
    <p>Vector Control Pipeline 3-stage</p>
    <p>Vector Pipeline 6-stage</p>
    <p>Icache Dcache</p>
    <p>Decode RF A L U</p>
    <p>M U X</p>
    <p>WB</p>
    <p>VC RF</p>
    <p>VS RF</p>
    <p>VC WB</p>
    <p>VS WB</p>
    <p>Logic</p>
    <p>Decode Replicate</p>
    <p>Hazard check</p>
    <p>VR RF</p>
    <p>VR WB</p>
    <p>VR RF</p>
    <p>VR WB</p>
    <p>Decode</p>
    <p>Supports integer and fixed-point operations [VIRAM]</p>
    <p>Shared Dcache</p>
    <p>Legend Pipe stage Logic Storage</p>
    <p>Lane 1 ALU,Mem UnitLane 2 ALU, Mem, Mul</p>
  </div>
  <div class="page">
    <p>VESPA Parameters</p>
    <p>Description Symbol Values</p>
    <p>Number of Lanes L 1,2,4,8,</p>
    <p>Memory Crossbar Lanes M 1,2, , L</p>
    <p>Multiplier Lanes X 1,2, , L</p>
    <p>Maximum Vector Length MVL 2,4,8,</p>
    <p>Width of Lanes (in bits) W 1-32</p>
    <p>Instruction Enable (each) - on/off</p>
    <p>Data Cache Capacity DD any</p>
    <p>Data Cache Line Size DW any</p>
    <p>Data Prefetch Size DPK &lt; DD</p>
    <p>Vector Data Prefetch Size DPV &lt; DD/MVL</p>
    <p>Compute Architecture</p>
    <p>Memory Hierarchy</p>
    <p>Instruction Set</p>
    <p>Architecture</p>
  </div>
  <div class="page">
    <p>VESPA Evaluation Infrastructure</p>
    <p>Vectorized assembly</p>
    <p>subroutines GNU as</p>
    <p>ELF Binary</p>
    <p>Instruction Set</p>
    <p>Simulation</p>
    <p>scalar P</p>
    <p>+ vpu</p>
    <p>VC RF</p>
    <p>VS RF</p>
    <p>VC W B</p>
    <p>VS W B</p>
    <p>Logic</p>
    <p>Decode Replicate</p>
    <p>Hazard check</p>
    <p>VR RF</p>
    <p>A L U</p>
    <p>Mem Unit</p>
    <p>x &amp; satur.</p>
    <p>VR W B</p>
    <p>M U X</p>
    <p>Saturate</p>
    <p>Rshift</p>
    <p>VR RF</p>
    <p>A L U</p>
    <p>x &amp; satur.</p>
    <p>VR W B</p>
    <p>M U X</p>
    <p>Saturate</p>
    <p>Rshift</p>
    <p>EEMBC C Benchmarks</p>
    <p>RTL Simulation</p>
    <p>SOFTWARE HARDWARE Verilog</p>
    <p>Altera Quartus II</p>
    <p>v 8.1</p>
    <p>cycles area, clock frequency</p>
    <p>GCC</p>
    <p>ld</p>
    <p>verification verification</p>
    <p>TM4</p>
    <p>Realistic and detailed evaluation</p>
  </div>
  <div class="page">
    <p>Measuring the Gap</p>
    <p>EEMBC Benchmarks</p>
    <p>Scalar Soft</p>
    <p>Processor</p>
    <p>Soft Vector</p>
    <p>Processor</p>
    <p>HW Circuits</p>
    <p>Evaluation Evaluation Evaluation</p>
    <p>Speed Area</p>
    <p>Speed Area</p>
    <p>Speed Area</p>
    <p>Compare Compare</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Designing HW Circuits (with simplifying assumptions)</p>
    <p>DDR Core</p>
    <p>Datapath</p>
    <p>Memory Request</p>
    <p>Control</p>
    <p>HW</p>
    <p>Idealized</p>
    <p>cycle count (modelled)  Assume fed at full DDR bandwidth  Calculate execution time from data size</p>
    <p>Optimistic HW implementations vs real processors</p>
    <p>Altera Quartus II</p>
    <p>v 8.1</p>
    <p>area, clock frequency</p>
  </div>
  <div class="page">
    <p>Benchmarks Converted to HW</p>
    <p>EEMBC</p>
    <p>VIRAM</p>
    <p>Stratix III 3S200C2</p>
    <p>VESPA Clock: 120-140 MHz</p>
    <p>HW Clock: 275-475 MHz</p>
    <p>HW advantage: 3x faster clock frequency</p>
  </div>
  <div class="page">
    <p>Performance/Area Space (vs HW)</p>
    <p>Scalar  432x slower, 7x larger</p>
    <p>Soft vector processors can significantly close performance gap</p>
    <p>S lo</p>
    <p>w d</p>
    <p>o w</p>
    <p>n v</p>
    <p>s H</p>
    <p>W</p>
    <p>Area vs HW fastest VESPA 17x slower, 64x larger</p>
    <p>HW (1,1) optimistic</p>
    <p>HW Area Advantage</p>
    <p>H</p>
    <p>W S</p>
    <p>p e</p>
    <p>e d</p>
    <p>A d</p>
    <p>v a</p>
    <p>n ta</p>
    <p>g e</p>
  </div>
  <div class="page">
    <p>Area-Delay Product</p>
    <p>Commonly used to measure efficiency in silicon  Considers both performance and area  Inverse of performance-per-area</p>
    <p>Calculated using:</p>
    <p>(Area)  (Wall Clock Execution Time)</p>
  </div>
  <div class="page">
    <p>Area-Delay Space (vs HW)</p>
    <p>VESPA up to 3 times better silicon usage than Scalar</p>
    <p>A re</p>
    <p>a -D</p>
    <p>e la</p>
    <p>y v</p>
    <p>s H</p>
    <p>W</p>
    <p>HW Area Advantage</p>
    <p>H</p>
    <p>W A</p>
    <p>re a</p>
    <p>-D e</p>
    <p>la y</p>
    <p>A d</p>
    <p>v a</p>
    <p>n ta</p>
    <p>g e</p>
  </div>
  <div class="page">
    <p>Reducing the Performance Gap</p>
    <p>Previously: VESPA was 50x slower than HW</p>
    <p>Reducing loop overhead  VESPA: Decoupled pipelines (+7% speed)</p>
    <p>Improving data delivery  VESPA: Parameterized cache (2x speed, 2x area)  VESPA: Data Prefetching (+42% speed)</p>
    <p>These enhancements were key parts of reducing gap, combined 3x performance improvement</p>
  </div>
  <div class="page">
    <p>Vector Memory Crossbar</p>
    <p>Wider Cache Line Size</p>
    <p>Scalar Vector Coproc</p>
    <p>Lane 0 Lane</p>
    <p>Dcache 4KB,</p>
    <p>Lane 0 Lane</p>
    <p>Lane 4 Lane</p>
    <p>VESPA 16 lanes</p>
    <p>vld.w (load 16 sequential 32-bit words)</p>
  </div>
  <div class="page">
    <p>Vector Memory Crossbar</p>
    <p>Wider Cache Line Size</p>
    <p>Scalar Vector Coproc</p>
    <p>Lane 0 Lane</p>
    <p>Dcache 16KB,</p>
    <p>Lane 0 Lane</p>
    <p>Lane 4 Lane</p>
    <p>VESPA 16 lanes</p>
    <p>vld.w (load 16 sequential 32-bit words)</p>
  </div>
  <div class="page">
    <p>Hardware Prefetching Example</p>
    <p>DDR</p>
    <p>Dcache</p>
    <p>vld.w</p>
    <p>No Prefetching Prefetching 3 blocks</p>
    <p>DDR</p>
    <p>Dcache</p>
    <p>vld.w</p>
    <p>MISS MISS</p>
    <p>vld.w vld.w</p>
    <p>HITMISS</p>
  </div>
  <div class="page">
    <p>Reducing the Area Gap (by Customizing the Instruction Set)</p>
    <p>FPGAs can be reconfigured between applications</p>
    <p>Observations: Not all applications 1. Operate on 32-bit data types</p>
    <p>Eliminate unused hardware</p>
  </div>
  <div class="page">
    <p>VESPA Parameters</p>
    <p>Description Symbol Values</p>
    <p>Number of Lanes L 1,2,4,8,</p>
    <p>Maximum Vector Length MVL 2,4,8,</p>
    <p>Width of Lanes (in bits) W 1-32</p>
    <p>Memory Crossbar Lanes M 1,2, , L</p>
    <p>Multiplier Lanes X 1,2, , L</p>
    <p>Instruction Enable (each) - on/off</p>
    <p>Data Cache Capacity DD any</p>
    <p>Data Cache Line Size DW any</p>
    <p>Data Prefetch Size DPK &lt; DD</p>
    <p>Vector Data Prefetch Size DPV &lt; DD/MVL</p>
    <p>Subset instruction set</p>
    <p>Reduce width</p>
  </div>
  <div class="page">
    <p>Customized VESPA vs HW</p>
    <p>Up to 45% area saved with width reduction &amp; subsetting</p>
    <p>S lo</p>
    <p>w d</p>
    <p>o w</p>
    <p>n v</p>
    <p>s H</p>
    <p>W</p>
    <p>Area vs HW HW Area Advantage</p>
    <p>H</p>
    <p>W S</p>
    <p>p e</p>
    <p>e d</p>
    <p>A d</p>
    <p>v a</p>
    <p>n ta</p>
    <p>g e</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>VESPA more competitive with HW design  Fastest VESPA only 17x slower than HW</p>
    <p>Scalar soft processor was 432x slower than HW  Attacking loop overhead and data delivery was key</p>
    <p>Decoupled pipelines, cache tuning, data prefetching  Further enhancements can reduce the gap more</p>
    <p>VESPA improves efficiency of silicon usage  900x worse area-delay than HW</p>
    <p>Scalar soft processor 2900x worse area-delay than HW  Subsetting/width reduction can further reduce to 561x</p>
    <p>Enable software implementation for non-critical data-parallel computation</p>
  </div>
  <div class="page">
    <p>Thank You!</p>
    <p>Stay tuned for public release: 1. GNU assembler ported for VIRAM (integer only)</p>
  </div>
  <div class="page">
    <p>Breaking Down Performance</p>
    <p>Components of performance</p>
    <p>Loop:</p>
    <p>&lt;work&gt;</p>
    <p>goto Loop</p>
    <p>Loop:</p>
    <p>&lt;work&gt;</p>
    <p>goto Loop</p>
    <p>Loop:</p>
    <p>&lt;work&gt;</p>
    <p>goto Loop</p>
    <p>Iteration-level parallelism</p>
    <p>Cycles per iteration  Clock period</p>
    <p>a)</p>
    <p>b)</p>
    <p>c)</p>
    <p>Measure the HW advantage in each of these components</p>
  </div>
  <div class="page">
    <p>Breakdown of Performance Loss (16 lane VESPA vs HW)</p>
    <p>Benchmark Clock</p>
    <p>Frequency</p>
    <p>Iteration Level</p>
    <p>Parallelism</p>
    <p>Cycles Per</p>
    <p>Iteration</p>
    <p>autcor 2.6x 1x 9.1x</p>
    <p>conven 3.9x 1x 6.1x</p>
    <p>rgbcmyk 3.7x 0.375x 13.8x</p>
    <p>rgbyiq 2.2x 0.375x 19.0x</p>
    <p>ip_checksum 3.7x 0.5x 4.8x</p>
    <p>imgblend 3.6x 1x 4.4x</p>
    <p>GEOMEAN 3.2x 0.64x 8.2x</p>
    <p>Largest factor</p>
    <p>Was previously worse, recently improved</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Measuring the Gap</p>
    <p>Scalar: MIPS soft processor</p>
    <p>VESPA: VIRAM soft vector processor</p>
    <p>HW: Custom circuit for each benchmark</p>
    <p>COMPARE</p>
    <p>(simplified &amp; idealized)</p>
    <p>(complete &amp; real)</p>
    <p>COMPARE</p>
    <p>(complete &amp; real)</p>
    <p>EEMBC C Benchmarks</p>
    <p>C</p>
    <p>assembly</p>
    <p>Verilog</p>
  </div>
  <div class="page">
    <p>Reporting Comparison Results</p>
    <p>Performance (wall clock time)</p>
    <p>Area (actual silicon area)</p>
    <p>HW Speed Advantage = Execution Time of Processor</p>
    <p>Execution Time of Hardware</p>
    <p>HW Area Advantage = Area of Processor</p>
    <p>Area of Hardware</p>
    <p>VESPA (Vector assembly) HW (Verilog)</p>
    <p>vs HW (Verilog) vs HW (Verilog)</p>
  </div>
  <div class="page">
    <p>Cache Design Space  Performance (Wall Clock Time)</p>
    <p>Best cache design almost doubles performance of original VESPA</p>
    <p>More pipelining/retiming could reduce clock frequency penalty</p>
    <p>Cache line more important than cache depth (lots of streaming)</p>
  </div>
  <div class="page">
    <p>Vector Length Prefetching Performance</p>
    <p>Peak 29%</p>
    <p>Not receptive</p>
    <p>no cache pollution</p>
  </div>
  <div class="page">
    <p>Overall Memory System Performance</p>
    <p>(4KB) (16KB)</p>
    <p>Wider line + prefetching reduces memory unit stall cycles significantly</p>
    <p>Wider line + prefetching eliminates all but 4% of miss cycles</p>
  </div>
</Presentation>
