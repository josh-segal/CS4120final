<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>HASE: A Hybrid Approach to Selectivity Estimation for Conjunctive Queries</p>
    <p>Xiaohui Yu University of Toronto xhyu@cs.toronto.edu</p>
    <p>Joint work with Nick Koudas (University of Toronto) and Calisto Zuza rte (IBM Toronto Lab)</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Background  Motivation  Related Work</p>
    <p>HASE  Estimator  A lgorithms  Bounds  Experiments</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Query Optimization</p>
    <p>Execution plans differ in costs  Difference can be huge (1 sec vs. 1 hour)  Which Plan to Choose??</p>
    <p>Query Optimization  Estimate the costs of different plans  Choose the plan with the least cost</p>
    <p>Cost Estimation  Factors: run-time environments, data properties</p>
    <p>,</p>
  </div>
  <div class="page">
    <p>Selectivity  Important factor in costing: selectivity</p>
    <p>Fraction of records satisfying the predicate (s)  E.g., 100 out of 10,000 records having salary &gt; 3000</p>
    <p>s = 100/10000 = 0.01</p>
    <p>Selectivity can make a big difference</p>
    <p>Selectivity (s)</p>
    <p>co st</p>
    <p>Plan 1: Table scan</p>
    <p>Plan 2: Index scan</p>
    <p>Cost = s * const2</p>
    <p>Cost = const1s = 0.01</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>Two streams  Synopsis-based  Sampling-based</p>
    <p>Synopses  Capture the characteristics of data  Obtained off-line, used on-line  E.g., Histograms</p>
  </div>
  <div class="page">
    <p>Histograms</p>
    <p>Salary 2500 3500 5000 6000</p>
    <p>Q: Selectivity of salary&gt;3000?</p>
    <p>A: # of records in red / total # of records</p>
    <p>Estimate = ( 500 + 800 + 1700 ) / 5000 = 0.6</p>
    <p>Salary</p>
    <p>3200.00</p>
    <p>2500.00</p>
    <p>4000.00</p>
    <p>6000.00</p>
  </div>
  <div class="page">
    <p>Synopses: pros and cons</p>
    <p>Pros:  Built offline; can be used many times  minimal overhead at selectivity</p>
    <p>estimation time  Cons:</p>
    <p>Difficult to capture all useful information in a limited space</p>
    <p>Correlation between attributes</p>
  </div>
  <div class="page">
    <p>Sampling</p>
    <p>Number of records in the table: 10,000</p>
    <p>Sample size: 100</p>
    <p>Number of records having age &gt; 50 and salary &gt; 5500 : 12</p>
    <p>Selectivity estimate = 12/100 = 0.12</p>
    <p>True selectivity = 0.09</p>
  </div>
  <div class="page">
    <p>Sampling: pros and cons  The good:</p>
    <p>Provides correlation info through the sample  The bad:</p>
    <p>Cost, cost  Accurate results require a large portion of</p>
    <p>the data to be accessed  Random access is much slower than</p>
    <p>sequential access</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Synopses Sampling</p>
    <p>Runtime cost</p>
    <p>Correlation information</p>
    <p>Take the best of both worlds?</p>
    <p>Capture correlation + reduce sampling rate</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Background  Motivation  Related Work</p>
    <p>Our approach: HASEOur approach: HASE  Estimator  Algorithms  Bounds  Experiments</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>HASE  Hybrid approach to selectivity estimation</p>
    <p>Salary 2500 3500 5000 6000</p>
    <p>Goal: Consistent utilization of both sources of information</p>
    <p>Benefits:</p>
  </div>
  <div class="page">
    <p>Problem setting</p>
    <p>Conjuncts of predicates Q = P1^P2^P3 ^ (age&gt;50)^(salary&gt;5500)^(hire_date&gt;01-01-05)</p>
    <p>P1 P2 P3</p>
    <p>Selectivities of individual predicates (obtained from synopses)</p>
    <p>s1 = 0.1, s2 = 0.2, s3 = 0.05</p>
    <p>A Sample S of n records</p>
    <p>Inclusion probability of record j : j For simple random sampling (SRS) j = n/N</p>
    <p>Query:</p>
    <p>Available info:</p>
    <p>Data: Table of size N</p>
    <p>Goal Estimate the selectivity s of the query Q</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>Table R with 10,000 records</p>
    <p>Query Q = P1^P2 on two attributes</p>
    <p>Suppose 500 records satisfy both predicates</p>
    <p>True Selectivity s = 500/10000 = 0.05</p>
  </div>
  <div class="page">
    <p>Histogram-based estimate</p>
    <p>Assuming independence between attributes</p>
    <p>Selectivity estimate  i</p>
    <p>ihis ss</p>
    <p>Based on the histograms, s1 = 0.6, s2 = 0.3</p>
    <p>Relative error = |0.18  0.05 | /0.05 = 260%</p>
    <p>ihis ss</p>
  </div>
  <div class="page">
    <p>Sampling-based estimate</p>
    <p>Sj</p>
    <p>jjspl yd N</p>
    <p>s 1</p>
    <p>otherwise 0,</p>
    <p>query thesatisfies if ,1 j y j</p>
    <p>Sample weight of j : dj = 1/ j</p>
    <p>Indicator variable</p>
    <p>Selectivity Estimate (HT estimator)</p>
    <p>Take a SRS of size 100  dj = 10000/100 = 100</p>
    <p>Estimate = 9*100/10000 = 0.09</p>
    <p>Relative error = | 0.05  0.09 | / 0.05 = 80%</p>
    <p>spls</p>
  </div>
  <div class="page">
    <p>A new estimator</p>
    <p>Sj</p>
    <p>jjspl yd N</p>
    <p>s 1</p>
    <p>Known selectivities (through histograms) s1, s2,</p>
    <p>Sj</p>
    <p>jjcal yw N</p>
    <p>s 1</p>
    <p>wj: (1) reproduce known selectivities of individual predicates</p>
    <p>(2) as close to dj as possible</p>
    <p>Original weights</p>
    <p>New weights Calibration estimator</p>
  </div>
  <div class="page">
    <p>Consistency with known selectivities</p>
    <p>otherwise0</p>
    <p>satisfies 1 i ji</p>
    <p>Pj x</p>
    <p>P2=true P2=false</p>
    <p>P1=true 0.09 0.56 0.65</p>
    <p>P1=false 0.24 0.11 0.35</p>
    <p>- 0.33 0.67</p>
    <p>Observed frequencies from sample</p>
    <p>dj = 100</p>
    <p>Sj jj xd s1 = 0.6</p>
    <p>Sj jj xw</p>
  </div>
  <div class="page">
    <p>Calibration estimator</p>
    <p>Why do we want wj to be as close as dj as possible?</p>
    <p>dj have the property of producing unbiased estimates</p>
    <p>wj remain nearly unbiased</p>
    <p>Keep wj as close to dj as possible</p>
  </div>
  <div class="page">
    <p>Constrained optimization problem</p>
    <p>Distance function D(x) (x = wj /dj )</p>
    <p>Minimize  Sj</p>
    <p>jjj dwDd )/(</p>
    <p>Subject to</p>
    <p>Sj</p>
    <p>xjjw N</p>
    <p>tx 1</p>
    <p>w.r.t. wj</p>
    <p>),,...,,,( 1,1  mjjmjijj xxxx x</p>
    <p>j satisfies Pi? Yes: 1</p>
    <p>No: 0</p>
    <p>)1,,,( 1 msst x</p>
    <p>Sj</p>
    <p>jj sxw N</p>
    <p>(As close to dj as possible)</p>
    <p>(reproduce known selectivities)</p>
  </div>
  <div class="page">
    <p>An algorithm based on Newtons method</p>
    <p>Method of Lagrange multipliers</p>
    <p>Minimize w.r.t.</p>
    <p>Sj Sj</p>
    <p>xjj T</p>
    <p>jjj NwdwDd )()/( tx jw</p>
    <p>),,...,,( 121  mm where</p>
    <p>Can be solved using Newtons method via an ite rative procedure.   wj</p>
    <p>Sj</p>
    <p>xj T jj NFd txx )(</p>
    <p>)(' offunction inverse theis )( where xDxF</p>
    <p>cals</p>
  </div>
  <div class="page">
    <p>An alternative algorithm</p>
    <p>)1,...,2,1( 1</p>
    <p>misw N</p>
    <p>i DSj</p>
    <p>j</p>
    <p>i</p>
    <p>)1,...,2,1( )( 1</p>
    <p>misFd N</p>
    <p>i DSj</p>
    <p>T jj</p>
    <p>i</p>
    <p>x</p>
    <p>)( xTjjj Fdw</p>
    <p>)(' offunction inverse theis )( where xDxF</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>P2=true P2=false</p>
    <p>P1=true 0.09 0.56</p>
    <p>P1=false 0.24 0.11</p>
    <p>Observed frequencies from sample</p>
    <p>)( 140),( 97</p>
    <p>)( 102),( 60</p>
    <p>DDSjwDDSjw</p>
    <p>DDSjwDDSjw</p>
    <p>jj</p>
    <p>jj</p>
    <p>DDSj</p>
    <p>j Sj</p>
    <p>jjcal w N</p>
    <p>yw N</p>
    <p>s</p>
    <p>%805.005.0054.0||Error Relative  ssscal</p>
    <p>s</p>
    <p>s</p>
    <p>jd j</p>
  </div>
  <div class="page">
    <p>Distance measures  Requirements on the distance function</p>
    <p>(1) D is positive and strictly convex (2) D(1) = D(1) = 0 (3) D(1) = 1</p>
    <p>Linear function  only one iteration required  fast!  wj &lt; 0 possible  negative estimates</p>
    <p>Multiplicative function  Converges after a few iterations (typically two)  wj &gt; 0 always</p>
    <p>21/2/1)/(  jjjjlin dwdwD</p>
  </div>
  <div class="page">
    <p>Error bounds</p>
    <p>Probabilistic bounds</p>
    <p>jl = Pr ( both j and l are in the sample ) jjj</p>
    <p>:</p>
    <p>Rj</p>
    <p>T jjjj yd 0)( xx</p>
    <p>Tjjjljjljl xy  ,</p>
    <p>Rj Rl lljjjljlcal</p>
    <p>calcalcalcal</p>
    <p>wwsV</p>
    <p>z</p>
    <p>sVzssVzss</p>
    <p>))()(/()(</p>
    <p>and Guassian, ofpoint /2upper theis where</p>
    <p>,-1 prob with )(,)(</p>
    <p>(0,1),constant given a and sample large aFor</p>
  </div>
  <div class="page">
    <p>Synthetic data  Skew: Zipfian distribution (z=0,1,2,3)  Correlation: corr. coef. between attributes: [0, 1]</p>
    <p>Real data  Census-Income data from UCI KDD Archive  Population surveys by the US Census Bureau.  ~200,000 records, 40 attributes</p>
    <p>Queries  Range queries: attribute&lt;= constant  Equality queries: attribute = constant</p>
    <p>Experiments</p>
  </div>
  <div class="page">
    <p>Effect of correlation</p>
  </div>
  <div class="page">
    <p>Effect of data skew</p>
    <p>z</p>
    <p>A bs</p>
    <p>ol ut</p>
    <p>e re</p>
    <p>la tiv</p>
    <p>e er</p>
    <p>ro r</p>
    <p>correlation coefficient = 1, sample rate = 0.005</p>
    <p>Sampling Synopsis HASE</p>
  </div>
  <div class="page">
    <p>Effect of sample rate</p>
  </div>
  <div class="page">
    <p>Effect of number of attributes</p>
    <p>Number of attributes</p>
    <p>A bs</p>
    <p>ol ua</p>
    <p>te r</p>
    <p>el at</p>
    <p>iv e</p>
    <p>er ro</p>
    <p>r</p>
    <p>z = 0, correlation = 0.85, sample rate = 0.01</p>
    <p>HASE Sampling Synopsis</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Synopsis-based estimation Sampling-based estimation</p>
    <p>Selectivity Estimation</p>
    <p>HASE</p>
    <p>The calibrated estimator</p>
    <p>Algorithms</p>
    <p>Probabilistic bounds on errors</p>
    <p>Experimental results</p>
    <p>Benefits:</p>
  </div>
</Presentation>
