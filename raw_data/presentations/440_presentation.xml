<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>2011 IBM Corporation</p>
    <p>Dean Hildebrand, Anna Povzner, Renu Tewari  IBM Almaden Vasily Tarasov  Stony Brook University</p>
    <p>Revisiting the Storage Stack in Virtualized NAS Environments</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation2</p>
    <p>NAS On the Rise</p>
    <p>o Increase in unstructured data  web, video, photograph, images, music</p>
    <p>o Move to single storage network  Users migrating from SAN block storage to IPSAN</p>
    <p>10GigE becoming commonplace</p>
    <p>o Virtual Mache Disk Images  Ease of movement</p>
    <p>Migrate and run anywhere</p>
    <p>Simplified and flexible storage management</p>
    <p>Thin provisioning by default</p>
    <p>Industry Protocol Mix</p>
    <p>NAS %</p>
    <p>iSCSI %</p>
    <p>FC SAN %</p>
    <p>DAS %</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation3</p>
    <p>NAS in the Data Center</p>
    <p>o Single scalable NAS storage system  Capacity and throughput limited only by budget</p>
    <p>o Support all relevant NAS protocols  NFSv3/v4/v4.1/pNFS/v4.2, iSCSI, CIFS, SMB2</p>
    <p>Storage JBODS,</p>
    <p>Controllers, DAS</p>
    <p>Servers Scalable NAS</p>
    <p>Servers</p>
    <p>Hypervisor A  pNFS</p>
    <p>Hypervisor B  iSCSI</p>
    <p>Hypervisor C  NFSv3</p>
    <p>App Server 1 - pNFS</p>
    <p>Backup Server 1  CIFS</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation4</p>
    <p>Applications migrating from traditional NAS environments</p>
    <p>H y p e</p>
    <p>rv is</p>
    <p>o r</p>
    <p>SAN</p>
    <p>V M</p>
    <p>N A</p>
    <p>S S</p>
    <p>e rv</p>
    <p>e r</p>
    <p>Applications</p>
    <p>Virtual File System</p>
    <p>File System</p>
    <p>Block Layer</p>
    <p>Storage Controller Drv</p>
    <p>Controller Emulator</p>
    <p>NAS Client</p>
    <p>NFS Server</p>
    <p>Virtual File System</p>
    <p>On-Disk File System</p>
    <p>Block Layer</p>
    <p>Storage</p>
    <p>IP Network</p>
    <p>VM-NAS Software Stack</p>
    <p>A p</p>
    <p>p S</p>
    <p>e rv</p>
    <p>e r</p>
    <p>SAN</p>
    <p>N A</p>
    <p>S S</p>
    <p>e rv</p>
    <p>e r</p>
    <p>Applications</p>
    <p>NAS Client</p>
    <p>NFS Server</p>
    <p>Virtual File System</p>
    <p>On-Disk File System</p>
    <p>Block Layer</p>
    <p>Storage</p>
    <p>IP Network</p>
    <p>NFS Software Stack</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation5</p>
    <p>VM-NAS Write Example</p>
    <p>Lots of opportunities for inefficiencies</p>
    <p>A I C F D G E H B</p>
    <p>Guest File System</p>
    <p>Guest Block Layer</p>
    <p>Disk Image in</p>
    <p>Server FS</p>
    <p>Server Block Layer</p>
    <p>File1 File2 File3</p>
    <p>A I C F D G E H B</p>
    <p>A B C D E F G H I</p>
    <p>B C I A H E F D G</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation6</p>
    <p>Virtual Machines and NAS  Plug and Play?</p>
    <p>Potential Hurdles</p>
    <p>o I/O workloads revamped  Typical DB, Web Server, etc workloads may no longer</p>
    <p>applicable  Workloads changes as I/O requests flow through virtualization and</p>
    <p>NAS software stack</p>
    <p>Server file system may not handle these new workloads</p>
    <p>For example, workload may change from many small</p>
    <p>files to a small number of large files.</p>
    <p>o Block on File  NFS must support block requests</p>
    <p>VM block driver in layer above NFS client</p>
    <p>Basic file system optimizations now handled by VM  NFS client can no longer leverage techniques such as readahead,</p>
    <p>write-back cache, and write gathering</p>
    <p>o I/O Optimization layering  Does VM or NAS client implement performance optimizations</p>
    <p>such as caching, readahead, write gathering, etc.</p>
    <p>o Out-of-band storage management operations  Server-side copy, clones, snapshots, space reservations, etc</p>
    <p>H y p e</p>
    <p>rv is</p>
    <p>o r</p>
    <p>SAN</p>
    <p>V M</p>
    <p>N A</p>
    <p>S S</p>
    <p>e rv</p>
    <p>e r</p>
    <p>Applications</p>
    <p>Virtual File System</p>
    <p>File System</p>
    <p>Block Layer</p>
    <p>Storage Controller Drv</p>
    <p>Controller Emulator</p>
    <p>NAS Client</p>
    <p>NFS Server</p>
    <p>Virtual File System</p>
    <p>On-Disk File System</p>
    <p>Block Layer</p>
    <p>Storage</p>
    <p>IP Network</p>
    <p>VM-NAS Software Stack</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation7</p>
    <p>Test Harness and Multi-Level Tracing</p>
    <p>o Setup  Virtual Environment (VM-NFS)</p>
    <p>Hypervisor: ESX 4.1 with NFSv3</p>
    <p>Guest: Fedora 14</p>
    <p>Disk image: Ext2</p>
    <p>NFS Environment (NFS)  Linux 2.6.34</p>
    <p>NFS  rsize = 64KB, wsize = 512KB (ESX maximums)</p>
    <p>32 nfsd threads</p>
    <p>Server File System: GPFS</p>
    <p>o Tracing at four levels  Guest VFS  What is the app doing?</p>
    <p>vscsistats  What is coming out of the VM?</p>
    <p>Server file system  What is NFS sending to the server?</p>
    <p>Server block layer  What is the FS sending to the disks?</p>
    <p>H y p e</p>
    <p>rv is</p>
    <p>o r</p>
    <p>SAN</p>
    <p>V M</p>
    <p>N A</p>
    <p>S S</p>
    <p>e rv</p>
    <p>e r</p>
    <p>Applications</p>
    <p>Virtual File System</p>
    <p>File System</p>
    <p>Block Layer</p>
    <p>Storage Controller Drv</p>
    <p>Controller Emulator</p>
    <p>NAS Client</p>
    <p>NFS Server</p>
    <p>Virtual File System</p>
    <p>On-Disk File System</p>
    <p>Block Layer</p>
    <p>Storage</p>
    <p>IP Network</p>
    <p>VM-NAS Software Stack</p>
    <p>Trace1</p>
    <p>Trace2</p>
    <p>Trace3</p>
    <p>Trace4</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation8</p>
    <p>o All metadata operations converted to</p>
    <p>read/write  create, remove, etc, converted to writes</p>
    <p>stat, readdir, etc, converted to reads</p>
    <p>o Virtual machines block controller</p>
    <p>dictates I/O requests to NFS client  NFS client must satisfy block requests</p>
    <p>immediately without buffering  Philosophy is to leverage VM OS cache</p>
    <p>For example, VMWares proprietary NFSv3</p>
    <p>client has the following properties</p>
    <p>Synchronous</p>
    <p>All writes direct to disk (stable flag turned on)</p>
    <p>No readahead</p>
    <p>No write behind</p>
    <p># stat /foo/bar</p>
    <p>sys_stat(/foo/bar)</p>
    <p>NFS_GETATTR(foobar_fh)</p>
    <p>Non-VM case VM case</p>
    <p># stat /foo/bar</p>
    <p>sys_stat(/foo/bar)</p>
    <p>NFS_READ(dskimg_fh) NFS_WRITE(dskimg_fh)</p>
    <p>Update attributes</p>
    <p>List directories</p>
    <p>Creation/deletion</p>
    <p>Lookup</p>
    <p>Access permissions</p>
    <p>Link/Symlink/Rename</p>
    <p>Point 1: Block on File</p>
    <p>Example</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation9</p>
    <p>File Create (100K files)</p>
    <p>o With single directory  VM-NFS</p>
    <p>reads 21.5MB and writes 21MB (209 bytes per dir)</p>
    <p>98% of reads and 52% of writes are sequential</p>
    <p>NFS cause GPFS to receive ~500K getattr calls (in addition to the 100K creates)</p>
    <p>Read and Write Sizes at GPFS</p>
    <p>with a single directory</p>
    <p>File Create Performance Dir width - # files in a directory</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation10</p>
    <p>File Stat (100K files)</p>
    <p>GPFS Seek Distance</p>
    <p>o Collocation of inodes in disk image reduces seek distance  Randomness of read requests decreases with number of directories</p>
    <p>o With single directory  VM-NFS reads 26.3MB (8622 ops/sec) (276 bytes/op)</p>
    <p>NFS caused GPFS to receive ~610K lookup/getattr calls (2656 ops/sec)</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation11</p>
    <p>Applications</p>
    <p>Virtual File System</p>
    <p>On-Disk File System</p>
    <p>Block Layer</p>
    <p>Controller Driver</p>
    <p>Controller Emulator</p>
    <p>NFS Client</p>
    <p>V M</p>
    <p>G u</p>
    <p>e s t</p>
    <p>NETWORK</p>
    <p>H o</p>
    <p>s t</p>
    <p>NFS Server</p>
    <p>Virtual File System</p>
    <p>On-Disk File System</p>
    <p>Block Layer</p>
    <p>Controller Driver</p>
    <p>N A</p>
    <p>S Point 2: I/O Size Transformation</p>
    <p>4KB</p>
    <p>128KB</p>
    <p>&lt;4KB</p>
    <p>4KB</p>
    <p>READ</p>
    <p>256KB</p>
    <p>4KB</p>
    <p>WRITE</p>
    <p>4KB &lt;4KB</p>
    <p>Writes in VM &lt; 4K Guest initiates</p>
    <p>read-modify-write</p>
    <p>No readahead</p>
    <p>performed</p>
    <p>(rsize) (wsize)</p>
    <p>(fs block size) (fs block size)</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation12</p>
    <p>Sequential Write</p>
    <p>o Data Transfer  VM-NFS 2KB</p>
    <p>Read-modify-write from NFS client AND server file system</p>
    <p>VM-NFS and NFS experience read-modify-write on server</p>
    <p>o Performance  VM-NFS suffers from stable writes, client-side read-modify-write</p>
    <p>NV-RAM or SSDs would help</p>
    <p>Sequential Write Data Transfer Sequential Write Performance</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation13</p>
    <p>Random 2KB Reads (2GB from a 4GB file)</p>
    <p>o Machine has 500MB RAM</p>
    <p>o GPFS uses 256KB block size, 50MB cache</p>
    <p>VM-NFS NFS</p>
    <p>MB/s 0.6MB/s 2.5MB/s</p>
    <p>app reads 2048M 2048M</p>
    <p>file reads 4710M 1140M</p>
    <p>block reads 6758M 5853M</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation14</p>
    <p>Future Work: NFS Has Potential!</p>
    <p>o Current performance degradation artifact of current implementations  Each software layer acting independently</p>
    <p>Every write need not necessarily be stable</p>
    <p>Need alignment across the layers</p>
    <p>Single client Linux NFS supports POSIX semantics  In some cases, NFS is more strict</p>
    <p>E.g., POSIX supports unstable file creates</p>
    <p>o Think of different ways of accessing disk images</p>
    <p>Performance (MB/s)</p>
    <p>VM-NFS 36.3</p>
    <p>Linux-NFS 98.3</p>
    <p>Guest-NFS 66.2</p>
    <p>Comparing performance of 3</p>
    <p>different ways of using NFS</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation15</p>
    <p>Other Ongoing Work</p>
    <p>o NFSv4.2 turning into the VM protocol  Cloning</p>
    <p>Server-side copy</p>
    <p>Hole punch</p>
    <p>Space reservations</p>
    <p>Sparse reads  http://www.ietf.org/id/draft-hildebrand-nfsv4-read-sparse-02.txt</p>
    <p>I/O hints  http://www.ietf.org/id/draft-hildebrand-nfsv4-fadvise-01.txt</p>
    <p>o pNFS</p>
    <p>o Study of workload transformations  Real workloads (DB, webserver)</p>
    <p>Effect of fragmentation, etc</p>
    <p>o Improved benchmarks and workload models</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation16</p>
    <p>Summary</p>
    <p>o Block on file makes NFS do unnatural things  Stable writes</p>
    <p>Client-side read-modify-write</p>
    <p>Small reads in the guest can double the amount of data read at the NAS level.</p>
    <p>o Server file systems need to adapt to new workloads  SpecSFS and creates/second are a thing of the past</p>
    <p>Sequential I/O in guest highly likely to be transformed to random I/O</p>
    <p>NAS workload changes from many smaller files to a small number of considerably larger files</p>
    <p>o Need to rethink how we use NFS to access disk images  Depending on your server file system, using Guest NFS client may be preferable</p>
    <p>Existing NAS-based applications may scrap disk images altogether</p>
  </div>
  <div class="page">
    <p>2011 IBM Corporation17</p>
    <p>Thank You</p>
    <p>Questions?</p>
  </div>
</Presentation>
