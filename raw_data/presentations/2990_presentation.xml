<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Network Requirements for Resource Disaggregation</p>
    <p>Peter Gao (Berkeley), Akshay Narayan (MIT), Sagar Karandikar (Berkeley), Joao Carreira (Berkeley), Sangjin Han (Berkeley),</p>
    <p>Rachit Agarwal (Cornell), Sylvia Ratnasamy (Berkeley), Scott Shenker (Berkeley/ICSI)</p>
  </div>
  <div class="page">
    <p>Current Datacenter: Server-Centric Future datacenter: Disaggregated?</p>
    <p>Disaggregated Datacenters</p>
    <p>GPU GPUGPUGPU</p>
    <p>Datacenter Network</p>
    <p>Datacenter Network</p>
    <p>HP  The Machine Intel - RSD Facebook</p>
    <p>Huawei - NUWA SeaMicro Berkeley - FireBox 2</p>
  </div>
  <div class="page">
    <p>Disaggregation Benefits (Architecture Community)</p>
    <p>Overcome memory capacity wall Higher resource density</p>
    <p>Simplify Hardware</p>
    <p>Design</p>
    <p>Relax Power &amp; Capacity</p>
    <p>Scaling</p>
  </div>
  <div class="page">
    <p>Network is the key</p>
    <p>Network</p>
    <p>GPU</p>
    <p>Network</p>
    <p>GPUGPU</p>
    <p>QPI, SMI, PCI-e</p>
    <p>Existing prototypes use specialized hardware, such as Silicon Photonics, PCI-e</p>
    <p>Server-Centric Disaggregated</p>
    <p>GPU</p>
    <p>Do we need specialized hardware? e.g.: Silicon photonics, PCI-e</p>
  </div>
  <div class="page">
    <p>What end-to-end latency and bandwidth must the network provide for legacy apps?  Do existing transport protocols meet these requirements?  Do existing OS network stacks meet these requirements?</p>
    <p>Can commodity network hardware meet these requirements?</p>
    <p>Application</p>
    <p>OS</p>
    <p>Transport</p>
    <p>NIC</p>
    <p>Switch</p>
    <p>Remote Resource</p>
    <p>OS</p>
    <p>Transport</p>
    <p>NIC</p>
    <p>OS</p>
    <p>Transport</p>
    <p>NIC</p>
    <p>Switch</p>
    <p>OS</p>
    <p>Transport</p>
    <p>NIC Commodity hardware solutions may be sufficient</p>
    <p>Current OS and network stack are not (Solutions are feasible)</p>
    <p>Worst case performance degradation</p>
  </div>
  <div class="page">
    <p>Assumptions</p>
    <p>CPU</p>
    <p>Memory</p>
    <p>Storage</p>
    <p>Scale</p>
    <p>Datacenter Network</p>
    <p>Limited cache coherence domain  Small amount of local cache (how much?)</p>
    <p>Page-level remote memory access</p>
    <p>Block-level distributed data placement</p>
    <p>Rack-scale?  Datacenter-scale?</p>
    <p>Cache Coherence</p>
  </div>
  <div class="page">
    <p>Methodology: Workload Driven</p>
    <p>10 workloads on 8 applications  ~ 125 GB input data</p>
    <p>5 m3.2xlarge EC2 nodes  Virtual Private Cloud enabled</p>
    <p>Latency and Bandwidth Requirements</p>
    <p>Key-value Store</p>
    <p>SQL</p>
    <p>Streaming</p>
    <p>Wordcount</p>
    <p>Sort</p>
    <p>Pagerank</p>
    <p>Collaborative Filter.</p>
    <p>Spark Hadoop</p>
    <p>Timely Dataflow</p>
    <p>Graphlab</p>
    <p>Memcached HERD</p>
    <p>Spark SQL</p>
    <p>Spark Streaming</p>
    <p>Batch Processing</p>
    <p>Interactive</p>
    <p>Workloads Applications</p>
  </div>
  <div class="page">
    <p>Disaggregated Datacenter Emulator OS</p>
    <p>Memory</p>
    <p>Special Swap Device (Handles Page Fault)</p>
    <p>Local RAM Emulated Remote RAM</p>
    <p>Backed by the machines own memory  Partition the memory into local and remote</p>
    <p>Free to access Via swap device</p>
    <p>Inject latency and bandwidth constraints  Using special swap device  Delay = latency + request size / bandwidth  Akin to a dedicated link between CPU and memory</p>
  </div>
  <div class="page">
    <p>*Note: Delay = latency + request size / bandwidth</p>
    <p>Latency and Bandwidth Requirement</p>
    <p>Gb ps</p>
    <p>bp s</p>
    <p>bp s</p>
    <p>Gb ps</p>
    <p>bp s</p>
    <p>bp s</p>
    <p>Gb ps</p>
    <p>bp s</p>
    <p>bp s</p>
    <p>~3us latency / 40Gbps bandwidth is enough, ignoring queueing delay</p>
  </div>
  <div class="page">
    <p>Understanding Performance Degradation</p>
    <p>Spark Streaming Wordcount</p>
    <p>Memcached YCSB</p>
    <p>Graphlab CF</p>
    <p>Hadoop Sort</p>
    <p>Hadoop Wordcount</p>
    <p>Timely Pagerank</p>
    <p>HERD YCSB</p>
    <p>SparkSQL BDB</p>
    <p>Spark Sort</p>
    <p>Spark Wordcount</p>
    <p>Performance degradation is correlated with application memory bandwidth</p>
  </div>
  <div class="page">
    <p>Application</p>
    <p>OS</p>
    <p>Transport</p>
    <p>NIC</p>
    <p>Switch</p>
    <p>Remote Resource</p>
    <p>OS</p>
    <p>Transport</p>
    <p>NIC</p>
    <p>Application Remote Resource</p>
    <p>3us end-to-end latency  40Gbps dedicated link (no queueing delay)</p>
  </div>
  <div class="page">
    <p>Transport Simulation Setting</p>
    <p>Special Swap Instrumentation</p>
    <p>Network Simulator Flow Trace</p>
    <p>Flow completion time distribution</p>
    <p>Need new transport protocols</p>
  </div>
  <div class="page">
    <p>Application Performance Degradation</p>
    <p>~5% degradation</p>
    <p>~5% degradation</p>
  </div>
  <div class="page">
    <p>Application</p>
    <p>OS</p>
    <p>Transport</p>
    <p>NIC</p>
    <p>Switch</p>
    <p>Remote Resource</p>
    <p>OS</p>
    <p>Transport</p>
    <p>NIC</p>
    <p>3us end-to-end latency  40Gbps dedicated link</p>
    <p>Transport Transport</p>
    <p>Efficient Transport  100Gbps network</p>
  </div>
  <div class="page">
    <p>Is 100Gbps/3us achievable?</p>
  </div>
  <div class="page">
    <p>Feasibility of end-to-end latency within a rack</p>
    <p>Application Remote Resource</p>
    <p>Propagation Transmission Switching Data Copying OS</p>
  </div>
  <div class="page">
    <p>Feasibility of end-to-end latency within a rack</p>
    <p>Application Remote Resource</p>
    <p>Propagation Transmission Switching Data Copying OS</p>
    <p>Application Remote Resource</p>
    <p>Propagation Transmission Switching</p>
    <p>Data Copying OSCut-through Switch</p>
  </div>
  <div class="page">
    <p>Feasibility of end-to-end latency within a rack</p>
    <p>Application Remote Resource</p>
    <p>Propagation Transmission Switching Data Copying OS</p>
    <p>Application Remote Resource</p>
    <p>Data Copying</p>
    <p>Cut-through Switch NIC Integration</p>
    <p>OS</p>
  </div>
  <div class="page">
    <p>Feasibility of end-to-end latency within a rack</p>
    <p>Application Remote Resource</p>
    <p>Propagation Transmission Switching Data Copying OS</p>
    <p>Application Remote Resource</p>
    <p>Cut-through Switch NIC Integration</p>
    <p>OSUse RDMA</p>
    <p>Feasible to meet target across the datacenter?</p>
  </div>
  <div class="page">
    <p>Application</p>
    <p>OS</p>
    <p>Transport</p>
    <p>NIC</p>
    <p>Switch</p>
    <p>Remote Resource</p>
    <p>OS</p>
    <p>Transport</p>
    <p>NIC</p>
    <p>3us end-to-end latency  40Gbps dedicated link</p>
    <p>Efficient Transport (pFabric,SIGCOMM13, pHost,CoNEXT15)</p>
    <p>100Gbps network (Available)</p>
    <p>Kernel bypassing (RDMA common)</p>
    <p>CPU-NIC Integration (Coming soon)  Cut-through switch (Common?)  100Gbps links (Available)</p>
    <p>Application</p>
    <p>OS</p>
    <p>Transport</p>
    <p>NIC</p>
    <p>Switch</p>
    <p>Remote Resource</p>
    <p>OS</p>
    <p>Transport</p>
    <p>NIC</p>
  </div>
  <div class="page">
    <p>Whats next?</p>
    <p>Please refer our paper for evaluations on improving application performance in disaggregated datacenters</p>
    <p>Application Design</p>
    <p>Rethinking OS Stack</p>
    <p>Storage Network</p>
    <p>Stack Failure Models</p>
    <p>Network Fabric Design</p>
  </div>
  <div class="page">
    <p>Thank You!</p>
    <p>Peter X. Gao Akshay Narayan Sagar Karandikar Joao Carreira Sangjin Han</p>
    <p>Sylvia Ratnasamy Scott ShenkerRachit Agarwal</p>
  </div>
  <div class="page"/>
</Presentation>
