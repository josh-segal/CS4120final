<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Cache-Oblivious Simulation of Parallel Programs</p>
    <p>Andrea Pietracaprina Geppino Pucci Francesco Silvestri</p>
    <p>Bertinoro, February 17-18th 2006</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 1/ 19</p>
  </div>
  <div class="page">
    <p>Outline of the talk</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 2/ 19</p>
  </div>
  <div class="page">
    <p>Architectural trends</p>
    <p>Modern parallel archictectures:</p>
    <p>Network hierarchies: communication costs depend on the processors involved; Memory hierarchies: access costs depend on the level of memory involved.</p>
    <p>Examples:</p>
    <p>IBM BlueGene/L;</p>
    <p>IBM SP5.</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 3/ 19</p>
  </div>
  <div class="page">
    <p>Locality</p>
    <p>Temporal locality of reference: the same data are frequently reused within a short time interval;</p>
    <p>Spatial locality of reference: data stored at consecutive addresses are involved in consecutive operations;</p>
    <p>Submachine locality: communications are confined within small submachines featuring high bandwidth and small latency.</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 4/ 19</p>
  </div>
  <div class="page">
    <p>Objective</p>
    <p>Study the relation between submachine locality (SL) in network hierarchies and locality of reference (LR) in memory hierarchies.</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 5/ 19</p>
  </div>
  <div class="page">
    <p>Previous work</p>
    <p>Vishkin 94, 02: Flat Parallelism PRAM  Cache prefetching strategies;</p>
    <p>Dehne et al. 97, 99: Bulk Parallelism (BSP, CGM)  Efficient External Memory (EM) algorithms;</p>
    <p>FPP 0205 Structured parallelism (D-BSP)  Efficient HMM and BT algorithms.</p>
    <p>Remarks</p>
    <p>Works based on flat parallelism (PRAM, BSP) cant be extended to memory hierarchies with more than two levels.</p>
    <p>EM, HMM, BT models have explicit control over the hierarchy.</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 6/ 19</p>
  </div>
  <div class="page">
    <p>Our results</p>
    <p>Parallel model: Decomposable Bulk Syncronous Parallel Model (D-BSP) [De la Torre, Kruskal, 96];</p>
    <p>Rewards Submachine Locality.</p>
    <p>Sequential model: Ideal Cache Model (ICM) [Frigo et al., 99];</p>
    <p>Rewards Temporal Locality; Rewards Spatial Locality; Cache is hardware controlled.</p>
    <p>Results</p>
    <p>Automatic and cache oblivious simulation of D-BSP algorithms on ICM;</p>
    <p>Efficient ICM (cache oblivious) algorithms obtained from efficient D-BSP algorithms.</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 7/ 19</p>
  </div>
  <div class="page">
    <p>Ideal Cache Model</p>
    <p>Only two levels of memory: cache, RAM memory;</p>
    <p>Parameters:</p>
    <p>Z : cache size;</p>
    <p>L: cache line size;</p>
    <p>Cache features:</p>
    <p>Fully associative;</p>
    <p>Optimal offline strategy for cache line replacement;</p>
    <p>Tall cache hypotesis Z = (L2).</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 8/ 19</p>
  </div>
  <div class="page">
    <p>Ideal Cache Model (Contd)</p>
    <p>An algorithm is characterized by:</p>
    <p>Work complexity W (N, Z , L): number of CPU operations; Cache complexity Q(N, Z , L): number of cache miss.</p>
    <p>Definition</p>
    <p>An algorithm is cache oblivious if its specification is independent of the two parameters Z and L. An algorithm is cache aware otherwise.</p>
    <p>Large literature on cache-oblivious algorithms.</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 9/ 19</p>
  </div>
  <div class="page">
    <p>D-BSP</p>
    <p>N processor-RAM memory pairs.</p>
    <p>Recursive decomposition into i-clusters of N/2i processor-RAM memory pairs, 0  i &lt; log N.</p>
    <p>i-clusters work independent in i-supersteps.</p>
    <p>Parameters of D-BSP: gi : inverse measure of i-cluster bandwidth; usually gi  gi+1. h: upper bound to number of messages sent/received by a processor. : upper bound to the local memory used by a processor during the execution of a D-BSP program.</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 10/ 19</p>
  </div>
  <div class="page">
    <p>Simulation</p>
    <p>How can an i-superstep for an i-cluster C be simulated?</p>
    <p>Execution of C s local contexts:</p>
    <p>if i = log N: the unique context of C is simulated; If i &lt; log N: the contexts of the two i + 1-clusters of C are recursively simulated.</p>
    <p>Communications between C s processors:</p>
    <p>the contexts of C are partitioned into constant size elements; each element is tagged with a suitable key; the elements are sorted by a (cache-oblivious) algorithm.</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 11/ 19</p>
  </div>
  <div class="page">
    <p>Simulation (Contd)</p>
    <p>Remarks</p>
    <p>[FPP 0205]: explicit movements of data through the hierarchy.</p>
    <p>This work: indirect movement of data through the hierarchy regulates by order of accesses to clusters/contexts.</p>
    <p>Which cluster will be simulated in next round?</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 12/ 19</p>
  </div>
  <div class="page">
    <p>Next round</p>
    <p>Let C be the i-cluster that has been just simulated and j be the next superstep index to be executed by processors in C ;</p>
    <p>If i  j, simulate the first j-subcluster of C ;</p>
    <p>C</p>
    <p>C0 C1 C2 C3</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 13/ 19</p>
  </div>
  <div class="page">
    <p>Next round (Contd)</p>
    <p>If i &gt; j and C is the last i-subcluster contained in the j-cluster C , then simulate C ,</p>
    <p>C</p>
    <p>otherwise simulate the next sibling of C .</p>
    <p>C</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 14/ 19</p>
  </div>
  <div class="page">
    <p>Complexity</p>
    <p>Theorem</p>
    <p>Consider a D-BSP program, with contexts of size  and aggregate time for local computations  . Let ki be the number of i-supersteps, 0  i &lt; log N. The work and cache complexities of the simulation are:</p>
    <p>W (N, Z , L) = O</p>
    <p>(</p>
    <p>+ N</p>
    <p>log N1</p>
    <p>i=0</p>
    <p>ki log N</p>
    <p>)</p>
    <p>,</p>
    <p>Q(N, Z , L) = O</p>
    <p>( 1</p>
    <p>i=0</p>
    <p>ki log</p>
    <p>N</p>
    <p>log Z</p>
    <p>)</p>
    <p>.</p>
    <p>for a suitable .</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 15/ 19</p>
  </div>
  <div class="page">
    <p>Complexity (Contd)</p>
    <p>: index of the largest cluster whose contexts fit in cache.</p>
    <p>All misses due to simulation of i-clusters with i   are negligible!</p>
    <p>Applications:</p>
    <p>Matrix Multiplication:</p>
    <p>W (N, Z , L) = O(N3/2)</p>
    <p>Q(N, Z , L) = O (</p>
    <p>N 3/2</p>
    <p>L</p>
    <p>Z</p>
    <p>)  OPTIMAL</p>
    <p>DFT: W (N, Z , L) = O(N log N log log N)</p>
    <p>Q(N; Z , L) = O (</p>
    <p>N log N log log Z</p>
    <p>N</p>
    <p>L log Z</p>
    <p>)  QUASI-OPTIMAL</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 16/ 19</p>
  </div>
  <div class="page">
    <p>Discussion</p>
    <p>The simulation is cache oblivious.</p>
    <p>The simulation automatically gives efficient cache oblivious algorithms from D-BSP ones.</p>
    <p>The complexities remain asymptotically unchanged under LRU.</p>
    <p>Extends to multilevel hierarchies [Frigo et al., 99].</p>
    <p>The double logarithmic slowdown for DFT is due to the generality of the simulation algorithm (arbitrary communication patterns).</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 17/ 19</p>
  </div>
  <div class="page">
    <p>Discussion (Contd)</p>
    <p>Better approaches can be employed with regular communication patterns (ad-hoc simulations:).</p>
    <p>Optimal cache-oblivious ad-hoc DFT algorithm.</p>
    <p>Complexity implication: ICM optimality of the simulated algorithm implies optimality of the D-BSP source algorithm.</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 18/ 19</p>
  </div>
  <div class="page">
    <p>Questions?</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 19/ 19</p>
  </div>
  <div class="page">
    <p>Questions?</p>
    <p>Thank you!!!</p>
    <p>University of Padova Bertinoro, February 17-18th 2006 19/ 19</p>
  </div>
</Presentation>
