<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Mohammad Shahrad, Rodrigo Fonseca, igo Goiri, Gohar Chaudhry, Paul Batum, Jason Cooke, Eduardo Laureano,</p>
    <p>Colby Tresness, Mark Russinovich, and Ricardo Bianchini</p>
    <p>Serverless in the Wild: Characterizing and Optimizing the Serverless Workload</p>
    <p>at a Large Cloud Provider</p>
    <p>July 15, 2020</p>
  </div>
  <div class="page">
    <p>What is Serverless? Very attractive abstraction:  Pay for Use  Infinite elasticity from 0 (and back)  No worry about servers  Provisioning, Reserving, Configuring, patching, managing</p>
    <p>Most popular offering: Function-as-a-Service (FaaS)  Bounded-time functions with no persistent state among invocations  Upload code, get an endpoint, and go</p>
    <p>For the rest of this talk, Serverless = Serverless FaaS</p>
  </div>
  <div class="page">
    <p>What is Serverless?</p>
    <p>Bare Metal VMs (IaaS) Containers Functions (FaaS)</p>
    <p>Unit of Scale Server VM Application/Pod Function</p>
    <p>Provisioning Ops DevOps DevOps Cloud Provider</p>
    <p>Init Time Days ~1 min Few seconds Few seconds</p>
    <p>Scaling Buy new hardware Allocate new VMs 1 to many, auto 0 to many, auto</p>
    <p>Typical Lifetime Years Hours Minutes O(100ms)</p>
    <p>Payment Per allocation Per allocation Per allocation Per use</p>
    <p>State Anywhere Anywhere Anywhere Elsewhere</p>
  </div>
  <div class="page">
    <p>Serverless more than 20 percent of global enterprises will have deployed serverless computing</p>
    <p>technologies by 2020. Gartner, Dec 2018</p>
  </div>
  <div class="page">
    <p>Serverless</p>
    <p>So ur</p>
    <p>ce : C</p>
    <p>N C</p>
    <p>F C</p>
    <p>lo ud</p>
    <p>N at</p>
    <p>iv e</p>
    <p>In te</p>
    <p>ra ct</p>
    <p>iv e</p>
    <p>La nd</p>
    <p>sc ap</p>
    <p>e ht</p>
    <p>tp s:</p>
    <p>// la</p>
    <p>nd sc</p>
    <p>ap e.</p>
    <p>cn cf</p>
    <p>.io /fo</p>
    <p>rm at</p>
    <p>=s er</p>
    <p>ve rle</p>
    <p>ss</p>
  </div>
  <div class="page">
    <p>Serverless</p>
    <p>we predict that () serverless computing will grow to dominate the future of cloud computing.</p>
    <p>Decem ber 20</p>
  </div>
  <div class="page">
    <p>So what are people doing with FaaS?</p>
    <p>Many simple things  ETL workloads  IoT data collection / processing  Stateless processing  Image / Video transcoding  Translation  Check processing</p>
    <p>Serving APIs, Mobile/Web Backends</p>
    <p>Interesting Explorations  MapReduce (pywren)  Linear Algebra (numpywren)  ExCamera  gg burst-parallel functions apps  ML training</p>
    <p>Limitations  Communication  Latency  Locality (lack)  State management</p>
  </div>
  <div class="page">
    <p>What is Serverless? Very attractive abstraction:  Pay for Use  Infinite elasticity from 0 (and back)  No worry about servers  Provisioning, Reserving, Configuring, patching, managing</p>
  </div>
  <div class="page">
    <p>If you are a cloud provider</p>
    <p>A big challenge  You do worry about servers!  Provisioning, scaling, allocating, securing, isolating</p>
    <p>Illusion of infinite scalability  Optimize resource use  Fierce competition</p>
    <p>A bigger opportunity  Fine grained resource packing  Great space for innovating, and capturing new applications, new markets</p>
  </div>
  <div class="page">
    <p>Cold Starts</p>
    <p>Typically range between 0.2 to a few seconds1,2</p>
    <p>OpenWhisk</p>
    <p>Azure Functions</p>
    <p>AWS Lambda</p>
  </div>
  <div class="page">
    <p>Cold Starts and Resource Wastage</p>
    <p>Cold Starts</p>
    <p>Wasted Memory</p>
    <p>Keeping functions in memory indefinitely.</p>
    <p>Removing function instance from memory after invocation.</p>
    <p>?</p>
  </div>
  <div class="page">
    <p>Stepping Back: Characterizing the Workload</p>
    <p>How are functions accessed  What resources do they use  How long do functions take</p>
    <p>First characterization of the workload of a large serverless provider</p>
    <p>Subset of the traces available for research: https://github.com/Azure/AzurePublicDataset</p>
  </div>
  <div class="page">
    <p>Invocations per Application*</p>
    <p>This graph is from a representative subset of the workload. See paper for details.</p>
  </div>
  <div class="page">
    <p>Invocations per Application</p>
    <p>This graph is from a representative subset of the workload. See paper for details.</p>
  </div>
  <div class="page">
    <p>Invocations per Application</p>
    <p>This graph is from a representative subset of the workload. See paper for details.</p>
  </div>
  <div class="page">
    <p>Invocations per Application</p>
    <p>This graph is from a representative subset of the workload. See paper for details.</p>
  </div>
  <div class="page">
    <p>Invocations per Application</p>
    <p>This graph is from a representative subset of the workload. See paper for details.</p>
  </div>
  <div class="page">
    <p>Invocations per Application</p>
    <p>This graph is from a representative subset of the workload. See paper for details.</p>
  </div>
  <div class="page">
    <p>Invocations per Application 18% &gt;1/min</p>
    <p>This graph is from a representative subset of the workload. See paper for details.</p>
  </div>
  <div class="page">
    <p>Apps are highly heterogeneous</p>
  </div>
  <div class="page">
    <p>What about memory? If we wanted to keep all apps warm</p>
    <p>C um</p>
    <p>ul at</p>
    <p>iv e</p>
    <p>Fr ac</p>
    <p>tio n</p>
    <p>of T</p>
    <p>ot al</p>
    <p>M em</p>
    <p>or y</p>
    <p>Allocated Memory Physical Memory</p>
  </div>
  <div class="page">
    <p>What about memory? If we wanted to keep all apps warm</p>
    <p>C um</p>
    <p>ul at</p>
    <p>iv e</p>
    <p>Fr ac</p>
    <p>tio n</p>
    <p>of T</p>
    <p>ot al</p>
    <p>M em</p>
    <p>or y</p>
    <p>Allocated Memory Physical Memory</p>
  </div>
  <div class="page">
    <p>Function Execution Duration</p>
    <p>C D</p>
    <p>F</p>
    <p>Minimum Average Maximum LogNormal Fit</p>
    <p>Executions are short  50% of apps on average run for &lt;= 0.67s  75% of apps on run for &lt;= 10s max</p>
    <p>Times at the same scale as cold start times1,2 1https://levelup.gitconnected.com/1946d32a0244 2https://mikhail.io/serverless/coldstarts/big3/</p>
  </div>
  <div class="page">
    <p>Key Takeaways</p>
    <p>Highly concentrated accesses  82% of the apps are accessed &lt;1/min on average  Correspond to 0.4% of all accesses  But in aggregate would take 40% of the service memory if kept warm</p>
    <p>Arrival processes are highly variable  Execution times are short  Same OOM as cold start times</p>
  </div>
  <div class="page">
    <p>Cold Starts and Resource Wastage</p>
    <p>Cold Starts</p>
    <p>Wasted Memory</p>
    <p>Keeping functions in memory indefinitely.</p>
    <p>Removing function instance from memory after invocation.</p>
    <p>?</p>
    <p>C um</p>
    <p>ul at</p>
    <p>ive F</p>
    <p>ra ct</p>
    <p>io n</p>
    <p>of T</p>
    <p>ot al</p>
    <p>M em</p>
    <p>or y</p>
    <p>Allocated Memory Physical Memory</p>
    <p>C um</p>
    <p>ul at</p>
    <p>ive F</p>
    <p>ra ct</p>
    <p>io n</p>
    <p>of T</p>
    <p>ot al</p>
    <p>M em</p>
    <p>or y</p>
    <p>Allocated Memory Physical Memory</p>
    <p>C D</p>
    <p>F</p>
    <p>Minimum Average Maximum LogNormal Fit</p>
    <p>C D</p>
    <p>F</p>
    <p>Minimum Average Maximum LogNormal Fit</p>
  </div>
  <div class="page">
    <p>What do serverless providers do?</p>
    <p>Mikhail Shilkov, Cold Starts in Serverless Functions, https://mikhail.io/serverless/coldstarts/</p>
    <p>Amazon Lambda</p>
    <p>Fixed 10-minute keep-alive.</p>
    <p>C ol</p>
    <p>d st</p>
    <p>ar t p</p>
    <p>ro ba</p>
    <p>bi lit</p>
    <p>y</p>
    <p>Time since last invocation (mins)</p>
    <p>Azure Functions</p>
    <p>Time since last invocation (mins)</p>
    <p>C ol</p>
    <p>d st</p>
    <p>ar t p</p>
    <p>ro ba</p>
    <p>bi lit</p>
    <p>y Fixed 20-minute</p>
    <p>keep-alive.</p>
  </div>
  <div class="page">
    <p>Fixed Keep-Alive Policy Results from simulation of the entire workload for a week.</p>
    <p>Longer keep-alive</p>
  </div>
  <div class="page">
    <p>Time</p>
    <p>Cold Start</p>
    <p>Fixed Keep-Alive Wont Fit All</p>
    <p>Warm Start</p>
    <p>Time</p>
    <p>Keep-alive</p>
  </div>
  <div class="page">
    <p>Fixed Keep-Alive Is Wasteful</p>
    <p>Function image kept in memory but not used.</p>
    <p>Time</p>
    <p>Cold Start</p>
    <p>Warm Start</p>
    <p>Keep-alive</p>
  </div>
  <div class="page">
    <p>Hybrid Histogram Policy</p>
    <p>Adapt to each application</p>
    <p>Pre-warm in addition to keep-alive</p>
    <p>Lightweight implementation</p>
  </div>
  <div class="page">
    <p>A Histogram Policy To Learn Idle Times</p>
    <p>Time</p>
    <p>Idle Time (IT)</p>
    <p>Fr eq</p>
    <p>ue nc</p>
    <p>y</p>
    <p>Cold Start</p>
    <p>Warm Start</p>
    <p>Keep-alive</p>
  </div>
  <div class="page">
    <p>Idle Time (IT)</p>
    <p>Fr eq</p>
    <p>ue nc</p>
    <p>y</p>
    <p>Pre-warm Keep-alive</p>
    <p>A Histogram Policy To Learn Idle Times</p>
  </div>
  <div class="page">
    <p>A Histogram Policy To Learn Idle Times</p>
    <p>Fr eq</p>
    <p>ue nc</p>
    <p>y</p>
    <p>Idle Time (IT)</p>
    <p>Pre-warm Keep-alive</p>
    <p>pe rc</p>
    <p>en til</p>
    <p>e</p>
    <p>pe rc</p>
    <p>en til</p>
    <p>e</p>
    <p>Minute-long bins Limited number of bins (e.g., 240 bins for 4-hours) 32</p>
  </div>
  <div class="page">
    <p>The Hybrid Histogram Policy</p>
    <p>Fr eq</p>
    <p>ue nc</p>
    <p>y</p>
    <p>Idle Time (IT)</p>
    <p>Pre-warm Keep-alive</p>
    <p>pe rc</p>
    <p>en til</p>
    <p>e</p>
    <p>pe rc</p>
    <p>en til</p>
    <p>e</p>
    <p>Out of Bound (OOB)</p>
    <p>We can afford to run complex predictors given the low arrival rate.</p>
    <p>A histogram might be too wasteful. Time Series Forecast</p>
  </div>
  <div class="page">
    <p>Time-series forecast (ARIMA)</p>
    <p>Use IT distribution (histogram)</p>
    <p>Be conservative (standard keep-alive)</p>
    <p>Too many OOB ITs</p>
    <p>No</p>
    <p>Yes</p>
    <p>Pattern Significant</p>
    <p>New invocation</p>
    <p>The Hybrid Histogram Policy</p>
    <p>Yes</p>
    <p>No</p>
    <p>Update apps IT</p>
    <p>distribution</p>
    <p>ARIMA: Autoregressive Integrated Moving Average 34</p>
  </div>
  <div class="page">
    <p>More Optimal Pareto Frontier</p>
  </div>
  <div class="page">
    <p>Implemented in OpenWhisk</p>
    <p>REST Interface</p>
    <p>Controller</p>
    <p>Load Balancer</p>
    <p>Distributed Messaging</p>
    <p>Invoker</p>
    <p>Distributed Database</p>
    <p>ContainerContainerContainer ContainerContainerContainer</p>
    <p>ContainerContainerContainer</p>
    <p>Invoker Invoker</p>
    <p>Open-sourced industry-grade (IBM Cloud Functions)  Functions run in docker containers  Uses 10-minute fixed keep-alive</p>
    <p>Built a distributed setup with 19 VMs 36</p>
  </div>
  <div class="page">
    <p>C D</p>
    <p>)</p>
    <p>Hybrid )ixHd (10-min)</p>
    <p>Simulation Experimental4-Hour Hybrid Histogram</p>
    <p>Latency overhead: &lt; 1ms (835.7s)</p>
    <p>Container memory reduction: 15.6%Average exec time reduction: 32.5%</p>
  </div>
  <div class="page">
    <p>Closing the loop</p>
    <p>First serverless characterization from a providers point of view</p>
    <p>Azure Functions traces available to download:</p>
    <p>https://github.com/Azure/AzurePublicDataset/blob/master/ AzureFunctionsDataset2019.md</p>
    <p>A dynamic policy to manage serverless workloads more efficiently ( First elements now running in production. )</p>
  </div>
</Presentation>
