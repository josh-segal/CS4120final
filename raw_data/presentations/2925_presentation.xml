<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Online Graph Planarisation for</p>
    <p>Synchronous Parsing of Semantic and</p>
    <p>Syntactic Dependencies</p>
    <p>Ivan Titov University of Illinois at Urbana-Champaign</p>
    <p>James Henderson, Paola Merlo, Gabriele Musillo University of Geneva</p>
  </div>
  <div class="page">
    <p>Motivation / Problem Statement</p>
    <p>NLP applications will require a shallow representation of</p>
    <p>meaning</p>
    <p>Often shallow semantic structures can be regarded as labeled</p>
    <p>directed graphs</p>
    <p>Can we apply methods for syntactic dependency parsing</p>
    <p>to predict these trees?</p>
    <p>Sequa makes and repairs enginesjet AGENT</p>
    <p>AGENT PATIENT</p>
    <p>PATIENT</p>
    <p>Semantic</p>
    <p>structure</p>
  </div>
  <div class="page">
    <p>Motivation / Problem Statement</p>
    <p>NLP applications will require a shallow representation of</p>
    <p>meaning</p>
    <p>Often shallow semantic structures can be regarded as labeled</p>
    <p>directed graphs</p>
    <p>Sequa makes and repairs enginesjet</p>
    <p>SBJ COORD CONJ</p>
    <p>OBJ</p>
    <p>NMOD Syntactic</p>
    <p>structure</p>
    <p>AGENT</p>
    <p>AGENT PATIENT</p>
    <p>PATIENT</p>
    <p>Semantic</p>
    <p>structure</p>
    <p>Not necessary a tree.</p>
    <p>(only 22% are trees in</p>
    <p>CoNLL-08 dataset)</p>
    <p>Tree structured</p>
    <p>Many crossing arcs</p>
    <p>(non-planarity)</p>
    <p>Often little or no</p>
    <p>crossing links</p>
  </div>
  <div class="page">
    <p>Motivation / Problem Statement</p>
    <p>NLP applications will require a shallow representation of</p>
    <p>meaning</p>
    <p>Often shallow semantic structures can be regarded as labeled</p>
    <p>directed graphs</p>
    <p>Sequa makes and repairs enginesjet</p>
    <p>SBJ COORD CONJ</p>
    <p>OBJ</p>
    <p>NMOD Syntactic</p>
    <p>structure</p>
    <p>AGENT</p>
    <p>AGENT PATIENT</p>
    <p>PATIENT</p>
    <p>Semantic</p>
    <p>structure</p>
    <p>Not necessary a tree.</p>
    <p>(only 22% are trees in</p>
    <p>CoNLL-08 dataset)</p>
    <p>Tree structured</p>
    <p>Many crossing arcs</p>
    <p>(non-planarity)</p>
    <p>Often little or no</p>
    <p>crossing links</p>
    <p>- How can we deal with more general graphs</p>
    <p>representing semantic structures?</p>
    <p>- How can we construct an effective semantic parser</p>
    <p>on the basis of an existing syntactic parser?</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation / Problem Statement</p>
    <p>Background</p>
    <p>Dependency parsing</p>
    <p>Properties of dependency graphs</p>
    <p>Non-Planar Parsing using Swapping</p>
    <p>Synchronous Parsing of Semantic and Syntactic Dependencies</p>
    <p>Synchronization</p>
    <p>Statistical Model</p>
    <p>Experiments</p>
    <p>Conclusions and Future Directions</p>
  </div>
  <div class="page">
    <p>Dependency Parsing Problem</p>
    <p>Parsing: given sentence predict structure :</p>
    <p>Graph-based methods: assume that features factorize over subgraphs</p>
    <p>of (e.g., edges) [Eisner, 96; McDonald et al., 05]</p>
    <p>Transition-based methods [Yamada and Matsumoto, 03; Nivre et al., 04]:</p>
    <p>Define derivation order for structures, i.e. mapping from to</p>
    <p>sequences of decisions</p>
    <p>Learn to score individual decision given preceding decisions:</p>
    <p>Decode greedily:</p>
    <p>Model estimated on a labeled</p>
    <p>dataset (treebank)</p>
    <p>Beam-search can be used</p>
    <p>instead of greedy decoding</p>
    <p>That will be the main focus</p>
    <p>of the talk</p>
  </div>
  <div class="page">
    <p>Properties of Semantic Structures</p>
    <p>Semantic structures are not trees</p>
    <p>Graph-based (GB) methods based on maximum spanning tree</p>
    <p>algorithms are not directly applicable</p>
    <p>Semantic structures are not planar</p>
    <p>Definition: planar graphs can be drawn in the semi-plane above the</p>
    <p>sentence without any two arcs crossing and without changing the</p>
    <p>order of words</p>
  </div>
  <div class="page">
    <p>Properties of Semantic Structures</p>
    <p>Semantic structures are not trees</p>
    <p>Graph-based (GB) methods based on maximum spanning tree</p>
    <p>algorithms are not directly applicable</p>
    <p>Semantic structures are not planar</p>
    <p>Definition: planar graphs can be drawn in the semi-plane above the</p>
    <p>sentence without any two arcs crossing and without changing the</p>
    <p>order of words</p>
    <p>Most transition-based (TB) algorithms handle only planar graphs</p>
    <p>Related work:</p>
    <p>[Attardi, 06]: TB method with extended derivation order to handle non-planarity</p>
    <p>[Nivre, 08]: Assumes that a structure can be made planar by changing order of</p>
    <p>words (not true for general non-tree graphs)</p>
    <p>...</p>
  </div>
  <div class="page">
    <p>Properties of Semantic Structures</p>
    <p>Semantic structures are not trees</p>
    <p>Graph-based (GB) methods based on maximum spanning tree</p>
    <p>algorithms are not directly applicable</p>
    <p>Semantic structures are not planar</p>
    <p>Definition: planar graphs can be drawn in the semi-plane above the</p>
    <p>sentence without any two arcs crossing and without changing the</p>
    <p>order of words</p>
    <p>Most transition-based (TB) algorithms handle only planar graphs</p>
    <p>Related work:</p>
    <p>[Attardi, 06]: TB method with extended derivation order to handle non-planarity</p>
    <p>[Nivre, 08]: Assumes that a structure can be made planar by changing order of</p>
    <p>words (not true for general non-tree graphs)</p>
    <p>...</p>
    <p>We will propose a very simple</p>
    <p>technique to extend standard TB</p>
    <p>methods to handle non-planar and</p>
    <p>not-tree structured graphs</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation / Problem Statement</p>
    <p>Background</p>
    <p>Dependency parsing</p>
    <p>Properties of dependency graphs</p>
    <p>Non-Planar Parsing using Swapping</p>
    <p>Synchronous Parsing of Semantic and Syntactic Dependencies</p>
    <p>Synchronization</p>
    <p>Statistical Model</p>
    <p>Experiments</p>
    <p>Conclusions and Future Directions</p>
  </div>
  <div class="page">
    <p>Derivation order [Nivre, 04]</p>
    <p>State of the parser after steps is characterized by:</p>
    <p>current stack S (wj  word on top of the stack)</p>
    <p>a queue I of remaining input words (wk  next input word)</p>
    <p>partial dependency structure defined by</p>
    <p>New decision di can be</p>
    <p>LeftArcr - adds a labeled dependency arc</p>
    <p>RightArcr - adds a labeled dependency arc</p>
    <p>Shift - moves wk from queue to the stack</p>
    <p>Reduce - remove wj from the stack</p>
    <p>Terminates when the queue is empty</p>
  </div>
  <div class="page">
    <p>Handling non-planar structures</p>
    <p>[Nivre, 04] order cannot handle non-planar structures:</p>
    <p>All the arcs are created between top of the stack and front of queue</p>
    <p>Words are stored in the stack in the same order as they appear in</p>
    <p>the sentence</p>
    <p>A single new decision:</p>
    <p>Swap - swaps 2 top words in the stack</p>
    <p>Stack before: Stack after:</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>Sequa makes and repairs enginesjet AGENT</p>
    <p>AGENT PATIENT</p>
    <p>PATIENT</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>Sequa makes and repairs enginesjet</p>
    <p>S = [ ]</p>
    <p>Partial Structure:</p>
    <p>I = [ Sequa makes and .... ]</p>
    <p>Next action: Shift</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>Sequa makes and repairs enginesjet</p>
    <p>S = [ Sequa ]</p>
    <p>Partial Structure:</p>
    <p>I = [ makes and repairs .... ]</p>
    <p>Next action: LeftArcAGENT</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>Sequa makes and repairs enginesjet AGENT</p>
    <p>S = [ Sequa ]</p>
    <p>Partial Structure:</p>
    <p>I = [ makes and repairs .... ]</p>
    <p>Next action: Shift</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>Sequa makes and repairs enginesjet AGENT</p>
    <p>S = [ Sequa makes ]</p>
    <p>Partial Structure:</p>
    <p>I = [ and repairs jet engines ]</p>
    <p>Next action: Shift</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>Sequa makes and repairs enginesjet AGENT</p>
    <p>S = [ Sequa makes and ]</p>
    <p>Partial Structure:</p>
    <p>I = [ repairs jet engines ]</p>
    <p>Next action: Reduce</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>Sequa makes and repairs enginesjet AGENT</p>
    <p>S = [ Sequa makes ]</p>
    <p>Partial Structure:</p>
    <p>I = [ repairs jet engines ]</p>
    <p>Next action: Swap Stalled if without swap:</p>
    <p>- repairs needs an arc to Sequa</p>
    <p>- but makes cannot be removed from stack</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>Sequa makes and repairs enginesjet AGENT</p>
    <p>S = [ makes Sequa ]</p>
    <p>Partial Structure:</p>
    <p>I = [ repairs jet engines ]</p>
    <p>Next action: LeftArcAGENT</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>Sequa makes and repairs enginesjet AGENT</p>
    <p>AGENT</p>
    <p>S = [ makes Sequa ]</p>
    <p>Partial Structure:</p>
    <p>I = [ repairs jet engines ]</p>
    <p>Next action: Reduce</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>Sequa makes and repairs enginesjet AGENT</p>
    <p>AGENT</p>
    <p>S = [ makes ]</p>
    <p>Partial Structure:</p>
    <p>I = [ repairs jet engines ]</p>
    <p>Next action: Shift</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>Sequa makes and repairs enginesjet AGENT</p>
    <p>AGENT</p>
    <p>S = [ makes repairs ]</p>
    <p>Partial Structure:</p>
    <p>I = [ jet engines ]</p>
    <p>Next action: Shift</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>Sequa makes and repairs enginesjet AGENT</p>
    <p>AGENT</p>
    <p>S = [ makes repairs jet ]</p>
    <p>Partial Structure:</p>
    <p>I = [ engines ]</p>
    <p>Next action: Reduce</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>Sequa makes and repairs enginesjet AGENT</p>
    <p>AGENT</p>
    <p>S = [ makes repairs ]</p>
    <p>Partial Structure:</p>
    <p>I = [ engines ]</p>
    <p>Next action: RightArcPATIENT</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>Sequa makes and repairs enginesjet AGENT</p>
    <p>AGENT PATIENT</p>
    <p>S = [ makes repairs ]</p>
    <p>Partial Structure:</p>
    <p>I = [ engines ]</p>
    <p>Next action: Reduce</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>Sequa makes and repairs enginesjet AGENT</p>
    <p>AGENT PATIENT</p>
    <p>S = [ makes ]</p>
    <p>Partial Structure:</p>
    <p>I = [ engines ]</p>
    <p>Next action: RightArcPATIENT</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>Sequa makes and repairs enginesjet AGENT</p>
    <p>AGENT PATIENT</p>
    <p>PATIENT</p>
    <p>S = [ makes ]</p>
    <p>Partial Structure:</p>
    <p>I = [ engines ]</p>
    <p>Next action: Shift</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>Sequa makes and repairs enginesjet AGENT</p>
    <p>AGENT PATIENT</p>
    <p>PATIENT</p>
    <p>S = [ makes engines ]</p>
    <p>Partial Structure:</p>
    <p>I = [ ]</p>
    <p>Next action: Stop</p>
  </div>
  <div class="page">
    <p>Canonical orders</p>
    <p>The algorithm allows the same structure to be parsed multiple ways</p>
    <p>Summing over all the possible derivation when parsing is not feasible</p>
    <p>Instead, models are trained to produce derivations in a canonical way</p>
    <p>In other words, canonical orders define how derivations should be</p>
    <p>produced for the training set</p>
    <p>We consider two canonical derivations which differ in when</p>
    <p>swapping is done</p>
    <p>last-resort: Swap is used as a last resort when no other operation is</p>
    <p>possible</p>
    <p>exhaustive: Swap is used pre-emptively</p>
  </div>
  <div class="page">
    <p>Last-Resort ordering</p>
    <p>Swap is used as a last resort when no operation is possible</p>
    <p>Drawback: not all the structures parsable with swapping have a lastresort derivation</p>
    <p>in CoNLL-2008 dataset 2.8% fewer structures are parsable with last-resort ordering</p>
    <p>An example of such a structure:</p>
    <p>Advantage: this canonical derivation is predictable and, therefore, supposedly easier to learn</p>
    <p>Suddenly CDC and DEC productshave</p>
  </div>
  <div class="page">
    <p>Exhaustive ordering</p>
    <p>Algorithm for preemptive swapping:</p>
    <p>Ordering follows standard planar parser ordering until no other</p>
    <p>operation except Shift and Swap are possible</p>
    <p>Compute the ordered list of positions of words in the queue to</p>
    <p>which current top of the stack wj will be connected</p>
    <p>Compute a similar list for word wm under the top of the stack</p>
    <p>Swap if wms list precedes wjs list in their lexicographical order</p>
    <p>Suddenly1 CDC2 and3 DEC4 products6have5</p>
    <p>S = [ Suddenly CDC ]  I = [ DEC .... ]</p>
    <p>List for Suddenly: {5} SwapList for CDC: {5, 6}</p>
  </div>
  <div class="page">
    <p>Exhaustive ordering</p>
    <p>Algorithm for preemptive swapping:</p>
    <p>Ordering follows standard planar parser ordering until no other</p>
    <p>operation except Shift and Swap are possible</p>
    <p>Compute the ordered list of positions of words in the queue to</p>
    <p>which current top of the stack wj will be connected</p>
    <p>Compute a similar list for word wm under the top of the stack</p>
    <p>Swap if wms list precedes wjs list in their lexicographical order</p>
    <p>Theorem If the graph is parsable with the defined set of</p>
    <p>operations then the exhaustive ordering is guaranteed to find a</p>
    <p>derivation</p>
    <p>See the paper for the proof sketch</p>
  </div>
  <div class="page">
    <p>Structures Parsable with Swapping</p>
    <p>Not all the non-planar graphs are parsable</p>
    <p>In CoNLL-2008 ST dataset only 1% of semantic structures are not</p>
    <p>parsable whereas 44% are not planar (i.e., require swapping)</p>
    <p>Among common linguistic structures requiring Swap are</p>
    <p>coordinations</p>
    <p>E.g., Sequa makes, repairs and sells engines</p>
    <p>A frequent example of an unparsable structure:</p>
    <p>Funds also might buy sell and</p>
  </div>
  <div class="page">
    <p>Structures Parsable with Swapping</p>
    <p>Any structures with isolated pairs of crossing arcs are parsable but they are more powerful than that</p>
    <p>Theorem A graph cannot be parsed with the defined set of parsing operations iff the graph contains at least one of the subgraphs presented below:</p>
    <p>the unspecified arc end points can be anywhere strictly following those specified</p>
    <p>circled pairs of endpoints can be either a single word or two distinct words</p>
    <p>See the paper for the proof sketch</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation / Problem Statement</p>
    <p>Background</p>
    <p>Dependency parsing</p>
    <p>Properties of dependency graphs</p>
    <p>Non-Planar Parsing using Swapping</p>
    <p>Synchronous Parsing of Semantic and Syntactic Dependencies</p>
    <p>Synchronization</p>
    <p>Statistical Model</p>
    <p>Experiments</p>
    <p>Conclusions and Future Directions</p>
  </div>
  <div class="page">
    <p>Synchronization [Henderson et al., 2008]</p>
    <p>We define two separate derivations: one for semantics, one for</p>
    <p>syntax</p>
    <p>Instead of using pipelines we synchronize these two derivations</p>
    <p>joint learning and joint inference</p>
  </div>
  <div class="page">
    <p>Synchronization</p>
    <p>Example:</p>
    <p>Sequa makes and repairs enginesjet</p>
    <p>Syntactic</p>
    <p>structure</p>
    <p>Semantic</p>
    <p>structure</p>
  </div>
  <div class="page">
    <p>Synchronization</p>
    <p>Example:</p>
    <p>Sequa makes and repairs enginesjet</p>
    <p>SBJ Syntactic</p>
    <p>structure</p>
    <p>Semantic</p>
    <p>structure</p>
  </div>
  <div class="page">
    <p>Synchronization</p>
    <p>Example:</p>
    <p>Sequa makes and repairs enginesjet</p>
    <p>SBJ Syntactic</p>
    <p>structure</p>
    <p>AGENT</p>
    <p>Semantic</p>
    <p>structure</p>
  </div>
  <div class="page">
    <p>Synchronization</p>
    <p>Example:</p>
    <p>Sequa makes and repairs enginesjet</p>
    <p>SBJ COORD Syntactic</p>
    <p>structure</p>
    <p>AGENT</p>
    <p>Semantic</p>
    <p>structure</p>
  </div>
  <div class="page">
    <p>Synchronization</p>
    <p>Example:</p>
    <p>Sequa makes and repairs enginesjet</p>
    <p>SBJ COORD Syntactic</p>
    <p>structure</p>
    <p>AGENT</p>
    <p>Semantic</p>
    <p>structure</p>
  </div>
  <div class="page">
    <p>Synchronization</p>
    <p>Example:</p>
    <p>Sequa makes and repairs enginesjet</p>
    <p>SBJ COORD CONJ Syntactic</p>
    <p>structure</p>
    <p>AGENT</p>
    <p>Semantic</p>
    <p>structure</p>
  </div>
  <div class="page">
    <p>Synchronization</p>
    <p>Example:</p>
    <p>Sequa makes and repairs enginesjet</p>
    <p>SBJ COORD CONJ Syntactic</p>
    <p>structure</p>
    <p>AGENT</p>
    <p>AGENT Semantic</p>
    <p>structure</p>
  </div>
  <div class="page">
    <p>Synchronization</p>
    <p>Example:</p>
    <p>Sequa makes and repairs enginesjet</p>
    <p>SBJ COORD CONJ Syntactic</p>
    <p>structure</p>
    <p>AGENT</p>
    <p>AGENT Semantic</p>
    <p>structure</p>
  </div>
  <div class="page">
    <p>Synchronization</p>
    <p>Example:</p>
    <p>Sequa makes and repairs enginesjet</p>
    <p>SBJ COORD CONJ Syntactic</p>
    <p>structure</p>
    <p>AGENT</p>
    <p>AGENT Semantic</p>
    <p>structure</p>
  </div>
  <div class="page">
    <p>Synchronization</p>
    <p>Example:</p>
    <p>Sequa makes and repairs enginesjet</p>
    <p>SBJ COORD CONJ</p>
    <p>SBJ</p>
    <p>NMOD Syntactic</p>
    <p>structure</p>
    <p>AGENT</p>
    <p>AGENT Semantic</p>
    <p>structure</p>
  </div>
  <div class="page">
    <p>Synchronization</p>
    <p>Example:</p>
    <p>Sequa makes and repairs enginesjet</p>
    <p>SBJ COORD CONJ</p>
    <p>SBJ</p>
    <p>NMOD Syntactic</p>
    <p>structure</p>
    <p>AGENT</p>
    <p>AGENT PATIENT</p>
    <p>PATIENT</p>
    <p>Semantic</p>
    <p>structure</p>
  </div>
  <div class="page">
    <p>Statistical Model</p>
    <p>Following [Henderson, et al. ,08], the synchronous derivations are</p>
    <p>modeled with Incremental Sigmoid Belief Networks (ISBNs) [Titov and Henderson, 07]</p>
    <p>previously successfully applied to constituent and dependency syntactic</p>
    <p>parsing</p>
    <p>Vectors of latent variables are associated with each parsing</p>
    <p>decision</p>
    <p>Each vector is connected with previous vectors by a pattern of</p>
    <p>interconnections determined by the previous decisions</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation / Problem Statement</p>
    <p>Background</p>
    <p>Dependency parsing</p>
    <p>Properties of dependency graphs</p>
    <p>Non-Planar Parsing using Swapping</p>
    <p>Synchronous Parsing of Semantic and Syntactic Dependencies</p>
    <p>Synchronization</p>
    <p>Statistical Model</p>
    <p>Experiments</p>
    <p>Conclusions and Future Directions</p>
  </div>
  <div class="page">
    <p>Empirical Evaluation</p>
    <p>CoNLL-2008 Shared Task data [Surdeanu et al., 08], merged</p>
    <p>dependency transformation of Penn Treebank WSJ (syntax)</p>
    <p>dependency representation of Propbank and Nombank (semantics)</p>
    <p>Data: 39,279/1,334/2,824 sentences for training/development/testing</p>
    <p>Systems</p>
    <p>Our models</p>
    <p>exhaustive order</p>
    <p>last-resort order</p>
    <p>planar order (can only process projective parts of derivations)</p>
    <p>[Henderson et al., 08] planarisation: a modification of [Nivre and Nilsson, 05]</p>
    <p>method for semantic graphs (HEAD)</p>
    <p>Crossing links are removed and encoded in labels of remaining arcs</p>
    <p>Model structure and estimation methods are kept constant</p>
  </div>
  <div class="page">
    <p>Results on Development Set</p>
    <p>Technique CoNLL Measures Crossing Paris (Sem)</p>
    <p>Syn LAS Sem F1 Aver F1 P R F1</p>
    <p>Last resort 86.6 76.2 81.5 61.5 25.6 36.1</p>
    <p>Exhaustive 86.8 76.0 81.4 59.7 23.5 33.8</p>
    <p>HEAD 86.7 73.3 80.1 78.6 2.2 4.2</p>
    <p>Planar 85.9 72.8 79.4 undef 0 undef</p>
  </div>
  <div class="page">
    <p>Results on Development Set</p>
    <p>Technique CoNLL Measures Crossing Paris (Sem)</p>
    <p>Syn LAS Sem F1 Aver F1 P R F1</p>
    <p>Last resort 86.6 76.2 81.5 61.5 25.6 36.1</p>
    <p>Exhaustive 86.8 76.0 81.4 59.7 23.5 33.8</p>
    <p>HEAD 86.7 73.3 80.1 78.6 2.2 4.2</p>
    <p>Planar 85.9 72.8 79.4 undef 0 undef</p>
  </div>
  <div class="page">
    <p>Results on Development Set</p>
    <p>Technique CoNLL Measures Crossing Pairs (Sem)</p>
    <p>Syn LAS Sem F1 Aver F1 P R F1</p>
    <p>Last resort 86.6 76.2 81.5 61.5 25.6 36.1</p>
    <p>Exhaustive 86.8 76.0 81.4 59.7 23.5 33.8</p>
    <p>HEAD 86.7 73.3 80.1 78.6 2.2 4.2</p>
    <p>Planar 85.9 72.8 79.4 undef 0 undef</p>
  </div>
  <div class="page">
    <p>Results on Development Set</p>
    <p>Technique CoNLL Measures Crossing Pairs (Sem)</p>
    <p>Syn LAS Sem F1 Aver F1 P R F1</p>
    <p>Last resort 86.6 76.2 81.5 61.5 25.6 36.1</p>
    <p>Exhaustive 86.8 76.0 81.4 59.7 23.5 33.8</p>
    <p>HEAD 86.7 73.3 80.1 78.6 2.2 4.2</p>
    <p>Planar 85.9 72.8 79.4 undef 0 undef</p>
    <p>The model is generative and, therefore, decisions</p>
    <p>are not conditioned on future words  a likely</p>
    <p>reason why no improvement from using exhaustive</p>
    <p>strategy</p>
  </div>
  <div class="page">
    <p>Test Set Results</p>
    <p>Model CoNLL Measures Crossing Pairs (Sem)</p>
    <p>Syn LAS Sem F1 Aver F1 P R F1</p>
    <p>Johanssen 89.3 81.6 85.5 67.0 44.5 53.5</p>
    <p>Ciaramita 87.4 78.0 82.7 59.9 34.2 43.5</p>
    <p>Che 86.7 78.5 82.7 56.9 32.4 41.3</p>
    <p>Zhao 87.7 76.7 82.2 58.5 36.1 44.6</p>
    <p>This paper 87.5 76.1 81.8 62.1 29.4 39.9</p>
    <p>Henderson+ 87.6 73.1 80.5 72.6 1.7 3.3</p>
    <p>Lluis 85.8 70.3 78.1 53.8 19.2 28.3</p>
    <p>3% improvement over the baseline on semantics graphs</p>
    <p>However, does not outperform reranking or ensemble techniques</p>
  </div>
  <div class="page">
    <p>Test Set Results</p>
    <p>Model CoNLL Measures Crossing Pairs (Sem)</p>
    <p>Syn LAS Sem F1 Aver F1 P R F1</p>
    <p>Johanssen 89.3 81.6 85.5 67.0 44.5 53.5</p>
    <p>Ciaramita 87.4 78.0 82.7 59.9 34.2 43.5</p>
    <p>Che 86.7 78.5 82.7 56.9 32.4 41.3</p>
    <p>Zhao 87.7 76.7 82.2 58.5 36.1 44.6</p>
    <p>This paper 87.5 76.1 81.8 62.1 29.4 39.9</p>
    <p>Henderson+ 87.6 73.1 80.5 72.6 1.7 3.3</p>
    <p>Lluis 85.8 70.3 78.1 53.8 19.2 28.3</p>
    <p>Recent results: 3rd result in CoNLL-2009 Shared task (7 languages)</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Proposed a simple modification to handle semantic graphs with transitionbased parsers</p>
    <p>though not powerful enough to process all the semantic graphs it is able to handle vast majority</p>
    <p>proposed and analyzed two algorithms for canonical derivation induction</p>
    <p>theoretically characterized the class of parsable structures</p>
    <p>Showed improvements over previous methods</p>
    <p>Demonstrated state-of-the-art results without ensemble techniques or pipelines</p>
    <p>Future directions: applying this approach to parsing of language with highly non-planar syntactic structures</p>
  </div>
</Presentation>
