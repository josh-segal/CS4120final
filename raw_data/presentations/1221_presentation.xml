<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Reexamining Direct Cache Access to Optimize I/O Intensive Applications for Multi- hundred- gigabit Networks</p>
    <p>Alireza Farshin*, Amir Roozbeh*+, Gerald Q. Maguire Jr.*, Dejan Kosti * KTH Royal Institute of Technology, School of Electrical Engineering and Computer Science (EECS)</p>
    <p>+ Ericsson Research</p>
  </div>
  <div class="page">
    <p>Traditional I/O</p>
    <p>I/O Device</p>
    <p>* Direct Memory Access (DMA)</p>
  </div>
  <div class="page">
    <p>Traditional I/O</p>
    <p>I/O Device</p>
    <p>Inefficient:  Large number of accesses to main</p>
    <p>memory  High access latency (&gt;60ns)  Unnecessary memory bandwidth usage</p>
    <p>* Direct Memory Access (DMA)</p>
  </div>
  <div class="page">
    <p>Direct Cache Access (DCA)</p>
    <p>I/O Device</p>
    <p>* PCIe Transaction protocol Processing Hint (TPH)</p>
  </div>
  <div class="page">
    <p>Direct Cache Access (DCA)</p>
    <p>I/O Device</p>
    <p>* PCIe Transaction protocol Processing Hint (TPH)</p>
    <p>Still inefficient in terms of memory bandwidth usage  Requires OS intervention and support from processor</p>
  </div>
  <div class="page">
    <p>Intel Data Direct I/O (DDIO)</p>
    <p>I/O Device</p>
    <p>DDIO in Xeon processors since Xeon E5</p>
    <p>DMA packets or descriptors directly to/from Last Level Cache (LLC)</p>
  </div>
  <div class="page">
    <p>Trends</p>
    <p>More in-network computing + offloading capabilities</p>
    <p>Push costly calculations into the network and perform stateful functions at the processor, which makes applications more I/O intensive.</p>
  </div>
  <div class="page">
    <p>Pressure from these trends</p>
    <p>Multi-hundred-gigabit networks cannot tolerate memory</p>
    <p>access and interarrival time of packets continues to shrink</p>
    <p>Every 6.72 ns a new (64-B+20-B*) packet arrives at 100 Gbps</p>
    <p>* 7B preamble + 1B start-of-frame delimiter +12B inter-frame gap = 20B</p>
    <p>More in-network computing + offloading capabilities</p>
    <p>Faster link speeds</p>
  </div>
  <div class="page">
    <p>DCA matters because</p>
    <p>Without DCA we are unable to process I/O at line rate, thus increasing packet loss or latency when utilizing multi-hundred-gigabit networks.</p>
  </div>
  <div class="page">
    <p>Forwarding Packets at 100 Gbps</p>
    <p>Packet Generator</p>
    <p>Device under Test Forwarding Packets</p>
    <p>Intel Xeon Gold 6140</p>
    <p>Mellanox ConnectX-5</p>
    <p>Each NIC is placed in a PCIe 3.0 16x slot*</p>
    <p>P er</p>
    <p>ce n</p>
    <p>ti le</p>
    <p>L at</p>
    <p>en cy</p>
    <p>( s)</p>
    <p>Rate</p>
    <p>* A PCIe 3.0 16x slot is capable of providing ~125 Gbps effective full-duplex bandwidth.</p>
  </div>
  <div class="page">
    <p>What happens at 200 Gbps?</p>
    <p>Packet Generator</p>
    <p>Device under Test Forwarding Packets</p>
    <p>Intel Xeon Gold 6140</p>
    <p>Mellanox ConnectX-5</p>
    <p>Each NIC is placed in a PCIe 3.0 16x slot*</p>
    <p>P er</p>
    <p>ce n</p>
    <p>ti le</p>
    <p>L at</p>
    <p>en cy</p>
    <p>(</p>
    <p>s)</p>
    <p>Latency of the first NIC, when forwarding at indicated aggregate rate</p>
    <p>When forwarding at 200 Gbps, 30% higher</p>
    <p>latency for the NIC forwarding at 100 Gbps</p>
    <p>* A PCIe 3.0 16x slot is capable of providing ~125 Gbps effective full-duplex bandwidth.</p>
  </div>
  <div class="page">
    <p>How does DDIO work?</p>
    <p>Writing packets/descriptors: C C C C</p>
    <p>C C C C</p>
    <p>C C C C</p>
    <p>Logical LLC</p>
    <p>CPU Socket</p>
    <p>DDIO overwrites a cache line if it is already present in any LLC ways ( write update or hit)</p>
    <p>Sending/Receiving Packets via DDIO</p>
    <p>Write to the Same cache line</p>
    <p>Already Present In LLC</p>
  </div>
  <div class="page">
    <p>How does DDIO work?</p>
    <p>Writing packets/descriptors: C C C C</p>
    <p>C C C C</p>
    <p>C C C C</p>
    <p>Logical LLC</p>
    <p>CPU Socket</p>
    <p>DDIO overwrites a cache line if it is already present in any LLC ways ( write update or hit)</p>
    <p>Sending/Receiving Packets via DDIO</p>
    <p>Otherwise, DDIO allocates a cache line in a limited portion of LLC ( write allocate or miss)</p>
    <p>Not Present In LLC</p>
    <p>Allocate a cache</p>
    <p>line</p>
  </div>
  <div class="page">
    <p>How does DDIO work?</p>
    <p>Writing packets/descriptors: C C C C</p>
    <p>C C C C</p>
    <p>C C C C</p>
    <p>Logical LLC</p>
    <p>CPU Socket</p>
    <p>DDIO overwrites a cache line if it is already present in any LLC ways ( write update or hit)</p>
    <p>Sending/Receiving Packets via DDIO</p>
    <p>Otherwise, DDIO allocates a cache line in a limited portion of LLC ( write allocate or miss)</p>
    <p>Reading packets/descriptors: NIC reads a cache line if it is already present in any LLC ways ( read hit)</p>
    <p>Otherwise, NIC reads it from main memory ( read miss)</p>
  </div>
  <div class="page">
    <p>How does DDIO work?</p>
    <p>C C C C</p>
    <p>C C C C</p>
    <p>C C C C</p>
    <p>Logical LLC</p>
    <p>CPU Socket</p>
    <p>Sending/Receiving Packets via DDIO</p>
    <p>Designed a set of micro-benchmarks to learn about DDIO:</p>
    <p>Which ways are used for allocation?  How does DDIO interact with other</p>
    <p>applications?  Does DMA via a remote CPU socket</p>
    <p>pollute LLC?</p>
  </div>
  <div class="page">
    <p>LLC ways used by DDIO</p>
    <p>Logical LLC</p>
    <p>C0</p>
    <p>Sending/Receiving Packets via DDIO</p>
    <p>I/O Application</p>
    <p>* Cache Allocation Technology</p>
    <p>Use CAT* to limit code/data</p>
  </div>
  <div class="page">
    <p>LLC ways used by DDIO</p>
    <p>Logical LLC</p>
    <p>C0</p>
    <p>Sending/Receiving Packets via DDIO</p>
    <p>C1</p>
    <p>I/O Application</p>
    <p>Cache-sensitive Application+</p>
    <p>Use CAT* to limit code/data</p>
    <p>* Cache Allocation Technology</p>
    <p>+ water_nsquared from Splash-3 benchmark</p>
  </div>
  <div class="page">
    <p>LLC ways used by DDIO</p>
    <p>Logical LLC</p>
    <p>C0</p>
    <p>Sending/Receiving Packets via DDIO</p>
    <p>C1</p>
    <p>I/O Application</p>
    <p>Cache-sensitive Application+</p>
    <p>* Cache Allocation Technology</p>
    <p>Su m</p>
    <p>o f C</p>
    <p>ac h</p>
    <p>e M</p>
    <p>is se</p>
    <p>s (M</p>
    <p>il li</p>
    <p>on )</p>
    <p>Ways Alloca ted by CAT to the Cache-sensitive Application1 2 3 4 5 6 7 8 9 10 11</p>
    <p>Use CAT* to limit code/data</p>
    <p>+ water_nsquared from Splash-3 benchmark</p>
  </div>
  <div class="page">
    <p>LLC ways used by DDIO</p>
    <p>Logical LLC</p>
    <p>C0</p>
    <p>Sending/Receiving Packets via DDIO</p>
    <p>C1</p>
    <p>I/O Application</p>
    <p>Cache-sensitive Application+</p>
    <p>* Cache Allocation Technology</p>
    <p>Su m</p>
    <p>o f C</p>
    <p>ac h</p>
    <p>e M</p>
    <p>is se</p>
    <p>s (M</p>
    <p>il li</p>
    <p>on )</p>
    <p>Ways Alloca ted by CAT to the Cache-sensitive Application1 2 3 4 5 6 7 8 9 10 11</p>
    <p>Use CAT* to limit code/data</p>
    <p>+ water_nsquared from Splash-3 benchmark</p>
  </div>
  <div class="page">
    <p>LLC ways used by DDIO</p>
    <p>Logical LLC</p>
    <p>C0</p>
    <p>Sending/Receiving Packets via DDIO</p>
    <p>C1</p>
    <p>I/O Application</p>
    <p>Cache-sensitive Application+</p>
    <p>* Cache Allocation Technology</p>
    <p>Su m</p>
    <p>o f C</p>
    <p>ac h</p>
    <p>e M</p>
    <p>is se</p>
    <p>s (M</p>
    <p>il li</p>
    <p>on )</p>
    <p>Ways Alloca ted by CAT to the Cache-sensitive Application1 2 3 4 5 6 7 8 9 10 11</p>
    <p>Use CAT* to limit code/data</p>
    <p>+ water_nsquared from Splash-3 benchmark</p>
  </div>
  <div class="page">
    <p>LLC ways used by DDIO</p>
    <p>Logical LLC</p>
    <p>C0</p>
    <p>Sending/Receiving Packets via DDIO</p>
    <p>C1</p>
    <p>I/O Application</p>
    <p>Cache-sensitive Application+</p>
    <p>* Cache Allocation Technology</p>
    <p>Su m</p>
    <p>o f C</p>
    <p>ac h</p>
    <p>e M</p>
    <p>is se</p>
    <p>s (M</p>
    <p>il li</p>
    <p>on )</p>
    <p>Ways Alloca ted by CAT to the Cache-sensitive Application1 2 3 4 5 6 7 8 9 10 11</p>
    <p>Use CAT* to limit code/data</p>
    <p>+ water_nsquared from Splash-3 benchmark</p>
  </div>
  <div class="page">
    <p>LLC ways used by DDIO</p>
    <p>Logical LLC</p>
    <p>C0</p>
    <p>Sending/Receiving Packets via DDIO</p>
    <p>C1</p>
    <p>I/O Application</p>
    <p>Cache-sensitive Application+</p>
    <p>* Cache Allocation Technology</p>
    <p>Su m</p>
    <p>o f C</p>
    <p>ac h</p>
    <p>e M</p>
    <p>is se</p>
    <p>s (M</p>
    <p>il li</p>
    <p>on )</p>
    <p>Ways Alloca ted by CAT to the Cache-sensitive Application</p>
    <p>Contention with code/data causes a rise in the cache misses of the I/O application</p>
    <p>Use CAT* to limit code/data</p>
    <p>+ water_nsquared from Splash-3 benchmark</p>
  </div>
  <div class="page">
    <p>LLC ways used by DDIO</p>
    <p>Logical LLC</p>
    <p>C0</p>
    <p>Sending/Receiving Packets via DDIO</p>
    <p>C1</p>
    <p>I/O Application</p>
    <p>Cache-sensitive Application+</p>
    <p>* Cache Allocation Technology</p>
    <p>Su m</p>
    <p>o f C</p>
    <p>ac h</p>
    <p>e M</p>
    <p>is se</p>
    <p>s (M</p>
    <p>il li</p>
    <p>on )</p>
    <p>Ways Alloca ted by CAT to the Cache-sensitive Application1 2 3 4 5 6 7 8 9 10 11</p>
    <p>Use CAT* to limit code/data</p>
    <p>+ water_nsquared from Splash-3 benchmark</p>
  </div>
  <div class="page">
    <p>LLC ways used by DDIO</p>
    <p>Logical LLC</p>
    <p>C0</p>
    <p>Sending/Receiving Packets via DDIO</p>
    <p>C1</p>
    <p>I/O Application</p>
    <p>Cache-sensitive Application+</p>
    <p>* Cache Allocation Technology</p>
    <p>Su m</p>
    <p>o f C</p>
    <p>ac h</p>
    <p>e M</p>
    <p>is se</p>
    <p>s (M</p>
    <p>il li</p>
    <p>on )</p>
    <p>Ways Alloca ted by CAT to the Cache-sensitive Application1 2 3 4 5 6 7 8 9 10 11</p>
    <p>Use CAT* to limit code/data</p>
    <p>+ water_nsquared from Splash-3 benchmark</p>
  </div>
  <div class="page">
    <p>LLC ways used by DDIO</p>
    <p>Logical LLC</p>
    <p>C0</p>
    <p>Sending/Receiving Packets via DDIO</p>
    <p>C1</p>
    <p>I/O Application</p>
    <p>Cache-sensitive Application+</p>
    <p>* Cache Allocation Technology</p>
    <p>Su m</p>
    <p>o f C</p>
    <p>ac h</p>
    <p>e M</p>
    <p>is se</p>
    <p>s (M</p>
    <p>il li</p>
    <p>on )</p>
    <p>Ways Alloca ted by CAT to the Cache-sensitive Application1 2 3 4 5 6 7 8 9 10 11</p>
    <p>Use CAT* to limit code/data</p>
    <p>+ water_nsquared from Splash-3 benchmark</p>
  </div>
  <div class="page">
    <p>LLC ways used by DDIO</p>
    <p>Logical LLC</p>
    <p>C0</p>
    <p>Sending/Receiving Packets via DDIO</p>
    <p>C1</p>
    <p>I/O Application</p>
    <p>Cache-sensitive Application+</p>
    <p>* Cache Allocation Technology</p>
    <p>Su m</p>
    <p>o f C</p>
    <p>ac h</p>
    <p>e M</p>
    <p>is se</p>
    <p>s (M</p>
    <p>il li</p>
    <p>on )</p>
    <p>Ways Alloca ted by CAT to the Cache-sensitive Application1 2 3 4 5 6 7 8 9 10 11</p>
    <p>Use CAT* to limit code/data</p>
    <p>+ water_nsquared from Splash-3 benchmark</p>
  </div>
  <div class="page">
    <p>LLC ways used by DDIO</p>
    <p>Logical LLC</p>
    <p>C0</p>
    <p>Sending/Receiving Packets via DDIO</p>
    <p>C1</p>
    <p>I/O Application</p>
    <p>Cache-sensitive Application+</p>
    <p>* Cache Allocation Technology</p>
    <p>Su m</p>
    <p>o f C</p>
    <p>ac h</p>
    <p>e M</p>
    <p>is se</p>
    <p>s (M</p>
    <p>il li</p>
    <p>on )</p>
    <p>Ways Alloca ted by CAT to the Cache-sensitive Application</p>
    <p>Contention with I/O causes a rise in the cache misses of the I/O application</p>
    <p>Use CAT* to limit code/data</p>
    <p>+ water_nsquared from Splash-3 benchmark</p>
  </div>
  <div class="page">
    <p>LLC ways used by DDIO</p>
    <p>Logical LLC</p>
    <p>C0</p>
    <p>Sending/Receiving Packets via DDIO</p>
    <p>C1</p>
    <p>I/O Application</p>
    <p>Cache-sensitive Application+</p>
    <p>* Cache Allocation Technology</p>
    <p>Su m</p>
    <p>o f C</p>
    <p>ac h</p>
    <p>e M</p>
    <p>is se</p>
    <p>s (M</p>
    <p>il li</p>
    <p>on )</p>
    <p>Ways Alloca ted by CAT to the Cache-sensitive Application</p>
    <p>Contention with I/O causes a rise in the cache misses of the I/O application</p>
    <p>Use CAT* to limit code/data See our paper</p>
    <p>+ water_nsquared from Splash-3 benchmark</p>
    <p>DDIO Ways</p>
  </div>
  <div class="page">
    <p>How does DDIO perform?</p>
    <p>DDIO cannot provide expected benefits!  ResQ* [NSDI18]  Intel reports</p>
    <p>Write-allocate DDIO could evict not-yet-processed and already-processed packets from LLC</p>
    <p>Packet should be read from main memory rather than LLC</p>
    <p>Reduce the number of RX descriptors so that the buffer fit in the limited DDIO portion.</p>
    <p>* ResQ: Enabling SLOs in Network Function Virtualization</p>
  </div>
  <div class="page">
    <p>Reducing #Descriptors is Not Sufficient! (1/2)</p>
    <p>Increasing the number of RX</p>
    <p>descriptors and packet size</p>
    <p>adversely affects the performance</p>
    <p>of DDIO</p>
    <p>DDIO cannot use the whole reserved</p>
    <p>capacity in LLC</p>
    <p>* DDIO uses 2 ways out of 11 ways, i.e., 24.75 MB x 2 / 11 = 4.5 MB</p>
  </div>
  <div class="page">
    <p>Reducing #Descriptors is Not Sufficient! (2/2)</p>
    <p>DDIO should be able to perform well</p>
    <p>with high number of RX descriptors!</p>
    <p>D D</p>
    <p>IO W</p>
    <p>ri te</p>
    <p>H</p>
    <p>it R</p>
    <p>at e</p>
    <p>(% )</p>
    <p>Number of Cores</p>
    <p>Increasing the number of cores does not always improve PCIe metrics for an I/O intensive application.</p>
    <p>Forwarding 1500-B Packets at 100 Gbps with 256 per-core RX descriptors</p>
  </div>
  <div class="page">
    <p>Tuning a little-discussed register can improve the performance of DDIO</p>
    <p>Logical LLC</p>
    <p>IIO LLC WAYS Register</p>
    <p>Default value is 0x600</p>
    <p>Increasing the number of bits set improves DDIO hit rates.</p>
  </div>
  <div class="page">
    <p>DDIOs effect on hit rates can affect application-level performance based on an applications characteristics</p>
    <p>Impact of Tuning DDIO s)</p>
    <p>th P</p>
    <p>er ce</p>
    <p>n ti</p>
    <p>le L</p>
    <p>a te</p>
    <p>n cy</p>
    <p>(</p>
    <p>Number of RX Descriptors</p>
    <p>For example, an I/O intensive application: 2 cores forwarding 1500-B Packets at 100 Gbps</p>
  </div>
  <div class="page">
    <p>DDIOs effect on hit rates can affect application-level performance based on an applications characteristics</p>
    <p>Impact of Tuning DDIO s)</p>
    <p>th P</p>
    <p>er ce</p>
    <p>n ti</p>
    <p>le L</p>
    <p>a te</p>
    <p>n cy</p>
    <p>(</p>
    <p>Number of RX Descriptors</p>
    <p>For example, an I/O intensive application: 2 cores forwarding 1500-B Packets at 100 Gbps</p>
    <p>Setting more bits reduces tail latency</p>
  </div>
  <div class="page">
    <p>Is Tuning DDIO Enough?</p>
    <p>Tuning is not a perfect solution! Due to:  Cache is used for code/data,  Smaller per-core cache quota, and  Coarse-grained partitions.</p>
    <p>Next generation DCA should provide:</p>
    <p>Fine-grained placement: Similar to CacheDirector* [EuroSys19] I/O isolation: Extend CAT+ and CDP++ to include I/O Selective DCA/DMA: only transfer relevant parts of the packet to LLC</p>
    <p>* Make the Most out of Last Level Cache in Intel Processors</p>
    <p>+ Cache Allocation Technology ++ Code/Data Prioritization</p>
  </div>
  <div class="page">
    <p>What about Current Systems?</p>
    <p>DMA should not be directed to the cache if this would cause I/O evictions!</p>
    <p>Disabling DDIO for a specific PCIe port  Exploiting a remote socket</p>
    <p>Bypassing cache is beneficial in multi-tenant/application environment, where some performance isolation is desired.</p>
  </div>
  <div class="page">
    <p>Using Our Knowledge for 200 Gbps</p>
    <p>Device under Test Forwarding Packets</p>
    <p>UPI</p>
    <p>h Pe</p>
    <p>rc en</p>
    <p>ti le</p>
    <p>L at</p>
    <p>en cy</p>
    <p>(</p>
    <p>s) Latency of the first NIC versus aggregate Rate</p>
    <p>Tuning DDIO improves packet processing at 200 Gbps</p>
    <p>Better cache management is necessary for multi-hundred-gigabit-per-second networks</p>
  </div>
  <div class="page">
    <p>Other Insights</p>
    <p>See our paper for more results about:</p>
    <p>How does receiving rate affect the DDIO performance?  How does processing time affect the DDIO performance?  Is DDIO always beneficial?  Scaling up and DDIO.</p>
    <p>We study the performance of DDIO in different scenarios</p>
  </div>
  <div class="page">
    <p>Our Key Findings (1/2)</p>
    <p>If an application is I/O bound, adding excessive cores could degrade its performance.</p>
    <p>If an application is I/O bound, tuning a little-discussed register called IIO LLC WAYS could improve performance and lead to the same improvements as adding more cores.</p>
    <p>If an application starts to become CPU bound, adding more cores could improve its throughput, but it is important to balance load among cores to maximize DDIOs benefits.</p>
    <p>Getting close to ~100 Gbps can cause DDIO to become a bottleneck. Therefore, it is essential to know when to bypass the cache to realize performance isolation.</p>
  </div>
  <div class="page">
    <p>Our Key Findings (2/2)</p>
    <p>If an application is truly CPU/memory bound, tuning DDIO is less efficient.</p>
    <p>We now explain the impact of processing time on the performance DDIO, which resulted in this finding.</p>
  </div>
  <div class="page">
    <p>Impact of Processing Time</p>
    <p>H</p>
    <p>it R</p>
    <p>at e</p>
    <p>D D</p>
    <p>IO M</p>
    <p>et ri</p>
    <p>c</p>
    <p>(% )</p>
    <p>Number of Calls</p>
    <p>Write Read Throughput</p>
    <p>Device under Test</p>
    <p>Input Packet</p>
    <p>Output Packet</p>
    <p>Swapping MAC</p>
    <p>Calling Random Number Generator</p>
    <p>(std::mt1993)</p>
    <p>Increasing processing time improves DDIO performance</p>
    <p>Increasing processing time improves the</p>
    <p>performance of DDIO</p>
  </div>
  <div class="page">
    <p>Write Read Throughput</p>
    <p>Impact of Processing Time</p>
    <p>T hr</p>
    <p>ou gh</p>
    <p>p u</p>
    <p>t (G</p>
    <p>b p</p>
    <p>s)</p>
    <p>Device under Test</p>
    <p>Input Packet</p>
    <p>Output Packet</p>
    <p>Swapping MAC</p>
    <p>Calling Random Number Generator</p>
    <p>(std::mt1993)</p>
    <p>DDIO performance matters most when an application is I/O bound, rather than CPU/memory bound.</p>
    <p>Increasing processing time reduces throughput</p>
    <p>H</p>
    <p>it R</p>
    <p>at e</p>
    <p>D D</p>
    <p>IO M</p>
    <p>et ri</p>
    <p>c (%</p>
    <p>)</p>
  </div>
  <div class="page">
    <p>DCA/DDIO should be tuned for I/O intensive applications.</p>
    <p>DCA/DDIO needs to be rearchitected for multi-hundred-gigabit networks.</p>
    <p>Benchmark your testbed with our source code.</p>
    <p>Conclusion</p>
    <p>https://github.com/aliireza/ddio-bench</p>
    <p>This work is supported by ERC, SSF, and WASP.</p>
  </div>
  <div class="page">
    <p>Thanks for listening Do not hesitate to contact us if you have any questions.</p>
    <p>farshin@kth.se and amirrsk@kth.se</p>
  </div>
</Presentation>
