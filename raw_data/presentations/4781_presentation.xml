<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Hash, Dont Cache: Fast Packet Forwarding for Enterprise Edge Routers</p>
    <p>Minlan Yu Princeton University</p>
    <p>minlanyu@cs.princeton.edu Joint work with Jennifer Rexford</p>
    <p>SIGCOMM WREN09</p>
  </div>
  <div class="page">
    <p>Enterprise Edge Router  Enterprise edge routers</p>
    <p>Connects upstream providers and internal routers</p>
    <p>A few outgoing links  A small data structure for each next hop</p>
    <p>Provider 1 Provider 2</p>
    <p>Enterprise Network</p>
  </div>
  <div class="page">
    <p>Challenges of Packet Forwarding</p>
    <p>Full routes forwarding table (FIB)  For load balancing, fault tolerance, etc.  More than 250K entries, and growing</p>
    <p>Increasing link speed  Over 10 Gbps</p>
    <p>Requires large, expensive memory  Expensive, complicated high-end routers</p>
    <p>More cost-efficient, less power-hungry solution?  Perform fast packet forwarding in a small SRAM</p>
  </div>
  <div class="page">
    <p>Using a Small SRAM</p>
    <p>Route caching is not a viable solution  Store the most frequently used entries in cache  Bad performance during cache miss</p>
    <p>Low throughput and high packet loss</p>
    <p>Bad performance under worst-case workloads  Malicious traffic with a wide range of destinations  Route changes, link failures</p>
    <p>Our solution should be workload independent  Fit the entire FIB in the small SRAM</p>
  </div>
  <div class="page">
    <p>Bloom Filter  Bloom filters in fast memory (SRAM)</p>
    <p>A compact data structure for a set of elements  Calculate s hash functions to store element x  Easy to check membership  Reduce memory at the expense of false positives</p>
    <p>h1(x) h2(x) hs(x) 01000 10100 00010</p>
    <p>x</p>
    <p>V0 Vm-1</p>
    <p>h3(x)</p>
  </div>
  <div class="page">
    <p>Bloom Filter Forwarding  One Bloom filter (BF) per next hop</p>
    <p>Store all addresses forwarded to that next hop</p>
    <p>Consider flat addresses in the talk  See paper for extensions to longest prefix match</p>
    <p>Nexthop 1</p>
    <p>Nexthop 2</p>
    <p>Nexthop T</p>
    <p>Packet destination</p>
    <p>query</p>
    <p>Bloom Filters</p>
    <p>hit</p>
    <p>T is small for enterprise edge routers</p>
  </div>
  <div class="page">
    <p>Contributions</p>
    <p>Make efficient use of limited fast memory  Formulate and solve optimization problem to</p>
    <p>minimize false-positive rate</p>
    <p>Handle false positives  Leverage properties of enterprise edge routers</p>
    <p>Adapt Bloom filters for routing changes  Leverage counting Bloom filter in slow memory  Dynamically adjust Bloom filter size</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Optimize memory usage</p>
    <p>Handle false positives</p>
    <p>Handle routing dynamics</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Optimize memory usage</p>
    <p>Handle false positives</p>
    <p>Handle routing dynamics</p>
  </div>
  <div class="page">
    <p>Memory Usage Optimization  Consider fixed forwarding table  Goal: Minimize overall false-positive rate</p>
    <p>Probability one or more BFs have a false positive</p>
    <p>Input:  Fast memory size M  Number of destinations per next hop  The maximum number of hash functions</p>
    <p>Output: the size of each Bloom filter  Larger BF for next-hops with more destinations</p>
  </div>
  <div class="page">
    <p>Constraints and Solution</p>
    <p>Constraints  Memory constraint</p>
    <p>Sum of all BF sizes fast memory size M</p>
    <p>Bound on number of hash functions  To bound CPU calculation time  Bloom filters share the same hash functions</p>
    <p>Proved to be a convex optimization problem  An optimal solution exists  Solved by IPOPT (Interior Point OPTimizer)</p>
  </div>
  <div class="page">
    <p>The FIB with 200K entries, 10 next hop  8 hash functions  Takes at most 50 msec to solve the optimization</p>
    <p>Evaluation of False Positives</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Optimize memory usage</p>
    <p>Handle false positives</p>
    <p>Handle routing dynamics</p>
  </div>
  <div class="page">
    <p>False Positive Detection</p>
    <p>Multiple matches in the Bloom filters  One of the matches is correct  The others are caused by false positives</p>
    <p>Nexthop 1</p>
    <p>Nexthop 2</p>
    <p>Nexthop T</p>
    <p>Packet destination</p>
    <p>query</p>
    <p>Bloom Filters Multiple hits</p>
  </div>
  <div class="page">
    <p>Handle False Positives on Fast Path</p>
    <p>Leverage multi-homed enterprise edge router  Send to a random matching next hop</p>
    <p>Packets can get to the destination even through a lesspreferred outgoing link occasionally</p>
    <p>No extra traffic, but may cause packet loss</p>
    <p>Send duplicate packets  Send copy of packet to all matching next hops  Guarantees reachability, but introduce extra traffic</p>
  </div>
  <div class="page">
    <p>Prevent Future False Positives  For a packet that experiences a false positive</p>
    <p>Conventional lookup in the background  Cache the result</p>
    <p>For the subsequent packets  No longer experience false positives</p>
    <p>Compared to conventional route cache  Much smaller (only for false-positive destinations)  Not easily invalidated by an adversary</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Optimize memory usage</p>
    <p>Handle false positives</p>
    <p>Handle routing dynamics</p>
  </div>
  <div class="page">
    <p>Problem of Bloom Filters</p>
    <p>Routing changes  Add/delete entries in BFs</p>
    <p>Problem of Bloom Filters (BF)  Do not allow deleting an element</p>
    <p>Counting Bloom Filters (CBF)  Use a counter instead of a bit in the array  CBFs can handle adding/deleting elements  But, require more memory than BFs</p>
  </div>
  <div class="page">
    <p>Update on Routing Change</p>
    <p>Use CBF in slow memory  Assist BF to handle forwarding-table updates  Easy to add/delete a forwarding-table entry</p>
    <p>CBF in slow memory</p>
    <p>BF in fast memory</p>
    <p>Delete a route</p>
  </div>
  <div class="page">
    <p>Occasionally Resize BF  Under significant routing changes</p>
    <p>Number of addresses in BFs changes significantly  Re-optimize BF sizes</p>
    <p>Use CBF to assist resizing BF  Large CBF and small BF  Easy to expand BF size by contracting CBF</p>
    <p>Hard to expand to size 4</p>
    <p>CBF BF</p>
    <p>Easy to contract CBF to size 4</p>
  </div>
  <div class="page">
    <p>BF-based Router Architecture</p>
  </div>
  <div class="page">
    <p>Prototype and Evaluation</p>
    <p>Prototype in kernel-level Click  Experiment environment</p>
    <p>3.0 GHz 64-bit Intel Xeon  2 MB L2 data cache, used as fast memory size M</p>
    <p>Forwarding table  10 next hops, 200K entries</p>
    <p>Peak forwarding rate  365 Kpps for 64 Byte packets  10% faster than conventional lookup</p>
  </div>
  <div class="page">
    <p>Conclusion  Improve packet forwarding for enterprise edge</p>
    <p>routers  Use Bloom filters to represent forwarding table</p>
    <p>Only require a small SRAM  Optimize usage of a fixed small memory</p>
    <p>Multiple ways to handle false positives  Leverage properties of enterprise edge routers</p>
    <p>React quickly to FIB updates  Leverage Counting Bloom Filter in slow memory</p>
  </div>
  <div class="page">
    <p>Ongoing Work: BUFFALO</p>
    <p>Bloom filter forwarding in large enterprise  Deploy BF-based switches in the entire network  Forward all the packets on the fast path</p>
    <p>Gracefully handling false positives  Randomly select a matching next hop  Techniques to avoid loops and bound path stretch</p>
    <p>www.cs.princeton.edu/~minlanyu/writeup/conext09.pdf</p>
  </div>
  <div class="page">
    <p>Thanks</p>
    <p>Questions?</p>
  </div>
</Presentation>
