<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>A Cross-Collection Mixture Model</p>
    <p>for Comparative Text Mining</p>
    <p>ChengXiang Zhai1 Atulya Velivelli2 Bei Yu3</p>
    <p>University of Illinois, Urbana-Champaign</p>
    <p>U.S.A.</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Many applications involve a comparative analysis of several comparable text collections, e.g.,  Given news articles from different sources (about the same</p>
    <p>event), can we extract what is common to all the sources and what is unique to one specific souce?</p>
    <p>Given customer reviews about 3 different brands of laptops, can we extract the common themes (e.g., battery life, speed, warranty) and compare the three brands in terms of each common theme?</p>
    <p>Given web sites about companies selling similar products, can we analyze the strength/weakness of each company?</p>
    <p>Existing work in text mining has conceptually focused on one single collection of text thus is inadequate for comparative text analysis</p>
    <p>We aim at developing methods for comparing multiple collections of text and performing comparative text mining</p>
  </div>
  <div class="page">
    <p>Problem definition:  Given a comparable set of text collections  Discover &amp; analyze their common and unique properties</p>
    <p>Collection C1 Collection C2 .</p>
    <p>C1specific themes</p>
    <p>Common themes</p>
    <p>C2specific themes</p>
    <p>Ckspecific themes</p>
    <p>A pool of text Collections</p>
    <p>Collection Ck</p>
    <p>Comparative Text Mining (CTM)</p>
  </div>
  <div class="page">
    <p>Example: Summarizing Customer Reviews</p>
    <p>Common Themes IBM specific APPLE specific DELL specific</p>
    <p>Battery Life Long, 4-3 hrs Medium, 3-2 hrs Short, 2-1 hrs</p>
    <p>Hard disk Large, 80-100 GB Small, 5-10 GB Medium, 20-50 GB</p>
    <p>Speed Slow, 100-200 Mhz Very Fast, 3-4 Ghz Moderate, 1-2 Ghz</p>
    <p>IBM Laptop Reviews</p>
    <p>APPLE Laptop Reviews</p>
    <p>DELL Laptop Reviews</p>
    <p>Ideal results from comparative text mining</p>
  </div>
  <div class="page">
    <p>A More Realistic Setup of CTM</p>
    <p>Common Themes IBM specific APPLE specific DELL specific</p>
    <p>Battery 0.129</p>
    <p>Hours 0.080</p>
    <p>Life 0.060</p>
    <p>Long 0.120</p>
    <p>Reasonable 0.10</p>
    <p>Medium 0.08</p>
    <p>Short 0.05</p>
    <p>Poor 0.01</p>
    <p>..</p>
    <p>Disk 0.015</p>
    <p>IDE 0.010</p>
    <p>Drive 0.005</p>
    <p>..</p>
    <p>Large 0.100</p>
    <p>Small 0.050</p>
    <p>...</p>
    <p>Medium 0.123</p>
    <p>.</p>
    <p>Pentium 0.113</p>
    <p>Processor 0.050</p>
    <p>Slow 0.114</p>
    <p>Fast 0.151</p>
    <p>Moderate 0.116</p>
    <p>IBM Laptop Reviews APPLE Laptop Reviews DELL Laptop Reviews</p>
    <p>Collection-specific Word Distributions</p>
    <p>Common Word Distr.</p>
  </div>
  <div class="page">
    <p>A Basic Approach: Simple Clustering</p>
    <p>Pool all documents together and perform clustering</p>
    <p>Hopefully, some clusters are reflecting common themes and others specific themes</p>
    <p>However, we cant force a common theme to cover all collections</p>
    <p>Background B</p>
    <p>Theme 1 1</p>
    <p>Theme 3 3</p>
    <p>Theme 2 2</p>
    <p>Theme 4 4</p>
  </div>
  <div class="page">
    <p>Improved Clustering: Cross-Collection Mixture Models</p>
    <p>Explicitly distinguish and model common themes and specific themes</p>
    <p>Fit a mixture model with the text data</p>
    <p>Estimate parameters using EM</p>
    <p>Clusters are more meaningful</p>
    <p>Background B</p>
    <p>Theme 1 in common: 1 Theme 1 Specific</p>
    <p>to C1 1,1</p>
    <p>CmC2C1</p>
    <p>Theme k in common: k Theme k Specific</p>
    <p>to C1 k,1</p>
    <p>Theme 1 Specific</p>
    <p>to C2 1,2</p>
    <p>Theme 1 Specific</p>
    <p>to Cm 1,m</p>
    <p>Theme k Specific</p>
    <p>to C2 k,2</p>
    <p>Theme k Specific</p>
    <p>to Cm k,m</p>
  </div>
  <div class="page">
    <p>Details of the Mixture Model</p>
    <p>C</p>
    <p>B</p>
    <p>1</p>
    <p>1,i 1-C</p>
    <p>Ck</p>
    <p>k,i 1-C</p>
    <p>d,1</p>
    <p>d,k</p>
    <p>B</p>
    <p>Theme 1</p>
    <p>Background</p>
    <p>, 1</p>
    <p>,</p>
    <p>( | ) (1 ) ( | )</p>
    <p>[ ( | )</p>
    <p>(1 ) ( | )]</p>
    <p>d i B B</p>
    <p>k</p>
    <p>B d j C j j</p>
    <p>C j i</p>
    <p>p w C p w</p>
    <p>p w</p>
    <p>p w</p>
    <p>Account for noise (common non-informative words)</p>
    <p>Common Distribution</p>
    <p>Collection-specific Distr.</p>
    <p>Collection-specific Distr.</p>
    <p>Common Distribution</p>
    <p>Theme k Parameters: B=noise-level (manually set) C=Common-Specific tradeoff (manually set) s and s are estimated with Maximum Likelihood</p>
    <p>W</p>
    <p>Generating word w in doc d in collection Ci</p>
  </div>
  <div class="page">
    <p>Experiments</p>
    <p>Two Data Sets  War news (2 collections)</p>
    <p>Iraq war: A combination of 30 articles from CNN and BBC websites</p>
    <p>Afghan war: A combination of 26 articles from CNN and BBC websites</p>
    <p>Laptop customer reviews (3 collections)</p>
    <p>Apple iBook Mac: 34 reviews downloaded from epinions.com</p>
    <p>Dell Inspiron: 22 reviews downloaded from epinions.com</p>
    <p>IBM Thinkpad: 42 reviews downloaded from epinions.com</p>
    <p>On each data set, we compare a simple mixture model with the cross-collection mixture model</p>
  </div>
  <div class="page">
    <p>Comparison of Simple and Cross-Collection Clustering</p>
    <p>Simple</p>
    <p>Cross Collection</p>
    <p>Results from Cross-collection clustering are more meaningful</p>
  </div>
  <div class="page">
    <p>Cross-Collection Clustering Results (Laptop Reviews)</p>
    <p>Top words serve as labels for common themes (e.g., [sound, speakers], [battery, hours], [cd,drive])</p>
    <p>These word distributions can be used to segment text and add hyperlinks between documents</p>
  </div>
  <div class="page">
    <p>Summary and Future Work</p>
    <p>We defined a new text mining problem, referred to as comparative text mining (CTM), which has many applications</p>
    <p>We proposed and evaluated a cross-collection mixture model for CTM</p>
    <p>Experiment results show that the proposed crosscollection model is more effective for CTM than a simple mixture model for CTM</p>
    <p>Future work  Further improve the mixture model and estimation method</p>
    <p>(e.g., consider proximity, MAP estimation)</p>
    <p>Use the model to segment documents and create hyperlinks between segments (e.g., feed the learned word distributions into HMMs for segmentation)</p>
  </div>
</Presentation>
