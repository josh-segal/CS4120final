<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Multi-Level Cache Hierarchy Evaluation for Programmable Media Processors</p>
    <p>Jason Fritts Assistant Professor</p>
    <p>Department of Computer Science Co-Author: Prof. Wayne Wolf</p>
    <p>Overview</p>
    <p>Why Programmable Media Processors?</p>
    <p>Evaluation Environment</p>
    <p>Cache Memory Hierarchy Evaluation  preliminary investigation of memory hierarchy for media processing</p>
    <p>Conclusions</p>
    <p>Future Research</p>
  </div>
  <div class="page">
    <p>Multimedia Applications</p>
    <p>Wide range of applications  Communication</p>
    <p>video conferencing  World Wide Web  digital/video libraries  videophones</p>
    <p>Entertainment  video/computer games  movies  animation</p>
    <p>Computer Vision  image understanding  surveillance  tracking</p>
    <p>Education  interactive learning  virtual classrooms</p>
    <p>Art and Architecture</p>
    <p>Multimedia is primarily a</p>
    <p>communication media</p>
    <p>Multimedia is primarily a</p>
    <p>communication media</p>
    <p>Future of Multimedia</p>
    <p>Multimedia is moving towards</p>
    <p>advanced representations</p>
    <p>Multimedia is moving towards</p>
    <p>advanced representations</p>
    <p>Multimedia industry evolves with processor performance.</p>
    <p>Multimedia industry evolves with processor performance.</p>
    <p>P ro</p>
    <p>ce ss</p>
    <p>in g</p>
    <p>P er</p>
    <p>fo rm</p>
    <p>an ce</p>
    <p>Compression</p>
    <p>Video</p>
    <p>Object-Based</p>
    <p>Multimedia</p>
    <p>Image</p>
    <p>Compression</p>
    <p>Time</p>
  </div>
  <div class="page">
    <p>Multimedia Processing Solutions</p>
    <p>Application-specific processors  high performance at low cost  very limited flexibility</p>
    <p>Multimedia extensions to general-purpose processors  good programmability at little added cost  some speedup for SIMD parallelism</p>
    <p>Current programmable media processors  good performance</p>
    <p>specialized hardware  subword parallelism  ILP</p>
    <p>good programmability (w/ special programming libraries)  moderate frequency</p>
    <p>Expectations for Future Media Processors</p>
    <p>Greater Throughput</p>
    <p>Larger On-Chip Memory Hierarchies</p>
    <p>Increased Architecture Regularity</p>
    <p>Storage - large on-chip memory - large register file - efficient memory I/O</p>
    <p>Programmability - high connectivity - regular arrangement - optimizing compiler</p>
    <p>Throughput - fast clock speed - high parallelism - high utilization</p>
    <p>Balance</p>
  </div>
  <div class="page">
    <p>Evaluation Environment</p>
    <p>MediaBench Benchmark Suite</p>
    <p>Developed at UCLA</p>
    <p>[CLee97] MediaBench: A Tool for Evaluating and Synthesizing Multimedia Communication Systems, MICRO-30, 1997.</p>
    <p>Excellent combination of applications  video: MPEG-2  audio: ADPCM coder  graphics: Mesa  image: JPEG, EPIC, Ghostscript  security: PGP, Pegwit  speech: GSM, G.721, Rasta</p>
    <p>Augmented for greater representation of future multimedia  MPEG-4 object-oriented video  H.263 very-low bitrate video</p>
  </div>
  <div class="page">
    <p>!&quot;#$</p>
    <p>%</p>
    <p>IMPACT Environment</p>
    <p>Aggressive ILP research compiler  Three levels of optimizations</p>
    <p>Classical - classical optimizations only  Superscalar - adds loop unrolling and superblock formation  Hyperblock - adds hyperblock optimization</p>
    <p>Architecture-independent evaluation  large, generic instruction set  retargetable back-end</p>
    <p>Performance analysis tools  profiling  simulation for superscalar and VLIW architectures</p>
    <p>&amp;('</p>
    <p>Cache Memory Hierarchy Evaluation</p>
  </div>
  <div class="page">
    <p>)*+,</p>
    <p>./.</p>
    <p>Architecture Evaluation</p>
    <p>Variety of Memory Hierarchy Options  Cache vs. Memory  Automatic Prefetching vs. Software Prefetching  Streaming Memory vs. DMA Prefetching  Organization of hierarchy?</p>
    <p>Related Work</p>
    <p>[CLee97] MediaBench: A Tool for Evaluating and Synthesizing Multimedia Communications Systems, MICRO-30, 1997.</p>
    <p>[ZWu97] Study of Cache Systems in Video Signal Processors, SiPS-98, 1998. [DZucker97] Architecture and Arithmetic for Multimedia Enhanced Processors, Ph.D.</p>
    <p>Thesis, Dept. of Electrical Engineering, Stanford Univ., 1997. [DZucker95] A comparison of hardware prefetching techniques for multimedia</p>
    <p>benchmarks, Technical Report CSL-TR-95-683, Stanford University, 1995. [YChen98] Multimedia Signal Processors: An Architectural Platform with Algorithmic</p>
    <p>Compilation, Journal of VLSI Signal Processing Systems for Signal, Image, and Video Technology, vol. 20, 1998.</p>
    <p>[FCatthoor98] Custom Memory Management Methodology: Exploration of Memory Organisation for Embedded Multimedia System Design, Kluwer Academic Publishers, 1998.</p>
    <p>Base Architecture Model</p>
    <p>Architecture model  8-issue VLIW media processor  operation latencies targeting 500 MHz to 1 GHz processor frequency  64 integer and floating-point registers  pipeline: 1 fetch, 2 decode, 1 write back, variable execute stages</p>
    <p>L1 Cache  16 KB direct-mapped L1 instruction cache w/ 256 byte lines  32 KB direct-mapped L1 data cache w/ 64 byte lines</p>
    <p>non-blocking w/ 8-entry miss buffer  no-write allocate w/ 8-entry write buffer</p>
    <p>currently no streaming memory support</p>
    <p>On-Chip L2 Cache  256 KB 4-way set associate w/ 64 byte lines</p>
    <p>non-blocking w/ 8-entry miss buffer  write allocate w/ 8-entry write buffer</p>
    <p>External Memory  4:1 Processor to external bus frequency ratio</p>
    <p>Miss Latency</p>
    <p>Cache</p>
    <p>L2 Cache</p>
    <p>L1 D-Cache</p>
    <p>L1 I-Cache</p>
  </div>
  <div class="page">
    <p>L1 Cache</p>
    <p>Results from earlier workload evaluation:  i-cache working set size: &lt; 8 KB  i-cache spatial locality: 84.8% locality within 256 bytes  d-cache working set size: &lt; 32 KB  d-cache spatial locality: 60.8% locality within 128 bytes</p>
    <p>[JFritts99] Understanding multimedia application characteristics for designing programmable media processors, SPIE Photonics West, Media Processors 99, 1999.</p>
    <p>No streaming memory support  to be evaluated in future work</p>
    <p>L2 Cache Evaluation</p>
    <p>Cache size  regression over cache sizes from 128 KB to 1 MB  base cache size is 256 KB  0.5% avg. performance increase from doubling cache size</p>
    <p>~7% difference for unepic and mpeg4dec</p>
    <p>Access latency  regression over access latencies of 8, 15, 30, 60 cycles  base access latency is 15 cycles  5.6% avg. performance decrease from doubling access latency</p>
    <p>~35% difference for pegwitdec and pegwitenc (large working set size)  ~16% difference for mpeg2dec</p>
    <p>attributable to increasing memory access latency</p>
  </div>
  <div class="page">
    <p>;&lt;=&gt;?</p>
    <p>@(A</p>
    <p>L2 Cache Line Size Evaluation</p>
    <p>Line size  regression over line sizes from 32 to 512 bytes  base line size is 64 bytes  10% avg. performance decrease from doubling line size</p>
    <p>1.5-3.5% degradation for speech and security media  32-37% degradation for image, audio, and graphics</p>
    <p>degradation attributable to increased latency for longer lines</p>
    <p>L2 Cache Line Size (# bytes )</p>
    <p>In st</p>
    <p>ru ct</p>
    <p>io n</p>
    <p>s p</p>
    <p>er C</p>
    <p>y cl</p>
    <p>e (I</p>
    <p>P C</p>
    <p>)</p>
    <p>video image graphics audio speech security decode encode</p>
    <p>B/C</p>
    <p>External Memory Latency Evaluation</p>
    <p>Latency  regression over memory latencies from 25 to 400 bus cycles  base line size is 50 bytes  20% avg. performance decrease from doubling memory latency</p>
    <p>minimal degradation for speech and security media  59-77% degradation for image, audio, and graphics</p>
    <p>In st</p>
    <p>ru ct</p>
    <p>io n</p>
    <p>s p</p>
    <p>er C</p>
    <p>y cl</p>
    <p>e (I</p>
    <p>P C</p>
    <p>)</p>
    <p>video image graphics audio speech security decode encode</p>
  </div>
  <div class="page">
    <p>DEFGH</p>
    <p>I/J</p>
    <p>External Memory Bandwidth Evaluation</p>
    <p>Bandwidth  regression over system bus width of 4 to 32 bytes  base system bus width is 8 bytes  6% avg. performance increase from doubling system bus width</p>
    <p>0.6 - 2.7% increase for speech, security, and encoding benchmarks  7.5 - 13.9% increase for decoding and graphics benchmarks</p>
    <p>data bus )</p>
    <p>In st</p>
    <p>ru ct</p>
    <p>io ns</p>
    <p>p er</p>
    <p>C yc</p>
    <p>le (</p>
    <p>IP C</p>
    <p>)</p>
    <p>video image graphics audio speech security decode encode</p>
    <p>K(L</p>
    <p>Correlation Between External Memory Latency and Bandwidth Experiments</p>
    <p>Latency Experiment  increasing memory latency decreases memory bandwidth</p>
    <p>Bandwidth Experiment  increasing memory bandwidth decreases transfer latency</p>
    <p>Simultaneously Evaluate Latency and Bandwidth  consider only high bandwidth benchmarks</p>
    <p>Program Avg. Latency Degradation (%)</p>
    <p>Avg. Bandwidth Degradation (%)</p>
    <p>Bandwidth (L, M, H)</p>
    <p>cjpeg 68.1 11.3 M gs 66.8 15.4 M</p>
    <p>gsmencode 3.6 0.4 L H263dec 99.1 30.8 H mipmap 75.6 13.1 H</p>
    <p>mpeg2enc 25.3 2.8 L mpeg4dec 95.3 27.8 H pegwitdec 25.1 3.0 L rawdaudio 108.1 22.3 H</p>
    <p>texgen 53.3 6.1 M unepic 88.1 21.5 H</p>
  </div>
  <div class="page">
    <p>MONPRQTSVU</p>
    <p>W/X</p>
    <p>Conclusions</p>
    <p>L2 cache has little impact on performance  useful for storing state during context switches</p>
    <p>External memory latency =&gt; primary memory problem  Streaming data structures will help alleviate this</p>
    <p>External memory bandwidth =&gt; secondary problem</p>
    <p>Y/Z</p>
    <p>Future Work</p>
    <p>Multi-Level Prefetch Hierarchy  automatic prefetching structures primarily researched at L1-level  desire automatic prefetching without saturating bandwidth  possible solution:</p>
    <p>conservative prefetch unit on-chip  aggressive prefetch unit off-chip</p>
    <p>Streaming Data Out  automated prefetching techniques primarily support streaming data IN  examine characteristics of streaming data out  modify streaming memory structures to support both input and output  example:</p>
    <p>write buffers already similar to streaming memory buffers for output data  modify to predict output stride and fetch (allocate) memory lines as appropriate</p>
  </div>
</Presentation>
