<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Automatic extraction of synonyms in a dictionary</p>
    <p>Vincent D. Blondel Pierre P. Senellart</p>
    <p>April 13th 2002</p>
  </div>
  <div class="page">
    <p>The dictionary graph</p>
    <p>Computation (n.) The act or process of computing; calculation; reckoning.</p>
    <p>Computation (n.) The result of computation; the amount computed.</p>
    <p>Computed (imp. &amp; p. p.) of Compute</p>
    <p>Computing (p. pr. &amp; vb. n.) of Compute</p>
    <p>Compute (v.t.) To determine calculation; to reckon; to count.</p>
    <p>Compute (n.) Computation.</p>
    <p>Computer (n.) One who computes.</p>
  </div>
  <div class="page">
    <p>ComputerCompute</p>
    <p>Computing</p>
    <p>Computation</p>
    <p>Computed</p>
    <p>Rest of the graph</p>
  </div>
  <div class="page">
    <p>Looking for near-synonyms</p>
    <p>Definition. The neighborhood graph of a node i in a directed graph G is the subgraph consisting of i, all parents of i and all children of i.</p>
    <p>i is some word we want a synonym of.</p>
    <p>A will be the adjacency matrix of the neighborhood graph of i in the dictionary graph.</p>
    <p>n is the order of A.</p>
  </div>
  <div class="page">
    <p>Subgraph of the neighborhood graph of likely</p>
    <p>invidious</p>
    <p>truthy</p>
    <p>verisimilar probable</p>
    <p>likely adapted</p>
    <p>giving</p>
    <p>belief</p>
    <p>probably</p>
  </div>
  <div class="page">
    <p>Hubs and Authorities on the Web</p>
    <p>The Web as a graph:</p>
    <p>vertices=web pages</p>
    <p>edges=links</p>
    <p>Hub  Authority</p>
    <p>A mutually reinforcing relationship: good hubs are pages that point to good authorities and good authorities are pages pointed by good hubs.</p>
  </div>
  <div class="page">
    <p>Kleinbergs algorithm</p>
    <p>x1i : iteratively computed hub weights x2i : iteratively computed authority weights</p>
    <p>x10 = x 2 0 =</p>
    <p>1. . .</p>
    <p>( x1</p>
    <p>x2</p>
    <p>) t+1</p>
    <p>= (</p>
    <p>)( x1</p>
    <p>x2</p>
    <p>) t</p>
    <p>t = 0, 1, . . .</p>
    <p>The principal eigenvectors of ATA and AAT give respectively the authority weights and hub weights of the vertices of the graph.</p>
  </div>
  <div class="page">
    <p>An extension of Kleinbergs algorithm</p>
    <p>Let M(m,m) and N(n,n) be the transition matrices of two oriented graphs.</p>
    <p>Let C = M N + MT NT where  is the Kronecker tensorial product.</p>
    <p>We assume that the greatest eigenvalue of C is strictly greater than the absolute value of all other eigenvalues.</p>
    <p>Then, the normalized principal eigenvector X of C gives the similarity between a vertex of M and a vertex of N: Xin+j characterizes the similarity between vertex i of M and vertex j of N.</p>
    <p>In particular, if M = (</p>
    <p>) , the result is that of Kleinbergs algorithm.</p>
  </div>
  <div class="page">
    <p>Application to the search for synonyms</p>
    <p>We are looking for vertices like 2 in the neighborhood graph of i.</p>
    <p>Let C = M A + MT AT where M =</p>
    <p>0 1 00 0 1</p>
    <p>.</p>
    <p>The principal eigenvector of C gives the similarity between a node in G and a node in the graph 1  2  3.</p>
    <p>We just select the subvector corresponding to the vertex 2 in order to have synonymy weights.</p>
  </div>
  <div class="page">
    <p>The vectors method</p>
    <p>For each 1  j  n,j 6= i, compute:</p>
    <p>(Ai,Aj,) + (A,i A,j)T</p>
    <p>(where   is some vector norm, Ai, and A,i are respectively the ith line and the ith column of A).</p>
    <p>For instance, if we choose the Euclidean norm, we compute:</p>
    <p>( n k=1</p>
    <p>(Ai,k Aj,k)2 )1</p>
    <p>+</p>
    <p>( n k=1</p>
    <p>(Ak,i Ak,j)2 )1</p>
    <p>The lower this value is, the better j is a synonym of i.</p>
  </div>
  <div class="page">
    <p>ArcRank</p>
    <p>PageRank (Google): stationary distribution of weights over vertices corresponding to the principal eigenvector of the adjacency matrix.</p>
    <p>ArcRank:</p>
    <p>rs,t = ps/|as| pt</p>
    <p>|as| is the outdegree of s.</p>
    <p>pt is the pagerank of t.</p>
    <p>The best synonyms of i are the other extremity of the best-ranked arcs arriving to or leaving from i.</p>
  </div>
  <div class="page">
    <p>Extraction of the graph</p>
    <p>Multiwords (e.g. All Saints, Surinam toad)</p>
    <p>Prefixes and suffixes (e.g un-, -ous)</p>
    <p>Different meanings of a word</p>
    <p>Derived forms (e.g. daisies, sought)</p>
    <p>Accentuated characters (e.g. proven/al, cr/che)</p>
    <p>Misspelled words</p>
  </div>
  <div class="page">
    <p>Lexical units</p>
    <p>Numbers (e.g. 14159265, 14th)</p>
    <p>Mathematical and chemical symbols (e.g. x3, fe3o4)</p>
    <p>Proper nouns (e.g. California, Aaron)</p>
    <p>Misspelled words (e.g. aligator, abudance)</p>
    <p>Undefined words (e.g. snakelike, unwound)</p>
    <p>Abbreviations (e.g. adj, etc)</p>
  </div>
  <div class="page">
    <p>Too frequent words</p>
    <p>of 68187 a 47500</p>
    <p>the 43760 or 41496 to 31957 in 23999 as 22529</p>
    <p>and 16781 an 14027 by 12468</p>
    <p>one 12216 with 10944</p>
    <p>which 10446</p>
  </div>
  <div class="page">
    <p>Parts of speech</p>
    <p>noun</p>
    <p>adjective</p>
    <p>adverb</p>
    <p>verb</p>
    <p>other (articles, conjunctions, interjections. . . )</p>
  </div>
  <div class="page">
    <p>Disappear</p>
    <p>Vectors Kleinberg ArcRank Wordnet Microsoft Word</p>
    <p>Mark 3.6 6.3 1.2 7.5 8.6</p>
    <p>Std dev. 1.8 1.7 1.2 1.4 1.3</p>
    <p>Table 1: Near-synonyms for disappear</p>
  </div>
  <div class="page">
    <p>Parallelogram</p>
    <p>Vectors Kleinberg ArcRank Wordnet Microsoft Word</p>
    <p>Mark 4.6 4.8 3.3 6.3 5.3</p>
    <p>Std dev. 2.7 2.5 2.2 2.5 2.6</p>
    <p>Table 2: Near-synonyms for parallelogram</p>
  </div>
  <div class="page">
    <p>Sugar</p>
    <p>Vectors Kleinberg ArcRank Wordnet Microsoft Word</p>
    <p>Mark 3.9 6.3 4.3 6.2 4.7</p>
    <p>Std dev. 2.0 2.4 2.3 2.9 2.7</p>
    <p>Table 3: Near-synonyms for sugar</p>
  </div>
  <div class="page">
    <p>Science</p>
    <p>Vectors Kleinberg ArcRank Wordnet Microsoft Word</p>
    <p>Mark 3.6 4.4 3.2 7.1 6.5</p>
    <p>Std dev. 2.0 2.5 2.9 2.6 2.4</p>
    <p>Table 4: Near-synonyms for science</p>
  </div>
  <div class="page">
    <p>Perspectives</p>
    <p>Extension of the subgraph</p>
    <p>Other dictionaries, other languages</p>
    <p>Other applications of the extension of Kleinbergs algorithm</p>
  </div>
</Presentation>
