<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Deriving Invariants by Algorithmic Learning, Decision Procedure, and Predicate Abstraction</p>
    <p>Yungbum Jung1 Soonho Kong1 Bow-Yaw Wang2 Kwangkeun Yi1</p>
    <p>VMCAI10, 2010/01/18 @ Madrid, Spain</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>Automated Technique</p>
    <p>Output</p>
    <p>A Loop Invariant (Propositional Formula)</p>
    <p>Input Annotated Loop</p>
    <p>(Pre-/Post-conditions)</p>
    <p>InputAtomic Propositions</p>
  </div>
  <div class="page">
    <p>Automated Technique</p>
    <p>Overview</p>
    <p>Input Annotated Loop</p>
    <p>(Pre-/Post-conditions)</p>
    <p>InputAtomic Propositions</p>
    <p>Algorithmic Learning</p>
    <p>Query</p>
    <p>Answer</p>
    <p>Query</p>
    <p>Answer . .</p>
    <p>.</p>
    <p>Output</p>
    <p>A Loop Invariant (Propositional Formula)</p>
  </div>
  <div class="page">
    <p>Automated Technique</p>
    <p>Overview</p>
    <p>Input Annotated Loop</p>
    <p>(Pre-/Post-conditions)</p>
    <p>InputAtomic Propositions</p>
    <p>Decision Procedures</p>
    <p>Algorithmic Learning</p>
    <p>Query</p>
    <p>Answer</p>
    <p>Query</p>
    <p>Answer . .</p>
    <p>.</p>
    <p>Output</p>
    <p>A Loop Invariant (Propositional Formula)</p>
  </div>
  <div class="page">
    <p>Automated Technique</p>
    <p>Overview</p>
    <p>Input Annotated Loop</p>
    <p>(Pre-/Post-conditions)</p>
    <p>Decision Procedures</p>
    <p>Algorithmic Learning</p>
    <p>Query</p>
    <p>Answer</p>
    <p>Query</p>
    <p>Answer . .</p>
    <p>.</p>
    <p>Predicate Abstraction Boolean</p>
    <p>Formulae Propositional</p>
    <p>Formulae</p>
    <p>InputAtomic Propositions</p>
    <p>Output</p>
    <p>A Loop Invariant (Propositional Formula)</p>
  </div>
  <div class="page">
    <p>{ phase = F  success = F  give up = F  cutoff = 0  count = 0 } 1 while (success  give up) do 2 entered phase := F; 3 if phase then 4 if cutoff = 0 then cutoff := 1; 5 else if cutoff = 1  maxcost &gt; 1 then cutoff := maxcost; 6 else phase := T; entered phase := T; cutoff := 1000; 7 if cutoff = maxcost  search then give up := T; 8 else 9 count := count + 1;</p>
    <p>Fig. 3. A Sample Loop in SPEC2000 Benchmark PARSER</p>
    <p>conjunct of postcondition). Despite the complexity of the postcondition and the while body, our approach is able to compute an invariant in 13 iterations on average. The execution time and number of iterations vary significantly. They range from 2.22s to 196.52s and 1 to 84 with standard deviations 31.01 and 13.33 respectively. By Chebyshevs inequality [27], our technique infers an invariant within two minutes with probability 0.876.</p>
    <p>One of the found invariants is the following:</p>
    <p>success  (valid  linkages  linkages  5000  canonical = linkages)</p>
    <p>success  (search  count &gt; words  valid = 0)</p>
    <p>success  (count &gt; words  cutoff = maxcost  (canonical = 0  valid = 0  linkages = 0))</p>
    <p>give up  ((valid = 0  linkages = 0  canonical = linkages) (canonical = 0  valid  linkages  linkages  5000  canonical = linkages))</p>
    <p>give up  (cutoff = maxcost  count &gt; words (canonical = 0  valid = 0  linkages = 0))</p>
    <p>give up  (search  count &gt; words  valid = 0)</p>
    <p>This invariant describes the conditions when success or give up are true. For instance, it specifies that valid  linkages  linkages  5000  canonical = linkages should hold if success is true. In Figure 3, we see that success is assigned to T at line 18 when valid is positive. Yet valid is set to 0 at line 14. Hence line 16 and 17 must be executed. Thus, the first (valid  linkages) and the third</p>
    <p>with 20 Atomic Propositions (Building Blocks)</p>
  </div>
  <div class="page">
    <p>{ phase = F  success = F  give up = F  cutoff = 0  count = 0 } 1 while (success  give up) do 2 entered phase := F; 3 if phase then 4 if cutoff = 0 then cutoff := 1; 5 else if cutoff = 1  maxcost &gt; 1 then cutoff := maxcost; 6 else phase := T; entered phase := T; cutoff := 1000; 7 if cutoff = maxcost  search then give up := T; 8 else 9 count := count + 1;</p>
    <p>Fig. 3. A Sample Loop in SPEC2000 Benchmark PARSER</p>
    <p>conjunct of postcondition). Despite the complexity of the postcondition and the while body, our approach is able to compute an invariant in 13 iterations on average. The execution time and number of iterations vary significantly. They range from 2.22s to 196.52s and 1 to 84 with standard deviations 31.01 and 13.33 respectively. By Chebyshevs inequality [27], our technique infers an invariant within two minutes with probability 0.876.</p>
    <p>One of the found invariants is the following:</p>
    <p>success  (valid  linkages  linkages  5000  canonical = linkages)</p>
    <p>success  (search  count &gt; words  valid = 0)</p>
    <p>success  (count &gt; words  cutoff = maxcost  (canonical = 0  valid = 0  linkages = 0))</p>
    <p>give up  ((valid = 0  linkages = 0  canonical = linkages) (canonical = 0  valid  linkages  linkages  5000  canonical = linkages))</p>
    <p>give up  (cutoff = maxcost  count &gt; words (canonical = 0  valid = 0  linkages = 0))</p>
    <p>give up  (search  count &gt; words  valid = 0)</p>
    <p>This invariant describes the conditions when success or give up are true. For instance, it specifies that valid  linkages  linkages  5000  canonical = linkages should hold if success is true. In Figure 3, we see that success is assigned to T at line 18 when valid is positive. Yet valid is set to 0 at line 14. Hence line 16 and 17 must be executed. Thus, the first (valid  linkages) and the third</p>
    <p>with 20 Atomic Propositions (Building Blocks)</p>
    <p>{ phase = F  success = F  give up = F  cutoff = 0</p>
    <p>count = 0 }</p>
    <p>then cutoff := 1;</p>
    <p>cutoff := maxcost;</p>
    <p>se := T; cutoff := 10 00;</p>
    <p>up := T;</p>
    <p>= T;</p>
    <p>id  linkages;</p>
    <p>{ (valid &gt; 0  count &gt; word s  (cutoff = maxcost  s</p>
    <p>earch))</p>
    <p>valid  linkages  canonica l = linkages  linkages  50</p>
    <p>Fig. 3. A Sample Lo op in SPEC2000 Ben</p>
    <p>chmark PARSER</p>
    <p>conjunct of postcondition) . Despite the complexity o</p>
    <p>f the postcondition and th e</p>
    <p>while body, our approach is able to compute an inv</p>
    <p>ariant in 13 iterations on</p>
    <p>average. The execution ti me and number of iterati</p>
    <p>ons vary significantly. Th ey</p>
    <p>range from 2.22s to 196.52 s and 1 to 84 with standar</p>
    <p>d deviations 31.01 and 13. 33</p>
    <p>respectively. By Chebyshe vs inequality [27], our te</p>
    <p>chnique infers an invarian t</p>
    <p>within two minutes with p robability 0.876.</p>
    <p>One of the found invarian ts is the following:</p>
    <p>success  (valid  linkages  linkages  5000  canonic</p>
    <p>al = linkages)</p>
    <p>success  (search  count &gt; words  valid = 0)</p>
    <p>success  (count &gt; words  cutoff = maxcost  (canonic</p>
    <p>al = 0  valid = 0  linkages = 0))</p>
    <p>give up  ((valid = 0  link ages = 0  canonical = linka</p>
    <p>ges)</p>
    <p>(canonical = 0  valid  lin kages  linkages  5000  ca</p>
    <p>nonical = linkages))</p>
    <p>give up  (cutoff = maxcos t  count &gt; words</p>
    <p>(canonical = 0  valid = 0  linkages = 0))</p>
    <p>give up  (search  count &gt; words  valid = 0)</p>
    <p>This invariant describes t he conditions when succe</p>
    <p>ss or give up are true. Fo r</p>
    <p>instance, it specifies that valid  linkages  linkages</p>
    <p>5000  canonical =</p>
    <p>linkages should hold if suc cess is true. In Figure 3, w</p>
    <p>e see that success is assign ed</p>
    <p>to T at line 18 when valid is positive. Yet valid is set</p>
    <p>to 0 at line 14. Hence line</p>
    <p>linkages) and the third</p>
    <p>Find this Invariant in 33 sec</p>
  </div>
  <div class="page">
    <p>Algorithmic Learning: CDNF Algorithm</p>
  </div>
  <div class="page">
    <p>CDNF Algorithm</p>
    <p>Query</p>
    <p>CDNF Algorithm</p>
    <p>Answer</p>
    <p>...</p>
    <p>Query</p>
    <p>Answer</p>
    <p>Teacher</p>
    <p>Boolean Formula</p>
    <p>Actively learning a Boolean formula from membership and equivalence queries</p>
    <p>(polynomial # of queries in and # of variables)</p>
    <p>Teacher is required</p>
    <p>Result</p>
    <p>Bshouty, N.H.: Exact learning boolean functions via the monotone theory. Information and Computation 123 (1995) 146153</p>
    <p>Deriving Invariants by Algorithmic Learning, Decision Procedures, and Predicate Abstraction1</p>
    <p>Yungbum Jung and Soonho Kong and Bow-Yaw Wang and Kwangkeun Yi</p>
    <p>School of Computer Science and Engineering, Seoul National University</p>
    <p>{dreameye,soon,kwang}@ropas.snu.ac.kr</p>
    <p>Institute of Information Science, Academia Sinica</p>
    <p>bywang@iis.sinica.edu.tw</p>
    <p>We present a novel technique for finding loop invariants in propositional formulae by com</p>
    <p>bining algorithmic learning, decision procedures, and predicate abstraction. Given invariant</p>
    <p>approximations derived from pre- and post-conditions, our new technique exploits the flexibil</p>
    <p>ity in invariants by a simple randomized mechanism.</p>
    <p>Algorithmic learning has been applied to assumption generation in compositional reasoning.</p>
    <p>In contrast to traditional techniques, the learning approach does not derive assumptions in an</p>
    <p>off-line manner. It instead finds assumptions by interacting with a model checker progressively. Since assumptions in compositional reasoning are generally not unique, algorithmic learning can</p>
    <p>exploit the flexibility in assumptions to attain preferable solutions. Applications in verifying</p>
    <p>concurrent systems have been reported.</p>
    <p>Finding loop invariants follows a similar pattern. Invariants are often not unique. Indeed,</p>
    <p>programmers derive invariants incrementally. They usually have their guesses of invariants in</p>
    <p>mind, and gradually refine their guesses by observing program behavior more. Since in practice</p>
    <p>there are many invariants for given pre- and post-conditions, programmers have more freedom in</p>
    <p>deriving invariants. Yet traditional invariant generation techniques do not exploit the flexibility.</p>
    <p>They have a similar impediment to traditional assumption generation.</p>
    <p>We report our first findings in applying algorithmic learning to invariant generation. We</p>
    <p>show that the three technologies (algorithmic learning, decision procedures, and predicate ab</p>
    <p>straction) can be arranged in concert to derive loop invariants in propositional (or, quantifier</p>
    <p>free) formulae. The new technique is able to generate invariants for some Linux device drivers</p>
    <p>and SPEC2000 benchmarks without any help from static or dynamic analyses.</p>
    <p>For a while loop, an exact learning algorithm for Boolean formulae searches for invariants</p>
    <p>by asking queries. Queries can be resolved (not always, see below) by decision procedures</p>
    <p>automatically. Recall that the learning algorithm generates only Boolean formulae but deci</p>
    <p>sion procedures work in propositional formulae. We thus perform predicate abstraction and</p>
    <p>concretization to integrate the two components.</p>
    <p>In reality, information about loop invariant is incomplete. Queries may not be resolvable</p>
    <p>due to insufficient information. One striking feature of our learning approach is to exploit the flexibility in invariants. When query resolution requires information unavailable to decision</p>
    <p>procedures, we simply give a random answer. We surely could use static analysis to compute</p>
    <p>soundly approximated information other than random answers. Yet there are so many invariants</p>
    <p>for the given pre- and post-conditions. A little bit of incorrect information does not prevent</p>
    <p>algorithmic learning from inferring correct invariants. Indeed, the learning algorithm is able to</p>
    <p>derive invariants in our experiments by coin tossing.</p>
    <p>The technique can be seen as a framework for invariant generation. Static analyzers can</p>
    <p>contribute by providing information to algorithmic learning. Ours is hence orthogonal to existing</p>
    <p>techniques.</p>
    <p>Deriving Invariants by Algorithmic Learning, Decision Procedures, and Predicate Abstraction1</p>
    <p>Yungbum Jung and Soonho Kong and Bow-Yaw Wang and Kwangkeun Yi</p>
    <p>School of Computer Science and Engineering, Seoul National University</p>
    <p>{dreameye,soon,kwang}@ropas.snu.ac.kr</p>
    <p>Institute of Information Science, Academia Sinica</p>
    <p>bywang@iis.sinica.edu.tw</p>
    <p>We present a novel technique for finding loop invariants in propositional formulae by com</p>
    <p>bining algorithmic learning, decision procedures, and predicate abstraction. Given invariant</p>
    <p>approximations derived from pre- and post-conditions, our new technique exploits the flexibil</p>
    <p>ity in invariants by a simple randomized mechanism.</p>
    <p>Algorithmic learning has been applied to assumption generation in compositional reasoning.</p>
    <p>In contrast to traditional techniques, the learning approach does not derive assumptions in an</p>
    <p>off-line manner. It instead finds assumptions by interacting with a model checker progressively. Since assumptions in compositional reasoning are generally not unique, algorithmic learning can</p>
    <p>exploit the flexibility in assumptions to attain preferable solutions. Applications in verifying</p>
    <p>concurrent systems have been reported.</p>
    <p>Finding loop invariants follows a similar pattern. Invariants are often not unique. Indeed,</p>
    <p>programmers derive invariants incrementally. They usually have their guesses of invariants in</p>
    <p>mind, and gradually refine their guesses by observing program behavior more. Since in practice</p>
    <p>there are many invariants for given pre- and post-conditions, programmers have more freedom in</p>
    <p>deriving invariants. Yet traditional invariant generation techniques do not exploit the flexibility.</p>
    <p>They have a similar impediment to traditional assumption generation.</p>
    <p>We report our first findings in applying algorithmic learning to invariant generation. We</p>
    <p>show that the three technologies (algorithmic learning, decision procedures, and predicate ab</p>
    <p>straction) can be arranged in concert to derive loop invariants in propositional (or, quantifier</p>
    <p>free) formulae. The new technique is able to generate invariants for some Linux device drivers</p>
    <p>and SPEC2000 benchmarks without any help from static or dynamic analyses.</p>
    <p>For a while loop, an exact learning algorithm for Boolean formulae searches for invariants</p>
    <p>by asking queries. Queries can be resolved (not always, see below) by decision procedures</p>
    <p>automatically. Recall that the learning algorithm generates only Boolean formulae but deci</p>
    <p>sion procedures work in propositional formulae. We thus perform predicate abstraction and</p>
    <p>concretization to integrate the two components.</p>
    <p>In reality, information about loop invariant is incomplete. Queries may not be resolvable</p>
    <p>due to insufficient information. One striking feature of our learning approach is to exploit the flexibility in invariants. When query resolution requires information unavailable to decision</p>
    <p>procedures, we simply give a random answer. We surely could use static analysis to compute</p>
    <p>soundly approximated information other than random answers. Yet there are so many invariants</p>
    <p>for the given pre- and post-conditions. A little bit of incorrect information does not prevent</p>
    <p>algorithmic learning from inferring correct invariants. Indeed, the learning algorithm is able to</p>
    <p>derive invariants in our experiments by coin tossing.</p>
    <p>The technique can be seen as a framework for invariant generation. Static analyzers can</p>
    <p>contribute by providing information to algorithmic learning. Ours is hence orthogonal to existing</p>
    <p>techniques.</p>
    <p>||</p>
  </div>
  <div class="page">
    <p>Membership Query Membership Query asks whether Boolean assignment satisfies the Boolean formula</p>
    <p>MEM ()</p>
    <p>MEM () = Yes if  |=  MEM () = No if  |=</p>
    <p>Example: XOR function</p>
    <p>MEM({b1 = T, b2 = F}) = Yes</p>
    <p>MEM({b1 = T, b2 = T}) = No</p>
    <p>T  F = T</p>
    <p>T  T = F</p>
    <p>= b1  b2</p>
  </div>
  <div class="page">
    <p>Equivalence Query Equivalence Query asks whether the guessed Boolean formula is equivalent to ..</p>
    <p>EQ()</p>
    <p>if</p>
    <p>Yes EQ(b1  b2  b1  b2) = Yes Example: XOR function = b1  b2</p>
  </div>
  <div class="page">
    <p>Equivalence Query</p>
    <p>if</p>
    <p>Yes</p>
    <p>if     ( |=   )</p>
    <p>No with</p>
    <p>Otherwise, the teacher needs to provide a truth assignment as a counterexample .</p>
    <p>Example: XOR function</p>
    <p>Example: XOR function</p>
    <p>=</p>
    <p>=</p>
    <p>b1  b2</p>
    <p>b1  b2</p>
    <p>T  T = F T  T = T</p>
    <p>EQ(b1  b2) = No with {b1 = T, b2 = T}</p>
    <p>Equivalence Query asks whether the guessed Boolean formula is equivalent to ..</p>
    <p>EQ()</p>
    <p>EQ(b1  b2  b1  b2) = Yes</p>
  </div>
  <div class="page">
    <p>Goal</p>
    <p>Query</p>
    <p>CDNF Algorithm</p>
    <p>Answer</p>
    <p>...</p>
    <p>Query</p>
    <p>Answer</p>
    <p>Teacher for</p>
    <p>an Invariant</p>
    <p>A Loop Invariant</p>
    <p>Result</p>
    <p>Implement a Teacher to guide CDNF algorithm infer an Invariant</p>
  </div>
  <div class="page">
    <p>Predicate Abstraction</p>
  </div>
  <div class="page">
    <p>Predicate Abstraction</p>
    <p>?</p>
    <p>We want to find a Propositional invariant while the CDNF algorithm finds a Boolean formula.</p>
    <p>Problem:</p>
    <p>b1  (b2  b3) Boolean Formula</p>
    <p>i &lt; 10  (i = 10  ret) Propositional Formula</p>
  </div>
  <div class="page">
    <p>Predicate Abstraction</p>
    <p>Use predicate abstraction with given atomic propositions. Solution:</p>
    <p>Boolean Formula</p>
    <p>bi&lt;10  (bi=10  bret)</p>
    <p>EQ()</p>
    <p>Learning Algorithm</p>
    <p>AP = {i &lt; 10, i = 10, ret}</p>
  </div>
  <div class="page">
    <p>Predicate Abstraction</p>
    <p>Use predicate abstraction with given atomic propositions. Solution:</p>
    <p>Boolean Formula</p>
    <p>i &lt; 10  (i = 10  ret) Propositional Formula</p>
    <p>bi&lt;10  (bi=10  bret)</p>
    <p>EQ()</p>
    <p>SMT Solver Learning Algorithm</p>
    <p>AP = {i &lt; 10, i = 10, ret}</p>
  </div>
  <div class="page">
    <p>Predicate Abstraction</p>
    <p>Use predicate abstraction with given atomic propositions. Solution:</p>
    <p>Boolean Formula</p>
    <p>i &lt; 10  (i = 10  ret) Propositional Formula</p>
    <p>bi&lt;10  (bi=10  bret)</p>
    <p>Propositional Assignment i = 5, ret = T</p>
    <p>EQ()</p>
    <p>Counterexample</p>
    <p>SMT Solver Learning Algorithm</p>
    <p>AP = {i &lt; 10, i = 10, ret}</p>
  </div>
  <div class="page">
    <p>Predicate Abstraction</p>
    <p>Use predicate abstraction with given atomic propositions. Solution:</p>
    <p>Boolean Formula</p>
    <p>i &lt; 10  (i = 10  ret) Propositional Formula</p>
    <p>Boolean Assignment</p>
    <p>bi&lt;10  (bi=10  bret)</p>
    <p>Propositional Assignment i = 5, ret = T</p>
    <p>EQ()</p>
    <p>Counterexample</p>
    <p>bi&lt;10 = T bi=10 = F bret = T</p>
    <p>SMT Solver Learning Algorithm</p>
    <p>AP = {i &lt; 10, i = 10, ret}</p>
  </div>
  <div class="page">
    <p>Predicate Abstraction</p>
    <p>Use predicate abstraction with given atomic propositions. Solution:</p>
    <p>Boolean Formula</p>
    <p>i &lt; 10  (i = 10  ret) Propositional Formula</p>
    <p>Boolean Assignment</p>
    <p>bi&lt;10  (bi=10  bret)</p>
    <p>Propositional Assignment i = 5, ret = T</p>
    <p>EQ()</p>
    <p>Counterexample</p>
    <p>bi&lt;10 = T bi=10 = F bret = T</p>
    <p>SMT Solver Learning Algorithm</p>
    <p>AP = {i &lt; 10, i = 10, ret}</p>
  </div>
  <div class="page">
    <p>Predicate Abstraction</p>
    <p>Use predicate abstraction with given atomic propositions. Solution:</p>
    <p>Boolean Assignment</p>
    <p>MEM ()</p>
    <p>bi&lt;10 = T bi=10 = F bret = T</p>
    <p>SMT Solver Learning Algorithm</p>
    <p>AP = {i &lt; 10, i = 10, ret}</p>
  </div>
  <div class="page">
    <p>Predicate Abstraction</p>
    <p>Use predicate abstraction with given atomic propositions. Solution:</p>
    <p>Boolean Assignment</p>
    <p>MEM ()</p>
    <p>bi&lt;10 = T bi=10 = F bret = T</p>
    <p>SMT Solver Learning Algorithm</p>
    <p>AP = {i &lt; 10, i = 10, ret}</p>
    <p>Propositional Formula</p>
    <p>(i &lt; 10)  (i = 10)  ret</p>
  </div>
  <div class="page">
    <p>Predicate Abstraction</p>
    <p>Use predicate abstraction with given atomic propositions. Solution:</p>
    <p>Boolean Assignment</p>
    <p>MEM ()</p>
    <p>bi&lt;10 = T bi=10 = F bret = T</p>
    <p>SMT Solver Learning Algorithm</p>
    <p>AP = {i &lt; 10, i = 10, ret}</p>
    <p>Propositional Formula</p>
    <p>(i &lt; 10)  (i = 10)  ret</p>
  </div>
  <div class="page">
    <p>Predicate Abstraction</p>
    <p>Use predicate abstraction with given atomic propositions. Solution:</p>
    <p>Boolean Formula</p>
    <p>i &lt; 10  (i = 10  ret) Propositional Formula</p>
    <p>Boolean Assignment</p>
    <p>bi&lt;10  (bi=10  bret) (i &lt; 10)  (i = 10)  ret</p>
    <p>MEM ()</p>
    <p>Propositional Assignment i = 5, ret = T</p>
    <p>EQ()</p>
    <p>Counterexample</p>
    <p>bi&lt;10 = T bi=10 = F bret = T</p>
    <p>SMT Solver Learning Algorithm</p>
    <p>AP = {i &lt; 10, i = 10, ret}</p>
  </div>
  <div class="page">
    <p>How to Answer Queries</p>
  </div>
  <div class="page">
    <p>Problem</p>
    <p>The teacher is asked to answer the question about invariants without knowing invariants..</p>
  </div>
  <div class="page">
    <p>Invariant Properties For the annotated loop</p>
    <p>An Invariant I must satisfy the following conditions:</p>
    <p>{} while  do S end {}</p>
    <p>(A) ( holds when entering the loop)</p>
    <p>(B) ( holds at each iteration)</p>
    <p>(C) ( gives after leaving the loop)</p>
    <p>Pre(, S)</p>
    <p>Observation #1 In we can say YES by checking three conditions.EQ()</p>
  </div>
  <div class="page">
    <p>Invariant Properties For the annotated loop</p>
    <p>An Invariant I must satisfy the following conditions:</p>
    <p>{} while  do S end {}</p>
    <p>(A) ( holds when entering the loop)</p>
    <p>(B) ( holds at each iteration)</p>
    <p>(C) ( gives after leaving the loop)</p>
    <p>Pre(, S)</p>
    <p>Observation #1 In we can say YES by checking three conditions.</p>
    <p>Observation #2</p>
    <p>I     strongest</p>
    <p>under-approximation of an invariant</p>
    <p>weakest over-approximation</p>
    <p>of an invariant</p>
    <p>EQ()</p>
  </div>
  <div class="page">
    <p>Equivalence Query Resolution:</p>
    <p>Then, we find an invariant!</p>
    <p>()</p>
    <p>EQ()</p>
    <p>(A) ( holds when entering the loop)</p>
    <p>(B) ( holds at each iteration)</p>
    <p>(C) ( gives after leaving the loop)</p>
    <p>Pre(, S)</p>
  </div>
  <div class="page">
    <p>No</p>
    <p>Guess()</p>
    <p>|= ()</p>
    <p>No, with found a counterexample .()</p>
    <p>|= ()</p>
    <p>Equivalence Query Resolution: EQ() ()</p>
    <p>Under Approximation Over Approximation</p>
    <p>Case 1</p>
  </div>
  <div class="page">
    <p>No, with found a counterexample .()</p>
    <p>|= ()     |= ()</p>
    <p>Equivalence Query Resolution: EQ()</p>
    <p>()</p>
    <p>Under Approximation Over Approximation</p>
    <p>Guess</p>
    <p>No</p>
    <p>()</p>
    <p>Case 2</p>
  </div>
  <div class="page">
    <p>Guess</p>
    <p>No</p>
    <p>()</p>
    <p>Case 1 &amp; 2</p>
    <p>No, with found a counterexample .()</p>
    <p>No</p>
    <p>Equivalence Query Resolution: EQ()</p>
    <p>Under Approximation Over Approximation</p>
    <p>()</p>
  </div>
  <div class="page">
    <p>Guess</p>
    <p>No</p>
    <p>()</p>
    <p>Case 1 &amp; 2</p>
    <p>No, with found a counterexample .()</p>
    <p>No</p>
    <p>()   Cannot find a counterexample.</p>
    <p>Guess()</p>
    <p>Case 3</p>
    <p>Equivalence Query Resolution: EQ()</p>
    <p>Under Approximation Over Approximation</p>
    <p>()</p>
  </div>
  <div class="page">
    <p>Guess</p>
    <p>No</p>
    <p>()</p>
    <p>Case 1 &amp; 2</p>
    <p>No, with found a counterexample .()</p>
    <p>No</p>
    <p>Restart the learning algorithm! Cannot find a counterexample.</p>
    <p>Guess()</p>
    <p>Case 3</p>
    <p>Equivalence Query Resolution: EQ()</p>
    <p>Under Approximation Over Approximation</p>
    <p>()</p>
  </div>
  <div class="page">
    <p>Membership Query Resolution:</p>
    <p>()</p>
    <p>() = (i = 0  (i &lt; 10))  = {bi=0 = T, bi&lt;10 = F}</p>
    <p>MEM ()</p>
  </div>
  <div class="page">
    <p>Answer Yes</p>
    <p>Yes</p>
    <p>Case 1</p>
    <p>()</p>
    <p>()   ()</p>
    <p>Under Approximation Over Approximation</p>
    <p>()</p>
    <p>Membership Query Resolution: MEM ()</p>
  </div>
  <div class="page">
    <p>Answer/No</p>
    <p>Yes</p>
    <p>No</p>
    <p>Case 2</p>
    <p>()</p>
    <p>()   ()   Under Approximation</p>
    <p>Over Approximation</p>
    <p>()</p>
    <p>Membership Query Resolution: MEM ()</p>
  </div>
  <div class="page">
    <p>Case 3</p>
    <p>?</p>
    <p>()   ()</p>
    <p>Unknown</p>
    <p>Answer Yes / No</p>
    <p>Yes</p>
    <p>No</p>
    <p>Case 1 &amp; 2</p>
    <p>Under Approximation Over Approximation</p>
    <p>()</p>
    <p>Membership Query Resolution: MEM ()</p>
  </div>
  <div class="page">
    <p>Case 3</p>
    <p>?</p>
    <p>()</p>
    <p>Unknown</p>
    <p>Random Answer!Answer Yes / No</p>
    <p>Yes</p>
    <p>No</p>
    <p>Case 1 &amp; 2</p>
    <p>()</p>
    <p>Membership Query Resolution: MEM ()</p>
  </div>
  <div class="page">
    <p>Its still Sound Why? When resolving equivalence query EQ()</p>
    <p>()</p>
    <p>(A)</p>
    <p>I    Pre(I , S)(B)</p>
    <p>I    (C)</p>
    <p>I ( holds when entering the loop)</p>
    <p>( holds at each iteration)</p>
    <p>( gives after leaving the loop)</p>
    <p>I</p>
    <p>I</p>
    <p>I</p>
    <p>We always check the conditions before say Yes.</p>
    <p>An SMT solver is sound and complete for propositional formulae.</p>
  </div>
  <div class="page">
    <p>Effect of Random Answer</p>
    <p>Under Approximation</p>
    <p>Over Approximation</p>
    <p>()</p>
    <p>MEM ()</p>
    <p>? Unknown</p>
  </div>
  <div class="page">
    <p>Effect of Random Answer</p>
    <p>Under Approximation</p>
    <p>Over Approximation</p>
    <p>Invariants 1 2</p>
    <p>()</p>
    <p>MEM ()</p>
    <p>1</p>
    <p>2</p>
    <p>? Unknown</p>
    <p>Both of the random answers can lead to an invariant.</p>
  </div>
  <div class="page">
    <p>Effect of Random Answer</p>
    <p>Under Approximation</p>
    <p>Over Approximation</p>
    <p>Invariants 1 2</p>
    <p>()</p>
    <p>MEM ()</p>
    <p>1</p>
    <p>MEM () = Y ES</p>
    <p>leads to 1</p>
    <p>Yes</p>
  </div>
  <div class="page">
    <p>Effect of Random Answer</p>
    <p>Under Approximation</p>
    <p>Over Approximation</p>
    <p>Invariants 1</p>
    <p>2</p>
    <p>()</p>
    <p>MEM ()</p>
    <p>2</p>
    <p>leads to MEM () = NO</p>
    <p>No</p>
    <p>2</p>
  </div>
  <div class="page">
    <p>Invariants are Not Unique</p>
    <p>while i &lt; entries &amp;&amp; status = 0 do ! retval := nondet ! locked := false; ! switch retval do ! ! case ENXIO: retval := 0; ! ! case EAGAIN: retval := 0; ! ! case ENOMEN: retval := 0; ! ! case 0: i := i + 1; ! end ! locked := true; ! if retval != 0 &amp;&amp; (status = 0 || status = ECONNRESET) then ! ! status := retval; end</p>
    <p>{locked  i = 0}</p>
    <p>{locked  (i = 0  status = retval)}</p>
    <p>((io status = retval  io status = 0)  (io status = retval  retval = 0  io lock) (i = 0  io lock))  ((i &lt; entries)  io lock)</p>
    <p>io lock  (i = 0  (io status = 0  io status = retval)  (retval = 0  io status = retval))</p>
    <p>io lock  ((io status = 0  retval = 0  i = 0) (io status = retval  retval = 0)  (io status = retval  io status = 0)  i = 0)</p>
    <p>...</p>
  </div>
  <div class="page">
    <p>Experiments Case AP MEM EQ Coin Toss Restarts Time(sec)</p>
    <p>ide-ide-tape 6 18.2 5.2 4.1 1.2 0.055</p>
    <p>ide-wait-ireason 6 216.1 111.8 47.2 9.9 0.602</p>
    <p>parser 20 6694.5 819.4 990.3 12.5 32.120</p>
    <p>usb-message 10 20.1 6.8 1.0 1.0 0.128</p>
    <p>vpr 7 14.5 8.9 11.8 2.9 0.055</p>
    <p>Performance Table</p>
  </div>
  <div class="page">
    <p>Experiments Case AP MEM EQ Coin Toss Restarts Time(sec)</p>
    <p>ide-ide-tape 6 18.2 5.2 4.1 1.2 0.055</p>
    <p>ide-wait-ireason 6 216.1 111.8 47.2 9.9 0.602</p>
    <p>parser 20 6694.5 819.4 990.3 12.5 32.120</p>
    <p>usb-message 10 20.1 6.8 1.0 1.0 0.128</p>
    <p>vpr 7 14.5 8.9 11.8 2.9 0.055</p>
    <p>Performance Table</p>
  </div>
  <div class="page">
    <p>Experiments Performance Table</p>
    <p>If there is only one the invariant, then we need restarts. 279.5</p>
    <p>Case AP MEM EQ Coin Toss Restarts Time(sec)</p>
    <p>ide-ide-tape 6 18.2 5.2 4.1 1.2 0.055</p>
    <p>ide-wait-ireason 6 216.1 111.8 47.2 9.9 0.602</p>
    <p>parser 20 6694.5 819.4 990.3 12.5 32.120</p>
    <p>usb-message 10 20.1 6.8 1.0 1.0 0.128</p>
    <p>vpr 7 14.5 8.9 11.8 2.9 0.055</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Algorithmic Learning + Decision Procedures + Predicate Abstraction =&gt; Invariant Generation Technique</p>
    <p>Works in realistic settings (Linux device drivers and SPEC 200 Benchmarks)</p>
    <p>Exploits the flexibility in invariants by randomized mechanism.</p>
    <p>Static/Dynamic Analysis can help. More accurate approximations reduce number of restarts(EQ) and random answers(MEM).</p>
  </div>
  <div class="page">
    <p>Thank You</p>
  </div>
</Presentation>
