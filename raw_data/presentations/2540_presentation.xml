<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Juggling the Jigsaw Towards Automated Problem Inference from</p>
    <p>Network Trouble Tickets</p>
    <p>Rahul Potharaju (Purdue University)</p>
    <p>Navendu Jain (Microsoft Research)</p>
    <p>Cristina Nita-Rotaru (Purdue University)</p>
    <p>April 3, 2013 NSDI 2013</p>
  </div>
  <div class="page">
    <p>Network Troubleshooting: The Big Picture</p>
    <p>Diaries written by operators during network</p>
    <p>troubleshooting Datacenters</p>
    <p>Network Monitoring Link Down</p>
    <p>Alert</p>
    <p>Log Ticket</p>
    <p>Operator Console</p>
    <p>Network Trouble</p>
    <p>Ticket</p>
    <p>Trigger Switch A</p>
    <p>Switch B</p>
  </div>
  <div class="page">
    <p>Problems</p>
    <p>Activities</p>
    <p>Actions</p>
    <p>Goal: Automated Problem Inference from Trouble Tickets</p>
    <p>Network trouble ticket</p>
    <p>Inference Output</p>
    <p>What problems were observed? E.g., reboot loops, switch failure</p>
    <p>What troubleshooting was done? E.g., check config, verify BGP routes</p>
    <p>What was the resolution? E.g., replace line card, reboot</p>
  </div>
  <div class="page">
    <p>Problems</p>
    <p>Activities</p>
    <p>Actions</p>
    <p>Goal: Automated Problem Inference from Trouble Tickets</p>
    <p>Network trouble ticket</p>
    <p>Inference Output</p>
    <p>What problems were observed? E.g., reboot loops, switch failure</p>
    <p>What troubleshooting was done? E.g., check config, verify BGP routes</p>
    <p>What was the resolution? E.g., replace line card, reboot</p>
    <p>Key questions for network management [Q1]: Why is network redundancy ineffective? [Q2]: What are the top-k failing components? [Q3]: Are new devices more reliable?</p>
  </div>
  <div class="page">
    <p>What Does a Ticket Contain?</p>
    <p>STRUCTURED FIELDS</p>
    <p>E.g., ticket title, problem type,</p>
    <p>priority etc.</p>
    <p>FREE-FORM TEXT</p>
    <p>E.g., operator notes, emails,</p>
    <p>device debug logs, etc.</p>
  </div>
  <div class="page">
    <p>Challenges in Analyzing Trouble Tickets</p>
    <p>Coarse-grained information</p>
    <p>Inaccurate or Incomplete:</p>
    <p>our study!</p>
    <p>Written in natural language</p>
    <p>Typos and ambiguity</p>
    <p>Grammatical errors</p>
    <p>Domain-specific terms</p>
    <p>E.g., DNS, DMZ, line card</p>
  </div>
  <div class="page">
    <p>Our Contributions</p>
    <p>Measurement study: 10K+ tickets logged from a large cloud provider (April 2010-12)  Coarse-grained and inaccurate structured data in 69%-75% of the tickets</p>
    <p>Free-form natural language text comprising emails, IMs, device debug logs, etc.</p>
    <p>NetSieve: Combines NLP, knowledge discovery and ontology modeling in a novel way 1. Problems: Network entity and its state/condition e.g., firewall failure, firmware error</p>
    <p>Achieves 83%-100% accuracy  Evaluated using a domain-expert, hardware vendor tickets and a survey of operators</p>
  </div>
  <div class="page">
    <p>Roadmap</p>
    <p>Motivation</p>
    <p>Strawman Approaches to Analyze Free-form Text</p>
    <p>NetSieve: Semantic-based Approach</p>
    <p>Evaluation</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Strawman Approach To Analyze Free-form Text</p>
    <p>Strawman #1: Use NLP techniques</p>
    <p>Strawman #2: Keyword selection</p>
    <p>Strawman #3: Clustering tickets based on manual keyword selection</p>
    <p>Limitation: Work only on well-written text such as news-articles</p>
    <p>Limitations: 1. Significant time and effort to build the keyword list 2. Limited coverage or risks becoming outdated as the network evolves</p>
    <p>Limitations: Ignores contextual semantics</p>
  </div>
  <div class="page">
    <p>NetSieve: Semantic-based Approach to Do Problem Inference</p>
    <p>Problems</p>
    <p>Activities</p>
    <p>Actions</p>
    <p>Network trouble ticket</p>
    <p>Inference Output</p>
  </div>
  <div class="page">
    <p>NetSieve Architecture</p>
    <p>KNOWLEDGE BUILDING PHASE</p>
    <p>TROUBLE TICKET REPOSITORY</p>
    <p>Repeated Phrase Extraction</p>
    <p>Knowledge Discovery</p>
    <p>Ontology Modeling</p>
    <p>Goal: Find frequently occurring phrases</p>
    <p>power supply unit is faulty  access router inoperative</p>
    <p>run config script   is to inform you that there</p>
    <p>&lt;power supply unit is faulty&gt; &lt;access router inoperative&gt;</p>
    <p>&lt;run config script&gt;</p>
    <p>Goal: Find phrases important in the networking domain</p>
    <p>ENTITY: power supply unit -&gt; STATE: faulty</p>
    <p>ENTITY: access router -&gt; CONDITION: inoperative</p>
    <p>ENTITY: config script -&gt; ACTION: run</p>
    <p>Goal: Semantic interpretation of the domain-specific phrases</p>
  </div>
  <div class="page">
    <p>Step  I: Repeated Phrase Extraction</p>
    <p>Goal: Find frequently occurring phrases  Extracting all possible n-grams</p>
    <p>Challenges:  Computationally expensive</p>
    <p>Fine-tuning numerous thresholds</p>
    <p>Not all n-grams are useful (noise)</p>
    <p>Approach: Trade completeness for speed and scalability</p>
    <p>DICTIONARY BUILT BY LZW (Encoder by-product)</p>
    <p>Tickets</p>
    <p>Apply a data compression algorithm (LZW) to the input tickets</p>
    <p>Compute frequency of phrases in the LZW dictionary using Aho-Corasick algorithm</p>
    <p>TOKENIZE INTO SENTENCES</p>
    <p>Repeated Phrases + Frequencies</p>
  </div>
  <div class="page">
    <p>Step  II: Knowledge Discovery</p>
    <p>Goal: Find phrases important in the current domain to do problem inference</p>
    <p>Challenges:  Filter meaningful phrases from noisy ones</p>
    <p>Expert-labeling is time-consuming</p>
    <p>Approach: (19M phrases  5.6K phrases) 1. Apply a pipeline of linguistic filters</p>
    <p>Phrase Important?</p>
    <p>power disruption on access router</p>
    <p>key corruption due to expired certificate</p>
    <p>bad memory on server</p>
    <p>prior communication</p>
    <p>best regards</p>
    <p>informing you that</p>
  </div>
  <div class="page">
    <p>Step  III: Ontology Modeling</p>
    <p>Goal: Semantic interpretation of the extracted important phrases in the current domain</p>
    <p>Challenges:</p>
    <p>How to precisely define the meaning of domain-specific phrases and relationships between them?</p>
    <p>Approach:</p>
    <p>and</p>
    <p>replace line card</p>
    <p>OMIT</p>
    <p>?? ??</p>
  </div>
  <div class="page">
    <p>Step  III: Ontology Modeling</p>
    <p>and</p>
    <p>replace line card</p>
    <p>OMIT</p>
    <p>Action Entity</p>
    <p>Semantic Meaning</p>
    <p>Entity Object that can be deployed or repaired e.g., flash memory, core router</p>
    <p>Action Behavior that can be caused upon an entity e.g., reboot, replace</p>
    <p>Condition Describes the state of an entity e.g., bit error, hung state</p>
    <p>DOMAINEXPERT</p>
    <p>Split Phrases</p>
    <p>Tag using ontology class</p>
    <p>and</p>
    <p>replace line card</p>
    <p>OMIT</p>
    <p>?? ??</p>
  </div>
  <div class="page">
    <p>Putting it All Together (1/2): Tagging a Ticket</p>
    <p>We have raised a request #9646604 and found that the device xxx-xxx-xxx-130a Power LED is amber and it is in hung state. We checked the device for connectivity issues, cleaned the fiber and found that the power supply unit is faulty. We replaced the power supply unit.</p>
    <p>Tokenize into sentences Find domain-specific</p>
    <p>phrases Tag with Ontology Classes</p>
  </div>
  <div class="page">
    <p>Putting it All Together (1/2): Tagging a Ticket</p>
    <p>We have raised a request #9646604 and found that the device xxx-xxx-xxx-130a Power LED is amber and it is in hung state. We checked the device for connectivity issues, cleaned the fiber and found that the power supply unit is faulty. We replaced the power supply unit.</p>
    <p>Tokenize into sentences Find domain-specific</p>
    <p>phrases Tag with Ontology Classes</p>
  </div>
  <div class="page">
    <p>Putting it All Together (1/2): Tagging a Ticket</p>
    <p>Tokenize into sentences Find domain-specific</p>
    <p>phrases Tag with Ontology Classes</p>
    <p>We have raised a request #9646604 and found that the device xxx-xxx-xxx-130a Power LED is amber and it is in hung state. We checked the device for connectivity issues, cleaned the fiber and found that the power supply unit is faulty. We replaced the power supply unit.</p>
  </div>
  <div class="page">
    <p>Putting it All Together (1/2): Tagging a Ticket</p>
    <p>Tokenize into sentences Find domain-specific</p>
    <p>phrases Tag with Ontology Classes</p>
    <p>We have raised a request #9646604 and found that the (device)/ReplaceableEntity xxx-xxx-xxx-130a (Power LED)/ReplaceableEntity is (amber)/Condition and it is in (hung state)/ProblemCondition. We checked the device for connectivity issues, cleaned the fiber and found that the power supply unit is faulty. We replaced the power supply unit.</p>
  </div>
  <div class="page">
    <p>Putting it All Together (1/2): Tagging a Ticket</p>
    <p>Tokenize into sentences Find domain-specific</p>
    <p>phrases Tag with Ontology Classes</p>
    <p>We have raised a request #9646604 and found that the (device)/ReplaceableEntity xxx-xxx-xxx-130a (Power LED)/ReplaceableEntity is (amber)/Condition and it is in (hung state)/ProblemCondition. We (checked)/MaintenanceAction the (device)/ReplaceableEntity for (connectivity issues) /ProblemCondition, (cleaned)/MaintenanceAction the (fiber)/ReplaceableEntity and found that the (power supply unit)/ReplaceableEntity is (faulty)/ProblemCondition. We replaced the power supply unit.</p>
  </div>
  <div class="page">
    <p>Putting it All Together (1/2): Tagging a Ticket</p>
    <p>Tokenize into sentences Find domain-specific</p>
    <p>phrases Tag with Ontology Classes</p>
    <p>We have raised a request #9646604 and found that the (device)/ReplaceableEntity xxx-xxx-xxx-130a (Power LED)/ReplaceableEntity is (amber)/Condition and it is in (hung state)/ProblemCondition. We (checked)/MaintenanceAction the (device)/ReplaceableEntity for (connectivity issues) /ProblemCondition, (cleaned)/MaintenanceAction the (fiber)/ReplaceableEntity and found that the (power supply unit)/ReplaceableEntity is (faulty)/ProblemCondition. We (replaced)/PhysicalAction the (power supply unit)/ReplaceableEntity.</p>
  </div>
  <div class="page">
    <p>Putting it All Together (1/2): Tagging a Ticket</p>
    <p>Tokenize into sentences Find domain-specific</p>
    <p>phrases Tag with Ontology Classes</p>
    <p>We have raised a request #9646604 and found that the (device)/ReplaceableEntity xxx-xxx-xxx-130a (Power LED)/ReplaceableEntity is (amber)/Condition and it is in (hung state)/ProblemCondition. We (checked)/MaintenanceAction the (device)/ReplaceableEntity for (connectivity issues) /ProblemCondition, (cleaned)/MaintenanceAction the (fiber)/ReplaceableEntity and found that the (power supply unit)/ReplaceableEntity is (faulty)/ProblemCondition. We (replaced)/PhysicalAction the (power supply unit)/ReplaceableEntity.</p>
  </div>
  <div class="page">
    <p>Putting it All Together (2/2): Information Inference</p>
    <p>Rule Inference</p>
    <p>Problems Entity precedes/succeeds ProblemCondition</p>
    <p>Activities Entity|Condition precedes/succeeds MaintenanceAction</p>
    <p>Actions Entity precedes/succeeds PhysicalAction</p>
  </div>
  <div class="page">
    <p>Putting it All Together (2/2): Information Inference</p>
    <p>Rule Inference</p>
    <p>Problems Entity precedes/succeeds ProblemCondition</p>
    <p>Activities Entity|Condition precedes/succeeds MaintenanceAction</p>
    <p>Actions Entity precedes/succeeds PhysicalAction</p>
    <p>We have raised a request #9646604 and found that the (device)/ReplaceableEntity xxx-xxx-xxx-130a (Power LED)/ReplaceableEntity is (amber)/Condition and it is in (hung state)/ProblemCondition. We (checked)/MaintenanceAction the (device)/ReplaceableEntity for (connectivity issues) /ProblemCondition, (cleaned)/MaintenanceAction the (fiber)/ReplaceableEntity and found that the (power supply unit)/ReplaceableEntity is (faulty)/ProblemCondition. We (replaced)/PhysicalAction the (power supply unit)/ReplaceableEntity.</p>
  </div>
  <div class="page">
    <p>Putting it All Together (2/2): Information Inference</p>
    <p>Rule Inference</p>
    <p>Problems Entity precedes/succeeds ProblemCondition</p>
    <p>Activities Entity|Condition precedes/succeeds MaintenanceAction</p>
    <p>Actions Entity precedes/succeeds PhysicalAction</p>
    <p>&lt;device : hung state&gt; &lt;power supply unit : faulty&gt;</p>
    <p>We have raised a request #9646604 and found that the (device)/ReplaceableEntity xxx-xxx-xxx-130a (Power LED)/ReplaceableEntity is (amber)/Condition and it is in (hung state)/ProblemCondition. We (checked)/MaintenanceAction the (device)/ReplaceableEntity for (connectivity issues) /ProblemCondition, (cleaned)/MaintenanceAction the (fiber)/ReplaceableEntity and found that the (power supply unit)/ReplaceableEntity is (faulty)/ProblemCondition. We (replaced)/PhysicalAction the (power supply unit)/ReplaceableEntity.</p>
  </div>
  <div class="page">
    <p>Putting it All Together (2/2): Information Inference</p>
    <p>Rule Inference</p>
    <p>Problems Entity precedes/succeeds ProblemCondition</p>
    <p>Activities Entity|Condition precedes/succeeds MaintenanceAction</p>
    <p>Actions Entity precedes/succeeds PhysicalAction</p>
    <p>&lt;device : hung state&gt; &lt;power supply unit : faulty&gt;</p>
    <p>&lt;connectivity issues : checked&gt; &lt;fiber : cleaned&gt;</p>
    <p>We have raised a request #9646604 and found that the (device)/ReplaceableEntity xxx-xxx-xxx-130a (Power LED)/ReplaceableEntity is (amber)/Condition and it is in (hung state)/ProblemCondition. We (checked)/MaintenanceAction the (device)/ReplaceableEntity for (connectivity issues) /ProblemCondition, (cleaned)/MaintenanceAction the (fiber)/ReplaceableEntity and found that the (power supply unit)/ReplaceableEntity is (faulty)/ProblemCondition. We (replaced)/PhysicalAction the (power supply unit)/ReplaceableEntity.</p>
  </div>
  <div class="page">
    <p>Putting it All Together (2/2): Information Inference</p>
    <p>Rule Inference</p>
    <p>Problems Entity precedes/succeeds ProblemCondition</p>
    <p>Activities Entity|Condition precedes/succeeds MaintenanceAction</p>
    <p>Actions Entity precedes/succeeds PhysicalAction</p>
    <p>&lt;device : hung state&gt; &lt;power supply unit : faulty&gt;</p>
    <p>&lt;connectivity issues : checked&gt; &lt;fiber : cleaned&gt;</p>
    <p>We have raised a request #9646604 and found that the (device)/ReplaceableEntity xxx-xxx-xxx-130a (Power LED)/ReplaceableEntity is (amber)/Condition and it is in (hung state)/ProblemCondition. We (checked)/MaintenanceAction the (device)/ReplaceableEntity for (connectivity issues) /ProblemCondition, (cleaned)/MaintenanceAction the (fiber)/ReplaceableEntity and found that the (power supply unit)/ReplaceableEntity is (faulty)/ProblemCondition. We (replaced)/PhysicalAction the (power supply unit)/ReplaceableEntity.</p>
    <p>&lt;power supply unit : replace&gt;</p>
  </div>
  <div class="page">
    <p>NetSieve Evaluation</p>
  </div>
  <div class="page">
    <p>Evaluation Methodology</p>
    <p>Goals: Evaluate Accuracy and Usability</p>
    <p>Metrics:</p>
    <p>Percentage Accuracy, F-Score, Precision, Recall</p>
    <p>Time to read a ticket manually vs. NetSieve inference</p>
    <p>Dataset: 10K+ tickets</p>
    <p>Ground truth: 696 tickets labeled by an expert; 155 tickets from two network vendors</p>
    <p>Method:</p>
  </div>
  <div class="page">
    <p>Evaluating Accuracy: Expert-labeled and Vendor Tickets</p>
    <p>Load Balancer-1 Load Balancer-2 Load Balancer-3 Load Balancer-4 Firewalls Access Routers Load Balancer Core Routers</p>
    <p>Expert-labeled (696 tickets) Vendor (155 tickets)</p>
    <p>P e</p>
    <p>rc e</p>
    <p>n ta</p>
    <p>g e</p>
    <p>A cc</p>
    <p>u ra</p>
    <p>cy</p>
    <p>Load Balancer-1 Load Balancer-2 Load Balancer-3 Load Balancer-4 Firewalls Access Routers Load Balancer Core Routers</p>
    <p>Problems</p>
    <p>Actions</p>
  </div>
  <div class="page">
    <p>NetSieve Use Cases for Network Management</p>
    <p>Team Questions Findings</p>
    <p>Capacity Planning</p>
    <p>Why is network redundancy ineffective?</p>
    <p>Incident Management</p>
    <p>What are the top-k failing components?</p>
    <p>Network Architecture</p>
    <p>Are new devices more reliable?</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Goal: Automate problem inference from trouble tickets</p>
    <p>NetSieve semantic based approach  Combines NLP, knowledge discovery and ontology modeling in a novel way  Three key features: Problems, Activities and Actions  Achieves an accuracy of 83%-100% over a large ticket dataset</p>
    <p>Future Work  Build an ontology model automatically  Improving accuracy using expert feedback  Applying NetSieve to other problem domains</p>
  </div>
  <div class="page">
    <p>Thank You</p>
    <p>for your time!</p>
    <p>Poster &amp; Demo session</p>
    <p>Tomorrow Evening!</p>
    <p>Project page</p>
    <p>http://netsieve.info</p>
  </div>
</Presentation>
