<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Caching Doesnt Improve Mobile Web Performance* Jamshed Vesuna Colin Scott Michael Buettner Michael Piatek Arvind Krishnamurthy* Scott Shenker</p>
    <p>UC Berkeley Google *University of Washington ICSI</p>
    <p>Special thanks to our shepherd Dan Tsafrir *Much</p>
  </div>
  <div class="page">
    <p>Flywheel NSDI15 Results</p>
    <p>Increasing the cache hit ratio of their proxy from 22% to 32% resulted in only 1-2% reduction in median mobile page load time</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Goal:</p>
    <p>Understand the effects of caching on mobile web performance</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation  Background  Model (Estimating Page Load Time)  Methodology for empirical results  Corroborating model with empirical results  Conclusion</p>
  </div>
  <div class="page">
    <p>Background - Loading a Web Page</p>
  </div>
  <div class="page">
    <p>Background - Critical Path</p>
    <p>Critical Path: the longest chain of dependent browser tasks Fetch Delay = Network Delay</p>
    <p>Render Delay = Computational Delay</p>
  </div>
  <div class="page">
    <p>Background - Page Load Time (PLT)</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation  Background  Model (Estimating Page Load Time)  Methodology for empirical results  Corroborating model with empirical results  Conclusion</p>
  </div>
  <div class="page">
    <p>Performance Model - Estimating PLT</p>
    <p>C - computational delays N - network delays K - fraction of objects on the critical path that are cacheable X - cache hit ratio (out of all objects) f() - overlap of C and N on the critical path</p>
    <p>EPLT [X] = C+N(1KX) f(X)</p>
  </div>
  <div class="page">
    <p>Performance Model - Building an Intuition</p>
    <p>Cold cache (X = 0):  Original Page Load Time = C + N</p>
    <p>Perfect cache for a perfectly cacheable page  X = 1, K = 1  Strict upper bound on improved page load time:</p>
    <p>EPLT [1] = C</p>
    <p>EPLT [X] = C+N(1KX)</p>
  </div>
  <div class="page">
    <p>Performance Model - Fitting K</p>
    <p>In practice, K ~ 0.2 = *</p>
    <p>EPLT [max]  C + N</p>
    <p>*Demystifying Page Load Performance with WProf. NSDI 13 12</p>
  </div>
  <div class="page">
    <p>Prediction: Upper Bound on Caching Benefits</p>
    <p>C:N ~  for mobile devices</p>
    <p>PLTo = EPLT [0]  C+N = 5/2 C</p>
    <p>EPLT [max]  11/5 C</p>
    <p>Reduction in PLT: (EPLT [X] - PLT o) / PLTo</p>
    <p>3/25 (12% with a perfect cache!)</p>
  </div>
  <div class="page">
    <p>C:N ~  for fast desktop devices</p>
    <p>PLTo = EPLT [0]  C+N = 7 C</p>
    <p>EPLT [max]  21/5 C</p>
    <p>Reduction in PLT: (EPLT [X] - PLT o) / PLTo</p>
    <p>2/5 (40% with a perfect cache!)</p>
    <p>Prediction: Desktop Benefits from Caching</p>
  </div>
  <div class="page">
    <p>Explanation: C is Small for Desktop C:N ~  for 2GHz CPU*</p>
    <p>*Demystifying Page Load Performance with WProf. NSDI 13</p>
  </div>
  <div class="page">
    <p>Explanation: C is Small for Desktop C:N ~  for 2GHz CPU*</p>
    <p>*Demystifying Page Load Performance with WProf. NSDI 13</p>
  </div>
  <div class="page">
    <p>C:N ~  for 2GHz CPU* Explanation: C is Small for Desktop</p>
    <p>*Demystifying Page Load Performance with WProf. NSDI 13</p>
  </div>
  <div class="page">
    <p>C:N ~  for 2GHz CPU* Explanation: C is Small for Desktop</p>
    <p>*Demystifying Page Load Performance with WProf. NSDI 13</p>
  </div>
  <div class="page">
    <p>C:N ~  for 1GHz CPU</p>
    <p>Explanation: C is Larger for Mobile</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation  Background  Model (Estimating Page Load Time)  Methodology for empirical results  Corroborating model with empirical results  Conclusion</p>
  </div>
  <div class="page">
    <p>Measurement Methodology</p>
  </div>
  <div class="page">
    <p>Measurement Methodology</p>
  </div>
  <div class="page">
    <p>Measurement Methodology</p>
  </div>
  <div class="page">
    <p>Measurement Methodology</p>
  </div>
  <div class="page">
    <p>Measurement Methodology</p>
    <p>a. With a perfect cache b. Or a partial cache</p>
  </div>
  <div class="page">
    <p>Measurement Methodology</p>
    <p>a. With a perfect cache b. Or a partial cache</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation  Background  Model (Estimating Page Load Time)  Methodology for empirical results  Corroborating model with empirical results  Conclusion</p>
  </div>
  <div class="page">
    <p>Workload Characteristics</p>
  </div>
  <div class="page">
    <p>Workload Characteristics</p>
  </div>
  <div class="page">
    <p>Workload Characteristics</p>
  </div>
  <div class="page">
    <p>Increasing Cache Hits - Flywheel Result</p>
    <p>Increased cache hit ratio from 20% to 30%  1-2% reduction in page load time 31</p>
  </div>
  <div class="page">
    <p>Desktop vs Mobile, Perfect Cache</p>
    <p>Reduction Defined As: (Original PLT - PLT with a perfect cache) / (Original PLT)</p>
  </div>
  <div class="page">
    <p>Desktop vs Mobile, Perfect Cache</p>
    <p>Median reduction in PLT for 3.2 GHz desktop is 34%</p>
  </div>
  <div class="page">
    <p>Desktop vs Mobile, Perfect Cache</p>
    <p>Median reduction in PLT for mobile is 13% 34</p>
  </div>
  <div class="page">
    <p>Isolating the Bottleneck Resource</p>
    <p>Constrained CPU similar to Mobile</p>
  </div>
  <div class="page">
    <p>Isolating the Bottleneck Resource</p>
    <p>Constrained RAM similar to Desktop</p>
  </div>
  <div class="page">
    <p>Isolating the Bottleneck Resource</p>
    <p>CPU is the key difference, not RAM 37</p>
  </div>
  <div class="page">
    <p>Slower CPUs Show Reduced Improvements</p>
    <p>As CPU is throttled, caching has a reduced impact on PLT 38</p>
  </div>
  <div class="page">
    <p>Slower CPUs Show Reduced Improvements</p>
    <p>As CPU is throttled, caching has a reduced impact on PLT 39</p>
  </div>
  <div class="page">
    <p>Caching Benefits are Limited by Slow CPUs</p>
    <p>We know: slower CPUs increase computational delays (C)  For desktop, network delay (N) dominates (C)  For mobile*, network delay (N) is comparable to (C) (3:2)</p>
    <p>*Assumption: All else being equal (including b/w) 40</p>
    <p>Caching only reduces (N)</p>
    <p>Mobile devices benefit less from web caching</p>
  </div>
  <div class="page">
    <p>Implications</p>
    <p>Content providers:  Stop paying for CDNs* [for mobile users]</p>
    <p>*If you only care about end user latency</p>
    <p>Analyze whats on the critical path  Cache critical path items  Make use of SPDY or HTTP/2 prioritization levels</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>jamshed.vesuna@gmail.com cs@cs.berkeley.edu</p>
    <p>This Presentation: https://goo.gl/plH4HE PLT Analysis: https://github.com/colin-scott/page_load_time Open Source Tools: https://github.com/JamshedVesuna/telemetry</p>
    <p>Caching doesnt decrease mobile PLT much  Items on the critical path are often not cacheable*  CPU is the key bottleneck resource on mobile</p>
    <p>Key contribution: predictive performance model</p>
    <p>*Demystifying Page Load Performance with WProf. NSDI 13</p>
  </div>
</Presentation>
