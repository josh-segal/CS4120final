<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>A Study of Reuse and Plagiarism in Speech and Natural Language</p>
    <p>Processing Papers</p>
    <p>Joseph Mariani1, Gil Francopoulo2, Patrick Paroubek1</p>
  </div>
  <div class="page">
    <p>Objectives</p>
    <p>Study the practices of the NLP (Spoken, Written and Sign Language) community regarding reuse and plagiarism</p>
    <p>Check whether there is a meaningful difference in taking the verbatim raw word strings compared with applying natural language processing methods to detect possible cases of reuse and plagiarism?</p>
  </div>
  <div class="page">
    <p>NLP4NLP Corpus</p>
    <p>Presently conduct large scholar analysis of NLP domain  Production, Collaboration, Citation, Innovation</p>
    <p>NLP4NLP: 34 sources over 50 years (1965-2015)</p>
    <p>Major conferences (ACL, IEEE-ICASSP, ISCA-Interspeech, ELRA-LREC, etc.) and Journals (IEEE-TASLP, CL, SpeechCom, CSAL, LRE, etc.)</p>
    <p>558 Venues (conferences) / Issues (journals)</p>
    <p>65,003 documents</p>
    <p>48,894 Authors</p>
    <p>270 MWords</p>
  </div>
  <div class="page">
    <p>NLP4NLP Corpus short name # docs format long name language access to content period # venues</p>
    <p>acl 4264 conference Association for Computational Linguistics Conference English open access * 1979-2015 37</p>
    <p>acmtslp 82 journal ACM Transaction on Speech and Language Processing English private access 2004-2013 10</p>
    <p>alta 262 conference Australasian Language Technology Association English open access * 2003-2014 12</p>
    <p>anlp 278 conference Applied Natural Language Processing English open access * 1983-2000 6</p>
    <p>cath 932 journal Computers and the Humanities English private access 1966-2004 39</p>
    <p>cl 776 journal American Journal of Computational Linguistics English open access * 1980-2014 35</p>
    <p>coling 3813 conference Conference on Computational Linguistics English open access * 1965-2014 21</p>
    <p>conll 842 conference Computational Natural Language Learning English open access * 1997-2015 18</p>
    <p>csal 762 journal Computer Speech and Language English private access 1986-2015 29</p>
    <p>eacl 900 conference European Chapter of the ACL English open access * 1983-2014 14</p>
    <p>emnlp 2020 conference Empirical methods in natural language processing English open access * 1996-2015 20</p>
    <p>hlt 2219 conference Human Language Technology English open access * 1986-2015 19</p>
    <p>icassps 9819 conference</p>
    <p>IEEE International Conference on Acoustics, Speech and Signal</p>
    <p>Processing - Speech Track English private access 1990-2015 26</p>
    <p>ijcnlp 1188 conference International Joint Conference on NLP English open access * 2005-2015 6</p>
    <p>inlg 227 conference International Conference on Natural Language Generation English open access * 1996-2014 7</p>
    <p>isca 18369 conference International Speech Communication Association English open access 1987-2015 28</p>
    <p>jep 507 conference Journes d'Etudes sur la Parole French open access * 2002-2014 5</p>
    <p>lre 308 journal Language Resources and Evaluation English private access 2005-2015 11</p>
    <p>lrec 4552 conference Language Resources and Evaluation Conference English open access * 1998-2014 9</p>
    <p>ltc 656 conference Language and Technology Conference English private access 1995-2015 7</p>
    <p>modulad 232 journal Le Monde des Utilisateurs de L'Analyse des Donnes French open access 1988-2010 23</p>
    <p>mts 796 conference Machine Translation Summit English open access 1987-2015 15</p>
    <p>muc 149 conference Message Understanding Conference English open access * 1991-1998 5</p>
    <p>naacl 1186 conference North American Chapter of ACL English open access * 2000-2015 11</p>
    <p>paclic 1040 conference</p>
    <p>Pacific Asia Conference on Language, Information and</p>
    <p>Computation English open access * 1995-2014 19</p>
    <p>ranlp 363 conference Recent Advances in Natural Language Processing English open access * 2009-2013 3</p>
    <p>sem 950 conference Lexical and Computational Semantics / Semantic Evaluation English open access * 2001-2015 8</p>
    <p>speechc 593 journal Speech Communication English private access 1982-2015 34</p>
    <p>tacl 92 journal Transactions of the Association for Computational Linguistics English open access * 2013-2015 3</p>
    <p>tal 177 journal Revue Traitement Automatique du Langage French open access 2006-2015 10</p>
    <p>taln 1019 conference Traitement Automatique du Langage Naturel French open access * 1997-2015 19</p>
    <p>taslp 6612 journal</p>
    <p>IEEE/ACM Transactions on Audio, Speech and Language</p>
    <p>Processing English private access 1975-2015 41</p>
    <p>tipster 105 conference Tipster DARPA text program English open access * 1993-1998 3</p>
    <p>trec 1847 conference Text Retrieval Conference English open access 1992-2015 24</p>
    <p>Total incl. duplicates 67937 1965-2015 577</p>
    <p>Total excl. duplicates 65,003 1965-2015 558</p>
  </div>
  <div class="page">
    <p>Definitions</p>
    <p>Self-reuse: copy &amp; paste when the source of the copy has at least one author who belongs to the group of authors of the text of the paste and when the source is cited.</p>
    <p>Self-plagiarism: copy &amp; paste when the source of the copy has at least one author who belongs to the group of authors of the text of the paste, but when the source is not cited.</p>
    <p>Reuse: copy &amp; paste when the source of the copy has no author in the group of authors of the paste and when the source is cited.</p>
    <p>Plagiarism: copy &amp; paste when the source of the copy has no author in the group of the paste and when the source is not cited.</p>
  </div>
  <div class="page">
    <p>Definitions</p>
    <p>Source paper is quoted Source paper is not quoted</p>
    <p>At least one author in</p>
    <p>common</p>
    <p>Self-Reuse</p>
    <p>Self-Plagiarism</p>
    <p>No author in common</p>
    <p>Reuse</p>
    <p>Plagiarism</p>
  </div>
  <div class="page">
    <p>Each year: Papers of the focus borrowing papers of the search space (same year or previous years: Backward study)</p>
    <p>Self-Reusing Self-Plagiarizing Reusing Plagiarizing</p>
    <p>Year1</p>
    <p>Year2</p>
    <p>Year3</p>
    <p>Search Space</p>
    <p>Focus NLP4NLP (Same year or previous years)</p>
  </div>
  <div class="page">
    <p>Each year: Papers of the focus being borrowed by papers of search space (same year or following years: Forward study)</p>
    <p>Self-Reused Self-Plagiarized Reused Plagiarized</p>
    <p>Year1</p>
    <p>Year2</p>
    <p>Year3</p>
    <p>Search Space</p>
    <p>Focus NLP4NLP (Same year or following years)</p>
  </div>
  <div class="page">
    <p>Algorithm</p>
    <p>Based on comparison of word sequences, had to be optimized:  For each pair of documents D1 of the focus (LREC) and D2 of the search space</p>
    <p>(NLP4NLP), consider 1. either raw text 2. or text after LP (Tagparser [Francopoulo 2007] with Global Atlas + LRE Map)</p>
    <p>Hyphen variations  Caesura  Upper/lower cases  Plurals  Orthographic variations (British English versus American English)  Spelling errors  Abbreviations (BNC versus British National Corpus)</p>
    <p>Compare 2 texts D1 / D2 using sliding windows of (5-7) lemmas (excluding punctuations)</p>
    <p>Compute a similarity overlapping score [Lyon et al 2001] between documents D1 and D2, with (a variant of) the Jaccard similarity coefficient  Score (D1,D2) = #shared windows / #union (D1 windows, D2 windows)</p>
    <p>Filter the pairs of documents D1 / D2 according to a threshold of (0.03-0.04) (3-4% coverage) to retain only significantly similar pairs</p>
  </div>
  <div class="page">
    <p>Raw text versus LP</p>
    <p>Strategy</p>
    <p>Backward study document pairs#</p>
    <p>Forward study</p>
    <p>document pairs#</p>
    <p>Backward + forward document pairs# after</p>
    <p>duplicate pruning</p>
    <p>Difference (LP-raw) 121 81 158</p>
  </div>
  <div class="page">
    <p>Tuning Parameters</p>
    <p>Windows: 7 words</p>
    <p>Jaccard similarity coefficient</p>
    <p>Similarity threshold: 0.04 (4%)</p>
    <p>+ Number of shared windows &gt; 50</p>
  </div>
  <div class="page">
    <p>Example of IEEE ICASSP 2001</p>
    <p>Self-Reusing Self-Plagiarizing</p>
  </div>
  <div class="page">
    <p>Example of IEEE ICASSP 2001</p>
    <p>Reusing Plagiarizing</p>
  </div>
  <div class="page">
    <p>Example of similarities between 2 papers (couple 18)</p>
    <p>Icassps2001-123.pdf taslp1999-27.pdf</p>
  </div>
  <div class="page">
    <p>Self Reuse-Plagiarism</p>
    <p>12,493 cases (18% papers) : no manual checking  4% to 97% overlapping  In 61% of the cases, authors do not quote the source paper  130 papers have both the same title and the same list of authors  205 papers have the same title</p>
    <p>Some specific cases (largest similarities)  Republishing the corrigendum of a previously published paper  Republishing a paper with a small difference in the title and one</p>
    <p>missing author in the authors list  Same research center described by the same author in two different</p>
    <p>conferences, with an overlapping of 90%  2 papers presented by the same author in 2 successive conferences,</p>
    <p>the difference being primarily in the name of the 2 systems being presented, that have been funded by the same project agency in 2 different contracts, with an overlapping of 45%</p>
  </div>
  <div class="page">
    <p>Similarity Scores Self Reuse-Plagiarism</p>
  </div>
  <div class="page">
    <p>Self Reuse-Plagiarism Used Using a</p>
    <p>cl</p>
    <p>a cm</p>
    <p>ts lp</p>
    <p>a lta</p>
    <p>a n</p>
    <p>lp</p>
    <p>ca th</p>
    <p>cl</p>
    <p>c o lin</p>
    <p>g</p>
    <p>c o n</p>
    <p>ll</p>
    <p>cs a l</p>
    <p>e a c l</p>
    <p>e m</p>
    <p>n lp</p>
    <p>h lt</p>
    <p>ic a s sp</p>
    <p>s</p>
    <p>ijc n lp</p>
    <p>in lg</p>
    <p>is ca</p>
    <p>je p</p>
    <p>lr e</p>
    <p>lr e c</p>
    <p>lt c</p>
    <p>m o</p>
    <p>d u</p>
    <p>la d</p>
    <p>m ts</p>
    <p>m u c</p>
    <p>n a a</p>
    <p>cl</p>
    <p>p a</p>
    <p>cl ic</p>
    <p>ra n</p>
    <p>lp</p>
    <p>se m</p>
    <p>sp e e ch</p>
    <p>c</p>
    <p>ta cl</p>
    <p>ta l</p>
    <p>ta ln</p>
    <p>ta sl</p>
    <p>p</p>
    <p>ti p st</p>
    <p>e r</p>
    <p>tr e</p>
    <p>c</p>
    <p>T o</p>
    <p>ta l u</p>
    <p>s e d</p>
    <p>T o</p>
    <p>ta l u si</p>
    <p>n g</p>
    <p>D iff</p>
    <p>e re</p>
    <p>n c e</p>
    <p>acl 22 8 1 4 8 136 78 25 31 22 83 85 29 31 7 48 0 20 71 4 0 19 1 51 8 5 26 1 2 0 0 24 4 9 863 625 238 acl</p>
    <p>acmtslp 1 0 0 0 0 0 0 0 2 0 0 2 3 2 0 6 0 1 1 0 0 0 0 2 0 0 1 0 1 0 0 2 0 0 24 93 -69 acmtslp</p>
    <p>alta 3 0 2 0 0 1 5 0 1 2 5 0 0 1 0 4 0 0 4 0 0 0 0 0 0 1 0 0 0 0 0 0 0 4 33 14 19 alta</p>
    <p>anlp 7 0 0 1 3 5 8 1 1 2 1 4 0 0 0 1 0 0 5 0 0 1 0 2 1 0 0 0 0 0 0 0 2 5 50 50 0 anlp</p>
    <p>cath 1 0 0 1 7 2 0 0 0 1 0 1 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 18 50 -32 cath</p>
    <p>cl 9 0 0 4 3 0 4 0 2 4 3 1 0 0 0 0 0 2 5 0 0 0 0 0 1 0 4 0 0 0 0 0 0 0 42 433 -391 cl</p>
    <p>coling 74 10 3 8 7 62 19 24 17 15 43 49 8 24 7 42 0 14 90 4 0 9 2 33 12 5 25 3 0 0 0 12 6 5 632 500 132 coling</p>
    <p>conll 26 1 1 1 1 20 18 8 5 6 16 11 2 14 2 2 0 2 10 1 0 3 0 7 0 5 13 0 1 0 0 3 0 0 179 151 28 conll</p>
    <p>csal 3 0 0 0 0 4 4 2 7 0 3 2 20 1 0 35 0 2 7 0 0 0 0 0 0 0 2 6 0 0 0 13 0 0 111 643 -532 csal</p>
    <p>eacl 16 2 0 2 5 31 12 6 3 1 8 13 3 1 2 9 0 0 21 1 0 1 0 13 1 1 4 0 0 0 0 5 0 1 162 130 32 eacl</p>
    <p>emnlp 103 2 2 1 2 44 52 26 18 9 16 30 14 47 1 27 0 5 29 0 0 7 0 22 2 1 19 0 3 0 0 20 1 5 508 355 153 emnlp</p>
    <p>hlt 83 12 0 5 3 48 48 11 42 14 33 22 29 30 2 104 0 4 26 1 0 13 2 6 1 0 9 8 0 0 0 25 7 19 607 476 131 hlt</p>
    <p>icassps 16 5 0 0 0 3 4 1 130 4 7 21 262 2 0 1005 0 0 19 0 0 2 0 14 2 0 0 65 0 0 0 746 0 3 2311 2160 151 icassps</p>
    <p>ijcnlp 27 6 1 0 0 3 29 10 7 2 34 18 2 4 3 7 0 5 19 3 0 9 0 13 4 8 3 0 0 0 0 4 0 1 222 237 -15 ijcnlp</p>
    <p>inlg 7 0 0 1 1 6 5 2 0 3 1 3 0 1 2 4 0 1 6 0 0 1 0 4 0 0 0 0 0 0 0 1 0 0 49 35 14 inlg</p>
    <p>isca 56 23 0 2 0 13 45 0 317 10 25 116 1531 10 4 879 0 10 133 19 0 12 0 38 6 0 1 233 0 0 0 669 0 5 4157 2460 1697 isca</p>
    <p>jep 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 10 0 0 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 16 18 -2 jep</p>
    <p>lre 2 1 0 0 0 2 3 0 0 0 0 1 0 0 0 2 0 2 6 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 22 146 -124 lre</p>
    <p>lrec 58 3 0 2 6 16 80 6 13 15 16 17 16 10 2 72 0 52 67 12 0 6 0 11 11 4 12 5 2 0 0 6 1 3 524 660 -136 lrec</p>
    <p>ltc 4 0 0 0 0 0 0 0 0 0 0 0 0 2 0 15 0 1 35 10 0 2 0 0 6 6 1 4 0 0 0 0 0 0 86 71 15 ltc</p>
    <p>modulad 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 modulad</p>
    <p>mts 13 0 0 0 0 2 9 2 0 2 9 10 3 9 0 9 0 2 20 2 0 8 0 8 5 2 1 1 0 0 0 2 0 0 119 109 10 mts</p>
    <p>muc 2 0 0 2 0 2 3 0 0 1 0 7 0 0 0 0 0 0 0 0 0 0 10 1 0 0 0 0 0 0 0 0 18 1 47 28 19 muc</p>
    <p>naacl 46 10 0 2 1 24 30 7 12 11 22 5 15 22 3 30 0 3 16 1 0 9 0 3 0 0 9 1 0 0 0 8 0 3 293 251 42 naacl</p>
    <p>paclic 4 0 0 0 1 0 12 1 1 1 1 0 2 8 0 3 0 5 18 7 0 3 0 0 21 7 1 0 0 0 0 1 0 0 97 85 12 paclic</p>
    <p>ranlp 3 2 0 0 0 0 2 4 4 2 2 1 0 7 0 0 0 2 19 5 0 2 0 1 2 4 2 1 0 0 0 0 0 1 66 54 12 ranlp</p>
    <p>sem 25 2 0 0 0 7 16 14 4 1 12 12 0 8 0 0 0 13 12 1 0 1 0 8 1 4 53 0 0 0 0 0 0 1 195 188 7 sem</p>
    <p>speechc 0 0 0 0 0 1 1 0 11 0 0 4 17 0 0 48 0 0 2 0 0 0 0 0 0 0 0 1 0 0 0 17 0 0 102 344 -242 speechc</p>
    <p>tacl 1 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 7 9 -2 tacl</p>
    <p>tal 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 13 0 0 0 18 59 -41 tal</p>
    <p>taln 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 53 9 0 0 0 65 22 43 taln</p>
    <p>taslp 0 5 0 0 0 0 1 1 13 0 1 4 197 0 0 103 0 0 2 0 0 1 0 2 0 0 0 15 0 0 0 49 0 0 394 1610 -1216 taslp</p>
    <p>tipster 3 0 0 3 0 0 6 0 0 0 1 5 0 0 0 0 0 0 2 0 0 0 13 1 0 0 0 0 0 0 0 0 2 7 43 65 -22 tipster</p>
    <p>trec 10 0 4 11 2 1 6 0 2 2 11 32 7 3 0 5 0 0 10 0 0 0 0 10 0 1 1 0 0 0 0 2 24 287 431 362 69 trec</p>
    <p>Total using 625 93 14 50 50 433 500 151 643 130 355 476 2160 237 35 2460 18 146 660 71 0 109 28 251 85 54 188 344 9 59 22 1610 65 362 12493 12493 0</p>
  </div>
  <div class="page">
    <p>Reuse and Plagiarism</p>
    <p>261 cases : manual checking  Reuse</p>
    <p>12 have a least one author in common, but with a somehow different spelling and should therefore be placed in the Selfreuse category.</p>
    <p>Plagiarism  25 have a least one author in common, but with a somehow</p>
    <p>different spelling, and should therefore be placed in the Selfplagiarism category</p>
    <p>14 correctly quote the source paper, but with variants in the spelling of the authors names, of the papers title or of the conference or journal source, or correctly citing the source paper but forgetting to place it among the references, and should therefore be placed in the Reuse category.</p>
  </div>
  <div class="page">
    <p>Variants in Spelling Authors Name</p>
    <p>Non-Linear Probability Estimation Method Used in HMM for Modeling Frame Correlation  Qing Guo, Fang Zheng, Jian Wu, and Wenhu Wu</p>
    <p>(ISCA-Interspeech 1998)</p>
    <p>An New Method Used in HMM for Modeling Frame Correlation  Guo Qing, Zheng Fang, Wu Jian and Wu Wenhu</p>
    <p>(IEEE-ICASSP 1999)</p>
  </div>
  <div class="page">
    <p>Variants in Spelling References</p>
    <p>Quoted Reference: Graham W. (2007) an OWL Ontology for HPSG proceeding of the ACL 2007 demo and poster sessions, 169-172.</p>
    <p>Correct Reference: Graham Wilcock (2007), An OWL Ontology for HPSG</p>
    <p>Quoted Reference: Li Liu, Jianglong He, On the</p>
    <p>use of orthogonal GMM in speaker verification  Correct Reference: Li Liu and Jialong He, On the</p>
    <p>use of orthogonal GMM in speaker recognition</p>
  </div>
  <div class="page">
    <p>Reuse and Plagiarism</p>
    <p>After manual corrections: 224 cases (0.33% of papers)  4% to 42% overlapping  In 52% of the cases, authors do not quote the source paper  This results in 117 possible cases of plagiarism (0.17%):</p>
    <p>The copying paper cites another reference from the same authors of the source paper (typically a previous reference, or a paper published in a Journal) (46 cases)</p>
    <p>Both papers use extracts of a third paper that they both cite (31 cases)  Authors of the two papers are different, but from same laboratory (typical in industrial</p>
    <p>laboratories or funding agencies) (11 cases)  Authors of the two papers previously co-authored papers (typically as supervisor and</p>
    <p>PhD student or postdoc) but are now in different laboratories (11 cases)  Authors of the papers are different, but collaborated in the same project which is</p>
    <p>presented in the two papers (2 cases)  The two papers present the same short example, result or definition coming from</p>
    <p>another source (13 cases)  Only 3 remaining cases of possible plagiarism: same paper as a patchwork of 3 other</p>
    <p>papers, while sharing several references with them.</p>
  </div>
  <div class="page">
    <p>Similarity Scores Reuse/Plagiarism</p>
  </div>
  <div class="page">
    <p>Reuse and Plagiarism Used Using a</p>
    <p>cl</p>
    <p>a cm</p>
    <p>ts lp</p>
    <p>a lta</p>
    <p>a n</p>
    <p>lp</p>
    <p>ca th</p>
    <p>cl</p>
    <p>c o lin</p>
    <p>g</p>
    <p>c o n</p>
    <p>ll</p>
    <p>cs a l</p>
    <p>e a c l</p>
    <p>e m</p>
    <p>n lp</p>
    <p>h lt</p>
    <p>ic a s sp</p>
    <p>s</p>
    <p>ijc n lp</p>
    <p>in lg</p>
    <p>is ca</p>
    <p>je p</p>
    <p>lr e</p>
    <p>lr e c</p>
    <p>lt c</p>
    <p>m o</p>
    <p>d u</p>
    <p>la d</p>
    <p>m ts</p>
    <p>m u c</p>
    <p>n a a</p>
    <p>cl</p>
    <p>p a</p>
    <p>cl ic</p>
    <p>ra n</p>
    <p>lp</p>
    <p>se m</p>
    <p>sp e e ch</p>
    <p>c</p>
    <p>ta cl</p>
    <p>ta l</p>
    <p>ta ln</p>
    <p>ta sl</p>
    <p>p</p>
    <p>ti p st</p>
    <p>e r</p>
    <p>tr e</p>
    <p>c</p>
    <p>T o</p>
    <p>ta l u</p>
    <p>s e d</p>
    <p>T o</p>
    <p>ta l u si</p>
    <p>n g</p>
    <p>D iff</p>
    <p>e re</p>
    <p>n c e</p>
    <p>acl 1 0 0 0 1 1 2 2 0 0 4 3 0 3 0 2 0 0 1 1 0 0 1 1 1 1 3 0 0 0 0 0 0 0 28 7 21 acl</p>
    <p>acmtslp 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 acmtslp</p>
    <p>alta 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 alta</p>
    <p>anlp 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 anlp</p>
    <p>cath 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 -2 cath</p>
    <p>cl 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 4 0 0 1 0 1 2 0 0 0 0 0 0 0 0 0 12 5 7 cl</p>
    <p>coling 0 0 0 0 1 0 0 0 0 0 0 2 1 1 0 2 0 0 2 0 0 0 1 1 1 0 2 0 0 0 0 1 0 0 15 7 8 coling</p>
    <p>conll 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 3 5 -2 conll</p>
    <p>csal 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 3 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 7 6 1 csal</p>
    <p>eacl 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 eacl</p>
    <p>emnlp 0 0 0 0 0 2 0 2 0 1 1 2 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 2 13 15 -2 emnlp</p>
    <p>hlt 2 0 0 0 0 1 0 1 1 0 2 1 1 1 0 2 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 2 17 17 0 hlt</p>
    <p>icassps 0 0 0 0 0 0 0 0 1 0 1 2 3 0 0 32 0 0 0 0 0 0 0 2 0 0 0 2 0 0 0 5 0 0 48 37 11 icassps</p>
    <p>ijcnlp 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 2 9 -7 ijcnlp</p>
    <p>inlg 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 inlg</p>
    <p>isca 0 0 0 0 0 1 1 0 1 0 0 1 18 1 0 7 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 3 0 0 36 70 -34 isca</p>
    <p>jep 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 jep</p>
    <p>lre 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 -1 lre</p>
    <p>lrec 0 0 0 0 0 0 0 0 1 0 2 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 8 8 0 lrec</p>
    <p>ltc 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 -4 ltc</p>
    <p>modulad 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 modulad</p>
    <p>mts 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 4 3 1 mts</p>
    <p>muc 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 3 3 0 muc</p>
    <p>naacl 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 9 10 -1 naacl</p>
    <p>paclic 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 10 -8 paclic</p>
    <p>ranlp 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 -3 ranlp</p>
    <p>sem 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 3 7 -4 sem</p>
    <p>speechc 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 4 5 -1 speechc</p>
    <p>tacl 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 tacl</p>
    <p>tal 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 tal</p>
    <p>taln 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 taln</p>
    <p>taslp 0 0 0 0 0 0 0 0 1 1 0 0 10 0 0 16 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 30 10 20 taslp</p>
    <p>tipster 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 2 0 tipster</p>
    <p>trec 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 8 13 13 0 trec</p>
    <p>Total using 7 0 0 0 2 5 7 5 6 2 15 17 37 9 0 70 0 1 8 4 0 3 3 10 10 3 7 5 0 0 0 10 2 13 261 261 0</p>
  </div>
  <div class="page">
    <p>Time Delay Publication / Reuse (1.22 years on average)</p>
  </div>
  <div class="page">
    <p>Time Delay Publication in Conferences / Reuse in Journals (2.07 years on average)</p>
  </div>
  <div class="page">
    <p>Self-Plagiarism or Fair Use? (Pamela Samuelson, Comm. of ACM 1994)</p>
    <p>Acceptable if:  The previous work must be restated to lay the groundwork</p>
    <p>for a new contribution in the second work,  Portions of the previous work must be repeated to deal</p>
    <p>with new evidence or arguments,  The audience for each work is so different that publishing</p>
    <p>the same work in different places is necessary to get the message out,</p>
    <p>The authors think they said it so well the first time that it makes no sense to say it differently a second time.</p>
    <p>30% as an upper limit in the reuse of parts of a previously published paper.</p>
    <p>Only 1.3% of NLP4NLP papers go beyond this limit</p>
  </div>
  <div class="page">
    <p>Plagiarism: Right to Quote</p>
    <p>National legislations usually embody the Berne convention limits in one or more of the following requirements:  the cited paragraphs are within a reasonable limit,</p>
    <p>&lt;= 10% of the copied / copying papers in France / Canada  Only 0.05% of NLP4NLP papers go beyond this limit</p>
    <p>the cited paragraphs are clearly marked as quotations and fully referenced,</p>
    <p>the resulting new work is not just a collection of quotations, but constitutes a fully original work in itself.</p>
    <p>the copied paragraphs must have a function in the goal of the copying paper.</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Produce results on the study of copy &amp; paste operations on corpora of NLP archives of very large size, using NLP methods  Large number of pairwise comparisons (65,000*65,000), which</p>
    <p>still represents a practical computing limitation.</p>
    <p>Self-reuse and self-plagiarism are common practices (18%)  40% happen on same year (no way to detect beforehand)  No quote of source paper in 60% of the cases (75% if same year)  Natural flow from conferences to journals  Current tendency for salami-slicing publications caused by the</p>
    <p>publish-and-perish demand</p>
    <p>Plagiarism very uncommon in the NLP community (&lt;0.05%)  Ethically acceptable if principles are respected</p>
  </div>
  <div class="page">
    <p>Further developments</p>
    <p>Process rogeting: replacing words with synonymous alternatives</p>
    <p>Study the position and rhetorical structure of the copy &amp; paste in order to identify and justify their function.</p>
    <p>Explore whether copy &amp; paste is more common for non native-English speakers  publish first in their native language, then in English in</p>
    <p>an international conference or an international journal, in order to broaden their audience</p>
  </div>
  <div class="page">
    <p>Thank you.</p>
  </div>
</Presentation>
