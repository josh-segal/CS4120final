<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Vamsidhar Thummala</p>
    <p>Joint work with Shivnath Babu, Songyun Duan, Nedyalkov Borisov,</p>
    <p>and Herodotous Herodotou</p>
    <p>Duke University</p>
  </div>
  <div class="page">
    <p>Claim:</p>
    <p>Current techniques for managing</p>
    <p>systems have limitations</p>
    <p>Not adequate for end-to-end systems management</p>
    <p>Closing the loop</p>
    <p>Experiment-driven management of systems</p>
  </div>
  <div class="page">
    <p>An example scenario</p>
    <p>A CEO Query does not meet the SLO</p>
    <p>Reason: Violates the response time objective</p>
    <p>Admins observation: High disk activity</p>
    <p>Admins dilemma:  What corrective action should I</p>
    <p>take?</p>
    <p>How to validate the impact of my action?</p>
    <p>Hardware-level changes  Add more DRAM</p>
    <p>OS-level changes  Increase memory/CPU cycles (VMM)</p>
    <p>Increase swap space</p>
    <p>DB-level changes  Partition the data</p>
    <p>Update database statistics</p>
    <p>Change physical database design  indexes, schema, views</p>
    <p>Tune the query/Manually change query plan</p>
    <p>Change configuration parameters like buffer pool sizes, I/O daemons, and max connections</p>
  </div>
  <div class="page">
    <p>Get more insight into the problem  Use domain knowledge</p>
    <p>Admins experience</p>
    <p>Use apriori models if available</p>
    <p>Fast prediction</p>
    <p>Systems are complex</p>
    <p>Hard to capture the behavior of the system apriori</p>
    <p>Rely on Empirical Analysis</p>
    <p>More accurate prediction</p>
    <p>Time-consuming</p>
    <p>Sometimes the only choice!</p>
    <p>How to find the corrective action?</p>
  </div>
  <div class="page">
    <p>How Adminsdo Empirical Analysis</p>
    <p>Conduct an experiment run with a</p>
    <p>prospective setting (trial)</p>
    <p>Pay some extra cost, get new information in return</p>
    <p>Learn from observations (error)</p>
    <p>Repeat until satisfactory solution is found</p>
    <p>Automating the above process is what we call</p>
    <p>Experiment-driven Management</p>
  </div>
  <div class="page">
    <p>An example where experiment</p>
    <p>driven management can be used</p>
    <p>Configuration parameter tuning  Database parameters (PostgreSQL-specific)</p>
    <p>Memory distribution  shared_buffers, work_mem</p>
    <p>I/O optimization  fsync, checkpoint_segments, checkpoint_timeout</p>
    <p>Parallelism  max_connections</p>
    <p>Optimizers cost model  effective_cache_size, random_page_cost, default_statistics_target, enable_indexscan</p>
  </div>
  <div class="page">
    <p>Configuration parameter tuning</p>
    <p>TPC-H Q18: Large Volume Customer Query</p>
    <p>Data size: 4GB, Memory: 1GB</p>
    <p>DB cache (dedicated)OS cache (prescriptive)</p>
  </div>
  <div class="page">
    <p>More examples where experiment</p>
    <p>driven management can be used</p>
    <p>Configuration parameter tuning</p>
    <p>Problem diagnosis (troubleshooting), finding</p>
    <p>fixes, and validating the fixes</p>
    <p>Benchmarking</p>
    <p>Capacity planning</p>
    <p>Speculative execution</p>
    <p>Canary in server farm (James Hamilton, a</p>
    <p>Amazon Web Services)</p>
  </div>
  <div class="page">
    <p>Workflow for Experiment-driven</p>
    <p>Management</p>
    <p>Process output to</p>
    <p>extract information</p>
    <p>Plan next set of</p>
    <p>experiments</p>
    <p>How/where to conduct</p>
    <p>experiments?</p>
    <p>Yes</p>
    <p>Mgmt. taskResult</p>
    <p>Are more experiments</p>
    <p>needed?</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Process output to</p>
    <p>extract information</p>
    <p>Plan next set of</p>
    <p>experiments</p>
    <p>How/where to conduct</p>
    <p>experiments?</p>
    <p>Yes</p>
    <p>Mgmt. taskResult</p>
    <p>Are more experiments</p>
    <p>needed?</p>
  </div>
  <div class="page">
    <p>Challenges in setting up an experiment</p>
    <p>What is the right abstraction for an experiment?</p>
    <p>Ensuring representative workloads</p>
    <p>Can be tuning task specific</p>
    <p>Detecting deadlocks vs. performance tuning</p>
    <p>Ensuring representative data</p>
    <p>Full copy vs. sampled data?</p>
  </div>
  <div class="page">
    <p>Where to conduct experiments in</p>
    <p>a 24X7 production environment?</p>
    <p>Production system itself [USENIX09,</p>
    <p>ACDC09]</p>
    <p>May impact user-facing workload</p>
    <p>Test system</p>
    <p>Hard to replicate exact production settings</p>
    <p>Manual set-up</p>
    <p>How and where to conduct experiments?</p>
    <p>Without impacting user-facing workload</p>
    <p>As close to production runs as possible</p>
  </div>
  <div class="page">
    <p>What do DB Administrators do today?</p>
    <p>Database</p>
    <p>DBMS</p>
    <p>Production Environment</p>
    <p>Database</p>
    <p>DBMS</p>
    <p>Standby Environment</p>
    <p>Clients Clients Clients</p>
    <p>Write Ahead</p>
    <p>Log (WAL)</p>
    <p>shipping</p>
    <p>Middle Tier</p>
    <p>scenarios</p>
    <p>changes</p>
    <p>Staging</p>
    <p>Database</p>
    <p>DBMS</p>
    <p>Test</p>
    <p>Database</p>
    <p>DBMS</p>
    <p>Test Environment</p>
  </div>
  <div class="page">
    <p>An idea</p>
    <p>How to conduct experiments?</p>
    <p>Exploit underutilized resources</p>
    <p>Where to conduct experiments?</p>
    <p>Production system, Standby system, Test system</p>
    <p>Need mechanisms and policies to</p>
    <p>utilize idle resources efficiently Mechanisms: Next slide</p>
    <p>Policies: If CPU, memory, &amp; disk utilization</p>
    <p>is below 10% for past 10 minutes, then</p>
    <p>resource X can be used for experiments</p>
  </div>
  <div class="page">
    <p>Mechanisms Production Environment</p>
    <p>Database</p>
    <p>DBMS</p>
    <p>Database</p>
    <p>DBMS</p>
    <p>Standby Environment</p>
    <p>Clients Clients Clients</p>
    <p>Write Ahead</p>
    <p>Log (WAL)</p>
    <p>shipping</p>
    <p>Middle Tier</p>
    <p>scenarios</p>
    <p>changes</p>
    <p>Staging</p>
    <p>Database</p>
    <p>DBMS</p>
    <p>Test</p>
    <p>Database</p>
    <p>DBMS</p>
    <p>Test Environment</p>
    <p>Enterprises that have 99.999% availability have</p>
    <p>standby databases that are 99.999% idle, Oracle</p>
    <p>DBAs handbook</p>
  </div>
  <div class="page">
    <p>Mechanisms: Workbench Standby Environment</p>
    <p>Database</p>
    <p>DBMS</p>
    <p>Production Environment</p>
    <p>Clients Clients Clients</p>
    <p>Database</p>
    <p>Write Ahe ad Log shipping</p>
    <p>Standby Machine</p>
    <p>Garage</p>
    <p>DBMS</p>
    <p>Workbe nch for conducting e xpe riments</p>
    <p>M iddle Tie r</p>
    <p>Interface</p>
    <p>Engine</p>
    <p>Policy Manager</p>
    <p>Experiment Planner &amp; Scheduler</p>
    <p>Copy on Write</p>
    <p>Home</p>
    <p>DBMS</p>
    <p>Apply WAL continuously</p>
    <p>Home</p>
    <p>Apply WAL continuously</p>
    <p>DBMS</p>
  </div>
  <div class="page">
    <p>Workbench features</p>
    <p>Implemented using Solaris OS</p>
    <p>Zones to isolate resources between home &amp; garage containers</p>
    <p>ZFS to create fast snapshots</p>
    <p>Dtrace for resource monitoring</p>
  </div>
  <div class="page">
    <p>Overhead of workbench Operation by workbench</p>
    <p>Time (sec) Description</p>
    <p>Create Container 610 Create a new garage (one time process)</p>
    <p>Clone Container 17 Clone a garage from already existing one</p>
    <p>Boot Container 19 Boot garage from halt state</p>
    <p>Halt Container 2 Stop garage and release resources</p>
    <p>Reboot Container 2 Reboot the garage</p>
    <p>Snapshot-R DB (5GB, 20GB)</p>
    <p>database</p>
    <p>Snapshot-RW DB (5GB, 20GB)</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Process output to</p>
    <p>extract information</p>
    <p>Plan next set of</p>
    <p>experiments</p>
    <p>How/where to conduct</p>
    <p>experiments?</p>
    <p>Yes</p>
    <p>Mgmt. taskResult</p>
    <p>Are more experiments</p>
    <p>needed?</p>
  </div>
  <div class="page">
    <p>Which experiments to run?</p>
    <p>Gridding</p>
    <p>Random Sampling</p>
    <p>Simulated Annealing</p>
    <p>Space-filling Sampling  Latin Hypercube Sampling  k-Furthest First Sampling</p>
    <p>Design of Experiments (Statistics)  Plackett-Burman</p>
    <p>Fractional Factorial</p>
    <p>Can we do better than above?</p>
  </div>
  <div class="page">
    <p>Our approach</p>
    <p>Adaptive Sampling</p>
    <p>Bootstrapping: Conduct initial set of</p>
    <p>experiments</p>
    <p>based on previous samples</p>
    <p>Stopping Criteria: Based on</p>
    <p>budget</p>
    <p>Main idea: 1. Compute the utility of the experiment</p>
  </div>
  <div class="page">
    <p>Results</p>
    <p>Empirical Setting</p>
    <p>PostgreSQL v8.2: Tuning up to 30 parameters</p>
    <p>3 Sun Solaris machines with 3 GB RAM, 1.8 GHz processor</p>
    <p>Workloads</p>
    <p>TPC-H benchmark</p>
    <p>SF = 1 (1GB, total database size = 5GB)</p>
    <p>SF = 10 (10GB, total database size = 20GB)</p>
    <p>TPC-W benchmark</p>
    <p>Synthetic response surfaces</p>
  </div>
  <div class="page">
    <p>Results on Real Response Surfaces</p>
    <p>Simple Workload: W1-SF1 TPC-H Q18, Large Volume Customer Query</p>
    <p>Complex Workload: W2-SF1 Random mix of 100 TPC-H Queries</p>
  </div>
  <div class="page">
    <p>Results on Real Response Surfaces</p>
    <p>Complex Workload: W2-SF10 Random mix of 100 TPC-H Queries</p>
    <p>Complex Workload: W2-SF1 Random mix of 100 TPC-H Queries</p>
  </div>
  <div class="page">
    <p>Comparison of Tuning Quality</p>
  </div>
  <div class="page">
    <p>Comparison of Tuning time</p>
    <p>BruteForce AdaptiveSampling</p>
    <p>W1-SF1 8 hours 1.4 hours</p>
    <p>W2-SF1 21.7 days 4.6 days</p>
    <p>W2-SF10 68 days 14.8 days</p>
    <p>Cutoff time for each query : 90 minutes</p>
    <p>We further reduced the time using techniques</p>
    <p>Workload compression</p>
    <p>Database specific information</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Experiment-driven management is an</p>
    <p>essential part of system administration</p>
    <p>Our premise: Experiments should be supported as first-class citizens in systems</p>
    <p>Compliments existing approaches</p>
    <p>Experiments in the cloud  the time has</p>
    <p>come!</p>
  </div>
  <div class="page">
    <p>Q &amp; A</p>
    <p>Thanks!</p>
  </div>
</Presentation>
