<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Modeling Online Reviews</p>
    <p>with Multi-grain Topic Models</p>
    <p>Ivan Titov1 and Ryan McDonald2</p>
  </div>
  <div class="page">
    <p>Online User Reviews</p>
  </div>
  <div class="page">
    <p>Sentiment Classification</p>
    <p>Sentiment and Opinion Classification (Wiebe, 00), (Pang et al, 02), (Turney, 02)</p>
    <p>However, sentiment is often provided by the user  Isnt this just a contrived task?</p>
    <p>Not always:  Train sentiment classifiers on reviews use it 4</p>
    <p>blogs</p>
    <p>Train review ratings, apply on phrases or sentences</p>
    <p>Train on one blog, apply to unannotated blogs</p>
  </div>
  <div class="page">
    <p>Sentiment Summarization  Take a set of reviews for an entity and summarize</p>
    <p>them</p>
    <p>Aspect-based summarization (Hu &amp; Liu 2004)  Summarize along key aspects</p>
    <p>Many real world manual examples, e.g., Zagat.com</p>
  </div>
  <div class="page">
    <p>Text Segmentation</p>
    <p>Focus on models for segmenting text</p>
  </div>
  <div class="page">
    <p>Previous</p>
    <p>Work</p>
    <p>Hu and Liu 04  Aspect-based summarization  String-based aspects + lexicon sentiment</p>
    <p>Popescu and Etzioni 05: Opine system  Gamon et al. 05</p>
    <p>Aspect clusters: use most frequent word label  Carenini 06</p>
    <p>String-based + ontologies  Mei et al. 07</p>
    <p>Generative topic-sentiment models (at document level)</p>
  </div>
  <div class="page">
    <p>Three Tasks</p>
    <p>Identify Aspects  Often we know this (pros-cons, tech specs, ontologies)</p>
    <p>Extract Mentions  We always have to do this</p>
    <p>Aggregate Sentiment  Again, we often know this (star ratings, eg, TripAdvisor)</p>
  </div>
  <div class="page">
    <p>Aspect Identification</p>
    <p>and Extraction</p>
    <p>Common method: String-based extraction  Find frequently occurring nouns that are modified</p>
    <p>by opinion words</p>
    <p>Take top K as relevant aspects  Extract all sentences / phrases that match  Problem: Get a long list of aspects w/ no clustering</p>
  </div>
  <div class="page">
    <p>Aspect Identification and Extraction</p>
    <p>food</p>
    <p>place</p>
    <p>pizza</p>
    <p>service</p>
    <p>restaurant</p>
    <p>atmosphere</p>
    <p>time</p>
    <p>wine</p>
    <p>meal</p>
    <p>prices</p>
    <p>value</p>
    <p>sauce</p>
    <p>hour</p>
    <p>price</p>
    <p>dim</p>
    <p>selection</p>
    <p>experience</p>
    <p>crust</p>
    <p>dining</p>
    <p>ingredients</p>
    <p>General</p>
    <p>Food</p>
    <p>Ambiance</p>
    <p>Service</p>
    <p>Value</p>
    <p>String-based example: restaurants  Is list really summarization?  How far down to get cozy, fish,</p>
    <p>$, waitress, dark?</p>
    <p>We really want to cluster these</p>
  </div>
  <div class="page">
    <p>Topic Models</p>
    <p>Studied in ML and Data Mining  LSA, PLSA, LDA, Pachinko Allocation, ...</p>
    <p>Build semantic topics of data collections  e.g., newsgroups into religion, politics,</p>
    <p>science, ...</p>
    <p>Simple hypothesis  Topics in reviews correspond to clustered aspects</p>
    <p>We will focus on LDA type models (Blei et al. 03)  Others produce similar observations</p>
  </div>
  <div class="page">
    <p>LDA</p>
    <p>Generative model of text  Sample multinomial word</p>
    <p>distributions for each topic</p>
    <p>The for each document d:</p>
  </div>
  <div class="page">
    <p>Side Note: Inference</p>
    <p>All methods use collapsed Gibbs (Griffiths &amp; Steyvers 04)</p>
    <p>A sample from the chain used to approx:  Distribution of words in topics  Distribution of topics in text fragments</p>
    <p>We tried variational techniques, but they didnt work for our models</p>
    <p>More details in the paper</p>
  </div>
  <div class="page">
    <p>LDA</p>
    <p>Problem with LDA (and most other topic models)  Co-occurrences modeled at document level  Topics are about instances not aspects</p>
    <p>e.g., iPod versus Creative Labs  Often clusters are meaningless</p>
    <p>(Service??) Topic 0: product player did support bought work unit problem $</p>
    <p>(Creative Labs) Topic 1: gigabeat deleted waiting jukebox creative playback</p>
    <p>(iPod) Topic 11: ipod apple mac firewire dock itunes x display aac</p>
    <p>Most topics are incoherent. Only 4 out of first 40 can be viewed as aspects.</p>
  </div>
  <div class="page">
    <p>LDA</p>
    <p>Simple solutions: LDA over sentences  Co-occurrence counts too sparse  Can use sliding window, but results look like LDA  Still cant distinguish aspect topics from the rest</p>
    <p>Another solution: Multi-grain topic models  Model local topics (aspects) and global topics (types)  Creates a bottleneck for local topics  Words generated from sliding windows</p>
  </div>
  <div class="page">
    <p>Varying Granularity</p>
    <p>Global topic London: London, tube,  , Tower, Thames  Global topic dist is assigned to the document</p>
    <p>Local topics:  Location: transport, station, walk, bus, minute  View: view, window  Local topic dist is assigned to current sliding window</p>
    <p>... public transport in London is straightforward, the tube</p>
    <p>station is about an 8 minute walk  or you can get a bus</p>
    <p>for  1.50 ....</p>
    <p>We had a stunning view (from the floor to ceiling window)</p>
    <p>of the Tower and the Thames.</p>
  </div>
  <div class="page">
    <p>MG-LDA  Draw global topic word</p>
    <p>dist.</p>
    <p>Draw local topic word dist.  For each document d:</p>
  </div>
  <div class="page">
    <p>Multi-Grain models</p>
    <p>For local topics instead of sliding windows we could use topical ngrams (Wang and McCallum 05,</p>
    <p>Wallach 06)</p>
    <p>But topical ngrams are computationally expensive  Efficiency of MG-LDA is comparable with that of LDA  Crucial property is that the topic distributions are</p>
    <p>associated with different scopes in a text</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Qualitative comparison of LDA and MG-LDA topics  Quantitative comparison: improving multi-aspect</p>
    <p>ranking by using information about topic distribution</p>
  </div>
  <div class="page">
    <p>Qualitative Evaluation</p>
    <p>Data: 3,872 reviews of MP3 players, 32,861 reviews of hotels and 32,563 reviews of restaurants (from</p>
    <p>Google Product and Local Search)</p>
    <p>Stop words and punctuation are removed</p>
  </div>
  <div class="page">
    <p>MG-LDA Topics (Mp3) First 8 Local Topics!!</p>
    <p>First 4 Global Topics</p>
    <p>LDA</p>
    <p>- 40 topics</p>
    <p>- Only 4 aspect topics</p>
    <p>- A couple other coherent topics</p>
    <p>- Good topics in no order</p>
    <p>- Mostly junk topics</p>
    <p>iPod Creative Zen Sony</p>
    <p>Walkman</p>
    <p>Video</p>
    <p>Players</p>
    <p>ipod zen sony video</p>
    <p>music creative Zen walkman screen</p>
    <p>apple micro memory videos</p>
    <p>songs touch stick device</p>
    <p>use xtra sonicstage photos</p>
    <p>mini pad players tv</p>
    <p>very nomad atrac3 archos</p>
    <p>just waiting mb pictures</p>
    <p>itunes labs atrac camera</p>
    <p>Sound</p>
    <p>Quality</p>
    <p>sound</p>
    <p>quality</p>
    <p>headphones</p>
    <p>volume</p>
    <p>bass</p>
    <p>earphones</p>
    <p>ear</p>
    <p>rock</p>
    <p>settings</p>
    <p>Features</p>
    <p>games</p>
    <p>features</p>
    <p>clock</p>
    <p>contacts</p>
    <p>calendar</p>
    <p>alarm</p>
    <p>notes</p>
    <p>game</p>
    <p>quiz</p>
    <p>PC</p>
    <p>Connection</p>
    <p>usb</p>
    <p>pc</p>
    <p>windows</p>
    <p>port</p>
    <p>transfer</p>
    <p>computer</p>
    <p>mac</p>
    <p>software</p>
    <p>cable</p>
    <p>Tech</p>
    <p>Problems</p>
    <p>reset</p>
    <p>noise</p>
    <p>backlight</p>
    <p>slow</p>
    <p>freeze</p>
    <p>turn</p>
    <p>remove</p>
    <p>playing</p>
    <p>hot</p>
    <p>Looks</p>
    <p>case</p>
    <p>pocket</p>
    <p>silver</p>
    <p>screen</p>
    <p>plastic</p>
    <p>clip</p>
    <p>easily</p>
    <p>small</p>
    <p>blue</p>
    <p>Controls</p>
    <p>button</p>
    <p>play</p>
    <p>track</p>
    <p>menu</p>
    <p>song</p>
    <p>buttons</p>
    <p>volume</p>
    <p>album</p>
    <p>tracks</p>
    <p>Battery</p>
    <p>battery</p>
    <p>hours</p>
    <p>life</p>
    <p>batteries</p>
    <p>charge</p>
    <p>aaa</p>
    <p>rechargeable</p>
    <p>time</p>
    <p>power</p>
    <p>Accessories</p>
    <p>usb</p>
    <p>cable</p>
    <p>headphones</p>
    <p>adapter</p>
    <p>remote</p>
    <p>plug</p>
    <p>power</p>
    <p>charger</p>
    <p>included</p>
  </div>
  <div class="page">
    <p>MG-LDA vs. LDA (Hotels)MG-LDA: first 8 Local Topics!! Amenities</p>
    <p>coffee</p>
    <p>microwave</p>
    <p>fridge</p>
    <p>tv</p>
    <p>ice</p>
    <p>room</p>
    <p>refrigerator</p>
    <p>machine</p>
    <p>kitchen</p>
    <p>Food/Drink</p>
    <p>food</p>
    <p>restaurant</p>
    <p>bar</p>
    <p>good</p>
    <p>dinner</p>
    <p>service</p>
    <p>breakfast</p>
    <p>ate</p>
    <p>eat</p>
    <p>Noise/AC</p>
    <p>air</p>
    <p>noise</p>
    <p>door</p>
    <p>room</p>
    <p>hear</p>
    <p>open</p>
    <p>night</p>
    <p>conditioning</p>
    <p>loud</p>
    <p>Bathroom</p>
    <p>shower</p>
    <p>water</p>
    <p>bathroom</p>
    <p>hot</p>
    <p>towels</p>
    <p>toilet</p>
    <p>tub</p>
    <p>bath</p>
    <p>sink</p>
    <p>Breakfast</p>
    <p>breakfast</p>
    <p>coffee</p>
    <p>continental</p>
    <p>morning</p>
    <p>fruit</p>
    <p>fresh</p>
    <p>buffet</p>
    <p>included</p>
    <p>free</p>
    <p>Spa</p>
    <p>pool</p>
    <p>area</p>
    <p>hot</p>
    <p>tub</p>
    <p>indoor</p>
    <p>nice</p>
    <p>swimming</p>
    <p>outdoor</p>
    <p>fitness</p>
    <p>Parking</p>
    <p>parking</p>
    <p>car</p>
    <p>park</p>
    <p>lot</p>
    <p>valet</p>
    <p>garage</p>
    <p>free</p>
    <p>street</p>
    <p>parked</p>
    <p>Staff</p>
    <p>staff</p>
    <p>friendly</p>
    <p>helpful</p>
    <p>very</p>
    <p>desk</p>
    <p>extremely</p>
    <p>help</p>
    <p>directions</p>
    <p>courteous</p>
    <p>LDA: examples of LDA topics (out of 45), only 9 aspect topics</p>
    <p>Beach</p>
    <p>resorts</p>
    <p>beach</p>
    <p>great</p>
    <p>pool</p>
    <p>very</p>
    <p>place</p>
    <p>ocean</p>
    <p>stay</p>
    <p>view</p>
    <p>just</p>
    <p>Las Vegas</p>
    <p>vegas</p>
    <p>strip</p>
    <p>great</p>
    <p>casino</p>
    <p>$</p>
    <p>good</p>
    <p>hotel</p>
    <p>food</p>
    <p>las</p>
    <p>?</p>
    <p>motel</p>
    <p>rooms</p>
    <p>nice</p>
    <p>hotel</p>
    <p>like</p>
    <p>place</p>
    <p>stay</p>
    <p>parking</p>
    <p>price</p>
    <p>Smells/</p>
    <p>stains?</p>
    <p>room</p>
    <p>did</p>
    <p>smoking</p>
    <p>bed</p>
    <p>night</p>
    <p>went</p>
    <p>like</p>
    <p>desk</p>
    <p>smoke</p>
    <p>Getting</p>
    <p>there</p>
    <p>airport</p>
    <p>hotel</p>
    <p>shuttle</p>
    <p>bus</p>
    <p>very</p>
    <p>minutes</p>
    <p>flight</p>
    <p>hour</p>
    <p>free</p>
    <p>Breakfast</p>
    <p>breakfast</p>
    <p>coffee</p>
    <p>fruit</p>
    <p>room</p>
    <p>juice</p>
    <p>fresh</p>
    <p>eggs</p>
    <p>continental</p>
    <p>very</p>
    <p>Front desk</p>
    <p>room</p>
    <p>hotel</p>
    <p>told</p>
    <p>desk</p>
    <p>did</p>
    <p>manager</p>
    <p>asked</p>
    <p>said</p>
    <p>service</p>
    <p>Opinion</p>
    <p>hotel</p>
    <p>best</p>
    <p>stay</p>
    <p>hotels</p>
    <p>stayed</p>
    <p>reviews</p>
    <p>service</p>
    <p>great</p>
    <p>time</p>
  </div>
  <div class="page">
    <p>Local LDA</p>
    <p>LDA applied on individual sentences (Local LDA) on MP3 reviews:</p>
    <p>Infers a number of valid aspects  Still many are related to brands of MP3 players</p>
    <p>(ipod, sony, yepp,...)</p>
    <p>Simultaneous modeling of both local and global topics is important for discovery of coherent aspects</p>
  </div>
  <div class="page">
    <p>Restaurant Reviews</p>
    <p>Restaurant reviews are challenging, only the following aspects are inferred:</p>
    <p>MG-LDA : service, location, atmosphere and decor  LDA: waiting time and location</p>
    <p>Challenge: majority of aspects are specific for a type of restaurants: pizza and pasta for a Italian rest., sushi and noodles for Japanese</p>
    <p>Good results with MG-LDA when applied to a specific restaurant type (9 aspects are inferred for Italian).</p>
    <p>Hierarchical topic modeling could address this problem</p>
  </div>
  <div class="page">
    <p>Quantitative Evaluation</p>
    <p>We wish to evaluate how well the learned topics correspond to aspects that users typically rate</p>
    <p>Multi-aspect opinion rating (Snyder and Barzilay,07):  predicting a rating for multiple aspects of an object</p>
    <p>Data: 27,564 reviews labeled reviews from TripAdvisor</p>
  </div>
  <div class="page">
    <p>Using a topic model</p>
    <p>Information about a topic of a sentence should help a classifier:</p>
    <p>The X was great,  X  is duck, steak, soup - food rating is high  X  is music, light  atmosphere rating is high</p>
    <p>We extended standard ngram features of text x by adding top topics and their bucketed probabilities:</p>
    <p>x contains great &amp; topic = 3 &amp; bucket = 0.4-0.5</p>
  </div>
  <div class="page">
    <p>Results</p>
    <p>Ranking loss: (lower  better)</p>
    <p>PRank (Crammer and Singer, 02)  perceptron for ranking</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>We demonstrated that:  topic models are appropriate for discovery of</p>
    <p>aspects in user reviews</p>
    <p>simultaneous modeling of both local and global topics is important for discovery of coherent</p>
    <p>ratable aspects</p>
  </div>
  <div class="page">
    <p>Future/Recent work</p>
    <p>Integrating user annotation for topic discovery:  (Titov and McDonald, ACL 2008)</p>
    <p>Hierarchical topic modeling  E.g, infer a hierarchy representing cuisines and</p>
    <p>with each cuisine extract cuisine specific aspects</p>
    <p>Combining aspect extraction with sentiment classification:</p>
    <p>Examining joint models of topics and sentiment (Mei et al, 07)</p>
  </div>
</Presentation>
