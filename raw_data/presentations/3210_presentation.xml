<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Scheduler-based Defenses against Cross-VM Side-channels</p>
    <p>Venkat(anathan) Varadarajan, Thomas Ristenpart, and Michael Swi6</p>
  </div>
  <div class="page">
    <p>V M M</p>
    <p>Public Clouds (EC2, Azure, Rackspace, )</p>
    <p>VM</p>
    <p>Mul2-tenancy Different customers virtual machines (VMs) share same server</p>
    <p>VM</p>
    <p>VM</p>
    <p>V M M</p>
    <p>V M M VM</p>
    <p>V M M</p>
    <p>VM</p>
    <p>V M M</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM</p>
    <p>Benefits: 1. High resource uDlizaDon, 2. Low service cost</p>
    <p>VM</p>
  </div>
  <div class="page">
    <p>Core</p>
    <p>Private Caches</p>
    <p>Branch Predictor</p>
    <p>Shared Resources and Isolation</p>
    <p>VM (m-VCPUs)</p>
    <p>Hypervisor</p>
    <p>Core</p>
    <p>Private Caches</p>
    <p>Branch Predictor</p>
    <p>VM (m-VCPUs)</p>
    <p>VM (m-VCPUs)</p>
    <p>VM (m-VCPUs)</p>
    <p>VM (m-VCPUs)</p>
    <p>VM (m-VCPUs)</p>
    <p>System shared resources (LLC, memory, disk, n/w etc.)</p>
    <p>via per-core sharing [Zhang et al12, Ristenpart al09]</p>
    <p>via system-level sharing [Yarom &amp; Falkner14, Varadarajan et al12]</p>
    <p>Core</p>
    <p>Private Caches</p>
    <p>Branch Predictor</p>
  </div>
  <div class="page">
    <p>Problem: Cache-based Side-channels*</p>
    <p>VM</p>
    <p>VM</p>
    <p>Time</p>
    <p>Core: A V</p>
    <p>cache sets</p>
    <p>cache ways</p>
    <p>Prime</p>
    <p>A</p>
    <p>Probe</p>
    <p>A[acker Timing Profile</p>
    <p>Extract secret informaDon</p>
    <p>CRYPTO_FUNCTION(s): s  secret bit if (s = 0) { OPERATION_A } if (s = 1) { OPERATION_B }</p>
    <p>Secret</p>
    <p>*Zhang, Juels, Reiter, Ristenpart, Cross-VM Side-channels , CCS12</p>
    <p>I-cache</p>
  </div>
  <div class="page">
    <p>Requirements for Successful Side-channel</p>
    <p>VM</p>
    <p>VM</p>
    <p>Time</p>
    <p>Core: A V</p>
    <p>cache sets</p>
    <p>cache ways</p>
    <p>Prime</p>
    <p>A</p>
    <p>Probe</p>
    <p>A[acker Timing Profile</p>
    <p>Extract secret informaDon</p>
    <p>CRYPTO_FUNCTION(s): s  secret bit if (s = 0) { OPERATION_A } if (s = 1) { OPERATION_B }</p>
    <p>Secret</p>
    <p>*Zhang, Juels, Reiter, Ristenpart, Cross-VM Side-channels , CCS12</p>
    <p>I-cache quick preemp2on</p>
    <p>shared resource</p>
    <p>high-precision 2mer</p>
  </div>
  <div class="page">
    <p>Defenses against Side-channels 1. Sharing  Resource ParDDoning [NoHype10]  Specialized Hardware [RPcache07]  So6ware-based parDDoning [StealthMem12]</p>
    <p>No countermeasures deployed by providers!</p>
  </div>
  <div class="page">
    <p>Our Solution: Soft Isolation</p>
    <p>Allow sharing but limit frequency of dangerous VM interacDons Goals: 1. Secure: Controlled informaDon leakage 2. Commodity: Easy to adopt 3. Efficient: Allow sharing, low overhead</p>
    <p>with simple changes to Hypervisors CPU scheduler</p>
    <p>Core</p>
    <p>(per core state)</p>
    <p>Private Caches</p>
    <p>VM</p>
    <p>VM</p>
    <p>Hypervisor</p>
  </div>
  <div class="page">
    <p>Rest of the talk</p>
  </div>
  <div class="page">
    <p>Requirement for Quick Preemptions</p>
    <p>VM</p>
    <p>VM</p>
    <p>V</p>
    <p>Time</p>
    <p>Core: A</p>
    <p>cache sets</p>
    <p>Prime</p>
    <p>A</p>
    <p>Probe</p>
    <p>cache ways</p>
    <p>Preemp2on Interval</p>
    <p>V V</p>
    <p>Rate of preemp2on &gt; Rate of event to measure</p>
    <p>CRYPTO_FUNCTION(s): s  secret bit if (s = 0) { OPERATION_A } if (s = 1) { OPERATION_B }</p>
    <p>Next subsequent code/task execuDon  (or noise)</p>
  </div>
  <div class="page">
    <p>Why do schedulers allow quick preemptions?</p>
    <p>Prime-probe aUacker: Abuses BOOST priority, using interrupts.</p>
    <p>Throughput- oriented: Benefits from longer scheduler Dmeslices</p>
    <p>Latency-oriented: Benefits from quick wakeups , BOOST priority</p>
    <p>State-of-art CPU schedulers</p>
    <p>V</p>
    <p>Time</p>
    <p>Core: A V A</p>
    <p>&lt; 10s</p>
    <p>Batch VMs Interac2ve VMs</p>
    <p>Malicious VM</p>
  </div>
  <div class="page">
    <p>V</p>
    <p>Time</p>
    <p>A A</p>
    <p>Min. run2me (scheduler parameter)</p>
    <p>Interrupt (boosted)</p>
    <p>V V</p>
    <p>Soft-Isolation: Ratelimit Preemptions</p>
    <p>VM</p>
    <p>VM</p>
    <p>Core:</p>
    <p>Available in Xen (and KVM)  ratelimit_us (and sched_min_granularity_ns)!  Reduces VM-switches  Boosts batch-workloads performance</p>
    <p>Minimum RunTime (MRT) guarantee  soP-isola2on</p>
  </div>
  <div class="page">
    <p>MRT Guarantee and Open Questions</p>
    <p>Time Core: A V V</p>
    <p>delay</p>
    <p>MRT value</p>
  </div>
  <div class="page">
    <p>Xen Version 4.2.1</p>
    <p>Scheduler Credit Scheduler 1 Configura2on</p>
    <p>(Non-work conserving) 40% cap on DomU VCPUs</p>
    <p>with equal weight # VMs 6</p>
    <p># VCPUs per VM 2</p>
    <p>Experimental Methodology</p>
    <p>Two VMs: 1. A[acker 2. VicDm</p>
    <p>Machine Intel Xeon E5645, 2.4GHz, 6 cores, single package</p>
    <p>Memory Hierarchy</p>
    <p>Private 32KB L1 (I- and D- Cache), 256KB unified L2, 12MB shared L3 &amp; 16GB</p>
    <p>DDR3 RAM.</p>
    <p>Machine Configura2on Xen Configura2on</p>
    <p>Core</p>
    <p>VM</p>
    <p>VM</p>
    <p>Hypervisor</p>
    <p>Se`ng similar to public clouds (e.g. EC2)</p>
  </div>
  <div class="page">
    <p>Security Evaluation :  Prime-Probe Timing Profile</p>
    <p>Idle VicDm VM Simple VicDm VM Under Zero-MRT</p>
    <p>AlternaDng usage pa[ern i-cache access Dming</p>
  </div>
  <div class="page">
    <p>Security Evaluation :  Prime-Probe Timing Profile</p>
    <p>Simple VicDm VM Under Zero-MRT</p>
    <p>Simple VicDm VM Under 1ms MRT</p>
    <p>Side-channel not discernible AlternaDng usage pa[ern</p>
  </div>
  <div class="page">
    <p>Security Evaluation:  ElGamal Victim</p>
    <p>Minimum number of itera2ons per preemp2on</p>
    <p>Avg: 0.096 ops</p>
    <p>SQUAREMULT(x, e, N): Let en , ..., e1 be the bits of e y  1 for i = n down to 1 do y  SQUARE(y) y  MODREDUCE(y, N) if ei = 1 then y  MULT(y, x) y  MODREDUCE(y, N) end if end for return y</p>
    <p>ElGamal Side-channel require mul2ple preemp2ons within single itera2on for noise-reduc2on [Zhang et al12]</p>
  </div>
  <div class="page">
    <p>MRT Guarantee and Open Questions</p>
    <p>Time Core: A V V</p>
    <p>delay</p>
  </div>
  <div class="page">
    <p>Performance Evaluation:  Overall System Performance</p>
    <p>Core Core</p>
    <p>Core Core</p>
    <p>VCPU</p>
    <p>VCPU</p>
    <p>VCPU VCPU</p>
    <p>VCPU VCPU</p>
    <p>Hypervisor</p>
    <p>workload-mix Measured workload: 1. Interac=ve  memcached,</p>
    <p>cassandra, etc. and 2. Batch  graph500, specJBB, etc.</p>
    <p>Compe2ng workloads: microbenchmarks  highly cache-thrashing + (interacDve or batch)</p>
  </div>
  <div class="page">
    <p>Performance Evaluation:  Overall System Performance</p>
    <p>N or m al iz ed</p>
    <p>t o Ze ro -M</p>
    <p>RT</p>
    <p>All-Batch All-InteracDve InteracDve-Batch Idle</p>
    <p>Avg. 95th PercenDle Latency (interacDve workloads)</p>
    <p>Avg. RunDme (batch workloads)</p>
    <p>At 5ms MRT &lt; 7% overhead</p>
  </div>
  <div class="page">
    <p>More details in the paper</p>
    <p>Per-core State-Cleansing  InteracDve VMs may sDll leak informaDon  MRT + State-cleansing incur low overhead</p>
    <p>Detailed Performance and Security Analysis  20+ graphs in the paper</p>
    <p>It is cheap and easy to deploy!</p>
  </div>
  <div class="page">
    <p>Conclusion 5ms MRT + selec2ve state-cleansing - known a[acks no longer work - negligible overhead - easy to adopt Introduce new scheduler principle - soD-isola=on = allow sharing + limit dangerous cross-VM interac=ons</p>
    <p>h[ps://bitbucket.org/vvaradarajan/robsched</p>
    <p>contact: venkatv@cs.wisc.edu 21</p>
  </div>
</Presentation>
