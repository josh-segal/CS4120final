<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Implicit and Explicit Optimizations for Stencil Computations</p>
    <p>By Shoaib Kamil1,2, Kaushik Datta1, Samuel Williams1,2, Leonid Oliker2, John Shalf2 and Katherine A. Yelick1,2</p>
    <p>October 22, 2006</p>
    <p>http://bebop.cs.berkeley.edu kdatta@eecs.berkeley.edu</p>
  </div>
  <div class="page">
    <p>What are stencil codes?</p>
    <p>For a given point, a stencil is a pre-determined set of nearest neighbors (possibly including itself)</p>
    <p>A stencil code updates every point in a regular grid with a weighted subset of its neighbors (applying a stencil)</p>
  </div>
  <div class="page">
    <p>Stencil Applications</p>
    <p>Stencils are critical to many scientific applications:  Diffusion, Electromagnetics, Computational Fluid Dynamics  Both explicit and implicit iterative methods (e.g. Multigrid)  Both uniform and adaptive block-structured meshes</p>
    <p>Many type of stencils  1D, 2D, 3D meshes  Number of neighbors (5</p>
    <p>pt, 7-pt, 9-pt, 27-pt,)  Gauss-Seidel (update in</p>
    <p>place) vs Jacobi iterations (2 meshes)</p>
    <p>Our study focuses on 3D, 7-point, Jacobi iteration</p>
  </div>
  <div class="page">
    <p>Nave Stencil Pseudocode (One iteration)</p>
    <p>void stencil3d(double A[], double B[], int nx, int ny, int nz) { for all grid indices in x-dim { for all grid indices in y-dim { for all grid indices in z-dim { B[center] = S0* A[center] +</p>
    <p>S1*(A[top] + A[bottom] + A[left] + A[right] +</p>
    <p>A[front] + A[back]); }</p>
    <p>} } }</p>
  </div>
  <div class="page">
    <p>Potential Optimizations</p>
    <p>Performance is limited by memory bandwidth and latency  Re-use is limited to the number of neighbors in a stencil  For large meshes (e.g., 5123), cache blocking helps  For smaller meshes, stencil time is roughly the time to read the</p>
    <p>mesh once from main memory  Tradeoff of blocking: reduces cache misses (bandwidth), but</p>
    <p>increases prefetch misses (latency)  See previous paper for details [Kamil et al, MSP 05]</p>
    <p>We look at merging across iterations to improve reuse  Three techniques with varying level of control</p>
    <p>We vary architecture types  Significant work (not shown) on low level optimizations</p>
  </div>
  <div class="page">
    <p>Optimization Strategies</p>
    <p>O b liv</p>
    <p>io u s</p>
    <p>(I m</p>
    <p>p lic</p>
    <p>it )</p>
    <p>C on</p>
    <p>sc io</p>
    <p>u s</p>
    <p>(E xp</p>
    <p>lic it )</p>
    <p>S of</p>
    <p>tw ar</p>
    <p>e</p>
    <p>Cache (Implicit)</p>
    <p>Local Store (Explicit)</p>
    <p>Hardware</p>
    <p>Cache Oblivious</p>
    <p>Cache Conscious</p>
    <p>Cache Conscious</p>
    <p>on Cell</p>
    <p>N/A</p>
    <p>Two software techniques  Cache oblivious algorithm</p>
    <p>recursively subdivides  Cache conscious has an</p>
    <p>explicit block size  Two hardware techniques</p>
    <p>Fast memory (cache) is managed by hardware</p>
    <p>Fast memory (local store) is managed by application software</p>
    <p>If hardware forces control, software cannot be oblivious</p>
  </div>
  <div class="page">
    <p>Opt. Strategy #1: Cache Oblivious</p>
    <p>O b liv</p>
    <p>io u s</p>
    <p>(I m</p>
    <p>p lic</p>
    <p>it )</p>
    <p>C on</p>
    <p>sc io</p>
    <p>u s</p>
    <p>(E xp</p>
    <p>lic it )</p>
    <p>S of</p>
    <p>tw ar</p>
    <p>e</p>
    <p>Cache (Implicit)</p>
    <p>Local Store (Explicit)</p>
    <p>Hardware</p>
    <p>Cache Oblivious</p>
    <p>Cache Conscious</p>
    <p>Cache Conscious</p>
    <p>on Cell</p>
    <p>N/A</p>
    <p>Two software techniques  Cache oblivious algorithm</p>
    <p>recursively subdivides  Elegant Solution  No explicit block size  No need to tune block size</p>
    <p>Cache conscious has an explicit block size</p>
    <p>Two hardware techniques  Cache managed by hw</p>
    <p>Less programmer effort</p>
    <p>Local store managed by sw</p>
  </div>
  <div class="page">
    <p>Cache Oblivious Algorithm</p>
    <p>By Matteo Frigo et al  Recursive algorithm consists of space cuts, time cuts, and a base case  Operates on well-defined trapezoid (x0, dx0, x1, dx1, t0, t1):</p>
    <p>Trapezoid for 1D problem; our experiments are for 3D (shrinking cube)</p>
    <p>tim e</p>
    <p>space x1x0</p>
    <p>t1</p>
    <p>t0</p>
    <p>dx1dx0</p>
  </div>
  <div class="page">
    <p>Cache Oblivious Algorithm - Base Case</p>
    <p>If the height=1, then we have a line of points (x0:x1, t0):</p>
    <p>At this point, we stop the recursion and perform the stencil on this set of points</p>
    <p>Order does not matter since there are no inter-dependencies</p>
    <p>tim e</p>
    <p>space x1x0</p>
    <p>t1 t0</p>
  </div>
  <div class="page">
    <p>Cache Oblivious Algorithm - Space Cut</p>
    <p>If trapezoid width &gt;= 2*height, cut with slope=-1 through the center:</p>
    <p>Since no point in Tr1 depends on Tr2, execute Tr1 first and then Tr2</p>
    <p>In multiple dimensions, we try space cuts in each dimension before proceeding</p>
    <p>tim e</p>
    <p>space x1x0</p>
    <p>t1</p>
    <p>t0</p>
    <p>Tr1 Tr2</p>
  </div>
  <div class="page">
    <p>Cache Oblivious Algorithm - Time Cut</p>
    <p>Otherwise, cut the trapezoid in half in the time dimension:</p>
    <p>Again, since no point in Tr1 depends on Tr2, execute Tr1 first and then Tr2</p>
    <p>tim e</p>
    <p>space x1x0</p>
    <p>t1</p>
    <p>t0 Tr1</p>
    <p>Tr2</p>
  </div>
  <div class="page">
    <p>Poor Itanium 2 Cache Oblivious Performance</p>
    <p>Cycle ComparisonL3 Cache Miss Comparison</p>
    <p>Fewer cache misses BUT longer running time</p>
  </div>
  <div class="page">
    <p>Poor Cache Oblivious Performance</p>
    <p>Power5 Cycle ComparisonOpteron Cycle Comparison</p>
    <p>Much slower on Opteron and Power5 too</p>
  </div>
  <div class="page">
    <p>Improving Cache Oblivious Performance</p>
    <p>Fewer cache misses did NOT translate to better performance:</p>
    <p>Early cut off of recursion Recursion even after block fits in cache</p>
    <p>Pre-computed lookup arrayModulo Operator</p>
    <p>Maintain explicit stackRecursion stack overhead</p>
    <p>No cuts in unit-stride dimension</p>
    <p>Poor prefetch behavior</p>
    <p>Inlined kernelExtra function calls</p>
    <p>SolutionProblem</p>
  </div>
  <div class="page">
    <p>Cache Oblivious Performance</p>
    <p>Only Opteron shows any benefit</p>
  </div>
  <div class="page">
    <p>Opt. Strategy #2: Cache Conscious</p>
    <p>O b liv</p>
    <p>io u s</p>
    <p>(I m</p>
    <p>p lic</p>
    <p>it )</p>
    <p>C on</p>
    <p>sc io</p>
    <p>u s</p>
    <p>(E xp</p>
    <p>lic it )</p>
    <p>S of</p>
    <p>tw ar</p>
    <p>e</p>
    <p>Cache (Implicit)</p>
    <p>Local Store (Explicit)</p>
    <p>Hardware</p>
    <p>Cache Oblivious</p>
    <p>Cache Conscious</p>
    <p>Cache Conscious</p>
    <p>on Cell</p>
    <p>N/A</p>
    <p>Two software techniques  Cache oblivious algorithm</p>
    <p>recursively subdivides  Cache conscious has an</p>
    <p>explicit block size  Easier to visualize  Tunable block size  No recursion stack</p>
    <p>overhead</p>
    <p>Two hardware techniques  Cache managed by hw</p>
    <p>Less programmer effort</p>
    <p>Local store managed by sw</p>
  </div>
  <div class="page">
    <p>Like the cache oblivious algorithm, we have space cuts  However, cache conscious is NOT recursive and explicitly</p>
    <p>requires cache block dimension c as a parameter</p>
    <p>Again, trapezoid for a 1D problem above</p>
    <p>Cache Conscious Algorithm tim e</p>
    <p>space x1x0</p>
    <p>t1</p>
    <p>t0</p>
    <p>dx1dx0 Tr1 Tr2 Tr3</p>
    <p>c c c</p>
  </div>
  <div class="page">
    <p>Cache Conscious - 3D Animation</p>
  </div>
  <div class="page">
    <p>Cache Conscious - 3D Animation</p>
  </div>
  <div class="page">
    <p>Cache Conscious - 3D Animation</p>
  </div>
  <div class="page">
    <p>Cache Conscious - 3D Animation</p>
  </div>
  <div class="page">
    <p>Cache Conscious - 3D Animation</p>
  </div>
  <div class="page">
    <p>Cache Conscious - 3D Animation</p>
  </div>
  <div class="page">
    <p>Cache Conscious - 3D Animation</p>
  </div>
  <div class="page">
    <p>Cache Conscious - 3D Animation</p>
  </div>
  <div class="page">
    <p>Cache Conscious - 3D Animation</p>
  </div>
  <div class="page">
    <p>Cache Conscious - 3D Animation</p>
  </div>
  <div class="page">
    <p>Cache Conscious - 3D Animation</p>
  </div>
  <div class="page">
    <p>Cache Conscious - 3D Animation</p>
  </div>
  <div class="page">
    <p>Cache Conscious - 3D Animation</p>
  </div>
  <div class="page">
    <p>Cache Conscious - 3D Animation</p>
  </div>
  <div class="page">
    <p>Cache Conscious - 3D Animation</p>
  </div>
  <div class="page">
    <p>Cache Conscious - 3D Animation</p>
  </div>
  <div class="page">
    <p>Cache Conscious - 3D Animation</p>
  </div>
  <div class="page">
    <p>Cache Conscious - Optimal Block Size Search</p>
  </div>
  <div class="page">
    <p>Cache Conscious - Optimal Block Size Search</p>
    <p>Reduced memory traffic does correlate to higher GFlop rates</p>
  </div>
  <div class="page">
    <p>Cache Conscious Performance</p>
    <p>Cache conscious measured with optimal block size on each platform  Itanium 2 and Opteron both improve</p>
  </div>
  <div class="page">
    <p>Opt. Strategy #3: Cache Conscious on Cell</p>
    <p>O b liv</p>
    <p>io u s</p>
    <p>(I m</p>
    <p>p lic</p>
    <p>it )</p>
    <p>C on</p>
    <p>sc io</p>
    <p>u s</p>
    <p>(E xp</p>
    <p>lic it )</p>
    <p>S of</p>
    <p>tw ar</p>
    <p>e</p>
    <p>Cache (Implicit)</p>
    <p>Local Store (Explicit)</p>
    <p>Hardware</p>
    <p>Cache Oblivious</p>
    <p>Cache Conscious</p>
    <p>Cache Conscious</p>
    <p>on Cell</p>
    <p>N/A</p>
    <p>Two software techniques  Cache oblivious algorithm</p>
    <p>recursively subdivides  Cache conscious has an</p>
    <p>explicit block size  Easier to visualize  Tunable block size  No recursion stack</p>
    <p>overhead</p>
    <p>Two hardware techniques  Cache managed by hw  Local store managed by sw</p>
    <p>Eliminate extraneous reads/writes</p>
  </div>
  <div class="page">
    <p>Cell Processor</p>
    <p>PowerPC core that controls 8 simple SIMD cores (SPEs)  Memory hierarchy consists of:</p>
    <p>Registers  Local memory  External DRAM</p>
    <p>Application explicitly controls memory:  Explicit DMA operations required to move data from DRAM to each</p>
    <p>SPEs local memory  Effective for predictable data access patterns</p>
    <p>Cell code contains more low-level intrinsics than prior code</p>
  </div>
  <div class="page">
    <p>Cell Local Store Blocking</p>
    <p>Stream out planes to target grid</p>
    <p>Stream in planes from source grid</p>
    <p>SPE local store</p>
  </div>
  <div class="page">
    <p>Excellent Cell Processor Performance</p>
    <p>Double-Precision (DP) Performance: 7.3 GFlops/s  DP performance still relatively weak</p>
    <p>Only 1 floating point instruction every 7 cycles  Problem becomes computation-bound when cache-blocked</p>
    <p>Single-Precision (SP) Performance: 65.8 GFlops/s!  Problem now memory-bound even when cache-blocked</p>
    <p>If Cell had better DP performance or ran in SP, could take further advantage of cache blocking</p>
  </div>
  <div class="page">
    <p>Summary - Computation Rate Comparison</p>
  </div>
  <div class="page">
    <p>Summary - Algorithmic Peak Comparison</p>
  </div>
  <div class="page">
    <p>Stencil Code Conclusions</p>
    <p>Cache-blocking performs better when explicit  But need to choose right cache block size for architecture</p>
    <p>Software-controlled memory boosts stencil performance  Caters memory accesses to given algorithm  Works especially well due to predictable data access patterns</p>
    <p>Low-level code gets closer to algorithmic peak  Eradicates compiler code generation issues  Application knowledge allows for better use of functional units</p>
  </div>
</Presentation>
