<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>+ fNML Criterion for Learning Bayesian Network Structures</p>
    <p>Tomi Silander Teemu Roos Petri Kontkanen Petri Myllymaki</p>
    <p>Helsinki Institute for Information Technology HIIT FINLAND</p>
    <p>PGM08 Hirtshals</p>
    <p>September 1719 2008</p>
  </div>
  <div class="page">
    <p>+ 1. Bayesian Networks 2. Model Selection Scores 3. New Stuff: fNML Score</p>
  </div>
  <div class="page">
    <p>+ Bayesian Networks</p>
    <p>Conditional independence assumptions</p>
    <p>Factorization of a joint probability distribution:</p>
  </div>
  <div class="page">
    <p>+ Data</p>
    <p>NAME GENDER PROFESSION CHILDREN</p>
    <p>Teemu male researcher 2</p>
    <p>Clark male reporter 0</p>
    <p>Margrethe female queen 2</p>
    <p>: : : :</p>
  </div>
  <div class="page">
    <p>+ Data</p>
    <p>NAME GENDER PROFESSION CHILDREN</p>
    <p>Teemu male researcher 2</p>
    <p>Clark male reporter 0</p>
    <p>Margrethe female queen 2</p>
    <p>: : : :</p>
  </div>
  <div class="page">
    <p>+</p>
    <p>NAME GENDER PROFESSION CHILDREN</p>
    <p>Teemu male researcher 2</p>
    <p>Clark male reporter 0</p>
    <p>Margrethe female queen 2</p>
    <p>: : : :</p>
    <p>Data</p>
    <p>D</p>
  </div>
  <div class="page">
    <p>+</p>
    <p>NAME GENDER PROFESSION CHILDREN</p>
    <p>Teemu male researcher 2</p>
    <p>Clark male reporter 0</p>
    <p>Margrethe female queen 2</p>
    <p>: : : :</p>
    <p>Data</p>
    <p>Di</p>
  </div>
  <div class="page">
    <p>+</p>
    <p>Bayes (BDe)  BIC &amp; AIC  MDL</p>
  </div>
  <div class="page">
    <p>+ Bayesian Score</p>
    <p>The state-of-the-art model selection criterion:</p>
    <p>Bayesian Dirichlet equivalent (BDe) score</p>
    <p>Assumes Dirichlet prior on model parameters .</p>
    <p>Evaluate marginal likelihood of data given model</p>
    <p>Depends on hyper-parameter .</p>
  </div>
  <div class="page">
    <p>+ BIC &amp; AIC</p>
    <p>BIC: Asymptotic approximation of marginal likelihood:</p>
    <p>AIC: Asymptotic approximation of estimated prediction error:</p>
  </div>
  <div class="page">
    <p>+ MDL</p>
    <p>Minimum Description Length (MDL) Principle:</p>
    <p>Choose the model that yields the shortest description of the data together with the model.</p>
    <p>Too simple model data long, model short</p>
    <p>&quot;Just right&quot; data short, model short</p>
    <p>Too complex model data short, model long</p>
  </div>
  <div class="page">
    <p>+ Flavours of MDL</p>
  </div>
  <div class="page">
    <p>+ Flavours of MDL</p>
  </div>
  <div class="page">
    <p>+ Flavours of MDL</p>
    <p>normalized maximum likelihood (NML)</p>
    <p>Problem: NML computationally very hard.</p>
  </div>
  <div class="page">
    <p>+ Bayes vs. MDL (minimax regret)</p>
    <p>The Bayesian decision principle is minimization of expected loss:</p>
    <p>minA EX [loss(A,X)]</p>
    <p>MDL (especially NML) is based on minimization of worst-case regret:</p>
    <p>minA maxX [loss(A,X)  minA' loss(A',X)]</p>
    <p>&quot;regret&quot;</p>
  </div>
  <div class="page">
    <p>+</p>
    <p>fNML = &quot;factorized NML&quot;  computation  consistency</p>
  </div>
  <div class="page">
    <p>+ fNML Score</p>
    <p>We propose a new MDL score, factorized NML, which is</p>
  </div>
  <div class="page">
    <p>+</p>
    <p>NAME GENDER PROFESSION CHILDREN</p>
    <p>Teemu male researcher 2</p>
    <p>Clark male reporter 0</p>
    <p>Margrethe female queen 2</p>
    <p>: : : :</p>
    <p>fNML vs. NML: what's new? 18/30</p>
  </div>
  <div class="page">
    <p>+</p>
    <p>NAME GENDER PROFESSION CHILDREN</p>
    <p>Teemu male researcher 2</p>
    <p>Clark male reporter 0</p>
    <p>Margrethe female queen 2</p>
    <p>: : : :</p>
    <p>fNML vs. NML: what's new?</p>
    <p>D</p>
    <p>NML: Minimax code applied to whole data as one block</p>
  </div>
  <div class="page">
    <p>+</p>
    <p>NAME GENDER PROFESSION CHILDREN</p>
    <p>Teemu male researcher 2</p>
    <p>Clark male reporter 0</p>
    <p>Margrethe female queen 2</p>
    <p>: : : :</p>
    <p>fNML vs. NML: what's new?</p>
    <p>D2</p>
    <p>fNML: minimax code applied column by column</p>
  </div>
  <div class="page">
    <p>+</p>
    <p>NAME GENDER PROFESSION CHILDREN</p>
    <p>Teemu male researcher 2</p>
    <p>Clark male reporter 0</p>
    <p>Margrethe female queen 2</p>
    <p>: : : :</p>
    <p>fNML vs. NML: what's new?</p>
    <p>D1</p>
    <p>fNML: Conditional minimax code when parent(s) exist.</p>
  </div>
  <div class="page">
    <p>+</p>
    <p>NAME GENDER PROFESSION CHILDREN</p>
    <p>Teemu male researcher 2</p>
    <p>Clark male reporter 0</p>
    <p>Margrethe female queen 2</p>
    <p>: : : :</p>
    <p>fNML vs. NML: what's new? fNML: Conditional minimax code when parent(s) exist.</p>
    <p>D3</p>
  </div>
  <div class="page">
    <p>+</p>
    <p>NAME GENDER PROFESSION CHILDREN</p>
    <p>Teemu male researcher 2</p>
    <p>Clark male reporter 0</p>
    <p>Margrethe female queen 2</p>
    <p>: : : :</p>
    <p>fNML vs. NML: what's new? fNML: Conditional minimax code when parent(s) exist.</p>
    <p>D4</p>
  </div>
  <div class="page">
    <p>+</p>
    <p>NAME GENDER PROFESSION CHILDREN</p>
    <p>Teemu male researcher 2</p>
    <p>Clark male reporter 0</p>
    <p>Margrethe female queen 2</p>
    <p>: : : :</p>
    <p>fNML vs. NML: what's new? fNML: Conditional minimax code when parent(s) exist.</p>
    <p>D4</p>
    <p>Each column is encoded using the minimax code for multinomials.</p>
    <p>Using fast NML algorithms, this takes O(n log n) per column.</p>
  </div>
  <div class="page">
    <p>+ fNML: Consistency</p>
    <p>(Haughton, 1988): Any penalized likelihood score of the form</p>
    <p>where an satisfies and , is consistent.</p>
    <p>Theorem: fNML behaves asymptotically like BIC, i.e., an = log n.</p>
    <p>Hence, fNML is consistent.</p>
  </div>
  <div class="page">
    <p>+ Robustness</p>
    <p>BIC</p>
    <p>BDe, fNML</p>
  </div>
  <div class="page">
    <p>+ Robustness</p>
    <p>BDe optimal when prior &quot;correct&quot;. fNML</p>
    <p>almost as good.</p>
    <p>BIC</p>
    <p>BDe, fNML</p>
  </div>
  <div class="page">
    <p>+ Robustness</p>
    <p>fNML</p>
  </div>
  <div class="page">
    <p>+ Robustness</p>
    <p>fNML</p>
    <p>BDe much worse when prior &quot;incorrect&quot;.</p>
    <p>fNML more robust.</p>
  </div>
  <div class="page">
    <p>+ Questions?</p>
  </div>
  <div class="page">
    <p>+ Decomposable Scores</p>
    <p>Problem: Super-exponential search space.</p>
    <p>Solution: Decomposable scores</p>
    <p>SCORE(G,D) = S(Di,DGi) For decomposable scores, exact search (global</p>
    <p>optimum) can be done for about m  30 nodes (Koivisto &amp; Sood, 2004; Silander and Myllymki, 2006).</p>
    <p>i=1</p>
    <p>m</p>
  </div>
</Presentation>
