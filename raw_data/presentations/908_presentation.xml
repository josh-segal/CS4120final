<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>MetaSync File Synchroniza/on Across Mul/ple Untrusted Storage Services</p>
    <p>Seungyeop Han (syhan@cs.washington.edu) Haichen Shen, Taesoo Kim*, Arvind Krishnamurthy,</p>
    <p>Thomas Anderson, and David Wetherall</p>
    <p>University of Washington *Georgia Ins/tute of Technology 1 USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>File sync services are popular</p>
  </div>
  <div class="page">
    <p>Baidu(2TB)</p>
    <p>Many sync service providers</p>
    <p>Dropbox (2GB) Google Drive (15GB)</p>
    <p>MS OneDrive (15GB) Box.net (10GB)</p>
  </div>
  <div class="page">
    <p>Can we rely on any single service?</p>
  </div>
  <div class="page">
    <p>Exis/ng Approaches</p>
    <p>Encrypt files to prevent modifica/on  Boxcryptor</p>
    <p>Rewrite file sync service to reduce trust  SUNDR (Li et al., 04), DEPOT (Mahajan et al., 10)</p>
  </div>
  <div class="page">
    <p>MetaSync: Can we build a beaer file synchroniza/on system across mul/ple exis/ng services?</p>
    <p>MetaSync</p>
    <p>Higher availability, greater capacity, higher performance Stronger confiden/ality &amp; integrity</p>
    <p>USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>Goals</p>
    <p>Higher availability  Stronger confiden/ality &amp; integrity  Greater capacity and higher performance</p>
    <p>No service-service, client-client communica/on</p>
    <p>No addi/onal server  Open source soeware</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>Mo/va/on &amp; Goals  MetaSync Design  Implementa/on  Evalua/on  Conclusion</p>
  </div>
  <div class="page">
    <p>Key Challenges</p>
    <p>Maintain a globally consistent view of the synchronized files across mul/ple clients</p>
    <p>Using only the service providers unmodified APIs without any centralized server</p>
    <p>Even in the presence of service failure</p>
  </div>
  <div class="page">
    <p>Design Choices</p>
    <p>How to manage files?  Content-based addressing &amp; hash tree</p>
    <p>How to update consistently with unmodified APIs?  Client-based Paxos (pPaxos)</p>
    <p>How to spread files?  Stable determinis/c mapping</p>
    <p>How to protect files?  Encryp/on from clients</p>
    <p>How to make it extensible?  Common abstrac/ons</p>
  </div>
  <div class="page">
    <p>Design Choices</p>
    <p>How to manage files?  Content-based addressing &amp; hash tree</p>
    <p>How to update consistently with unmodified APIs?  Client-based Paxos (pPaxos)</p>
    <p>How to spread files?  Stable determinis/c mapping</p>
    <p>How to protect files?  Encryp/on from clients</p>
    <p>How to make it extensible?  Common abstrac/ons</p>
  </div>
  <div class="page">
    <p>Overview of the Design</p>
    <p>Synchroniza/on Replica/on Object Store</p>
    <p>MetaSync</p>
    <p>Backend abstrac/ons Local Storage</p>
    <p>Dropbox Google Drive OneDrive</p>
    <p>Remote Services</p>
    <p>USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>Object Store</p>
    <p>Similar data structure with version control systems (e.g., git)</p>
    <p>Content-based addressing  File name = hash of the contents  De-duplica/on  Simple integrity checks</p>
    <p>Directories form a hash tree  Independent &amp; concurrent updates</p>
  </div>
  <div class="page">
    <p>Object Store</p>
    <p>head = f12</p>
    <p>Dir1</p>
    <p>abc</p>
    <p>Dir2</p>
    <p>Large.bin</p>
    <p>blob blob blob</p>
    <p>small1 small2</p>
    <p>Files are chunked or grouped into blobs  The root hash = f12 uniquely iden/fies a snapshot</p>
    <p>USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>Object Store</p>
    <p>old = f12</p>
    <p>Dir1</p>
    <p>abc</p>
    <p>Dir2</p>
    <p>Large.bin</p>
    <p>blob blob blob</p>
    <p>small1 small2</p>
    <p>Files are chunked or grouped into blobs  The root hash = f12 uniquely iden/fies a snapshot</p>
    <p>blob</p>
    <p>head = 07c</p>
    <p>Large.bin</p>
    <p>USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>Overview of the Design</p>
    <p>Synchroniza/on Replica/on Object Store</p>
    <p>MetaSync</p>
    <p>Backend abstrac/ons Local Storage</p>
    <p>Dropbox Google Drive OneDrive</p>
    <p>Remote Services</p>
    <p>USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>Upda/ng Global View</p>
    <p>Global View</p>
    <p>v0 ab1</p>
    <p>Client1 Prev</p>
    <p>Head</p>
    <p>Prev</p>
    <p>Head</p>
    <p>Client2</p>
    <p>master</p>
    <p>Previously synchronized point</p>
    <p>Current root hash</p>
    <p>USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>Upda/ng Global View</p>
    <p>Global View</p>
    <p>v0 ab1</p>
    <p>Client1 Prev Head</p>
    <p>Prev Client2</p>
    <p>v1 c10</p>
    <p>master</p>
    <p>Head</p>
    <p>USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>Upda/ng Global View</p>
    <p>Global View</p>
    <p>v0 ab1</p>
    <p>Client1 Prev</p>
    <p>Head</p>
    <p>Prev Client2</p>
    <p>v1 c10</p>
    <p>master</p>
    <p>Head</p>
    <p>USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>Upda/ng Global View</p>
    <p>Global View</p>
    <p>v0 ab1</p>
    <p>Client1 Prev</p>
    <p>Head</p>
    <p>Prev Client2</p>
    <p>v1 c10</p>
    <p>master</p>
    <p>Head</p>
    <p>USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>Upda/ng Global View</p>
    <p>Global View</p>
    <p>v0 ab1</p>
    <p>Client1 Prev</p>
    <p>Prev Head Client2</p>
    <p>v1 c10</p>
    <p>v2 7b3</p>
    <p>master</p>
    <p>Head</p>
    <p>v2 f13</p>
    <p>USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>Upda/ng Global View</p>
    <p>Global View</p>
    <p>v0 ab1</p>
    <p>Client1 Prev</p>
    <p>Prev</p>
    <p>Head</p>
    <p>Client2</p>
    <p>v1 c10 v2 7b3</p>
    <p>master</p>
    <p>Head</p>
    <p>v2 f13</p>
    <p>USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>Upda/ng Global View</p>
    <p>Global View</p>
    <p>v0 ab1</p>
    <p>Client1 Prev</p>
    <p>Prev</p>
    <p>Head</p>
    <p>Client2</p>
    <p>v1 c10 v2 7b3</p>
    <p>master</p>
    <p>Head</p>
    <p>v3 a31</p>
    <p>USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>Consistent Update of Global View</p>
    <p>Need to handle concurrent updates, unavailable services based on exis/ng APIs</p>
    <p>MetaSync</p>
    <p>Dropbox</p>
    <p>MetaSync</p>
    <p>Google Drive</p>
    <p>OneDrive</p>
    <p>root= f12 root= b05</p>
  </div>
  <div class="page">
    <p>Paxos</p>
    <p>Mul/-round non-blocking consensus algorithm  Safe regardless of failures  Progress if majority is alive</p>
    <p>Proposer Acceptor 25 USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>Metasync: Simulate Paxos  Use an append-only list to log Paxos messages  Client sends normal Paxos messages  Upon arrival of message, service appends it into a list  Client can fetch a list of the ordered messages</p>
    <p>Each service provider has APIs to build append- only list  Google Drive, OneDrive, Box: Comments on a file  Dropbox: Revision list of a file  Baidu: Files in a directory</p>
  </div>
  <div class="page">
    <p>Metasync: Passive Paxos (pPaxos)</p>
    <p>Backend services work as passive acceptor  Acceptor decisions are delegated to clients</p>
    <p>Clients Passive Storage Services</p>
    <p>New root = 1</p>
    <p>New root = 2</p>
    <p>Accepted root = 1</p>
    <p>S2</p>
    <p>S1</p>
    <p>S3 fetch(S1)</p>
    <p>fetch(S2)</p>
    <p>USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>Paxos vs. Disk Paxos vs. pPaxos</p>
    <p>Disk Paxos: maintains a block per client</p>
    <p>Proposer</p>
    <p>Acceptor computa/on</p>
    <p>Propose Accept</p>
    <p>Paxos</p>
    <p>Proposer</p>
    <p>Acceptor</p>
    <p>disk blocks</p>
    <p>Propose Check</p>
    <p>Disk Paxos</p>
    <p>Proposer</p>
    <p>Acceptor</p>
    <p>append-only</p>
    <p>Propose Check</p>
    <p>pPaxos</p>
    <p>Gafni &amp; Lamport 02</p>
    <p>Requires acceptor API O(clients x acceptors) O(acceptors) O(acceptors)</p>
    <p>require # msgs</p>
    <p>USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>Overview of the Design</p>
    <p>Synchroniza/on Replica/on Object Store</p>
    <p>MetaSync</p>
    <p>Backend abstrac/ons Local Storage</p>
    <p>Dropbox Google Drive OneDrive</p>
    <p>Remote Services</p>
    <p>USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>Stable Determinis/c Mapping</p>
    <p>MetaSync replicates objects R /mes across S storage providers (R&lt;S)</p>
    <p>Requirements  Share minimal informa/on among services/clients  Support varia/on in storage size  Minimize realignment upon configura/on changes</p>
    <p>Determinis/c mapping</p>
    <p>E.g., map(7a1) = Dropbox, Google</p>
    <p>USENIX ATC '15 30</p>
  </div>
  <div class="page">
    <p>Implementa/on</p>
    <p>Prototyped with Python  ~8k lines of code</p>
    <p>Currently supports 5 backend services  Dropbox, Google Drive, OneDrive, Box.net, Baidu</p>
    <p>Two front-end clients  Command line client  Sync daemon</p>
  </div>
  <div class="page">
    <p>Evalua/on</p>
    <p>How is the end-to-end performance?</p>
    <p>Whats the performance characteris/cs of pPaxos?</p>
    <p>How quickly does MetaSync reconfigure mappings?</p>
  </div>
  <div class="page">
    <p>Evalua/on</p>
    <p>How is the end-to-end performance?</p>
    <p>Whats the performance characteris/cs of pPaxos?</p>
    <p>How quickly does MetaSync reconfigure mappings?</p>
  </div>
  <div class="page">
    <p>End-to-End Performance</p>
    <p>Dropbox Google MetaSync Linux Kernel 920 directories 15k files, 166MB</p>
    <p>Pictures 50 files, 193MB</p>
    <p>Synchronize the target between two computers</p>
    <p>Performance gains are from:  Parallel upload/download with mul/ple providers  Combined small files into a blob</p>
    <p>(S = 4, R = 2)</p>
    <p>USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>Latency of pPaxos</p>
    <p>Latency is not degraded with increasing concurrent proposers or adding slow backend storage service 35</p>
    <p>La te nc y (s )</p>
    <p># of Proposers</p>
    <p>Google</p>
    <p>Dropbox</p>
    <p>OneDrive</p>
    <p>Box</p>
    <p>Baidu</p>
    <p>USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>Latency of pPaxos</p>
    <p>Latency is not degraded with increasing concurrent proposers or adding slow backend storage service 36</p>
    <p>La te nc y (s )</p>
    <p># of Proposers</p>
    <p>Google</p>
    <p>Dropbox</p>
    <p>OneDrive</p>
    <p>Box</p>
    <p>Baidu</p>
    <p>All</p>
    <p>USENIX ATC '15</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>MetaSync provides a secure, reliable, and performant files sync service on top of popular cloud providers  To achieve a consistent update, we devise a new client-based Paxos</p>
    <p>To minimize redistribu/on, we present a stable determinisOc mapping</p>
    <p>Source code is available:  hap://uwnetworkslab.github.io/metasync/</p>
  </div>
</Presentation>
