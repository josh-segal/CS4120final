<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Towards GPU Utilization Prediction for Cloud Deep Learning</p>
    <p>Gingfung Yeung, Damian Borowiec, Adrian Friday, Richard Harper, Peter Garraghan</p>
    <p>Evolving Distributed System Lab</p>
    <p>School of Computing &amp; Communications</p>
    <p>Lancaster University</p>
    <p>UK</p>
  </div>
  <div class="page">
    <p>Deep Learning (DL) Systems</p>
    <p>More Deep Learning</p>
    <p>(DL) workloads</p>
    <p>Growing number of</p>
    <p>expensive GPUs Machine Learning engineers,</p>
    <p>researchers, users</p>
    <p>Require efficient resource usage &amp;</p>
    <p>high DL performance</p>
  </div>
  <div class="page">
    <p>DL System Challenges</p>
    <p>DL System Challenges</p>
    <p>Avg. GPU utilization ~ 52% in production systems [Jeon et al. 19]</p>
    <p>Long job completion + queue times ~ up to hours [Jeon et al. 19; Gu et al. 19]</p>
    <p>Addressed via understanding and exploiting</p>
    <p>workload patterns</p>
  </div>
  <div class="page">
    <p>Online profiling approach</p>
    <p>GPU-1 GPU-2</p>
    <p>Workload</p>
    <p>Resource</p>
    <p>Monitor</p>
    <p>Node</p>
    <p>Response</p>
    <p>Profile</p>
    <p>GPU-1 {Utilization = 20, Memory = 4GiB,Bytes}</p>
    <p>GPU-2 {Utilization = 40, Memory = 6GiB,Bytes}</p>
    <p>Workload</p>
    <p>Deploy workload into isolated</p>
    <p>machines and GPUs to obtain</p>
    <p>workload patterns</p>
    <p>Usually per workload profiling range from</p>
    <p>minutes to hours</p>
  </div>
  <div class="page">
    <p>Iteration time</p>
    <p>Useful for scale-out workers, migration, SLA-aware inference</p>
    <p>[Peng et al. 18; Xiao et al. 18; Shen et al. 19]</p>
    <p>Network I/O</p>
    <p>Useful for efficient distributed training</p>
    <p>[Gu et al. 19]</p>
    <p>GPU Utilization</p>
    <p>For packing and calculating interference</p>
    <p>[Thinakaran et al. 19; Xu et al. 19]</p>
    <p>DL Metrics</p>
  </div>
  <div class="page">
    <p>Case: Scheduling</p>
    <p>Resource</p>
    <p>Monitor Scheduler</p>
    <p>Resource Management Framework 6</p>
    <p>Make decision based on</p>
    <p>workload patterns from profiling</p>
    <p>Scheduling</p>
    <p>Loop</p>
  </div>
  <div class="page">
    <p>Time is Money</p>
    <p>N workload  mins</p>
    <p>Workload Queue</p>
    <p>Profiling Stage (mins)</p>
    <p>Scheduling Stage</p>
    <p>If the system has many heterogenous</p>
    <p>workloads, will lead to head-of-line blocking.</p>
  </div>
  <div class="page">
    <p>Online Profiling</p>
    <p>Pros</p>
    <p>Accurate, near real-time workload patterns</p>
    <p>Provide insights to the system</p>
    <p>Cons</p>
    <p>Heterogenous workloads require different profiles</p>
    <p>Time consuming (~mins to ~hours)</p>
    <p>Require modifying underlying frameworks</p>
  </div>
  <div class="page">
    <p>Pros</p>
    <p>Accurate, near real-time workload patterns</p>
    <p>Provide insights to the system</p>
    <p>Cons</p>
    <p>Heterogenous workloads require different profiles</p>
    <p>Time consuming (~mins to ~hours)</p>
    <p>Require actual execution onto an isolated machine</p>
    <p>Require modifying underlying frameworks</p>
    <p>Online Profiling</p>
    <p>Obtain prior execution ?</p>
  </div>
  <div class="page">
    <p>Prediction</p>
    <p>N workload  seconds</p>
    <p>Workload Queue</p>
    <p>Prediction Stage (sub-second  seconds)</p>
    <p>Scheduling Stage</p>
    <p>Reduce blocking</p>
  </div>
  <div class="page">
    <p>DL System Challenges</p>
    <p>DL System Challenges</p>
    <p>Avg. GPU utilization ~ 52% in production systems [Jeon et al. 19]</p>
    <p>Long job completion + queue times ~ up to hours [Jeon et al. 19; Gu et al. 19]</p>
    <p>Addressed via understanding and exploiting</p>
    <p>workload patterns</p>
  </div>
  <div class="page">
    <p>Iteration time</p>
    <p>Useful for scale-out workers, migration, SLA-aware inference</p>
    <p>[Peng et al. 18; Xiao et al. 18; Shen et al. 19]</p>
    <p>Network I/O</p>
    <p>Useful for efficient distributed training</p>
    <p>[Gu et al. 19]</p>
    <p>GPU Utilization</p>
    <p>For packing and calculating interference</p>
    <p>[Thinakaran et al. 19; Xu et al. 19]</p>
    <p>DL Metrics</p>
  </div>
  <div class="page">
    <p>Objective</p>
    <p>Benefits</p>
    <p>Estimates GPU utilization of unseen workloads</p>
    <p>Prior to execution</p>
    <p>No modification of existing DL frameworks</p>
    <p>E.g. PyTorch, TensorFlow, MXNet</p>
    <p>GPU utilization prediction engine for Cloud DL Systems</p>
    <p>Analysis, prediction model, case study</p>
  </div>
  <div class="page">
    <p>Going deeper with convolutions [Szegedy et al 2014]</p>
    <p>Leverage graph information to</p>
    <p>predict workload usage.</p>
    <p>Features: Num. Convs, FLOPs, layers, etc.</p>
    <p>(See paper for full features list)</p>
    <p>DL computation graph</p>
  </div>
  <div class="page">
    <p>Analysis</p>
    <p>Profile DL workload utilization  Determine important model features</p>
    <p>Set up  Nvidia 1080, Nvidia 2080, Intel i7-6850k</p>
    <p>13 DNN model architectures, 81 workloads</p>
    <p>Tools  Nvidia-smi</p>
    <p>Nvidia Nsight Systems</p>
    <p>See paper for full list of models and permutations.</p>
  </div>
  <div class="page">
    <p>CNN RNN</p>
    <p>G P</p>
    <p>U U</p>
    <p>ti li</p>
    <p>za ti</p>
    <p>o n</p>
    <p>%</p>
    <p>Analysis</p>
    <p>G F</p>
    <p>L O</p>
    <p>P s</p>
    <p>GPU Utilization %</p>
  </div>
  <div class="page">
    <p>Analysis</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d J</p>
    <p>C T</p>
    <p>i n</p>
    <p>cr e</p>
    <p>a se</p>
    <p>Summative GPU Utilization (%)</p>
    <p>G P</p>
    <p>U U</p>
    <p>ti li</p>
    <p>za ti</p>
    <p>o n</p>
    <p>%</p>
    <p>Nvidia 1080</p>
    <p>Nvidia 2080</p>
    <p>B a tc h 1 6</p>
    <p>B a tc h 6 4</p>
    <p>B a tc h 1 2 8</p>
    <p>from co-location</p>
  </div>
  <div class="page">
    <p>GPU Utilization Prediction</p>
    <p>=1</p>
    <p>log  + 1  log  + 1 2</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>A v</p>
    <p>g C</p>
    <p>lu st</p>
    <p>e r</p>
    <p>G P</p>
    <p>U</p>
    <p>U ti</p>
    <p>li za</p>
    <p>ti o</p>
    <p>n (</p>
    <p>% )</p>
    <p>Time (minutes)</p>
    <p>Slot-based</p>
    <p>Reactive</p>
    <p>Proactive</p>
  </div>
  <div class="page">
    <p>Open Challenges</p>
    <p>Hardware  Number of processing elements, memory bandwidth and cache</p>
    <p>sizes.</p>
    <p>DL Compilers  Extract lower level IR to determine optimization decision for</p>
    <p>more accurate prediction. (e.g. Op fusion  ConvBatchNorm)</p>
    <p>Distributed Workload  Network I/O, parallelism strategy and system configuration.</p>
    <p>(e.g. ring topology)</p>
    <p>Co-location Scheduling  Incorporate prediction and system constraints</p>
    <p>Derive an optimization algorithm</p>
    <p>(e.g. Mixed Integer Programming).</p>
  </div>
</Presentation>
