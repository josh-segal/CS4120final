<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>On the Impact of Isolation Costs on Locality-aware Cloud Scheduling</p>
    <p>Ankit Bhardwaj, Meghana Gupta, Ryan Stutsman University of Utah</p>
    <p>Scalable Computer Systems Lab www.utah.systems</p>
  </div>
  <div class="page">
    <p>Code Isolation-cost Aware Scheduling</p>
    <p>Three recent shifts in the cloud</p>
    <p>Cloud Networking Performance  100 Gbps, microsecond round-trips</p>
    <p>Rethink of code isolation schemes  Meltdown, Spectre, VT-x, eBPF, WASM</p>
    <p>Granular, Serverless Applications  Visibility and Placement a fine grain</p>
  </div>
  <div class="page">
    <p>Code Isolation-cost Aware Scheduling</p>
    <p>Three recent shifts in the cloud</p>
    <p>Cloud Networking Performance  100 Gbps, microsecond round-trips</p>
    <p>Rethink of code isolation schemes  Meltdown, Spectre, VT-x, eBPF, WASM</p>
    <p>Granular, Serverless Applications  Visibility and Placement a fine grain</p>
  </div>
  <div class="page">
    <p>Code Isolation-cost Aware Scheduling</p>
    <p>Three recent shifts in the cloud</p>
    <p>Cloud Networking Performance  100 Gbps, microsecond round-trips</p>
    <p>Rethink of code isolation schemes  Meltdown, Spectre, VT-x, eBPF, WASM</p>
    <p>Granular, Serverless Applications  Visibility and Placement a fine grain</p>
  </div>
  <div class="page">
    <p>Code Isolation-cost Aware Scheduling</p>
    <p>Cloud Networking Performance  100 Gbps, microsecond round-trips</p>
    <p>Rethink of code isolation schemes  Meltdown, Spectre, VT-x, eBPF, WASM</p>
    <p>Granular, Serverless Applications  Visibility and Placement a fine grain</p>
    <p>Diversity and Flexibility in Placement, Workloads, and Isolation Costs</p>
  </div>
  <div class="page">
    <p>Code Isolation-cost Aware Scheduling</p>
    <p>Cloud Networking Performance  100 Gbps, microsecond round-trips</p>
    <p>Rethink of code isolation schemes  Meltdown, Spectre, VT-x, eBPF, WASM</p>
    <p>Granular, Serverless Applications  Visibility and Placement a fine grain</p>
    <p>Diversity and Flexibility in Placement, Workloads, and Isolation Costs</p>
    <p>Isolation- and data-movement-cost Aware Scheduling for Cloud Compute</p>
    <p>It is time for a holistic, cost-aware approach to scheduling in the cloud</p>
  </div>
  <div class="page">
    <p>Past: State + Application on One VM</p>
    <p>Compute/storage together on one machine; VMs access state locally</p>
    <p>Problem: Resource stranding  Idle compute when storage capacity is the limiting factor  Idle storage when compute capacity is the limiting factor  Costly to reorganize</p>
    <p>DATA DATA</p>
  </div>
  <div class="page">
    <p>Today: Disaggregation  Solution: Separate compute from storage</p>
    <p>New Problem: High data movement costs (multiple gets/puts)  RPC, serialization/deserialization  TCP/transport  memcpys  Substantial costs at gigabits/second</p>
  </div>
  <div class="page">
    <p>Move compute to storage at finer grain?</p>
    <p>Solution: storage-side computation over stored data</p>
    <p>But, high tenant density at storage to homogenize/balance load  Need granular decomposition of application logic</p>
    <p>Problem: Many tenants sharing storage; code isolation is hard  Process creation and context switch add up</p>
  </div>
  <div class="page">
    <p>Key Idea: Isolation-cost Aware Scheduler</p>
    <p>Placement of computation in the cloud can improve efficiency  by eliminating data movement,  but it also must reason about code isolation costs to do so.</p>
    <p>Profile  inter-function interaction in applications,  data access and locality patterns,  networking, dispatch, and isolation domain context switch costs</p>
    <p>Global fine-grained, core-level choices at microsecond-timescales</p>
  </div>
  <div class="page">
    <p>Challenges for Isolation-cost Aware Scheduling  Need for Fine-grained Applications  Workload Characterization  Profiling and Understanding Context Switch Costs  Provisioning, Re-provisioning, and Placement  Dealing with Intermediate State</p>
  </div>
  <div class="page">
    <p>Challenge #0: Need Finer-grained Apps</p>
    <p>Scheduler must be able to &quot;see&quot; into applications to optimize  Solution: serverless  Functions can be individually placed  Creates visibility into applications  Supports alternative isolation schemes  Malleable interface</p>
    <p>Today implementations do not tap into these potential benefits</p>
    <p>VM</p>
  </div>
  <div class="page">
    <p>Challenge #1: Workload Characterization</p>
    <p>Problem: No insight into function's network and data access costs  Solution: Profile functions to capture  data access patterns and locality  runtime distribution</p>
    <p>F u</p>
    <p>n c ti o</p>
    <p>n T</p>
    <p>h ro</p>
    <p>u g</p>
    <p>h p</p>
    <p>u t</p>
    <p>(m ill</p>
    <p>io n</p>
    <p>s o</p>
    <p>f in</p>
    <p>v o</p>
    <p>c a</p>
    <p>ti o</p>
    <p>n s /s</p>
    <p>e c o</p>
    <p>n d</p>
    <p>)</p>
    <p>Data Record Accesses (accesses/invocation)</p>
    <p>Client-side Function + Disaggregated Access Server-side Function + Colocated Access</p>
    <p>Place functions that access many records or much data at storage  Dynamically shift to idle compute when server is overloaded  Even simple schemes can work: counting accesses &amp; runtime</p>
  </div>
  <div class="page">
    <p>VT-x VMs for isolation, SR-IOV+IOMMU for dispatch</p>
    <p>Challenge #2: Code Isolation Costs</p>
    <p>Problem: isolation costs vary depending on workload VMs: hw protection &amp; dispatch  Too expensive to context switch  Good if high per-tenant throughput</p>
    <p>Containers: sw dispatch  Need ms-scale length requests  Good for timesharing CPU</p>
    <p>Language Runtimes: pure sw  Good for short-running functions</p>
    <p>with constrained logic</p>
    <p>App 2 VT-x VM</p>
    <p>App 1 VT-x VM</p>
    <p>Processes for isolation, software demultiplexing for dispatch</p>
    <p>App 1 Address Space App 1 Address Space</p>
    <p>App 1 Address Space App 1 Address Space</p>
    <p>App 1 Address Space App 1 Address Space</p>
    <p>Page Table Switching</p>
  </div>
  <div class="page">
    <p>Comparing Three Hw Isolation Schemes</p>
    <p>Paging/conventional process context switch is always costly  Low tenant counts  MPK Page Table Entry Coloring Fastest  Higher tenants counts  Extended Page Table Switching Fastest</p>
    <p>Best scheme depends on tenant count and request rates</p>
  </div>
  <div class="page">
    <p>Challenge #3: Provisioning &amp; Placement</p>
    <p>Problem: Function properties change over time  in data access patterns  in computational costs  in distribution of functions invoked</p>
    <p>Churn and instability forces new placement decisions  VMs, containers, etc have different start, stop, migration costs</p>
    <p>Solution: scheduling must model stability and variance of workload  In compute costs, invocation frequency, and data access</p>
  </div>
  <div class="page">
    <p>Storage Node Storage Node</p>
    <p>Storage Node</p>
    <p>Compute Node Compute Node</p>
    <p>Compute Node</p>
    <p>Preliminary Design Ideas Task Dispatching  Two-level scheduling avoids idle CPUs but</p>
    <p>limits queue imbalance  History at global level, route invocations to</p>
    <p>avoid context switching  Global knowledge of data placement</p>
    <p>Statistics, Load, &amp; Prediction  Core and task level stats collection</p>
    <p>Push via RDMA writes  Low-cost with frequent updates  100s to 1000s of machines pushing</p>
    <p>updates each second  Use in assessing workload stability</p>
    <p>Used by scheduler to promote/demote functions between isolation schemes</p>
    <p>Load Balancer</p>
    <p>Global Scheduler</p>
    <p>Stored Data</p>
    <p>Local Task Scheduler</p>
    <p>Local Task Scheduler</p>
    <p>Incoming Function</p>
    <p>Invocations</p>
  </div>
  <div class="page">
    <p>Discussion Questions</p>
    <p>Cloud process model  Cloud function interfaces (that differ from POSIX) are likely to take hold?</p>
    <p>Security risks  Larger attack surface, but works around vulnerabilities with less reengineering  Which isolation schemes and runtimes likely to be sufficiently trustworthy?</p>
    <p>Workloads  What will future, more granular serverless workloads look like?  What ways might there be to approximate these workloads using public data?</p>
    <p>Pricing  How might improved but hard-to-predict efficiency gains be reflected in pricing?</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Kernel-bypass  low-latency, high-throughput storage services  These gains are now showing up in the cloud  Fast networks  more data movement</p>
    <p>Small functions over data, but code isolation cuts into gains</p>
    <p>Key idea: different code isolation schemes have different costs  Dynamically understand data movement and code isolation costs  Run different functions with different schemes based on runtime profiling</p>
    <p>For more details, check out our project website or reach out to me at meghana@cs.utah.edu.</p>
  </div>
</Presentation>
