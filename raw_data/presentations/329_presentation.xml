<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>CAFTL: A Content-Aware Flash Translation Layer Enhancing the Lifespan of Flash Memory based Solid State Drivesthe Lifespan of Flash Memory based Solid State Drives</p>
    <p>Feng Chen1 Tian Luo2 Xiaodong Zhang2Feng Chen1 Tian Luo2 Xiaodong Zhang2</p>
    <p>Intel Labs The Ohio State University feng.a.chen@intel.com {luot,zhang}@cse.ohio-state.edu</p>
  </div>
  <div class="page">
    <p>Flash Memory based Solid State Drives</p>
    <p>Solid State Drive (SSD)  A semiconductor device built on NAND flash memoryA semiconductor device built on NAND flash memory  Mechanical components free</p>
    <p>Technical meritsTechnical merits  High performance (e.g. 250MB/sec, 75s)  Low power consumption (e.g. 0.06~2w)  Shock resistance Shock resistance  Decreasing price (e.g. $150 for 32GB)</p>
    <p>id fA wide scope of usage  Mobile computers (e.g. Asus EeePC, Dell Inspiron Mini)  High-performance desktops (e.g. gaming machines)</p>
  </div>
  <div class="page">
    <p>Limited lifespan Achilles heel of Solid State Drives</p>
    <p>Limited program/erase (P/E) cycles of flash memory</p>
    <p>Multi level Cell (MLC) 5 000 10 000 Multi-level Cell (MLC)  5,000 ~ 10,000</p>
    <p>Single-level Cell (SLC)  100,000 ~ 1,000,000</p>
    <p>Limited lifespan of SSDs</p>
    <p>Naturally limited by the lifetime constraint of flash memoryy y y</p>
    <p>Most prior research work focused on wear-leveling techniques*</p>
    <p>SSD manufacturers  SSDs can sustain routine usages for years</p>
  </div>
  <div class="page">
    <p>SSD Endurance Remains a Serious Concern</p>
    <p>Technical trend of flash memory  Bit density increases price decreases, endurance decreases  Sharp drop of program/erase cycles from 10 000 to 5 000 [A d 10] Sharp drop of program/erase cycles from 10,000 to 5,000 [Anderson10]</p>
    <p>Redundancy-based solution (e.g. RAID) is less effective RAID l ti ( 0 1 5) l di t ib t d i RAID solutions (e.g. 0,1,5) evenly distribute accesses across devices</p>
    <p>High risk of correlated device failures in SSD-based RAID [Balakrishnan10]</p>
    <p>Limited public info on SSD endurance in the field  Both positive/neg. results reported in prior work [Boboila10, Grupp09, Mohan10]  Endurance and retention (of SSDs) not yet proven in the field [Barroso10]</p>
    <p>Commercial systems are sensitive to reliability issues  Undergoes highly intensive write traffic than client systems  Permanent data loss is unacceptable (e g financial systems)</p>
    <p>Permanent data loss is unacceptable (e.g. financial systems)</p>
    <p>* Barraso, L. A. (Google), Warehouse-scale computing, Keynote in SIGMOD10</p>
    <p>SSD endurance remains a serious issue, and solutions effectively enhancing the lifespan of SSDs is highly desirable in practice</p>
  </div>
  <div class="page">
    <p>Lifespan of Solid State Drives Limited by flash Wear-leveling/GC</p>
    <p>Limited lifespan of SSDs</p>
    <p>C  program/erase Cycles EC</p>
    <p>y memory technology</p>
    <p>g/ Techniques*</p>
    <p>E  Efficiency of FTL designs</p>
    <p>V  write Volume per day</p>
    <p>EC</p>
    <p>V S  available flash memory Space S Designated during</p>
    <p>manufacturing time</p>
    <p>Optimization factors</p>
    <p>C  Increasing P/E cycles of flash</p>
    <p>Endurance = (C  S ) /(V  E)</p>
    <p>Determined by usage model and workload property</p>
    <p>E  Improving efficiency of FTL designs, e.g. GC and wear-leveling</p>
    <p>V  reducing the amount of incoming write traffic</p>
    <p>S  increasing the size of over-provisioned space (e.g. 6~25%)</p>
    <p>* Gale and Toledo, Algorithms and data structures for flash memories, ACM Computing Survey, 2005, vol. 37(2), pp. 138-163</p>
    <p>In this talk, we will show this goal can be achieved based on our observation of a widely existing phenomenon  data duplication</p>
  </div>
  <div class="page">
    <p>Data Duplication is Common</p>
    <p>Data redundancy in storage  Duplicate data rate  up to 85.9% over 15 disks in CSE/OSUDuplicate data rate up to 85.9% over 15 disks in CSE/OSU  A good extension to over-provisioned space (only 6~25%)</p>
  </div>
  <div class="page">
    <p>Data Duplication is Common</p>
    <p>Write redundancy in workloads  Duplicate writes  5.8 ~ 28.1% in 11 workloadsDuplicate writes 5.8 28.1% in 11 workloads</p>
  </div>
  <div class="page">
    <p>Making FTL Content Aware Flash Translation Layer (FTL)</p>
    <p>Emulating a hard drive with an LBA interface at the device levelEmulating a hard drive with an LBA interface at the device level</p>
    <p>Content-aware Flash Translation Layer (CAFTL)</p>
    <p>Eliminating duplicate writesg p</p>
    <p>Coalescing redundant data</p>
    <p>Potential benefits</p>
    <p>Removing duplicate writes into flash memory reducing V</p>
    <p>Extending available flash memory space increasing S</p>
    <p>EC</p>
    <p>VS</p>
  </div>
  <div class="page">
    <p>Technical Challenges</p>
    <p>Information constraint  Block-level information only no file-level semantic hints can be used</p>
    <p>Resource constraint  Limited on-device resource resource usage must be minimized</p>
    <p>Workload constraint  Regular file system workloads relatively low duplication level</p>
    <p>Overhead constraint  Stringent requirement on runtime latencies high access performance</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction</p>
    <p>Hashing and Fingerprint Store</p>
    <p>Indirect mapping Indirect mapping</p>
    <p>Acceleration methods</p>
    <p>Evaluation</p>
    <p>C l i Conclusion</p>
  </div>
  <div class="page">
    <p>Overview of CAFTL</p>
    <p>Incoming write</p>
    <p>(5) If no match, write to flash</p>
    <p>Flash Memory</p>
    <p>Segment #0</p>
    <p>Fingerprint Store Find a match?</p>
    <p>(1) Buffering (4) If match,</p>
    <p>update mapping tables</p>
    <p>Buffer</p>
    <p>Segment #1</p>
    <p>Segment #1024</p>
    <p>Mapping Tables</p>
    <p>(3) Lookup</p>
    <p>(2) Fingerprinting</p>
    <p>....1 2 3 23</p>
    <p>Primary Mapping</p>
    <p>T bl</p>
    <p>pp g</p>
    <p>Sec</p>
    <p>Hash Engine 0x743728fd43(160-bit SHA-1)</p>
    <p>( ) g p g Table Sec.</p>
    <p>Mapping Table</p>
    <p>An incoming write arrives   Dirty data is temporarily cached in an on-device buffer  Computing a SHA-1 hash value (fingerprint) for each page  Lookup against a fingerprint store to search for a match</p>
    <p>Lookup against a fingerprint store to search for a match  If a match is found update the mapping tables, drop the write  If no match is found dispatch the write to flash memory</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction</p>
    <p>Hashing and Fingerprint Store</p>
    <p>Indirect mapping Indirect mapping</p>
    <p>Acceleration methods</p>
    <p>Evaluation</p>
    <p>C l i Conclusion</p>
  </div>
  <div class="page">
    <p>Hash Function and Fingerprints</p>
    <p>Fixed-sized chunking  Basic hash unit size  a flash page (e.g. 4KB)Basic hash unit size a flash page (e.g. 4KB)</p>
    <p>A cryptographic hash function S h h f i l lli i b bili SHA-1 hash function  low collision probability</p>
    <p>Fingerprintsge p ts  A 160-bit SHA-1 hash value for a page  Identifying duplicate data by comparing fingerprints</p>
  </div>
  <div class="page">
    <p>Fingerprint Store</p>
    <p>Fingerprint Store</p>
    <p>M i t i i fi i t i  Maintaining fingerprints in memory</p>
    <p>Challenges 10-20%</p>
    <p>Memory overhead (25 bytes each)</p>
    <p>Fingerprint store lookup overhead</p>
    <p>Observations &amp; indications</p>
    <p>Skewed duplicate fingerprint distribution  only 10~20% Most fingerprints are NOT duplicate a waste of memory space Most fingerprints are NOT duplicate a waste of memory space</p>
    <p>Most lookups CANNOT find a match a waste of lookup latencies</p>
    <p>We only need to store the most likely-to-be-duplicate fingerprints in memory and search them in the fingerprint store</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction</p>
    <p>Hashing and Fingerprint Store</p>
    <p>Indirect mapping Indirect mapping</p>
    <p>Acceleration methods</p>
    <p>Evaluation</p>
    <p>C l i Conclusion</p>
  </div>
  <div class="page">
    <p>Indirect Mapping Mechanism Existing Mapping Structure</p>
    <p>Essentially 1-to-1 mapping  Forward mapping: LBA PBA (1:1)</p>
    <p>LBA PBA</p>
    <p>Flash</p>
    <p>Reverse mapping: PBA LBA (1:1)</p>
    <p>Indirect mapping in CAFTL</p>
    <p>Essentially N-to-1 mapping</p>
    <p>AInvalid</p>
    <p>Challenges  Reverse Mapping</p>
    <p># of sharing LBAs can be large/variable</p>
    <p>LBAs sharing a PBA can change on the fly</p>
    <p>A</p>
    <p>How to keep reverse-mapping info?</p>
    <p>Array, list, exhaustive scanning  high cost</p>
    <p>Keep/updating info in flash  slow/complex 15 14</p>
    <p>The Mapping Table</p>
    <p>Flash Memory</p>
  </div>
  <div class="page">
    <p>Two-level Indirect Mapping LBA PBA/</p>
    <p>Virtual block address (VBA)</p>
    <p>A pseudo address  sharing LBAs</p>
    <p>LBA /VBA 0 0 1 6 2 3</p>
    <p>Flash</p>
    <p>Primary mapping table  Unique pages  LBA PBA (1:1)</p>
    <p>Secondary mapping table VBA PBA (1 1)</p>
    <p>update the 1:N mappings</p>
    <p>VBA PBA (1:1)</p>
    <p>Reverse mapping Unique pages PBA LBA (1:1)</p>
    <p>A</p>
    <p>Unique pages  PBA LBA (1:1)</p>
    <p>Shared pages  PBA VBA (1:1) 12 9 13 0 14 3 15 3</p>
    <p>Mapping Table</p>
    <p>Mapping Table Flash Memory</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction</p>
    <p>Hashing and Fingerprint Store</p>
    <p>Indirect mapping Indirect mapping</p>
    <p>Acceleration methods</p>
    <p>Evaluation</p>
    <p>C l i Conclusion</p>
  </div>
  <div class="page">
    <p>Acceleration Methods</p>
    <p>Overhead of fingerprinting</p>
    <p>SHA 1 hash function incurs high overhead SHA-1 hash function incurs high overhead</p>
    <p>On-device buffer size is limited and can be overfilled</p>
    <p>Dedicated hash engine increases production costDedicated hash engine increases production cost</p>
    <p>Acceleration methodscce e at o et ods</p>
    <p>Sampling for hashing</p>
    <p>Light-weight pre-hashing</p>
    <p>Dynamic Switch</p>
  </div>
  <div class="page">
    <p>Sampling for Hashing</p>
    <p>Principle  Speeding up the common case  Most writes are unique most hashing operations turn out useless eventually</p>
    <p>Intuition  If a page in a write is a duplicate page, the other pages are likely to be duplicate too</p>
    <p>Sampling  Select one page in a write request as a sample  If the sample page is duplicate hash and examine the other pages If the sample page is duplicate, hash and examine the other pages  Otherwise, we stop fingerprinting the whole request at the earliest time</p>
    <p>Technical Challenges  No file-level info available e.g. we cannot use the first page in a file  Overhead concerns e.g. we cannot rely on hashing to select samples</p>
  </div>
  <div class="page">
    <p>Selecting Sample Pages</p>
    <p>Potential candidate solutions  Request-based Sampling requests may not repeat</p>
    <p>LBN b d S li itt l ti t t LBN-based Sampling written locations may not repeat</p>
    <p>Content-based Samplingp g  Selecting/comparing first four bytes in each page  The page with the largest sample bytes is the sample page</p>
    <p>S l b t th fi t f b t th b t h i Sample bytes  the first four bytes are the best choice</p>
    <p>Request-based Sampling 1 2 3 4</p>
    <p>LBN-based Sampling 1 2 3 4</p>
    <p>Content-based Sampling 1 2 3 4</p>
    <p>The first page in a request</p>
    <p>The page with LBN % 4 == 0</p>
    <p>The page with maximum sample byte</p>
  </div>
  <div class="page">
    <p>Selecting Sample Pages</p>
    <p>Potential candidate solutions  Request-based Sampling requests may not repeat</p>
    <p>LBN b d S li itt l ti t t LBN-based Sampling written locations may not repeat</p>
    <p>Content-based Samplingp g  Selecting/comparing first four bytes in each page  The page with the largest sample bytes is the sample page</p>
    <p>S l b t th fi t f b t th b t h i Sample bytes  the first four bytes are the best choice</p>
    <p>Content-based Sampling 1 2 3 41 2 3 4 1</p>
    <p>1 2 3 4</p>
    <p>X X</p>
    <p>The page with maximum sample byte</p>
    <p>First 4 bytes Sparse 4 bytesLast 4 bytes</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction</p>
    <p>Hashing and Fingerprint Store</p>
    <p>Indirect mapping Indirect mapping</p>
    <p>Acceleration methods</p>
    <p>Evaluation</p>
    <p>C l i Conclusion</p>
  </div>
  <div class="page">
    <p>Performance Evaluation</p>
    <p>SSD simulator</p>
    <p>Microsoft Research SSD extension for DiskSim simulator* - Indirect mapping, wear-leveling, garbage collection, etc.Indirect mapping, wear leveling, garbage collection, etc.</p>
    <p>Simulator augmented with CAFTL design and an on-device buffer</p>
    <p>SSD configurations</p>
    <p>Default configuration numbers</p>
    <p>Estimated latencies of hashing code on ARM simulator</p>
    <p>Description Configurations</p>
    <p>Flash page size 4KB</p>
    <p>Description Latency Flash Read 25s</p>
    <p>Fl h it 200Pages / block 64</p>
    <p>Blocks / plane 2048</p>
    <p>Num of pkgs 10</p>
    <p>Over-provisioning 15%</p>
    <p>Flash write 200s</p>
    <p>Flash Erase 1.5ms</p>
    <p>SHA-1 hashing 47,548 cycles</p>
    <p>CRC32 hashing 4,120 cycles</p>
    <p>p g g , y</p>
    <p>* MSR, http://research.microsoft.com/en-us/downloads/b41019e2-1d2b-44d8-b512-ba35ab814cd4/</p>
  </div>
  <div class="page">
    <p>Workloads</p>
    <p>Desktop (d1, d2)</p>
    <p>Office workloads  Web surfing, emailing, word editing (12 and 19 hours)</p>
    <p>Workloads feature irregular idle intervals and small read/writes</p>
    <p>TPC-H queries (h1-h7)TPC H queries (h1 h7)</p>
    <p>TPC-H queries  Query 1,6,14,15,16,20 (Scale factor of 1)</p>
    <p>Workloads run on Hadoop distributed system platform (2~40 min)</p>
    <p>Workloads feature intensive large writes of temp data</p>
    <p>Transaction processing (t1 t2)Transaction processing (t1, t2)</p>
    <p>TCP-C workloads  Transaction processing on PostgreSQL 8.4.3 database systems (1,3 warehouses, 10 terminals)</p>
    <p>W kl d f 30 i d 4 h i h i i i i</p>
    <p>Workloads run for 30 min and 4 hours with intensive write operations</p>
  </div>
  <div class="page">
    <p>Effectiveness of De-duplication i d li iRemoving duplicate writes</p>
    <p>Deduplication Rate: (n-m)/n  n  total number of pages of incoming write requests  m total number of pages being actually written into flash memory m  total number of pages being actually written into flash memory</p>
    <p>Experimental Results</p>
    <p>Deduplication Rate: 4.6% (t1) ~ 24.2% (h6)</p>
    <p>Up to 86.2% of the duplicate writes in offline (optimal case)</p>
  </div>
  <div class="page">
    <p>Effectiveness of De-duplication Extending flash space</p>
    <p>Space Saving Rate: (n-m)/n  n total number of occupied erase blocks of flash memory w/o CAFTL</p>
    <p>m total number of occupied erase blocks of flash memory w/ CAFTL m total number of occupied erase blocks of flash memory w/ CAFTL</p>
    <p>Experimental Results</p>
    <p>Space Saving Rate: up to 31.2% (h1)</p>
    <p>Small workloads (h2, h5) receive less benefits 31.2%</p>
  </div>
  <div class="page">
    <p>Effectiveness of Sampling</p>
    <p>Response Time Speedup</p>
    <p>Read  up to 110.6x</p>
    <p>W ite p to 6 9</p>
    <p>Write  up to 6.9x</p>
    <p>Deduplication Rate Reduction  Dedup Rate  24.2% 19.8% (h6)p ( )</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction</p>
    <p>Hashing and Fingerprint Store</p>
    <p>Indirect mapping Indirect mapping</p>
    <p>Acceleration methods</p>
    <p>Evaluation</p>
    <p>C l i Conclusion</p>
  </div>
  <div class="page">
    <p>Conclusion  SSD endurance would remain a serious concern in reality</p>
    <p>Data duplication is common in regular file systems, which provides unique Data duplication is common in regular file systems, which provides unique opportunities for improving SSD lifespan via deduplication on the device</p>
    <p>We present a unique Content-Aware Flash Translation Layer (CAFTL) to remove duplicate writes and coalesce redundant data in SSDs on the fly</p>
    <p>We show that CAFTL can effectively improve SSD lifespan via on-device deduplication while retaining low performance overhead</p>
    <p>Feng Chen</p>
    <p>: feng.a.chen@intel.com</p>
  </div>
</Presentation>
