<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Wimpy Nodes with 10GbE: Leveraging One-Sided Operations in Soft-RDMA to Boost Memcached</p>
    <p>Oriana Riva, Department of Computer Science | ETH Zrich</p>
    <p>Patrick Stuedi, Animesh Trivedi, Bernard Metzler</p>
    <p>IBM Research Zurich</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>Known: key/value stores and low-power CPUs/cores go well together  Workload typically not compute-heavy</p>
    <p>Slower CPU clock sufficient</p>
    <p>Easy to parallelize, distribute load over many low-power cores</p>
    <p>Examples: FAWN, Facebook/Tilera</p>
    <p>What are the implications of attaching 10 GbE NICs to the low-power key/value storage nodes?  Improved latency</p>
    <p>What about the CPU load?</p>
  </div>
  <div class="page">
    <p>Memcached/GET: 1GbE vs 10GbE</p>
    <p>Setup: 100K GET requests, 6 clients</p>
    <p>High CPU usage limits performance (ops/sec)</p>
    <p>Gigabit Ethernet 10 Gigabit Ethernet</p>
  </div>
  <div class="page">
    <p>Does multicore help?</p>
    <p>Throughput performance  Yes, considering the scaling limitations of Memcached</p>
    <p>Efficiency  More cores consume more energy</p>
    <p>Efficient processing on one-core will hopefully translate to efficient multi-core setup.</p>
  </div>
  <div class="page">
    <p>How is the CPU being used?</p>
    <p>Depends on the size of the value  Small values (~1K): 60% of CPU usage scattered across</p>
    <p>many OS functions (e.g. context switching, etc.)</p>
    <p>Larger values (~100K): 60% of CPU usage inside network stack</p>
    <p>CPU at 1.1 GHz</p>
  </div>
  <div class="page">
    <p>Using RDMA</p>
    <p>RDMA: Remote Direct Memory Access  Efficient remote memory access</p>
    <p>Zero-copy (inside the end hosts), low latency, low CPU usage</p>
    <p>Great!</p>
  </div>
  <div class="page">
    <p>Using RDMA</p>
    <p>RDMA: Remote Direct Memory Access  Efficient remote memory access</p>
    <p>Zero-copy (inside the end hosts), low latency, low CPU usage</p>
    <p>Great!</p>
    <p>Who has RDMA capable</p>
    <p>NICs deployed?</p>
  </div>
  <div class="page">
    <p>Using RDMA</p>
    <p>RDMA: Remote Direct Memory Access  Efficient remote memory access</p>
    <p>Zero-copy (inside the end hosts), low latency, low CPU usage</p>
    <p>Great!</p>
    <p>Who has RDMA capable</p>
    <p>NICs deployed?  HPC: Yes</p>
    <p>Commodity data centers?</p>
  </div>
  <div class="page">
    <p>RDMA in Software</p>
    <p>No hardware acceleration, runs on Ethernet</p>
    <p>But still RDMA semantics</p>
    <p>Example: One-sided RDMA read in SoftiWARP  Zero copy, no context switching, low CPU footprint, etc.</p>
  </div>
  <div class="page">
    <p>Memcached/RDMA</p>
    <p>Modified Memcached Architecture:</p>
    <p>New value: get new chunk, store key/value pair, return stag</p>
    <p>Update value: get new chunk, store store key/value pair, swap stags with old chunk</p>
    <p>Zero copy</p>
    <p>No context switch</p>
    <p>Move parts of server processing to the client (e.g., request parsing)</p>
  </div>
  <div class="page">
    <p>Memcached/RDMA (2)</p>
    <p>single process</p>
    <p>user space</p>
    <p>kernel space</p>
    <p>kernel network processing</p>
    <p>event dispatcher</p>
    <p>chained hash table</p>
    <p>soft-RDMA provider</p>
    <p>thread 1</p>
    <p>thread N</p>
  </div>
  <div class="page">
    <p>single process</p>
    <p>user space</p>
    <p>kernel space</p>
    <p>kernel network processing</p>
    <p>event dispatcher</p>
    <p>chained hash table</p>
    <p>soft-RDMA provider</p>
    <p>Register memory chunks</p>
    <p>thread 1</p>
    <p>thread N</p>
    <p>Memcached/RDMA (2)</p>
  </div>
  <div class="page">
    <p>Memcached/RDMA (2)</p>
    <p>single process</p>
    <p>user space</p>
    <p>kernel space</p>
    <p>kernel network processing</p>
    <p>event dispatcher</p>
    <p>chained hash table</p>
    <p>GET request</p>
    <p>soft-RDMA provider</p>
    <p>Register memory chunks</p>
    <p>memory chunk</p>
    <p>thread 1</p>
    <p>thread N</p>
  </div>
  <div class="page">
    <p>Implementation &amp; Benchmarks</p>
    <p>Implementation Memcached/RDMA  Standalone prototype: server/client</p>
    <p>Uses Memcached data types (e.g., item for storing key/value pairs)</p>
    <p>Benchmark Setup  1 Server, 6 Clients</p>
    <p>4 core Intel Xeon E5345, 10GbE</p>
    <p>Server CPU clock frequency: 1.1 Ghz</p>
    <p>1000 pre-insterted key/value pairs</p>
    <p>OProfile to measure CPU load</p>
  </div>
  <div class="page">
    <p>CPU Efficiency</p>
    <p>Memcached/RDMA consumes less CPU  For small packets: less OS overhead (excluding network stack)</p>
    <p>For large packets: less network stack overhead</p>
  </div>
  <div class="page">
    <p>Multicore Performance</p>
    <p>Memcached/RDMA with one core performs like Memcached with 4 cores</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Memcached/RDMA is a more CPU efficient Memcached based on Software RDMA  Zero copy, zero context switching for re-occurring GET</p>
    <p>requests, memory chunk parsing moved to client side</p>
    <p>No special hardware required</p>
    <p>Architecture also suitable for SSD based key/value stores  Any combination of high bandwidth storage and fast</p>
    <p>network will put pressure on the CPU</p>
    <p>Outlook: multicore, latency, etc.</p>
  </div>
  <div class="page">
    <p>Thanks! Questions?</p>
    <p>http://gitorious.org/softiwarp</p>
  </div>
</Presentation>
