<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Dont Tread on Me:</p>
    <p>Moderating Access to</p>
    <p>OSN Data with</p>
    <p>SpikeStrip</p>
    <p>Christo Wilson, Alessandra Sala,</p>
    <p>Joseph Bonneau*, Robert Zablit,</p>
    <p>Ben Y. Zhao</p>
    <p>University of California, Santa Barbara</p>
    <p>*University of Cambridge</p>
  </div>
  <div class="page">
    <p>Problem: People Want Your Data</p>
    <p>from: Birthday E-Cards &lt;cardbot@evil-cards.com&gt;</p>
    <p>to: Christo Wilson &lt;bowlinearl@gmail.com&gt;</p>
    <p>date: Monday, January 31, 2011 at 12:01 AM</p>
    <p>subject: You got a Birthday E-Card!</p>
    <p>Youve received a Happy Birthday E-Card from Sandi Klopcic!</p>
    <p>Visit this link to view your card: http://www.evil-cards.com/</p>
  </div>
  <div class="page">
    <p>Big Data = Big Problems</p>
    <p>450 Million 150 Million 70 Million</p>
    <p>Crawlers are actively collecting OSN data</p>
    <p>Pete Warden crawled 210 Million profiles</p>
    <p>crawls and sells OSN data to marketers</p>
    <p>offers crawling as a service (150K pages per $1)</p>
    <p>Yes, this includes researchers</p>
    <p>Many more emerging threats!</p>
  </div>
  <div class="page">
    <p>How Can the Crawlers Be Controlled?</p>
    <p>Users are unwilling/unable to defend themselves</p>
    <p>Privacy paradox  paranoia vs. laziness</p>
    <p>Privacy conscious people (us) are the minority</p>
    <p>OSNs have notoriously difficult privacy settings</p>
    <p>OSNs must protect their users but how?</p>
    <p>Existing anti-crawler mechanisms are ineffective</p>
    <p>Designed in the mid 90s</p>
    <p>Broadband + botnets = massive, distributed crawlers</p>
    <p>More on this later</p>
    <p>New technology is necessary</p>
    <p>Image  The New York Times http://www.nytimes.com/interactive/2010/05/12/business/facebook-privacy.html</p>
  </div>
  <div class="page">
    <p>Introducing SpikeStrip</p>
    <p>Project goal: defend against malicious crawlers</p>
    <p>Seamless to end-users and beneficial crawlers</p>
    <p>Minimal impact on web server</p>
    <p>Compatible with existing technology</p>
    <p>SpikeStrip uses novel link-encryption primitive</p>
    <p>Used to track and rate-limit users</p>
    <p>Implement and evaluate SpikeStrip</p>
    <p>Can impose arbitrary slowdowns on rogue crawlers</p>
    <p>Only imposes 7% performance overhead on web server</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>Existing Defenses (and why they dont work)</p>
    <p>Designing SpikeStrip</p>
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>File placed on web server that tells crawlers how to behave</p>
    <p>Problem: compliance is voluntary</p>
    <p>Robots.txt</p>
  </div>
  <div class="page">
    <p>Filter requests based on HTTP Request Header information</p>
    <p>Problem: headers can be modified by clients</p>
    <p>HTTP Request Headers</p>
    <p>HTTP Request</p>
    <p>GET /index.html HTTP/1.1</p>
    <p>Host: www.slashdot.org</p>
    <p>User-Agent: Googlebot/2.1Mozilla/5.0 Firefox/2.0.0.9</p>
  </div>
  <div class="page">
    <p>Rate limit request on a per-IP basis</p>
    <p>Problem 1: NATs and Proxies</p>
    <p>IP Address Tracking</p>
  </div>
  <div class="page">
    <p>Rate limit request on a per-IP basis</p>
    <p>Problem 2: Botnets</p>
    <p>IP Address Tracking</p>
  </div>
  <div class="page">
    <p>OSNs require users to sign-up and log-in</p>
    <p>Ban user accounts that generate too much traffic</p>
    <p>Problem: URLs are session independent</p>
    <p>Authenticated User Accounts</p>
    <p>URL</p>
    <p>Queue</p>
    <p>User</p>
    <p>Accounts</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>Existing Defenses (and why they dont work)</p>
    <p>Designing SpikeStrip</p>
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>Link-Encryption</p>
    <p>State of the art in crawler defense isnt enough</p>
    <p>URLs are still session independent</p>
    <p>Crawlers can switch accounts, share state between accounts</p>
    <p>Need a way to link URLs to clients</p>
    <p>Solution: server-side link-encryption</p>
    <p>Encrypt links using users session key and server-side secret key</p>
    <p>Uniquely binds all served URLs to the user</p>
    <p>Link-encryption enables reliable per-session tracking</p>
    <p>Rate-limit sessions to throttle crawlers</p>
  </div>
  <div class="page">
    <p>Link-Encryption Example</p>
    <p>Session Key = ABC123</p>
    <p>Get /index.html</p>
    <p>&lt;html&gt;</p>
    <p>&lt;a href= /product.html &gt;</p>
    <p>Buy this product&lt;/a&gt;</p>
    <p>&lt;/html&gt;</p>
    <p>/SSA3OFLX7B9</p>
    <p>Get /SSA3OFLX7B9</p>
    <p>&lt;html&gt;</p>
    <p>Product info and such.</p>
    <p>&lt;/html&gt;</p>
    <p>/product.html</p>
    <p>Session Key = XYZ789</p>
    <p>Get /SSA3OFLX7B9 /hF4%fjGG&amp;zL</p>
    <p>HTTP 404 Not Found Error</p>
    <p>Secret Key = ********</p>
    <p>HTTP 403 Forbidden Error</p>
    <p>Get /product.html</p>
  </div>
  <div class="page">
    <p>Implications of Link Encryption</p>
    <p>Consider a BFS on an OSN website</p>
    <p>Queued URLs are bound to session</p>
    <p>Prevents sessionswitching</p>
    <p>index.html</p>
    <p>Frontier</p>
    <p>Session Key =</p>
    <p>ABC123</p>
    <p>Session Key =</p>
    <p>XYZ789</p>
    <p>Frontier</p>
  </div>
  <div class="page">
    <p>Rate Tracking and Limiting</p>
    <p>Reliable tracking enables rate limiting</p>
    <p>Very tight limits  no need to pad for NATs</p>
    <p>Enforcement  drop requests, ban accounts, etc</p>
    <p>Challenge: Scaling to high volume OSN sites</p>
    <p>Solution: Counting Bloom Filters</p>
    <p>Often used in high-throughput network security contexts</p>
    <p>SpikeStrip uses d-left CBF  fastest and most space efficient CBF variant</p>
  </div>
  <div class="page">
    <p>SpikeStrip Overview</p>
    <p>Link-encryption creates per-session views of the OSN</p>
    <p>URLs are unique within each view</p>
    <p>Binds URLs and clients</p>
    <p>Enables reliable client tracking</p>
    <p>Prevents bad behavior</p>
    <p>Crawlers cant switch sessions</p>
    <p>Distributed crawlers cant share URLs</p>
    <p>Enables strong rate-limiting</p>
    <p>Doesnt hinder normal users and useful crawlers</p>
    <p>Whitelist safe URLs using regex</p>
    <p>Whitelist IPs/domains of good crawlers</p>
    <p>S u m</p>
    <p>m a r y</p>
    <p>N e w</p>
    <p>!</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>Existing Defenses (and why they dont work)</p>
    <p>Designing SpikeStrip</p>
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>SpikeStrip Evaluation</p>
    <p>Questions:</p>
    <p>How much server overhead does SpikeStrip cause?</p>
    <p>Implemented SpikeStrip as an Apache 2 module</p>
    <p>256-bit AES encryption, d-left CBF</p>
    <p>How effective is SpikeStrip at throttling crawlers?</p>
    <p>Created mock OSN called Fakebook</p>
    <p>Based on data from London</p>
    <p>3.5 Million pages</p>
    <p>Typical LAMP setup (Linux, Apache, MySQL, Python)</p>
    <p>10 load-balanced web servers, 1 DB</p>
  </div>
  <div class="page">
    <p>SpikeStrip Micro-Benchmarks</p>
    <p>Link</p>
    <p>Decryption</p>
    <p>Rate Limiting Link</p>
    <p>Encryption (0)</p>
    <p>Link</p>
    <p>Encryption (3)</p>
    <p>Link</p>
    <p>Encryption</p>
    <p>(10)</p>
    <p>Link</p>
    <p>Encryption</p>
    <p>(25)</p>
    <p>T im</p>
    <p>e P</p>
    <p>e r R</p>
    <p>e q</p>
    <p>u e s t</p>
    <p>( s )</p>
    <p>Handle Incoming</p>
    <p>Requests</p>
    <p>Process Outgoing HTML</p>
    <p>On average, SpikeStrip reduces</p>
    <p>Apache performance by 7%</p>
  </div>
  <div class="page">
    <p>SpikeStrip vs. Crawlers</p>
    <p>% o</p>
    <p>f S</p>
    <p>it e C</p>
    <p>r a w</p>
    <p>le d</p>
    <p>Time (Hours)</p>
    <p>Complete Crawl</p>
    <p>Rate limit = 1000 requests per hour</p>
    <p>0.25 Requests Per Second (RPS)</p>
    <p>Crawl rate = 0.25 RPS * # of sessions Each hour the request counters reset</p>
    <p>Successfully throttles crawlers</p>
    <p>Speed penalties can be made</p>
    <p>arbitrarily harsh, depending rate</p>
    <p>limiter parameters</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>OSN users are defenseless against malicious crawlers</p>
    <p>Its up to OSNs to secure users data</p>
    <p>SpikeStrip uses novel link-encryption technique</p>
    <p>Overcomes traditional user tracking challenges</p>
    <p>Disambiguates users behind NATs/proxies</p>
    <p>Renders botnets ineffectual</p>
    <p>Minimal inconvenience for end-users</p>
    <p>SpikeStrip works in practice</p>
    <p>Imposes minimal overhead on server</p>
    <p>Successfully throttles crawlers</p>
    <p>Works with existing Apache setups</p>
  </div>
  <div class="page">
    <p>SpikeStrip for Apache 2.x</p>
    <p>is Open Source!</p>
    <p>Source code and benchmark tests available at</p>
    <p>http://www.cs.ucsb.edu/~bowlin/projects.html</p>
  </div>
  <div class="page">
    <p>Why are OSNs so popular?</p>
    <p>Christo Wilson @ University of California, Santa Barbara</p>
    <p>Sharing and Socializing</p>
    <p>Convenience</p>
    <p>Because everyone uses them!</p>
    <p>(Corollary: they have lots of data)</p>
    <p>Games and Interaction</p>
  </div>
  <div class="page">
    <p>Existing Defenses Against Crawlers</p>
    <p>Passive Defenses</p>
    <p>Robots.txt</p>
    <p>HTTP Request Header Filtering</p>
    <p>Active Defenses</p>
    <p>Relies on identifying, tracking, and rate limiting clients</p>
    <p>Usually done by IP address</p>
    <p>Authentication Based Defenses</p>
    <p>Control access by authenticating users</p>
    <p>Use CAPTCHAs to control account creation</p>
    <p>Ban users who break the rules</p>
  </div>
  <div class="page">
    <p>Link Opacity</p>
    <p>Link-encryption makes links opaque</p>
    <p>bit.ly/bXRgmp  www.engadget.com/2010/06/07/</p>
    <p>facebook.com/secure/AnvTR641z  facebook.com/christowilson</p>
    <p>Not useful for security  metadata allows disambiguation</p>
    <p>&lt;a href=http://facebook.com/secure/AnvTR641z&gt;</p>
    <p>Christo Wilsons Profile</p>
    <p>&lt;/a&gt;</p>
  </div>
  <div class="page">
    <p>Link Sharing</p>
    <p>Link-encryption makes it hard to share links</p>
    <p>Lots of web tech already does this</p>
    <p>Shopping carts</p>
    <p>AJAX</p>
    <p>Important pages to people  important pages to crawlers</p>
    <p>Crawlers need friends lists and search results</p>
    <p>People want pictures</p>
    <p>Solution: permalinks</p>
    <p>en.wikipedia.org/wiki/Facebook vs.</p>
    <p>en.wikipedia.org/w/index.php?title=Facebook&amp;oldid=366580719</p>
  </div>
  <div class="page">
    <p>End-to-End Latency</p>
    <p>T im</p>
    <p>e P</p>
    <p>e r R</p>
    <p>e q</p>
    <p>u e s t</p>
    <p>(S )</p>
    <p># of Requesting Threads</p>
    <p>Apache with SpikeStrip</p>
    <p>Apache</p>
  </div>
  <div class="page">
    <p>Does SpikeStrip Ruin OSN Research?</p>
    <p>NO!  SpikeStrip enables OSNs to set up controlled access</p>
    <p>channels for researchers</p>
    <p>i.e. *.ucsb.edu can crawl at rate X for Y days</p>
    <p>This arrangement benefits both parties</p>
    <p>Researchers can crawl in a secure way</p>
    <p>No need deal with account bans, etc</p>
    <p>OSNs can control who has access and their bandwidth allocation</p>
  </div>
</Presentation>
