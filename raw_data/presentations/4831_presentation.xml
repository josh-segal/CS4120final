<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Lazy Approximation An approach for solving continuous finite-horizon MDPs</p>
    <p>Presented by Lihong Li</p>
    <p>Joint work with Michael Littman</p>
    <p>With thanks to N. Meuleau and other RL3 members</p>
    <p>AAAI-05 / Rutgers Lab for Real-Life Reinforcement Learning (RL3)</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>Markov decision processes (MDPs) Framework for decision-theoretic planning</p>
    <p>Many problems are continuous in nature Transportation scheduling [Boyan &amp; Littman 00] Planetary rover planning [Bresina et al. 02]</p>
  </div>
  <div class="page">
    <p>Planetary Rover Example</p>
    <p>State components include Remaining energy Remaining execution time</p>
    <p>Continuous state transition E.g., energy consumption of taking a picture</p>
    <p>p.d.f. of energy consumption</p>
    <p>Both continuous</p>
  </div>
  <div class="page">
    <p>Introduction (contd)</p>
    <p>Solving large-scale MDPs is difficult Curse of dimensionality</p>
    <p>Solving continuous MDPs is even more difficult</p>
    <p>Need practical representations for models value functions</p>
    <p>Need efficient &amp; stable approximate solutions</p>
  </div>
  <div class="page">
    <p>Notation</p>
    <p>MDP X: continuous state space</p>
    <p>Usuallly, X=[0,1)k</p>
    <p>A: finite action set T: transition function R: reward function</p>
    <p>Solving MDPs by dynamic programming Bellman equation</p>
  </div>
  <div class="page">
    <p>Previous Work</p>
    <p>[Boyan &amp; Littman 00]: TiMDP [Feng et al. 04]: extension Limited to structured MDPs with</p>
    <p>Reward function PWC or PWLC Continuous</p>
    <p>Transition function: Discrete Need to pre-specify discretization resolution Referred to as DM</p>
    <p>Motivation: discretization-free?</p>
  </div>
  <div class="page">
    <p>LA Summary</p>
    <p>Design objectives Continuous PWC transitions T Continuous PWC reward R Flexible error control Flexible function compactness control</p>
    <p>Compactness: # pieces in PWC functions Main idea</p>
    <p>Manipulate the continuous model directly Postpone approximation until necessary</p>
    <p>Thus called lazy approximation (LA)</p>
    <p>But were not lazy</p>
  </div>
  <div class="page">
    <p>Recall Bellman Equation</p>
    <p>Two transition models</p>
    <p>Absolute model:</p>
    <p>Relative model:</p>
    <p>Relative model is more challenging Integral becomes a convolution of two PWCs</p>
    <p>( ' | ) ( ' | )T x xa T x x a=</p>
    <p>( ' | ) ( ' | )T x xa T x a=</p>
  </div>
  <div class="page">
    <p>Basic Idea</p>
    <p>DP LA</p>
    <p>compact approximation</p>
    <p>convolution approximation</p>
    <p>small</p>
    <p>DP</p>
  </div>
  <div class="page">
    <p>Extensions</p>
    <p>Multidimensional state spaces PWC: constant in each hyper-rectangle Can use kd-trees [Friedman et al. 77] Convolution of two PWCs</p>
    <p>Efficient LA: Complexity of finding optimal constant-function approximation within each piece: O(k)</p>
  </div>
  <div class="page">
    <p>Extensions (contd)</p>
    <p>Non-PWC transition function Approximate it w/ PWC Favored by empirical evidence, over DM</p>
    <p>Dealing w/ discrete state components Rover example No additional essential difficulties Can be handled within the same framework</p>
  </div>
  <div class="page">
    <p>Error Control</p>
    <p>DP LA</p>
    <p>Errors in DM rely on 1. Resolution 2. Smoothness of the value function: not measurable</p>
    <p>L</p>
  </div>
  <div class="page">
    <p>Compactness Control</p>
    <p>DP LA</p>
    <p>more compact at the same error level</p>
    <p>Compactness/resolution in DM is usually determined a priori</p>
  </div>
  <div class="page">
    <p>Experiments</p>
    <p>Randomly generated 1-D problems State space: [0,1) Horizon: 10 PWC reward PWC or Gaussian transitions</p>
    <p>For Gaussian transitions DM: use discretization LA: use PWC approximation</p>
  </div>
  <div class="page">
    <p>Horizon = 1 S</p>
    <p>ta te</p>
    <p>v al</p>
    <p>ue</p>
  </div>
  <div class="page">
    <p>Horizon = 5 S</p>
    <p>ta te</p>
    <p>v al</p>
    <p>ue</p>
  </div>
  <div class="page">
    <p>Horizon = 10 S</p>
    <p>ta te</p>
    <p>v al</p>
    <p>ue</p>
    <p>FuncSizeTime (s)</p>
  </div>
  <div class="page">
    <p>Error Results</p>
    <p>Gaussian transitions</p>
  </div>
  <div class="page">
    <p>Compactness Results</p>
    <p>Gaussian transitions</p>
  </div>
  <div class="page">
    <p>One Application</p>
    <p>Planetary rover planning Two-location, two-object problem</p>
    <p>More realistic experiments in the future energ</p>
    <p>ytime</p>
    <p>st at</p>
    <p>e va</p>
    <p>lu e</p>
  </div>
  <div class="page">
    <p>Future Work Efficient data structures and algorithms for</p>
    <p>manipulating models computing convolution is quite expensive with kd-trees</p>
    <p>lazy approximation w/ specified error level currently, greedy alg for high dimensional space</p>
    <p>Relax some structural constraints</p>
    <p>Implement wait/dawdle actions [Boyan &amp; Littman 00] E.g., wait until sunrise to take high-quality pictures</p>
    <p>Real-world applications E.g., planetary rover planning</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Developed Lazy Approximation Solving continuous structured MDPs Discretization-free Flexible error control Flexible compactness control</p>
    <p>For more details: Rutgers CS Tech Report #577 RL3: http://www.cs.rutgers.edu/rl3</p>
    <p>Questions &amp; comments?</p>
  </div>
</Presentation>
