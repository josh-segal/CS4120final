<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>A Crowdsourced Frame Disambiguation Corpus with Ambiguity</p>
    <p>Anca Dumitrache, Lora Aroyo, Chris Welty</p>
  </div>
  <div class="page">
    <p>For prevention of malaria, use only in individuals traveling to malarious</p>
    <p>areas where CHLOROQUINE resistant P. falciparum MALARIA has</p>
    <p>not been reported.</p>
    <p>TYPICAL EXPERT ANNOTATION TASK</p>
    <p>Rheumatoid arthritis and MALARIA have been treated with</p>
    <p>CHLOROQUINE for decades.</p>
    <p>Does the sentence express TREATS?</p>
    <p>Among 56 subjects reporting to a clinic with symptoms of MALARIA</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
  </div>
  <div class="page">
    <p>For prevention of malaria, use only in individuals traveling to malarious</p>
    <p>areas where CHLOROQUINE resistant P. falciparum MALARIA has</p>
    <p>not been reported.</p>
    <p>Rheumatoid arthritis and MALARIA have been treated with</p>
    <p>CHLOROQUINE for decades.</p>
    <p>Among 56 subjects reporting to a clinic with symptoms of MALARIA</p>
    <p>BUT WHEN YOU ENCOURAGE DISAGREEMENT</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
    <p>Does the sentence express TREATS?</p>
  </div>
  <div class="page">
    <p>Theres a difference between these two</p>
    <p>This one isnt utterly wrong</p>
    <p>BETTER</p>
    <p>WORSE</p>
    <p>areas where CHLOROQUINE resistant P. falciparum MALARIA has</p>
    <p>not been reported.</p>
    <p>Rheumatoid arthritis and MALARIA have been treated with</p>
    <p>CHLOROQUINE for decades.</p>
    <p>Among 56 subjects reporting to a clinic with symptoms of MALARIA</p>
    <p>AND ASK THE CROWD ...</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
    <p>Does the sentence express TREATS?</p>
  </div>
  <div class="page">
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
    <p>What causes disagreement?</p>
    <p>Workers  spam, lazy, unskilled</p>
    <p>Sentences  missing context  tokenization, span detection, etc.  doesnt quite fit the task  poorly written, vague, ambiguous</p>
    <p>Target Semantics  unclear, confusing relations or types  granularity issues  limits of inference</p>
  </div>
  <div class="page">
    <p>What causes disagreement?</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
    <p>Workers  spam, lazy, unskilled</p>
    <p>Sentences  missing context  tokenization, span detection, etc.  doesnt quite fit the task  poorly written, vague, ambiguous</p>
    <p>Target Semantics  unclear, confusing relations or types  granularity issues  limits of inference</p>
  </div>
  <div class="page">
    <p>CROWDTRUTH Three Sides of CrowdTruth, Human Computation 2014, L. Aroyo, C. Welty</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
  </div>
  <div class="page">
    <p>CrowdTruth Methodology</p>
    <p>Annotator disagreement is signal, not noise</p>
    <p>It is indicative of the variation in human semantic interpretation</p>
    <p>It can indicate ambiguity, vagueness, similarity, over-generality, as well as quality</p>
    <p>CrowdTruth.org</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
  </div>
  <div class="page">
    <p>What is FrameNet?</p>
    <p>FrameNet: computational linguistics resource based</p>
    <p>on the frame semantics theory (Baker, Fillmore, Lowe,</p>
    <p>collection of semantic frames</p>
    <p>documents annotated with these frames</p>
    <p>semantic frame: abstract representation of a word</p>
    <p>sense, describing a type of entity, relation, or event</p>
    <p>grounded in roles implied by the frame</p>
    <p>e.g. from &amp; to are roles in a movement frame</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
  </div>
  <div class="page">
    <p>Frame Disambiguation</p>
    <p>= task of selecting the best frame for a word phrase</p>
    <p>Illegal skimming of profits is rampant.</p>
    <p>A. removing</p>
    <p>B. theft</p>
    <p>C. commiting crime</p>
    <p>D. cause change</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
  </div>
  <div class="page">
    <p>Frame Disambiguation</p>
    <p>= task of selecting the best frame for a word phrase</p>
    <p>Illegal skimming of profits is rampant.</p>
    <p>A. removing (*)</p>
    <p>B. theft</p>
    <p>C. commiting crime</p>
    <p>D. cause change</p>
    <p>The frame picked by the expert is marked with (*). What does the crowd think?</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
  </div>
  <div class="page">
    <p>Frame Disambiguation</p>
    <p>= task of selecting the best frame for a word phrase</p>
    <p>Illegal skimming of profits is rampant.</p>
    <p>A. removing (*)  7 votes</p>
    <p>B. theft  6 votes</p>
    <p>C. commiting crime  6 votes</p>
    <p>D. cause change  4 votes</p>
    <p>The frame picked by the expert is marked with (*).</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
  </div>
  <div class="page">
    <p>Dataset  9000 sentence-word pairs from Wikipedia</p>
    <p>&lt;= 25 candidate frames per word</p>
    <p>POS: verb, noun</p>
    <p>in 1000 pairs from this set, the word (i.e. Lexical Unit) is not in FrameNet</p>
    <p>Pre-processing to find candidate frames for each word:</p>
    <p>match word to synonym sets in WordNet corpus (Miller, 1995)</p>
    <p>match synonym set to FrameNet frame using Framester corpus (Gangemi et al., 2016)</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
  </div>
  <div class="page">
    <p>Example sentences for each frame, toggled by button</p>
    <p>Frame definition</p>
    <p>Frame definition</p>
    <p>Multiple choice task</p>
    <p>Crowdsourcing task</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
  </div>
  <div class="page">
    <p>Worker Vectors</p>
    <p>Sentence Vector</p>
    <p>W1:</p>
    <p>W2:</p>
    <p>W3:</p>
    <p>W4:</p>
    <p>W5:</p>
    <p>W6:</p>
    <p>W7:</p>
    <p>W8:</p>
    <p>Co m</p>
    <p>m un</p>
    <p>ica tio</p>
    <p>n</p>
    <p>At te</p>
    <p>m pt</p>
    <p>su as</p>
    <p>io n</p>
    <p>Ca us</p>
    <p>e ch</p>
    <p>an ge</p>
    <p>. . .</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
  </div>
  <div class="page">
    <p>CrowdTruth metrics Frame-Sentence Score (FSS): the degree with which a particular frame matches the sense of the word in the sentence</p>
    <p>Sentence Quality Score (SQS): overall worker agreement over one sentence, measured with cosine similarity</p>
    <p>Frame Quality Score (FQS): agreement over a frame in all sentences where the frame was picked at least once</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
  </div>
  <div class="page">
    <p>Frame-Sentence Score (FSS): how clearly the frame is expressed in the sentence</p>
    <p>Egypt has provided no evidence demonstrating the elimination of its biological weapons.</p>
    <p>removing - FSS = 0.938 cause change - FSS = 0.175</p>
    <p>Example sentences with removing frame:</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
  </div>
  <div class="page">
    <p>Egypt has provided no evidence demonstrating the elimination of its biological weapons.</p>
    <p>The Syrian Mujahiddin asked Hussein to overthrow the regime of Hafiz Al Assad.</p>
    <p>removing - FSS = 0.938 cause change - FSS = 0.175</p>
    <p>change of leadership - FSS = 0.847 removing - FSS = 0.539</p>
    <p>Example sentences with removing frame:</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
    <p>Frame-Sentence Score (FSS): how clearly the frame is expressed in the sentence</p>
  </div>
  <div class="page">
    <p>Egypt has provided no evidence demonstrating the elimination of its biological weapons.</p>
    <p>The Syrian Mujahiddin asked Hussein to overthrow the regime of Hafiz Al Assad.</p>
    <p>Illegal skimming of profits is rampant.</p>
    <p>removing - FSS = 0.938 cause change - FSS = 0.175</p>
    <p>change of leadership - FSS = 0.847 removing - FSS = 0.539</p>
    <p>removing - FSS = 0.532 theft - FSS = 0.494 commiting crime - FSS = 0.459 misdeed - FSS = 0.431 cause change - FSS = 0.273</p>
    <p>Example sentences with removing frame:</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
    <p>Frame-Sentence Score (FSS): how clearly the frame is expressed in the sentence</p>
  </div>
  <div class="page">
    <p>Egypt has provided no evidence demonstrating the elimination of its biological weapons.</p>
    <p>The Syrian Mujahiddin asked Hussein to overthrow the regime of Hafiz Al Assad.</p>
    <p>Illegal skimming of profits is rampant.</p>
    <p>Sentence Quality Score (SQS): how ambiguous the sentence is</p>
    <p>removing - FSS = 0.938 cause change - FSS = 0.175</p>
    <p>change of leadership - FSS = 0.847 removing - FSS = 0.539</p>
    <p>removing - FSS = 0.532 theft - FSS = 0.494 commiting crime - FSS = 0.459 misdeed - FSS = 0.431 cause change - FSS = 0.273</p>
    <p>SQS = 0.841</p>
    <p>SQS = 0.669</p>
    <p>SQS = 0.366</p>
    <p>Example sentences with removing frame:</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
  </div>
  <div class="page">
    <p>Frame Quality Score (FQS): how ambiguous the frame is</p>
    <p>Concrete frames have high FQS.</p>
    <p>e.g. removing</p>
    <p>Abstract frames have low FQS.</p>
    <p>e.g. cause change</p>
    <p>Frames with overlapping definitions have low FQS.</p>
    <p>e.g. objective influence &amp; subjective influence</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
  </div>
  <div class="page">
    <p>Ambiguity in the corpus</p>
    <p>More ambiguous</p>
  </div>
  <div class="page">
    <p>Ambiguity in the corpus</p>
    <p>There is more ambiguity for sentences where the Lexical Unit is not part of FrameNet.</p>
    <p>More ambiguous</p>
  </div>
  <div class="page">
    <p>These Articles continue to direct the ethos of the Communion.</p>
    <p>Some aikido organizations use belts to distinguish practitioners grades</p>
    <p>Cornwallis prematurely abandoned his outer position, hastening his subsequent defeat.</p>
    <p>Why does ambiguity happen?</p>
    <p>activity ongoing - FSS = 0.862 process continue - FSS = 0.86</p>
    <p>SQS = 0.795</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
    <p>parent-child relation between frames</p>
    <p>differentiation - FSS = 0.867 distinctiveness - FSS = 0.703</p>
    <p>SQS = 0.68 overlapping frame definitions</p>
    <p>speed description - FSS = 0.39 assistance - FSS = 0.209 self motion - FSS = 0.165 travel - FSS = 0.16 causation - FSS = 0.124</p>
    <p>SQS = 0.134</p>
    <p>meaning of the word is a composition of frames</p>
  </div>
  <div class="page">
    <p>Evaluation with CrowdTruth data Models:</p>
    <p>OS: OpenSesame frame disambiguation classifier (Swayamdipta et al., 2017), results in 1 frame per sentence, cannot classify Lexical Units not in FrameNet</p>
    <p>OS+: OpenSesame modified to perform multi-label classification, cannot classify Lexical Units not in FrameNet</p>
    <p>Framester: rule-based multi-class multi-label classification; works on an older version of FrameNet</p>
    <p>TC: top frame picked by the crowd</p>
    <p>Evaluation metrics:</p>
    <p>Kendalls : list ranking coefficient  cosine similarity: distance between FSS-labeled crowd frames &amp; frames predicted by the models</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
  </div>
  <div class="page">
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
    <p>Restricted Set = sentences where all the Lexical Units are in FrameNet (i.e. less ambiguous)</p>
    <p>OS+ does better than TC for Kendalls . Correctly ranking multiple frames per sentence is more important than finding the single best frame.</p>
  </div>
  <div class="page">
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
    <p>OS+ performance drops, since it cant classify Lexical Units not in FrameNet. FS performance is low because of missing frames in the older version of FrameNet it uses.</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Results:</p>
    <p>9000 sentences from FrameNet annotated with CrowdTruth</p>
    <p>Theres not only one right answer for each example, tolerate multiple outcomes</p>
    <p>Dont assume lexical resources are perfect</p>
    <p>Disagreement is a good indicator of ambiguity in sentences &amp; frames.</p>
    <p>Resources:</p>
    <p>Dataset: https://github.com/CrowdTruth/FrameDisambiguation</p>
    <p>CrowdTruth metrics: https://github.com/CrowdTruth/CrowdTruth-core</p>
    <p>CrowdTruth metrics Python package: https://pypi.org/project/CrowdTruth/</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
  </div>
  <div class="page">
    <p>Crowd vs. FrameNet experts ground truth</p>
    <p>Crowd performance is comparable to the experts.</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
  </div>
  <div class="page">
    <p>SQS and FQS vs. Expert ground truth</p>
    <p>When the crowd workers agree with each other, they also agree with the expert.</p>
    <p>But disagreement can have a good reason!</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
  </div>
  <div class="page">
    <p>Crowd misunderstood the frame definition.</p>
    <p>Information in the sentence is incomplete.</p>
    <p>Crowd is correct.</p>
    <p>When crowd &amp; expert disagree</p>
    <p>Does supersizing cause obesity?</p>
    <p>Crowd: cause to start (FSS = 0.804)</p>
    <p>Expert: causation (FSS = 0.608)</p>
    <p>The investigation has been stymied, stopped, obstructions thrown every step of the way. Crowd: criminal investigation (FSS = 0.804)</p>
    <p>Expert: scrutiny (FSS = 0.305)</p>
    <p>Crowd still picked the expert frame, but with lower FSS.</p>
    <p>@anca_dmtrch @laroyo @cawelty CrowdTruth.org #CrowdTruth</p>
  </div>
</Presentation>
