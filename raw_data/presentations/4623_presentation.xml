<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>From Chaos to QoS: Case Studies in From Chaos to QoS: Case Studies in</p>
    <p>CMP Resource ManagementCMP Resource Management</p>
    <p>North Carolina State University</p>
    <p>Stanford UniversityIntel Corporation</p>
    <p>Hari Kannan, Fei Guo, Li Zhao, Ramesh Illikkal, Ravi Iyer, Don Newell, Yan Solihin, Christos Kozyrakis</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation and Problem Statement</p>
    <p>QoS in Resource Management  Platform QoS</p>
    <p>Case Study: Cache Resource</p>
    <p>Experiments and Evaluation  Prototype Implementation</p>
    <p>Initial Results</p>
    <p>Summary</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>More cores are integrated on the die</p>
    <p>Multi-tasking becomes more common: multiple applications are running simultaneously</p>
    <p>Virtualized workloads become mainstream: multiple VMs are consolidated onto the same platform</p>
    <p>Problems in platform resource management</p>
    <p>Loss of efficiency</p>
    <p>Disparate Behavior or Disparate Resource Usage of simultaneously-running applications/VMs</p>
    <p>No fairness or determinism guarantees</p>
    <p>Cache space or memory bandwidth available is non-deterministic</p>
    <p>No prioritization</p>
    <p>Cannot map priority level to platform resource allocation</p>
  </div>
  <div class="page">
    <p>Problem Statement</p>
    <p>Not all applications are equal - Users have preferences  End-users (client) want to treat foreground preferentially  End-users (server) want to provide service differentiation</p>
    <p>Priority-based OS scheduling no longer sufficient  With more cores, OS will allow high and low priority</p>
    <p>applications to run simultaneously  Low priority applications will steal platform resources from</p>
    <p>high priority apps  loss in performance &amp; user experience</p>
    <p>Platform has no support for application differentiation  No knowledge of user preferences  No support for preferential treatment</p>
  </div>
  <div class="page">
    <p>Example of Resource Sharing Impact</p>
    <p>Choose art as high priority and iperf as low priority</p>
    <p>High priority application suffers 10X more cache misses  Iperf has poor cache locality thus thrashes the cache</p>
    <p>Need for the platform to comprehend the priority of applications so that it can allocate hardware resources accordingly</p>
    <p>Art (alone) Art+Iperf</p>
    <p>N o rm a li z e d o c c u p a n c y ( % )</p>
    <p>N o rm a li z e d M P I</p>
    <p>Art-occupancy Art-MPI</p>
    <p>Investigate QoS policies and mechanisms to efficiently manage these shared resources in the presence of disparate applications.</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation and Problem Statement</p>
    <p>QoS in Resource Management  Platform QoS</p>
    <p>Case Study: Cache Resource</p>
    <p>Experiments and Evaluation  Prototype Implementation</p>
    <p>Initial Results</p>
    <p>Summary</p>
  </div>
  <div class="page">
    <p>Resource Management</p>
    <p>Capitalist</p>
    <p>No management of resources  If you can generate more requests, you will use more resources</p>
    <p>Grab as you will  E.g. All of todays policies</p>
    <p>Fair distribution of resources  Give equal share of resources to all executing threads</p>
    <p>Does not necessarily guarantee equal performance</p>
    <p>E.g. Partitioning resources for fairness and isolation</p>
    <p>Communist/Fair</p>
    <p>Focus on individual efficiency</p>
    <p>Provide more performance and resources to the VIP</p>
    <p>Limited resources to non-VIP</p>
    <p>E.g. Service Level Agreements, Foreground/Background</p>
    <p>Elitist</p>
    <p>Focus on overall efficiency</p>
    <p>Give more resource to those that need it the most, less to others</p>
    <p>E.g. Cache-friendly vs. Unfriendly, resource-aware scheduling</p>
    <p>Utilitarian</p>
  </div>
  <div class="page">
    <p>Platform QoS</p>
    <p>Software Domain</p>
    <p>Hardware Domain</p>
    <p>HW Policies</p>
    <p>Resource Monitoring</p>
    <p>Resource Enforcement</p>
    <p>QoS Exposure</p>
    <p>Feedback</p>
    <p>QoS Hints via Architectural Interface</p>
    <p>Memory IO CPU Core</p>
    <p>Cache</p>
    <p>QoS Enabled Resources</p>
    <p>uArch resource usage</p>
    <p>Cache Space</p>
    <p>Bandwidth and Latency</p>
    <p>I/O Response Time</p>
    <p>Case Study</p>
  </div>
  <div class="page">
    <p>Platform Priority Sent through PQR</p>
    <p>QoS Aware OS/VMM: Platform Priority added</p>
    <p>to App state</p>
    <p>QoS Exposure: QoS Aware OS/VMM Platform QoS Register</p>
    <p>CacheCacheHi LoHi Lo</p>
    <p>Low Priority</p>
    <p>OSOS</p>
    <p>High Priority</p>
    <p>Set Applications Platform Priority</p>
    <p>IOIO</p>
    <p>MemoryMemory</p>
    <p>QOS Interface</p>
    <p>Application Platform Priority</p>
    <p>App State</p>
    <p>App State</p>
    <p>App State</p>
    <p>App State</p>
    <p>Resource Monitoring:</p>
    <p>Monitor cache utilization per priority level</p>
    <p>- Tag cache requests - Count usage per priority</p>
    <p>Resource Enforcement: Enforce cache utilization for priority levels</p>
    <p>- Way Partitioning - Capacity Partitioning</p>
    <p>Core 0 Core 1</p>
    <p>Platform QOS Register</p>
    <p>Requests tagged with Priority</p>
    <p>QoS Aware Architecture</p>
    <p>Expose QoS Interface</p>
    <p>Cache</p>
  </div>
  <div class="page">
    <p>Cache QoS Polices &amp; Metrics</p>
    <p>Static  N priority levels supported in platform</p>
    <p>Set a threshold of cache usage for each priority level</p>
    <p>Dynamic  Monitor cache space usage &amp;</p>
    <p>performance metric at frequent intervals</p>
    <p>Dynamically Adjust based on</p>
    <p>QoS Targets: The extent to which high priority application should be improved</p>
    <p>QoS Constraints: The allowable degradation to low priority application or the overall performance</p>
    <p>Metrics</p>
    <p>Resource performance (Miss Rate or MPI, etc)</p>
    <p>Overall performance (IPC, etc)</p>
    <p>P e rf o rm a n c e</p>
    <p>High Priority Low Priority Overall</p>
    <p>Dedicated Mode</p>
    <p>Shared Mode</p>
    <p>QoSQoS TargetTarget</p>
    <p>Shared Mode</p>
    <p>Dedicated ModeDedicated Mode</p>
    <p>QoSQoS ConstraintConstraint</p>
    <p>High priorityHigh priority</p>
    <p>QoSQoS TargetTarget</p>
    <p>Low priorityLow priority</p>
    <p>QoSQoS ConstraintConstraint</p>
    <p>Shared Mode</p>
    <p>L2 High Priority</p>
    <p>Data</p>
    <p>Mid Priority Data</p>
    <p>L1</p>
    <p>CORE 0</p>
    <p>L1</p>
    <p>CORE 1</p>
    <p>APP1(High) APP2(Mid)</p>
    <p>L1</p>
    <p>CORE 2</p>
    <p>APP3(Low)</p>
    <p>Low</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation and Problem Statement</p>
    <p>QoS in Resource Management  Platform QoS</p>
    <p>Case Study: Cache Resource</p>
    <p>Experiments and Evaluation  Prototype Implementation</p>
    <p>Initial Results</p>
    <p>Summary</p>
  </div>
  <div class="page">
    <p>Prototype -- QoS aware OS/VMM</p>
    <p>Add QoS bits -- indicate the priority level of the application</p>
    <p>Set QoS register in the platform</p>
    <p>Special I/O instruction during each context switch</p>
    <p>Priority level management</p>
    <p>Linux Kernel</p>
    <p>Add QoS bits in processs state data structure</p>
    <p>Modify OS scheduler to set QoS register</p>
    <p>Add sys_getQR and sys_setQR system calls as API for users</p>
    <p>QoS utility</p>
    <p>Add a tool to query/set QoS bits in user</p>
    <p>level</p>
    <p>App0 AppN</p>
  </div>
  <div class="page">
    <p>Simulation Framework</p>
    <p>Software Prototype  QoS-enabled OS: Fedora Core 5 Linux  QoS-enabled VMM: Xen with Suse 9.1 Linux</p>
    <p>Full system simulation  Employ SoftSDV to functionally model the architecture  Employ Casper as a cache simulator</p>
    <p>Modified to support monitoring and cache space allocation using static/dynamic QoS policies</p>
    <p>SoftSDV</p>
    <p>Functional</p>
    <p>CPU Model</p>
    <p>Performance</p>
    <p>Cache Model</p>
    <p>QoS-Enabled Linux OS</p>
    <p>( Fedora Core 5 )</p>
    <p>APP 1</p>
    <p>APP n</p>
    <p>.</p>
    <p>QoS-Enabled VMM</p>
    <p>( Xen )</p>
    <p>OS</p>
    <p>App1 App2</p>
    <p>VM1</p>
    <p>OS</p>
    <p>App1 App2</p>
    <p>VM2</p>
    <p>Disk image</p>
    <p>APIs</p>
    <p>S/W Prototype</p>
    <p>H/W Simulation</p>
  </div>
  <div class="page">
    <p>Evaluation Setup</p>
    <p>Simulation configuration</p>
    <p>Applications  QoS aware OS simulation  Spec2000 benchmarks (gcc, ammp, art, applu, mcf, mesa)</p>
    <p>QoS aware VMM simulation  Spec2000 benchmarks (art, swim, mesa, bzip2)  Networking benchmark (Iperf)</p>
    <p>Unified, 256/512/2048/4096/8192 KB, 16 way, 64B line</p>
    <p>L2 (Shared)</p>
    <p>Unified, 32KB, 16 way, 64B line, LRUL1 (Private)</p>
    <p>ValuesParameters</p>
  </div>
  <div class="page">
    <p>Static Policy on Two-core CMP</p>
    <p>Cache Space that Ammp can consume</p>
    <p>N o rm a li z e d M P I</p>
    <p>A v e ra g e C a c h e O c c u p a n c y ( % )</p>
    <p>Gcc-space Ammp-space Gcc-MPI Ammp-MPI</p>
    <p>Cache Space that Gcc can consume</p>
    <p>N o rm a li z e d M P I</p>
    <p>A v e ra g e C a c h e O c c u p a n c y ( % )</p>
    <p>Ammp-space Gcc-space Ammp-MPI Gcc-MPI</p>
    <p>As we reduce the cache space available for ammp, MPI for gcc is reduced</p>
    <p>Gcc benefits more from cache QoS than ammp</p>
    <p>Probably because gcc is more sensitive to the cache size around this size range</p>
    <p>Low priority application exceeds its threshold</p>
    <p>Sharing between applications</p>
    <p>Capacity partitioning</p>
    <p>Try to find a victim of low priority if it exceeds its threshold</p>
    <p>Replace a high priority cache line if set is full of high priority cache lines</p>
  </div>
  <div class="page">
    <p>Static Policy on Four-core CMP</p>
    <p>Set threshold for high, mid and low as 100%, 10%, 10%, 0%</p>
    <p>Applu Art Gcc Mcf</p>
    <p>N o rm a li z e d M P I</p>
    <p>Shared</p>
    <p>Prioritized</p>
    <p>High</p>
    <p>%</p>
    <p>Mid Mid Low</p>
    <p>C a c h e O c c u p a n c y ( % )</p>
    <p>applu art gcc mcf</p>
    <p>AVE</p>
    <p>Time interval</p>
    <p>C a c h e O c c u p a n c y ( % )</p>
    <p>applu art gcc mcf</p>
    <p>AVE</p>
    <p>MPI for applu is reduced by 33%, MPI for art, gcc and mcf increases by 21%, 150% and 216% respectively</p>
    <p>Employing cache QoS can efficiently assign a deterministic amount of cache space to various applications.</p>
  </div>
  <div class="page">
    <p>Static Policy on Two-VM CMP</p>
    <p>Iperf (low pri) in Xens Domain 0, art (high pri) in Domain 1</p>
    <p>4M cache  MPI for art is reduced significantly</p>
    <p>2M cache  MPI for art is reduced lineally</p>
    <p>This is at the cost of iperf performance</p>
    <p>The overall MPI increases significantly when iperf is limited to 10% of the 2M cache --&gt; resource management of small caches could adversely affect the systems performance if the lower priority application is not allocated a minimum amount of cache space</p>
    <p>Cache Space that Iperf can consume</p>
    <p>N o rm a liz e d M P II</p>
    <p>A v e ra g e C a c h e O c c u p a n c y ( % )</p>
    <p>Art-occupancy Iperf-occupancy Art-MPI Iperf-MPI</p>
    <p>Cache Space that Iperf can consume</p>
    <p>N o rm a li z e d M P II</p>
    <p>A v e ra g e C a c h e O c c u p a n c y ( % )</p>
    <p>Art-occupancy Iperf-occupancy Art-MPI Iperf-MPI</p>
  </div>
  <div class="page">
    <p>Static Policy on Four-VM CMP</p>
    <p>Set threshold for high, mid, low as 100%, 20%, 20%, 10%</p>
    <p>MPI for art is reduced by 45%</p>
    <p>MPI for mesa is reduced by 10% because of the decreased interference from iperf</p>
    <p>Bzip2 gets some degradation</p>
    <p>Iperf sees more than 2x degradation</p>
    <p>Art Mesa Bzip2 Iperf</p>
    <p>N o rm a li z e d M P I Shared</p>
    <p>Prioritized</p>
    <p>High LowMidMid</p>
  </div>
  <div class="page">
    <p>Comparison of Various Policies</p>
    <p>art as high priority and iperf as low priority</p>
    <p>Shared mode: without prioritization</p>
    <p>Fair mode: each application occupies half of the cache</p>
    <p>Static QoS mode: set threshold for iperf as 10%</p>
    <p>Dynamic QoS mode: QoS target, MPI = 0.5 of the shared mode</p>
    <p>Dedicated mode: application occupies the whole cache</p>
    <p>Static and dynamic QoS are efficient to approach the performance improvement bound (the dedicated mode)</p>
    <p>Art Iperf</p>
    <p>N o rm a li z e d M P I</p>
    <p>Shared Fair Static QoS Dynamic QoS Dedicated</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation and Problem Statement</p>
    <p>QoS in Resource Management  Platform QoS</p>
    <p>Case Study: Cache Resource</p>
    <p>Experiments and Evaluation  Prototype Implementation</p>
    <p>Initial Results</p>
    <p>Summary</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Motivate QoS-aware platform by showing case studies of CMP cache resource management</p>
    <p>Showed that it is important to provide better determinism in the platform that supports multi-tasking and virtualization</p>
    <p>Described QoS aware architecture and QoS policies</p>
    <p>Developed two software prototypes (QoS aware Linux and QoS aware Xen)</p>
    <p>Simulation results have shown that these techniques efficiently manage the platform resources towards better performance for high priority level applications</p>
  </div>
  <div class="page">
    <p>Future Works</p>
    <p>Experiment more with dynamic QoS mechanism  Detailed Specification of QoS targets &amp; constraints</p>
    <p>Other algorithms for dynamic schemes</p>
    <p>Study the impact of QoS on more diverse applications (servers, VMs, etc)</p>
    <p>Generalize QoS for all other CMP resources  Core, Memory, Interconnect, I/O, etc</p>
  </div>
  <div class="page">
    <p>Thank You!</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>ICS 2004  Iyer, CQoS: A Framework for Enabling QoS in Shared Caches of CMP</p>
    <p>Platforms</p>
    <p>PACT 2004  Kim, Chandra, Solihin, Fair Cache Sharing and Partitioning in a Chip</p>
    <p>Multiprocessor Architecture</p>
    <p>PACT 2006  Hsu, Reinhardt, Iyer, Makineni, Newell, Capitalist, Communist and Utilitarian</p>
    <p>Policies: Shared Cache as a CMP Resource</p>
    <p>Rafique, Lim, Thottethodi, Architectural support for OS-driven CMP cache management</p>
    <p>MICRO 2006  Qureshi, Patt, Utility-Based Cache Partitioning: A Low-Overhead, High</p>
    <p>Performance, Runtime Mechanism to Partition Shared Caches</p>
    <p>Nesbit, Aggarwal, Laudon, Smith, Fair Queuing CMP Memory Systems</p>
    <p>Keshavan, et al, Molecular Caches</p>
  </div>
</Presentation>
