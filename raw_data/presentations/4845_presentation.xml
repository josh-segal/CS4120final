<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Selective Capture and Replay of Program Executions</p>
    <p>Alex Orso Bryan Kennedy</p>
    <p>Georgia Institute of Technology orso@cc.gatech.edu|bck@acm.org</p>
    <p>This work was supported in part by NSF awards CCR-0205422, CCR-0306372, and CCR-0209322 to Georgia Tech.</p>
  </div>
  <div class="page">
    <p>Impact Analysis Field Data</p>
    <p>GAMMA: Overall Picture</p>
    <p>Program P</p>
    <p>Regression Testing</p>
    <p>User User</p>
    <p>User</p>
    <p>User UserUserUserUser</p>
    <p>UserUserUser</p>
    <p>User</p>
    <p>User UserUser</p>
    <p>User</p>
    <p>Fault Localization Perform. analysis</p>
    <p>SE Tasks</p>
  </div>
  <div class="page">
    <p>Replaying Executions: Issues Practicality  High volume of data  Hard to capture (custom)  Rich environment</p>
    <p>Privacy  Sensitive information</p>
    <p>Safety  Side-effects</p>
    <p>Partial replay</p>
    <p>Application Subset</p>
  </div>
  <div class="page">
    <p>Replaying Executions: Applications</p>
    <p>Generation of test cases from users executions</p>
    <p>Generation of subsystem/unit test cases from system test cases</p>
    <p>Off-line dynamic analysis  Debugging</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation  Our approach  Implementation and Evaluation  Conclusions and Future Work</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation  Our approach  Implementation and Evaluation  Conclusions and Future Work</p>
  </div>
  <div class="page">
    <p>Overview</p>
  </div>
  <div class="page">
    <p>Overview: Capture  Input observed set  Identify observed</p>
    <p>sets boundaries  Collect interactions</p>
    <p>and data across boundaries =&gt; event log</p>
  </div>
  <div class="page">
    <p>Overview: Replay</p>
    <p>Provide replay scaffolding</p>
    <p>Process event log  Create classes  Replay interactions</p>
  </div>
  <div class="page">
    <p>Characteristics of the Approach</p>
    <p>Selective</p>
    <p>Observed Set</p>
  </div>
  <div class="page">
    <p>Characteristics of the Approach</p>
    <p>Selective  Event based</p>
    <p>Observed Set</p>
  </div>
  <div class="page">
    <p>Characteristics of the Approach</p>
    <p>Selective  Event based  Efficient</p>
    <p>(partial data)</p>
    <p>Observed Set</p>
  </div>
  <div class="page">
    <p>Capture Phase: Captured Events Unobserved Set</p>
    <p>Observed Set</p>
    <p>x = getRatio(hugeTree)</p>
    <p>getRatio(hugeTree)</p>
  </div>
  <div class="page">
    <p>Capture Phase: Captured Events Unobserved Set</p>
    <p>Observed Set</p>
    <p>it.next()</p>
    <p>&lt;some object&gt;</p>
    <p>n = it.next()</p>
  </div>
  <div class="page">
    <p>Capture Phase: Captured Events</p>
    <p>Method calls  INCALL  INCALLRET  OUTCALL  OUTCALLRET</p>
    <p>Unobserved Set</p>
    <p>Observed Set</p>
  </div>
  <div class="page">
    <p>Capture Phase: Captured Events</p>
    <p>Method calls  INCALL  INCALLRET  OUTCALL  OUTCALLRET</p>
    <p>Field Access  INWRITE  OUTWRITE  OUTREAD</p>
    <p>Exceptions  EXCIN  EXCOUT</p>
    <p>INCALL / OUTCALL</p>
    <p>event</p>
    <p>callees type  callees object ID  callee signature  parameter*</p>
  </div>
  <div class="page">
    <p>Capture Phase: Capturing Partial Data</p>
    <p>Capturing complete data is impractical (&gt; 500% overhead in preliminary study)</p>
    <p>only data that affect the computation  Scalar values  Object IDs and types</p>
    <p>Unobserved Set</p>
    <p>Observed Set</p>
    <p>getRatio(hugeTree)</p>
    <p>&lt; 1110, some.package.HugeTree &gt;</p>
  </div>
  <div class="page">
    <p>Mechanics</p>
    <p>Capture/replay through instrumentation  Probes  Modifications of call sites and proxying  Modification of field accesses  Use of exception handling capabilities</p>
  </div>
  <div class="page">
    <p>Replaying Events</p>
    <p>Technique acts as both driver and stub  Produces events</p>
    <p>INWRITE  INCALL, OUTCALLRET, and EXCIN</p>
    <p>(passing control to observed code)  Consumes events</p>
    <p>OUTCALL, INCALLRET, OUTWRITE, OUTREAD, EXCOUT</p>
    <p>Events from observed code are optional</p>
  </div>
  <div class="page">
    <p>Replaying Events</p>
    <p>Technique acts as both driver and stub  Produces events</p>
    <p>INWRITE  INCALL, OUTCALLRET, and EXCIN</p>
    <p>(passing control to observed code)  Consumes events</p>
    <p>OUTCALL, INCALLRET, OUTWRITE, OUTREAD, EXCOUT</p>
    <p>Checks for out-of-sync events  Events from observed code are optional</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation  Our approach  Implementation and Evaluation  Conclusions and Future Work</p>
  </div>
  <div class="page">
    <p>Feasibility Study</p>
    <p>Tool: SCARPE (Selective CApture and Replay of Program Executions)  Two modalities: Online and offline instrumentation  Uses BCEL</p>
    <p>Subject: NanoXML  19 classes  3,300 LOCs,  216 test cases</p>
    <p>Study setup: For each class in NanoXML  Capture execution of the class for each test case  Reply all such executions (&gt; 4,000)</p>
    <p>Results: all captures and replays were successful</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation  Our approach  Implementation and Evaluation  Conclusions and Future Work</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>DejaVu [Choi98]  jRapture [Steven00]  Mock-object creation [Saff04]</p>
  </div>
  <div class="page">
    <p>Execution Logs</p>
    <p>Input Output</p>
    <p>Environment</p>
    <p>A B C  EL1 EL2 EL3</p>
    <p>App A</p>
    <p>B</p>
    <p>C</p>
    <p>EL1 EL2 EL3  EL1 EL2 EL3</p>
    <p>Summary</p>
  </div>
  <div class="page">
    <p>Execution Logs</p>
    <p>Input Output</p>
    <p>Environment</p>
    <p>A B C  EL1 EL2 EL3</p>
    <p>App A</p>
    <p>B</p>
    <p>C</p>
    <p>EL1 EL2 EL3  EL1 EL2 EL3</p>
    <p>Summary 1  cardinality  #classes in App</p>
  </div>
  <div class="page">
    <p>Execution Logs</p>
    <p>Input Output</p>
    <p>Environment</p>
    <p>A B C  EL1 EL2 EL3</p>
    <p>App A</p>
    <p>B</p>
    <p>C</p>
    <p>EL1 EL2 EL3  EL1 EL2 EL3</p>
    <p>Summary</p>
    <p>Same VS different subsystems at different sites Static VS dynamic configuration</p>
  </div>
  <div class="page">
    <p>Execution Logs</p>
    <p>Input Output</p>
    <p>Environment</p>
    <p>A B C  EL1 EL2 EL3</p>
    <p>App A</p>
    <p>B</p>
    <p>C</p>
    <p>EL1 EL2 EL3  EL1 EL2 EL3</p>
    <p>Summary</p>
    <p>Collect always VS anomaly-driven collect Send back VS replay locally</p>
  </div>
  <div class="page">
    <p>Execution Logs</p>
    <p>Input Output</p>
    <p>Environment</p>
    <p>A B C  EL1 EL2 EL3</p>
    <p>App A</p>
    <p>B</p>
    <p>C</p>
    <p>EL1 EL2 EL3  EL1 EL2 EL3</p>
    <p>Summary</p>
    <p>Field VS In-House</p>
  </div>
  <div class="page">
    <p>Future Work</p>
    <p>Further validation (especially w.r.t. performance)  Post-mortem dynamic analysis of users executions</p>
    <p>Collection and replay in-house  Replay in the field  Conditional collection</p>
    <p>Regression testing  Automated generation of subsystem/unit test cases  Handling of out-of-sequence events  Possible extensions to the technique</p>
    <p>Debugging  Static- and dynamic-analysis support for selection  Application in other contexts (e.g., web services)  Implementation at the JVM level</p>
  </div>
  <div class="page">
    <p>? Questions?</p>
  </div>
</Presentation>
