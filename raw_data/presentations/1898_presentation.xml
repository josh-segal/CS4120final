<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Lube: Mitigating Bottlenecks in Wide Area Data Analytics</p>
    <p>Hao Wang* Baochun Li</p>
    <p>iQua</p>
    <p>HotCloud17</p>
  </div>
  <div class="page">
    <p>Wide Area Data Analytics</p>
    <p>Workers</p>
    <p>Datanodes</p>
    <p>DC</p>
    <p>Master</p>
    <p>Namenode</p>
  </div>
  <div class="page">
    <p>Wide Area Data Analytics</p>
    <p>DC #2 DC #n</p>
    <p>WorkersWorkers</p>
    <p>Datanodes Datanodes</p>
    <p>DC #1</p>
    <p>Master</p>
    <p>Namenode</p>
    <p>Why wide area data analytics?  Data Volume  User Distribution  Regulation Policy Problems  Widely shared resources  Fluctuating available provision</p>
    <p>Distributed runtime environment  Heterogenous utilizations</p>
  </div>
  <div class="page">
    <p>Fluctuating WAN Bandwidths 10.8.3.3 (CT) 10.12.3.32 (TR) 10.4.3.5 (WT) 10.2.3.4 (TR)</p>
    <p>B an</p>
    <p>dw id</p>
    <p>th (M</p>
    <p>bp s)</p>
    <p>Measured by iperf on SAVI testbed https://www.savinetwork.ca/</p>
  </div>
  <div class="page">
    <p>Heterogenous Memory Util</p>
    <p>node_4 node_3 node_2 node_1</p>
    <p>Running Berkeley Big Data Benchmark on AWS EC2 4 nodes across 4 regions.</p>
    <p>Collected by jvmtop</p>
    <p>Nodes in different DCs may have different resource utilizations</p>
  </div>
  <div class="page">
    <p>Bottlenecks</p>
    <p>Runtime Bottlenecks Bottlenecks emerges at runtime  Any time  Any nodes  Any resources</p>
    <p>Fluctuation Heterogeneity</p>
    <p>Data analytics performance</p>
    <p>Long completion times  Low resource utilization  Invalid optimization</p>
  </div>
  <div class="page">
    <p>Optimization of Data Analytics</p>
    <p>Much of this performance work has been motivated by three widely-accepted mantras about the performance of data analytics  network, disk and straggler.</p>
    <p>Making Sense of Performance in Data Analytics Frameworks NSDI15, Kay Ousterhout</p>
    <p>Existing optimization method does not consider runtime bottlenecks  Clarient [OSDI16] considers the heterogeneity of available WAN bandwidth  Iridium [SIGCOMM15] trades off between time and WAN bandwidth usage  Geode [NSDI15] saves WAN usage via data placement and query plan selection  SWAG [SoCC15] reorders jobs across datacenters</p>
  </div>
  <div class="page">
    <p>Mitigating Bottlenecks at Runtime</p>
    <p>Task queue Resource queue</p>
    <p>Mitigating bottlenecks  How to detect bottlenecks?  How to overcome the scheduling delay?  How to enforce the bottleneck mitigation?</p>
    <p>in bottleneck</p>
  </div>
  <div class="page">
    <p>Lube Master</p>
    <p>Bottleneck Info. Cache</p>
    <p>Lube Scheduler</p>
    <p>Available Worker Pool</p>
    <p>Lube Client</p>
    <p>Model Update</p>
    <p>Online Bottleneck Detector</p>
    <p>Training Pool</p>
    <p>Network I/O JVM</p>
    <p>more metricsDisk I/O</p>
    <p>Lightweight Performance Monitors</p>
    <p>Bottleneck Detector</p>
    <p>Submitted Task Queue</p>
    <p>(worker, intensity)</p>
    <p>Bottleneck-aware Scheduling</p>
    <p>Architecture of Lube</p>
    <p>Three major components</p>
    <p>Performance monitors  Bottleneck detecting module  Bottleneck-aware scheduler</p>
  </div>
  <div class="page">
    <p>Detecting Bottlenecks  ARIMA yt = 0 +1yt1 +2yt2 ++pytp +t 1t1 2t2 qtq</p>
    <p>yt Current state   Coefficients  Ramdon error</p>
    <p>Historical states</p>
    <p>Autoregressive (AR) + Moving Average(MA)</p>
    <p>Current state</p>
    <p>input output</p>
    <p>(time_1, mem_util) (time_2, mem_util)</p>
    <p>(time_t-1, mem_util)</p>
    <p>(time_t, mem_util)</p>
    <p>ARIMA(p, d, q)</p>
  </div>
  <div class="page">
    <p>Detecting Bottlenecks  HMM</p>
    <p>past</p>
    <p>futuret</p>
    <p>{time_stamp: mem, net, cpu, disk}</p>
    <p>A(aij)A(aij)</p>
    <p>B(bj(k))B(bj(k))</p>
    <p>QQ</p>
    <p>OdOdO2O2O1O1</p>
    <p>q1q1 q2q2 qiqi qjqj</p>
    <p>OkOkOO</p>
    <p>Hidden Markov Model  Hidden states: O  Observation states: Q  Emission probability: A  Transition probability: B</p>
    <p>Sliding Hidden Markov Model  A sliding window for new</p>
    <p>observations  A moving average approximation</p>
    <p>for outdated observations</p>
    <p>To make HMM online</p>
  </div>
  <div class="page">
    <p>Bottleneck-Aware Scheduling Memory utilization of executor processes</p>
    <p>Network utilization of datanode processes</p>
    <p>CPU utilization of executor processes</p>
    <p>Disk (SSD) utilization of datanode processes</p>
    <p>Time (s)</p>
    <p>Built-in task schedulers:  Data-locality</p>
    <p>Bottleneck-aware scheduler:  Data-locality  Bottlenecks at runtime</p>
    <p>A single worker node is bottlenecked continuously while all nodes are rarely bottlenecked</p>
    <p>at the same time</p>
  </div>
  <div class="page">
    <p>Implementation &amp; Deployment</p>
    <p>PUBLISH + HSET metric {time: val} (e.g, iotop {time: I/O})</p>
    <p>SUBSCRIBE metric_1 metric_2</p>
    <p>HSET worker_id {time: {metric: val_ob, val_inf}}</p>
    <p>HGET worker_id time</p>
    <p>Worker Redis Server</p>
    <p>iotopjvmtopnethogs</p>
    <p>Master Redis Server</p>
    <p>Lube Scheduler</p>
    <p>M as</p>
    <p>te r N</p>
    <p>od e</p>
    <p>W or</p>
    <p>ke r N</p>
    <p>od es</p>
    <p>Bottleneck Detection Module</p>
    <p>APIs:</p>
    <p>Implementation  Spark-1.6.1 (scheduler)  redis database (cache)  Python scikit-learn, Keras (ML)</p>
    <p>Deployment  37 EC2 m4.2xlarge instances  9 regions  Berkeley Big Data Benchmark  An 1.1 TB dataset</p>
  </div>
  <div class="page">
    <p>Evaluation  Accuracy</p>
    <p>Query-1</p>
    <p>H it</p>
    <p>R at</p>
    <p>e (%</p>
    <p>)</p>
    <p>a b c</p>
    <p>Query-2 H</p>
    <p>it R</p>
    <p>at e</p>
    <p>(% )</p>
    <p>a b c</p>
    <p>Query-3</p>
    <p>H it</p>
    <p>R at</p>
    <p>e (%</p>
    <p>)</p>
    <p>a b c</p>
    <p>Query-4</p>
    <p>H it</p>
    <p>R at</p>
    <p>e (%</p>
    <p>)</p>
    <p>ARIMA SlidHMM</p>
    <p>Calculation</p>
    <p>ARIMA ignores nonlinear patterns</p>
    <p>hitrate = #((time, detection)  (time, observation))</p>
    <p># (time, detection)</p>
  </div>
  <div class="page">
    <p>Evaluation  Completion Times</p>
    <p>Query-1</p>
    <p>Time (ms) 0</p>
    <p>Query-2</p>
    <p>Time (ms) 0</p>
    <p>Query-3</p>
    <p>Time (ms) 0</p>
    <p>Query-4</p>
    <p>Time (ms) 0</p>
    <p>Pure Spark Lube-ARIMA</p>
    <p>Lube-SlidHMM</p>
    <p>Task completion times</p>
    <p>Average 75th</p>
    <p>Lube-ARIMA 12.454s 22.075s</p>
    <p>Lube-SlidHMM 14.783s 27.469s</p>
  </div>
  <div class="page">
    <p>Evaluation  Completion Times Pure Spark ARIMA + Spark SlidHMM + Spark</p>
    <p>Lube-ARIMA Lube-SlidHMM</p>
    <p>Query-11000</p>
    <p>Query-21000</p>
    <p>Query-3 800</p>
    <p>Query-41000</p>
    <p>Ti m</p>
    <p>e (s</p>
    <p>) Ti</p>
    <p>m e</p>
    <p>(s )</p>
    <p>Query completion times  Lube-ARIMA  Lube-SlidHMM  Reduce median query response</p>
    <p>time by up to 33%</p>
    <p>Control Groups for overhead  ARIMA + Spark  SlidHMM + Spark  Negligible overhead</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Runtime performance bottleneck detection  ARIMA, HMM</p>
    <p>A simple greedy bottleneck-aware task scheduler  Jointly consider data-locality and bottlenecks</p>
    <p>Lube, a closed-loop framework mitigating bottlenecks at runtime.</p>
  </div>
  <div class="page">
    <p>The End Thank You</p>
  </div>
  <div class="page">
    <p>Discussion Bottleneck detection models  More performance metrics could be explored  More efficient models for time series prediction, e.g., Reinforcement</p>
    <p>Learning, LSTM</p>
    <p>Bottleneck-aware scheduling  Fine-grained scheduling with specific resource awareness</p>
    <p>WAN conditions  We measure pair-wise WAN bandwidths by a cron job running iperf locally  Try to exploit support from SDN interfaces</p>
  </div>
</Presentation>
