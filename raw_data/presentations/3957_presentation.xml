<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Reducing Seek Overhead with Application-Directed Prefetching</p>
    <p>Steve VanDeBogart, Christopher Frost, Eddie Kohler</p>
    <p>University of California, Los Angeles</p>
    <p>http://libprefetch.cs.ucla.edu</p>
  </div>
  <div class="page">
    <p>Disks are Relatively Slow</p>
    <p>Average Throughput Whetstone Seek Time Instr./Sec.</p>
  </div>
  <div class="page">
    <p>Work Arounds</p>
    <p>Buffer cache  Avoid redoing reads</p>
    <p>Write batching  Avoid redoing writes</p>
    <p>Disk scheduling  Reduce (expensive) seeks</p>
    <p>Readahead  Overlap disk &amp; CPU time</p>
  </div>
  <div class="page">
    <p>Readahead</p>
    <p>Generally applies to sequential workloads  Harsh penalties for mispredicting accesses  Hard to predict nonsequential access patterns</p>
    <p>Some workloads are nonsequential  Databases  Image / Video processing  Scientific workloads: simulations, experimental</p>
    <p>data, etc.</p>
  </div>
  <div class="page">
    <p>Nonsequential Access</p>
    <p>Why so slow?  Seek costs</p>
    <p>Possible solutions  More RAM  More spindles  Disk scheduling</p>
    <p>Why are nonsequential access patterns often scheduled poorly?  Painful to get right</p>
  </div>
  <div class="page">
    <p>Example  Getting it Wrong</p>
    <p>Programmer will access nonsequential dataset</p>
    <p>Prefetch it</p>
    <p>fadvise(fd, data_start, data_size, WILLNEED)</p>
    <p>Now it's slower  Maybe prefetching evicted other useful data  Maybe the dataset is larger than the cache size</p>
  </div>
  <div class="page">
    <p>Libprefetch</p>
    <p>User space library</p>
    <p>Provides new prefetching interface  Application-directed prefetching</p>
    <p>Manages details of prefetching</p>
    <p>Up to 20x improvement  Real applications (GIMP, SQLite)  Small modifications (&lt; 1,000 lines per app)</p>
  </div>
  <div class="page">
    <p>Libprefetch Contributions</p>
    <p>Microbenchmarks  Quantitatively understand problem</p>
    <p>Interface  Convenient interface to provide access information</p>
    <p>Kernel  Some changes needed</p>
    <p>Contention  Share resources</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Related work</p>
    <p>Microbenchmarks</p>
    <p>Libprefetch interface</p>
    <p>Results</p>
  </div>
  <div class="page">
    <p>Prefetching</p>
    <p>Determining future accesses  Historic access patterns  Static analysis  Speculative execution  Application-directed</p>
    <p>Using future accesses to influence I/O</p>
  </div>
  <div class="page">
    <p>Application-Directed Prefetching</p>
    <p>Patterson (Tip 1995), Cao (ACFS 1996)</p>
    <p>Roughly doubled performance</p>
    <p>Tight memory constraints  Little reordering of disk requests</p>
    <p>More in paper</p>
  </div>
  <div class="page">
    <p>Prefetching</p>
    <p>Access pattern: 1, 6, 2, 8, 4, 7</p>
    <p>6 2 8 4 7</p>
    <p>No prefetching CPU I/O</p>
    <p>Time</p>
  </div>
  <div class="page">
    <p>Prefetching</p>
    <p>Access pattern: 1, 6, 2, 8, 4, 7</p>
    <p>6 2 8 4 7</p>
    <p>No prefetching CPU I/O</p>
    <p>Traditional prefetching  Overlap I/O &amp; CPU CPU I/O</p>
    <p>Time</p>
  </div>
  <div class="page">
    <p>Prefetching</p>
    <p>Access pattern: 1, 6, 2, 8, 4, 7</p>
    <p>6 2 8 4 7</p>
    <p>No prefetching CPU I/O</p>
    <p>Traditional prefetching  Overlap I/O &amp; CPU CPU I/O</p>
    <p>Traditional prefetching  Fast CPU CPU I/O</p>
    <p>Time</p>
  </div>
  <div class="page">
    <p>Seek Performance</p>
  </div>
  <div class="page">
    <p>Seek Performance</p>
  </div>
  <div class="page">
    <p>Expensive Seeks</p>
    <p>Minimizing expensive seeks with disk scheduling  reordering</p>
    <p>Access pattern: 1, 6, 2, 8, 4, 7</p>
    <p>In order:</p>
    <p>Reorder:</p>
  </div>
  <div class="page">
    <p>Reordering</p>
    <p>Must buffer out of order requests  Reordering limited by buffer space</p>
    <p>4</p>
    <p>21 6 7 8</p>
    <p>CPU Dependency I/O</p>
    <p>2 8 4 7</p>
    <p>CPU Dependency I/O</p>
    <p>Time</p>
  </div>
  <div class="page">
    <p>Reorder Prefetching</p>
    <p>Access pattern: 1, 6, 2, 8, 4, 7</p>
    <p>Traditional prefetching  Fast CPU CPU I/O</p>
    <p>Time</p>
    <p>Reorder prefetching  Buffer size = 3 CPU I/O 2</p>
    <p>Reorder prefetching  Buffer size = 6 CPU I/O 2 6</p>
  </div>
  <div class="page">
    <p>Buffer Size</p>
    <p>Random access to a 256MB file with varying amounts of reordering allowed</p>
  </div>
  <div class="page">
    <p>Buffer Size</p>
    <p>Random access to a 256MB file with varying amounts of reordering allowed</p>
  </div>
  <div class="page">
    <p>Buffer Size</p>
  </div>
  <div class="page">
    <p>Buffer Size</p>
    <p>Random access to a 256MB file with varying amounts of reordering allowed</p>
  </div>
  <div class="page">
    <p>Buffer Size</p>
    <p>Buffer size important to performance  Too low: not using all capability, lower performance  Too high: evict useful data, performance goes down</p>
    <p>Start with all free and buffer cache memory  Libprefetch uses /proc to find free memory</p>
    <p>Change memory target with usage</p>
  </div>
  <div class="page">
    <p>More microbenchmarks</p>
    <p>Request size  Large requests vs. small requests</p>
    <p>Platter location  Start of disk vs. end of disk</p>
    <p>Infill  Reading extra data to eliminate small seeks</p>
  </div>
  <div class="page">
    <p>Libprefetch algorithm</p>
    <p>Application-directed prefetching for deep, accurate access lists</p>
    <p>Use as much memory as possible to maximize reordering</p>
    <p>Reorder requests to minimize large seeks</p>
  </div>
  <div class="page">
    <p>Interface Outline</p>
    <p>List of access entries</p>
    <p>Callback  Supply access list incrementally  Non-invasive to existing applications</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>c = register_client(callback, NULL);</p>
    <p>File BFile A</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>c = register_client(callback, NULL); r1 = register_region(c, A, 75, 350); r2 = register_region(c, B, 100, 200); r3 = register_region(c, B, 300, 400);</p>
    <p>File BFile A</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>c = register_client(callback, NULL); r1 = register_region(c, A, 75, 350); r2 = register_region(c, B, 100, 200); r3 = register_region(c, B, 300, 400);</p>
    <p>a_list = { {A, 100, 1}, ... {B, 150, 0}, ... {A, 200, 1} }; n = request_prefetching(c, a_list, 3, PF_SET  PF_DONE);</p>
    <p>File BFile A</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>c = register_client(callback, NULL); r1 = register_region(c, A, 75, 350); r2 = register_region(c, B, 100, 200); r3 = register_region(c, B, 300, 400);</p>
    <p>a_list = { {A, 100, 1}, ... {B, 150, 0}, ... {A, 200, 1} }; n = request_prefetching(c, a_list, 3, PF_SET  PF_DONE);</p>
    <p>Access list entry: file descriptor, file offset, marked flag</p>
    <p>File BFile A</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>c = register_client(callback, NULL); r1 = register_region(c, A, 75, 350); r2 = register_region(c, B, 100, 200); r3 = register_region(c, B, 300, 400);</p>
    <p>a_list = { {A, 100, 1}, ... {B, 150, 0}, ... {A, 200, 1} }; n = request_prefetching(c, a_list, 3, PF_SET  PF_DONE);</p>
    <p>Flags: append, clear, complete</p>
    <p>File BFile A</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>c = register_client(callback, NULL); r1 = register_region(c, A, 75, 350); r2 = register_region(c, B, 100, 200); r3 = register_region(c, B, 300, 400);</p>
    <p>a_list = { {A, 100, 1}, ... {B, 150, 0}, ... {A, 200, 1} }; n = request_prefetching(c, a_list, 3, PF_SET  PF_DONE);</p>
    <p>Accepted entries short = full</p>
    <p>File BFile A</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>c = register_client(callback, NULL); r1 = register_region(c, A, 75, 350); r2 = register_region(c, B, 100, 200); r3 = register_region(c, B, 300, 400);</p>
    <p>a_list = { {A, 100, 1}, ... {B, 150, 0}, ... {A, 200, 1} }; n = request_prefetching(c, a_list, 3, PF_SET  PF_DONE);</p>
    <p>libprefetch_a_list = {{A, 100, 1}, ... {B, 150, 0}, ... {A, 200, 1}};</p>
    <p>File BFile A</p>
    <p>fadvise(A, 100, WILL_NEED)  fadvise(B, 150, WILL_NEED)  fadvise(A, 200, WILL_NEED)</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>c = register_client(callback, NULL); r1 = register_region(c, A, 75, 350); r2 = register_region(c, B, 100, 200); r3 = register_region(c, B, 300, 400);</p>
    <p>a_list = { {A, 100, 1}, ... {B, 150, 0}, ... {A, 200, 1} }; n = request_prefetching(c, a_list, 3, PF_SET  PF_DONE);</p>
    <p>pread(A, ..., 100);</p>
    <p>File BFile A</p>
    <p>libprefetch_a_list = {{A, 100, 1}, ... {B, 150, 0}, ... {A, 200, 1}};</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>c = register_client(callback, NULL); r1 = register_region(c, A, 75, 350); r2 = register_region(c, B, 100, 200); r3 = register_region(c, B, 300, 400);</p>
    <p>a_list = { {A, 100, 1}, ... {B, 150, 0}, ... {A, 200, 1} }; n = request_prefetching(c, a_list, 3, PF_SET  PF_DONE);</p>
    <p>pread(A, ..., 100);</p>
    <p>File BFile A</p>
    <p>libprefetch_a_list = {{A, 100, 1}, ... {B, 150, 0}, ... {A, 200, 1}};</p>
    <p>Check access list Check in memory fincore(A, 100, ...)</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>c = register_client(callback, NULL); r1 = register_region(c, A, 75, 350); r2 = register_region(c, B, 100, 200); r3 = register_region(c, B, 300, 400);</p>
    <p>a_list = { {A, 100, 1}, ... {B, 150, 0}, ... {A, 200, 1} }; n = request_prefetching(c, a_list, 3, PF_SET  PF_DONE);</p>
    <p>pread(A, ..., 100); ... pread(B, ..., 350);</p>
    <p>File BFile A</p>
    <p>Access list doesn't match. Callback into application to update it.</p>
    <p>libprefetch_a_list = {{A, 100, 1}, ... {B, 150, 0}, ... {A, 200, 1}};</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>c = register_client(callback, NULL); r1 = register_region(c, A, 75, 350); r2 = register_region(c, B, 100, 200); r3 = register_region(c, B, 300, 400);</p>
    <p>a_list = { {A, 100, 1}, ... {B, 150, 0}, ... {A, 200, 1} }; n = request_prefetching(c, a_list, 3, PF_SET  PF_DONE);</p>
    <p>pread(A, ..., 100); ... pread(B, ..., 350);</p>
    <p>File BFile A</p>
    <p>void callback(void* arg, int markedFD, loff_t markedOffset, int requestedFD, loff_t requestedOffset);</p>
    <p>libprefetch_a_list = {{A, 100, 1}, ... {B, 150, 0}, ... {A, 200, 1}};</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>c = register_client(callback, NULL); r1 = register_region(c, A, 75, 350); r2 = register_region(c, B, 100, 200); r3 = register_region(c, B, 300, 400);</p>
    <p>a_list = { {A, 100, 1}, ... {B, 150, 0}, ... {A, 200, 1} }; n = request_prefetching(c, a_list, 3, PF_SET  PF_DONE);</p>
    <p>pread(A, ..., 100); ... pread(B, ..., 350);</p>
    <p>File BFile A</p>
    <p>void callback(NULL, A, 100, B, 350) { a_list = compute_new_alist(B, 350); n = request_prefetching(c, a_list, 2, PF_SET  PF_DONE);</p>
    <p>}</p>
    <p>libprefetch_a_list = {{A, 100, 1}, ... {B, 150, 0}, ... {A, 200, 1}};</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>c = register_client(callback, NULL); r1 = register_region(c, A, 75, 350); r2 = register_region(c, B, 100, 200); r3 = register_region(c, B, 300, 400);</p>
    <p>a_list = { {A, 100, 1}, ... {B, 150, 0}, ... {A, 200, 1} }; n = request_prefetching(c, a_list, 3, PF_SET  PF_DONE);</p>
    <p>pread(A, ..., 100); ... pread(B, ..., 350);</p>
    <p>File BFile A</p>
    <p>void callback(NULL, A, 100, B, 350) { a_list = compute_new_alist(B, 350); n = request_prefetching(c, a_list, 2, PF_SET  PF_DONE);</p>
    <p>}</p>
    <p>libprefetch_a_list = {{B, 150, 0}, ... {A, 200, 1}};</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>c = register_client(callback, NULL); r1 = register_region(c, A, 75, 350); r2 = register_region(c, B, 100, 200); r3 = register_region(c, B, 300, 400);</p>
    <p>a_list = { {A, 100, 1}, ... {B, 150, 0}, ... {A, 200, 1} }; n = request_prefetching(c, a_list, 3, PF_SET  PF_DONE);</p>
    <p>pread(A, ..., 100); ... pread(B, ..., 350); ... pread(A, ..., 400);</p>
    <p>File BFile A</p>
    <p>libprefetch_a_list = {{B, 150, 0}, ... {A, 200, 1}};</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>c = register_client(callback, NULL); r1 = register_region(c, A, 75, 350); r2 = register_region(c, B, 100, 200); r3 = register_region(c, B, 300, 400);</p>
    <p>a_list = { {A, 100, 1}, ... {B, 150, 0}, ... {A, 200, 1} }; n = request_prefetching(c, a_list, 3, PF_SET  PF_DONE);</p>
    <p>pread(A, ..., 100); ... pread(B, ..., 350); ... pread(A, ..., 400); pread(A, ..., 200); File BFile A</p>
    <p>End of access list, callback to get more information.</p>
    <p>libprefetch_a_list = {{B, 150, 0}, ... {A, 200, 1}};</p>
  </div>
  <div class="page">
    <p>Interface Summary</p>
    <p>Access list  Simply discloses application's intentions  Provided incrementally</p>
    <p>Callback  Asks application for more information  Easily retrofitted into existing applications  Aids in debugging access list information</p>
  </div>
  <div class="page">
    <p>Libprefetch</p>
    <p>Prefetching library</p>
    <p>A few important kernel modifications  fincore() - File page in memory?  Modified fadvise() - Fetch/evict file page</p>
    <p>Uses fadvise() to prefetch; manages details  When to prefetch  How much to prefetch  Right order for prefetching</p>
  </div>
  <div class="page">
    <p>Contention</p>
    <p>Disk scheduling  OS scheduler ok</p>
    <p>Memory for libprefetch behaves like bandwidth in TCP  Changes quickly  Performs poorly if over subscribed</p>
    <p>Use AIMD to determine memory target  Decrease when miss in buffer cache  Increase when all prefetched data stays in memory</p>
  </div>
  <div class="page">
    <p>Contention</p>
    <p>Disk scheduling  OS scheduler ok</p>
    <p>Memory for libprefetch behaves like bandwidth in TCP  Changes quickly  Performs poorly if over subscribed</p>
    <p>Use AIMD to determine memory target  Decrease when miss in buffer cache  Increase when all prefetched data stays in memory</p>
  </div>
  <div class="page">
    <p>Evaluation Methodology</p>
    <p>Pentium 4, 3.2GHz</p>
    <p>512MB of RAM</p>
    <p>Seagate 7200.11 500GB SATA 3Gb/s</p>
    <p>Silicon Image 3132-2 SATA controller</p>
    <p>Logging over the network</p>
  </div>
  <div class="page">
    <p>Random Access</p>
    <p>SQLite with TPC-C like dataset:</p>
    <p>select * from Customer order by Zip_code;</p>
    <p>Secondary key =&gt; resulting rows will be randomly located in the dataset</p>
    <p>Total modifications: &lt; 500 lines of code</p>
  </div>
  <div class="page">
    <p>Results: Random</p>
    <p>SQLite secondary key query</p>
    <p>RAM</p>
  </div>
  <div class="page">
    <p>Strided Accesses</p>
    <p>GIMP  Array of image tiles  Row-major layout accessed in Column-major order  Column-major layout accessed in Row-major order  Total modifications: 679 lines</p>
  </div>
  <div class="page">
    <p>Results: Strided</p>
    <p>GIMP blur</p>
  </div>
  <div class="page">
    <p>Sequential Access</p>
    <p>Sequentially read a large file</p>
    <p>Libprefetch should do just as well as readahead</p>
  </div>
  <div class="page">
    <p>Results: Sequential</p>
  </div>
  <div class="page">
    <p>Impact of AIMD</p>
  </div>
  <div class="page">
    <p>Performance with Contention</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>A relatively simple library can transform accesses to avoid slow operations</p>
    <p>Microbenchmarks quantitatively show cause of nonsequential slowness</p>
    <p>Interface to easily retrofit applications  Libprefetch handles kernel and concurrency</p>
    <p>complications  Big performance gains (up to 20x) are possible</p>
    <p>for some workloads</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Implementation Sketch</p>
  </div>
</Presentation>
