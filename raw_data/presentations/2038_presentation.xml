<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>IBM Research</p>
    <p>Towards an understanding of oversubscription in cloud</p>
    <p>Salman A. Baset, Long Wang, Chunqiang Tang sabaset@us.ibm.com IBM T. J. Watson Research Center Hawthorne, NY</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Oversubscription background - Airlines and cloud - What are typical overload symptoms for CPU, memory, disk, and network? - Isnt managing oversubscribed cloud the same as regular cloud?</p>
    <p>Mitigating overload: mechanism vs. policy  Contributions</p>
    <p>- Theoretical basis for oversubscription problem - A Markov model for oversubscription - SLAs and oversubscription - Results on increasing oversubscription in cloud by terminating or live</p>
    <p>migrating a VM while meeting SLAs  Ongoing work</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Plans changed last minute</p>
    <p>Airline boss: my planes are not flying</p>
    <p>full. Overbook the seats!</p>
  </div>
  <div class="page">
    <p>Motivation</p>
  </div>
  <div class="page">
    <p>Motivation</p>
  </div>
  <div class="page">
    <p>Cloud motivation</p>
    <p>Studies indicate that VMs do not fully utilize the provisioned resources</p>
    <p>Definitions - Provisioned resources</p>
    <p>e.g., the resources with which a VM is configured. EC2 small instance (1.7 GB memory, 160 GB disk)</p>
    <p>- Used resources  e.g., the resources used by a VM at a point time (1 GB memory, 50 GB disk)</p>
    <p>- Overcommitted, oversubscribed</p>
    <p>Can we oversubscribe the resources of a physical machine while meeting the SLAs promised to a customer?</p>
  </div>
  <div class="page">
    <p>Regular cloud</p>
    <p>VM: 2 GB RAM 500 GB 1 CPU</p>
    <p>Black box indicates provisioned resources per VM</p>
  </div>
  <div class="page">
    <p>Oversubscribed cloud</p>
    <p>VM: 2 GB RAM 500 GB 1 CPU</p>
    <p>Black box indicates provisioned resources per VM</p>
  </div>
  <div class="page">
    <p>Oversubscribed cloud</p>
    <p>VM: 2 GB RAM 500 GB 1 CPU</p>
    <p>Black box indicates provisioned resources per VM</p>
    <p>Green box indicates used resources per VM</p>
  </div>
  <div class="page">
    <p>Overload!</p>
    <p>VM: 2 GB RAM 500 GB 1 CPU</p>
    <p>Black box indicates provisioned resources per VM</p>
    <p>Green box indicates used resources per VM</p>
    <p>VMs requesting more memory than available in physical server.</p>
  </div>
  <div class="page">
    <p>What are overload symptoms for CPU, memory, network, disk?</p>
    <p>CPU</p>
    <p>Memory</p>
    <p>Disk</p>
    <p>Network</p>
  </div>
  <div class="page">
    <p>What are overload symptoms for CPU, memory, network, disk?</p>
    <p>CPU - less CPU share per VM, long run queues</p>
    <p>Memory - Swapping to hypervisor disk, thrashing</p>
    <p>Disk (spinning) - Increased r/w latency, decreased throughput</p>
    <p>Network</p>
    <p>- Link fully utilized</p>
    <p>Are symptoms</p>
    <p>related?</p>
  </div>
  <div class="page">
    <p>What are overload symptoms for CPU, memory, network, disk?</p>
    <p>CPU - less CPU share per VM, long run queues</p>
    <p>Memory - Swapping to hypervisor disk, thrashing</p>
    <p>Disk (spinning) - Increased r/w latency, decreased throughput</p>
    <p>Network</p>
    <p>- Link fully utilized</p>
    <p>Locally attached disks</p>
    <p>Increased disk traffic</p>
    <p>Network attached disks</p>
    <p>Increased network traffic</p>
  </div>
  <div class="page">
    <p>What are overload symptoms for CPU, memory, network, disk?</p>
    <p>CPU - less CPU share per VM</p>
    <p>Memory - Swapping to hypervisor disk, thrashing</p>
    <p>Disk (spinning) - Increased r/w latency, decreased throughput</p>
    <p>Network</p>
    <p>- Link fully utilized</p>
    <p>Monitoring agents within VMs and hypervisor may not get a chance to run as per their schedule</p>
  </div>
  <div class="page">
    <p>What are overload symptoms for CPU, memory, network, disk?</p>
    <p>CPU - less CPU share per VM</p>
    <p>Memory - Swapping to hypervisor disk, thrashing</p>
    <p>Disk (spinning) - Increased r/w latency, decreased throughput</p>
    <p>Network</p>
    <p>- Link fully utilized</p>
    <p>If work of all VMs is I/O bound, a fully utilized link (for one VM) may cause other VMs to sit idle, wasting CPU and memory resources.</p>
  </div>
  <div class="page">
    <p>Isnt managing oversubscribed cloud the same as regular cloud?</p>
    <p>Regular cloud - Only network and disk are susceptible to overload - CPU and memory are never oversubscribed</p>
    <p>Oversubscribed cloud - CPU, disk, memory, and network are oversubscribed</p>
  </div>
  <div class="page">
    <p>Mitigating overload</p>
    <p>Mechanism vs. policy</p>
    <p>Mechanisms - Stealing</p>
    <p>Borrow resources from one VM and give it to other - Quiescing</p>
    <p>Terminate a VM. Which VMs to terminate? - Migrate</p>
    <p>Live migration - Shared vs. local disk storage - VMware VMotion - Streaming disks</p>
    <p>Offline migration  Which VMs to live / offline migrate?</p>
    <p>- Network memory  Swap space is over network. May work for transient workloads.</p>
  </div>
  <div class="page">
    <p>Handling overload</p>
    <p>Overload detection - Detect that overload is occurring (within VMs or physical server) - Hard or adaptive thresholds</p>
    <p>Overload mitigation - Mitigate overload by terminating a VM, live migrating it, or using network</p>
    <p>memory</p>
    <p>It is hard!</p>
  </div>
  <div class="page">
    <p>Overload mitigation policy</p>
    <p>Factors to consider - Performance - Useful work done - Cost - Fairness - Minimal impact to VMs - SLAs</p>
    <p>An optimization problem</p>
  </div>
  <div class="page">
    <p>Multiple-constraints single knapsack (FPTAS polynomial in n and 1/e for e &gt; 0) - Given n items and one bin (single knapsack) - Each item and bin has d dimensions, and each item has profit p(i) - Find a packing of n items into this bin which maximizes profit, while meeting bins</p>
    <p>dimensions  Multiple knapsacks (bin packing) (PTAS polynomial in 1/e for e &gt; 0)</p>
    <p>- Given n items, and m bins (knapsacks) - Each item has a profit, p(i), and size(i) - Find items with maximum profit that fit in n bins</p>
    <p>Vector bin packing (no-APTAS cannot find a PTAS for every constant e &gt; 0) - Given n items and m bins - Each item and bin has d dimensions - Find a packing of n into m which minimizes m, while meeting bins dimensions</p>
    <p>Online vector bin packing - Same as above - but also minimize the total number of moves across bins or VM terminations</p>
    <p>Oversubscription and classical problems</p>
  </div>
  <div class="page">
    <p>Online multiple constraints multiple knapsack problem with costs of moving between knapsacks</p>
    <p>- Given n items (VMs), and m bins (servers) - Each VM and server has d dimensions, and each VM has utility u(i) - Moving a VM from server i to j has a cost Mij - Terminating a VM k has a cost Tk - lambda is the rate of arrival of workloads within VMs (iid) - Utility of a VM and PM, UVM, UPM, respectively - State space:</p>
    <p>resource consumption of PMs and VMs resources - PM resources: CPU, memory, disk, network - state tuple: (PMi  CPU , PMi  disk , PMi  mem, PMi  network ) - state space explosion</p>
    <p>probability of being in that state, given workload distributions  Utility of a state</p>
    <p>Given workload distributions, find argmax number of VMs s.t. - Total utility (profit) is maximized</p>
    <p>The underlying theoretical problem of oversubscription</p>
  </div>
  <div class="page">
    <p>SLAs and overload</p>
    <p>Overload must be precisely defined as part of SLAs  What are the SLAs of public cloud providers?</p>
    <p>- None provide any performance guarantees for compute - Uptime guarantees, typically only for data center and not for VMs.</p>
  </div>
  <div class="page">
    <p>Compute SLA comparison Amazon EC2 Azure Compute Rackspace Cloud</p>
    <p>Servers Terremark vCloud Express</p>
    <p>Storm on Demand</p>
    <p>Service guarantee Availability (99.95%) 5 minute interval</p>
    <p>Role uptime and availability, 5 minute interval</p>
    <p>Availability Availability Availability</p>
    <p>Granularity Data center Aggregate across all role</p>
    <p>Per instance and data center + mgmt. stack</p>
    <p>Data center + management stack</p>
    <p>Per instance</p>
    <p>Scheduled maintenance</p>
    <p>Unclear if excluded Includ. in service guarantee calc.</p>
    <p>Excluded Unclear if excluded Excluded</p>
    <p>Patching N/A Excluded Excluded if managed N/A Excluded</p>
    <p>Guarantee time period</p>
    <p>Per month Per month Per month Unclear</p>
    <p>Service credit 10% if &lt; 99.95% 10% if &lt; 99.95% 25% if &lt; 99%</p>
    <p>Violation report respon.</p>
    <p>Customer Customer Customer Customer Customer</p>
    <p>Reporting time period</p>
    <p>N/A 5 days of occurrence N/A N/A N/A</p>
    <p>Claim filing timer period</p>
    <p>Within 1 billing month of incident</p>
    <p>Within 30 days of downtime</p>
    <p>Within 30 days of the last reported incident in claim</p>
    <p>Within 5 days of incident in question</p>
    <p>Credit only for future payments</p>
    <p>Yes No No Yes No</p>
    <p>Cloud SLAs: Present and Future. To appear in ACM Operating System Review</p>
    <p>Uptime guarantees on a data center (very weak) Implicit uptime guarantees on a VM</p>
  </div>
  <div class="page">
    <p>Questions investigated in this paper</p>
    <p>Overload detection interval and request inter-arrival within VM  Mitigating overload by terminating VMs over a do nothing approach  Mitigating overload by live migrating a VM, over terminating VMs and do nothing.</p>
    <p>Simulations - Setup</p>
    <p>40 PMs (rack of physical machines), each has 64 GB of RAM  Only memory overload  30 days of simulated time  Number of VMs fixed  Request interarrival rate exponentially distributed  Request size exponential and pareto  (real data set in progress)  Live migration: 1 VM per minute at most (mig-1) or all VMs until overload alleviated (mig-all).</p>
    <p>- Overload definition  If memory consumption exceeds 95% of physical server memory for five contiguous minutes,</p>
    <p>overload occurs. - Metrics</p>
    <p>Percentage of VMs not experiencing overload for given workload arrival rate  Number of VMs terminated and migrated</p>
  </div>
  <div class="page">
    <p>Preliminary results</p>
    <p>u p</p>
    <p>ti m</p>
    <p>e &gt;</p>
    <p>quiesce no quiesce</p>
    <p>% o</p>
    <p>f V</p>
    <p>M s k</p>
    <p>ill e</p>
    <p>d</p>
    <p>M a</p>
    <p>x .</p>
    <p># V</p>
    <p>M k</p>
    <p>ill e</p>
    <p>d</p>
    <p>Load on VMs as a function of their provisioned capacity. Overcommit factor is 2.</p>
    <p>up tim</p>
    <p>e &gt;</p>
    <p>%</p>
    <p>mig all mig 1</p>
    <p>m ig</p>
    <p>s / m</p>
    <p>in</p>
    <p>Load on VMs as a function of their provsioned capacity. Overcommit factor is 2.</p>
    <p>Overcommit factor is 2.  All VMs have same provisioned memory, i.e., 2 GB. Physical server has 64 GB memory.  Average load on VMs as a function of provisioned capacity. E.g., 32.5% of 2 GB = 650 MB  When average load on all VMs is 50% of provisioned capacity, the physical server memory is exhausted.</p>
    <p>Migration strategy: Select the VM with the largest memory consumption and terminate or live migrate it</p>
    <p>Insights: - Terminating a VM improves the uptime performance of all VMs by more than a factor of 2 over</p>
    <p>a do nothing approach. - Mig-1 (at most one migration per minute results in a step function like reduction in uptime)</p>
  </div>
  <div class="page">
    <p>Preliminary results</p>
    <p>u p</p>
    <p>ti m</p>
    <p>e &gt;</p>
    <p>quiesce no quiesce</p>
    <p>% o</p>
    <p>f V</p>
    <p>M s k</p>
    <p>ill e</p>
    <p>d</p>
    <p>M a</p>
    <p>x .</p>
    <p># V</p>
    <p>M k</p>
    <p>ill e</p>
    <p>d</p>
    <p>Load on VMs as a function of their provisioned capacity. Overcommit factor is 2.</p>
    <p>up tim</p>
    <p>e &gt;</p>
    <p>%</p>
    <p>mig all mig 1</p>
    <p>m ig</p>
    <p>s / m</p>
    <p>in</p>
    <p>Load on VMs as a function of their provsioned capacity. Overcommit factor is 2.</p>
    <p>Percentage of VMs killed Percentage of VMs migrated</p>
    <p>mig-all</p>
    <p>mig-1</p>
    <p>Insights: - One or more VMs killed as aggregate memory consumption of all VMs approach physical</p>
    <p>server memory - mig-all can overly stress the network - Always selecting the VM with highest memory consumption for terminating or live migrating</p>
    <p>is not a good idea!</p>
  </div>
  <div class="page">
    <p>Questions under investigation</p>
    <p>To what extent a combination of VM quiescing and live migration schemes perform better than the individual schemes?</p>
    <p>Does asymmetry in oversubscription levels across PMs (within the same rack) and workload distributions lead to a higher overall overcommit level?</p>
    <p>When identical or asymmetric capacity VMs have different SLAs, which overload mitigation scheme gives the best results?</p>
    <p>When the available SLAs are defined per VM group instead of per VM, can it be leveraged to improve the performance of underlying overload mitigation scheme?</p>
    <p>How are the results affected when other resources such as CPU, network, and disk are oversubscribed?</p>
    <p>What is the best strategy for selecting VMs to terminate or live migrate?</p>
    <p>How the SLAs should be defined for oversubscribed environments?</p>
    <p>How can we answer all of the above questions for real workloads in a test-bed or deployed environment?</p>
  </div>
</Presentation>
