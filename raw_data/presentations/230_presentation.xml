<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Irfan Ahmad Ajay Gula@, Ali Mash@zadeh</p>
    <p>USENIX Annual Technical Conference</p>
    <p>June 15, 2011</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Interrupts Interrupts Coalesced</p>
    <p>Virtual Interrupts Virtual Interrupts Coalesced</p>
    <p>Inter-Processor Interrupts Coalesced</p>
  </div>
  <div class="page">
    <p>Interrupts</p>
    <p>User</p>
    <p>Kernel/Driver</p>
    <p>Intr Handler</p>
    <p>@me</p>
    <p>I/O Device</p>
    <p>Interrupt Fired IO Requested Interrupt Fired</p>
  </div>
  <div class="page">
    <p>Interrupts</p>
    <p>It was a great inven@on, but also a Box of Pandora. -- E.W. Dijkstra</p>
    <p>Source: EWD 1303 h_p://www.cs.utexas.edu/users/EWD/transcrip@ons/EWD13xx/EWD1303.html</p>
  </div>
  <div class="page">
    <p>Electrologica X-1</p>
    <p>Source: People Behind Informa@cs, An exhibi@on in memory of Dahl, Dijkstra, Nygaard h_p://cs-exhibi@ons.uni-klu.ac.at/</p>
    <p>Picture: h_p://cs-exhibi@ons.uni-klu.ac.at/fileadmin/template/pictures/Dijkstra_electrologica.jpg</p>
  </div>
  <div class="page">
    <p>E. W. Djikstra</p>
    <p>Halfway the func@onal design of the X1, I guess early 1957, Bram [J. Loopstra] and Carel [S. Scholten] confronted me with the idea of the interrupt, and I remember that I panicked, being used to machines with reproducible behaviour. How was I going to iden@fy a bug if I had introduced one?</p>
    <p>Picture: h_p://27.media.tumblr.com/tumblr_l4nhw73hGD1qz8lbio1_400.jpg</p>
    <p>Source: EWD 1303 h_p://www.cs.utexas.edu/users/EWD/transcrip@ons/EWD13xx/EWD1303.html Dijkstras PhD disserta@on (on X-1): h_p://www.cs.utexas.edu/users/EWD/PhDthesis/PhDthesis.PDF</p>
  </div>
  <div class="page">
    <p>E. W. Djikstra</p>
    <p>Amer I had delayed the decision to include the interrupt for 3 months, Bram and Carel fla_ered me out of my resistance, it was decided that an interrupt would be included and I began to study the problem. Picture: h_p://27.media.tumblr.com/tumblr_l4nhw73hGD1qz8lbio1_400.jpg</p>
    <p>Source: EWD 1303 h_p://www.cs.utexas.edu/users/EWD/transcrip@ons/EWD13xx/EWD1303.html Dijkstras PhD disserta@on (on X-1): h_p://www.cs.utexas.edu/users/EWD/PhDthesis/PhDthesis.PDF</p>
  </div>
  <div class="page">
    <p>Source: Mark Smotherman h_p://www.cs.clemson.edu/ ~mark/interrupts.html</p>
    <p>Univac 1103A wind tunnel interrupts IBM Stretch vectored interrupts Lincoln Labs TX-2 nested intrs + cri@cal sec@on Electrologica X-1 vectored interrupt system</p>
    <p>Univac-I overflow trap</p>
    <p>High-Speed Ethernet NICs High-Speed Storage Controllers</p>
    <p>Techniques in the 70s  &gt;1 comple@on per interrupt  Spin-wait a li_le before dismiss  Amer dismiss, HW delay @ll next</p>
    <p>Higher interrupt overheads + CompeIIon: Dozens of patents (mostly networking)</p>
    <p>LSI Logic interrupt coalescing patent: use #Commands in Flight to set delay 'mer</p>
    <p>VMware ESX 4.0 vIC:  #Commands in Flight to set fine-</p>
    <p>grained delivery ra'o +  No need for high-res Imers +  Inter-processor Interrupt Coalescing</p>
    <p>Typical techniques modify one or both of:  Maximum Interrupt Delay Latency (MIDL)  Maximum Coalesce Count (MCC)</p>
  </div>
  <div class="page">
    <p>Virtual Interrupts are Different?</p>
    <p>Real HW I/O controllers are embedded systems  Device emula@on executes on general purpose, mul@-user, @me-shared architectures</p>
    <p>Cant install @mers for 100 microseconds intervals  Host would be overwhelmed by interrupt storm  Other VMs would be impacted  Shouldnt solve interrupt coalescing for VMs by increasing interrupt rate on host!</p>
  </div>
  <div class="page">
    <p>First Intui@on Behind vIC</p>
    <p>Lets pretend HW IO comple@ons are @mers  But, just cant program them to our desired rate  So, lets piggyback the ShouldDeliverInterrupt() logic on real HW comple@on handlers</p>
    <p>HW controllers: deliver when internal @mers fire  vIC: lets only deliver in line with HW comple@on  Mo@vates using a delivery ra+o instead of @mer  Deliver a virtual interrupt for every nth comple@on</p>
  </div>
  <div class="page">
    <p>Delivery Ra@o</p>
    <p>Nave implementa@on: deliver an interrupt for 1 of every n HW comple@ons</p>
    <p>Equivalent of the typical max coalesce count (MCC) parameter in HW controllers</p>
    <p>Problem in MCC: limits delivery ra@o to be 1/n  E.g. 1/1, 1/2, 1/3, 1/4, etc.  Cant express, say, 80% delivery ra@o</p>
    <p>Experiments suggest 1.0-&gt;0.5 jump too dras@c</p>
  </div>
  <div class="page">
    <p>Delivery Ra@o</p>
    <p>Use two coun@ng parameters (MCC has one) 1. countUp 2. skipUp</p>
    <p>Express arbitrary frac@onal delivery rate</p>
  </div>
  <div class="page">
    <p>Second Intui@on Behind vIC</p>
    <p>Suppose a scheme coalesces 2 comple@ons</p>
    <p>Commands in Flight: 32 Commands in Flight: 4</p>
    <p>With CIF of 32, pipeline remains mostly full  With CIF of 4, pipeline is half empty!</p>
    <p>make delivery ra@o a func@on of CIF</p>
  </div>
  <div class="page">
    <p>Delivery Ra@o: CIF Dependence</p>
    <p>CIF</p>
    <p>L</p>
    <p>CIF</p>
    <p>T</p>
    <p>L</p>
    <p>T</p>
    <p>La te nc y</p>
    <p>Th ro ug hp</p>
    <p>ut</p>
    <p>La te nc y</p>
    <p>Th ro ug hp</p>
    <p>ut</p>
    <p>L</p>
    <p>T</p>
    <p>L</p>
    <p>T</p>
    <p>CIF</p>
    <p>CIF</p>
  </div>
  <div class="page">
    <p>Delivery Ra@o: CIF Dependence</p>
    <p>Measure dynamic Commands in Flight (CIF)  Vary delivery ra@o R inversely with CIF</p>
    <p>Interrupt delivery ra@o (R ) as a func@on of CIF.</p>
  </div>
  <div class="page">
    <p>Loose ends</p>
    <p>What if next HW comple@on never comes?  There is always a future I/O when CIF &gt; 0 J  S@ll, short-circuit to deliver f/ low CIF situa@ons</p>
    <p>What if the hardware comple@ons are too far apart: could cause high latency?  Measure and automa@cally enable/disable vIC</p>
    <p>Trickle I/O  Measure and automa@cally enable/disable vIC</p>
  </div>
  <div class="page">
    <p>vIC Implementa@on</p>
    <p>Portable to other hypervisors on any CPU architecture. Also to firmware/hardware</p>
    <p>No floa@ng point  No int div or RDTSC in cri@cal path  Increase in the 64-bit VMM:</p>
    <p>.text: +400 bytes .data: +104 bytes.</p>
    <p>LSI Logic emula@on in VMM: &lt;120 new LoC  IPI coalescing logic in the Vmkernel: 50 new LoC</p>
  </div>
  <div class="page">
    <p>Results</p>
    <p>Applica@on benchmarks  GSBlaster and SQLIOSim  Throughput (IOPS) increase by up to 19%  Improve CPU efficiency up to 17%</p>
    <p>Lets look at TPC-C next  transca@on rate increased by up to 5%</p>
  </div>
  <div class="page">
    <p>Internal TPC-C Testbed</p>
    <p>Throughput Increased</p>
    <p>More Users</p>
    <p>IOPS Increased</p>
    <p>Interrupts Decreased</p>
    <p>Propor@onal Latency increase</p>
  </div>
  <div class="page">
    <p>Dynamic Adapta@on (TPC-C)</p>
    <p>Virtual interrupt coalescing rate, R. Online adapta@on by vIC to burs@ness in outstanding IOs of the workload</p>
    <p>vI C Ra</p>
    <p>I o (R )</p>
    <p>Time (seconds)</p>
  </div>
  <div class="page">
    <p>Dynamic Adapta@on (TPC-C)</p>
    <p>Virtual interrupt coalescing ra@os, R, during our TPC-C run. x-axis log-scale.</p>
    <p>vIC RaIo (R)</p>
  </div>
  <div class="page">
    <p>vIC Deployment Experience</p>
    <p>vIC default in VMwares LSI Logic virtual adapter on ESX (since v. 4.0 released 2Q 09)</p>
    <p>Till now, no performance bug reports</p>
  </div>
  <div class="page">
    <p>Key Takeaways  60-yr old problem revisited  Encouraging results  TPC-C by 5%, other by 18%+  Take another look at your interrupt subsystem</p>
    <p>IPI coalescing very beneficial  More op@miza@on opportuni@es exist in vIC</p>
    <p>Change the rules when they weigh you down  What about networking?  An equivalent of CIF there (TCP window size?)</p>
  </div>
</Presentation>
