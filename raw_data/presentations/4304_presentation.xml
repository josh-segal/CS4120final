<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Simple and Effective Multi-Paragraph Reading Comprehension</p>
    <p>Christopher Clark and Matt Gardner</p>
  </div>
  <div class="page">
    <p>Neural Question Answering</p>
    <p>Question: What color is the sky?</p>
    <p>Passage: Air is made mainly from molecules of nitrogen and oxygen. These molecules scatter the blue colors of sunlight more effectively than the green and red colors. Therefore, a clean sky appears blue.</p>
  </div>
  <div class="page">
    <p>Fast Progress on Paragraph Datasets</p>
    <p>Ju n16</p>
    <p>Ju l-1</p>
    <p>Au g16</p>
    <p>Se p16</p>
    <p>O ct -1 6</p>
    <p>N ov -1 6</p>
    <p>D ec -1 6</p>
    <p>Ja n17</p>
    <p>Fe b17</p>
    <p>M ar -1 7</p>
    <p>Ap r17</p>
    <p>M ay -1 7</p>
    <p>Ju n17</p>
    <p>Ju l-1</p>
    <p>Au g17</p>
    <p>Se p17</p>
    <p>O ct -1 7</p>
    <p>N ov -1 7</p>
    <p>D ec -1 7</p>
    <p>Ja n18</p>
    <p>Fe b18</p>
    <p>M ar -1 8</p>
    <p>Ap r18</p>
    <p>M ay -1 8</p>
    <p>Ju n18</p>
    <p>Accuracy on SQuAD 1.1</p>
  </div>
  <div class="page">
    <p>What Next?</p>
  </div>
  <div class="page">
    <p>Open Question Answering</p>
    <p>Question: What color is the sky?</p>
    <p>Blue</p>
    <p>Document Retrieval Relevant Text</p>
    <p>Answer SpanModel</p>
  </div>
  <div class="page">
    <p>Challenge: Scaling Models to Documents</p>
    <p>Modern reading comprehension models have many layers and parameters  The trend is continuing in this direction, for example with the use of large language models</p>
    <p>Reduced efficiency as the paragraph length increases due to long RNN chains or transformers/self-attention modules</p>
    <p>Limits the model to processing short paragraphs</p>
  </div>
  <div class="page">
    <p>Two Possible Approaches</p>
    <p>Pipelined Systems  Select a single paragraph from the input, and run the model on that paragraph</p>
    <p>Confidence Systems  Run the model on many paragraphs from the input, and have itassign a confidence score to its results on each paragraph</p>
    <p>(0.68)</p>
    <p>(0.83)</p>
    <p>(0.29)</p>
  </div>
  <div class="page">
    <p>This Work</p>
    <p>Improved Pipeline Method  Improve several of the key design decision that arise when training on document-level data</p>
    <p>Improved Confidence Method  Study ways to train models to produce correct confidence scores</p>
  </div>
  <div class="page">
    <p>Pipeline Method: Paragraph Selection</p>
    <p>Train a shallow linear model to select the best paragraphs  Features include TF-IDF, word occurrences, and its position within the document</p>
    <p>If there is just one document TF-IDF alone is effective Improves change of selecting an answering-containing paragraph from 83.0 to 85.1 on TriviaQA Web</p>
  </div>
  <div class="page">
    <p>Pipeline Method: Noisy Supervision</p>
    <p>Document level data can be expected to be distantly supervised:</p>
    <p>Question: Which British general was killed at Khartoum in 1885?</p>
    <p>In February 1884 Gordon returned to the Sudan to evacuate Egyptian forces. Rebels broke into the city , killing Gordon and the other defenders. The British public reacted to his death by acclaiming ' Gordon of Khartoum , a saint. However, historians have since suggested that Gordon defied orders and.</p>
    <p>Passage:</p>
  </div>
  <div class="page">
    <p>Pipeline Method: Noisy Supervision</p>
    <p>Need a training objective that can handle multiple (noisy) answer spans Use the summed objective from Kadlec et al (2016), that optimizes the log sum of the probability of all answer spans</p>
    <p>Remains agnostic to how probability mass is distributed among the answer spans</p>
  </div>
  <div class="page">
    <p>Pipeline Method: Model</p>
    <p>Construct a fast, competitive model Use some keys ideas from prior work, bidirectional-attention, self-attention, characterembeddings, variational dropout</p>
    <p>Also added learned tokens for document and paragraphs starts</p>
    <p>&lt; 5 hours to train for 26 epochs on SQuAD</p>
  </div>
  <div class="page">
    <p>Confidence Methods</p>
    <p>We can derive confidence scores from the logit scores given to each span by the model, i.e., the scores given before the softmax operator is applied</p>
    <p>Without re-training this can work poorly</p>
  </div>
  <div class="page">
    <p>Example from SQuAD</p>
    <p>Question: When is the Members Debate held?</p>
    <p>Model Extraction: ..majority of the Scottish electorate voted for it in a referendum to be held on 1 March 1979 that represented at least...</p>
    <p>Correct Answer: Immediately after Decision Time a Members Debate is held, which lasts for 45 minutes...</p>
  </div>
  <div class="page">
    <p>Learning Well-Calibrated Confidence Scores</p>
    <p>Train the model on both answering-containing and non-answering containing paragraph and use a modified objective function</p>
    <p>Merge: Concatenate sampled paragraphs together No-Answer: Process paragraphs independently, and allow the model to place probability mass on a no-answer output</p>
    <p>Sigmoid: Assign an independent probability on each span using the sigmoid operator</p>
    <p>Shared-Norm: Process paragraphs independently, but compute the span probability across spans in all paragraphs</p>
  </div>
  <div class="page">
    <p>Results</p>
  </div>
  <div class="page">
    <p>Datasets</p>
    <p>TriviaQA: Datasets of trivia questions and related documents found by websearch  Includes three setting, Web (a single document for each questions) Wiki (multiple wikipedia documents for each questions) and Unfiltered (Multiple documents for each questions)</p>
    <p>SQuAD: Turker-generated questions about Wikipedia articles  We use the questions paired with the entire article  Manual annotation shows most (90%) of questions are answerable as given the document it was generated from</p>
  </div>
  <div class="page">
    <p>Pipeline Method: Results on TriviaQA Web</p>
    <p>Baseline implementation:  Uses BiDAF as the model  Select paragraphs by truncating documents  Select answer-spans randomly</p>
    <p>72.14 EM / 81.05 F1 on SQuAD  78.58 EM / 85.83 F1 with contextualized word embeddings (Peters et al., 2017)</p>
    <p>TriviaQA Baseline</p>
    <p>Our Baseline</p>
    <p>+TF-IDF +Sum +TF-IDF +Sum</p>
    <p>+Model +TF-IDF +Sum</p>
    <p>EM</p>
  </div>
  <div class="page"/>
  <div class="page"/>
  <div class="page"/>
  <div class="page">
    <p>TriviaQA Leaderboard (Exact Match Scores) Model Web-All Web-Verified Wiki-All Wiki-Verified</p>
    <p>Best leaderboard entry (mingyan) 68.65 82.44 66.56 74.83 Leaderboard entry (dirkweissen)</p>
    <p>Neural Cascades (Swayamdipta et al., 2017) 53.75 63.20 51.59 58.90 MnemonicReader (Hue et al., 2017) 46.65 56.96 46.94 54.45 SMARNET (Chen et al., 2017 40.87 51.11 42.41 50.51</p>
  </div>
  <div class="page">
    <p>Error Analysis</p>
    <p>Manually annotated 200 errors made by the TriviaQA Web model  40.5% are due to noise or lack of context in the relevant documents  Of the remaining.</p>
  </div>
  <div class="page">
    <p>Sentence Reading 35%</p>
    <p>Paragraph Reading 18%</p>
    <p>Document Coreference</p>
    <p>Part of answer extracted</p>
    <p>Missing backgroun knoweldge</p>
    <p>Answer indirectly stated 20%</p>
  </div>
  <div class="page">
    <p>Building an Open Question Answering System</p>
    <p>Use Bing web search and a Wikipedia entity linker to locate relevant documents  Extract the top 12 paragraphs, as found using the linear paragraph ranker  Use the model trained for TriviaQA Unfiltered to find the final answer</p>
    <p>Question</p>
  </div>
  <div class="page">
    <p>Demo</p>
  </div>
  <div class="page">
    <p>Curated Trec Results</p>
    <p>YodaQA with Bing (Baudis, 2015),</p>
    <p>YodaQA (Baudis, 2015)</p>
    <p>DrQA + DS (Chen et al., 2017a)</p>
    <p>S-Norm (ours)</p>
    <p>AC CU</p>
    <p>RA CY</p>
  </div>
  <div class="page">
    <p>Thank You</p>
    <p>Github: https://github.com/allenai/document-qa</p>
    <p>Demo: https://documentqa.allenai.org/</p>
    <p>Question</p>
  </div>
</Presentation>
