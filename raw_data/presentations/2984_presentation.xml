<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Slicer: Auto-Sharding for Datacenter Applications</p>
    <p>Atul Adya, Daniel Myers, Jon Howell, Jeremy Elson, Colin Meek, Vishesh Khemani, Stefan Fulger, Pan Gu, Lakshminath Bhuvanagiri,</p>
    <p>Jason Hunter, Roberto Peon, Larry Kai, Alexander Shraer, Arif Merchant, Kfir Lev-Ari (Technion  Israel)</p>
  </div>
  <div class="page">
    <p>Local Memory Considered Helpful</p>
    <p>Server machines have a lot of memory  Applications should take advantage of it, e.g., caching</p>
    <p>Datacenter applications often dont cache data  Too hard to implement</p>
    <p>Slicer makes it easy to build services that use local memory</p>
  </div>
  <div class="page">
    <p>Talk Outline</p>
    <p>Why stateful servers are difficult</p>
    <p>Slicer model and architecture</p>
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>Building a DNS Service</p>
    <p>DNS Service</p>
    <p>End-user devices</p>
    <p>Virtual Machines</p>
    <p>Cloud Platform</p>
    <p>DNS service needs to be scalable and fast!</p>
  </div>
  <div class="page">
    <p>Full State Replicated on Every Server</p>
    <p>DNS Servers</p>
    <p>Frontends</p>
    <p>End-user devices</p>
    <p>Any server can handle any request  Easy adaptation to failures, capacity changes,</p>
    <p>load skews  Hard to scale or handle mutations</p>
  </div>
  <div class="page">
    <p>Stateless: Interchangeable Servers + Database</p>
    <p>Database</p>
    <p>DNS Servers</p>
    <p>Frontends</p>
    <p>End-user devices</p>
    <p>Any server can handle a request  Cannot query DB for every DNS request</p>
    <p>High latency  Network hop and marshaling costs</p>
  </div>
  <div class="page">
    <p>Stateful: Static Sharding</p>
    <p>Simple mapping from keys to servers via static function  Failure adaptation: Black-hole traffic for crashed server  Capacity adaptation: Could result in significant key churn</p>
    <p>Frontends</p>
    <p>DNS servers</p>
    <p>Hash(key) mod 4 Hash(key) mod 4</p>
  </div>
  <div class="page">
    <p>Stateful: Consistent Hashing</p>
    <p>Implement server presence detection</p>
    <p>Addresses capacity and failure adaptation, key churn</p>
    <p>Stochastic load balancing is inadequate</p>
    <p>Distributed decisions harm affinity</p>
    <p>Frontends</p>
    <p>DNS servers</p>
    <p>ConsistentHash(key) ConsistentHash(key)</p>
  </div>
  <div class="page">
    <p>Stateful: Central Controller</p>
    <p>Frontends</p>
    <p>Application servers</p>
    <p>Hash(key) Hash(key)</p>
    <p>Central server: presence detection, load monitoring, consistent view  Fan-out assignments to large number of clients and servers  Internals of a sharded distributed storage system! Should we use stateless servers?</p>
    <p>ControllerStorage Master</p>
    <p>Hash(key)</p>
    <p>Tablet servers</p>
  </div>
  <div class="page">
    <p>Slicer: Refactored System for Sharded Apps</p>
    <p>Provides auto-sharding without tying to storage  Separate assignment generation control plane from request</p>
    <p>forwarding data plane  Via a small interface  In a scalable, consistent, fault-tolerant manner</p>
    <p>Reshards for capacity and failure adaptation, load balancing  Evaluated Slicer in production deployment</p>
  </div>
  <div class="page">
    <p>Benefits of Sharding/Affinity</p>
    <p>Any type of serving from memory / caching  E.g., Cloud DNS</p>
    <p>Even stateless services use stateful components  E.g. External caches such as Memcache</p>
    <p>Affinity helps aggregating writes to storage  E.g., Thialfi [SOSP 11] batches notification messages to storage</p>
  </div>
  <div class="page">
    <p>Slicer Sharding Model</p>
    <p>Application servers</p>
    <p>Hash(K1) Hash(K2) Hash(K3)</p>
    <p>Slices</p>
    <p>Hash keys into 63-bit space Assign ranges (&quot;slices&quot;) of space to servers</p>
    <p>Split/Merge/Migrate slices for load balancing Asymmetric replication: more copies for hot slices</p>
  </div>
  <div class="page">
    <p>Slicer Architecture: Goals</p>
    <p>High-quality sharding and consistency of a centralized system</p>
    <p>Low latency and high availability of local decisions</p>
  </div>
  <div class="page">
    <p>Slicer Overview</p>
    <p>Frontends</p>
    <p>Application servers</p>
    <p>Slicelet</p>
    <p>Clerk</p>
    <p>Distributed data plane Centralized control plane</p>
    <p>Hash(key) Hash(key)</p>
    <p>Slicer Service</p>
  </div>
  <div class="page">
    <p>Slicer Architecture</p>
    <p>Frontends</p>
    <p>Application servers</p>
    <p>Slicelet</p>
    <p>Clerk</p>
    <p>Distributor</p>
    <p>Backup Distributor</p>
    <p>Assigner</p>
    <p>Existing Google Infrastructure</p>
    <p>Capacity Monitoring</p>
    <p>Health Monitoring</p>
    <p>Load Monitoring</p>
    <p>Lease Manager</p>
  </div>
  <div class="page">
    <p>Tolerating Failures</p>
    <p>Two types of failures:  Localized failures: machine failures or datacenter offline  Correlated failures: whole service such as Assigner or Distributor</p>
    <p>being down due to, e.g.,  Bad configuration push  Software bug  Bug in underlying dependencies</p>
  </div>
  <div class="page">
    <p>Tolerating Localized and Correlated Failures</p>
    <p>Frontends</p>
    <p>Application servers</p>
    <p>Backup Distributor datacenters</p>
    <p>Assigner datacenters</p>
    <p>Distributor datacenters</p>
    <p>Smaller/Simpler Components</p>
    <p>More Complex Components</p>
  </div>
  <div class="page">
    <p>Slicer Features and Evaluation</p>
    <p>Load balancing algorithm  Assignments with strong consistency guarantees  Production Measurements  scale, load balancing, availability,  Comparison with consistent hashing</p>
    <p>Experiments  Comparing load balancing strategies  Load reaction time  Assigner recovery time</p>
    <p>assignment latenciesDetailedBrief</p>
  </div>
  <div class="page">
    <p>Evaluation: Slicer Usage</p>
    <p>Slicer load balances a few million RPS for several Google services  99.98% of clients requests had a valid assignment  &lt; 0.01% of these requests directed to the wrong server</p>
  </div>
  <div class="page">
    <p>Evaluation: Load Balancing Effectiveness</p>
    <p>Slicer allows tighter capacity allocation by reducing skew 20</p>
  </div>
  <div class="page">
    <p>Summary: Slicer makes Stateful Services Practical</p>
    <p>Reshards in the presence of capacity changes, failures, load skews  Scalable and fault-tolerant architecture  Separates assignment generation control plane from request forwarding</p>
    <p>data plane</p>
    <p>Evaluated Slicer in production deployment</p>
  </div>
</Presentation>
