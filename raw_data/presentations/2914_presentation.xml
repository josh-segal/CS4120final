<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Bootstrapping Semantic Analyzers</p>
    <p>from Non-Contradictory Texts</p>
    <p>Ivan Titov, Mikhail Kozhevnikov Saarland University</p>
  </div>
  <div class="page">
    <p>Semantic Parsing</p>
    <p>Semantic Parsing</p>
    <p>Producing a semantic representation of a sentence</p>
    <p>Statistical Semantic Parsing</p>
    <p>Supervised methods:</p>
    <p>supervision is expensive</p>
    <p>resulting coverage is low</p>
    <p>Unsupervised methods</p>
    <p>they have their own challenges</p>
    <p>In this paper, we will propose a weakly-supervised learning</p>
    <p>scenario</p>
  </div>
  <div class="page">
    <p>Unsupervised Sem Parsing, challenges</p>
    <p>Models alternative verbalizations of the same meaning</p>
    <p>Unsupervised methods rely on distributional similarity to</p>
    <p>establish semantic equivalence of verbalizations</p>
    <p>Simple examples of clusters of verbalizations assumed</p>
    <p>equivalent by an unsupervised model:</p>
    <p>South wind, wind from west, southerly</p>
    <p>Fall, increase, decrease, rise</p>
    <p>Neutrophil, monocyte, lymphocite,</p>
    <p>Similar problems with alignment of predicate arguments</p>
    <p>(semantic roles)</p>
    <p>How would you decide</p>
    <p>that South wind  wind</p>
    <p>from west if you have</p>
    <p>only context?</p>
    <p>e.g., (Poon &amp; Domingos, 2009)</p>
  </div>
  <div class="page">
    <p>Unsupervised Sem Parsing, challenges</p>
    <p>Models alternative verbalizations of the same meaning</p>
    <p>Unsupervised methods rely on distributional similarity to</p>
    <p>establish semantic equivalence of verbalizations</p>
    <p>Simple examples of clusters of verbalizations assumed</p>
    <p>equivalent by an unsupervised model:</p>
    <p>South wind, wind from west, southerly</p>
    <p>Fall, increase, decrease, rise</p>
    <p>Neutrophil, monocyte, lymphocite,</p>
    <p>Similar problems with alignment of predicate arguments</p>
    <p>(semantic roles)</p>
    <p>e.g., (Poon &amp; Domingos, 2009)</p>
    <p>Antonyms appear in very</p>
    <p>similar contexts</p>
  </div>
  <div class="page">
    <p>Unsupervised Sem Parsing, challenges</p>
    <p>Models alternative verbalizations of the same meaning</p>
    <p>Unsupervised methods rely on distributional similarity to</p>
    <p>establish semantic equivalence of verbalizations</p>
    <p>Simple examples of clusters of verbalizations assumed</p>
    <p>equivalent by an unsupervised model:</p>
    <p>South wind, wind from west, southerly</p>
    <p>Fall, increase, decrease, rise</p>
    <p>Neutrophil, monocyte, lymphocite,</p>
    <p>Similar problems with alignment of predicate arguments</p>
    <p>(semantic roles)</p>
    <p>e.g., (Poon &amp; Domingos, 2009)</p>
    <p>These are all white blood</p>
    <p>cells, they are related but</p>
    <p>not equivalent.</p>
  </div>
  <div class="page">
    <p>Unsupervised Sem Parsing, challenges</p>
    <p>Models alternative verbalizations of the same meaning</p>
    <p>Unsupervised methods rely on distributional similarity to</p>
    <p>establish semantic equivalence of verbalizations</p>
    <p>Simple examples of clusters of verbalizations assumed</p>
    <p>equivalent by an unsupervised model:</p>
    <p>South wind, wind from west, southerly</p>
    <p>Fall, increase, decrease, rise</p>
    <p>Neutrophil, monocyte, lymphocite,</p>
    <p>Similar problems with alignment of predicate arguments</p>
    <p>(semantic roles)</p>
    <p>e.g., (Poon &amp; Domingos, 2009)</p>
    <p>How to tackle these challenges without</p>
    <p>human-annotated data?</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation</p>
    <p>Learning with Semantically Related Unannotated Texts</p>
    <p>Inference with Groups of Documents</p>
    <p>Example problem:</p>
    <p>Analyzing Weather Forecasts</p>
    <p>A Model of Semantics (Liang et al., 2009)</p>
    <p>Experiments</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Semantically-Overlapping Documents</p>
    <p>Much of information is retold multiple times:</p>
  </div>
  <div class="page">
    <p>Semantically-Overlapping Documents</p>
    <p>Much of information is retold multiple times:</p>
    <p>Can we exploit the fact that documents are not</p>
    <p>isolated but closely related to bootstrap a</p>
    <p>semantic parser?</p>
  </div>
  <div class="page">
    <p>Generation Assumptions</p>
    <p>We assume that each group of related documents is</p>
    <p>generated in the following way:</p>
    <p>Choose a total meaning m of the group</p>
    <p>For each document in the group  Choose a subset of this meaning mi ( m ) mi )</p>
    <p>Choose a verbalization xi for mi</p>
    <p>Why would it help?</p>
    <p>It forces a model to discover a representation m which is</p>
    <p>invariant of verbalizations xi  Enforces clustering of equivalent forms but prevents non</p>
    <p>equivalent ones from clustering</p>
  </div>
  <div class="page">
    <p>Given two semantically related documents</p>
    <p>Example</p>
    <p>USD 2.2 bn decrease in profit  ... profit fell by 2.2 billion dollars</p>
    <p>Document 1 Document 2</p>
    <p>profit(x)  decrease(x,y)  y = $ 2.2    profit(z)  fall(z,w)  w = $ 2.2</p>
    <p>Common semantics</p>
    <p>Initial model may be not aware that fall = decrease</p>
    <p>(in this context) and create distinct logic</p>
    <p>statements for them</p>
    <p>It would need to pay to generate</p>
    <p>that long semantic state</p>
  </div>
  <div class="page">
    <p>Given two semantically related documents</p>
    <p>Example</p>
    <p>USD 2.2 bn decrease in profit  ... profit fell by 2.2 billion dollars</p>
    <p>Document 1 Document 2</p>
    <p>profit(x)  decrease(x,y)  y = $ 2.2</p>
    <p>Common semantics</p>
    <p>But if it would observe enough such examples it</p>
    <p>would contract the semantic representation and</p>
    <p>realize that decrease = fall</p>
    <p>Generating this simpler semantic</p>
    <p>representation is cheaper</p>
    <p>Note:</p>
    <p>this is not going to happen for the pair decrease and increase</p>
    <p>we do not assume that the documents are paraphrases of</p>
    <p>each other</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation</p>
    <p>Learning with Semantically Related Unannotated Texts</p>
    <p>Inference with Groups of Documents</p>
    <p>Example problem:</p>
    <p>Analyzing Weather Forecasts</p>
    <p>A Model of Semantics (Liang et al., 2009)</p>
    <p>Experiments</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Inference</p>
    <p>Exact inference is expected to be intractable:</p>
    <p>It involves marginalization over latent shared semantics</p>
    <p>This would introduce non-trivial dependencies between</p>
    <p>semantic representations of individual documents</p>
    <p>Even most approximations are likely to be quire expensive</p>
    <p>Assuming that inference on individual documents is</p>
    <p>efficient, we propose a simple inference algorithm</p>
    <p>fast and sufficiently accurate for the considered model</p>
  </div>
  <div class="page">
    <p>Probability model</p>
    <p>Probability model for semantics (world model)</p>
    <p>P ( m | m) - probability of meaning m given m:</p>
    <p>1, if m ) m,</p>
    <p>0, if m ) : m,</p>
    <p>2 (0, 1), otherwise</p>
    <p>Our goal (EM E-step) is to infer the distribution:</p>
    <p>P( m | x1, , xn) / P(m) i P(xi | m)</p>
    <p>/ i P(mi | m1    mi-1) P(xi | mi)</p>
    <p>mi is semantics of document xi  m = m1  m2    mn</p>
    <p>(In practice, it involves marginalization over alignments between m and x)</p>
  </div>
  <div class="page">
    <p>Probability model</p>
    <p>Probability model for semantics (world model)</p>
    <p>P ( m | m) - probability of meaning m given m:</p>
    <p>1, if m ) m,</p>
    <p>0, if m ) : m,</p>
    <p>2 (0, 1), otherwise</p>
    <p>Our goal (EM E-step) is to infer the distribution:</p>
    <p>P( m | x1, , xn) / P(m) i P(xi | m)</p>
    <p>/ i P(mi | m1    mi-1) P(xi | mi)</p>
    <p>mi is semantics of document xi  m = m1  m2    mn</p>
    <p>(In practice, it involves marginalization over alignments between m and x)</p>
    <p>The probability of semantics for</p>
    <p>document i given chosen semantic for</p>
    <p>the previous documents</p>
  </div>
  <div class="page">
    <p>Probability model</p>
    <p>Probability model for semantics (world model)</p>
    <p>P ( m | m) - probability of meaning m given m:</p>
    <p>1, if m ) m,</p>
    <p>0, if m ) : m,</p>
    <p>2 (0, 1), otherwise</p>
    <p>Our goal (EM E-step) is to infer the distribution:</p>
    <p>P( m | x1, , xn) / P(m) i P(xi | m)</p>
    <p>/ i P(mi | m1    mi-1) P(xi | mi)</p>
    <p>mi is semantics of document xi  m = m1  m2    mn</p>
    <p>(In practice, it involves marginalization over alignments between m and x)</p>
    <p>The probability of semantics for</p>
    <p>document i given chosen semantic for</p>
    <p>the previous documents</p>
    <p>This is the component which drives</p>
    <p>learning: meaning of a document is</p>
    <p>affected by meaning of other</p>
    <p>documents</p>
  </div>
  <div class="page">
    <p>Greedy inference</p>
    <p>We consider a hard version of EM; instead of E-step:</p>
    <p>m* = argmaxm P (m | x1, , xn)</p>
    <p>Greedy approximate search:</p>
    <p>(1): m*1 = argmaxm1 P (m1 | x1)</p>
    <p>(2): m*2 = argmaxm2 P (m2 | m1, x2)</p>
    <p>(n): m*n = argmaxmn P (mn | m1    mn-1, xn)</p>
    <p>(n+1): m* = m*1  m*2    m*n</p>
  </div>
  <div class="page">
    <p>Greedy inference</p>
    <p>We consider a hard version of EM; instead of E-step:</p>
    <p>m* = argmaxm P (m | x1, , xn)</p>
    <p>Greedy approximate search:</p>
    <p>(1): m*1 = argmaxm1 P (m1 | x1)</p>
    <p>(2): m*2 = argmaxm2 P (m2 | m1, x2)</p>
    <p>(n): m*n = argmaxmn P (mn | m1    mn-1, xn)</p>
    <p>(n+1): m* = m*1  m*2    m*n</p>
    <p>Cannot backtrack and correct parsing errors</p>
    <p>Intuition: should start with documents simpler</p>
    <p>for the model</p>
  </div>
  <div class="page">
    <p>Semi-greedy inference</p>
    <p>In our algorithm, we search for a best order of greedy inference, O(n3)</p>
    <p>s = () [list: ordering for greedy inference]</p>
    <p>m* =  [joint semantics]</p>
    <p>for i = 1 to n [construct s and m*]</p>
    <p>for ( j 2 (1,, n)  j 2 s)</p>
    <p>mj = argmaxmj P (mj, xj | m*) [predict m for j conditioned on m</p>
    <p>*]</p>
    <p>si = argmaxj 2 s P(mj, xj | m*) k 2 s maxmk P(mk, xk| m*  mj</p>
    <p>)</p>
    <p>m* = m*  msi</p>
    <p>Can be regarded, as a form of belief propagation</p>
    <p>We select the document with</p>
    <p>semantics which is best in</p>
    <p>explaining the current document</p>
    <p>and the remaining documents</p>
  </div>
  <div class="page">
    <p>Semi-greedy inference: example</p>
    <p>In the afternoon the temperature</p>
    <p>can reach 29 C</p>
    <p>... Hot weather this afternoon, with</p>
    <p>a low of around 25 C</p>
    <p>Document 1</p>
    <p>Document 2</p>
    <p>... This afternoon, the temperature</p>
    <p>will be range from 25 to 30 C</p>
    <p>Document 3</p>
    <p>Parser prediction ProbTry starting from document 1:</p>
  </div>
  <div class="page">
    <p>Semi-greedy inference: example</p>
    <p>In the afternoon the temperature</p>
    <p>can reach 29 C</p>
    <p>... Hot weather this afternoon, with</p>
    <p>a low of around 25 C</p>
    <p>Document 1</p>
    <p>Document 2</p>
    <p>... This afternoon, the temperature</p>
    <p>will be range from 25 to 30 C</p>
    <p>Document 3</p>
    <p>temp(time = 1-6pm, min = 29, max = ?) 0.100</p>
    <p>Parser prediction ProbTry starting from document 1:</p>
  </div>
  <div class="page">
    <p>Semi-greedy inference: example</p>
    <p>In the afternoon the temperature</p>
    <p>can reach 29 C</p>
    <p>... Hot weather this afternoon, with</p>
    <p>a low of around 25 C</p>
    <p>Document 1</p>
    <p>Document 2</p>
    <p>... This afternoon, the temperature</p>
    <p>will be range from 25 to 30 C</p>
    <p>Document 3</p>
    <p>temp(time = 1-6pm, min = 29, max = ?) 0.100</p>
    <p>Parser prediction Prob</p>
    <p>temp(time = 7-10am, min = 25, max = ?) 0.001</p>
    <p>Now condition 2 and 3 on m1</p>
    <p>It cannot prediction this new value for low, so it</p>
    <p>mistakenly decides that it refers to other time</p>
    <p>period, but prob is low</p>
    <p>Try starting from document 1:</p>
  </div>
  <div class="page">
    <p>Semi-greedy inference: example</p>
    <p>In the afternoon the temperature</p>
    <p>can reach 29 C</p>
    <p>... Hot weather this afternoon, with</p>
    <p>a low of around 25 C</p>
    <p>Document 1</p>
    <p>Document 2</p>
    <p>... This afternoon, the temperature</p>
    <p>will be range from 25 to 30 C</p>
    <p>Document 3</p>
    <p>temp(time = 1-6pm, min = 29, max = ?) 0.100</p>
    <p>Parser prediction Prob</p>
    <p>temp(time = 7-10am, min = 25, max = ?) 0.001</p>
    <p>Now condition 2 and 3 on m1</p>
    <p>Temp(time = 7-10am, min = 25, max = 30) 0.001</p>
    <p>It cannot prediction this new value for low, so it</p>
    <p>mistakenly decides that it refers to other time</p>
    <p>period, but prob is low</p>
    <p>Try starting from document 1:</p>
  </div>
  <div class="page">
    <p>Semi-greedy inference: example</p>
    <p>In the afternoon the temperature</p>
    <p>can reach 29 C</p>
    <p>... Hot weather this afternoon, with</p>
    <p>a low of around 25 C</p>
    <p>Document 1</p>
    <p>Document 2</p>
    <p>... This afternoon, the temperature</p>
    <p>will be range from 25 to 30 C</p>
    <p>Document 3</p>
    <p>temp(time = 1-6pm, min = 29, max = ?) 0.100</p>
    <p>Parser prediction Prob</p>
    <p>temp(time = 7-10am, min = 25, max = ?) 0.001</p>
    <p>Now condition 2 and 3 on m1</p>
    <p>Temp(time = 7-10am, min = 25, max = 30) 0.001</p>
    <p>The product of probabilities:</p>
    <p>It cannot prediction this new value for low, so it</p>
    <p>mistakenly decides that it refers to other time</p>
    <p>period, but prob is low</p>
    <p>Try starting from document 1:</p>
  </div>
  <div class="page">
    <p>Semi-greedy inference: example</p>
    <p>In the afternoon the temperature</p>
    <p>can reach 29 C</p>
    <p>... Hot weather this afternoon, with</p>
    <p>a low of around 25 C</p>
    <p>Document 1</p>
    <p>Document 2</p>
    <p>... This afternoon, the temperature</p>
    <p>will be range from 25 to 30 C</p>
    <p>Document 3</p>
    <p>Parser prediction ProbNow try starting from document 2:</p>
  </div>
  <div class="page">
    <p>Semi-greedy inference: example</p>
    <p>In the afternoon the temperature</p>
    <p>can reach 29 C</p>
    <p>... Hot weather this afternoon, with</p>
    <p>a low of around 25 C</p>
    <p>Document 1</p>
    <p>Document 2</p>
    <p>... This afternoon, the temperature</p>
    <p>will be range from 25 to 30 C</p>
    <p>Document 3</p>
    <p>Parser prediction Prob</p>
    <p>temp(time = 1-6 pm, min = 25, max = ?) 0.2</p>
    <p>Predict</p>
    <p>Correct analysis, high probability</p>
    <p>Now try starting from document 2:</p>
  </div>
  <div class="page">
    <p>Semi-greedy inference: example</p>
    <p>In the afternoon the temperature</p>
    <p>can reach 29 C</p>
    <p>... Hot weather this afternoon, with</p>
    <p>a low of around 25 C</p>
    <p>Document 1</p>
    <p>Document 2</p>
    <p>... This afternoon, the temperature</p>
    <p>will be range from 25 to 30 C</p>
    <p>Document 3</p>
    <p>temp(time = 1-6pm, min = ?, max = 29) 0.008</p>
    <p>Parser prediction Prob</p>
    <p>temp(time = 1-6 pm, min = 25, max = ?) 0.2</p>
    <p>Predict</p>
    <p>Correct analysis, high probability</p>
    <p>Now try starting from document 2:</p>
    <p>Condition on m2</p>
    <p>Correct analysis here too</p>
  </div>
  <div class="page">
    <p>Semi-greedy inference: example</p>
    <p>In the afternoon the temperature</p>
    <p>can reach 29 C</p>
    <p>... Hot weather this afternoon, with</p>
    <p>a low of around 25 C</p>
    <p>Document 1</p>
    <p>Document 2</p>
    <p>... This afternoon, the temperature</p>
    <p>will be range from 25 to 30 C</p>
    <p>Document 3</p>
    <p>temp(time = 1-6pm, min = ?, max = 29) 0.008</p>
    <p>Parser prediction Prob</p>
    <p>temp(time = 1-6 pm, min = 25, max = ?) 0.2</p>
    <p>Predict</p>
    <p>temp(time = 1-6pm, min = 25, max = 30) 0.2</p>
    <p>Correct analysis, high probability</p>
    <p>Now try starting from document 2:</p>
    <p>Condition on m2</p>
    <p>Correct analysis here too</p>
    <p>Condition on m2</p>
  </div>
  <div class="page">
    <p>Semi-greedy inference: example</p>
    <p>In the afternoon the temperature</p>
    <p>can reach 29 C</p>
    <p>... Hot weather this afternoon, with</p>
    <p>a low of around 25 C</p>
    <p>Document 1</p>
    <p>Document 2</p>
    <p>... This afternoon, the temperature</p>
    <p>will be range from 25 to 30 C</p>
    <p>Document 3</p>
    <p>temp(time = 1-6pm, min = ?, max = 29) 0.008</p>
    <p>Parser prediction Prob</p>
    <p>temp(time = 1-6 pm, min = 25, max = ?) 0.2</p>
    <p>Predict</p>
    <p>temp(time = 1-6pm, min = 25, max = 30) 0.2</p>
    <p>The product of probabilities:</p>
    <p>Correct analysis, high probability</p>
    <p>Now try starting from document 2:</p>
    <p>Condition on m2</p>
    <p>Correct analysis here too</p>
    <p>Condition on m2</p>
  </div>
  <div class="page">
    <p>Semi-greedy inference: example</p>
    <p>In the afternoon the temperature</p>
    <p>can reach 29 C</p>
    <p>... Hot weather this afternoon, with</p>
    <p>a low of around 25 C</p>
    <p>Document 1</p>
    <p>Document 2</p>
    <p>... This afternoon, the temperature</p>
    <p>will be range from 25 to 30 C</p>
    <p>Document 3</p>
    <p>temp(time = 1-6pm, min = ?, max = 29) 0.008</p>
    <p>Parser prediction Prob</p>
    <p>temp(time = 1-6 pm, min = 25, max = ?) 0.2</p>
    <p>Predict</p>
    <p>temp(time = 1-6pm, min = 25, max = 30) 0.2</p>
    <p>The product of probabilities:</p>
    <p>Correct analysis, high probability</p>
    <p>Now try starting from document 2:</p>
    <p>Condition on m2</p>
    <p>Correct analysis here too</p>
    <p>Condition on m2</p>
    <p>- As a result, either document 2 or document 3 will be</p>
    <p>parsed before document 1</p>
    <p>- After this iteration the model would learn that reach is an</p>
    <p>indicator of high not low =&gt; The model is improved</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation</p>
    <p>Learning with Semantically Related Unannotated Texts</p>
    <p>Inference with Groups of Documents</p>
    <p>Example problem:</p>
    <p>Analyzing Weather Forecasts</p>
    <p>A Model of Semantics (Liang et al., 2009)</p>
    <p>Experiments</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Weather forecasts (Liang et al., 2009)</p>
    <p>Weather forecast and its semantic representation</p>
    <p>Equivalently, you can write semantics of this short text as:</p>
    <p>thunderChance(mode = -, time = 1730)  windDir(mode = S)</p>
    <p>windSpeed(min = 20, max = 28)  gust(mean = 50)</p>
    <p>Evaluation possible:</p>
    <p>Actual parsing</p>
    <p>Hard as semantic state is too detailed, and annotation is not available</p>
    <p>Predicting an alignment between a database of all the records and text (semanticstext correspondence)</p>
    <p>Hidden</p>
    <p>Note: testing for</p>
    <p>contradiction and</p>
    <p>entailment is trivial</p>
  </div>
  <div class="page">
    <p>Unaligned Supervision</p>
    <p>In (Liang et al., 2009) they learned their model from unaligned semantics</p>
    <p>Hidden</p>
    <p>Document</p>
    <p>Semantics</p>
    <p>(36 records per forecast)</p>
  </div>
  <div class="page">
    <p>Our settings</p>
    <p>Most documents (semi-supervised) are unlabeled but several texts per forecast:</p>
    <p>Hidden</p>
    <p>They are clearly similar</p>
    <p>(ad non-contradictory)</p>
    <p>but different semantics is</p>
    <p>verbalized</p>
  </div>
  <div class="page">
    <p>Hierarchical Markov Model</p>
    <p>We augment the model of Liang et al (2009) with the weather distribution</p>
    <p>n documents - verbalizations</p>
    <p>of a subset of semantics</p>
    <p>Model of record transitions</p>
    <p>Model of field transitions</p>
    <p>Weather distribution</p>
    <p>(P(m))</p>
    <p>Word generation</p>
  </div>
  <div class="page">
    <p>Probability model</p>
    <p>Probability model for semantics (weather model)</p>
    <p>P(m) - a fully factorizable smoothed model over records and</p>
    <p>their fields</p>
    <p>P ( m | m) - probability of meaning m given m:</p>
    <p>1, if m ) m,</p>
    <p>0, if m ) : m,</p>
    <p>P(m  m) / P(m), otherwise</p>
    <p>Now, we have all components to estimate the</p>
    <p>model (with EM). See the paper for details</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation</p>
    <p>Learning with Semantically Related Unannotated Texts</p>
    <p>Inference with Groups of Documents</p>
    <p>Example problem:</p>
    <p>Analyzing Weather Forecasts</p>
    <p>A Model of Semantics (Liang et al., 2009)</p>
    <p>Experiments</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Dataset</p>
    <p>We augmented the original dataset (Liang et al, 2009) with</p>
    <p>additional texts</p>
    <p>Texts were annotated using a graphical/symbolic representation of a</p>
    <p>forecast</p>
    <p>Training data</p>
    <p>Labeled data: 150 texts with unaligned semantics</p>
    <p>Unlabeled data: 259 groups of related texts (650 texts, 2.5 txts/group)</p>
    <p>They are not paraphrases: total field overlap in each group &lt; 35%, 60%</p>
    <p>fields are mentioned only in a single text</p>
    <p>Testing:</p>
    <p>Individual documents, 150 texts (testing on predicting alignment)</p>
  </div>
  <div class="page">
    <p>Results</p>
    <p>Approach Crossing Pairs (Sem)</p>
    <p>P R F1</p>
    <p>Supervised Baseline (100 lab docs) 63.3 52.9 57.6</p>
    <p>Semi-Sup Baseline 68.8 69.4 69.1</p>
    <p>Our approach 78.8 69.5 73.9</p>
    <p>Supervised Upperbound (750 lab docs) 69.4 69.5 77.9</p>
    <p>Evaluated on predicting alignments between world states and texts</p>
    <p>Semi-Sup Baseline  exactly as our method but treats documents as isolated</p>
    <p>Our results are in the middle between the results</p>
    <p>of the supervised upper bound and a</p>
    <p>conventional semi-supervised methods</p>
  </div>
  <div class="page">
    <p>Induced Language Models</p>
    <p>value top words</p>
    <p>Top 5 words for field mode of record sky cover (function words omitted)</p>
    <p>Underlined words never appeared</p>
    <p>in the labeled data For 75-100: the model confuses</p>
    <p>field sky cover with field rain (one</p>
    <p>of main sources of errors)</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Proposed a new (and abundant) form of supervision for learning semantic analyzers</p>
    <p>developed a simple but effective inference method</p>
    <p>applied it to the text-meaning correspondence model (Liang et al, 2009)</p>
    <p>significant improvements both over the supervised baseline and over the semisupervised baseline on the forecast dataset</p>
    <p>The method can be generalized to other representation of semantics</p>
    <p>Exact contradiction (or entailment) computation may need to be replaced with an approximate model</p>
    <p>Related work on weakly-supervised learning of semantics presented here in Uppsala: (Clarke et al., CoNLL 10)</p>
  </div>
  <div class="page">
    <p>Thanks to</p>
    <p>Alexandre Klementiev, Alexander Koller, Manfred Pinkal, Dan Roth,</p>
    <p>Caroline Sporleder for discussion and suggestions</p>
    <p>Percy Liang for answering questions about their model</p>
    <p>The research is supported by the Excellence Cluster on Multimodal</p>
    <p>Computing and Interaction (MMCI) at Saarland University</p>
  </div>
</Presentation>
