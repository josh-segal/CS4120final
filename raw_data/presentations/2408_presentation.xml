<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>T H</p>
    <p>E</p>
    <p>U N I</p>
    <p>V E R</p>
    <p>S</p>
    <p>I T</p>
    <p>Y</p>
    <p>O F</p>
    <p>E D</p>
    <p>I N B U</p>
    <p>R</p>
    <p>G H</p>
    <p>On The Scalability of Storage Sub-System</p>
    <p>Back-end Network</p>
    <p>Yan Li, Roland Ibbett, Nigel Topham and Tim Courtney</p>
    <p>School of Informatics University of Edinburgh</p>
    <p>Xyratex, UK</p>
  </div>
  <div class="page">
    <p>Project Motivation 1</p>
    <p>T H</p>
    <p>E</p>
    <p>U N I</p>
    <p>V E R</p>
    <p>S</p>
    <p>I T</p>
    <p>Y</p>
    <p>O F</p>
    <p>E D</p>
    <p>I N B U</p>
    <p>R</p>
    <p>G H</p>
    <p>Project Motivation</p>
    <p>Theoretically the more disks used in a disk array, the higher the degree of parallesim, so leading to larger the performance potential performance benefits.</p>
    <p>However, in a real system there is a limitation on the scale of RAID systems due to the limitation of interconnection network.</p>
    <p>The more disks are added to the system, the higher the contention for the shared media.</p>
    <p>When the number of disks and cache size in a RAID system reaches a certain threshold, there will be no further gain in performance by adding more disk or cache due to the saturation of the back-end network.</p>
  </div>
  <div class="page">
    <p>Project Goal 2</p>
    <p>T H</p>
    <p>E</p>
    <p>U N I</p>
    <p>V E R</p>
    <p>S</p>
    <p>I T</p>
    <p>Y</p>
    <p>O F</p>
    <p>E D</p>
    <p>I N B U</p>
    <p>R</p>
    <p>G H</p>
    <p>Project Goal</p>
    <p>Investigate the capacity of interconnection networks in terms of the numbers of disks that can be included in one chain. In particular, Fibre Channel (FC) SBOD is chosen as the interconnection network.</p>
    <p>Give a certain number of disks and cache size, how much bandwidth is necessary to support them to get the maximum performance?</p>
    <p>Likewise, how many disks (and cache) can be connected to a 2GFC (4GFC) port?</p>
  </div>
  <div class="page">
    <p>Analytical Models 3</p>
    <p>T H</p>
    <p>E</p>
    <p>U N I</p>
    <p>V E R</p>
    <p>S</p>
    <p>I T</p>
    <p>Y</p>
    <p>O F</p>
    <p>E D</p>
    <p>I N B U</p>
    <p>R</p>
    <p>G H</p>
    <p>Assumptions:</p>
    <p>The request size of random access workload is equal to the size of stripe unit.</p>
    <p>The access address of each request is aligned to the stripe unit boundary.  The capacity of the RAID system keeps fixed for all the study.  The queue length of disk is 1, ie., no disk command waits in the disk for</p>
    <p>service.  The FC SBOD is chosen as the research subject.</p>
    <p>Disk command transmission time T x = S</p>
    <p>B + overhead. .</p>
    <p>Disk command execution time T d = S</p>
    <p>Bport +</p>
    <p>S</p>
    <p>Bmedia + Tseek .</p>
    <p>S size of stripe unit; B network bandwidth;</p>
  </div>
  <div class="page">
    <p>Analytical Models 4</p>
    <p>T H</p>
    <p>E</p>
    <p>U N I</p>
    <p>V E R</p>
    <p>S</p>
    <p>I T</p>
    <p>Y</p>
    <p>O F</p>
    <p>E D</p>
    <p>I N B U</p>
    <p>R</p>
    <p>G H</p>
    <p>Large Sequential Access</p>
    <p>D</p>
    <p>T x T d</p>
    <p>T v</p>
    <p>T x</p>
    <p>T dT v Time</p>
    <p>D</p>
    <p>+T x=</p>
    <p>For sequential access workload, a large volume command is divided into D disk commands, so that the response time for that command T v = DT x + T d.</p>
    <p>Throughput is the major performance metric:</p>
    <p>Throughput = K</p>
    <p>T v =</p>
    <p>K</p>
    <p>DT x + T d .</p>
  </div>
  <div class="page">
    <p>Analytical Models 5</p>
    <p>T H</p>
    <p>E</p>
    <p>U N I</p>
    <p>V E R</p>
    <p>S</p>
    <p>I T</p>
    <p>Y</p>
    <p>O F</p>
    <p>E D</p>
    <p>I N B U</p>
    <p>R</p>
    <p>G H</p>
    <p>Small Random Access</p>
    <p>x</p>
    <p>T x T d T v T x T d</p>
    <p>T v</p>
    <p>= 5)(DT d&gt;</p>
    <p>T v</p>
    <p>= 3)(DT d</p>
    <p>T dT v x</p>
    <p>Time Time</p>
    <p>=</p>
    <p>(D1)T&lt;x</p>
    <p>x x(D1)T(D1)T</p>
    <p>(D1)T</p>
    <p>+= DTT x</p>
    <p>Tv =</p>
    <p>T x + T d (D  1)  T x &lt; T d</p>
    <p>D  T x (D  1)  T x &gt;= T d</p>
    <p>For random access workload, IOPS is the major performance metric,</p>
    <p>IOPS =</p>
    <p>1</p>
    <p>D  T x (D  1)  T x &gt;= T d</p>
  </div>
  <div class="page">
    <p>Analytical Models 6</p>
    <p>T H</p>
    <p>E</p>
    <p>U N I</p>
    <p>V E R</p>
    <p>S</p>
    <p>I T</p>
    <p>Y</p>
    <p>O F</p>
    <p>E D</p>
    <p>I N B U</p>
    <p>R</p>
    <p>G H</p>
    <p>Analytical Results (no cache)</p>
    <p>number of disks</p>
    <p>th ro</p>
    <p>ug hp</p>
    <p>ut (B</p>
    <p>yt es</p>
    <p>/s )</p>
    <p>Seq Read, K=128KBytes</p>
    <p>number of disks</p>
    <p>IO P</p>
    <p>S</p>
    <p>RANOM, S=16KBytes</p>
    <p>Sequential Access Random Access</p>
  </div>
  <div class="page">
    <p>Analytical Models 7</p>
    <p>T H</p>
    <p>E</p>
    <p>U N I</p>
    <p>V E R</p>
    <p>S</p>
    <p>I T</p>
    <p>Y</p>
    <p>O F</p>
    <p>E D</p>
    <p>I N B U</p>
    <p>R</p>
    <p>G H</p>
    <p>General Model</p>
    <p>B = F (D, C, S, L, P ) = N umd  S + overhead</p>
    <p>B, the bandwidth required to achieve the maximum performance with D disks and C cache in system.</p>
    <p>D: number of disks</p>
    <p>C: cache size</p>
    <p>S: size of stripe unit</p>
    <p>L: workload characteristic</p>
    <p>P : cache destage threshold, P=0 for our study</p>
    <p>N umd: number of disk commands send to disk per second</p>
  </div>
  <div class="page">
    <p>Simulation Results 8</p>
    <p>T H</p>
    <p>E</p>
    <p>U N I</p>
    <p>V E R</p>
    <p>S</p>
    <p>I T</p>
    <p>Y</p>
    <p>O F</p>
    <p>E D</p>
    <p>I N B U</p>
    <p>R</p>
    <p>G H</p>
    <p>Systems without Cache (S = 16KB)</p>
    <p>number of disks</p>
    <p>M ax</p>
    <p>S P</p>
    <p>C</p>
    <p>S U</p>
    <p>RAID5 RAID6</p>
    <p>number of disks</p>
    <p>ut ili</p>
    <p>za tio</p>
    <p>n</p>
    <p>Disk Uti RAID5 Disk Uti RAID6 Net Uti RAID5 Net Uti RAID6</p>
    <p>number of disks</p>
    <p>M ax</p>
    <p>S P</p>
    <p>C</p>
    <p>S U</p>
    <p>RAID5 RAID6</p>
    <p>number of disks</p>
    <p>ut ili</p>
    <p>za tio</p>
    <p>n</p>
    <p>Disk Uti RAID5 Disk Uti RAID6 Net Uti RAID5 Net Uti RAID6</p>
    <p>Port Bandwidth = 2.125 Gbps</p>
    <p>Port Bandwidth = 4.25 Gbps</p>
  </div>
  <div class="page">
    <p>Simulation Results 9</p>
    <p>T H</p>
    <p>E</p>
    <p>U N I</p>
    <p>V E R</p>
    <p>S</p>
    <p>I T</p>
    <p>Y</p>
    <p>O F</p>
    <p>E D</p>
    <p>I N B U</p>
    <p>R</p>
    <p>G H</p>
    <p>Systems with Cache (S = 32KB)</p>
    <p>number of disks</p>
    <p>M ax</p>
    <p>S P</p>
    <p>C 1</p>
    <p>B S</p>
    <p>U</p>
    <p>number of disks</p>
    <p>ba nd</p>
    <p>w id</p>
    <p>th (</p>
    <p>G bp</p>
    <p>s)</p>
    <p>number of disks</p>
    <p>di sk</p>
    <p>u til</p>
    <p>iz at</p>
    <p>io n</p>
    <p>number of disks</p>
    <p>re ad</p>
    <p>m is</p>
    <p>s ra</p>
    <p>te</p>
    <p>RAID5 RAID6</p>
    <p>RAID5 RAID6</p>
    <p>RAID5 RAID6</p>
    <p>RAID5 RAID6</p>
    <p>(a) (b)</p>
    <p>(c) (d)</p>
  </div>
  <div class="page">
    <p>Summary 10</p>
    <p>T H</p>
    <p>E</p>
    <p>U N I</p>
    <p>V E R</p>
    <p>S</p>
    <p>I T</p>
    <p>Y</p>
    <p>O F</p>
    <p>E D</p>
    <p>I N B U</p>
    <p>R</p>
    <p>G H</p>
    <p>Summary</p>
    <p>When this is no cache, a 2G FC port is able to support up to 46 disks for RAID5 and 53 disks for RAID6 (size of stripe unit = 16kBytes).</p>
    <p>With enough cache, a 2G FC port is able to support up to 18 disks under OLTP like workload. (size of stripe unit = 32KBytes).</p>
    <p>When there is enough cache, the bandwidth required to support a certain number of disks is fixed. It is irrelevant with protection level and cache size.</p>
  </div>
  <div class="page">
    <p>Future Work 11</p>
    <p>T H</p>
    <p>E</p>
    <p>U N I</p>
    <p>V E R</p>
    <p>S</p>
    <p>I T</p>
    <p>Y</p>
    <p>O F</p>
    <p>E D</p>
    <p>I N B U</p>
    <p>R</p>
    <p>G H</p>
    <p>Future Work</p>
    <p>Study the scalability of back-end network when the size of stripe unit is 16k and the system performance.</p>
    <p>Study the network bandwidth requirement when there is cache coherency between two controllers.</p>
  </div>
</Presentation>
