<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Memshare: a Dynamic Multi-tenant Key-value Cache</p>
    <p>A S A F C I D O N * , D A N I E L R U S H TO N  , S T E P H E N M . R U M B L E  , R YA N S T U T S M A N</p>
    <p>* S TA N F O R D U N I V E R S I T Y,  U N I V E R S I T Y O F U TA H ,  G O O G L E I N C .</p>
  </div>
  <div class="page">
    <p>Cache is 100X Faster Than Database</p>
    <p>Web Server</p>
  </div>
  <div class="page">
    <p>Cache Hit Rate Drives Cloud Performance</p>
    <p>Small improvements to cache hit rate make big difference:</p>
    <p>At 98% cache hit rate:  +1% hit rate  35% speedup</p>
    <p>Facebook study [Atikoglu 12]</p>
  </div>
  <div class="page">
    <p>Static Partitioning  Low Hit Rates  Cache providers statically partition their</p>
    <p>memory among applications</p>
    <p>Examples:  Facebook  Amazon Elasticache  Memcachier</p>
  </div>
  <div class="page">
    <p>Partitioned Memory Over Time</p>
    <p>Static Partition No Partition</p>
    <p>App B App C</p>
  </div>
  <div class="page">
    <p>Partitioned vs No Partition Hit Rates</p>
    <p>Application Hit Rate Partitioned Hit Rate No Partition</p>
    <p>Combined 87.8% 88.8%</p>
    <p>A 97.6% 96.6%</p>
    <p>B 98.8% 99.1%</p>
    <p>C 30.1% 39.2%</p>
  </div>
  <div class="page">
    <p>Partitioned Memory: Pros and Cons</p>
    <p>Disadvantages:  Lower hit rate due to low utilization  Higher TCO</p>
    <p>Advantages:  Isolated performance and predictable hit rate  Fairness: customers get what they pay for</p>
  </div>
  <div class="page">
    <p>Memshare: the Best of Both Worlds</p>
    <p>Optimize memory allocation to maximize overall hit rate</p>
    <p>While providing minimal guaranteed memory allocation and performance isolation</p>
  </div>
  <div class="page">
    <p>Multi-tenant Cache Design Challenges</p>
  </div>
  <div class="page">
    <p>Estimate Hit Rate Curve Gradient to Optimize Hit Rate</p>
  </div>
  <div class="page">
    <p>Estimate Hit Rate Curve Gradient to Optimize Hit Rate</p>
  </div>
  <div class="page">
    <p>Estimating Hit Rate Gradient</p>
    <p>Track access frequency to recently evicted objects to determine gradient at working point</p>
    <p>Can be further improved with full hit rate curve estimation</p>
    <p>SHARDS [Waldspurger 2015, 2017]</p>
    <p>AET [Hu 2016]</p>
  </div>
  <div class="page">
    <p>Multi-tenant Cache Design Challenges</p>
  </div>
  <div class="page">
    <p>Multi-tenant Cache Design Challenges</p>
    <p>Not so simple</p>
  </div>
  <div class="page">
    <p>Slab Allocation Primer</p>
    <p>Memcached Server</p>
    <p>App 1 App 2</p>
  </div>
  <div class="page">
    <p>Slab Allocation Primer</p>
    <p>Memcached Server</p>
    <p>App 1 App 2</p>
  </div>
  <div class="page">
    <p>Memcached Server</p>
    <p>Slab Allocation Primer</p>
    <p>LRU Queues</p>
    <p>App 1 App 2</p>
  </div>
  <div class="page">
    <p>Goal: Move 4KB from App 2 to App 1</p>
    <p>Memcached Server</p>
    <p>App 1 App 2</p>
  </div>
  <div class="page">
    <p>Goal: Move 4KB from App 2 to App 1</p>
    <p>Problems:  Need to evict 1MB  Contains many small objects,</p>
    <p>some are hot</p>
    <p>App 1 can only use extra space for objects of certain size</p>
    <p>Memcached Server</p>
    <p>App 1 App 2</p>
  </div>
  <div class="page">
    <p>Goal: Move 4KB from App 2 to App 1</p>
    <p>Problems:  Need to evict 1MB  Contains many small objects,</p>
    <p>some are hot</p>
    <p>App 1 can only use extra space for objects of certain size</p>
    <p>Problematic even for one application, see Cliffhanger [Cidon 2016]</p>
    <p>Memcached Server</p>
    <p>App 1 App 2</p>
  </div>
  <div class="page">
    <p>Instead of Slabs: Log-structured Memory</p>
    <p>Log segments</p>
    <p>Log Head</p>
  </div>
  <div class="page">
    <p>Instead of Slabs: Log-structured Memory</p>
    <p>Log segments</p>
    <p>Log Head</p>
    <p>Newly written object</p>
  </div>
  <div class="page">
    <p>Instead of Slabs: Log-structured Memory</p>
    <p>Log segments</p>
    <p>Log Head</p>
  </div>
  <div class="page">
    <p>Applications are Physically Intermixed</p>
    <p>Log segments</p>
    <p>Log Head</p>
    <p>App 1 App 2</p>
  </div>
  <div class="page">
    <p>Memshares Sharing Model  Reserved Memory: guaranteed static memory</p>
    <p>Pooled Memory: applications share of pooled memory</p>
    <p>Target Memory = Reserved Memory + Pooled Memory</p>
  </div>
  <div class="page">
    <p>Cleaning Priority Determines Eviction Priority</p>
    <p>Q: When does Memshare evict?</p>
    <p>A: Newly written objects evict old objects, but not in critical path</p>
    <p>Cleaner keeps 1% of cache empty</p>
    <p>Cleaner tries to enforce actual memory allocation to be equal to Target Memory</p>
  </div>
  <div class="page">
    <p>Cleaner Pass</p>
    <p>App 1 App 2</p>
    <p>n candidate segments (n = 2)</p>
    <p>n - 1 survivor segments (n = 2)</p>
  </div>
  <div class="page">
    <p>Cleaner Pass</p>
    <p>App 1 App 2</p>
    <p>n candidate segments (n = 2)</p>
    <p>n - 1 survivor segments (n = 2)</p>
  </div>
  <div class="page">
    <p>Cleaner Pass</p>
    <p>App 1 App 2</p>
    <p>n candidate segments (n = 2)</p>
    <p>n - 1 survivor segments (n = 2)</p>
  </div>
  <div class="page">
    <p>Cleaner Pass</p>
    <p>App 1 App 2</p>
    <p>n candidate segments (n = 2)</p>
    <p>n - 1 survivor segments (n = 2)</p>
  </div>
  <div class="page">
    <p>Cleaner Pass</p>
    <p>App 1 App 2</p>
    <p>n candidate segments (n = 2)</p>
    <p>n - 1 survivor segments (n = 2)</p>
  </div>
  <div class="page">
    <p>Cleaner Pass</p>
    <p>App 1 App 2</p>
    <p>n candidate segments (n = 2)</p>
    <p>n - 1 survivor segments (n = 2)</p>
  </div>
  <div class="page">
    <p>Cleaner Pass (n = 4): Twice the Work</p>
    <p>App 1 App 2</p>
  </div>
  <div class="page">
    <p>Application Need: How Far is Memory Allocation from Target Memory?</p>
    <p>App 1 App 2</p>
    <p>need(app) = targetMemory(app)</p>
    <p>actualMemory(app)</p>
    <p>Log segments</p>
    <p>Log Head</p>
  </div>
  <div class="page">
    <p>Within Each Application, Evict by Rank</p>
    <p>App 1 App 2</p>
    <p>Log segments</p>
    <p>Log Head</p>
    <p>To implement LRU: rank = last access time</p>
  </div>
  <div class="page">
    <p>Cleaning: Max Need and then Max Rank</p>
    <p>Rank 1 Rank 0Rank 2 Rank 3</p>
    <p>Need</p>
    <p>App 1 0.8</p>
    <p>App 2 1.4</p>
    <p>App 3 0.9</p>
    <p>Max Need? Max Rank?</p>
    <p>n segments n-1 segments</p>
  </div>
  <div class="page">
    <p>Cleaning: Max Need and then Max Rank</p>
    <p>Rank 1 Rank 0 Rank 3</p>
    <p>Need</p>
    <p>App 1 0.8</p>
    <p>App 2 1.4</p>
    <p>App 3 0.9</p>
    <p>Max Need?  App 2 Max Rank?</p>
    <p>n segments n-1 segments</p>
    <p>Rank 2</p>
  </div>
  <div class="page">
    <p>Cleaning: Max Need and then Max Rank</p>
    <p>Rank 1 Rank 0 Rank 3</p>
    <p>Need</p>
    <p>App 1 0.8</p>
    <p>App 2 1.4</p>
    <p>App 3 0.9</p>
    <p>Max Need?  App 2 Max Rank?  Rank 2</p>
    <p>n segments n-1 segments</p>
    <p>Rank 2</p>
  </div>
  <div class="page">
    <p>Cleaning: Max Need and then Max Rank</p>
    <p>Rank 1 Rank 0 Rank 3</p>
    <p>Need</p>
    <p>App 1 0.9</p>
    <p>App 2 0.8</p>
    <p>App 3 1.2</p>
    <p>Max Need? Max Rank?</p>
    <p>n segments n-1 segments</p>
    <p>Rank 2</p>
  </div>
  <div class="page">
    <p>Cleaning: Max Need and then Max Rank</p>
    <p>Rank 1 Rank 0 Rank 3</p>
    <p>Need</p>
    <p>App 1 0.9</p>
    <p>App 2 0.8</p>
    <p>App 3 1.2</p>
    <p>Max Need?  App 3 Max Rank?</p>
    <p>n segments n-1 segments</p>
    <p>Rank 2</p>
  </div>
  <div class="page">
    <p>Cleaning: Max Need and then Max Rank</p>
    <p>Rank 1 Rank 0 Rank 3</p>
    <p>Need</p>
    <p>App 1 0.9</p>
    <p>App 2 0.8</p>
    <p>App 3 1.2</p>
    <p>Max Need?  App 3 Max Rank?  Rank 1</p>
    <p>n segments n-1 segments</p>
    <p>Rank 2</p>
  </div>
  <div class="page">
    <p>Trading Off Eviction Accuracy and Cleaning Cost</p>
    <p>Eviction accuracy is determined by n  For example: rank = time of last access</p>
    <p>When n  # segments: ideal LRU</p>
    <p>Intuition: n is similar to cache associativity</p>
    <p>CPU consumption is determined by n</p>
  </div>
  <div class="page">
    <p>Trading Off Eviction Accuracy and Cleaning Cost</p>
    <p>Eviction accuracy is determined by n  For example: rank = time of last access</p>
    <p>When n  : ideal LRU</p>
    <p>Intuition: n is similar to cache associativity</p>
    <p>CPU consumption is determined by n</p>
    <p>In practice Memcached is never CPU-bound in our data centers. Increasing CPU to improve the hit rate would be a good trade off.</p>
    <p>- Nathan Bronson, Facebook</p>
  </div>
  <div class="page">
    <p>Implementation  Implemented in C++ on top of Memcached</p>
    <p>Reuse Memcacheds hash table, transport, request processing</p>
    <p>Implemented log-structured memory allocator</p>
  </div>
  <div class="page">
    <p>Partitioned vs. Memshare</p>
    <p>Application Hit Rate Partitioned Hit Rate Memshare (50% Reserved)</p>
    <p>Combined 87.8% 89.2%</p>
    <p>A 97.6% 99.4%</p>
    <p>B 98.8% 98.8%</p>
    <p>C 30.1% 34.5%</p>
  </div>
  <div class="page">
    <p>Reserved vs. Pooled Behavior</p>
    <p>Combined Hit Rates 90.2% 89.2% 88.8%</p>
    <p>App B App C</p>
  </div>
  <div class="page">
    <p>State-of-the-art Hit rate</p>
    <p>Application</p>
    <p>H it R</p>
    <p>a te</p>
    <p>( %</p>
    <p>)</p>
    <p>Memcached</p>
    <p>Memshare (75% Reser ved)</p>
    <p>Misses reduced by 40%</p>
    <p>Combined hit rate increase: 6% (85%  91%)</p>
  </div>
  <div class="page">
    <p>State-of-the-art Hit Rate Even for Single Tenant Applications</p>
    <p>Policy Memcached Memshare (100% Reserved)</p>
    <p>Average Single Tenant Hit Rate</p>
  </div>
  <div class="page">
    <p>Cleaning Overhead is Minimal</p>
    <p>MB/s</p>
    <p>n (number of cleaning candidate segments)</p>
    <p>Hit rate Memory Bandwidth</p>
  </div>
  <div class="page">
    <p>MB/s</p>
    <p>n (number of cleaning candidate segments)</p>
    <p>Hit rate Memory Bandwidth</p>
    <p>Cleaning Overhead is Minimal</p>
    <p>Modern servers have 10GB/s or more!</p>
  </div>
  <div class="page">
    <p>Related Work  Optimizing memory allocation using shadow</p>
    <p>queues  Cliffhanger [Cidon 2016]</p>
    <p>Log-structured single-tenant key-value stores  RAMCloud [Rumble 2014] and MICA [Lim 2014]</p>
    <p>Taxing idle memory  ESX Server [Waldspurger 2002]</p>
  </div>
  <div class="page">
    <p>Summary  First multi-tenant key-value cache that:  Optimizes share for highest hit rate</p>
    <p>Provides minimal guarantees</p>
    <p>Novel log-structured design  Use cleaner as enforcer</p>
  </div>
  <div class="page">
    <p>Appendix</p>
  </div>
  <div class="page">
    <p>Idle Tax for Selfish Applications  Some sharing models do not support pooled memory, each</p>
    <p>application is selfish  For example: Memcachiers Cache-as-a-Service</p>
    <p>Idle tax: reserved memory can be reassigned if idle</p>
    <p>Tax rate: determines portion of idle memory that can be reassigned</p>
    <p>If all memory is active: target memory = reserved memory</p>
  </div>
  <div class="page">
    <p>Partitioned vs. Idle Tax</p>
    <p>Application Hit Rate Partitioned Hit Rate Memshare Idle Tax</p>
    <p>Combined 87.8% 88.8%</p>
    <p>A 97.6% 99.4%</p>
    <p>B 98.8% 98.6%</p>
    <p>C 30.1% 31.3%</p>
  </div>
  <div class="page">
    <p>State-of-the-art Hit rate</p>
    <p>Memcached Cliffhanger Memshare (75% Reserved)</p>
    <p>Combined Hit Rate Miss Reduction vs. Memcached</p>
  </div>
  <div class="page">
    <p>Nearly Identical Latency</p>
  </div>
</Presentation>
