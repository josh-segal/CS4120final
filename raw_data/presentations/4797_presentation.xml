<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Generic Soft Pattern Models for Definitional Question Answering</p>
    <p>Hang Cui Min-Yen Kan Tat-Seng Chua</p>
    <p>Department of Computer Science National University of Singapore</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Patterns Are Everywhere</p>
    <p>Information Extraction (IE)</p>
    <p>noun preposition &lt;noun_phrase&gt; e.g. bomb against &lt;target&gt;</p>
    <p>Question Answering (QA)</p>
    <p>&lt;search_term&gt; , DT$ NNP , e.g. Gunter Blobel , a biologist at  , said</p>
    <p>Other tasks</p>
    <p>&lt;subj&gt; passive-verb e.g. &lt;subj&gt; was satisfied</p>
    <p>Lexico-syntactic Patterns</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Two Methods of Pattern Matching</p>
    <p>expression represented rules</p>
    <p>Performing slot by slot matching</p>
    <p>Soft pattern matching for definitional QA (Cui et al., 2004)</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Hard Matching</p>
    <p>Lack of flexibility in matching  Cant deal with gaps between rules and test</p>
    <p>instances</p>
    <p>Bob Lloyd , president and chief operating officer , was named to the chief executive.</p>
    <p>&lt;PersonIN&gt; , NNP , BE$ named to &lt;POST&gt;</p>
    <p>Lee Abraham , 65 years old , former chairman and chief executive officer of Associated Merchandising Corp. , New York , was named to the board of the footwear manufacturer.</p>
    <p>Gaps by insertion</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Soft Matching (Cui et al., 2004)</p>
    <p>The channel Iqra is owned by the   severance packages, known as golden parachutes, included</p>
    <p>A battery is a cell which can provide electricity.</p>
    <p>DT$ NN &lt;Search_Term&gt; BE$ owned by known as &lt;Search_Term&gt; , VB</p>
    <p>&lt;Search_Term&gt; BE$ DT$</p>
    <p>&lt;Slot-2&gt; &lt;Slot-1&gt; &lt;Search_Term&gt; &lt;Slot1&gt; &lt;Slot2&gt;  NN 0.12 NN 0.11 , 0.40 DT$ 0.2 known 0.09 as 0.20 BE$ 0.2 VB 0.1 DT$ 0.04 owned 0.09</p>
    <p>Training</p>
    <p>Testing known as &lt;Search_Term&gt; , DT$  is known as Wicca, a neo-pagan nature religion, includes the use of herbal magic and witchcraft in its practice.</p>
    <p>P ( Ins ) = P(known|S-2) + P(as|S-1) + P(,|S1) + P(DT$|S2) + P(known as) + P(, DT$)</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Weakness of Current Soft Matching Models  Ad-hoc in model parameter estimation</p>
    <p>Cui et al., 2004: Lack of formalization</p>
    <p>Not generic  Task specific topology for HMM</p>
    <p>Difficult to port to other applications</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>In This Paper</p>
    <p>Propose two generic soft pattern models  Bigram model</p>
    <p>Formalization of our previous model</p>
    <p>Profile Hidden Markov Model (PHMM)  More complex model that handles gaps better</p>
    <p>Parameter estimation by EM algorithm  Evaluations on definitional question</p>
    <p>answering  Can be applied to other pattern matching</p>
    <p>applications</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Outline</p>
    <p>Overview of Definitional QA</p>
    <p>Bigram Soft Pattern Model</p>
    <p>PHMM Soft Pattern Model</p>
    <p>Evaluations</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Outline</p>
    <p>Overview of Definitional QA</p>
    <p>Bigram Soft Pattern Model</p>
    <p>PHMM Soft Pattern Model</p>
    <p>Evaluations</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>(1)  that Wicca _ whose practitioners call themselves witches and believe in the dual deity of god and goddess _ is not a religion and should not be practiced on military bases. (2)  , Wicca, as contemporary witchcraft is often called, has been growing in the United States and abroad. (3) The Wiccans, whose religion is a reconstruction of nature worship from tribal Europe and other parts of the world, had to meet the same criteria as other religions to conduct services on the base, including sponsorship by a legally incorporated church, in this case one in San Antonio. (4) Wicca adherents celebrate eight major sabbats, festivals that mark the change of seasons and agricultural cycles, and believe in both god and goddess.</p>
    <p>Definitional QA</p>
    <p>To answer questions like Who is Gunter Blobel or What is Wicca.</p>
    <p>Why evaluating on definition sentence retrieval?  Diverse patterns</p>
    <p>Definitional QA is one of the least explored areas in QA</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Pattern Matching for Definitional QA</p>
    <p>Question</p>
    <p>Document Retrieval</p>
    <p>Preprocessing</p>
    <p>Definition Sentence Retrieval</p>
    <p>Redundancy Removal</p>
    <p>Definition Pattern Matching</p>
    <p>Bag-of-Words Similarity Ranking</p>
    <p>Definition</p>
    <p>Manually constructed patterns Appositive</p>
    <p>e.g. Gunter Blobel , a cellular and molecular biologist,</p>
    <p>Copulas e.g. Battery is a kind of electronic device</p>
    <p>Predicates (relations) e.g. TB is usually caused by</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Outline</p>
    <p>Overview of Definitional QA</p>
    <p>Bigram Soft Pattern Model</p>
    <p>PHMM Soft Pattern Model</p>
    <p>Evaluations</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Bigram Soft Pattern Model</p>
    <p>L</p>
    <p>i iiii</p>
    <p>L</p>
    <p>i iii</p>
    <p>L</p>
    <p>i iiL</p>
    <p>StPttPStP</p>
    <p>tPttPtP</p>
    <p>ttPttP</p>
    <p>))|()1()|(()|(</p>
    <p>)),()1(),|(()|(</p>
    <p>)|()(</p>
    <p>Bigram prob Slot-aware unigram prob</p>
    <p>P ( Ins ) = P(known|S-2) + P(as|S-1) + P(,|S1) + P(DT$|S2) + P(known as) + P(, DT$)</p>
    <p>To estimate the interpolation mixture weight   Expectation Maximization (EM) algorithm</p>
    <p>Count words and general tags separately  Avoid overwhelming frequency count of general tags</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Bigram Model in Dealing with Gaps  Bigram model can deal with gaps</p>
    <p>Unseen tokens have small smoothing probabilities in specific positions</p>
    <p>&lt;Search_Term&gt; which is known for DT$ NNP</p>
    <p>Test sentence:</p>
    <p>Pattern</p>
    <p>&lt;Search_Term&gt; , whose book is known for</p>
    <p>P(,|S1) = P(whose|S2) = P(book|S3) = P(is|S4) = P(,|S1) = P(whose|S2)  = small smoothing prob</p>
    <p>P(known|S3) = 0.3 P(for|S4) = 0.21Not too good!   k</p>
    <p>jk tNSt |)(||)(|</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Outline</p>
    <p>Overview of Definitional QA</p>
    <p>Bigram Soft Pattern Model</p>
    <p>PHMM Soft Pattern Model</p>
    <p>Evaluations</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>PHMM Soft Pattern Model</p>
    <p>Better solution for dealing with gaps  Left to right Hidden Markov Model with insertion and</p>
    <p>deletion states</p>
    <p>Start M1 M2 M3 M4 End</p>
    <p>D2 D3 D4D1</p>
    <p>I 0 I1 I2 I3</p>
    <p>I 4</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>How PHMM Deals with Gaps</p>
    <p>L</p>
    <p>i iiiinLLLN</p>
    <p>SSTStPSSTSSttob 1</p>
    <p>probability given a test instance  Find the most</p>
    <p>probable path by Viterbi algorithm</p>
    <p>Efficient calculation by forward-backward algorithm</p>
    <p>Probabilities obtained in the training process</p>
    <p>P(ti|Dj) = 1</p>
    <p>know n</p>
    <p>as DT $</p>
    <p>NNP</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Estimation of PHMM</p>
    <p>Estimated by Baum-Welch algorithm  Using the most probable path during training</p>
    <p>Random or uniform initialization may lead to unsatisfactory model  Extreme diversity of definition patterns</p>
    <p>Assume path should favor match states over others</p>
    <p>P( token | Match ) &gt; P ( token | Insertion )</p>
    <p>Using smoothed ML estimates</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Outline</p>
    <p>Overview of Definitional QA</p>
    <p>Bigram Soft Pattern Model</p>
    <p>PHMM Soft Pattern Model</p>
    <p>Evaluations  Overall performance evaluation</p>
    <p>Sensitivity to model length</p>
    <p>Sensitivity to size of training data</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Evaluation Setup</p>
    <p>Data set  Test data: TREC-13 question answering task data</p>
    <p>AQUAINT corpus and 64 definition questions with answers</p>
    <p>Training data  761 manually labeled definition sentences from TREC-12</p>
    <p>question answering task data</p>
    <p>Comparison systems  State-of-the-art manually constructed patterns</p>
    <p>Most comprehensive manually constructed patterns to our knowledge</p>
    <p>Previously proposed soft pattern in Cui et al., 2004</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Evaluation Metrics</p>
    <p>Manually checked F3 measure  Based on essential/acceptable answer nuggets</p>
    <p>NR  proportion of returned essential answer nuggets  NP  penalty to longer answers  Weighting NR 3 times as NP</p>
    <p>Subject to inconsistent scoring among assessors</p>
    <p>Automatic ROUGE score  Gold standard: sentences containing answer nuggets  Counting the trigrams shared in the gold standard and</p>
    <p>system answers  ROUGE-3-ALL (R3A) and ROUGE-3-ESSENTIAL</p>
    <p>(R3E)</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Performance Evaluation</p>
    <p>Soft pattern matching outperforms hard matching  Bigram and PHMM models perform better than the</p>
    <p>previously proposed soft pattern method  Previous soft pattern method is not optimized</p>
    <p>Manual F3 score correlate well with automatic R3 scores</p>
    <p>HP Original SP Bigram SP PHMM SP</p>
    <p>R3A 0.2106 0.2233</p>
    <p>(+6.00%) 0.2303</p>
    <p>(+9.37%) 0.2234</p>
    <p>(+6.08%)</p>
    <p>R3E 0.2286 0.2378</p>
    <p>(+4.00%) 0.2553</p>
    <p>(+11.67%)* 0.2496</p>
    <p>(+9.18%)</p>
    <p>F 3 0.4633</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Sensitivity to Model Length</p>
    <p>PHMM is less sensitive to model length  PHMM may handle longer sequences</p>
    <p>Soft Pattern Models' Sensitivity to Model Length</p>
    <p>Model Length</p>
    <p>Bigram SP R3A</p>
    <p>Bigram SP R3E</p>
    <p>PHMM SP R3A</p>
    <p>PHMM SP R3E</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Sensitivity to the Amount of Training Data  PHMM requires more training data to</p>
    <p>improve</p>
    <p>Training Data size (fraction of whole training corpus)</p>
    <p>PHMM R3A 0.2110 0.2179 (+3.24%) 0.2234 (+5.85%)</p>
    <p>PHMM R3E 0.2311 0.2402 (+3.93%) 0.2496 (+8.00%)</p>
    <p>Bigram R3A 0.2229 0.2269 (+1.76%) 0.2303 (+3.32%)</p>
    <p>Bigram R3E 0.2478 0.2510 (+1.29%) 0.2553 (+3.03%)</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Discussions on Both Models</p>
    <p>Capture the same information  The importance of a tokens position in the context of the search</p>
    <p>term  The sequential order of tokens</p>
    <p>Different in complexity  Bigram model</p>
    <p>Simplified Markov model with each token as a state  Captures token sequential information by bigram probabilities</p>
    <p>PHMM model  More complex  aggregated token sequential information by hidden</p>
    <p>state transition probabilities</p>
    <p>Experimental results show  PHMM is less sensitive to model length  PHMM may benefit more by using more training data</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Outline</p>
    <p>Overview of Definitional QA</p>
    <p>Bigram Soft Pattern Model</p>
    <p>PHMM Soft Pattern Model</p>
    <p>Evaluations</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Conclusions</p>
    <p>Proposed Bigram model and PHMM model  Generic in the forms</p>
    <p>Systematic parameter estimation by EM algorithm</p>
    <p>These two models can be applied to other applications using surface text patterns  Soft patterns have been applied to information</p>
    <p>extraction (Xiao et al., 2004)</p>
    <p>Can deal with diversified patterns</p>
    <p>PHMM is more flexible in dealing with gaps, but requires more training data to converge</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Q &amp; A</p>
    <p>Thanks!</p>
  </div>
</Presentation>
