<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>History-Independent Cuckoo Hashing</p>
    <p>Weizmann Institute Israel</p>
    <p>Udi Wieder</p>
    <p>Moni Naor Gil Segev</p>
    <p>Microsoft Research</p>
    <p>Silicon Valley</p>
  </div>
  <div class="page">
    <p>Election Day Carol</p>
    <p>Bob</p>
    <p>Carol</p>
    <p>Elections for class president  Each student whispers in Mr.</p>
    <p>Drews ear  Mr. Drew writes down the</p>
    <p>votes</p>
    <p>Alice Alice Bob</p>
    <p>Alice  Problem:</p>
    <p>Mr. Drews notebook leaks sensitive information  First student voted for</p>
    <p>Carol  Second student voted</p>
    <p>for Alice</p>
    <p>Alice May compromise the privacy of the elections</p>
  </div>
  <div class="page">
    <p>Election Day</p>
    <p>Carol</p>
    <p>Alice Bob</p>
    <p>Carol Alice Alice Bob  What about more involved</p>
    <p>applications?  Write-in candidates  Votes which are subsets or</p>
    <p>rankings  .</p>
    <p>A simple solution:  Lexicographically</p>
    <p>sorted list of candidates</p>
    <p>Unary counters</p>
  </div>
  <div class="page">
    <p>Learning From History</p>
    <p>A simple example: sorted list  Canonical memory representation  Not really efficient...</p>
    <p>The two levels of a data structure  Legitimate interface  Memory representation</p>
    <p>History independence The memory representation should not reveal information that cannot be obtained using the legitimate interface</p>
    <p>Alic eBob</p>
    <p>Car ol</p>
  </div>
  <div class="page">
    <p>Typical Applications</p>
    <p>Incremental cryptography [BGG94, Mic97]</p>
    <p>Voting [MKSW06, MNS07]</p>
    <p>Set comparison &amp; reconciliation [MNS08]</p>
    <p>Computational geometry [BGV08]</p>
    <p>...</p>
  </div>
  <div class="page">
    <p>Our Contribution A HI dictionary that simultaneously achieves the following:  Efficiency:</p>
    <p>Lookup time  O(1) worst case  Update time  O(1) expected amortized  Memory utilization 50% (25% with deletions)</p>
    <p>Strongest notion of history independence</p>
    <p>Simple and fast</p>
  </div>
  <div class="page">
    <p>Notions of History Independence</p>
    <p>Weak history independence  Memory revealed at the end of an activity period  Any two sequences of operations S1 and S2 that</p>
    <p>lead to the same content induce the same distribution on the memory representation</p>
    <p>Strong history independence  Memory revealed several times during an activity</p>
    <p>period  Any two sets of breakpoints along S1 and S2 with</p>
    <p>the same content at each breakpoint, induce the same distributions on the memory representation at all these points</p>
    <p>Completely randomizing memory after each operation is not good enough</p>
    <p>Naor and Teague (2001) following Macciancio (1997)</p>
  </div>
  <div class="page">
    <p>Notions of History Independence</p>
    <p>Weak &amp; strong are not equivalent  WHI for reversible data structures is possible</p>
    <p>without a canonical representation  Provable efficiency gaps [BP06] (in restricted</p>
    <p>models)</p>
    <p>We consider strong history independence  Canonical representation (up to initial</p>
    <p>randomness) implies SHI  Other direction shown to hold for reversible data</p>
    <p>structures [HHMPR05]</p>
  </div>
  <div class="page">
    <p>SHI Dictionaries Deleti ons</p>
    <p>Memor y</p>
    <p>utilizat ion</p>
    <p>Updat e</p>
    <p>time</p>
    <p>Looku p</p>
    <p>time</p>
    <p>Practic al?</p>
    <p>Naor &amp; Teague</p>
    <p>01</p>
    <p>Blelloch &amp;</p>
    <p>Golovin 07Blelloch &amp;</p>
    <p>Golovin 07 This work</p>
    <p>&lt; 9%</p>
    <p>&lt; 25% (&lt;</p>
    <p>O(1) expect</p>
    <p>ed</p>
    <p>O(1) expect</p>
    <p>ed</p>
    <p>O(1) expect</p>
    <p>ed</p>
    <p>O(1) expect</p>
    <p>ed</p>
    <p>O(1) worst case</p>
    <p>O(1) expect</p>
    <p>ed</p>
    <p>O(1) worst case</p>
    <p>O(1) worst case</p>
    <p>?</p>
    <p>(mem. util. &lt; 50%)</p>
    <p>(mem. util. &lt; 50%)</p>
  </div>
  <div class="page">
    <p>Our Approach  Cuckoo hashing [PR01]:</p>
    <p>A simple &amp; practical scheme with worst case constant lookup time</p>
    <p>Force a canonical representation on cuckoo hashing  No significant loss in efficiency</p>
    <p>Avoid rehashing by using a small stash  What happens when hash functions fail?  Rehashing is problematic in SHI data structures</p>
    <p>All hash functions need to be sampled in advance (theoretical problem)</p>
    <p>When an item is deleted, may need to roll back on previous functions</p>
    <p>We use a secondary storage to reduces the failure probability exponentially [KMW08]</p>
  </div>
  <div class="page">
    <p>Cuckoo Hashing  Tables T1 and T2 with hash functions h1 and h2  Store x in one of T1[h1(x)] and T2[h2(x)]</p>
    <p>Insert(x):  Greedily insert in T1 or T2  If both are occupied then store x in T1</p>
    <p>Repeat in other table with the previous occupant</p>
    <p>Y</p>
    <p>Z</p>
    <p>V</p>
    <p>T1 T2</p>
    <p>X</p>
    <p>Z</p>
    <p>Y</p>
    <p>V</p>
    <p>T1 T2</p>
    <p>X</p>
    <p>Succes sful</p>
    <p>insertio n</p>
    <p>W W</p>
  </div>
  <div class="page">
    <p>Cuckoo Hashing  Tables T1 and T2 with hash functions h1 and h2  Store x in one of T1[h1(x)] and T2[h2(x)]</p>
    <p>Y</p>
    <p>U</p>
    <p>Z</p>
    <p>V</p>
    <p>T1 T2</p>
    <p>X</p>
    <p>Failure</p>
    <p>rehash requir</p>
    <p>ed</p>
    <p>Insert(x):  Greedily insert in T1 or T2  If both are occupied then store x in T1</p>
    <p>Repeat in other table with the previous occupant</p>
  </div>
  <div class="page">
    <p>The Cuckoo Graph  Set S  U containing n</p>
    <p>keys  h1, h2 : U ! {1,...,r}</p>
    <p>Bipartite graph with sets of size r</p>
    <p>Edge (h1(x), h2(x)) for every x2S</p>
    <p>S is successfully stored</p>
    <p>Every connected component</p>
    <p>has at most one cycle</p>
    <p>Main theorem:</p>
    <p>If r  (1 + )n and h1,h2 are log(n)-wise independent, then failure probability is (1/n)</p>
  </div>
  <div class="page">
    <p>The Canonical Representation</p>
    <p>Assume that S can be stored using h1 and h2  We force a canonical representation on the</p>
    <p>cuckoo graph  Suffices to consider a single connected component</p>
    <p>Assume that S forms a tree in the cuckoo graph. Typical case</p>
    <p>One location must be empty. The choice of the empty location uniquely determines the location of all elements</p>
    <p>a</p>
    <p>b</p>
    <p>d</p>
    <p>c</p>
    <p>e Rule: h1 (minimal element)</p>
    <p>is empty</p>
  </div>
  <div class="page">
    <p>The Canonical Representation</p>
    <p>Assume that S can be stored using h1 and h2  We force a canonical representation on the</p>
    <p>cuckoo graph  Suffices to consider a single connected component</p>
    <p>Assume that S has one cycle  Two ways to assign</p>
    <p>elements in the cycle  Each choice uniquely</p>
    <p>determines the location of all elements</p>
    <p>a</p>
    <p>b</p>
    <p>d</p>
    <p>c</p>
    <p>e Rule: minimal element in</p>
    <p>cycle lies in T1</p>
  </div>
  <div class="page">
    <p>The Canonical Representation</p>
    <p>Updates efficiently maintain the canonical representation</p>
    <p>Insertions:  New leaf: check if new element is smaller than</p>
    <p>current min  new cycle:</p>
    <p>Same component  Merging two components</p>
    <p>All cases straight forward</p>
    <p>Update time &lt; size of component = expected (small) constant</p>
    <p>Deletions:  Find the new min, split component,  Requires connecting all elements in the component</p>
    <p>with a sorted cyclic list  Memory utilization drops to 25%</p>
    <p>All cases straight forward</p>
  </div>
  <div class="page">
    <p>Rehashing  What if S cannot be stored using h1 and</p>
    <p>h2 ?  Happens with probability (1/n)</p>
    <p>Can we simply pick new functions?  Rear, but very bad worst case performance  Canonical memory implies we need to sample</p>
    <p>all hash functions in advance (theoretical problem)</p>
    <p>Whenever an item is deleted, need to check whether we must role back to previous hash functions</p>
    <p>A bad item which is repeatedly inserted and deleted would cause a rehash every operation!</p>
  </div>
  <div class="page">
    <p>Using a Stash  Whenever an insert fails, put a bad</p>
    <p>item in a secondary data structure  Bad item: smallest item that belongs to a cycle  Secondary data structure must be SHI in itself</p>
    <p>Theorem [KMW08]: Pr[|stash| &gt; s] &lt; n-s</p>
    <p>In practice keeping the stash as a sorted list is probably the best solution  Effectively the query time is constant with (very)</p>
    <p>high probability  In theory the stash could be any SHI with</p>
    <p>constant lookup time  A deterministic hashing scheme, where the</p>
    <p>elements are rehashed whenever the content changes [AN96, HMP01]</p>
  </div>
  <div class="page">
    <p>Conclusions and Problems  Cuckoo hashing is a robust and flexible</p>
    <p>hashing scheme  Easily molded into a history independent data</p>
    <p>structure</p>
    <p>We dont know how to do this for CH with more than 2 hash functions and/or more than 1 element per bucket  Better memory utilization, better performance,</p>
    <p>but..  Expected size of connected component is not</p>
    <p>constant</p>
    <p>Full performance analysis</p>
  </div>
</Presentation>
