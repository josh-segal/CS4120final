<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Summarizing and mining inverse distributions</p>
    <p>on data streams via dynamic inverse sampling</p>
    <p>Graham Cormode cormode@bell-labs.com</p>
    <p>S. Muthukrishnan muthu@cs.rutgers.edu</p>
    <p>Irina Rozenbaum rozenbau@paul.rutgers.edu</p>
    <p>Presented by</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Defining and motivating the Inverse Distribution</p>
    <p>Queries and challenges on the Inverse Distribution</p>
    <p>Dynamic Inverse Sampling to draw sample from Inverse Distribution</p>
    <p>Experimental Study</p>
  </div>
  <div class="page">
    <p>Data Streams &amp; DSMSs  Numerous real world applications generate data streams:</p>
    <p>IP network monitoring  financial transactions  click streams  sensor networks  Telecommunications  text streams at application level, etc.</p>
    <p>Data streams are characterized by massive data volumes of transactions and measurements at high speeds.</p>
    <p>Query processing is difficult on data streams:  We cannot store everything, and must process at line speed.  Exact answers to many questions are impossible without storing</p>
    <p>everything  We must use approximation and randomization with strong guarantees.</p>
    <p>Data Stream Management Systems (DSMS) summarize streams in small space (samples and sketches).</p>
  </div>
  <div class="page">
    <p>DSMS Application: IP Network Monitoring</p>
    <p>Needed for:  network traffic patterns identification  intrusion detection  reports generation, etc.</p>
    <p>IP traffic stream:</p>
    <p>Massive data volumes of transactions and measurements:  over 50 billion flows/day in AT&amp;T backbone.</p>
    <p>Records arrive at a fast rate:  DDoS attacks - up to 600,000 packets/sec</p>
    <p>Query examples:  heavy hitters  change detection  quantiles  Histogram summaries</p>
  </div>
  <div class="page">
    <p>Forward and Inverse Views</p>
    <p>Problem A.</p>
    <p>Which IP address sent the</p>
    <p>most bytes?</p>
    <p>That is , find i such that</p>
    <p>p|ip=i sp is maximum.</p>
    <p>Forward distribution.</p>
    <p>Problem B.</p>
    <p>What is the most common</p>
    <p>volume of traffic sent by an</p>
    <p>IP address?</p>
    <p>That is , find traffic volume W</p>
    <p>s.t |{i|W = p|ip=i sp}| is</p>
    <p>maximum.</p>
    <p>Inverse distribution.</p>
    <p>Consider the IP traffic on a link as packet p representing (ip, sp)</p>
    <p>pairs where ip is a source IP address and sp is a size of the packet.</p>
  </div>
  <div class="page">
    <p>The Inverse Distribution If f is a discrete distribution over a large set X, then inverse</p>
    <p>distribution, f-1(i), gives fraction of items from X with count i.</p>
    <p>Inverse distribution is f-1[0N], f-1(i) = fraction of IP addresses which sent i bytes.</p>
    <p>= |{ x : f(x) = i, i-0}|/|{x : f(x)-0}|</p>
    <p>F-1(i) = cumulative distribution of f-1 = j &gt; i f</p>
    <p>-1(j) [sum of f-1(j) above i]</p>
    <p>Fraction of IP addresses which sent &lt; 1KB of data = 1  F-1(1024)</p>
    <p>Most frequent number of bytes sent = i s.t. f-1(i) is greatest  Median number of bytes sent = i s.t. F-1(i) = 0.5</p>
  </div>
  <div class="page">
    <p>Queries on the Inverse Distribution</p>
    <p>Particular queries proposed in networking map onto f-1,  f-1(1) (number of flows consisting of a single packet) indicative of</p>
    <p>network abnormalities / attack [Levchenko, Paturi, Varghese 04]  Identify evolving attacks through shifts in Inverse Distribution</p>
    <p>[Geiger, Karamcheti, Kedem, Muthukrishnan 05]</p>
    <p>Better understand resource usage:  what is dbn. of customer traffic? How many customers &lt; 1MB</p>
    <p>bandwidth / day? How many use 10  20MB per day?, etc.  Histograms/ quantiles on inverse distribution.</p>
    <p>Track most common usage patterns, for analysis / charging  requires heavy hitters on Inverse distribution</p>
    <p>Inverse distribution captures fundamental features of the distribution, has not been well-studied in data streaming.</p>
  </div>
  <div class="page">
    <p>Forward and Inverse Views on IP streams</p>
    <p>Forward distribution:  Work on f[0U] where f(x)</p>
    <p>is the number of bytes sent by IP address x.</p>
    <p>Each new packet (ip, sp) results in f[ip] f[ip] + sp.</p>
    <p>Problems:  f(i) = ?  which f(i) is the largest?  quantiles of f ?</p>
    <p>Inverse distribution:  Work on f--1[0K]</p>
    <p>Each new packet results in f1[f[ip]]f</p>
    <p>1[f[ip]]  1 and f1[f[ip] + sp]</p>
    <p>f1[f[ip] + sp]+1.</p>
    <p>Problems:  f1(i) = ?  which f1(i) is the largest?  quantiles of f1 ?</p>
    <p>Consider the IP traffic on a link as packet p representing (ip, sp)</p>
    <p>pairs where ip is a source IP address and sp is a size of the packet.</p>
  </div>
  <div class="page">
    <p>Inverse Distribution on Streams: Challenges I</p>
    <p>If we have full space, it is easy to go between forward and inverse distribution.</p>
    <p>But in small space it is much more difficult, and existing methods in small space dont apply.</p>
    <p>Find f(192.168.1.1) in small space, with query give a priori  easy: just count how many times the address is seen.</p>
    <p>Find f-1(1024)  is provably hard (cant find exactly how many IP addresses sent 1KB of data without keeping full space).</p>
    <p>F -1 (x</p>
    <p>)</p>
    <p>f -1 (x</p>
    <p>)</p>
    <p>i1 2 3 4 5</p>
    <p>i</p>
    <p>f( x)</p>
    <p>x</p>
  </div>
  <div class="page">
    <p>Inverse Distribution on Streams: Challenges II, deletions</p>
    <p>How to maintain summary in presence of insertions and deletions?</p>
    <p>Insertions only updates sp &gt; 0</p>
    <p>Stream of arrivals</p>
    <p>Can sample</p>
    <p>original</p>
    <p>distribution</p>
    <p>estimated</p>
    <p>distribution</p>
    <p>? ?</p>
    <p>Insertions and Deletions updates sp can be arbitrary</p>
    <p>original</p>
    <p>distribution</p>
    <p>estimated</p>
    <p>distribution</p>
    <p>Stream of arrivals and departures</p>
    <p>+</p>
    <p>How to summarize?</p>
  </div>
  <div class="page">
    <p>Our Approach: Dynamic Inverse Sampling</p>
    <p>Many queries on the forward distribution can be answered effectively by drawing a sample.  Draw an x so probability of picking x is f(x) / y f(y)</p>
    <p>Similarly, we want to draw a sample from the inverse distribution in the centralized setting.  draw (i,x) s.t. f(x)=i, i0 so probability of picking i is</p>
    <p>f-1(i) / j f -1(j) and probability of picking x is uniform.</p>
    <p>Drawing from forward distribution is easy: just uniformly decide to sample each new item (IP address, size) seen</p>
    <p>Drawing from inverse distribution is more difficult, since probability of drawing (i,1) should be same as (j,1024)</p>
  </div>
  <div class="page">
    <p>Dynamic Inverse Sampling: Outline</p>
    <p>Data structure split into levels</p>
    <p>For each update (ip, sp):</p>
    <p>compute hash l(ip) to a level in the data structure.</p>
    <p>Update counts in level l(ip) with ip and sp</p>
    <p>x count unique x</p>
    <p>M</p>
    <p>Mr</p>
    <p>Mr2</p>
    <p>Mr3</p>
    <p>l(x)</p>
    <p>At query time:  probe the data structure to return (ip,  sp) where ip is sampled</p>
    <p>uniformly from all items with non-zero count</p>
    <p>Use the sample to answer the query on the inverse distribution.</p>
  </div>
  <div class="page">
    <p>Hashing Technique Use hash function with exponentially decreasing distribution: Let h be the hash function and r is an appropriate const &lt; 1</p>
    <p>Pr[h(x) = 0] = (1-r)</p>
    <p>Pr[h(x) = 1] = r (1-r)</p>
    <p>Pr[h(x) = l] = rl(1-r)</p>
    <p>Track the following information as updates are seen:  x: Item with largest hash value seen so far  unique: Is it the only distinct item seen with that hash value?  count: Count of the item x Easy to keep (x, unique, count) up to date for insertions only</p>
    <p>x count unique x</p>
    <p>M</p>
    <p>Mr</p>
    <p>Mr2</p>
    <p>Mr3</p>
    <p>l(x)</p>
    <p>Challenge:</p>
    <p>How to maintain in presence of deletes?</p>
  </div>
  <div class="page">
    <p>Collision Detection: inserts and deletes sum count</p>
    <p>x</p>
    <p>M</p>
    <p>Mr</p>
    <p>Mr2</p>
    <p>Mr3</p>
    <p>l(x)</p>
    <p>coll. detection</p>
    <p>update output</p>
    <p>insert 13</p>
    <p>+1 +1 +1 +1</p>
    <p>insert 13</p>
    <p>+2 +2 +2</p>
    <p>+2</p>
    <p>insert 7</p>
    <p>+3 +3 +1</p>
    <p>+1</p>
    <p>collision</p>
    <p>delete 7 26/2=13</p>
    <p>Level 0</p>
    <p>Simple: Use approximate distinct element estimation routine.</p>
  </div>
  <div class="page">
    <p>Outline of Analysis</p>
    <p>Analysis shows: if theres unique item, its chosen uniformly from set of items with non-zero count.</p>
    <p>Can show whatever the distribution of items, the probability of a unique item at level l is at least constant</p>
    <p>Use properties of hash function:</p>
    <p>only limited, pairwise independence needed (easy to obtain)</p>
    <p>Theorem: With constant probability, for an arbitrary sequence of insertions and deletes, the procedure returns a uniform sample from the inverse distribution with constant probability.</p>
    <p>Repeat the process independently with different hash functions to return larger sample, with high probability.</p>
    <p>Level l</p>
  </div>
  <div class="page">
    <p>Application to Inverse Distribution Estimates</p>
    <p>Overall Procedure:  Obtain the distinct sample from the inverse distribution of size s;  Evaluate the query on the sample and return the result.</p>
    <p>Median number of bytes sent: find median from sample  The most common volume of traffic sent: find the most common</p>
    <p>from sample  What fraction of items sent i bytes: find fraction from the sample</p>
    <p>Example:</p>
    <p>Median is bigger than  and smaller than  the values.</p>
    <p>Answer has some error: not , but (  )</p>
    <p>Theorem: If sample size s = O(1/2 log 1/) then answer from the sample is between (-) and (+) with probability at least 1-.</p>
    <p>Proof follows from application of Hoeffdings bound.</p>
  </div>
  <div class="page">
    <p>Experimental Study</p>
    <p>Data sets:  Large sets of network data drawn from HTTP log files from the 1998 World Cup</p>
    <p>Web Site (several million records each)</p>
    <p>Synthetic data set with 5 million randomly generated distinct items</p>
    <p>Used to build a dynamic transactions set with many insertions and deletions</p>
    <p>(DIS) Dynamic Inverse Sampling algorithms  extract at most one sample from each data structure</p>
    <p>(GDIS) Greedy version of Dynamic Inverse Sampling  greedily process every level, extract as many samples as possible from each data structure</p>
    <p>(Distinct) Distinct Sampling (Gibbons VLDB 2001) draws a sample based on a coin-tossing procedure using a pairwise-independent hash function on item values</p>
  </div>
  <div class="page">
    <p>Sample Size vs. Fraction of Deletions</p>
    <p>Desired sample size is 1000.</p>
    <p>data: synthetic data size: 5000000</p>
    <p>fraction of deletions (%)</p>
    <p>a ct</p>
    <p>iu a l sa</p>
    <p>m p</p>
    <p>le s</p>
    <p>iz e</p>
    <p>Distinct</p>
    <p>DIS</p>
  </div>
  <div class="page">
    <p>Returned Sample Size</p>
    <p>data: WorldCup98 data size: 2266137</p>
    <p>desired sample size</p>
    <p>a ct</p>
    <p>u a</p>
    <p>l sa</p>
    <p>m p</p>
    <p>le s</p>
    <p>iz e</p>
    <p>Distinct</p>
    <p>DIS</p>
    <p>GDIS</p>
    <p>Experiments were run on the client ID attribute of the HTTP log data. 50% of the inserted records were deleted.</p>
  </div>
  <div class="page">
    <p>Sample Quality</p>
    <p>Inverse range query: Compute the fraction of records with size greater than i=1024 and compare it to the exact value computed offline</p>
    <p>Inverse quantile query: Estimate the median of the inverse distribution using the sample and measure how far was the position of the returned item i from 0.5.</p>
    <p>data: WorldCup98 data size: 4849706</p>
    <p>sample size</p>
    <p>q u</p>
    <p>al it</p>
    <p>y e</p>
    <p>rr o r</p>
    <p>DIS</p>
    <p>GDIS</p>
    <p>Distinct</p>
    <p>data: WorldCup98 data size: 2266137</p>
    <p>sample size</p>
    <p>q u</p>
    <p>a li</p>
    <p>ty e</p>
    <p>rr o</p>
    <p>r</p>
    <p>DIS</p>
    <p>Distinct</p>
    <p>GDIS</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>Distinct sampling under insert only:  Gibbons: Distinct Sampling, VLDB 2002.  Datar and Muthukrishnan: Rarity and similarity, ESA 2002.</p>
    <p>Distinct sampling under deletes also:  Frahling, Indyk, Sohler: Dynamic geometric streams, STOC</p>
    <p>over Continuous Update Streams, SIGMOD 2003.</p>
    <p>Inverse distributions:  Has recently informally appeared in networking papers.</p>
  </div>
  <div class="page">
    <p>Conclusions  We have formalized Inverse Distributions on data streams and</p>
    <p>introduced Dynamic Inverse Sampling method that draws uniform samples from the inverse distribution in presence of insertions and deletions.</p>
    <p>With a sample of size O(1/2), can answer many queries on the inverse distribution (including point and range queries, heavy hitters, quantiles) up to additive approximation of .</p>
    <p>Experimental study shows that proposed methods can work at high rates and answer queries with high accuracy</p>
    <p>Future work:  Incorporate in data stream systems  Can we also sample from forward dbn under inserts and deletes?</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Future Work</p>
    <p>Incorporate Inverse Distribution into Data Stream Management System</p>
    <p>Development of sampling techniques from forward distribution under inserts and deletes</p>
  </div>
  <div class="page">
    <p>DIS (example of insertions) We consider the following example sequence of insertions of items:</p>
    <p>Input: 4, 7, 4, 1, 3, 4, 2, 6, 4, 2</p>
    <p>Suppose these hash to levels in an instance of our data structure as follows:</p>
    <p>x l(x)</p>
    <p>Time Level 1 Level 2 Level 3</p>
    <p>Step item count unique item count unique item count unique</p>
    <p>(count,item)</p>
    <p>(1,4)</p>
    <p>(1,4)(2,7)</p>
    <p>(1,4)(2,7)</p>
    <p>(2,7)</p>
    <p>(1,2)</p>
    <p>(1,2)</p>
    <p>(1,2)</p>
    <p>(2,2)</p>
  </div>
  <div class="page">
    <p>Inverse Distribution on Streams: Challenges II, deletions</p>
    <p>Insertions only updates sp &gt; 0</p>
    <p>Stream of arrivals</p>
    <p>Can sample</p>
    <p>? ?</p>
    <p>Insertions and Deletions updates sp can be arbitrary</p>
    <p>original distribution</p>
    <p>estimated distribution</p>
    <p>original distribution</p>
    <p>estimated distribution</p>
    <p>Maintain summary in presence of insertions and deletions?</p>
    <p>How to summarize?</p>
    <p>Stream of arrivals and departures</p>
    <p>+</p>
  </div>
  <div class="page">
    <p>Sampling Insight Each distinct item x contributes to one pair (i,x)</p>
    <p>Need to sample uniformly from these pairs.</p>
    <p>Basic insight: sample uniformly from the items x and count how many times x is seen to give (i,x) pair that has correct i and is uniform.</p>
    <p>How to pick x uniformly before seeing any x?</p>
    <p>Use a randomly chosen hash function on each x to decide whether to pick it (and reset count).</p>
    <p>f( x)</p>
    <p>x</p>
    <p>f -1 (x</p>
    <p>)</p>
    <p>i1 2 3 4 5</p>
  </div>
  <div class="page">
    <p>Hashing Analysis Theorem: If unique is true, then x is picked uniformly.</p>
    <p>Probability of unique being true is at least a constant.</p>
    <p>(For right value of r, unique is almost always true in practice)</p>
    <p>Proof outline: Uniformity follows so long as hash function h is at least pairwise independent.</p>
    <p>Hard part is showing that unique is true with constant prob.</p>
    <p>Let D is number of distinct items. Fix l so 1/r  Drl  1/r2.  In expectation, Drl items hash to level l or higher  Variance is also bounded by Drl, and we ensure 1/r2  3/2.  Analyzing, can show that there is constant probability that there are either</p>
  </div>
  <div class="page">
    <p>Collision Detection: inserts and deletes sum count</p>
    <p>x</p>
    <p>M</p>
    <p>Mr</p>
    <p>Mr2</p>
    <p>Mr3</p>
    <p>l(x)</p>
    <p>coll. detection</p>
    <p>update output</p>
    <p>insert 13</p>
    <p>+1 +1 +1</p>
    <p>+1</p>
    <p>insert 13</p>
    <p>+2 +2</p>
    <p>+2</p>
    <p>+2</p>
    <p>insert 7</p>
    <p>+3 +3</p>
    <p>+1</p>
    <p>+1</p>
    <p>collision</p>
    <p>delete 7 26/2=13</p>
    <p>Level 0</p>
    <p>Simple: Use approximate distinct element estimation routine.</p>
  </div>
  <div class="page">
    <p>Collision Detection: inserts and deletes sum count</p>
    <p>x</p>
    <p>M</p>
    <p>Mr</p>
    <p>Mr2</p>
    <p>Mr3</p>
    <p>l(x)</p>
    <p>coll. detection</p>
    <p>update output</p>
    <p>insert 13</p>
    <p>+1 +1 +1 +1</p>
    <p>insert 13</p>
    <p>+2 +2 +2</p>
    <p>+2</p>
    <p>insert 7</p>
    <p>+3 +3 +1</p>
    <p>+1</p>
    <p>collision</p>
    <p>delete 7 26/2=13</p>
    <p>Level 0</p>
    <p>Simple: Use approximate distinct element estimation routine.</p>
  </div>
  <div class="page">
    <p>Hashing Analysis If only one item at level l, then unique is true</p>
    <p>If two items at level l or higher, can go deeper into the analysis and show that (assuming there are two items) there is constant probability that they are both at same level.</p>
    <p>If not at same level, then unique is true, and we recover a uniform sample.</p>
    <p>Probability of failure is p = r(3+r)/(2(1+r)).  Number of levels is O(log N / log 1/r)  Need 1/r &gt; 1 so this is bounded, and</p>
    <p>End up choosing r = p(2/3), so p is &lt; 1</p>
    <p>Level l</p>
  </div>
  <div class="page">
    <p>Collision Detection (contd)  Deterministic (previous slide):</p>
    <p>Suppose |X| = m = 2b so each x X is represented as a b bit integer. We can keep 2b counters c[j,k] indexed by j=1b and k {0,1}.</p>
    <p>Probabilistic:  Draw t hash functions, g1.gt, which map items uniformly onto {0,1},</p>
    <p>and a set of t2 counters c[j,k].  Heuristic:</p>
    <p>Compute q new hash functions gj[x] mapping items x onto 0m, and take the summation of g(x) as sumg[j, l(x)].</p>
    <p>on insert on delete collision test space, time</p>
    <p>Deterministic c[j,bit(j,x)]++ c[j,bit(j,x)]-- for any j, c[j,0]0 &amp; c[j,1]0</p>
    <p>O(b) O(b)</p>
    <p>Probabilistic c[j,gj(x)]++ c[j,gj(x)]-- same O(t) O(t)</p>
    <p>Heuristic sumg[j,l(x)]+g(x) sumg[j,l(x)]+g(x) for any j, sumg[j, l(x)]  gj(x)*count[l]</p>
    <p>O(q) O(q)</p>
  </div>
  <div class="page">
    <p>Sample Size This process either draws a single pair (i,x), or may not return anything.</p>
    <p>In order to get a larger sample with high probability, repeat the same process in parallel over the input with different hash functions h1  hs to draw up to s samples (ij,xj)</p>
    <p>Let e = p(2 log (1/d)/s). By Chernoff bounds, if we keep S = (1+2e) s/(1  p) copies of the data structure, then we recover at least s samples with probability at least 1-d</p>
    <p>Repetitions are a little slow  for better performance, keeping the s items with the s smallest hash values is almost uniform, and faster to maintain.</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Output process: At each level:</p>
    <p>If level is not empty, check whether there was a collision at the level</p>
    <p>If no collision, extract item from the level</p>
  </div>
  <div class="page">
    <p>Experimental Study</p>
  </div>
  <div class="page">
    <p>Key features of existing sampling methods</p>
    <p>Algorithms Type Method Deletions Random Reservoir Sampling</p>
    <p>Backing Sample</p>
    <p>Weighted Sampling</p>
    <p>Concise Sampling</p>
    <p>Count Sampling</p>
    <p>Fwd</p>
    <p>Fwd</p>
    <p>Fwd</p>
    <p>Fwd</p>
    <p>Fwd</p>
    <p>WoR</p>
    <p>WoR</p>
    <p>WR</p>
    <p>CF</p>
    <p>CF</p>
    <p>No</p>
    <p>Few</p>
    <p>No</p>
    <p>No</p>
    <p>Few</p>
    <p>Full</p>
    <p>Full</p>
    <p>Full</p>
    <p>Full</p>
    <p>Full</p>
    <p>Minwise-hashing</p>
    <p>Distinct sampling</p>
    <p>Dynamic Inverse Sampling</p>
    <p>Inv</p>
    <p>Inv</p>
    <p>Inv</p>
    <p>WR</p>
    <p>CF</p>
    <p>CF,WR</p>
    <p>No</p>
    <p>Few</p>
    <p>Yes</p>
    <p>Pairwise</p>
    <p>Pairwise</p>
  </div>
</Presentation>
