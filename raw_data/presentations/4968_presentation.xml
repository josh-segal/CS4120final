<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Hydra: Automatically Configuring Algorithms</p>
    <p>for Portfolio-Based Selection</p>
    <p>Lin Xu, Holger H. Hoos, Kevin Leyton-Brown</p>
    <p>Department of Computer Science University of British Columbia</p>
  </div>
  <div class="page">
    <p>SATzilla [Xu, Hutter, Hoos, Leyton-Brown, 2007; 2008]</p>
    <p>portfolio-based algorithm selection</p>
    <p>SATenstein [KhudaBukhsh, Xu, Hoos, Leyton-Brown, 2009]</p>
    <p>algorithm design via automatic configuration</p>
    <p>Two automated algorithm design ideas</p>
  </div>
  <div class="page">
    <p>Exploit per-instance variation between solvers using learned runtime models  practical: e.g., won 10 medals in</p>
    <p>time rather than human design effort</p>
    <p>Key drawback:  requires a set of strong, relatively</p>
    <p>uncorrelated candidate solvers  cant be applied in domains for which</p>
    <p>such solvers do not exist</p>
    <p>SATzilla [Xu, Hutter, Hoos, Leyton-Brown, 2007; 2008]</p>
    <p>portfolio-based algorithm selection</p>
    <p>Two automated algorithm design ideas</p>
    <p>Some particularly related work: [Rice, 1976]; [Leyton-Brown, Nudelman &amp; Shoham, 2003; 2009]; [Guerri &amp; Milano, 2004]; [Nudelman, Leyton-Brown, Shoham &amp; Hoos, 2004]</p>
  </div>
  <div class="page">
    <p>Instead of manually exploring a design space, build a highly-parameterized algorithm and then configure it automatically</p>
    <p>Can find powerful, novel designs  matched or outperformed existing</p>
    <p>SLS algorithms on six SAT domains  But: only produces single algorithms</p>
    <p>designed to perform well on the entire training set</p>
    <p>SATenstein [KhudaBukhsh, Xu, Hoos, Leyton-Brown, 2009]</p>
    <p>algorithm design via automatic configuration</p>
    <p>Two automated algorithm design ideas</p>
    <p>Some particularly related work: [Gratch &amp; Dejong, 1992]; [Fukunaga, 2002]; [Balaprakash, Birattari &amp; Stutzle, 2007]; [Hutter, Babic, Hoos &amp; Hu, 2007]; [Ansotegui, Sellmann &amp; Tierney, 2009]; [Hutter, Hoos, Stutzle &amp; Leyton-Brown, 2009]</p>
  </div>
  <div class="page">
    <p>Hydra automatic portfolio synthesis</p>
    <p>Two automated algorithm design ideas</p>
    <p>Starting from a single parameterized algorithm, automatically find a set of uncorrelated configurations that can be used to build a strong portfolio.</p>
  </div>
  <div class="page">
    <p>Plan of This Talk</p>
    <p>Background  SATzilla: Portfolio-Based Algorithm Selection  SATenstein: Algorithm Configuration as Design</p>
    <p>Portfolio Synthesis  Related Work  Hydra</p>
    <p>Experimental Results</p>
    <p>Conclusions and Future Work Xu, Hoos, Leyton-Brown. Hydra: Automatically Configuring Algorithms for Portfolio-Based Selection</p>
  </div>
  <div class="page">
    <p>Given:  training set of instances  performance metric  candidate solvers  portfolio builder</p>
    <p>(incl. instance features)</p>
    <p>Training:  collect performance data  portfolio builder learns</p>
    <p>predictive models</p>
    <p>At Runtime:  predict performance  select solver</p>
    <p>Metric</p>
    <p>Portfolio Builder</p>
    <p>Training Set</p>
    <p>Novel Instance Portfolio-Based</p>
    <p>Algorithm Selector</p>
    <p>Candidate Solvers</p>
    <p>Selected Solver</p>
    <p>SATzilla: Portfolio-Based Algorithm Selection [Xu, Hutter, Hoos, Leyton-Brown, 2007; 2008]</p>
  </div>
  <div class="page">
    <p>SATenstein: Automated Algorithm Design [KhudaBukhsh, Xu, Hoos, Leyton-Brown, 2009]</p>
    <p>Designer creates highlyparameterized algorithm from existing components</p>
    <p>Given:  training set of instances  performance metric  parameterized algorithm  algorithm configurator</p>
    <p>Configure algorithm:  run configurator on training</p>
    <p>instances  output is a configuration that</p>
    <p>optimizes metric</p>
    <p>Parameterized Algorithm</p>
    <p>Existing Algorithm Components</p>
    <p>Domain Expert</p>
  </div>
  <div class="page">
    <p>Algorithm Configurator</p>
    <p>Metric</p>
    <p>New Configuration</p>
    <p>Instance set</p>
    <p>SATenstein: Automated Algorithm Design</p>
    <p>Designer creates highlyparameterized algorithm from existing components</p>
    <p>Given:  training set of instances  performance metric  parameterized algorithm  algorithm configurator</p>
    <p>Configure algorithm:  run configurator on training</p>
    <p>instances  output is a configuration that</p>
    <p>optimizes metric</p>
    <p>Parameterized Algorithm</p>
  </div>
  <div class="page">
    <p>Plan of This Talk</p>
    <p>Background  SATzilla: Portfolio-Based Algorithm Selection  SATenstein: Algorithm Configuration as Design</p>
    <p>Portfolio Synthesis  Related Work  Hydra</p>
    <p>Experimental Results</p>
    <p>Conclusions and Future Work Xu, Hoos, Leyton-Brown. Hydra: Automatically Configuring Algorithms for Portfolio-Based Selection</p>
  </div>
  <div class="page">
    <p>Related Work  Algorithm synthesis; portfolios and online algorithm selection</p>
    <p>[Minton 1993]; [Huberman, Lukose &amp; Hogg 1997]; [Howe et al, 1999]; [Gomes &amp; Selman 2001]; [Carchrae &amp; Beck 2005]; [Gagliolo &amp; Schmidhuber 2006]; [Streeter, Golovin &amp; Smith 2007]; [Roberts &amp; Howe, 2007]; [Gaspero &amp; Schaerf 2007]; [Monette, Deville &amp; van Hentenryck 2009]</p>
    <p>Two proposals for synthesis of selection-based portfolios: 1. Boosting as a Metaphor for Algorithm Design [L-B et al., 2003; 2009] 2. Stochastic Offline Programming [Malitsky &amp; Sellmann, 2009]</p>
    <p>partition instances into k clusters based on features  find best-performing algorithm for each cluster  assumes that all algorithms repeatedly (1) sample from a distribution over</p>
    <p>heuristics; (2) use the sampled heuristic for one search step  best-performing algorithms identified using a custom optimization method  our goal is to construct an entirely general method for portfolio synthesis</p>
    <p>CP-Hydra [OMahony, Hebrard, Holland, Nugent, &amp; OSullivan, 2008]  selection-based portfolio for constraint programming</p>
  </div>
  <div class="page">
    <p>Core idea  re-weight instance distribution to emphasize problems on</p>
    <p>which an existing portfolio P performs poorly</p>
    <p>Interpretation as an automatic procedure:  generate a new distribution D that is hard for P  find a new solver maximizing average performance on D</p>
    <p>We intended to implement this procedure. But:  discovered examples in which the algorithm with best</p>
    <p>average performance does not improve the portfolio  thus, the portfolio synthesis procedure can stagnate, even</p>
    <p>when other, helpful algorithms exist</p>
    <p>Boosting as a Metaphor for Algorithm Design [Leyton-Brown, Nudelman, Andrew, McFadden, Shoham, 2003]; [Leyton-Brown, Nudelman, Shoham, 2009]</p>
  </div>
  <div class="page">
    <p>Hydra: Dynamic Performance Metric</p>
    <p>Avoid stagnation via a dynamic performance metric:  return performance of s when s outperforms P  return performance of P otherwise</p>
    <p>Intuitively: s is scored for its marginal contribution to P</p>
    <p>This metric is given to an off-the-shelf configurator, which optimizes it to find a new configuration s*</p>
    <p>Thus, we retain the same core idea as boosting  build a new algorithm that explicitly aims to improve upon an existing</p>
    <p>portfolio</p>
    <p>Contrast with Stochastic Offline Programming:  algorithms target sets of instances having very different features  these feature differences can be irrelevant to algorithm performance</p>
  </div>
  <div class="page">
    <p>Hydra Procedure: Iteration 1</p>
    <p>Algorithm Configurator</p>
    <p>Metric Training Set</p>
    <p>Portfolio-Based Algorithm Selector</p>
    <p>Candidate Solver Set</p>
    <p>Candidate Solver</p>
    <p>Parameterized Algorithm</p>
    <p>Portfolio Builder</p>
  </div>
  <div class="page">
    <p>Hydra Procedure: Iteration 2</p>
    <p>Algorithm Configurator</p>
    <p>Metric Training Set</p>
    <p>Portfolio-Based Algorithm Selector</p>
    <p>Candidate Solver Set</p>
    <p>Candidate Solver</p>
    <p>Parameterized Algorithm</p>
    <p>Portfolio Builder</p>
  </div>
  <div class="page">
    <p>Hydra Procedure: Iteration 3</p>
    <p>Algorithm Configurator</p>
    <p>Metric Training Set</p>
    <p>Portfolio-Based Algorithm Selector</p>
    <p>Candidate Solver Set</p>
    <p>Candidate Solver</p>
    <p>Parameterized Algorithm</p>
    <p>Portfolio Builder</p>
  </div>
  <div class="page">
    <p>Output:</p>
    <p>Hydra Procedure: After Termination</p>
    <p>Portfolio-Based Algorithm Selector</p>
    <p>Novel Instance</p>
    <p>Selected Solver</p>
  </div>
  <div class="page">
    <p>Plan of This Talk</p>
    <p>Background  SATzilla: Portfolio-Based Algorithm Selection  SATenstein: Algorithm Configuration as Design</p>
    <p>Portfolio Synthesis  Related Work  Hydra</p>
    <p>Experimental Results</p>
    <p>Conclusions and Future Work Xu, Hoos, Leyton-Brown. Hydra: Automatically Configuring Algorithms for Portfolio-Based Selection</p>
  </div>
  <div class="page">
    <p>Problem Domain</p>
    <p>Even though Hydra is most useful in other domains, we evaluated it on SAT.</p>
    <p>High bar for comparison  strong state-of-the-art solvers  portfolio-based solvers already successful  to be able to argue that Hydra does well,</p>
    <p>we want to compare to a strong portfolio</p>
    <p>Pragmatic benefits  a wide variety of interesting datasets  existing instance features  SATenstein is a suitable configuration target</p>
  </div>
  <div class="page">
    <p>Experimental Setup: Hydras Inputs</p>
    <p>Portfolio Builder: SATzilla framework [Xu, Hutter, Hoos, Leyton-Brown, 2008]</p>
    <p>Parameterized Solver: SATenstein-LS [KhudaBukhsh, Xu, Hoos, Leyton-Brown, 2009]</p>
    <p>Algorithm Configurator: FocusedILS 2.3 [Hutter, Hoos, Leyton-Brown, 2009]</p>
    <p>Performance Metric: Penalized average runtime (PAR)</p>
    <p>Instance Sets:  2 from SATenstein paper</p>
    <p>[KhudaBukhsh, Xu, Hoos, Leyton-Brown, 2009]</p>
    <p>2 from previous SAT competitions</p>
  </div>
  <div class="page">
    <p>Experimental Setup: Challengers</p>
    <p>Individual state-of-the-art solvers  11 manually-crafted SLS solvers</p>
    <p>all 7 SLS winners of any SAT competition 2002  2007  4 other prominent solvers</p>
    <p>6 SATenstein solvers</p>
    <p>Also considered portfolios of challengers  used same portfolio builder (SATenstein)</p>
  </div>
  <div class="page">
    <p>Solver RAND HAND BM INDU</p>
    <p>Best Challenger (of 17) 1128.63 2960.39 224.53 11.89</p>
    <p>Portfolio of 11 Challengers 897.37 2670.22 54.04 135.84</p>
    <p>Portfolio of 17 Challengers 813.72 2597.71 3.06* 7.74*</p>
    <p>Hydra (7 iterations) 631.35 2495.06 3.06 7.77</p>
    <p>Performance Summary</p>
    <p>* Statistically insignificant performance difference (sign rank test). Hydras performance was significantly better in all other pairings.</p>
  </div>
  <div class="page">
    <p>Performance Progress, RAND</p>
  </div>
  <div class="page">
    <p>Selection Percentages After 7 Iterations, RAND</p>
  </div>
  <div class="page">
    <p>Improvement After 7 Iterations, RAND</p>
  </div>
  <div class="page">
    <p>Thank You!</p>
    <p>Conclusions  Hydra: an automatic design approach combining</p>
    <p>portfolio-based algorithm selection (here: SATzilla)  automated algorithm configuration (here: SATenstein)</p>
    <p>Completely automated  Algorithm/configurator/portfolio-builder agnostic</p>
    <p>Most useful in domains where few strong solvers exist  Nevertheless met or exceeded state-of-the-art</p>
    <p>performance on SLS for SAT in 4 domains</p>
  </div>
</Presentation>
