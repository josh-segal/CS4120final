<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>DSybil: Optimal Sybil-ResistanceDSybil: Optimal Sybil-Resistance for Recommendation Systemsfor Recommendation Systems</p>
    <p>Haifeng Yu National University of Singapore</p>
    <p>Chenwei Shi National University of Singapore</p>
    <p>Michael Kaminsky Intel Research Pittsburgh</p>
    <p>Phillip B. Gibbons Intel Research Pittsburgh</p>
    <p>Feng Xiao National University of Singapore</p>
  </div>
  <div class="page">
    <p>Attacks on Recommendation SystemsAttacks on Recommendation Systems</p>
    <p>Netflix, Amazon, Razor, Digg, YouTube,</p>
    <p>Attacker may cast misleading votes</p>
    <p>To be more effective  Bribe other users</p>
    <p>Compromise other users</p>
    <p>Ultimate form: Sybil attack</p>
    <p>Haifeng Yu, National University of Singapore 2</p>
  </div>
  <div class="page">
    <p>Haifeng Yu, National University of Singapore 3</p>
    <p>Sybil AttackSybil Attack</p>
    <p>launch sybil attack</p>
    <p>malicious</p>
    <p>Post at random intervals to make it look like real people</p>
    <p>Supports multiple random proxies to make posts look like they came from visitors across the world</p>
    <p>Multithreaded comment blaster with account rotation</p>
    <p>honest automated sybil attack for $147</p>
  </div>
  <div class="page">
    <p>Haifeng Yu, National University of Singapore 4</p>
    <p>Background: Defending Against Sybil AttackBackground: Defending Against Sybil Attack</p>
    <p>Tie identities to human beings based on credentials (e.g., passport)  Privacy concerns, etc.</p>
    <p>Resource challenges  Vulnerable to attacks from botnets</p>
    <p>Social-network-based defense  SybilGuard [SIGCOMM06], SybilLimit [Oakland08], SybilInfer</p>
    <p>[NDSS09], SumUp [NSDI09]</p>
    <p>Better guarantees</p>
    <p>Sybil defense widely considered challenging: &gt;1000 papers acknowledging sybil attack, most without having a solution</p>
  </div>
  <div class="page">
    <p>Byzantine consensus</p>
    <p>n/3</p>
    <p>DHT n/4</p>
    <p>Recommendation systems</p>
    <p>n/500</p>
    <p>Rec Systems Are More VulnerableRec Systems Are More Vulnerable</p>
    <p>On an avg Digg object, only 1 out of every 500 honest users vote</p>
    <p>n/500 sybil identities are sufficient to outvote the honest voters</p>
    <p>Haifeng Yu, National University of Singapore 5</p>
    <p># sybil identities we can tolerate</p>
    <p>(n identities total)</p>
  </div>
  <div class="page">
    <p>Social-network-based Defenses Not Social-network-based Defenses Not Sufficiently Strong For Rec SystemsSufficiently Strong For Rec Systems</p>
    <p>Lower bound on all social-network-based approaches  Applicable to SybilGuard, SybilLimit, SybilInfer,</p>
    <p>SumUp, etc</p>
    <p>Compromising a degree-10 node creates 10 sybil identities</p>
    <p>To create n/500 sybil identities: Compromise 1 node out of every 5000 honest nodes is sufficient</p>
    <p>Haifeng Yu, National University of Singapore 6</p>
  </div>
  <div class="page">
    <p>Alternative: Leverage History and TrustAlternative: Leverage History and Trust</p>
    <p>Ancient idea: Adjust trust to an identity based on its historical behavior</p>
    <p>Numerous heuristics proposed -- target a few fixed attack strategies  No guarantees beyond the few strategies targeted</p>
    <p>Attacker is intelligent and will adapt  arms race</p>
    <p>Haifeng Yu, National University of Singapore 7</p>
  </div>
  <div class="page">
    <p>Our ResultsOur Results  DSybil: A novel defense mechanism</p>
    <p>Based on feedback and trust</p>
    <p>Loss (# of bad recommendations) is provably</p>
    <p>even under worst-case attack</p>
    <p>We prove that DSybils loss is optimal</p>
    <p>Experimental results (from 1-year Digg trace):  High-quality recommendation under potential sybil</p>
    <p>attack (with optimal strategy) from million-node botnet</p>
    <p>Haifeng Yu, National University of Singapore 8</p>
    <p>)log( MDO</p>
    <p>D : Dimension of the objects (&lt; 10 in Digg)</p>
    <p>M : Max # of sybil identities voting on each obj</p>
  </div>
  <div class="page">
    <p>OutlineOutline</p>
    <p>Background and our contribution</p>
    <p>Trust-based approaches  The obvious, the subtle, and the challenge</p>
    <p>Main component of DSybil: DSybils recommendation algorithm</p>
    <p>Experimental results</p>
    <p>Haifeng Yu, National University of Singapore 9</p>
  </div>
  <div class="page">
    <p>Subtle Aspects of Using TrustSubtle Aspects of Using Trust</p>
    <p>this additional vote is non-helpful</p>
    <p>Sybil identities may gain trust for free</p>
    <p>Determine the contribution amount by voting order does not work  see paper</p>
    <p>Haifeng Yu, National University of Singapore 10</p>
    <p>A good object</p>
    <p>my vote: this obj is good!</p>
    <p>sybil</p>
    <p>identity</p>
    <p>gain trust for</p>
    <p>free</p>
  </div>
  <div class="page">
    <p>Subtle Aspects of Using TrustSubtle Aspects of Using Trust</p>
    <p>Trial period of 5 votes not effective</p>
    <p>Cast 5 correct votes and then cheat</p>
    <p>about negative votes? ..</p>
    <p>Haifeng Yu, National University of Singapore 11</p>
  </div>
  <div class="page">
    <p>The Central ChallengeThe Central Challenge</p>
    <p>Numerous design choices -- fundamental tension between  Giving trust to honest identities</p>
    <p>Not giving trust to sybil identities casting correct votes (who may cause damage later)</p>
    <p>Impossible to explore all design alternatives  Our approach: Directly design an optimal algorithm</p>
    <p>Needs to strike the optimal balance</p>
    <p>Haifeng Yu, National University of Singapore 12</p>
  </div>
  <div class="page">
    <p>DSybils Key Insights DSybils Key Insights</p>
    <p>Key #1: Leverage typical</p>
    <p>voting behavior of</p>
    <p>honest users  Heavy-tail distribution</p>
    <p>Exist very active users</p>
    <p>who cast many votes</p>
    <p>Key #2: If user is already getting enough help, then do not give out more trust  Enables us to strike an optimal balance</p>
    <p>Haifeng Yu, National University of Singapore 13</p>
    <p># votes cast (on various objs)</p>
    <p>% o</p>
    <p>f u</p>
    <p>se rs</p>
    <p>ca</p>
    <p>st in</p>
    <p>g x</p>
    <p>v o</p>
    <p>te s</p>
    <p>all log-scale</p>
  </div>
  <div class="page">
    <p>Objects to be recommended are either good or bad (e.g., Digg)</p>
    <p>DSybil is personalized  Each user may have different subjective opinions</p>
    <p>Different users may get different recommendations</p>
    <p>From now on, always with respect to a user Alice</p>
    <p>Run by either Alice or a central server</p>
    <p>Haifeng Yu, National University of Singapore 14</p>
    <p>System Model and Attack ModelSystem Model and Attack Model</p>
  </div>
  <div class="page">
    <p>Haifeng Yu, National University of Singapore 15</p>
    <p>Each round has a pool of objects  DSybil recommends one object for Alice to consume</p>
    <p>Alice provide feedbacks after consumption</p>
    <p>DSybil adjust trust based on feedback</p>
    <p>See paper for generalizations</p>
    <p>System Model and Attack ModelSystem Model and Attack Model</p>
    <p>DSybil does not know which are good</p>
  </div>
  <div class="page">
    <p>Haifeng Yu, National University of Singapore 16</p>
    <p>Other identities have cast votes  DSybil only use positive votes</p>
    <p>We prove that using negative votes will not help</p>
    <p>Each identity cast at most one vote/object</p>
    <p>At most M (e.g. 1010) sybil identities voting on each object</p>
    <p>E F</p>
    <p>G H</p>
    <p>H</p>
    <p>System Model and Attack ModelSystem Model and Attack Model</p>
  </div>
  <div class="page">
    <p>DSybil Rec Algorithm: Classifying ObjectsDSybil Rec Algorithm: Classifying Objects</p>
    <p>Haifeng Yu, National University of Singapore 17</p>
    <p>E: 0.2</p>
    <p>total : 0.4</p>
    <p>F : 0.2</p>
    <p>total : 0.2</p>
    <p>G: 0.2</p>
    <p>total : 0.2</p>
    <p>H: 0.2</p>
    <p>total : 0.2</p>
    <p>H: 0.2</p>
    <p>Reminder: Trust is always with respect to Alice (how much Alice trusts the given identity)</p>
    <p>Each identity starts with initial trust 0.2 -- Fix later</p>
    <p>An object is overwhelming if total trust  C  C = 1.0</p>
  </div>
  <div class="page">
    <p>Rounds without Overwhelming ObjectsRounds without Overwhelming Objects</p>
    <p>Haifeng Yu, National University of Singapore 18</p>
    <p>E: 0.2</p>
    <p>total : 0.4</p>
    <p>F : 0.2</p>
    <p>total : 0.2</p>
    <p>G: 0.2</p>
    <p>total : 0.2</p>
    <p>H: 0.2</p>
    <p>total : 0.2</p>
    <p>H: 0.2</p>
    <p>trust to G: 0.2  0.2</p>
    <p>trust to E: 0.2  0.2</p>
    <p>trust to F: 0.2  0.2</p>
    <p>If obj good, multiply trust of voters by  &gt; 1</p>
    <p>Additive increase would result in linear (instead of logarithmic) loss</p>
    <p>Recommend obj with largest total trust would result in linear (instead of logarithmic) loss</p>
  </div>
  <div class="page">
    <p>Defining Guides and DimensionDefining Guides and Dimension</p>
    <p>Haifeng Yu, National University of Singapore 19</p>
    <p>Guides: Honest users with same/similar opinion with Alice  Never/seldom votes for bad objects</p>
    <p>Dimension: # of guides needed to cover large fraction (e.g., 60%) of the good objects -- Called critical guides</p>
    <p>X X Y Z</p>
    <p>W</p>
    <p>Dimension = 2; Critical guides = {X, Y} or {X, W}</p>
    <p>DSybil does not know who are the guides (critical guides) or what the dimension is</p>
  </div>
  <div class="page">
    <p>Key #1: Leverage Small DimensionKey #1: Leverage Small Dimension</p>
    <p>Haifeng Yu, National University of Singapore 20</p>
    <p>Dimension is typically small in practice  results later</p>
    <p>Small dimension  Will encounter critical guides frequently when picking random objects  Trust to critical guides quickly grow to C</p>
    <p>This will result in overwhelming objects</p>
  </div>
  <div class="page">
    <p>Rounds with Overwhelming ObjectsRounds with Overwhelming Objects</p>
    <p>If obj good, no additional trust given out</p>
    <p>Haifeng Yu, National University of Singapore 21</p>
    <p>E: 1.0</p>
    <p>total : 1.2</p>
    <p>H: 0.2 G: 0.2</p>
    <p>total : 0.4</p>
    <p>F : 1.0</p>
    <p>total : 1.0</p>
    <p>H: 0.2</p>
    <p>trust to E: 1.0  1.0</p>
    <p>trust to H: 0.2  0.2</p>
  </div>
  <div class="page">
    <p>Key #2: Identify Whether Help is Key #2: Identify Whether Help is SufficientSufficient</p>
    <p>Consumes good overwhelming object = Alice already has sufficient help</p>
    <p>Thus do not give out additional trust  Prevent sybil identities from getting trust for free</p>
    <p>May hurt honest identities (But remember this is optimal)</p>
    <p>Haifeng Yu, National University of Singapore 22</p>
  </div>
  <div class="page">
    <p>Omitted DetailsOmitted Details</p>
    <p>No free initial trust given out when Alice is getting sufficient help</p>
    <p>Proof for loss even under worstcase attack</p>
    <p>Optimality</p>
    <p>Alternative designs/tweaks  Most will break optimality</p>
    <p>Haifeng Yu, National University of Singapore 23</p>
    <p>)log( MDO</p>
  </div>
  <div class="page">
    <p>Results on DimensionResults on Dimension  One-year Digg dataset with half-million users</p>
    <p>Pessimistically assuming guides are only 2% of the honest users -see paper for other settings</p>
    <p>To cover 60% of good objs, need only 3 guides</p>
    <p>Robustness:  Remove the previous 3 guides  5 guides to cover 60%</p>
    <p>Remove top 100 heaviest voters  5 guides needed to cover 60%</p>
    <p>See paper for more</p>
    <p>Relates to heavy-tail distribution of votes cast by individual users  see paper  Exist very active users who cast many votes</p>
    <p>Similar heavy-tail distribution observed in 4 other datasets</p>
    <p>Haifeng Yu, National University of Singapore 24</p>
  </div>
  <div class="page">
    <p>Results on Loss (Based on Digg Dataset) Results on Loss (Based on Digg Dataset)</p>
    <p>Attack capacity: Max 10 billion sybil voters on any obj  In Digg, avg # honest voters on each obj is only ~1,000</p>
    <p>Fraction of bad recommendations (under worst-case attack): 12%</p>
    <p>Growing defense: 5% if user has used DSybil for a week before attack starts  If attack starts at random point, applies to 51/52 = 98%</p>
    <p>users</p>
    <p>1-minute computational puzzle per week  10 billion identities needs a million-node botnet</p>
    <p>Haifeng Yu, National University of Singapore 25</p>
  </div>
  <div class="page">
    <p>ConclusionConclusion</p>
    <p>Defending against sybil attacks is challenging  It is even harder in the context of rec systems</p>
    <p>DSybil: Provable and optimal loss  Almost no previous approaches provide provable</p>
    <p>guarantees against worst-case attack</p>
    <p>DSybil key insights:  Leverage small dimension of the voting pattern</p>
    <p>Carefully identify when help is already sufficient</p>
    <p>Haifeng Yu, National University of Singapore 26</p>
    <p>)log( MDO</p>
  </div>
  <div class="page">
    <p>Haifeng Yu, National University of Singapore 27</p>
  </div>
  <div class="page">
    <p>Haifeng Yu, National University of Singapore 28</p>
    <p>Which object to pick?</p>
  </div>
  <div class="page">
    <p>Central Question Answered by This WorkCentral Question Answered by This Work</p>
    <p>Haifeng Yu, National University of Singapore 29</p>
    <p>Can trust sufficiently diminish the influence of sybil identities in recommendation systems?</p>
    <p>Aim for provable guarantees under all attack strategies (including worst-case attack from intelligent attacker)</p>
    <p>Short answer: YES!</p>
  </div>
  <div class="page">
    <p>Our ResultsOur Results  DSybil: A novel defense mechanism</p>
    <p>Growing defense: If the user has used DSybil for some time before the attack starts, loss will be even smaller</p>
    <p>Experimental results (from one-year trace of Digg): High-quality recommendation even under potential sybil attack (with optimal strategy) from a millionnode botnet</p>
    <p>Haifeng Yu, National University of Singapore 30</p>
  </div>
</Presentation>
