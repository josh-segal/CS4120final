<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>A CoA Co--Evaluation Framework for Evaluation Framework for</p>
    <p>Improving Segmentation EvaluationImproving Segmentation Evaluation</p>
    <p>Hui Zhang, Jason Fritts, and Sally Goldman</p>
    <p>Washington University in St. Louis</p>
    <p>Department of Computer Science and Engineering</p>
  </div>
  <div class="page">
    <p>Image Segmentation &amp; Evaluation</p>
    <p>Co-Evaluation Framework</p>
    <p>Experiments</p>
    <p>Human vs. Machine Segmentation</p>
    <p>Machine vs. Machine Segmentation</p>
    <p>Conclusions &amp; Future Work</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Partitioning an image into separate regions</p>
    <p>Image Segmentation</p>
    <p>A critical early step towards content analysis and image understanding</p>
    <p>A B C</p>
  </div>
  <div class="page">
    <p>Three categories of segmentation methods</p>
    <p>Pixel-based</p>
    <p>Histogram thresholding, etc</p>
    <p>Image Segmentation</p>
    <p>Region-based  Split-and-merge, region growing, etc</p>
    <p>Edge-based  Edge flow, color snakes, etc</p>
  </div>
  <div class="page">
    <p>Problems</p>
    <p>Unable to compare different segmentation</p>
    <p>methods, or even different parameterizations of a</p>
    <p>single method</p>
    <p>Unable to determine whether one segmentation</p>
    <p>method is appropriate for different types of images</p>
    <p>Segmentation evaluation is of critical</p>
    <p>importance</p>
    <p>Image Segmentation</p>
  </div>
  <div class="page">
    <p>Segmentation Evaluation</p>
    <p>Original image</p>
    <p>HS</p>
    <p>IHS</p>
    <p>JSEG</p>
    <p>Image</p>
    <p>Magick</p>
    <p>Edison</p>
    <p>eCognition</p>
  </div>
  <div class="page">
    <p>Original image</p>
    <p>Improved Hierarchical Segmentation (IHS)</p>
    <p>Different parameterizations</p>
    <p>Of a single method:</p>
    <p>Segmentation Evaluation</p>
  </div>
  <div class="page">
    <p>Image</p>
    <p>Segmentation</p>
    <p>evaluation Objective</p>
    <p>evaluation</p>
    <p>Subjective</p>
    <p>evaluation</p>
    <p>System-level</p>
    <p>evaluation</p>
    <p>Direct</p>
    <p>evaluation</p>
    <p>Analytical</p>
    <p>methods</p>
    <p>Empirical</p>
    <p>methods</p>
    <p>Relative</p>
    <p>methods</p>
    <p>Stand-alone</p>
    <p>methods</p>
    <p>[ Taxonomy ]</p>
    <p>Segmentation Evaluation</p>
  </div>
  <div class="page">
    <p>Relative Evaluation (a.k.a. Empirical Discrepancy Measures)</p>
    <p>Most widely used objective evaluation methods</p>
    <p>Comparing results to manually-segmented reference</p>
    <p>image</p>
    <p>Original image reference image Result from EDISON</p>
    <p>Measure the discrepancy</p>
    <p>Objective Segmentation Evaluation</p>
  </div>
  <div class="page">
    <p>Stand-alone Evaluation (a.k.a. empirical goodness measures)  No reference image is needed</p>
    <p>Examine how well it matches the desired characteristics of segmented images, based on human intuition</p>
    <p>A goodness score is given for each segmentation result</p>
    <p>Segmentation</p>
    <p>Result 1</p>
    <p>Result 2 from</p>
    <p>EDISON</p>
    <p>Stand-alone Objective Evaluation</p>
    <p>Stand-alone Evaluation</p>
    <p>Goodness Score: 6.1345 Goodness Score: 8.2733</p>
  </div>
  <div class="page">
    <p>Intra-region uniformity measures</p>
    <p>Color variance</p>
    <p>Squared color error</p>
    <p>Texture</p>
    <p>Inter-region disparity measures</p>
    <p>Average color difference between regions</p>
    <p>Average color difference along boundary</p>
    <p>Semantic measures</p>
    <p>Shape</p>
    <p>Stand-alone Objective Evaluation</p>
  </div>
  <div class="page">
    <p>Liu and Yangs F function:</p>
    <p>Borsotti et al.s Q function:</p>
    <p>Correia and Pereiras V Functions:</p>
    <p>Stand-Alone Objective Evaluation</p>
    <p>Functions</p>
    <p>contrastcompactelongcircRvs 55.225._225.)( ++=</p>
    <p>contrastcompactelongcircRvm 40.30._30.)( ++=</p>
    <p>( )</p>
    <p>=</p>
    <p>+</p>
    <p>+ =</p>
    <p>N</p>
    <p>j j</p>
    <p>j</p>
    <p>j</p>
    <p>j</p>
    <p>I S</p>
    <p>SN</p>
    <p>S</p>
    <p>e N</p>
    <p>S IQ</p>
    <p>log11000</p>
    <p>=</p>
    <p>= N</p>
    <p>i i</p>
    <p>i</p>
    <p>S</p>
    <p>e NIF</p>
  </div>
  <div class="page">
    <p>Utilize minimum description length (MDL) principle</p>
    <p>regards segmentation as a modeling process</p>
    <p>MDL provides effective balance between:</p>
    <p>uniformity within a region</p>
    <p>complexity of segmentation</p>
    <p>Our evaluation function, E, based on MDL:</p>
    <p>Evaluation function E</p>
    <p>)()()|()( IHIHSRLSLE rl +=+=</p>
  </div>
  <div class="page">
    <p>Evaluation function E</p>
    <p>Region entropy</p>
    <p>Layout entropy</p>
    <p>E</p>
    <p>Original image</p>
    <p>Segmentation 1ayout</p>
  </div>
  <div class="page">
    <p>Image Segmentation &amp; Evaluation</p>
    <p>Co-Evaluation Framework</p>
    <p>Experiments</p>
    <p>Human vs. Machine Segmentation</p>
    <p>Machine vs. Machine Segmentation</p>
    <p>Conclusions &amp; Future Work</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Co-Evaluation framework</p>
  </div>
  <div class="page">
    <p>Co-Evaluation framework</p>
    <p>Evaluator 1</p>
    <p>Evaluator 2</p>
    <p>Evaluator N</p>
    <p>Combiner</p>
    <p>Original image</p>
    <p>Segmented images</p>
    <p>Simple combiner strategy:</p>
    <p>combinerEvaluator 5Evaluator 4Evaluator 3Evaluator 2Evaluator 1</p>
    <p>Example:</p>
  </div>
  <div class="page">
    <p>Co-Evaluation framework</p>
    <p>Evaluator 1</p>
    <p>Evaluator 2</p>
    <p>Evaluator N</p>
    <p>Combiner</p>
    <p>Original image</p>
    <p>Segmented images</p>
    <p>Human Evaluation Results: For Training</p>
    <p>Expert combiner strategy:</p>
    <p>Example:</p>
    <p>combinerHumanEvaluator5Evaluator4Evaluator3Evaluator2Evaluator1</p>
  </div>
  <div class="page">
    <p>Image Segmentation &amp; Evaluation</p>
    <p>Co-Evaluation Framework</p>
    <p>Experiments</p>
    <p>Human vs. Machine Segmentation</p>
    <p>Machine vs. Machine Segmentation</p>
    <p>Conclusions &amp; Future Work</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Human vs. Machine</p>
    <p>Segmentation Evaluation</p>
    <p>5 evaluators: E, F, Q, Vs, Vm</p>
    <p>Image pair (human segmentation, machine segmentation)</p>
    <p>108 training sets from Berkeley dataset and Military Graphics Collection (aircraft)</p>
  </div>
  <div class="page">
    <p>Human vs. Machine</p>
    <p>Segmentation Evaluation Results</p>
    <p>108 training pairs</p>
    <p>Results for 92 evaluation pairs:</p>
    <p>Single evaluation method:</p>
    <p>Co-Evaluation:</p>
  </div>
  <div class="page">
    <p>Image Segmentation &amp; Evaluation</p>
    <p>Co-Evaluation Framework</p>
    <p>Experiments</p>
    <p>Human vs. Machine Segmentation</p>
    <p>Machine vs. Machine Segmentation</p>
    <p>Conclusions &amp; Future Work</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Machine vs. Machine</p>
    <p>Segmentation Evaluation Results</p>
    <p>6 subjective evaluators determined 3 best and 3 worst segmentations across image regressions of 2 to 20 segments</p>
    <p>Most common best and worst segmentations from each image used to form Best set and Worst set</p>
    <p>125 pairs of (Best, Worst) used for training</p>
    <p>124 pairs used for evaluation</p>
    <p>E F Q Vs Vm SC WM NB SVM</p>
    <p>A c</p>
    <p>c u</p>
    <p>ra c</p>
    <p>y</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>By themselves,</p>
    <p>E is best at determining human vs. machine segmentations</p>
    <p>Q is best at comparing machine vs. machine segmentations</p>
    <p>Using the Co-Evaluation framework,</p>
    <p>Naive Bayesian combiner does best</p>
    <p>Weighted Majority and Support Vector Machines are also</p>
    <p>good, much better than a simple combiner</p>
    <p>Some gain from Co-Evaluation framework, but</p>
    <p>expect we can do better</p>
  </div>
  <div class="page">
    <p>Future Work Meta-Learning</p>
    <p>Evaluator 1</p>
    <p>Evaluator 2</p>
    <p>Evaluator N</p>
    <p>Combiner</p>
    <p>Original image</p>
    <p>Segmented images</p>
    <p>Human Evaluation Results: For Training</p>
    <p>Images</p>
    <p>features</p>
    <p>Meta-learner strategy:</p>
    <p>combinerhumanMeta-featureEval.5Eval.4Eval.3Eval.2Eval.1</p>
    <p>Example:</p>
  </div>
  <div class="page">
    <p>Thank You!</p>
    <p>More information:</p>
    <p>http://www.cse.wustl.edu/~jefritts/</p>
  </div>
</Presentation>
