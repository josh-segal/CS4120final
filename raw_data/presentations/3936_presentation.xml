<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Profiling Network Performance in Multi-tier Datacenter Applications</p>
    <p>Minlan Yu Princeton University</p>
    <p>Joint work with Albert Greenberg, Dave Maltz, Jennifer Rexford, Lihua Yuan, Srikanth Kandula, Changhoon Kim</p>
    <p>Scalable Net-App Profiler</p>
  </div>
  <div class="page">
    <p>Applications inside Data Centers</p>
    <p>Front end Server</p>
    <p>Front end Server</p>
    <p>AggregatorAggregator WorkersWorkers</p>
    <p>.</p>
    <p>. . .</p>
  </div>
  <div class="page">
    <p>Challenges of Datacenter Diagnosis</p>
    <p>Large complex applications  Hundreds of application components  Tens of thousands of servers</p>
    <p>New performance problems  Update code to add features or fix bugs  Change components while app is still in operation</p>
    <p>Old performance problems (Human factors)  Developers may not understand network well  Nagles algorithm, delayed ACK, etc.</p>
  </div>
  <div class="page">
    <p>Diagnosis in Todays Data Center</p>
    <p>HostHost</p>
    <p>App</p>
    <p>OS Packet sniffer</p>
    <p>App logs: #Reqs/sec Response time 1% req. &gt;200ms delay</p>
    <p>Switch logs: #bytes/pkts per minute</p>
    <p>Packet trace: Filter out trace for long delay req.</p>
    <p>SNAP: Diagnose net-app interactions SNAP: Diagnose net-app interactions</p>
    <p>Application-specific</p>
    <p>Too expensive</p>
    <p>Too coarse-grainedGeneric, fine-grained, and lightweight</p>
  </div>
  <div class="page">
    <p>SNAP: A Scalable Net-App Profiler</p>
    <p>that runs everywhere, all the time</p>
  </div>
  <div class="page">
    <p>SNAP Architecture</p>
    <p>At each host for every connection At each host for every connection</p>
    <p>Collect data</p>
  </div>
  <div class="page">
    <p>Collect Data in TCP Stack</p>
    <p>TCP understands net-app interactions  Flow control: How much data apps want to read/write  Congestion control: Network delay and congestion</p>
    <p>Collect TCP-level statistics  Defined by RFC 4898  Already exists in todays Linux and Windows OSes</p>
  </div>
  <div class="page">
    <p>TCP-level Statistics</p>
    <p>Cumulative counters  Packet loss: #FastRetrans, #Timeout  RTT estimation: #SampleRTT, #SumRTT  Receiver: RwinLimitTime  Calculate the difference between two polls</p>
    <p>Instantaneous snapshots  #Bytes in the send buffer  Congestion window size, receiver window size  Representative snapshots based on Poisson sampling</p>
  </div>
  <div class="page">
    <p>SNAP Architecture</p>
    <p>At each host for every connection At each host for every connection</p>
    <p>Collect data</p>
    <p>Performance Classifier</p>
  </div>
  <div class="page">
    <p>Life of Data Transfer</p>
    <p>Application generates the data</p>
    <p>Copy data to send buffer</p>
    <p>TCP sends data to the network</p>
    <p>Receiver receives the data and ACK 10</p>
    <p>Sender App</p>
    <p>Send Buffer</p>
    <p>Receiver</p>
    <p>Network</p>
  </div>
  <div class="page">
    <p>Taxonomy of Network Performance</p>
    <p>No network problem</p>
    <p>Send buffer not large enough</p>
    <p>Fast retransmission  Timeout</p>
    <p>Not reading fast enough (CPU, disk, etc.)  Not ACKing fast enough (Delayed ACK)</p>
    <p>Sender App</p>
    <p>Send Buffer</p>
    <p>Receiver</p>
    <p>Network</p>
  </div>
  <div class="page">
    <p>Identifying Performance Problems</p>
    <p>Not any other problems</p>
    <p>#bytes in send buffer</p>
    <p>#Fast retransmission  #Timeout</p>
    <p>RwinLimitTime  Delayed ACK diff(SumRTT) &gt; diff(SampleRTT)*MaxQueuingDelay</p>
    <p>Sender App</p>
    <p>Send Buffer</p>
    <p>Receiver</p>
    <p>Network Direct measure</p>
    <p>Sampling</p>
    <p>Inference</p>
  </div>
  <div class="page">
    <p>Management System</p>
    <p>Management System</p>
    <p>SNAP Architecture</p>
    <p>At each host for every connection At each host for every connection</p>
    <p>Collect data</p>
    <p>Performance Classifier</p>
    <p>Crossconnection correlation</p>
    <p>Topology, routing Conn  proc/app</p>
    <p>Offending app, host, link, or switch</p>
  </div>
  <div class="page">
    <p>Pinpoint Problems via Correlation</p>
    <p>Correlation over shared switch/link/host  Packet loss for all the connections going through</p>
    <p>one switch/host  Pinpoint the problematic switch</p>
  </div>
  <div class="page">
    <p>Pinpoint Problems via Correlation</p>
    <p>Correlation over application  Same application has problem on all machines  Report aggregated application behavior</p>
  </div>
  <div class="page">
    <p>Management System</p>
    <p>Management System</p>
    <p>SNAP Architecture</p>
    <p>At each host for every connection At each host for every connection</p>
    <p>Collect data</p>
    <p>Performance Classifier</p>
    <p>Crossconnection correlation</p>
    <p>Topology, routing Conn  proc/app</p>
    <p>Offending app, host, link, or switch</p>
    <p>Online, lightweight processing &amp; diagnosis</p>
    <p>Offline, cross-conn diagnosis</p>
  </div>
  <div class="page">
    <p>Reducing SNAP Overhead</p>
    <p>SNAP overhead  Data volume: 120 Bytes per connection per poll  CPU overhead:</p>
    <p>5% for polling 1K connections with 500 ms interval  Increases with #connections and polling freq.</p>
    <p>Solution: Adaptive tuning of polling frequency  Reduce polling frequency to stay within a target CPU  Devote more polling to more problematic connections</p>
  </div>
  <div class="page">
    <p>SNAP in the Real World</p>
  </div>
  <div class="page">
    <p>Key Diagnosis Steps</p>
    <p>Identify performance problems  Correlate across connections  Identify applications with severe problems</p>
    <p>Expose simple, useful information to developers  Filter important statistics and classification results</p>
    <p>Identify root cause and propose solutions  Work with operators and developers  Tune TCP stack or change application code</p>
  </div>
  <div class="page">
    <p>SNAP Deployment</p>
    <p>Deployed in a production data center  8K machines, 700 applications  Ran SNAP for a week, collected terabytes of data</p>
    <p>Diagnosis results  Identified 15 major performance problems  21% applications have network performance problems</p>
  </div>
  <div class="page">
    <p>Characterizing Perf. Limitations</p>
    <p>Send Buffer</p>
    <p>Receiver</p>
    <p>Network</p>
    <p>#Apps that are limited for &gt; 50% of the time</p>
    <p>Send buffer not large enough</p>
    <p>Fast retransmission  Timeout</p>
    <p>Not reading fast enough (CPU, disk, etc.)  Not ACKing fast enough (Delayed ACK)</p>
  </div>
  <div class="page">
    <p>Three Example Problems</p>
    <p>Delayed ACK affects delay sensitive apps</p>
    <p>Congestion window allows sudden burst</p>
    <p>Significant timeouts for low-rate flows</p>
  </div>
  <div class="page">
    <p>Problem 1: Delayed ACK  Delayed ACK affected many delay sensitive apps</p>
    <p>even #pkts per record  1,000 records/sec odd #pkts per record  5 records/sec  Delayed ACK was used to reduce bandwidth usage and</p>
    <p>server interrupts</p>
    <p>Data</p>
    <p>ACK</p>
    <p>Data</p>
    <p>A B</p>
    <p>ACK</p>
    <p>.Proposed solutions: Delayed ACK should be disabled in data centers</p>
    <p>Proposed solutions: Delayed ACK should be disabled in data centers</p>
    <p>ACK every other packet</p>
  </div>
  <div class="page">
    <p>ReceiverReceiverSocket send bufferSocket send buffer</p>
    <p>Send Buffer and Delayed ACK</p>
    <p>Application bufferApplication buffer Application</p>
    <p>Network Stack 2. ACK</p>
    <p>With Socket Send Buffer</p>
    <p>ReceiverReceiver</p>
    <p>Application bufferApplication buffer Application</p>
    <p>Zero-copy send</p>
    <p>SNAP diagnosis: Delayed ACK and zero-copy send</p>
  </div>
  <div class="page">
    <p>Problem 2: Congestion Window Allows Sudden Bursts</p>
    <p>Increase congestion window to reduce delay  To send 64 KB data with 1 RTT  Developers intentionally keep congestion window large  Disable slow start restart in TCP</p>
    <p>t</p>
    <p>Window Drops after an idle time</p>
  </div>
  <div class="page">
    <p>Slow Start Restart</p>
    <p>SNAP diagnosis  Significant packet loss  Congestion window is too large after an idle period</p>
    <p>Proposed solutions  Change apps to send less data during congestion  New transport protocols that consider both congestion</p>
    <p>and delay</p>
  </div>
  <div class="page">
    <p>Problem 3: Timeouts for Low-rate Flows</p>
    <p>SNAP diagnosis  More fast retrans. for high-rate flows (1-10MB/s)  More timeouts with low-rate flows (10-100KB/s)</p>
    <p>Proposed solutions  Reduce timeout time in TCP stack  New ways to handle packet loss for small flows</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>A simple, efficient way to profile data centers  Passively measure real-time network stack information  Systematically identify problematic stages  Correlate problems across connections</p>
    <p>Deploying SNAP in production data center  Diagnose net-app interactions  A quick way to identify them when problems happen</p>
    <p>Future work  Extend SNAP to diagnose wide-area transfers</p>
  </div>
  <div class="page">
    <p>Thanks!</p>
  </div>
</Presentation>
