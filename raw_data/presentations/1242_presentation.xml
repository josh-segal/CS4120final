<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Firefly: Untethered Multi-user VR for Commodity Mobile Devices</p>
    <p>Xing Liu, Christina Vlachou, Feng Qian, Chendong Wang, Kyu-Han Kim</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Cost</p>
    <p>Performance</p>
    <p>User mobility</p>
    <p>Deployment</p>
    <p>User scalability</p>
  </div>
  <div class="page">
    <p>State-of-the-art</p>
    <p>Flashback (Mobisys 2016)  Aggressive prerendering, local memorization.  Furion (Mobicom 2017)  Pipelining, offloading.</p>
  </div>
  <div class="page">
    <p>Firefly</p>
    <p>A low cost and easy to deploy colocation multi-user VR system that supports  10+ users with mobility</p>
    <p>High quality VR content  60 FPS  Low motion-to-photon latency  Quad HD</p>
    <p>Single server/AP, commodity smartphones, cheap VR headsets (e.g. google cardboard)</p>
    <p>Team training, group therapy, collaborative product design, multi-user gaming</p>
  </div>
  <div class="page">
    <p>Challenges</p>
    <p>Weak mobile GPU  Energy/heat constrains  Heterogeneous computing capabilities  Multi-user scalability</p>
    <p>Client-server load split  Single AP bandwidth limitation</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Overview  Firefly System Components  Evaluation  Summary</p>
  </div>
  <div class="page">
    <p>High Level Architecture</p>
    <p>A Serverless Design  full-fledged client rendering  far from being powerful enough</p>
    <p>Edge offloading  server real-time rendering, streamed as encoded VR frames  high encoding overhead for single server (~150 FPS for Quad HD)</p>
    <p>Performs One-time, Exhaustive Offline Rendering  Offline: prepare all possible VR viewports, encodes as video stream  Online: streams based on VR motion  eliminates rendering/encoding overhead, scales to tens of users, at the cost of high mem, disk</p>
    <p>and network usage.</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Overview  Firefly System Components  Evaluation  Summary</p>
  </div>
  <div class="page">
    <p>Offline Rendering Engine</p>
    <p>Populates the content DB by  Discretizing whole VR space into grids  At each grid, renders a panoramic VR frame (360 view)</p>
    <p>Client Projection</p>
  </div>
  <div class="page">
    <p>Offline Rendering Engine</p>
    <p>Tiles  Independently transmitted &amp; decoded  Streams at tile level</p>
    <p>Finer fetching granularity  Bandwidth saving</p>
    <p>Office vs. Museum  Map size: 30 X 30 m  Grid size: 5cm  Size: 137GB vs. 99GB</p>
    <p>Mega Frame</p>
    <p>Color D epth</p>
  </div>
  <div class="page">
    <p>How to fetch tiles?</p>
    <p>6 degree of freedom (DoF)  Translational  Rotational  (x, y, z, yaw, pitch, roll) -&gt; tile x</p>
    <p>Fetch based on users VR motion  End-to-end latency estimation: 3ms + 30ms + 34ms + 3ms = 70ms</p>
    <p>Motion-to-photon latency requirement: 1000ms / 60FPS = 16.7ms</p>
    <p>req trans decode render</p>
  </div>
  <div class="page">
    <p>Understanding VR Motion Predictability</p>
    <p>VR user motion data collection  25 participants  Unity API (Office, Museum)  6-DoF motion enabled by Oculus Rift  6-DoF trajectory recorded  50 5-min VR trajectory traces</p>
  </div>
  <div class="page">
    <p>VR User Motion Profile</p>
    <p>Office</p>
    <p>Museum</p>
  </div>
  <div class="page">
    <p>Understanding VR Motion Predictability</p>
    <p>A simple Linear Regression (LR) model (H=50ms, P=150ms)  MAEtrans = 1.4cm, MAElat = 1.9, MAElon = 7.6 (FoV 100 x 90)  Predict each dimension separately</p>
    <p>Translational Rotational</p>
    <p>Lat Lon</p>
  </div>
  <div class="page">
    <p>VR User Stationary Periods (SP)</p>
    <p>Within a 5-min VR session  43 seconds of SP  SP are short (~ 1s), but frequent  Sudden movements makes prediction unavailable</p>
    <p>Moving  fetch based on prediction  Stationary  fetch (best-effort) neighboring tiles 0 2 4 6 8 10 12</p>
    <p>Duration (sec)</p>
    <p>C D</p>
    <p>F</p>
    <p>Translation Rotation</p>
    <p>TAKE AWAY: 1. Users motion profile are diverse. 2. Good predictability for continuous VR motion. 3. Need to handle sudden movements.</p>
  </div>
  <div class="page">
    <p>System Architecture</p>
    <p>Offline Rendering Engine</p>
    <p>AQC Content DB</p>
    <p>L1 Cache</p>
    <p>L2 Cache</p>
    <p>L3 Cache</p>
    <p>Tile Fetching Scheduler</p>
    <p>Motion Prediction</p>
    <p>Renderer</p>
    <p>Decoding Scheduler</p>
    <p>Rendering Profiles</p>
    <p>Object Store</p>
    <p>Offline Foreground Object Profiling</p>
    <p>Tile Decoder</p>
    <p>Tile Req. Queue</p>
    <p>Tile Xmit Queue</p>
    <p>User Motion</p>
    <p>Network BW from AP</p>
    <p>Firefly Server</p>
    <p>Fi re</p>
    <p>fly Cl</p>
    <p>ie nt</p>
    <p>Client 2 Client 3 Client 4</p>
    <p>Features  maximize the quality level, minimize</p>
    <p>stall and quality switch  Fairness among users  Fast pace  Scale more users  Optimization vs. heuristics</p>
  </div>
  <div class="page">
    <p>Adaptive Quality Control (AQC)</p>
    <p>T = get_total_bw_from_AP() *  Q[1..n] = Q[1..n] B[1..n] = get_individual_bw_from_AP([1..n]) *  foreach user i:</p>
    <p>while (bw_util(Tiles[i],Q[i])B[i] and Q[i] is not lowest): Q[i] = Q[i] - 1</p>
    <p>T = T  min(B[i], max(RESERVE, bw_util(Tiles[i], Q[i]))) if (T &lt; 0):</p>
    <p>lru_decrease(Q[1..n]) until (T0 or Q[1..n] are lowest) else:</p>
    <p>lru_increase(Q[1..n]) until (T0 or Q[1..n] are highest) Q[1..n] = Q[1..n]</p>
    <p>n: total number of users T: total available bandwidth across all users Q: users current quality levels (input &amp; output) Tiles: users to-be-fetched tile lists (input) Q: local copy of Q B: individual users available bandwidth : bandwidth usage safety margin RESERVE: reserved bandwidth for each user bw_util: estimate bandwidth requirement for the request</p>
  </div>
  <div class="page">
    <p>System Architecture</p>
    <p>Offline Rendering Engine</p>
    <p>AQC Content DB</p>
    <p>L1 Cache</p>
    <p>L2 Cache</p>
    <p>L3 Cache</p>
    <p>Tile Fetching Scheduler</p>
    <p>Motion Prediction</p>
    <p>Renderer</p>
    <p>Decoding Scheduler</p>
    <p>Rendering Profiles</p>
    <p>Object Store</p>
    <p>Offline Foreground Object Profiling</p>
    <p>Tile Decoder</p>
    <p>Tile Req. Queue</p>
    <p>Tile Xmit Queue</p>
    <p>User Motion</p>
    <p>Network BW from AP</p>
    <p>Firefly Server</p>
    <p>Fi re</p>
    <p>fly Cl</p>
    <p>ie nt</p>
    <p>Client 2 Client 3 Client 4</p>
  </div>
  <div class="page">
    <p>Dynamic Foreground Objects</p>
    <p>Other users avatars, control panel, etc.  Foreground objects are rendered locally real-time</p>
    <p>Pre-render not feasible  Less rendering compared with complex backgrounds  Latency sensitive</p>
    <p>Adaptive object rendering  Prepare lower quality by mesh simplification  Dynamic decision</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Overview  Firefly System Components  Evaluation  Summary</p>
  </div>
  <div class="page">
    <p>Implementation and Evaluation Setup</p>
    <p>Offline rending engine: Unity API and ffmpeg, C#/Python (LoC 1,500)  Client: Android SDK (LoC 14,900)</p>
    <p>Tile decoding: Android MediaCodec  Projection/rendering: OpenGL ES  L1 cache: OpenGL frame buffer object (FBO)</p>
    <p>Server: Python (LoC 1,000)  Replayable experiment (15 devices)</p>
    <p>SGS8 x 2, SGN8, MOTO Z3, SGS 10  Raspberry Pi4 x 10  Server colocates with AP in a VR lab  Clients randomly distributed</p>
  </div>
  <div class="page">
    <p>Overall Performance Comparison</p>
    <p>C D F</p>
    <p>)LUHIO\ Furion 3HUIHFW</p>
    <p>C D F</p>
    <p>)LUHIO\ Furion 3HUIHFW</p>
    <p>CRF</p>
    <p>C D F</p>
    <p>)LUHIO\ Furion Perfect</p>
    <p>Firefly vs. multi-user Furion vs. Perfect</p>
    <p>FPS, stall, content quality, motion-to-photon delay, inter-frame quality variation, intra-frame quality variation, fairness  Overall, Firefly achieves good performance across all metrics  90%/99% of the time FPS  60/50  Stall = 1.2 sec/min  Bandwidth consumption (15 users) &lt; 200 Mbps  Quad HD (2560 x 1440) with average CRF = 23.8</p>
  </div>
  <div class="page">
    <p>Micro Benchmarks</p>
    <p>Impact of AQC  Impact of Bandwidth Reservation for stationary periods  Impact of different viewport prediction strategy  Impact of adaptive object quality selection</p>
  </div>
  <div class="page">
    <p>Case Study - Adaptiveness to Number of Users</p>
    <p>A vJ</p>
    <p>C R</p>
    <p>F</p>
    <p>8VHUV</p>
    <p>8VHUV</p>
    <p>8VHUV</p>
    <p>8VHUV</p>
    <p>8VHUV</p>
    <p>A vJ</p>
    <p>F P</p>
    <p>S</p>
    <p>8VHUV</p>
    <p>8VHUV</p>
    <p>8VHUV</p>
    <p>8VHUV</p>
    <p>8VHUV</p>
    <p>The global available bandwidth is throttled at 200 Mbps</p>
    <p>Average FPS Content Quality</p>
  </div>
  <div class="page">
    <p>Case Study - Adaptiveness to Available Bandwidth</p>
    <p>A vJ</p>
    <p>C R</p>
    <p>F</p>
    <p>A vJ</p>
    <p>F P</p>
    <p>S</p>
    <p>Average FPS Content Quality</p>
  </div>
  <div class="page">
    <p>Energy Usage and Thermal Characteristics</p>
    <p>After 25 mins of Firefly client usage, a fully charged smartphone  Battery left: 92% ~ 96%  GPU temperature &lt; 50C</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Firefly supports 15 VR users at 60 FPS using commodity smartphones and a single AP/server.  Our design makes judicious decisions on</p>
    <p>partitioning the workload (offline vs. runtime, client vs. server)  making the system adaptive to the available network/computation resources  handling VR users fast-paced motion</p>
    <p>Core concepts of Firefly are applicable to other multi-user scenarios (AR/MR)</p>
  </div>
</Presentation>
