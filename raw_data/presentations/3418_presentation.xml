<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Locally Differentially Private Protocols for Frequency</p>
    <p>Estimation Tianhao Wang, Jeremiah Blocki, Ninghui Li, Somesh Jha</p>
  </div>
  <div class="page">
    <p>Differential Privacy</p>
  </div>
  <div class="page">
    <p>Differential Privacy</p>
    <p>Classical setting</p>
  </div>
  <div class="page">
    <p>Differential Privacy</p>
    <p>DataDataData Data Data</p>
    <p>Classical setting</p>
  </div>
  <div class="page">
    <p>+Noise</p>
    <p>Differential Privacy</p>
    <p>DataDataData Data Data</p>
    <p>Classical setting</p>
  </div>
  <div class="page">
    <p>Database</p>
    <p>+Noise</p>
    <p>Differential Privacy</p>
    <p>DataDataData Data Data</p>
    <p>Classical setting</p>
  </div>
  <div class="page">
    <p>Data mining Statistical queriesDatabase</p>
    <p>+Noise</p>
    <p>Differential Privacy</p>
    <p>DataDataData Data Data</p>
    <p>Classical setting</p>
  </div>
  <div class="page">
    <p>Data mining Statistical queriesDatabase</p>
    <p>+Noise</p>
    <p>Differential Privacy</p>
    <p>DataDataData Data Data</p>
    <p>Classical setting</p>
    <p>Differential Privacy Interpretation: The decision to include/exclude</p>
    <p>individuals record has minimal () influence on the outcome.</p>
    <p>Smaller  Stronger Privacy</p>
  </div>
  <div class="page">
    <p>Data mining Statistical queriesDatabase</p>
    <p>+Noise</p>
    <p>Differential Privacy</p>
    <p>Trusted</p>
    <p>DataDataData Data Data</p>
  </div>
  <div class="page">
    <p>Local Differential Privacy</p>
    <p>Data mining Statistical queriesDatabase</p>
    <p>Data+Noise Data+Noise Data+Noise</p>
  </div>
  <div class="page">
    <p>Local Differential Privacy</p>
    <p>Data mining Statistical queriesDatabase</p>
    <p>No worry about untrusted server</p>
    <p>Data+Noise Data+Noise Data+Noise</p>
  </div>
  <div class="page">
    <p>Local Differential Privacy</p>
    <p>Data mining Statistical queriesDatabase</p>
    <p>No worry about untrusted server</p>
    <p>Data+Noise Data+Noise Data+Noise</p>
  </div>
  <div class="page">
    <p>Local Differential Privacy</p>
    <p>Data mining Statistical queriesDatabase</p>
    <p>No worry about untrusted server</p>
    <p>Data+Noise Data+Noise Data+Noise</p>
  </div>
  <div class="page">
    <p>The Warner Model (1965)</p>
    <p>Survey technique for private questions</p>
    <p>Survey people:  Are you communist party?</p>
    <p>Each person:  Flip a secret coin  Answer truth if head (w/p 0.5)  Answer randomly if tail  E.g., a communist will answer yes w/p 75%, and no w/p 25%</p>
    <p>To get unbiased estimation of the distribution:  If  out of  people are communist, we expect to see [ ] = 0.75 +0.25( ) yes answers</p>
    <p>()= 0.25</p>
    <p>Since [()] = []0.25</p>
    <p>Provide deniability: Seeing answer, not certain about the secret.</p>
  </div>
  <div class="page">
    <p>The Warner Model (1965)</p>
    <p>Survey technique for private questions</p>
    <p>Survey people:  Are you communist party?</p>
    <p>Each person:  Flip a secret coin  Answer truth if head (w/p 0.5)  Answer randomly if tail  E.g., a communist will answer yes w/p 75%, and no w/p 25%</p>
    <p>To get unbiased estimation of the distribution:  If  out of  people are communist, we expect to see [ ] = 0.75 +0.25( ) yes answers</p>
    <p>()= 0.25</p>
    <p>Since [()] = []0.25</p>
    <p>Provide deniability: Seeing answer, not certain about the secret.</p>
    <p>This only handles binary attribute. We want to handle the more general</p>
    <p>setting.</p>
    <p>We say the protocol is  -LDP iff for any  and  from yes and no,</p>
    <p>Pr   =</p>
    <p>Pr   =</p>
  </div>
  <div class="page">
    <p>Abstract LDP Protocol</p>
    <p>() takes input value  from domain  and outputs an encoded value   () takes an encoded value  and outputs .</p>
    <p>(  ) takes reports {} from all users and outputs estimations () for any value  in domain</p>
    <p>satisfies -LDP We focus on frequency estimation</p>
  </div>
  <div class="page">
    <p>Frequency Estimation Protocols</p>
    <p>Direct Encoding (Generalized Random Response) [Warner65]  Generalize binary attribute to arbitrary domain</p>
    <p>Unary Encoding (Basic One-time RAPPOR) [Erlingsson et al14]  Encode into a bit-vector and perturb each bit</p>
    <p>Binary Local Hash [Bassily and Smith15]  Encode by hashing and then perturb</p>
  </div>
  <div class="page">
    <p>Direct Encoding (Random Response)</p>
    <p>User:  Encode  = (suppose  from  = {1,2,,})</p>
    <p>Toss a coin with bias</p>
    <p>If it is head, report the true value =</p>
    <p>Otherwise, report any other value with probability  = 1</p>
    <p>1 (uniformly at random)</p>
    <p>=</p>
    <p>+1 , =</p>
    <p>+1  Pr   =</p>
    <p>Pr   = =</p>
    <p>=</p>
    <p>Aggregator:  Suppose  users possess value , is the number of reports on .</p>
    <p>[] =  +</p>
    <p>Unbiased Estimation: ()=</p>
  </div>
  <div class="page">
    <p>Direct Encoding (Random Response)</p>
    <p>User:  Encode  = (suppose  from  = {1,2,,})</p>
    <p>Toss a coin with bias</p>
    <p>If it is head, report the true value =</p>
    <p>Otherwise, report any other value with probability  = 1</p>
    <p>1 (uniformly at random)</p>
    <p>=</p>
    <p>+1 , =</p>
    <p>+1  Pr   =</p>
    <p>Pr   = =</p>
    <p>=</p>
    <p>Aggregator:  Suppose  users possess value , is the number of reports on .</p>
    <p>[] =  +</p>
    <p>Unbiased Estimation: ()=</p>
    <p>Intuitively, the higher , the more accurate</p>
    <p>However, when  is large,  becomes small</p>
  </div>
  <div class="page">
    <p>Unary Encoding (Basic RAPPOR)</p>
    <p>Encode the value  into a bit string 0,  1  e.g., = 1,2,3,4 , =3,then = [0,0,1,0]</p>
    <p>Perturb each bit independently</p>
    <p>= /2</p>
    <p>/2+1 , =</p>
    <p>/2+1  Pr (  )=</p>
    <p>Pr (  )= =</p>
    <p>]Pr[[]|</p>
    <p>]Pr[[]| = (1)</p>
    <p>(1) =</p>
    <p>Since  is unary encoding of , and  differ in two locations</p>
    <p>Intuition:  By unary encoding, each location can only be 0 or 1, effectively reducing  in</p>
    <p>each location to 2.  When  is large, UE is better.</p>
    <p>To estimate frequency of each value, do it for each bit.</p>
  </div>
  <div class="page">
    <p>The protocol description itself is more complicated  Now we describe a simpler equivalent  Each user uses a random hash function from  to 0,1  The user then perturbs the bit with probabilities</p>
    <p>=</p>
    <p>+1 =</p>
    <p>+1 , =</p>
    <p>+1 =</p>
    <p>+1  Pr (  )=</p>
    <p>Pr (  )= =</p>
    <p>=</p>
    <p>The user then reports the bit and the hash function  The aggregator increments the reported group</p>
    <p>[] =  +   ( 1</p>
    <p>Unbiased Estimation: ()=</p>
    <p>1</p>
    <p>Binary Local Hash</p>
    <p>={,,,}</p>
    <p>Group 0</p>
    <p>Group 1=2</p>
    <p>[,,,] + 1 + 1</p>
    <p>Group 1={2,4}</p>
  </div>
  <div class="page">
    <p>Takeaway</p>
    <p>Key Question:  Maximize utility of frequency estimation under LDP</p>
    <p>Key Idea:  A framework to generalize and optimize these protocols</p>
    <p>Results:  Optimized Unary Encoding and Local Hash</p>
    <p>By improving the frequency estimator, results in other more complicated settings that use LDP can be improved, e.g., private learning, frequent itemset mining, etc.</p>
  </div>
  <div class="page">
    <p>Method</p>
    <p>We measure utility of a mechanism by its variance</p>
    <p>E.g., in Random Response,    =</p>
    <p>= []</p>
    <p>2  (1)</p>
    <p>2</p>
    <p>We propose a framework called pure and cast existing mechanisms into the framework.</p>
    <p>For each output , define a set of input  called Support  Intuition: each output votes for a set of input</p>
    <p>After perturbation, output  will support input from Support</p>
    <p>E.g., In BLH, Support() =    =</p>
    <p>Define  and  such that (  ) support w/p  and dont w/p   E.g., In Random Response, =, =</p>
    <p>Pure means this holds for all input-output pairs</p>
  </div>
  <div class="page">
    <p>Method</p>
    <p>We measure utility of a mechanism by its variance</p>
    <p>E.g., in Random Response,    =</p>
    <p>= []</p>
    <p>2  (1)</p>
    <p>2</p>
    <p>We propose a framework called pure and cast existing mechanisms into the framework.</p>
    <p>For each output , define a set of input  called Support  Intuition: each output votes for a set of input</p>
    <p>After perturbation, output  will support input from Support</p>
    <p>E.g., In BLH, Support() =    =</p>
    <p>Define  and  such that (  ) support w/p  and dont w/p   E.g., In Random Response, =, =</p>
    <p>Pure means this holds for all input-output pairs</p>
    <p>or  (1)</p>
    <p>2</p>
    <p>where , satisfy -LDP</p>
  </div>
  <div class="page">
    <p>Optimized UE</p>
    <p>In the original UE, each bit is perturbed independently</p>
    <p>= /2</p>
    <p>/2+1 , =</p>
    <p>/2+1</p>
    <p>We want to make  higher.</p>
    <p>Key Insight: We perturb 0 and 1 differently!</p>
    <p>There are more 0, so we perturb with greater ; there is a single 1, so we perturb with smaller</p>
    <p>For bit 0: 0 =</p>
    <p>+1 ,0 =</p>
    <p>+1</p>
    <p>For bit 1: 1 = 1</p>
    <p>Pr (  )=</p>
    <p>Pr (  )= =</p>
    <p>]Pr[[]|</p>
    <p>]Pr[[]| =  0 (1</p>
    <p>0 (1</p>
  </div>
  <div class="page">
    <p>Optimized Local Hash (OLH)</p>
    <p>In original BLH, secret is compressed into a bit, perturbed and transmitted.</p>
    <p>=</p>
    <p>+1 , =</p>
    <p>+1  Pr (  )=</p>
    <p>Pr (  )= =</p>
    <p>= (=2 groups)</p>
    <p>Two steps that cause information loss:  Compressing: loses much  Perturbation: pretty accurate</p>
    <p>Key Insight: We want to make a balance between the two steps:  By compressing into more groups, the first step carries more information</p>
    <p>Variance is optimized when = +1</p>
    <p>Read our paper for details!</p>
  </div>
  <div class="page">
    <p>Comparison of Different Mechanisms</p>
    <p>OUE and OLH have the same variance But OLH has smaller communication cost</p>
    <p>Direct Encoding has greater variance with larger</p>
  </div>
  <div class="page">
    <p>Limitations  Variance is linear in , which seems inevitable</p>
    <p>Therefore, requires large number of users</p>
    <p>Cannot handle large domains</p>
    <p>Future Work  Handling large domains</p>
    <p>Handling set-values</p>
    <p>Conclusion  We survey existing LDP protocols on frequency estimation</p>
    <p>We propose a pure framework and cast existing protocols into it</p>
    <p>We optimize UE and BLH and come up with OUE and OLH</p>
  </div>
  <div class="page">
    <p>Backup: Experiments Highlights</p>
    <p>Dataset: Kosarak dataset  (also on Rockyou dataset and a Synthetic dataset)</p>
    <p>Competitors: RAPPOR, BLH, OLH  Randomized Response is not compared because the domain is large</p>
    <p>Key Results:  OLH performs magnitudes better, especially when  is large</p>
    <p>This also confirms our analytical conclusion</p>
  </div>
  <div class="page">
    <p>Backup: Accuracy on Frequent Values</p>
    <p>More Privacy</p>
    <p>M o</p>
    <p>re A</p>
    <p>cc u</p>
    <p>ra cy</p>
    <p>RAPPOR2  = 7.78</p>
    <p>RAPPOR1  = 4.39</p>
  </div>
  <div class="page">
    <p>Backup: On Information Quality</p>
  </div>
  <div class="page">
    <p>Backup: On answering multiple questions</p>
    <p>Previously works (including centralized DP) suggest splitting privacy budget</p>
    <p>For example, when a user answers two questions, privacy budgets are /2 and /2 (assuming the two questions are of equal importance)</p>
    <p>In the centralized setting, there are sequential composition and parallel composition</p>
    <p>By partitioning users, one uses to parallel composition</p>
    <p>By split privacy budget, one uses sequential composition</p>
    <p>The two can basically produce equivalent results</p>
    <p>What about the local setting?</p>
  </div>
  <div class="page">
    <p>Backup: On answering multiple questions</p>
    <p>Measure the frequency accuracy (normalize since two approach have different number of users)</p>
    <p>Assuming OLH is used:    / = (1)</p>
    <p>2 =</p>
    <p>1 2</p>
    <p>Two settings:</p>
    <p>Split privacy budget:    / = 4/2</p>
    <p>/21 2</p>
    <p>Partition users:    / 1</p>
    <p>1 2</p>
    <p>Algebra shows that it is better to partition users</p>
  </div>
  <div class="page">
    <p>// | ?</p>
    <p>Thanks to my coauthors</p>
  </div>
</Presentation>
