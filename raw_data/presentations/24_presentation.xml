<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Language Identification from Language Identification from Text Using Cumulative Text Using Cumulative</p>
    <p>Frequency AdditionFrequency Addition</p>
    <p>Bashir AhmedBashir Ahmed Student/Faculty Research DayStudent/Faculty Research Day</p>
    <p>Pace UniversityPace University May 07, 2004May 07, 2004</p>
  </div>
  <div class="page">
    <p>Problem StatementProblem Statement</p>
    <p>Existing Text-to-Speech (TTS) systems fail to Existing Text-to-Speech (TTS) systems fail to recognize foreign words in written Text. As a result, recognize foreign words in written Text. As a result, they try to sound foreign lingual words that are they try to sound foreign lingual words that are embedded in native text using native lexicon. This embedded in native text using native lexicon. This causes poor TTS conversion, and unpleasant causes poor TTS conversion, and unpleasant sounding of foreign words with garbled meaning. To sounding of foreign words with garbled meaning. To be really useful in production environment, a great be really useful in production environment, a great deal of improvement is necessary in the current TTS deal of improvement is necessary in the current TTS technology such as recognition of foreign words and technology such as recognition of foreign words and their proper sounding using the correct lexicon. The their proper sounding using the correct lexicon. The proposal in this thesis is to investigate a solution to proposal in this thesis is to investigate a solution to detect language shift in written text which can be detect language shift in written text which can be useful for TTS modules to switch to the proper useful for TTS modules to switch to the proper lexicon. lexicon.</p>
    <p>http://www.naturalvoices.att.com/demos/</p>
  </div>
  <div class="page">
    <p>What Do We Need?What Do We Need?</p>
    <p>To be able to detect language shift in a written To be able to detect language shift in a written document, we must be able to detect the document, we must be able to detect the major language first. So, we need a Language major language first. So, we need a Language Identifier.Identifier.</p>
    <p>The Language Identifier must be efficient  this The Language Identifier must be efficient  this is my focus at this early stage of my research.is my focus at this early stage of my research.</p>
    <p>Existing language Identifiers such as Ngram Existing language Identifiers such as Ngram based rank-order statistics and Nave Bayesian based rank-order statistics and Nave Bayesian classifiers work well, but they have their pros classifiers work well, but they have their pros and cons. and cons.</p>
  </div>
  <div class="page">
    <p>Approaches to Language Approaches to Language IdentificationIdentification</p>
    <p>Dictionary Based ApproachDictionary Based Approach</p>
    <p>Machine Learning (ML) ApproachMachine Learning (ML) Approach</p>
  </div>
  <div class="page">
    <p>ML Approach to Language ML Approach to Language Identification Identification</p>
    <p>Feature Extraction From Training SamplesFeature Extraction From Training Samples  Ngram Based Approach (i.e. The, Th, e, he etc)Ngram Based Approach (i.e. The, Th, e, he etc)  Unique Word Endings (i.e. cchi in Italian, vnd in Unique Word Endings (i.e. cchi in Italian, vnd in</p>
    <p>Dutch)Dutch)</p>
    <p>Grammatical Words / Common Short Words (the in Grammatical Words / Common Short Words (the in English, es in French)English, es in French)</p>
    <p>ASCII Feature VectorASCII Feature Vector</p>
    <p>Classification Using Proven AlgorithmClassification Using Proven Algorithm  Ngram Rank-Order StatisticsNgram Rank-Order Statistics  Bayesian Decision Rules - Nave Bayesian ClassifiersBayesian Decision Rules - Nave Bayesian Classifiers  Our New Classifier  Cumulative Frequency AdditionOur New Classifier  Cumulative Frequency Addition</p>
  </div>
  <div class="page">
    <p>Ngram Based Rank-Order Ngram Based Rank-Order StatisticsStatistics</p>
    <p>ProsPros  Insensitive to Insensitive to</p>
    <p>typographical errorstypographical errors  Works better than other Works better than other</p>
    <p>classifiers when dealing classifiers when dealing with shorter stringswith shorter strings</p>
    <p>ConsCons  Relatively Slower due to Relatively Slower due to</p>
    <p>counting and sorting of counting and sorting of NgramsNgrams</p>
    <p>Most Most FrequentFrequent</p>
    <p>THTH THTH 00</p>
    <p>ERER INGING 33</p>
    <p>ONON ONON 00</p>
    <p>LELE ERER 22</p>
    <p>INGING ANDAND 11</p>
    <p>Least Least FrequentFrequent</p>
    <p>ANDAND EDED No-match = No-match = max distancemax distance</p>
  </div>
  <div class="page">
    <p>Bayesian Decision RulesBayesian Decision Rules</p>
    <p>Given the task of deciding which of two possible phenomena have caused a Given the task of deciding which of two possible phenomena have caused a particular observation, we can minimize our probability of error by computing particular observation, we can minimize our probability of error by computing which is most likely to have given rise to the observation. Given observation which is most likely to have given rise to the observation. Given observation X, if we were to choose between A and B, we can use Bayes Theorem:X, if we were to choose between A and B, we can use Bayes Theorem:</p>
    <p>P(A,X) =p(A|X) * p(X), Since p(X) =1, P(A,X) =p(A|X) = p(X/A) * p(A)P(A,X) =p(A|X) * p(X), Since p(X) =1, P(A,X) =p(A|X) = p(X/A) * p(A) Similarly P(B,X) =p(X/B) * p(B)Similarly P(B,X) =p(X/B) * p(B) P(A), P(B) are prior probabilities, P(A), P(B) are prior probabilities, p(X|B) is the likelihood of X belonging to B. p(X|B) is the likelihood of X belonging to B.</p>
    <p>Calculating the likelihood is not so trivial. However, the calculation can be Calculating the likelihood is not so trivial. However, the calculation can be simplified by assuming that component probabilities are independent of each simplified by assuming that component probabilities are independent of each other and thus, they can be multiplied to get the likelihood. This is called other and thus, they can be multiplied to get the likelihood. This is called Nave Bayesian AssumptionNave Bayesian Assumption and used successfully in Language and used successfully in Language Classification.Classification.</p>
    <p>For Language classification, you simply multiply the probabilities of each matching Ngrams in the training database and select the language that produces the highest result.</p>
  </div>
  <div class="page">
    <p>Cumulative Frequency Cumulative Frequency AdditionAddition  Add the frequencies of all matching Add the frequencies of all matching</p>
    <p>Ngrams in the training database and Ngrams in the training database and decide based on which language have decide based on which language have given rise to the highest weight.given rise to the highest weight.</p>
    <p>Pros</p>
    <p>Extremely Simple</p>
    <p>Efficient</p>
    <p>More accurate than NBC with smaller string</p>
    <p>Cons</p>
    <p>Needs a large training set</p>
    <p>Performance may not be as good with smaller training set</p>
    <p>Demo</p>
  </div>
  <div class="page">
    <p>SummarySummary</p>
    <p>Ngram Based language identification can be useful even Ngram Based language identification can be useful even when there are typographical errors in the text.when there are typographical errors in the text.</p>
    <p>Even though Rank-order statistical method is accurate with Even though Rank-order statistical method is accurate with smaller strings, it may not be so useful when the analysis smaller strings, it may not be so useful when the analysis requires large string processing.requires large string processing.</p>
    <p>Nave Bayesian Classifiers are efficient, but they require Nave Bayesian Classifiers are efficient, but they require large test string to get correct classification.large test string to get correct classification.</p>
    <p>Cumulative frequency addition is simple, accurate and Cumulative frequency addition is simple, accurate and efficient, but it may not work well with smaller training set. efficient, but it may not work well with smaller training set. Further investigation is necessary!Further investigation is necessary!</p>
  </div>
</Presentation>
