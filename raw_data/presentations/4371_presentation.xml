<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Syntax for Semantic Role Labeling,</p>
    <p>To Be, Or Not To Be</p>
    <p>Shexia He1,2, Zuchao Li1,2, Hai Zhao1,2,*, Hongxiao Bai1,2</p>
    <p>and Cognitive Engineering, China</p>
  </div>
  <div class="page">
    <p>Semantic Role Labeling (SRL)</p>
    <p>SRL - a shallow semantic parsing task: recognize the predicate-argument</p>
    <p>structure, such as who did what to whom, where and when, etc.</p>
    <p>Four subtasks</p>
    <p>Predicate identification and disambiguation</p>
    <p>Argument identification and classification</p>
    <p>Applications:</p>
    <p>Machine Translation</p>
    <p>Information Extraction</p>
    <p>Question Answering, etc.</p>
  </div>
  <div class="page">
    <p>SRL - Example</p>
    <p>Two formulizations of predicate-argument structure:</p>
    <p>Span-based (i.e., phrase or constituent)</p>
    <p>Dependency-based: head of arguments</p>
    <p>Marry borrowed a book from john last week</p>
    <p>borrow.01 A0 A1 A2 AM-TMP</p>
    <p>Marry borrowed a book from john last week</p>
    <p>borrow.01 A0 A1 A2 AM-TMP</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>Previous methods</p>
    <p>Traditional Neural network</p>
    <p>Pradhan et al. (2005) utilized a SVM classifier Rot h and Yih ( 2005) employe d C R F w i t h integer linear programming Punyakanok et al. (2008) enforced global consistency with ILP Zhao et al. (2009) proposed a huge feature engineering method</p>
    <p>Zhou and Xu (2015) introduced deep bidirectional RNN model Roth and Lapata (2016) proposed PathLSTM modeling approach He et al. (2017) used deep highway BiLSTM with constrained decoding Marcheg giani et al. (2017) presented a simple BiLSTM model Marcheggiani and Titov (2017) proposed a GCN-based SRL model</p>
  </div>
  <div class="page">
    <p>Focus - Dependency SRL</p>
    <p>Syntax-aware:  Maximum entropy model (Zhao et al., 2009)  Path embedding (Roth and Lapata, 2016)  Graph convolutional network (Marcheggiani and Titov, 2017)</p>
    <p>Syntax-agnostic:  The simple BiLSTM (Marcheggiani et al., 2017)</p>
  </div>
  <div class="page">
    <p>Method - Overview</p>
    <p>Pipeline</p>
    <p>Predicate Disambiguation &amp; Argument Labeling</p>
    <p>Sequence labeling: BiLSTM - MLP</p>
    <p>Enhanced representation: ELMo</p>
    <p>Argument Labeling Model</p>
    <p>Preprocessing: k-order pruning</p>
  </div>
  <div class="page">
    <p>Initialization: Set the marked predicate as the current node;</p>
    <p>1. Collect all its descendant node as argument candidates,</p>
    <p>which is at most k syntactically distant from the current node.</p>
    <p>2. Reset the current node to its syntactic head and repeat step 1</p>
    <p>until the root is reached.</p>
    <p>3. Collect the root and stop.</p>
    <p>k-order argument pruning</p>
    <p>Reference: Zhao et al., 2009 7</p>
  </div>
  <div class="page">
    <p>CoNLL-2009 English development set</p>
    <p>syntax-aware syntax-agnostic</p>
    <p>CoNLL-2009 English training set</p>
  </div>
  <div class="page">
    <p>CoNLL-2009 Results</p>
    <p>Models English Chinese OOD</p>
    <p>Non-NN Zhao et al., 2009 86.2 77.7 74.6 Bjorkelund et al., 2010 85.8 78.6 73.9</p>
    <p>NN syntax-aware</p>
    <p>Lei et al., 2015 86.6 - 75.6 FitzGerald et al., 2015 86.7 - 75.2 Roth and Lapata, 2016 86.7 79.4 75.3 Marcheggiani and Titov, 2017 88.0 82.5 77.2 Ours 89.5 82.8 79.3</p>
    <p>NN syntax-agnostic</p>
    <p>Marcheggiani et al., 2017 87.7 81.2 77.7 Ours 88.7 81.8 78.8</p>
    <p>Results on CoNLL-2009 English, Chinese and out-of-domain (OOD) test set.</p>
  </div>
  <div class="page">
    <p>End-to-end SRL  Integrate predicate disambiguation and argument labeling</p>
    <p>CoNLL-2009 results</p>
    <p>Models F1</p>
    <p>syntax-agnostic end-to-end 88.4</p>
    <p>pipeline 88.7</p>
    <p>syntax-aware end-to-end 89.0</p>
    <p>pipeline 89.5</p>
    <p>Results of end-to-end model on the CoNLL-2009 data. 10</p>
  </div>
  <div class="page">
    <p>CoNLL-2008 Results</p>
    <p>Results on the CoNLL-2008 in-domain test set.</p>
    <p>Models LAS Sem-F1 Johansson and Nugues, 2008 90.13 81.75 Zhao and Kit, 2008 87.52 77.67 Zhao et al, 2009 88.39 82.1</p>
    <p>Indispensable task: predicate identification</p>
  </div>
  <div class="page">
    <p>Syntactic Role</p>
    <p>Different syntax-aware SRL models may adopt different syntactic parser</p>
    <p>PathLSTM SRL (Roth and Lapata, 2016): mate-tools</p>
    <p>GCN-based SRL (Marcheggiani and Titov, 2017): BIST Parser</p>
    <p>How to quantitatively evaluate the syntactic contribution to SRL?</p>
    <p>Evaluation Measure: the Sem-F1 / LAS ratio</p>
    <p>Sem-F1: the labeled F1 score for semantic dependencies</p>
    <p>LAS: the labeled attachment score for syntactic dependencies</p>
    <p>Reference: Surdeanu et al., CoNLL-2008 Shared Task 12</p>
  </div>
  <div class="page">
    <p>Performance Comparison</p>
    <p>Sem-F1/LAS ratio on CoNLL-2009 English test set.</p>
    <p>Models LAS Sem-F1 Sem-F1/LAS Zhao et al, 2009 [CoNLL SRL-only] 86.0 85.4 99.3 Zhao et al, 2009 [CoNLL Joint] 89.2 86.2 96.6 Bjorkelund et al, 2010 89.8 85.8 95.6 Lei et al, 2015 90.4 86.6 95.8 Roth and Lapata, 2016 89.8 86.7 96.5 Marcheggiani and Titov, 2017 90.3 88.0 97.5 Ours + CoNLL-2009 predicted 86.0 89.5 104.0 Ours + Auto syntax 90.0 89.9 99.9 Ours + Gold syntax 100.0 90.3 90.3</p>
  </div>
  <div class="page">
    <p>Faulty Syntactic Tree Generator</p>
    <p>How to obtain syntactic input of different quality?</p>
    <p>A Faulty Syntactic Tree Generator (STG)</p>
    <p>Produce random errors in the output parse tree</p>
    <p>STG implementation</p>
    <p>Given an input error probability distribution</p>
    <p>Modify the syntactic heads of nodes</p>
  </div>
  <div class="page">
    <p>Sem-F1 - LAS Curve</p>
    <p>Syntactic inputs generated from STG</p>
    <p>The 10th-order SRL gives quite stable</p>
    <p>results regardless of syntactic quality</p>
    <p>The 1st-order SRL model yields overall</p>
    <p>lower performance</p>
    <p>Better syntax could result in better SRL</p>
  </div>
  <div class="page">
    <p>Conclusion and Future Work</p>
    <p>We present an effective model for dependency SRL with extended k-order pruning.</p>
    <p>The gap between syntax-enhanced and -agnostic SRL has been greatly reduced,</p>
    <p>from as high as 10% to only 1-2% performance loss.</p>
    <p>High-quality syntactic parses indeed enhance SRL.</p>
    <p>Future work:</p>
    <p>Develop a more effective syntax-agnostic SRL system.</p>
    <p>Explore syntactic integration method based on high-quality syntax.</p>
  </div>
  <div class="page">
    <p>Thank You!</p>
    <p>{heshexia, charlee}@sjtu.edu.cn</p>
    <p>Code is publicly available at:</p>
    <p>https://github.com/bcmi220/srl_syn_pruning</p>
  </div>
</Presentation>
