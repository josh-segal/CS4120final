<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>k-fingerprinting: a Robust Scalable Website Fingerprinting Technique</p>
    <p>Jamie Hayes George Danezis</p>
    <p>University College London</p>
    <p>August 12, 2016</p>
  </div>
  <div class="page">
    <p>How does website fingerprinting work? - Training</p>
    <p>Adversary</p>
    <p>Tor network</p>
    <p>Relay1</p>
    <p>Relay2</p>
    <p>Relay3</p>
    <p>Create fingerprints for , and</p>
  </div>
  <div class="page">
    <p>How does website fingerprinting work? - Attack</p>
    <p>Client</p>
    <p>Tor network</p>
    <p>Relay1</p>
    <p>Relay2</p>
    <p>Relay3</p>
    <p>Adversary</p>
    <p>www</p>
    <p>Adversary checks if fingerprint of is equal to fingerprint of</p>
    <p>or or</p>
  </div>
  <div class="page">
    <p>Experimental Attack set-up</p>
    <p>Access only: Access any:</p>
    <p>Closed World Open World</p>
  </div>
  <div class="page">
    <p>Contributions</p>
    <p>k-FP - New attack based on Random Forests and k-NN1</p>
    <p>An analysis of the features used in this and prior work to determine which yield the most information about an encrypted or anonymized webpage.</p>
    <p>Large open world setting. In total we tested k-FP on 101,130 unique webpages.</p>
    <p>Experimented with both standard websites and Tor hidden services.</p>
  </div>
  <div class="page">
    <p>Feature Analysis</p>
    <p>Features need to be drawn from a diverse set to bypass targeted WF defenses.</p>
    <p>F e a tu</p>
    <p>re i m</p>
    <p>p o rt</p>
    <p>a n c e s</p>
    <p>c o re</p>
    <p>The best features were number of packets (incoming/outgoing) and information leaked from the first few seconds of loading a webpage.</p>
  </div>
  <div class="page">
    <p>k-FP Attack</p>
    <p>Train on a classification task with network traffic information as features.</p>
    <p>Use Random Forest output as the fingerprint of a website load.</p>
    <p>Then use k-NN for classification.</p>
  </div>
  <div class="page">
    <p>Base Rate</p>
    <p>Previous attacks had very high True Positive Rate (TPR) and very low False Positive Rate (FPR), but as the number of samples rises so too will the false alarms.</p>
    <p>As the number of samples grows, the vast majority of alarms will be false positives.</p>
  </div>
  <div class="page">
    <p>Base Rate</p>
    <p>FPR needs to be very low for an accurate attack as more fingerprints are tested.</p>
    <p>Suppose we have a FPR of 1%.</p>
    <p>If a client loads 100 unmonitored webpages. Then the attacker will mark 1 webpages incorrectly as monitored.</p>
    <p>If a client load 1,000,000 unmonitored webpages. Then the attacker will mark 10,000 webpages incorrectly as monitored.</p>
  </div>
  <div class="page">
    <p>Accuracy metrics</p>
    <p>TPR - The probability that a monitored page is classified as the correct monitored page.</p>
    <p>FPR - The probability that an unmonitored page is incorrectly classified as a monitored page.</p>
    <p>BDR - The probability that a page corresponds to the correct monitored page given that the classifier recognized it as that monitored page.</p>
    <p>Assuming a uniform distribution of pages BDR can be found from TPR and FPR using the formula</p>
    <p>TPR  Pr(M) (TPR  Pr(M) + FPR  Pr(U))</p>
    <p>where</p>
    <p>Pr(M) = |Monitored| |Total Pages|</p>
    <p>, Pr(U) = 1 P(M).</p>
  </div>
  <div class="page">
    <p>Tor hidden services</p>
    <p>Protects receiver anonymity in addition to sender anonymity.</p>
    <p>Sensitive servers such as SecureDrop use Tor hidden services.</p>
  </div>
  <div class="page">
    <p>Tor hidden services</p>
    <p>Client</p>
    <p>Tor network</p>
    <p>Adversary</p>
    <p>www</p>
  </div>
  <div class="page">
    <p>Tor hidden services</p>
    <p>Client</p>
    <p>Tor network</p>
    <p>IP</p>
    <p>Adversary</p>
    <p>www</p>
  </div>
  <div class="page">
    <p>Tor hidden services</p>
    <p>Client</p>
    <p>Tor network</p>
    <p>RP</p>
    <p>IP</p>
    <p>Adversary</p>
    <p>www</p>
  </div>
  <div class="page">
    <p>Tor hidden services</p>
    <p>Client</p>
    <p>Tor network</p>
    <p>RP</p>
    <p>IP</p>
    <p>Adversary</p>
    <p>www</p>
  </div>
  <div class="page">
    <p>Tor hidden services</p>
    <p>Client</p>
    <p>Tor network</p>
    <p>RP</p>
    <p>IP</p>
    <p>Adversary</p>
    <p>www</p>
  </div>
  <div class="page">
    <p>Prelims</p>
    <p>All traffic was collected via Tor.</p>
    <p>Monitored websites by the Adversary - Alexa Sites (Google, Facebook, Wikipedia etc.) &amp; popular Tor Hidden Services</p>
    <p>Only collected landing page of each website.</p>
    <p>Alexa monitored set consisted of 100 samples for each of 55 websites.</p>
    <p>Hidden Services monitored set consisted of 80 samples for each of 30 Hidden Services.</p>
    <p>Extra sites for testing purposes - 100,000 websites (chosen from top Alexa list).</p>
  </div>
  <div class="page">
    <p>Parameter tuning - number of neighbours and number of trees</p>
    <p>Number of neighbours Number of Trees</p>
    <p>T ru</p>
    <p>e p</p>
    <p>o si</p>
    <p>ti v e</p>
    <p>Max accuracy Min accuracy</p>
    <p>A c c u ra</p>
    <p>c y</p>
    <p>True positive rate False positive rate</p>
    <p>Using different k, the number of neighbours allows us to tune the TPR and FPR.</p>
    <p>After adding 15 decision trees only incremental benefit in adding more.</p>
  </div>
  <div class="page">
    <p>Alexa monitored set results</p>
    <p>T ru</p>
    <p>e p</p>
    <p>o si</p>
    <p>ti v e r</p>
    <p>a te</p>
    <p>k=1 k=5 k=10</p>
    <p>F a ls</p>
    <p>e p</p>
    <p>o si</p>
    <p>ti v e r</p>
    <p>a te</p>
  </div>
  <div class="page">
    <p>Tor hidden service monitored set results</p>
    <p>T ru</p>
    <p>e p</p>
    <p>o si</p>
    <p>ti v e r</p>
    <p>a te</p>
    <p>k=1 k=5 k=10</p>
    <p>F a ls</p>
    <p>e p</p>
    <p>o si</p>
    <p>ti v e r</p>
    <p>a te</p>
  </div>
  <div class="page">
    <p>BDR</p>
    <p>Tor Hidden Services Monitored set.</p>
    <p>a y e si</p>
    <p>a n d</p>
    <p>e te</p>
    <p>c ti</p>
    <p>o n r</p>
    <p>a te</p>
    <p>k=1 k=5 k=10</p>
    <p>B a y e si</p>
    <p>a n d</p>
    <p>e te</p>
    <p>c ti</p>
    <p>o n r</p>
    <p>a te</p>
    <p>Alexa Monitored set.</p>
  </div>
  <div class="page">
    <p>Limitations</p>
    <p>The BDR implicitly assumes a base rate, with no particular backing in reality. - We assume uniform expectation of visiting a webpage.</p>
    <p>I would like to better understand how these techniques would work if the attacker did not know the start/stop time that the user visits each website. - Website fingerprinting evaluation may not reflect practical risks.</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>The open world is not as much of a problem as we had thought, and using state-of-the-art machine learning we expect to be able to tackle other obstacles such as start-stop time identification and multiple tabs.</p>
    <p>Attack is highly accurate over a large number of webpages.</p>
    <p>Distiguishability between Tor Hidden Services and Non Tor Hidden Services.</p>
  </div>
  <div class="page">
    <p>Thanks</p>
    <p>Questions?</p>
    <p>j.hayes@cs.ucl.ac.uk</p>
    <p>@_jamiedh</p>
    <p>http://www.homepages.ucl.ac.uk/~ucabaye/</p>
  </div>
</Presentation>
