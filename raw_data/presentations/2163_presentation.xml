<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Quartet: Harmonizing task scheduling and caching for cluster computing</p>
    <p>Francis Deslauriers, Peter McCormick, George Amvrosiadis, Ashvin Goel &amp;</p>
    <p>Angela Demke Brown</p>
    <p>June 23, 2016</p>
  </div>
  <div class="page">
    <p>Analyses for the masses</p>
    <p>Data collection is cheap, so datasets are growing exponentially  Cluster computing makes it easy to analyze these datasets, enabling:</p>
    <p>Queries on entire datasets  Analysts running queries on the same corpus  Tuning queries</p>
  </div>
  <div class="page">
    <p>Data is often re-accessed</p>
    <p>Result is many queries running on the same large datasets  Leads to significant data reuse</p>
    <p>F il e a</p>
    <p>c c e s s f</p>
    <p>re q</p>
    <p>u e n c y</p>
    <p>Input file rank by descending access frequency</p>
    <p>CC-b</p>
    <p>CC-c</p>
    <p>CC-d</p>
    <p>CC-e</p>
    <p>FB-2010</p>
    <p>Facebook, and Cloudera customers [VLDB12]</p>
    <p>Cumulative distribution</p>
    <p>of input paths</p>
    <p>C D</p>
    <p>F o</p>
    <p>f p a th</p>
    <p>a c c e s s e s</p>
    <p>OpenCloud</p>
    <p>M45</p>
    <p>WebMining</p>
    <p>CMU academic clusters [VLDB13]</p>
  </div>
  <div class="page">
    <p>Data is often re-accessed</p>
    <p>Result is many queries running on the same large datasets  Leads to significant data reuse</p>
    <p>F il e a</p>
    <p>c c e s s f</p>
    <p>re q</p>
    <p>u e n c y</p>
    <p>Input file rank by descending access frequency</p>
    <p>CC-b</p>
    <p>CC-c</p>
    <p>CC-d</p>
    <p>CC-e</p>
    <p>FB-2010</p>
    <p>Facebook, and Cloudera customers [VLDB12]</p>
    <p>Cumulative distribution</p>
    <p>of input paths</p>
    <p>C D</p>
    <p>F o</p>
    <p>f p a th</p>
    <p>a c c e s s e s</p>
    <p>OpenCloud</p>
    <p>M45</p>
    <p>WebMining</p>
    <p>CMU academic clusters [VLDB13]</p>
  </div>
  <div class="page">
    <p>Data reuse does not help</p>
    <p>We should expect data reuse improves performance due to caching  We find that jobs do not see the benefits of reuse</p>
  </div>
  <div class="page">
    <p>Example: Repeating a Hadoop job</p>
  </div>
  <div class="page">
    <p>Example: Repeating a Hadoop job</p>
  </div>
  <div class="page">
    <p>Example: Repeating a Hadoop job</p>
  </div>
  <div class="page">
    <p>Example: Repeating a Hadoop job</p>
  </div>
  <div class="page">
    <p>Example: Repeating a Hadoop job</p>
  </div>
  <div class="page">
    <p>Example: Repeating a Hadoop job</p>
  </div>
  <div class="page">
    <p>Example: Repeating a Hadoop job</p>
  </div>
  <div class="page">
    <p>Missed Opportunities</p>
    <p>Working sets dont fit in the page cache  Jobs consume data independently of one another</p>
  </div>
  <div class="page">
    <p>Solution</p>
    <p>Key idea  Reorder work to first consume cached data  Jobs are made of small tasks with no ordering requirements</p>
    <p>Challenges  Cache visibility: Jobs need to know what data is cached on the different nodes  Task reordering: Jobs need to reorder their tasks based on this knowledge</p>
    <p>Our Quartet system addresses both these challenges</p>
  </div>
  <div class="page">
    <p>Challenge 1: Cache Visibility</p>
    <p>Datanodes collect information about HDFS blocks that reside in memory</p>
    <p>Requires the Duet kernel module that informs applications when pages are cached or evicted</p>
    <p>Nodes send this information periodically to the Quartet Manager  Changes to the number of resident pages of each</p>
    <p>block</p>
  </div>
  <div class="page">
    <p>Challenge 2: Task Reordering</p>
  </div>
  <div class="page">
    <p>Example: Repeating a Hadoop job</p>
  </div>
  <div class="page">
    <p>Example: Repeating a Hadoop job</p>
  </div>
  <div class="page">
    <p>Example: Repeating a Hadoop job</p>
  </div>
  <div class="page">
    <p>Example: Repeating a Hadoop job</p>
  </div>
  <div class="page">
    <p>Example: Repeating a Hadoop job</p>
  </div>
  <div class="page">
    <p>Experiments</p>
    <p>Spark and Hadoop implementations  24 nodes with a total of 384 GB of memory  Different input sizes:</p>
    <p>Smaller than physical memory (256 GB)  Slightly larger (512 GB)  Approximately 3 times (1024 GB)</p>
    <p>3 replicas per block</p>
  </div>
  <div class="page">
    <p>Results - Cache Hit Rate of the second job</p>
    <p>Hadoop Spark C</p>
    <p>a ch</p>
    <p>e h</p>
    <p>it ra</p>
    <p>te (</p>
    <p>% )</p>
    <p>Job size</p>
    <p>Baseline Quartet</p>
  </div>
  <div class="page">
    <p>Results - Runtime reduction of the second job</p>
    <p>Hadoop Spark N</p>
    <p>o rm</p>
    <p>a liz</p>
    <p>e d</p>
    <p>r u</p>
    <p>n tim</p>
    <p>e o</p>
    <p>f se</p>
    <p>co n</p>
    <p>d jo</p>
    <p>b (</p>
    <p>% )</p>
    <p>Job size</p>
    <p>Baseline Quartet</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Observation: Workloads show significant amount of reuse  Problem: Jobs are unable to take advantage of this reuse  Solution:</p>
    <p>Add visibility on what is cached in each of the cluster nodes  Reorder tasks to take advantage of this cached data</p>
    <p>Future work: More realistic workloads and scalability</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Thank you!</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Questions?</p>
  </div>
  <div class="page">
    <p>Network Overhead</p>
    <p>Watchers updates are aggregated per HDFS blocks (128-256MB)  Upper bound is the storage bandwidth  Manager notifications is proportional to the size of the input and hardware</p>
    <p>10-100 KB/s in our experiments</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>HDFS Cache Manager</p>
    <p>Requires manual changes in case of change of popularity  Cant be used when input is larger than memory</p>
    <p>PACMan</p>
    <p>Avoiding stragglers in single wave of Mappers  Modify cache eviction policy to ensure that entire computation stages have memory</p>
    <p>locality</p>
  </div>
</Presentation>
