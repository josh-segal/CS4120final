<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Taming the Flying Cable Monster: A Topology Design and</p>
    <p>Optimization Framework for Data-Center Networks</p>
    <p>Jayaram Mudigonda Praveen Yalagandula Jeff Mogul</p>
    <p>HP Labs, Palo Alto, CA</p>
  </div>
  <div class="page">
    <p>Wiring Data Centers: A complex problem</p>
    <p>Goal: design a cost-effective network for a large data center</p>
    <p>Network Designer</p>
    <p>Topologies</p>
    <p>Cables</p>
    <p>Switches</p>
    <p>Rack Layouts</p>
  </div>
  <div class="page">
    <p>This paper</p>
    <p>Introduces a new research area: datacenter topology design and wiring  Characterizes the problem and exposes several challenges  Presents a novel framework, Perseus, for datacenter network design  Describes the workflow for finding a cost-effective network  Solves several novel optimization problems</p>
    <p>Disclaimers: This paper does not  Quantify precise costs of different network designs  Please do not believe the cost numbers we present in the paper  Compare general merits of different topologies  Consider all dimensions of the design space</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction</p>
    <p>Problem</p>
    <p>Perseus Framework</p>
    <p>Workflow, Topologies, Optimizations</p>
    <p>Results</p>
    <p>Further steps</p>
    <p>Summary</p>
  </div>
  <div class="page">
    <p>Topologies</p>
    <p>Trends:  Datacenters are becoming larger and larger  Need high bisection bandwidth: E.g., Map-Reduce, VM placement</p>
    <p>Traditional topologies (tree-like) are not scalable  Core switch is the bottleneck for bandwidth</p>
    <p>Data-center networks need newer multi-path topologies  That achieve high bisection bandwidth with limited port count switches  E.g., FatTree, HyperX, Bcube</p>
    <p>So far these topologies have not been feasible but for the advent of  Cheap high speed high port count switches  Multi-path forwarding techniques: VL2, SPAIN, PortLand, etc.</p>
  </div>
  <div class="page">
    <p>Problem: Design space too large for humans</p>
    <p>Many topologies to choose from  Several different topology families</p>
    <p>Several free parameters  large number of choices within each family  Switch port count  Number of servers per edge-switch  Link speeds</p>
    <p>Previous topology work: Mostly focused on a few logical metrics  Bisection bandwidth, Maximum number of hops, etc.</p>
    <p>But in practice, wiring becomes a complex problem 6</p>
    <p>Fat Tree HyperCube Clique HyperX</p>
  </div>
  <div class="page">
    <p>Wiring is a complex problem</p>
    <p>Goal is to maximize performance at minimum cost</p>
    <p>Bisection Bandwidth Worst-case Latency</p>
    <p>Reliability Serviceability Expandability</p>
    <p>Capital Operational Switches Cables Racks</p>
    <p>Physical Space Installation</p>
    <p>Power SKUs</p>
    <p>Administration (regular maintenance,</p>
    <p>fixing faults)</p>
  </div>
  <div class="page">
    <p>Real world constraints</p>
    <p>Face-plate size restricts number of switch connectors</p>
    <p>Cross-aisle cable trays can not be over every rack</p>
    <p>Rack plenum restricts the size of cable bundle</p>
    <p>Cable length restrictions: e.g., copper 10GbE has max range of ~10m</p>
  </div>
  <div class="page">
    <p>SFP+ Copper QSFP Copper QSFP+ Copper QSFP+ Optical</p>
    <p>Length (Meters)</p>
    <p>C os</p>
    <p>t/L an</p>
    <p>e ($</p>
    <p>) Sources: www.cablesondemand.com www.elpeus.com</p>
  </div>
  <div class="page">
    <p>Related work - I</p>
    <p>Classical topology analysis  Mainly focused on bisection bandwidth &amp; hop counts  Ahn et al. 2009: find HyperX topology with min # of switches that achieve a</p>
    <p>given bisection BW  Cabling complexity/cost was not considered</p>
    <p>Placement and routing problems are similar to those in VLSI at a high level  But different in details</p>
  </div>
  <div class="page">
    <p>Related work - II</p>
    <p>Popa et al 2010: Compared the cost of different DC network architectures  Did not focus on cost minimization in each topology family  Did not consider placement optimization problem  Assumed simpler model for cable costs</p>
    <p>Farrington et al 2009: Analyzed cabling issues for FatTree networks  Upper level switches and levels consolidated  Design using merchant silicon, with cables as traces on circuit boards</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction</p>
    <p>Problem</p>
    <p>Perseus Framework</p>
    <p>Workflow, Topologies, Optimizations</p>
    <p>Results</p>
    <p>Further steps</p>
    <p>Summary</p>
  </div>
  <div class="page">
    <p>Perseus</p>
    <p>Framework to assist network designers</p>
    <p>Defines design workflow</p>
    <p>Topology families - Extended Generalized Fat Trees - HyperX</p>
    <p>Perseus with Medusa's head - sculpture by Antonio Canova, 1801. Museo PioClementino, Roma. Courtesy: Wikipedia</p>
  </div>
  <div class="page">
    <p>Topology planning workflow</p>
    <p>Generate Candidate Topologies</p>
    <p>Generate Physical Layout</p>
    <p>Compute Design Cost</p>
    <p>Visualize Results</p>
    <p>User inputs</p>
    <p>User inputs:  Number of servers, Number of racks and rack layout restrictions  Bandwidth, Hop count  Available parts (switches, cables, racks) and cost models  One or more of topology families</p>
  </div>
  <div class="page">
    <p>Topology planning workflow</p>
    <p>Generate Candidate Topologies</p>
    <p>Generate Physical Layout</p>
    <p>Compute Design Cost</p>
    <p>Visualize Results</p>
    <p>User inputs</p>
    <p>Candidate logical topology generation:  Extended Generalized Fat Tree (EGFT)  Covered in this talk  HyperX  See paper  Our framework allows plugging in other topology generators</p>
  </div>
  <div class="page">
    <p>EGFT topology</p>
    <p>Extended Generalized Fat Tree topologies Parameters:  Number of levels, L  Aggregation factor at each level, Ml for 1 l L  Number of top switches in each module at each level, Cl for 1 l L  Number of links from top switch to each module, Kl for 1 l L</p>
    <p>l =3</p>
    <p>M1=2 C1=1 K1=1</p>
    <p>M2=2 C2=2 K2=1</p>
    <p>M3=2 C3=2 K3=2</p>
    <p>O1=1</p>
    <p>O2=1</p>
    <p>O3=1</p>
    <p>Oversubscription Level-2 module</p>
    <p>l =2</p>
    <p>l =1</p>
  </div>
  <div class="page">
    <p>Generating Candidate Topologies: EGFT</p>
    <p>Bottom-up exhaustive search  Given: N servers and R-port switches  For each level l, choose Ml Cl Kl  Requirement:</p>
    <p>Each top switch should connect to all Ml level (l -1) modules  Constraints:</p>
    <p>Ml  R Cl  number of free ports at level (l - 1) module = fl-1 Kl  R/Ml AND Kl  fl-1/Cl</p>
    <p>Search space can be huge  Example: With N=1024 and R=48, size &gt; 1 billion</p>
  </div>
  <div class="page">
    <p>EGFT: Heuristics to Prune Search Space</p>
    <p>H1: At the top level, use the maximum lag factor possible</p>
    <p>H2: Ignore all possibilities at a level that achieve lower oversubscription than at the lower levels</p>
    <p>H3: If all lower level modules can be aggregated into one module, then do not consider other possible aggregations</p>
    <p>H4: At the top level, use as many available switches as you can for the core switches</p>
  </div>
  <div class="page">
    <p>Effectiveness of EGFT Heuristics</p>
    <p>None H1 H2 H3 H4 All</p>
    <p>#Terminals/Edge Switch</p>
    <p>S ea</p>
    <p>rc h</p>
    <p>S pa</p>
    <p>ce S</p>
    <p>iz e</p>
    <p>Switch Radix #Servers</p>
  </div>
  <div class="page">
    <p>Topology planning workflow</p>
    <p>Generate Candidate Topologies</p>
    <p>Generate Physical Layout</p>
    <p>Compute Design Cost</p>
    <p>Visualize Results</p>
    <p>User inputs</p>
    <p>Logical Topology Switches Servers Links</p>
    <p>Physical Layout Racks: rows, # racks/row</p>
    <p>Positions for each Switch &amp; Server Type &amp; layout of cables</p>
    <p>Heuristics:  Avoid placing server and its edge-switch in two different racks  Pack a rack tightly before using another rack</p>
  </div>
  <div class="page">
    <p>Topology planning workflow</p>
    <p>Generate Candidate Topologies</p>
    <p>Generate Physical Layout</p>
    <p>Compute Design Cost</p>
    <p>Visualize Results</p>
    <p>User inputs</p>
    <p>Part and manufacturing costs:  Switches: $500 per 10GbE port  Cables and connectors</p>
    <p>Cost depends on the length and type of a cable  Cable installation labor: $2.50 per intra-rack and $6.25 per inter-rack  Note: Perseus can be used with other cost models</p>
  </div>
  <div class="page">
    <p>Topology planning workflow</p>
    <p>Generate Candidate Topologies</p>
    <p>Generate Physical Layout</p>
    <p>Compute Design Cost</p>
    <p>Visualize Results</p>
    <p>User inputs</p>
    <p>Visualization: Rudimentary at this time  Excel sheets  2-D plots  DOT diagrams using GraphViz, an open source graph visualization package</p>
  </div>
  <div class="page">
    <p>Sample Results</p>
  </div>
  <div class="page">
    <p>Experimental parameters</p>
    <p>Parameter values:  Number of servers: 1024 to 8192  Switch radices: 32, 48, 64, 96, and 144  Restrict to topologies with only single switch type  Various number of terminals per switch</p>
    <p>Disclaimer:  Switch and cable costs are list prices; would be cheaper in bulk</p>
  </div>
  <div class="page">
    <p>Cost vs. Bisection BW: 1024 servers, FatTree</p>
    <p>Switch Radix</p>
    <p>Servers/Edge Switch</p>
    <p>Over-sub</p>
  </div>
  <div class="page">
    <p>Cost vs. Bisection BW: 1024 servers, FatTree</p>
    <p>Ease of upgrade: R=64 and T=32 is easily upgradeable to full-bisection bandwidth where as R=48 and T=32 only to 2:1 oversubscription</p>
    <p>R=64, T=32</p>
    <p>R=48, T=32</p>
  </div>
  <div class="page">
    <p>Cost vs. Bisection BW: 1024 servers, HyperX</p>
    <p>For same number of switches, a different HyperX configuration can result in better bisection bandwidth at lower cost</p>
  </div>
  <div class="page">
    <p>Further Steps</p>
  </div>
  <div class="page">
    <p>Optimization Problem: Logical to physical mapping</p>
    <p>Problem: Given logical topology of switches, servers, and links, generate a feasible mapping of these onto a physical space with racks arranged in rows with multiple racks per row such that the wiring cost is minimized.</p>
    <p>Rack constraints:  Racks have fixed heights  Limit on number of cables exiting a rack</p>
    <p>Cable tray constraints:  Each row has a cable tray running on top  Not every column has a cross tray running on top, for cooling</p>
    <p>reasons Cable constraints:  Cheap copper cables have a maximum span (about 10 meters)  Expensive optical components need to be used for longer links</p>
  </div>
  <div class="page">
    <p>Other interesting optimization challenges</p>
    <p>Performance metrics and costs not addressed currently:  Non-uniform Bisection Bandwidth  Reliability  Expandability  Serviceability: Maintenance, SKUs  Power  Topologies with different switch types</p>
    <p>Topologies:  BCube, CamCube, etc.:  Servers with multi-interface NICs  Servers acting as end-points and switches</p>
  </div>
  <div class="page">
    <p>Perseus Tool</p>
    <p>Current status: a preliminary prototype</p>
    <p>Further work:  Scalability to design networks for 100K servers  Current heuristics allow scaling to 8-32K servers  Visualization  Generate wiring instructions  Verify installations</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Data-center wiring  a rich research area with several hard and interesting problems  A complex problem for manual design</p>
    <p>Our current work barely scratches this problem space  Perseus: A framework to help engineers in exploring the large</p>
    <p>design space  Considered various topologies: EGFT and HyperX  Exposed several interesting problems  Heuristics for reducing the huge design search space</p>
  </div>
  <div class="page">
    <p>Thank you</p>
  </div>
</Presentation>
