<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>OPT: OsloPotsdamTeesside Pipelining Rules, Rankers, and Classifier Ensembles for Shallow Discourse Parsing</p>
    <p>Stephan Oepen1, Jonathon Read2, Tatjana Scheffler3, Uladzimir Sidarenka3,4, Manfred Stede3, Erik Velldal1, and Lilja vrelid1</p>
    <p>tatjana.scheffler@uni-potsdam.de August 12, 2016</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 1 / 20</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>In Short</p>
    <p>I good results with classical pipeline I explicit connectives and arguments: adapted approach from detection</p>
    <p>of speculation and negation (Velldal et al. 2012, Read et al. 2012) I cross-validation on training set I sense disambiguation: ensemble classifier I F1 = 27.77 on English blind test set</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 2 / 20</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>Architecture</p>
    <p>3 54</p>
    <p>Explicit Connective</p>
    <p>Disambiguation</p>
    <p>Arg1 Location Classification</p>
    <p>Explicit SS Argument Ranking</p>
    <p>Explicit PS Argument Ranking</p>
    <p>Non-Explicit Relation Detection</p>
    <p>Non-Explicit Argument Ranking</p>
    <p>Non-Explicit Sense Classification</p>
    <p>Explicit Sense Classification</p>
    <p>Figure : OPT system overview.</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 3 / 20</p>
  </div>
  <div class="page">
    <p>Explicit Connective Detection</p>
    <p>Explicit Connective Detection</p>
    <p>I extends the work by Velldal et al. (2012) for identifying expressions of speculation and negation</p>
    <p>I disambiguate closed class list of connectives (heads only) I binary SVMlight classifier</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 4 / 20</p>
  </div>
  <div class="page">
    <p>Explicit Connective Detection</p>
    <p>Classifier Features</p>
    <p>I surface features I token and POS n-grams around the candidate (up to 5)</p>
    <p>I parent, sibling, path, etc. features over PTB-style parse trees I from Pitler &amp; Nenkova (2009); Lin et al., (2014); Wang &amp; Lan, (2015)</p>
    <p>I feature tuning by ten-fold cross-validation on training set I final model selection (among some thousand runs):</p>
    <p>I prefer smaller models with less variation across folds I test twelve candidate models against development set</p>
    <p>I final model: I surface features up to 3 tokens before/after candidate I full feature conjunction for self and parent categories I limited conjunctions for siblings I no connected context</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 5 / 20</p>
  </div>
  <div class="page">
    <p>Explicit Connective Detection</p>
    <p>Explicit Connective Identification: Results</p>
    <p>I F1 = 94.4 on WSJ test set, F1 = 91.8 on blind test set I comparable to Wang &amp; Lan (2015) I but well below the best 2016 system (98.9/98.4; Zhongyi Li, Shanghai)</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 6 / 20</p>
  </div>
  <div class="page">
    <p>Argument Identification</p>
    <p>Arguments</p>
    <p>I based on work on the scope of speculation and negation (Read et al., 2012)</p>
    <p>I assumption: arguments basically correspond to phrases I approach:</p>
    <p>I extract clausal constituents: S, SBAR, SQ I rank them I post-editing</p>
    <p>I SVMlight classifiers; ten-fold cross-validation on training set</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 7 / 20</p>
  </div>
  <div class="page">
    <p>Argument Identification</p>
    <p>Argument Position</p>
    <p>Arg2Arg1 0 (SS) 1 (PS) 2 3 4+</p>
    <p>explicit 60.41% 27.98% 5.63% 2.30% 3.66% non-explicit 2.56% 95.28% 1.64% 0.34% 0.18%</p>
    <p>Table : Position of Arg2 relative to Arg1.</p>
    <p>I non-explicit relations: Arg1 is in previous sentence (PS) from Arg2 I explicit relations: classifier for PS or same sentence (SS)</p>
    <p>I connective form I path from connective to root I connective position in sentence (tertiles) I POS bigram of connective and following token</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 8 / 20</p>
  </div>
  <div class="page">
    <p>Argument Identification</p>
    <p>Argument Position</p>
    <p>Arg2Arg1 0 (SS) 1 (PS) 2 3 4+</p>
    <p>explicit 60.41% 27.98% 5.63% 2.30% 3.66% non-explicit 2.56% 95.28% 1.64% 0.34% 0.18%</p>
    <p>Table : Position of Arg2 relative to Arg1.</p>
    <p>I non-explicit relations: Arg1 is in previous sentence (PS) from Arg2 I explicit relations: classifier for PS or same sentence (SS)</p>
    <p>I connective form I path from connective to root I connective position in sentence (tertiles) I POS bigram of connective and following token</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 8 / 20</p>
  </div>
  <div class="page">
    <p>Argument Identification</p>
    <p>Argument Candidate Ranking I ordinal ranking of clausal constituents I iteratively build a pool of feature types</p>
    <p>Exp. PS Exp. SS Non-Exp.</p>
    <p>Arg1 Arg2 Arg1 Arg2 Arg1 Arg2</p>
    <p>Connective Form  Connective Category  Connective Precedes  Following Token  Initial Token  Path to Root     Path to Connective    Path to Initial Token   Preceding Token     Production Rules     Size</p>
    <p>Table : Feature types used to describe candidate constituents for argument ranking.Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 9 / 20</p>
  </div>
  <div class="page">
    <p>Argument Identification</p>
    <p>Post-Editing Heuristics Explicit Non-Explicit</p>
    <p>Arg1 Arg2 Arg1 Arg2</p>
    <p>Alignment w/o edits .483 .535 .870 .900 Alignment with edits .813 .840 .882 .900</p>
    <p>Table : Alignment of constituent yield with arguments (in SS or PS).</p>
    <p>I initial alignment of full constituent yield with arguments is low I post-editing rules</p>
    <p>- add conjunction (CC) preceding constituent (Arg1) - cut clause headed by connective (Arg1, explicit, SS) - cut constituent-final CC (Arg1) - cut constituent-final wh-determiner (Arg1) - cut constituent-initial CC (Arg2, explicit) - cut relative clause, i.e. SBAR initiated by WHNP/WHADVP - cut connective - cut initial and final punctuation</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 10 / 20</p>
  </div>
  <div class="page">
    <p>Argument Identification</p>
    <p>Argument Extraction: Results</p>
    <p>WSJ Test Set Blind Set</p>
    <p>Arg1 Arg2 Both Arg1 Arg2 Both</p>
    <p>Explicit (SS) .683 .817 .590 .647 .783 .519 Explicit (PS) .623 .663 .462 .611 .832 .505 Explicit (All) .572 .753 .474 .586 .782 .473</p>
    <p>Non-explicit (All) .744 .743 .593 .640 .758 .539</p>
    <p>Overall .668 .749 .536 .617 .769 .509</p>
    <p>Table : Argument extraction results, no error propagation.</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 11 / 20</p>
  </div>
  <div class="page">
    <p>Sense Classification</p>
    <p>Sense Classification</p>
    <p>I separate ensemble classifiers for explicit and non-explicit relations:</p>
    <p>same features</p>
    <p>I final prediction label picked from sum of individual classifier probabilities</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 12 / 20</p>
  </div>
  <div class="page">
    <p>Sense Classification</p>
    <p>Sense Classification: Results</p>
    <p>WSJ Test Set Blind Set</p>
    <p>System Exp Non-Exp All Exp Non-Exp All</p>
    <p>LSTM 89.90 33.76 60.78 77.63 33.69 53.29 OPT 90.01 41.12 64.70 77.06 37.20 55.55</p>
    <p>Table : Isolated results for sense classification (the bottom model was not part of the submission).</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 13 / 20</p>
  </div>
  <div class="page">
    <p>Overall Results</p>
    <p>Overall Results</p>
    <p>I WSJ test set and blind test set I compared to challenge in 2015 and 2016 I error propagation, automatic parses</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 14 / 20</p>
  </div>
  <div class="page">
    <p>Overall Results</p>
    <p>WSJ Test Set Blind Test Set</p>
    <p>Expl. Conn. 94.8 98.9 94.4 91.9 98.4 91.8 Expl. Arg1 50.7 53.8 52.0 49.7 52.4 52.4 Expl. Arg2 77.4 76.7 72.6 74.3 75.2 75.2 Expl. Arg1Arg2 45.2 45.3 43.9 41.4 44.0 44.0 Expl. Sense 39.4 34.5 Non-Ex. Arg1 67.2 69.9 69.9 60.9 66.8 64.6 Non-Ex. Arg2 68.4 71.5 71.5 74.6 79.1 76.4 Non-Ex. Arg1Arg2 53.1 53.5 53.5 50.4 58.1 52.0 Non-Ex. Sense 18.0 21.9 All Arg1Arg2 49.4 49.6 48.9 46.4 50.6 48.2 Overall Parser 29.7 30.7 28.2 24.0 27.8 27.8</p>
    <p>Table : Per-component breakdown of system performance.</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 15 / 20</p>
  </div>
  <div class="page">
    <p>Overall Results</p>
    <p>Take-Home Messages</p>
    <p>I overall, the end-to-end problem is anything but solved</p>
    <p>I adaptation of constituent ranking good fit for argument identification I cross-validation has helped reduce over-fitting to WSJ data I classifier ensemble improves sense prediction (post-submission results)</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 16 / 20</p>
  </div>
  <div class="page">
    <p>Overall Results</p>
    <p>Take-Home Messages</p>
    <p>I overall, the end-to-end problem is anything but solved I adaptation of constituent ranking good fit for argument identification</p>
    <p>I cross-validation has helped reduce over-fitting to WSJ data I classifier ensemble improves sense prediction (post-submission results)</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 16 / 20</p>
  </div>
  <div class="page">
    <p>Overall Results</p>
    <p>Take-Home Messages</p>
    <p>I overall, the end-to-end problem is anything but solved I adaptation of constituent ranking good fit for argument identification I cross-validation has helped reduce over-fitting to WSJ data</p>
    <p>I classifier ensemble improves sense prediction (post-submission results)</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 16 / 20</p>
  </div>
  <div class="page">
    <p>Overall Results</p>
    <p>Take-Home Messages</p>
    <p>I overall, the end-to-end problem is anything but solved I adaptation of constituent ranking good fit for argument identification I cross-validation has helped reduce over-fitting to WSJ data I classifier ensemble improves sense prediction (post-submission results)</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 16 / 20</p>
  </div>
  <div class="page">
    <p>Overall Results</p>
    <p>Thank you!</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 17 / 20</p>
  </div>
  <div class="page">
    <p>Overall Results</p>
    <p>Selected References</p>
    <p>Read, J., Velldal, E., vrelid, L., and Oepen, S. (2012). UiO1. Constituent-based discriminative ranking for negation resolution. In Proceedings of the 1st Joint Conference on Lexical and Computational Semantics (pp. 310318). Montreal, Canada.</p>
    <p>Velldal, E., vrelid, L., Read, J., and Oepen, S. (2012). Speculation and negation: Rules, rankers and the role of syntax. Computational Linguistics, 38(2), 369  410.</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 18 / 20</p>
  </div>
  <div class="page">
    <p>Non-Explicit Relation Detection</p>
    <p>Non-Explicit Relation Detection</p>
    <p>I non-explicit relation between sentences A and B, iff (PDTB): (i) A and B are adjacent, (ii) A and B are in the same paragraph, (iii) A and B are not linked by an explicit connective, and (iv) a coherence relation or an entity-based relation holds between them.</p>
    <p>Method: I traverse sentence bigrams (i), (ii) I check for explicit connectives with Arg1 in PS (iii) I NoRel (0.6% in PDTB) and AltLex (1.5%) are currently ignored (iv)</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 19 / 20</p>
  </div>
  <div class="page">
    <p>Non-Explicit Relation Detection</p>
    <p>Non-Explicit Relation Detection: Results</p>
    <p>I module evaluation on gold standard explicit connectives I F1 = 93.2 on WSJ test set; P = 89.9, R = 96.8</p>
    <p>Tatjana Scheffler (Uni Potsdam) OPT Shallow Discourse Parsing August 12, 2016 20 / 20</p>
  </div>
</Presentation>
