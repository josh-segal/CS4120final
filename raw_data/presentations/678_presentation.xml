<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Adaptive Memory System over Ethernet</p>
    <p>Jun Suzuki, Teruyuki Baba, Yoichi Hidaka, Junichi Higuchi, Nobuharu Kami, Satoshi Uchida, Masahiko Takahashi,</p>
    <p>Tomoyoshi Sugawara, and Takashi Yoshikawa</p>
    <p>System Platforms Research Laboratories, NEC Corporation IP Network Division, NEC Corporation</p>
    <p>2nd Computer Software Division, NEC Corporation</p>
  </div>
  <div class="page">
    <p>NEC Corporation 2010Page 2 HotStorage 10</p>
    <p>Memory Scalability in Cloud Computing</p>
    <p>Cannot scale depending on service requirements  Service performance limited by memory  Slow block I/O devices</p>
    <p>Needs for scaling memory beyond individually loaded amount</p>
    <p>Computer memory is limited by individually loaded resources</p>
    <p>MEMMEM</p>
    <p>MEMMEM</p>
    <p>MEMMEM</p>
    <p>MEMMEM</p>
    <p>MEMMEM</p>
    <p>MEMMEM MEMMEM MEMMEM</p>
  </div>
  <div class="page">
    <p>NEC Corporation 2010Page 3 HotStorage 10</p>
    <p>Resource Should Simultaneously be High-Performance and Networked</p>
    <p>Networked  Resource share among multiple computers  Ease of management</p>
    <p>High-Performance</p>
    <p>Large throughput, low latency  Avoid firmware process and memory copy to transfer data</p>
  </div>
  <div class="page">
    <p>NEC Corporation 2010Page 4 HotStorage 10</p>
    <p>Related Works</p>
    <p>(A) Intel Turbo Memory</p>
    <p>PCIe flash device for disk cache  Device driver between OS and disk driver</p>
    <p>J. Matthews et al., Intel Turbo Memory: Nonvolatile Disk Caches in the Storage Hierarchy of Mainstream Computer Systems, ACM Trans. on Storage, vol.4, no. 2, article 4, 2008.</p>
    <p>(B) Remote Page Swap</p>
    <p>Using memory of next machine with swapping  Standard interconnection, e.g., Ethernet</p>
    <p>E. P. Markatos and G. Dramitinos, Implementation of a Reliable Remote Memory Pager, USENIX 1996 Annual Technical Conference, 1996.</p>
    <p>SW</p>
    <p>MEM</p>
    <p>High Performance</p>
    <p>Resource Share by Network</p>
    <p>Turbo Memory Driver</p>
    <p>SATA Driver</p>
    <p>Turbo Memory SATA</p>
    <p>Block I/O from OS</p>
  </div>
  <div class="page">
    <p>NEC Corporation 2010Page 5 HotStorage 10</p>
    <p>I/O Expansion BoxI/O Expansion Box</p>
    <p>Our Method: Ethernet-Attached SSD as High-Speed Swap Device</p>
    <p>PCIe SSD</p>
    <p>High-Performance AND Resource Share</p>
    <p>Standard EthernetStandard Ethernet</p>
    <p>Standard Ethernet, PCIe SSD</p>
    <p>ExpEther Interconnect - PCIe over Ethernet [1]</p>
    <p>[1] J. Suzuki et al., ExpressEther  Ethernet-Based Virtualization Technology for Reconfigurable Hardware Platform, 14th IEEE Symposium on High-Performance Interconnects, pages 45-51, 2006.</p>
    <p>EE Brid.EE Brid. EE Brid.EE Brid. EE Brid.EE Brid.</p>
    <p>PCIe DMA w/o Firmware, Memcopy</p>
    <p>Hot-Plug and Remove</p>
  </div>
  <div class="page">
    <p>NEC Corporation 2010Page 6 HotStorage 10</p>
    <p>Computer</p>
    <p>Extending PCIe Tree over Ethernet  PCIe packet encapsulation into Ethernet frames  Ethernet region is PCIe switch</p>
    <p>High-Speed Ethernet Transport [1]  Delay-based congestion control  &lt; 8.5% of TCP-based delay</p>
    <p>Memory</p>
    <p>PCIe DMA over Ethernet</p>
    <p>Memory</p>
    <p>EthernetEthernet</p>
    <p>ExpEther Bridge</p>
    <p>ExpEther Bridge</p>
    <p>ExpEther Bridge</p>
    <p>ExpEther Bridge</p>
    <p>Host Bridge Host</p>
    <p>Bridge</p>
    <p>ExpEther Bridge</p>
    <p>ExpEther Bridge</p>
    <p>PCIe bus PCIe DMA</p>
    <p>CPUCPU</p>
    <p>SSD BSSD BSSD ASSD A</p>
    <p>No Drive r</p>
    <p>Standa rd Eth</p>
    <p>ernet</p>
    <p>[1] H. Shimonishi et al., A Congestion Control Algorithm for Data Center Area Communications, 2008 International CQR Workshop, 2008.</p>
    <p>No Firmware Process No Memory Copy</p>
  </div>
  <div class="page">
    <p>NEC Corporation 2010Page 7 HotStorage 10</p>
    <p>Hot-Plug and Remove</p>
    <p>Computer A</p>
    <p>ExpEther Bridge</p>
    <p>ExpEther Bridge</p>
    <p>Computer B</p>
    <p>ExpEther Bridge</p>
    <p>ExpEther Bridge</p>
    <p>Computer C</p>
    <p>ExpEther Bridge</p>
    <p>ExpEther Bridge</p>
    <p>ExpEther Bridge</p>
    <p>ExpEther Bridge</p>
    <p>SSD A</p>
    <p>ExpEther Bridge</p>
    <p>ExpEther Bridge</p>
    <p>SSD B</p>
    <p>SSD C</p>
    <p>VLAN 1</p>
    <p>Ethernet Ethernet VLAN 2</p>
    <p>ExpEther Bridge</p>
    <p>SSDs Assigned to Computer with VLAN Grouping  Adaptive assignment using system manager  PCIe-standard hot-plug and remove</p>
    <p>ExpEther Bridge</p>
    <p>System Manager</p>
  </div>
  <div class="page">
    <p>NEC Corporation 2010Page 8 HotStorage 10</p>
    <p>Evaluations</p>
    <p>Block I/O Performance of Ethernet-Attached SSD</p>
    <p>System Evaluation: In-Memory DB</p>
  </div>
  <div class="page">
    <p>NEC Corporation 2010Page 9 HotStorage 10</p>
    <p>Evaluation Setups</p>
    <p>SSDSSD</p>
    <p>ComputerComputer</p>
    <p>ExpEther Bridge</p>
    <p>(a) ExpEther</p>
    <p>ExpEther Bridge</p>
    <p>ExpEther Bridge</p>
    <p>(c) iSCSI with TOE(b) iSCSI</p>
    <p>ExpEther Bridge</p>
    <p>InitiatorInitiator</p>
    <p>TOE NICTOE NIC</p>
    <p>TargetTarget</p>
    <p>TOE NICTOE NIC SSDSSD</p>
    <p>InitiatorInitiator</p>
    <p>NICNIC</p>
    <p>TargetTarget</p>
    <p>NICNIC SSDSSD</p>
    <p>ConventionalConventional</p>
    <p>ProposalProposal</p>
  </div>
  <div class="page">
    <p>NEC Corporation 2010Page 10 HotStorage 10</p>
    <p>(b) Random Write IOPS</p>
    <p>Access Size</p>
    <p>IO P</p>
    <p>S</p>
    <p>Direct Insertion</p>
    <p>EE</p>
    <p>iSCSI with TOE</p>
    <p>iSCSI</p>
    <p>(a) Random Read IOPS</p>
    <p>Access Size</p>
    <p>IO P</p>
    <p>S</p>
    <p>Direct Insertion</p>
    <p>EE</p>
    <p>iSCSI with TOE</p>
    <p>iSCSI</p>
    <p>Block I/O Performance (IOPS) of Ethernet-Attached SSD</p>
    <p>Read Close to Host I/O Slot, Write Twice of TOE iSCSI</p>
    <p>Host I/O Slot ExpEther iSCSI w/ TOE iSCSI</p>
    <p>Ran. Read 100 92 50 14</p>
    <p>Ran. Write 100 74 42 14</p>
    <p>Ran. Read w/ Switch 100 91 46 14</p>
    <p>Ran. Write w/ Switch 100 68 39 14</p>
  </div>
  <div class="page">
    <p>NEC Corporation 2010Page 11 HotStorage 10</p>
    <p>Write IOPS Overhead and Its Solution</p>
    <p>Computer</p>
    <p>Memory Read Requests</p>
    <p>SSD</p>
    <p>Completion w/ Data</p>
    <p>Number of SSDs outstanding read request limited by its implementation</p>
    <p>Increasing number of requests enhances performance close to host I/O slot</p>
    <p>Up to 4 Requests</p>
  </div>
  <div class="page">
    <p>NEC Corporation 2010Page 12 HotStorage 10</p>
    <p>System Evaluation: In-Memory Database</p>
    <p>RDB: postgresql 8.1 Bench: pgbench (TPC-B-like) CPU: Intel Core 2 Quad OS: CentOS 5.3 (Linux 2.6.18) Ethernet: 10GbE SSD: 16-GB Partition of Fusion IO 160 GB (Write Improve Mode) #Client: 100 Transaction per Client: 1000</p>
    <p>SSDSSD</p>
    <p>ComputerComputer</p>
    <p>ExpEther Bridge</p>
    <p>ExpEther Bridge</p>
    <p>ExpEther Bridge</p>
    <p>ExpEther BridgeMemory</p>
    <p>Memory</p>
    <p>RDB FileRDB File Swap</p>
    <p>Placing RDB File on Ramdisk</p>
  </div>
  <div class="page">
    <p>NEC Corporation 2010Page 13 HotStorage 10</p>
    <p>Scaling-Up beyond Main Memory</p>
    <p>Maintaining performance when DB files enlarged beyond system memory  &gt;79% performance of all-in-memory at 4G Mem + ExpEther case</p>
    <p>Total Size of RDB Files [GB]</p>
    <p>T ra</p>
    <p>n sa</p>
    <p>c ti o n p</p>
    <p>e r</p>
    <p>S e c .</p>
    <p>&gt;79% Performance</p>
    <p>Maintaining Performance</p>
  </div>
  <div class="page">
    <p>NEC Corporation 2010Page 14 HotStorage 10</p>
    <p>Comparison with Conventional Protocol</p>
    <p>Total Size of DB Files [GB]</p>
    <p>T ra</p>
    <p>n sa</p>
    <p>c ti o n p</p>
    <p>e r</p>
    <p>S e c .</p>
    <p>Mem 4G + EE</p>
    <p>Mem 2G + EE</p>
    <p>Mem 4G + iSCSI</p>
    <p>Mem 2G + iSCSI</p>
    <p>Performance Gain</p>
    <p>[Note] iSCSI with TOE could not be evaluated by software bug. Calculation indicates proposal outperforms it by 21%</p>
    <p>Proposal outperforms iSCSI by 139% at best case</p>
  </div>
  <div class="page">
    <p>NEC Corporation 2010Page 15 HotStorage 10</p>
    <p>Saving CPU Resource for Transaction Processing</p>
    <p>High-speed swap saves CPU for user process</p>
    <p>Mem 4G + EE</p>
    <p>Mem 2G + EE</p>
    <p>Mem 8G</p>
    <p>Mem 4G + EE</p>
    <p>Mem 2G + EE</p>
    <p>Mem 8G</p>
    <p>Total Size of RDB Files [GB]</p>
    <p>C P</p>
    <p>U U</p>
    <p>ti l.</p>
    <p>[% ]</p>
    <p>software irq</p>
    <p>hardware irq</p>
    <p>wait nice</p>
    <p>system</p>
    <p>user</p>
    <p>Swap v v v v v Consumed by page swap</p>
  </div>
  <div class="page">
    <p>NEC Corporation 2010Page 16 HotStorage 10</p>
    <p>Conclusion</p>
    <p>Adaptive Memory Expansion with Ethernet-Attached SSD as High-Speed Swap Device</p>
    <p>Standard Components  Standard Ethernet and PCIe SSD  No software driver for Ethernet expansion</p>
    <p>High-Performance and Resource Share  PCIe DMA over Ethernet  Superior block-io performance than conventional protocol  PCIe hot-plug and remove</p>
    <p>Proven System Merits  Maintains database performance beyond system memory</p>
  </div>
  <div class="page">
    <p>NEC Corporation 2010Page 17 HotStorage 10</p>
    <p>Future Works</p>
    <p>Simultaneous Share of SSD among multiple computers  PCIe I/O virtualization emerges  Efficient resource utilization  High-speed data share</p>
    <p>Solve Performance Bottleneck of Storage and Database System  Network storage for system availability  Performance bottleneck by network storage</p>
  </div>
</Presentation>
