<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>When Address Remapping Techniques Meet Consistency Guarantee Mechanisms</p>
    <p>Dong Hyun Kang, Gihwan Oh, Dongki Kim, In Hwan Doh,</p>
    <p>Changwoo Min, Sang-Won Lee, and Young Ik Eom</p>
    <p>Sungkyunkwan University Samsung Electronics Virginia Tech</p>
  </div>
  <div class="page">
    <p>What Is Consistency, And Why Is It Important?</p>
    <p>What if you lose your precious data?</p>
    <p>How we can build a crash consistency system?</p>
    <p>Turn on one of the consistency mechanisms</p>
    <p>Journaling, copy-on-write, and logging</p>
    <p>[Source: https://n2ws.com/blog/ebs-snapshot/transaction-logs-and-journaling]</p>
  </div>
  <div class="page">
    <p>Where To Handle Consistency Mechanism?</p>
    <p>File system-level</p>
    <p>Journaling: ext3, ext4, and XFS</p>
    <p>Copy-on-write: Btrfs and ZFS</p>
    <p>Logging: F2FS</p>
    <p>Application-level</p>
    <p>Database: MySQL, Oracle, and SQLite</p>
    <p>Editor: Vim</p>
    <p>F2FS</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Consistency mechanisms need extra writes to keep the file system to a consistent state</p>
    <p>Redundant writes in journaling</p>
    <p>Copy writes in copy-on-write</p>
    <p>Additional writes in log-structured</p>
    <p>Research question</p>
    <p>Can we guarantee crash consistency by writing the data only once?</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Background</p>
    <p>Related work</p>
    <p>Case studies</p>
    <p>Implementation &amp; Challenges</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Flash Storage Device</p>
    <p>Flash storage device uses a special software inside the storage</p>
    <p>FTL (flash translation layer): it emulates overwrite behavior by remapping its own mapping table</p>
    <p>Page Mapping Table (L2P)</p>
    <p>Write (LPN2)</p>
  </div>
  <div class="page">
    <p>Flash Storage Device</p>
    <p>Flash storage device uses a special software inside the storage</p>
    <p>FTL (flash translation layer): it emulates overwrite behavior by remapping its own mapping table</p>
    <p>Page Mapping Table (L2P)</p>
    <p>Write (LPN2)</p>
  </div>
  <div class="page">
    <p>Flash Storage Device</p>
    <p>Flash storage device uses a special software inside the storage</p>
    <p>FTL (flash translation layer): it emulates overwrite behavior by remapping its own mapping table</p>
    <p>Page Mapping Table (L2P)</p>
    <p>Read (LPN2)</p>
  </div>
  <div class="page">
    <p>SHARE Interface</p>
    <p>SHARE interface [SIGMOD16] allows host to explicitly ask FTL to change its internal address mapping table</p>
    <p>Target PPN is shared via address remapping</p>
    <p>Page Mapping Table (L2P)</p>
    <p>Write (LPN 7)</p>
  </div>
  <div class="page">
    <p>SHARE Interface</p>
    <p>SHARE interface [SIGMOD16] allows host to explicitly ask FTL to change its internal address mapping table</p>
    <p>Target PPN is shared via address remapping</p>
    <p>Page Mapping Table (L2P)</p>
    <p>SHARE (LPN2, LPN 7)</p>
  </div>
  <div class="page">
    <p>SHARE Interface</p>
    <p>SHARE interface [SIGMOD16] allows host to explicitly ask FTL to change its internal address mapping table</p>
    <p>Target PPN is shared via address remapping</p>
    <p>Page Mapping Table (L2P)</p>
    <p>SHARE (LPN2, LPN 7)</p>
  </div>
  <div class="page">
    <p>SHARE Interface</p>
    <p>SHARE interface [SIGMOD16] allows host to explicitly ask FTL to change its internal address mapping table</p>
    <p>Target PPN is shared via address remapping</p>
    <p>SHARE atomically supports multi-address remapping</p>
    <p>Page Mapping Table (L2P)</p>
    <p>SHARE (LPN2, LPN 7)</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Background</p>
    <p>Related work</p>
    <p>Case studies</p>
    <p>Implementation &amp; Challenges</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Remapping Approaches in Various Cases</p>
    <p>Which layer</p>
    <p>JFTL [ACM TOS09] -&gt; FTL layer</p>
    <p>ANViL [USENIX FAST15] -&gt; Virtual storage layer</p>
    <p>SHARE [ACM SIGMOD16] -&gt; FTL layer</p>
    <p>Janus [USENIX ATC17] -&gt; FTL with File system layer</p>
    <p>SHRD [USENIX FAST17] -&gt; FTL with Block layer</p>
    <p>Ext4-lazy [USENIX FAST17] -&gt; File system layer</p>
  </div>
  <div class="page">
    <p>Remapping Approaches in Various Cases</p>
    <p>What purposes</p>
    <p>JFTL [ACM TOS09] -&gt; File system-level consistency</p>
    <p>ANViL [USENIX FAST15] -&gt; File system-level consistency</p>
    <p>SHARE [ACM SIGMOD16] -&gt; Application-level consistency</p>
    <p>Janus [USENIX ATC17] -&gt; Defragmentation</p>
    <p>SHRD [USENIX FAST17] -&gt; Sequential writes</p>
    <p>Ext4-lazy [USENIX FAST17] -&gt; Sequential writes</p>
  </div>
  <div class="page">
    <p>Remapping Approaches in Various Cases</p>
    <p>What purposes</p>
    <p>JFTL [ACM TOS09] -&gt; File system-level consistency</p>
    <p>ANViL [USENIX FAST15] -&gt; File system-level consistency</p>
    <p>SHARE [ACM SIGMOD16] -&gt; Application-level consistency</p>
    <p>Janus [USENIX ATC17] -&gt; Defragmentation</p>
    <p>SHRD [USENIX FAST17] -&gt; Sequential writes</p>
    <p>Ext4-lazy [USENIX FAST17] -&gt; Sequential writes</p>
  </div>
  <div class="page">
    <p>Remapping Approaches in Various Cases</p>
    <p>What purposes</p>
    <p>JFTL [ACM TOS09] -&gt; File system-level consistency</p>
    <p>ANViL [USENIX FAST15] -&gt; File system-level consistency</p>
    <p>SHARE [ACM SIGMOD16] -&gt; Application-level consistency</p>
    <p>Janus [USENIX ATC17] -&gt; Defragmentation</p>
    <p>SHRD [USENIX FAST17] -&gt; Sequential writes</p>
    <p>Ext4-lazy [USENIX FAST17] -&gt; Sequential writes</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Background</p>
    <p>Related work</p>
    <p>Case studies</p>
    <p>Implementation &amp; Challenges</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Case Study 1: Ext4</p>
    <p>Traditional Ext4 file system writes same data twice to guarantee crash consistency</p>
    <p>Page Mapping Table (L2P)</p>
    <p>Journal Write(LPN 7) Original Write(LPN 2)</p>
  </div>
  <div class="page">
    <p>Case Study 1: Ext4</p>
    <p>Traditional Ext4 file system writes same data twice to guarantee crash consistency</p>
    <p>SHARE-aware Ext4 can remove the second write by delegating it to SHARE  SHARE-aware ordered journaling (SOJ) mode</p>
    <p>SHARE-aware data journaling (SDJ) mode</p>
    <p>Page Mapping Table (L2P)</p>
    <p>Journal Write(LPN 7) Original Write(LPN 2)</p>
  </div>
  <div class="page">
    <p>Case Study 1: Ext4</p>
    <p>For example (Data journaling mode)</p>
    <p>: Clean data : Dirty data : Dirty metadata : Journal location : Original location</p>
    <p>A</p>
    <p>Time</p>
    <p>DJ</p>
    <p>Write AA</p>
    <p>Write BB</p>
    <p>Update Meta</p>
    <p>MAAB B</p>
    <p>Update Meta</p>
    <p>MB</p>
    <p>Commit Checkpoint</p>
    <p>MA A BMBMA MB A B</p>
  </div>
  <div class="page">
    <p>Case Study 1: Ext4</p>
    <p>For example (Data journaling mode)</p>
    <p>: Clean data : Dirty data : Dirty metadata : Journal location : Original location</p>
    <p>A</p>
    <p>Time</p>
    <p>DJ</p>
    <p>Write AA</p>
    <p>Write BB</p>
    <p>Update Meta</p>
    <p>MAAB B</p>
    <p>Update Meta</p>
    <p>MB</p>
    <p>Commit Checkpoint</p>
    <p>MA A BMBMA MB A B</p>
    <p>ASDJ MAAB B MB</p>
    <p>MA MB A B</p>
    <p>Share LPNs</p>
    <p>Performance gain</p>
  </div>
  <div class="page">
    <p>Case Study 1: Ext4</p>
    <p>Performance (FIO and Varmail)</p>
    <p>SOJ shows better performance than traditional OJ</p>
    <p>SDJ has significantly performance gain at large fsync interval</p>
    <p>IO P</p>
    <p>S (</p>
    <p>x 1</p>
    <p>Fsync Interval</p>
    <p>OJ SOJ DJ SDJ</p>
    <p>[FIO performance]</p>
  </div>
  <div class="page">
    <p>Case Study 1: Ext4</p>
    <p>Performance (FIO and Varmail)</p>
    <p>SOJ shows better performance than traditional OJ</p>
    <p>SDJ has significantly performance gain at large fsync interval</p>
    <p>IO P</p>
    <p>S (</p>
    <p>x 1</p>
    <p>Fsync Interval</p>
    <p>OJ SOJ DJ SDJ</p>
    <p>OJ SOJ DJ SDJ</p>
    <p>T h</p>
    <p>r o</p>
    <p>u g</p>
    <p>h p</p>
    <p>u t</p>
    <p>(M B</p>
    <p>/s )</p>
    <p>[FIO performance] [Varmail performance]</p>
  </div>
  <div class="page">
    <p>Case Study 2: LFS</p>
    <p>Existing LFS basically requires the segment cleaning operation to reclaim free space</p>
    <p>SHARE-aware LFS can remove the move operation by delegating it to SHARE</p>
    <p>SHARE-aware segment cleaning (SSC)</p>
    <p>A B C D A B C D</p>
    <p>Move</p>
    <p>Segment 1 Segment 2 Segment 3</p>
  </div>
  <div class="page">
    <p>Case Study 2: LFS</p>
    <p>Performance (FIO)</p>
    <p>The number of total moved pages is similar to that of SC</p>
    <p>But, SSC shows better performance than default SC</p>
    <p># o</p>
    <p>f P</p>
    <p>a g</p>
    <p>e s</p>
    <p>M o</p>
    <p>v e d</p>
    <p>( x</p>
    <p>)</p>
    <p>Fsync Interval</p>
    <p>SC</p>
    <p>SSC</p>
    <p>[The number of total moved pages]</p>
    <p>In SSC, move is changed to SHARE</p>
  </div>
  <div class="page">
    <p>IO P</p>
    <p>S (</p>
    <p>x 1</p>
    <p>Fsync Interval</p>
    <p>SC</p>
    <p>SSC</p>
    <p>Case Study 2: LFS</p>
    <p>Performance (FIO)</p>
    <p>The number of total moved pages is similar to that of SC</p>
    <p>But, SSC shows better performance than default SC</p>
    <p># o</p>
    <p>f P</p>
    <p>a g</p>
    <p>e s</p>
    <p>M o</p>
    <p>v e d</p>
    <p>( x</p>
    <p>)</p>
    <p>Fsync Interval</p>
    <p>SC</p>
    <p>SSC</p>
    <p>[The number of total moved pages] [Performance]</p>
    <p>In SSC, move is changed to SHARE</p>
  </div>
  <div class="page">
    <p>Case Study 3: Application</p>
    <p>Some applications (e.g., databases and key-value stores) have their own consistency mechanisms even with Ext4 DJ mode</p>
    <p>Double write buffer in MySQL</p>
    <p>In DJ mode, the transaction of file system may break the atomicity of the database application</p>
    <p>Database atomicity unit</p>
    <p>FS atomic unit FS atomic unit FS atomic unit</p>
    <p>Time</p>
    <p>Time</p>
    <p>Commit Commit</p>
  </div>
  <div class="page">
    <p>Case Study 3: Application</p>
    <p>Some applications (e.g., databases and key-value stores) have their own consistency mechanisms even with Ext4 DJ mode</p>
    <p>Double write buffer in MySQL</p>
    <p>In DJ mode, the transaction of file system may break the atomicity of the database application</p>
    <p>Database atomicity unit</p>
    <p>FS atomic unit FS atomic unit FS atomic unit</p>
    <p>Time</p>
    <p>Time</p>
    <p>Power failure</p>
    <p>Commit Commit</p>
    <p>Database atomicity unit</p>
    <p>One transaction was partially stored (Atomicity failure)</p>
  </div>
  <div class="page">
    <p>Case Study 3: Application</p>
    <p>The ACID semantics of database transactions can be successfully guaranteed via SHARE</p>
    <p>SHARE-aware application-level data journaling (SADJ) mode</p>
    <p>It utilizes the failure-atomic update APIs [EUROSYS13]</p>
    <p>O_ATOMIC flag, failure-atomic msync(), and syncv() interface</p>
    <p>Database atomicity unit</p>
    <p>FS atomic unit FS atomic unit</p>
    <p>Time</p>
    <p>Time</p>
    <p>Commit CommitO_ATOMIC Fsync()</p>
    <p>FS atomic unit</p>
    <p>Database data flush</p>
  </div>
  <div class="page">
    <p>Case Study 3: Application</p>
    <p>Performance (MySQL/InnoDB)</p>
    <p>DWB-OFF/SADJ outperforms the DWB-ON/OJ by 6.16 times and the DWB-OFF/DJ by 2.73 times</p>
    <p>DWB-OFF/SADJ invokes 16.4x less disk cache FLUSH operations</p>
    <p>O p</p>
    <p>e r a</p>
    <p>ti o</p>
    <p>n s</p>
    <p>P e r S</p>
    <p>e c o</p>
    <p>n d</p>
    <p>( x 1</p>
    <p>SysBench</p>
    <p>[Performance]</p>
  </div>
  <div class="page">
    <p>Case Study 3: Application</p>
    <p>Performance (MySQL/InnoDB)</p>
    <p>DWB-OFF/SADJ outperforms the DWB-ON/OJ by 6.16 times and the DWB-OFF/DJ by 2.73 times</p>
    <p>DWB-OFF/SADJ invokes 16.4x less disk cache FLUSH operations</p>
    <p>O p</p>
    <p>e r a</p>
    <p>ti o</p>
    <p>n s</p>
    <p>P e r S</p>
    <p>e c o</p>
    <p>n d</p>
    <p>( x 1</p>
    <p>SysBench</p>
    <p>W r it</p>
    <p>e A</p>
    <p>m o</p>
    <p>u n</p>
    <p>t (G</p>
    <p>B )</p>
    <p>LinkBench</p>
    <p>SysBench</p>
    <p>[Performance] [Write amount]</p>
  </div>
  <div class="page">
    <p>Case Study 3: Application</p>
    <p>Performance (MySQL/InnoDB)</p>
    <p>DWB-OFF/SADJ outperforms the DWB-ON/OJ by 6.16 times and the DWB-OFF/DJ by 2.73 times</p>
    <p>DWB-OFF/SADJ invokes 16.4x less disk cache FLUSH operations</p>
    <p>O p</p>
    <p>e r a</p>
    <p>ti o</p>
    <p>n s</p>
    <p>P e r S</p>
    <p>e c o</p>
    <p>n d</p>
    <p>( x 1</p>
    <p>SysBench</p>
    <p>W r it</p>
    <p>e A</p>
    <p>m o</p>
    <p>u n</p>
    <p>t (G</p>
    <p>B )</p>
    <p>LinkBench</p>
    <p>SysBench</p>
    <p># o</p>
    <p>f D</p>
    <p>is k</p>
    <p>C a</p>
    <p>c h</p>
    <p>e F</p>
    <p>lu sh</p>
    <p>e s</p>
    <p>(x 1</p>
    <p>SysBench</p>
    <p>[Performance] [Write amount] [# of Disk cash flush]</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Background</p>
    <p>Related work</p>
    <p>Case studies</p>
    <p>Implementation &amp; Challenges</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Implementation &amp; Challenges</p>
    <p>Implementation</p>
    <p>Linux kernel 4.6.7</p>
    <p>Quad-core processor (Intel i7-6700) and 8GB memory</p>
    <p>SHARE interface</p>
    <p>SHARE-enabled SSD by modifying an FTL firmware of a commercial high-end PCIeM.2 SSD</p>
    <p>SHARE command has been added as a vendor unique command</p>
    <p>Challenges</p>
    <p>the small-size journal area (i.e., 128 MB)</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Background</p>
    <p>Related work</p>
    <p>Case studies</p>
    <p>Implementation &amp; Challenges</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Tackled a problem in current consistency mechanisms</p>
    <p>Double write overhead</p>
    <p>Segment cleaning overhead</p>
    <p>Presented a comprehensive study with the address remapping technique</p>
    <p>Feature work</p>
    <p>CoW-based B-tree file systems need to be explored</p>
  </div>
  <div class="page">
    <p>Thank you!</p>
    <p>Questions?</p>
  </div>
</Presentation>
