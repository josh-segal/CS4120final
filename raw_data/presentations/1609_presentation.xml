<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>2015 Toshiba Corporation</p>
    <p>Toshiba MT System Description</p>
    <p>for the WAT2015 Workshop</p>
    <p>Satoshi SONOH</p>
    <p>Satoshi KINOSHITA</p>
    <p>Knowledge Media Laboratory,</p>
    <p>Corporate Research &amp; Development Center,</p>
    <p>Toshiba Corporation.</p>
    <p>WAT 2015, Oct. 16, 2015 @ Kyoto</p>
  </div>
  <div class="page">
    <p>2015 Toshiba Corporation 2</p>
    <p>Motivations</p>
    <p>Rule-Based Machine Translation (RBMT)</p>
    <p>We have been developed RBMT for more than 30 years.</p>
    <p>JapaneseEnglish, JapaneseChinese, JapaneseKorean</p>
    <p>Large technical dictionaries and translation rules</p>
    <p>Pre-ordering SMT and Tree/Forest to String</p>
    <p>Effective solutions for Asian language translation (WAT2014)</p>
    <p>But, pre-ordering rules and parsers are needed.</p>
    <p>Our approach:</p>
    <p>Statistical Post Editing (SPE) (same as WAT2014)</p>
    <p>Verify effectiveness in all tasks</p>
    <p>System combination between SPE and SMT (new in WAT2015)</p>
  </div>
  <div class="page">
    <p>2015 Toshiba Corporation 3</p>
    <p>Statistical Post Editing (SPE)</p>
    <p>Source Sentence</p>
    <p>RBMT</p>
    <p>Translated Sentence</p>
    <p>Target Sentence</p>
    <p>TM (ja -&gt; ja)</p>
    <p>LM RBMT</p>
    <p>Input Sentence</p>
    <p>Translated Sentence</p>
    <p>SPE ResultSPE Model</p>
    <p>Parallel Corpus (ASPEC / JPC)</p>
    <p>sentences by RBMT.</p>
    <p>translated corpus.</p>
    <p>Translating RBMT results to post-edited results.</p>
  </div>
  <div class="page">
    <p>2015 Toshiba Corporation 4</p>
    <p>Features of SPE</p>
    <p>From RBMTs standpoint</p>
    <p>Correct mistranslations / Translate unknown words</p>
    <p>Phrase-level correction (domain adaptation)</p>
    <p>Improve fluency</p>
    <p>Use of more fluent expressions</p>
    <p>Insertion of particles</p>
    <p>Recover translation failure</p>
    <p>From SMTs standpoint</p>
    <p>Pre-ordering by RBMT</p>
    <p>Reduction of NULL alignment (subject/particle)</p>
    <p>Use of syntax information (polarity/aspect)</p>
    <p>Enhancement of lexicon</p>
    <p>SRC:</p>
    <p>RBMT:</p>
    <p>SPE:</p>
  </div>
  <div class="page">
    <p>2015 Toshiba Corporation 5</p>
    <p>SPE for Patent Translation</p>
    <p>RBMT SMT SPE</p>
    <p>en-ja</p>
    <p>RBMT SMT SPE</p>
    <p>zh-ja</p>
    <p>RBMT SMT SPE</p>
    <p>ko-ja</p>
    <p>BLEUBLEUBLEU</p>
    <p>RBMT SMT SPE</p>
    <p>Adequacy</p>
    <p>RBMT SMT SPE</p>
    <p>Acceptability</p>
    <p>F</p>
    <p>C</p>
    <p>B</p>
    <p>A</p>
    <p>AA</p>
    <p>Human evaluation for zh-ja</p>
    <p>Corpus: JPO-NICT patent corpus</p>
    <p># of training data: 2M(en-ja), 1M(zh-ja/ko-ja)</p>
    <p># of automatic evaluation: 2,000</p>
    <p># of human evaluation: 200</p>
    <p>Automatic evaluation for en-ja/zh-ja/ko-ja</p>
    <p>* *</p>
    <p>en-ja zh-ja ko-ja</p>
    <p>SPE shows:</p>
    <p>- Better scores than PB-SMT in automatic evaluation</p>
    <p>- Improvements of understandable level (&gt;=C in acceptability)</p>
  </div>
  <div class="page">
    <p>2015 Toshiba Corporation 6</p>
    <p>System Combination</p>
    <p>How combine systems?</p>
    <p>Selection based on SMT scores and/or other features.</p>
    <p>Selection based on estimated score (Adequacy? Fluency? )</p>
    <p>Need data to learn the relationship</p>
    <p>Our approach in WAT2015:</p>
    <p>Merge n-best candidates and rescore them.</p>
    <p>We used RNNLM for reranking.</p>
    <p>SMT</p>
    <p>SPE</p>
    <p>N-best</p>
    <p>candidates</p>
    <p>N-best</p>
    <p>candidates</p>
    <p>Merge and Rescore Final translation</p>
  </div>
  <div class="page">
    <p>2015 Toshiba Corporation 7</p>
    <p>Reranking on the log-linear model</p>
    <p>Adding RNNLM score to default features of Moses.</p>
    <p>RNNLM trained by rnnlm toolkit (Mikolov 12).</p>
    <p>500,000 sentences for each language</p>
    <p># of hidden layer=500, # of class=50</p>
    <p>Tuning</p>
    <p>Using tuned weights without RNNLM, we ran only 1 iteration. (to reduce tuning time)</p>
    <p>Wlm=0.4</p>
    <p>Wtrans=0.1</p>
    <p>Wlm=0.2</p>
    <p>Wtrans=0.3</p>
    <p>Wlm=0.3</p>
    <p>Wtrans=0.2</p>
    <p>Wrnnlm=0.0</p>
    <p>RNNLM reranking and Tuning</p>
    <p>SMT</p>
    <p>SPE</p>
    <p>Dev</p>
    <p>Default</p>
    <p>features</p>
    <p>Default</p>
    <p>features</p>
    <p>Tuned</p>
    <p>weights</p>
    <p>Tuned</p>
    <p>weights</p>
    <p>New</p>
    <p>features</p>
    <p>Initial</p>
    <p>weights</p>
    <p>Linear interpolationAdding RNNLM</p>
    <p>MERT</p>
    <p>Tuned</p>
    <p>weights</p>
    <p>Wlm=0.2</p>
    <p>Wtrans=0.3</p>
    <p>Wrnnlm=0.3</p>
  </div>
  <div class="page">
    <p>2015 Toshiba Corporation 8</p>
    <p>Experimental Results</p>
    <p>ja-en en-ja ja-zh zh-ja</p>
    <p>JPOzh-ja JPOko-ja</p>
    <p>BLEU for ASPEC</p>
    <p>BLEU for Patent</p>
    <p>*SMT and SPE are 1-best results.</p>
    <p>SMT</p>
    <p>ja-en</p>
    <p>SPE COMB SMT</p>
    <p>en-ja</p>
    <p>SPE COMB SMT</p>
    <p>ja-zh</p>
    <p>SPE COMB SMT</p>
    <p>zh-ja</p>
    <p>SPE COMB</p>
    <p>SMT</p>
    <p>JPCzh-ja</p>
    <p>SPE COMB SMT</p>
    <p>JPCko-ja</p>
    <p>SPE COMB</p>
  </div>
  <div class="page">
    <p>2015 Toshiba Corporation 9</p>
    <p>Systems Rerank JPCzh-ja JPCko-ja</p>
    <p>BLEU RIBES BLEU RIBES</p>
    <p>RBMT No 25.81 0.764 51.28 0.902</p>
    <p>SMT No 38.77 0.802 70.17 0.943</p>
    <p>Yes 39.18 0.805 70.89 0.944</p>
    <p>SPE No 39.01 0.813 68.47 0.940</p>
    <p>Yes 39.30 0.811 68.76 0.940</p>
    <p>COMB Yes 40.23 0.813 70.40 0.942</p>
    <p>Systems Rerank ja-en en-ja ja-zh zh-ja</p>
    <p>BLEU RIBES BLEU RIBES BLEU RIBES BLEU RIBES</p>
    <p>RBMT No 15.31 0.677 14.78 0.685 19.51 0.767 15.39 0.767</p>
    <p>SMT No 17.41 0.620 25.17 0.642 28.20 0.810 36.34 0.810</p>
    <p>Yes 17.85 0.619 25.37 0.643 28.46 0.809 36.69 0.809</p>
    <p>SPE No 22.65 0.717 31.10 0.767 29.48 0.809 35.76 0.809</p>
    <p>Yes 22.92 0.718 31.73 0.770 29.49 0.809 36.06 0.809</p>
    <p>COMB Yes 23.00 0.716 31.82 0.770 29.60 0.810 37.47 0.810</p>
    <p>Experimental Results</p>
    <p>System Combination (COMB) achieved</p>
    <p>improvements of BLEU and RIBES score than SPE.</p>
    <p>COMB is the best system except JPCko-ja task.</p>
  </div>
  <div class="page">
    <p>2015 Toshiba Corporation 10</p>
    <p>Which systems did the combination selected?</p>
    <p>SMT</p>
    <p>SPE</p>
    <p>SAME</p>
    <p>SMT</p>
    <p>SPE</p>
    <p>SAME</p>
    <p>SMT</p>
    <p>SPE</p>
    <p>SAME</p>
    <p>SPE</p>
    <p>SAME</p>
    <p>SMT</p>
    <p>SPE</p>
    <p>SAME</p>
    <p>SMT</p>
    <p>SPE</p>
    <p>SAME</p>
    <p>ja-en en-ja ja-zh zh-ja</p>
    <p>JPCzh-ja JPCko-ja</p>
    <p>same means that COMB results were included both SMT and SPE.</p>
    <p>ja-en/en-ja/zh-ja: about 80% translations come from SPE.</p>
    <p>ja-zh and JPCzh-ja: COMB selected SPE and SMT, equivalently.</p>
    <p>(Because RBMT couldnt translate well, % of SMT increased. )</p>
  </div>
  <div class="page">
    <p>2015 Toshiba Corporation 12</p>
    <p>Toshiba MT system of WAT2015</p>
    <p>We additionally applied some pre/post processing.</p>
    <p>Technical Term</p>
    <p>Dictionaries</p>
    <p>Selecting RBMT</p>
    <p>dictionaries by devset.</p>
    <p>+ JPO patent dictionary</p>
    <p>(2.2M words</p>
    <p>for JPCzh-ja)</p>
    <p>English Word</p>
    <p>Correction</p>
    <p>Edited-distance based</p>
    <p>correction.</p>
    <p>continous -&gt; continuous</p>
    <p>behvior -&gt; behavior</p>
    <p>resolutin -&gt; resolution</p>
    <p>KATAKANA</p>
    <p>Normalization</p>
    <p>Normalize to highly</p>
    <p>frequent notations for .</p>
    <p>-&gt;   -&gt;</p>
    <p>Post-translation</p>
    <p>Translate remaining unknown</p>
    <p>words by RBMT.</p>
    <p>-&gt;  -&gt;</p>
  </div>
  <div class="page">
    <p>2015 Toshiba Corporation 13</p>
    <p>Official Results</p>
    <p>SPE and SMT ranked in the top 3 HUMAN in ja-en/ja-zh/JPCzh-ja.</p>
    <p>The correlation between BLEU/RIEBES and HUMAN is not clear in our</p>
    <p>system.</p>
    <p>System ja-en en-ja ja-zh zh-ja</p>
    <p>BLEU RIBES HUMAN BLEU RIBES HUMAN BLEU RIBES HUMAN BLEU RIBES HUMAN</p>
    <p>SPE 22.89 0.719 25.00 32.06 0.771 40.25 30.17 0.813 2.50 35.85 0.825 -1.00</p>
    <p>COMB 23.00 0.716 21.25 31.82 0.770 - 30.07 0.817 17.00 37.47 0.827 18.00</p>
    <p>System JPCzh-ja JPCko-ja</p>
    <p>BLEU RIBES HUMAN BLEU RIBES HUMAN</p>
    <p>SMT - - - 71.01 0.944 4.50</p>
    <p>SPE 41.12 0.822 24.25 - -</p>
    <p>COMB 41.82 0.821 14.50 70.51 0.942 3.00</p>
    <p>R = 0.2338</p>
    <p>R = 0.3813</p>
    <p>BLEU-HUMAN RIBES-HUMAN</p>
  </div>
  <div class="page">
    <p>2015 Toshiba Corporation 14</p>
    <p>Crowdsourcing Evaluation</p>
    <p>Analysis of JPCko-ja result (COMB vs Online A)</p>
    <p>In in-house evaluation, COMB is better than Online A.</p>
    <p>Effected by differences in number expressions !?</p>
    <p>SRC : (100)  Online A: (100)</p>
    <p>COMB(SMT): 100</p>
    <p>Equally evaluated in-house evaluation.</p>
    <p>Crowd-workers should be provided an evaluation guideline by</p>
    <p>which such a difference is considered.</p>
    <p>BLEU RIBES HUMAN</p>
    <p>Baseline COMB Online A</p>
    <p>COMB 70.51 0.94 3.00 - 10.75</p>
    <p>Online A 55.05 0.91 38.75 -10.75</p>
    <p>Official</p>
    <p>(Crowdsourcing)</p>
    <p>In-house evaluation</p>
    <p>results</p>
  </div>
  <div class="page">
    <p>2015 Toshiba Corporation 17</p>
    <p>Summary</p>
    <p>Toshiba MT system achieved a combination method</p>
    <p>between SMT and SPE by RNNLM reranking.</p>
    <p>Our system ranked the top 3 HUMAN score in ja-en/ja</p>
    <p>zh/JPCzh-ja.</p>
    <p>We will aim for practical MT system by more effective</p>
    <p>combination systems (SMT, SPE , RBMT and more...)</p>
  </div>
  <div class="page"/>
</Presentation>
