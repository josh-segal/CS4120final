<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Natural Language Processing for Intelligent Access</p>
    <p>to Scientific Information</p>
    <p>Francesco Ronzano and Horacio Saggion Natural Language Processing Group (TALN)</p>
    <p>Universitat Pompeu Fabra, Barcelona, Spain</p>
    <p>Tutorial @ COLING 2016 11th December 2016</p>
  </div>
  <div class="page">
    <p>TALN @ UPF</p>
    <p>Natural Language Processing Group</p>
    <p>Francesco Ronzano, Senior Post-doc</p>
    <p>Horacio Saggion, Research Professor</p>
  </div>
  <div class="page">
    <p>What its all about</p>
    <p>This tutorial provides an overview of the core content analysis challenges and opportunities of Scientific Literature Mining</p>
    <p>showing how we can characterize and take advantage of implicit and explicit traits of scientific publications to better organize and provide access to</p>
    <p>scientific literature</p>
    <p>Scientific literature is growing at an unprecedented rate</p>
    <p>Automated approaches to extract, enrich, aggregate and summarize information from scientific publications are essential to enable any</p>
    <p>careful and comprehensive assessment of scientific literature</p>
    <p>Natural Language Processing and Text Mining play a fundamental rule since they are key technologies to analyze scientific publications</p>
    <p>http://taln.upf.edu/pages/coling2016tutorial/</p>
  </div>
  <div class="page">
    <p>Outline  SCIENTIFIC INFORMATION OVERLOAD</p>
    <p>How much scientific literature is there out there? How can we search for and access to scientific information?</p>
    <p>DOCUMENT STRUCTURE ANALYSIS How can we extract textual contents from PDF papers? Which tools are there? How can we mine and link data form headers and bibliography?</p>
    <p>SCIENTIFIC DISCOURSE CHARACTERIZATION How can we spot the contributions of a piece of research? Where do the authors present their</p>
    <p>future work?</p>
    <p>CITATION ANALYSIS How can citations improve our access to scientific information? Are all citations equals? How can we suggest citations?</p>
    <p>SCIENTIFIC DOCUMENT SUMMARIZATION How can we take advantage of peculiar traits of scientific documents to generate better summaries?</p>
    <p>CHALLENGES, DATASETS AND ARCHITECTURES Which datasets are available for scientific text mining? Which tasks have been proposed?</p>
    <p>DR. INVENTOR TEXT MINING FRAMEWORK Whic scientific data analyses are supported? How can the framework be used in practice?</p>
    <p>GLOBAL CONCLUSIONS AND DISCUSSION</p>
  </div>
  <div class="page">
    <p>SCIENTIFIC INFORMATION OVERLOAD</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>How much scientific literature is there?</p>
    <p>How open is scientific literature?</p>
    <p>Who publish scientific articles?</p>
    <p>How researchers search and read publications?</p>
    <p>Academic social networks</p>
    <p>Social Media in academic communication</p>
    <p>Text mining opportunities and challenges</p>
  </div>
  <div class="page">
    <p>Scientific literature overload</p>
  </div>
  <div class="page">
    <p>How much scientific literature is there?</p>
    <p>Scientific Literature Overload</p>
    <p>(more than one new article every 13 seconds)</p>
    <p>Looking inside some citation database</p>
    <p>STM Report 2015 / citation database query</p>
    <p>(in 2013 about 2 million of new articles)</p>
    <p>(journal articles, books and grey literature, etc.)</p>
    <p>from more than 2,600 publishers</p>
  </div>
  <div class="page">
    <p>How much scientific literature is there?</p>
    <p>The growth in number of papers is proportional to the growth in number of scientific researchers all over the world (now between 7 and 9 million, only 20% repeated authors)</p>
    <p>STM Report 2015 Bornmann &amp; Mutz (2015). Growth rates of modern science.</p>
    <p>The number of paper published experimented an exponential growth during the last decades</p>
    <p>Global scientific publication growth (articles by year)</p>
    <p>Scientific Literature Overload</p>
    <p>(more than one new article every 13 seconds)</p>
  </div>
  <div class="page">
    <p>How much scientific literature is there?</p>
    <p>PubMed growth (articles by year)</p>
    <p>STM Report 2015 / PubMed</p>
    <p>Web of Science: in 2000, 8,684 journals. In 2005, 9,467 journals, an increase of 9%. In 2010 11,519 journals, a further increase of 22%.</p>
    <p>Scientific Literature Overload</p>
    <p>(more than one new article every 13 seconds)</p>
    <p>PubMed: from 1980 to 2003 the average growth is 2,9% per year, while from 2003 to 2013 it raised up to 6,7% per year</p>
  </div>
  <div class="page">
    <p>How much scientific literature is there? by country</p>
    <p>Elsevier, 2013</p>
    <p>The growth of scientific throughput of China: from 4,5% in 2002 to 17% currently  The citation count is dominated by USA (36%) with China in 11th place (6%), because of recent increase in scientific production</p>
    <p>Scientific Literature Overload</p>
  </div>
  <div class="page">
    <p>Who publish scientific articles?</p>
    <p>The long tail of publishing:  the top 100 journal publisher publish 67% of all journals  top 5 publishers are Springer, Elsevier, Wiley, Taylor&amp;Francis (35% of all journals)  many publishers with 1 or 2 journals</p>
    <p>STM Report 2015</p>
    <p>There are about 10,000 journal publishers globally 64% commercial publishers (including publishing for societies),</p>
    <p>Revenue:  $10 billion in 2013 ($8 billion in 2008)  55% from USA, 28% Europe/Middle east, 14% Asia/Pacific, 4% Others Employers:  110,000 people globally directly employed, 40% in EU (+ 20-30,000 people indirectly)</p>
    <p>Scientific Literature Overload</p>
  </div>
  <div class="page">
    <p>How open is scientific literature?</p>
    <p>Archambault et al. (2014). Proportion of open access papers published in peer-reviewed journals at the European and world levels19962013. Lewis, D. W. (2012). The inevitability of open access.</p>
    <p>Scientific Literature Overload</p>
    <p>The Open Access publishing model is consistently growing</p>
  </div>
  <div class="page">
    <p>How open is scientific literature?</p>
    <p>Scientific Literature Overload</p>
    <p>Open access growth Before 2021, globally more than half of the papers will be published as Open Access</p>
    <p>PlosONE, one of the biggest Open Access journals:  more than 34,000 articles per year (94 new articles per day)  2015 IF: 3.057</p>
    <p>Archambault et al. (2014). Proportion of open access papers published in peer-reviewed journals at the European and world levels19962013. Lewis, D. W. (2012). The inevitability of open access.</p>
    <p>The Open Access publishing model is consistently growing</p>
  </div>
  <div class="page">
    <p>How researchers search and read publications?</p>
    <p>Average number of articles read by year: about 270 (with several variations, depending on discipline - more in medicine and science, fewer in humanities and social sciences, increased from 188 in mid-1990s)</p>
    <p>Reading times of an article: about 30 minutes (went down from 45-50 minutes in the mid-1990s)</p>
    <p>STM Report 2015 Tenopir (2007) What does usage data tell us about our users?</p>
    <p>Scientific Literature Overload</p>
    <p>Clear growing importance of online literature search engines</p>
    <p>About 60% of article referrals of major publishers comes form one search engine, Google Scholar</p>
    <p>Publisher sites are accessed at article level (reduced importance of publisher site browsing)</p>
    <p>More reading, less time dedicated to each paper</p>
  </div>
  <div class="page">
    <p>How researchers search and read publications?</p>
    <p>Source: STM Report 2015 Source: Evans, J. A. (2008). Electronic publication and the narrowing of science and scholarship. science, 321(5887)</p>
    <p>Scientific Literature Overload</p>
    <p>Pros:  more comprehensive searches  more information to more extended audience Cons:  the articles cited tend to be more recent  there are fewer citations  most citations are to fewer journals and articles  weakening ability to explore scientific literature laterally finding in other studies and disciplines information potentially relevant to our current research</p>
    <p>The forced browsing of print archives may have stretched scientists and scholars to anchor findings deeply into past and present scholarship.</p>
    <p>Searching online is more efficient and following hyperlinks quickly puts researchers in touch with prevailing opinion, but this may accelerate consensus and narrow the</p>
    <p>range of findings and ideas built upon.</p>
    <p>Online search and access to scientific literature</p>
  </div>
  <div class="page">
    <p>How researchers search and read publications?</p>
    <p>Source: Khabsa &amp; Giles (2014). The number of scholarly documents on the public web. PloS one</p>
    <p>Scientific Literature Overload</p>
    <p>and the coverage of search engines</p>
    <p>About 24% of documents are freely available online with several differences across fields:</p>
  </div>
  <div class="page">
    <p>How researchers search and read publications?</p>
    <p>Improving and enriching their online offer and user experience (new tools: analytics, expertise search, etc.)</p>
    <p>Switching to exclusive online publishing:  currently all STM (International Association of Scientific, Technical, and Medical Publishers) journals can be accessible on-line  in 2003: 83%, in 2008: 96%  the number of established research journals dropping their print editions looks likely to accelerate over the coming few years</p>
    <p>Offering enhanced article-level access and easing the integration of their contents into third-party platforms by:</p>
    <p>providing enriched and linked versions of publications  exposing Open APIs</p>
    <p>Source: STM Report 2015</p>
    <p>Scientific Literature Overload</p>
    <p>How publishers are dealing with online scientific literature search and access?</p>
  </div>
  <div class="page">
    <p>Academic social networks</p>
    <p>Sources: STM Report 2015 / factsheets of academic networks</p>
    <p>Scientific Literature Overload</p>
    <p>Why academic social networks are used?  connecting with other researchers  make own research more visible and follow the updates of other researchers  like an online business card</p>
    <p>more than 11 million users (150.000 members in August 2008, 700.000 in December 2010, one</p>
    <p>million by May 2011, and 2 million in September 2012)</p>
    <p>more than 44 million registered users (16,205,767 papers added and 1,953,015 research interests</p>
    <p>specified) Academia.edu attracts over 36 million unique visitors a month</p>
    <p>about 4 million users (part of Elsevier from 2013)  470 million documents</p>
  </div>
  <div class="page">
    <p>Social Media in academic communication</p>
    <p>Sugimoto et al. (2016). Scholarly use of social media and altmetrics: a review of the literature.</p>
    <p>Scientific Literature Overload</p>
    <p>But there is still a long way to go to achieve broad Social Media adoption  growing impact but still limited when compared to conventional channels (in several surveys the percentage of researchers that actively use Social Media ranges from 3% to 32%)</p>
    <p>used mainly as complementary channels to make more visible the research than as means to interact, discuss with other users or to keep updated with new findings  proliferation of too many potentially useful platforms to consider</p>
    <p>Main obstacles to the use of Social Media:  lack of clearly compelling benefits with respect to the time needed to publishing material and manage interactions  quality and trust issues</p>
    <p>A wider adoption of altmetrics can foster the use of Social Media in scholarly communication</p>
    <p>Social Media are experimenting an increasing adoption as complementary channel to promote and discuss scientific publications and events</p>
  </div>
  <div class="page">
    <p>Text mining opportunities and challenges</p>
    <p>Natural Language Processing and Text Mining are starting to emerge as key technologies able to help scientists to deal with scientific literature overload</p>
    <p>Scientific Literature Overload</p>
    <p>Citation network / data linking</p>
    <p>BACKGROUND</p>
    <p>APPROACH</p>
    <p>BACKGROUND</p>
    <p>FUTURE WORK</p>
    <p>Scientific discourse</p>
    <p>Entities and relations Content relevance</p>
    <p>Algorithm</p>
    <p>Tool</p>
    <p>Dataset</p>
    <p>evaluated on</p>
    <p>im p</p>
    <p>le m</p>
    <p>e n</p>
    <p>te d</p>
    <p>b y</p>
    <p>SUMMARY</p>
    <p>The analysis of the structure and the semantics of full textual contents of scientific publications enables a wide range of new approaches to easily retrieve, compare and summarize scientific literature</p>
  </div>
  <div class="page">
    <p>Text mining opportunities and challenges</p>
    <p>Natural Language Processing and Text Mining are starting to emerge as key technologies able to help scientists to deal with scientific literature overload</p>
    <p>Scientific Literature Overload</p>
    <p>Opportunities (use cases):</p>
    <p>BACKGROUND APPROACH</p>
    <p>BACKGROUND FUTURE WORK</p>
    <p>search for information scoped to specific sections of the discursive structure  validating how scientific contents are exposed  scientific-discourse driven summaries</p>
    <p>SUMMARY  automated generation of state-of-the-art reviews  support fast scientific literature screening, thus reducing the efforts needed for literature reviews</p>
    <p>Challenges:  huge, evolving amounts of data  data collection, extraction, normalization  error rate of automated approaches</p>
    <p>high variety of knowledge domains  diversified information needs  data often protected by copyrights</p>
  </div>
  <div class="page">
    <p>Text mining opportunities and challenges</p>
    <p>Natural Language Processing and Text Mining are starting to emerge as key technologies able to help scientists to deal with scientific literature overload</p>
    <p>Scientific Literature Overload</p>
    <p>Access to full texts of publications: copyright issues</p>
    <p>Major publishers have defined their Text and data mining policy (limitation to text for restricted access, subject to license restriction for OA)</p>
    <p>Questions and answers on the modernization of EU copyright rules for the digital age - European Union, 14 September 2016: http://europa.eu/rapid/press-release_MEMO-16-3011_en.htm</p>
    <p>The Commission proposes a new mandatory exception, which would require all Member States to permit research organizations acting in the public interest  such as universities and research institutes  to carry out text and data mining of copyright protected content to which they have lawful access, for example scientific publications they have subscribed to, without the need of a prior authorization. The exception will not apply to commercial companies.</p>
  </div>
  <div class="page">
    <p>Text mining opportunities and challenges</p>
    <p>Natural Language Processing and Text Mining are starting to emerge as key technologies able to help scientists to deal with scientific literature overload</p>
    <p>Scientific Literature Overload</p>
    <p>Access to full texts of publications: copyright issues</p>
    <p>Include in CrossRef metadata that describe each bibliographic entry a standard set of license information fields that clearly specify</p>
    <p>the limitations and the way to access and mine the full textual contents of papers</p>
    <p>http://tdmsupport.crossref.org/</p>
    <p>12 publishers involved in the definition of license metadata (Elsevier, Springer, Wiley, etc.)  common mechanism for providing automated text and data mining tools with direct links to full text on the publishers site</p>
  </div>
  <div class="page">
    <p>Text mining opportunities and challenges</p>
    <p>Natural Language Processing and Text Mining are starting to emerge as key technologies able to help scientists to deal with scientific literature overload</p>
    <p>Scientific Literature Overload</p>
    <p>This tutorial provides an overview of the core content analysis challenges and opportunities of Scientific Literature Mining</p>
    <p>showing how we can characterize and take advantage of implicit and explicit traits of scientific publications to better organize and provide</p>
    <p>access to scientific literature</p>
    <p>Document Structure Analysis</p>
    <p>Scientific Discourse Characterization</p>
    <p>Citation Analysis Scientific Document</p>
    <p>Summarization</p>
  </div>
  <div class="page">
    <p>DOCUMENT STRUCTURE ANALYSIS</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Document formats: dealing with PDF</p>
    <p>Genral-purpose PDF-to-text tools</p>
    <p>PDF-to-text for scientific publications</p>
    <p>Comparing PDF-to-text for scientific publications</p>
    <p>Bibliographic entry parsing</p>
    <p>Annotated datasets</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Document formats: dealing with PDF</p>
    <p>Despite the many XML dialects and scientific publishing technologies proposed during the last few years,</p>
    <p>PDF still constitutes the most widespread distribution format of scientific publications</p>
    <p>(80% of scientific literature is accessed as PDF documents)</p>
    <p>Why PDF are so popular?</p>
    <p>mature technologies (1993, Adobe)  preserved format across platform with several tools to visualize and annotate it  easy to store and organize for off-line reading  self contained files: capture the article in a stable, read-only form  can include high-resolution images  print-friendly  can be reasonably protected without the use of dedicated servers</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>Document formats: dealing with PDF</p>
    <p>Despite the many XML dialects and scientific publishing technologies proposed during the last few years,</p>
    <p>PDF still constitutes the most widespread distribution format of scientific publications</p>
    <p>(80% of scientific literature is accessed as PDF documents)</p>
    <p>Some drawbacks  manipulation is dependent on a commercial software (even if some open-source alternative is available)  impossible to include multimedia material / low level of interactivity with contents (internal / external hyperlinks)  visualization not customized to the device  difficult to extract structured textual information</p>
    <p>Do you expect that the way they access and use articles today to change in the future? (281 responses of researchers in a variety of fields)</p>
    <p>Yes 36% Maybe</p>
    <p>Prob. not 10%</p>
    <p>Not 3%</p>
    <p>Not sure 5%</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>Document formats: dealing with PDF</p>
    <p>PDF is a layout based data format for professional document rendering</p>
    <p>Each PDF document is characterized by a body made of a set of objects that are usually grouped into pages: numbers, strings, streams, arrays, dictionaries, etc.</p>
    <p>Each object in the stream is assigned a special location inside a page viewport (as well as a special size and style if applicable)</p>
    <p>Objects are declared in the body of the PDF files, often non sequentially</p>
    <p>A cross-reference table (xref) lists all the objects providing the file offset of each of them (optimized for reading, no need to explore the contents of the whole PDF file)</p>
    <p>Object 1 Text: This Postion: (x1, y1)</p>
    <p>Offset of Obj. 1 Offset of Obj. 2</p>
    <p>Offset of Obj. n</p>
    <p>B O</p>
    <p>D Y</p>
    <p>X</p>
    <p>R E</p>
    <p>F</p>
    <p>Object 2 Image: binEnco Postion: (x2, y2)</p>
    <p>Object n Text: Reference Postion: (xn, yn)</p>
    <p>This</p>
    <p>(x1, y1)</p>
    <p>Reference</p>
    <p>(xn, yn)</p>
    <p>(x2, y2)</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>Document formats: dealing with PDF</p>
    <p>Customized approaches are necessary to extract structured textual information from the PDF of scientific publications</p>
    <p>robust with respect to different document layouts a random sample of 125,000 publications from PubMed contains articles of 500 publishers, each one with its own layout and style</p>
    <p>covering and customized to the wide set of structural elements of scientific articles</p>
    <p>Title: A Comparison of Layout based Bibliographic Metadata Extraction Techniques Author 1 Name: Michael Grantizer Author 1 Affiliation: University of Passau, Germany Author 1 Email: Michael.Grantizer@uni-passau.de Abstract: Social research networks such as Mendeley and CiteULike offer various services for collaboratively managing bibliographic metadata</p>
    <p>The quality of scientific text mining often depends in the first place to the quality of the extraction of semi-structured textual contents from the original PDF file</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>General purpose PDF-to-text software</p>
    <p>Java library Apache Project (actively maintained) 2.0.3 released on 17/9/2016</p>
    <p>C ++ code Freeware, based on xpdf 2.1 released on 14/6/2014</p>
    <p>Try and compare these tools and others at: http://backingdata.org/pdfconv/</p>
    <p>C++ code Open source, based on xpdf 0.49.0 released on 15/11/2016</p>
    <p>Used by GIMP, Okular, Pdf2HTMLex, etc.</p>
    <p>Commercial Specialized to extract tables, word lists and other elements</p>
    <p>JPedal</p>
    <p>also , , etc.</p>
    <p>Convert PDF files to plain text, XML / HTML files with some layout information</p>
    <p>https://github.com/itext/itext7</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>General purpose PDF-to-text software Example of XML output</p>
    <p>generated by</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>General purpose PDF-to-text software</p>
    <p>Open source project (GPL v3) of layout-preserving PDF to HTML converter (C++ mainly, based on Poppler to process PDF files)</p>
    <p>Each PDF file is converted in an HTML file made of a set of DIV elements properly positioned inside the page viewport</p>
    <p>&lt;div class=&quot;t x1 h1 y1 ff1 fs0 fc0 ws0&quot;&gt;Languages&lt;/div&gt;</p>
    <p>HTML source</p>
    <p>.x1 { left: 441.233569px; } .y1 { bottom: 1139.024816px; } .h1 { height: 49.637990px; } .ff1 { font-family: ff1; line-height: 0.898000;}</p>
    <p>.fs0 { font-size: 71.731200px; } .fc0 { color: rgb(0,0,0); } .ws0 { word-spacing: 0.000000px; } .t { position: absolute; white-space: pre; }</p>
    <p>CSS CLASSES TO DEFINE THE LAYOUT</p>
    <p>Used by:</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>PDF-to-text for scientific publications</p>
    <p>Integrating a general purpose PDF-to-text converter and post processing its output</p>
    <p>Implementing customized approaches to identify structural elements proper of scientific publications like: title, authors and affiliations, abstract, section heading and contents, figures, tables, formulas, bibliographic entries, in-line citation markers, etc.</p>
    <p>Robust to varied publishing styles</p>
    <p>SectLabel</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>PDF-to-text for scientific publications</p>
    <p>http://cermine.ceon.pl/ https://github.com/CeON/CERMINE</p>
    <p>Tkaczyk, D., Szostek, P., Fedoryszak, M., Dendek, P. J., &amp; Bolikowski, . (2015). CERMINE: automatic extraction of structured metadata from scientific literature. nternational Journal on Document Analysis and Recognition (IJDAR), 18(4), 317-335.</p>
    <p>Java, open-source (GitHub) - libSVM  PDF analysis: based on both layout features and contents  Output: JATS XML</p>
    <p>https://github.com/itext/itext7</p>
    <p>Split words into chars (height, width, x, y), then apply Docsum:  hierarchical grouping of elements relying on: nearest neighbor pairs of chars, averages distances among chars and lines, line parallelness and overlap, etc.  hierarchy of structural elements: chars, words, lines, zones, pages</p>
    <p>EXTRACTION OF HIERARCHY OF BASIC STRUCTURAL ELEMENTS PDF-TO-XML CONVERSION</p>
    <p>TEXT READING ORDER IDENTIFICATION</p>
    <p>HIGH-LEVEL ZONE</p>
    <p>CLASSIFICATION</p>
    <p>Algorithm: SVM Classes: metadata, references, body Feats: geometric, sequential, lexical, heuristics on content</p>
    <p>Algorithm: SVM Classes: title, author, affiliation, editor, correspondence, type, abstract, keywords, bib_info, dates</p>
    <p>METADATA ZONE CLASSIFICATION</p>
    <p>Algorithm: kMeans (k=2) to group reference lines into first line of bib. entry / other Feats: line length, indentation, space between lines, etc.</p>
    <p>BIB. ENTRIES IDENTIFICATION Algorithm: CRF Classes: firstname, surname, title, source, volume, infopage, year, etc. Feats: 42 like special chars, match in dict. lists, etc.</p>
    <p>BIB. ENTRIES PARSING</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>PDF-to-text for scientific publications</p>
    <p>http://cermine.ceon.pl/ https://github.com/CeON/CERMINE</p>
    <p>Tkaczyk, D., Szostek, P., Fedoryszak, M., Dendek, P. J., &amp; Bolikowski, . (2015). CERMINE: automatic extraction of structured metadata from scientific literature. nternational Journal on Document Analysis and Recognition (IJDAR), 18(4), 317-335.</p>
    <p>Zone classifier (high-level and metadata) trained and evaluated on the GROTOAP2 dataset:  2,651 document from PubMed available as PDF + JATS XML  for each PDF + JATS XML pair of files:</p>
    <p>PDF processed by CERMINE  JATS XML annotations used to label the zones identified by CERMINE (text sequence alignment algorithm)</p>
    <p>analyzing a sample of the subset of the transferred annotations, a set of heuristic rules to improve the quality of annotation transfer is developed and applied to each document Citation parser trained and evaluated on the three datasets: 4,000 parsed citations: 2,000 from CiteSeer and Cora-ref and 2,000 from 1991 different PMC documents</p>
    <p>TRAINING AND EVALUAITON OF SVM / CRF</p>
    <p>RESULTS:  Citation parsing F-score: 93,3%  Metadata and Bibliography extraction F-score (47,983 PDF + metadata records): 77,5%</p>
    <p>Document Structure Analysis</p>
    <p>LAYOUT</p>
  </div>
  <div class="page">
    <p>PDF-TO-XML CONVERSION (token info)</p>
    <p>PDF-to-text for scientific publications</p>
    <p>https://grobid.readthedocs.io/ https://github.com/kermitt2/grobid</p>
    <p>Java (with JNI call to native CRF libraries: CRF++ or Wapiti) open-source (GitHub)  PDF analysis with CRF exploiting both layout features and contents  Output: TEI XML</p>
    <p>position information (begin/end of line, in the doc.)  lexical information (vocabulary, large gazetteers)  layout information (font size, block, etc.)</p>
    <p>HIERARCHY OF CRF SEQUENCE TAGGERS</p>
    <p>Lopez, P. (2009, September). GROBID: Combining automatic bibliographic data recognition and term extraction for scholarship publications. In International Conference on Theory and Practice of Digital Libraries (pp. 473-474). Springer Berlin Heidelberg. .</p>
    <p>Document segmentation hierarchy Bibliographic entry segmentation hierarchy</p>
    <p>9 CRF models for full texts  14 intermediary labels in total  55 final labels</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>PDF-to-text for scientific publications</p>
    <p>https://grobid.readthedocs.io/ https://github.com/kermitt2/grobid</p>
    <p>Lopez, P. (2009, September). GROBID: Combining automatic bibliographic data recognition and term extraction for scholarship publications. In International Conference on Theory and Practice of Digital Libraries (pp. 473-474). Springer Berlin Heidelberg. .</p>
    <p>Each model with its own set of features, specialized to tag certain fields  Training sets specific to each model included in the software (see table)  Trainer framework to generate and manually validate new training examples from a collection of PDF files  Best performing header metadata extraction tool over 7 (Lipinski et al. 2013)</p>
    <p>TRAINING AND EVALUATION OF CRF</p>
    <p>A customized versions of GROBID is exploited by:</p>
    <p>Extraction of bibliographic entries and matching against internal DB  about 300,000 PDF processed monthly (16 nodes Hadoop cluster)  failure rate of 1% of user uploaded PDF</p>
    <p>Document Structure Analysis</p>
    <p>Model N training examples</p>
    <p>Exploit layout</p>
  </div>
  <div class="page">
    <p>PDF-to-text for scientific publications</p>
    <p>http://pdfx.cs.man.ac.uk/</p>
    <p>Online Web Service (Max 5Mb)  PDF analysis is rule-based, relying on both layout features and contents  Output: JATS compliant XML files</p>
    <p>Two steps PDF analysis: STEP 1: a geometrical model of the textual contents and the layout of the information contained in the PDF is build:</p>
    <p>each word described is by orientation, position, font, etc.  global document stats: most frequent font size and style, average line spacing and font spacing, etc.  neighbor words sharing similar text features are merged into blocks</p>
    <p>STEP 2: based on the layout features previously spotted, a set of rules is exploited to merge blocks into regions and iteratively identify 18 elements Inside the document (also on the basis o the surrounding elements) Constantin, A., Pettifer, S., &amp; Voronkov, A. (2013, September). PDFX: fully-automated PDF-to-XML conversion of scientific literature. In Proceedings of the 2013 ACM symposium on Document engineering (pp. 177-180). ACM.</p>
    <p>.</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>PDF-to-text for scientific publications</p>
    <p>http://pdfx.cs.man.ac.uk/</p>
    <p>Constantin, A., Pettifer, S., &amp; Voronkov, A. (2013, September). PDFX: fully-automated PDF-to-XML conversion of scientific literature. In Proceedings of the 2013 ACM symposium on Document engineering (pp. 177-180). ACM. .</p>
    <p>EVALUATION</p>
    <p>50,000 PDF + XML articles published by Elsevier in 2008  1,943 PDF + XML articles published in the PMC Open Access Subset in 2011 each one from a different journal</p>
    <p>F-score per class  0,95 similarity threshold between extracted and original textual contents of each field</p>
    <p>Elsevier dataset more curated  PMC dataset suffers the high variation in style due to the presence of 1,943 articles each one from a different journal  tables are with both datasets difficult to identify, while title and email are the easiest to spot</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>PDF-to-text for scientific publications</p>
    <p>https://github.com/knmnyn/ParsCit/tree/master/bin/sectLabel SectLabel</p>
    <p>Perl and Ruby (CRF++), open-source (GitHub), process Omnipage output  PDF analysis relying on both layout features and contents</p>
    <p>Luong, M. T., Nguyen, T. D., &amp; Kan, M. Y. (2012). Logical structure recovery in scholarly articles with rich document features. Multimedia Storage and Retrieval Innovations for Digital Library Systems, 270. Councill, I. G., Giles, C. L., &amp; Kan, M. Y. (2008, May). ParsCit: an Open-source CRF Reference String Parsing Package. In LREC (Vol. 8, pp. 661-667).</p>
    <p>PDF-TO-XML CONVERSION</p>
    <p>(line based repr.)</p>
    <p>ALL LINES LABELING</p>
    <p>Algorithm: CRF Classes (26): address, affiliation, author, bodyText, categories, construct, copyright, email, equation, figure, figureCaption, footnote, keywords, listItem, note, page, reference, sectionHeader, subsectionHeader, subsubsectionHeader, table, tableCaption, title Line feats: location, number, punctuation, length, format / layout, differences in format / layout with previous and following lines</p>
    <p>HEADER LINE LABELING</p>
    <p>Algorithm: CRF, applied only to lines classified as Header in the previous step Classes (13): abstract, categories, general terms, keywords, introduction, background, related work, methodology, evaluation, discussions, conclusions, acknowledgements, references Line feats: location, number, punctuation, length, format / layout, differences in format / layout with previous and following lines</p>
    <p>EVALUATION Adding to textual / content features also layout features improves the F-score of about 10 points (up to 84%) and is particularly beneficial for sections like metadata, captions, hierarchical headers</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>PDF-to-text for scientific publications</p>
    <p>https://github.com/BMKEG/lapdftextProject</p>
    <p>Ramakrishnan, C., Patnia, A., Hovy, E., &amp; Burns, G. A. (2012). Layout-aware text extraction from full-text PDF of scientific articles. Source code for biology and medicine, 7(1), 1.</p>
    <p>Java, open-source (GitHub)  PDF analysis is rule-based, relying on both layout features and contents  Output: JATS XML</p>
    <p>PDF-TO-XML CONVERSION (word blocks</p>
    <p>detection)</p>
    <p>JPedal</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>How header metadata are extracted from a PDF document?</p>
    <p>PDF-to-text for scientific publications</p>
    <p>https://www.mendeley.com/download-mendeley-desktop/</p>
    <p>Initial approach: PDF to text by means of PDFnet software (commercial) then apply iterative multi-step SVM classifier (RBF kernel) as in:</p>
    <p>Han, H., Giles, C. L., Manavoglu, E., Zha, H., Zhang, Z., &amp; Fox, E. A. (2003) Automatic document metadata extraction using support vector machines.</p>
    <p>In Digital Libraries proceedings. 2003 Joint Conference IEEE.</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>How header metadata are extracted from a PDF document?</p>
    <p>PDF-to-text for scientific publications</p>
    <p>https://www.mendeley.com/download-mendeley-desktop/</p>
    <p>Later approach:</p>
    <p>Trained on a large set of papers  Fields: title, authors, DOI, publication, volume, issue, year, page, ranges</p>
    <p>https://mendeleyapi.wordpress.com/2014/10/15/pdf-extraction-gets-a-boost-with-our-new-api-service/ https://krisjack.wordpress.com/2015/03/12/how-well-does-mendeleys-metadata-extraction-work/</p>
    <p>Evaluation:  Dataset: 26,000 PDFs with perfect metadata record in Mendeley Catalogue</p>
    <p>2,4% couldnt be converted to XML by pdftoxml  83,9% can be processed extracting perfect metadata records: authors, title, year, and publication venue (e.g. journal, conference, magazine)</p>
    <p>If you drop 10 PDFs into your Mendeley Library then, on average, youll get perfect, citable metadata for 8-9 of them.</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>Comparing PDF-to-text for scientific publications</p>
    <p>Lipinski, M., Yao, K., Breitinger, C., Beel, J., &amp; Gipp, B. (2013, July). Evaluation of header metadata extraction approaches and tools for scientific PDF documents.</p>
    <p>In Proceedings of the 13th ACM/IEEE-CS joint conference on Digital libraries (pp. 385-386). ACM.</p>
    <p>SectLabel</p>
    <p>Dataset: 1,153 random PDF articles from arXiv together with their metadata (title, authors, year, abstract) dealing with Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance and Statistics</p>
    <p>Evaluation: A100: 100 randomly selected articles and manual evaluation: 1 perfect match, 0.5 accent or ligature issues, 0.25 partial match, 0 no match B100: 100 randomly selected articles and automated evaluation: Levenshtein distance normalized by the length of the reference value for the field B1153: whole dataset and automated evaluation: Levenshtein distance normalized by the length of the reference value for the field</p>
    <p>Accuracy values</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>Comparing PDF-to-text for scientific publications</p>
    <p>Tkaczyk, D., Szostek, P., Fedoryszak, M., Dendek, P. J., &amp; Bolikowski, . (2015). CERMINE: automatic extraction of structured metadata from scientific literature.</p>
    <p>nternational Journal on Document Analysis and Recognition (IJDAR), 18(4), 317-335.</p>
    <p>Dataset: 1,943 pairs of PDF + JATS XML documents retrieved from PubMed Open Access Subset</p>
    <p>Evaluation: metadata extraction of CERMINE and other 4 similar tools (exact match)</p>
    <p>In every cell there is precision, recall and F-score value</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>Bibliographic entry parsing</p>
    <p>Tools:  most of them based on: rules or sequence taggers like HMM and CRF  some example:</p>
    <p>FreeCite: CRF++ library, CORA dataset, open-source (ruby), Web API http://freecite.library.brown.edu/  ParsCit: CRF++ library, open source (perl and C++) https://github.com/knmnyn/ParsCit</p>
    <p>Web API:</p>
    <p>Web services that match against a citation database:  CrossRef Metadata Search API: find metadata by DOI or by bibliographic entry string http://search.crossref.org/help/api  Bibsonomy REST API  search posts by string: https://bitbucket.org/bibsonomy/bibsonomy/wiki/documentation/api/REST%20A PI https://www.bibsonomy.org/api/posts?resourcetype=bookmark&amp;search=SemKey</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>Annotated datasets CORA Field Extraction dataset https://people.cs.umass.edu/~mccallum/data/cora-ie.tar.gz Seymore, K., McCallum, A., &amp; Rosenfeld, R. (1999, July). Learning hidden Markov model structure for information extraction. In AAAI99 Workshop on Machine Learning for Information Extraction (pp. 37-42).</p>
    <p>500 tagged references: author, title, journal, volume, pages, date  937 headers: title, author, affiliation, address, email, abstract, keywords</p>
    <p>FluXcim Citation dataset https://github.com/knmnyn/ParsCit/blob/master/doc/flux-cim-cs.tagged.txt Cortez, E., da Silva, A. S., Gonalves, M. A., Mesquita, F., &amp; de Moura, E. S. (2007, June). FLUX-CIM: flexible unsupervised extraction of citation metadata. In Proceedings of the 7th ACM/IEEE-CS joint conference on Digital libraries(pp. 215-224). ACM.</p>
    <p>300 citation strings randomly from ACM Digital Library - CORA format</p>
    <p>UMASS Citation dataset http://www.iesl.cs.umass.edu/data/umasscitationfield Anzaroot, S., &amp; McCallum, A. (2013). A new dataset for fine-grained citation field extraction. In ICML Workshop on Peer Reviewing and</p>
    <p>Publishing Models.  from arXiv papers in physics, mathematics, computer science and quantitative biology  1,800 citations hierarchically labeled as:</p>
    <p>ref-markers  author  first, middle, last and affix  title</p>
    <p>venue  publisher, note, web, institution, department, etc.  date  year and month  reference-id</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>Annotated datasets CiteSeer Citation dataset https://github.com/knmnyn/ParsCit/blob/master/doc/citeseerx.tagged.txt Lawrence, S., Giles, C. L., &amp; Bollacker, K. D. (1999, April). Autonomous citation matching. In Proceedings of the third annual conference on Autonomous Agents (pp. 392-393). ACM.</p>
    <p>200 tagged references: author, titile, journal, volume, pages, date</p>
    <p>GROTOAP2 - GROund Truth for Open Access Publications http://cermine.ceon.pl/grotoap2/ Tkaczyk, D., Szostek, P., &amp; Bolikowski, L. (2014). GROTOAP2 The Methodology of Creating a Large Ground Truth Dataset of Scientific Articles. D-Lib Magazine, 20(11), 13.</p>
    <p>13,210 ground truth files in TrueViz XML format (1,640,973 zones in total)  each one corresponding to a PDF + JATS XML of the Open Access Subset of PubMed Central  thanks to TrueViz, each file is represented as a hierarchy of structural elements:</p>
    <p>a list of pages  each page contains a list of zones  each zone contains a list of lines  each line contains a list of words  and finally each word contains a list of characters</p>
    <p>Structural elements have: text content, position on the page and dimensions. Also the natural reading order for all structure elements is specified.</p>
    <p>Each zone has labels (imported from PubMed) describing the role in the document are assigned to zones. There are 22 labels including: abstract, aknowledgments, affiliation , author, bib_info, body_content, conflict_statement, copyright, dates, editor, equation, etc.</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>A precise extraction of structured textual contents from the PDF of scientific publications is essential to enable any further text processing of their contents</p>
    <p>Several PDF-to-text conversion tools are available, both general purpose and customized to scientific publications</p>
    <p>Such tools usually rely on both layout and textual features of scientific publications and are rule-based or rely on supervised machine learning approaches</p>
    <p>A rich set of annotated corpora is freely available for further experimentation</p>
    <p>Document Structure Analysis</p>
  </div>
  <div class="page">
    <p>SCIENTIFIC DISCOURSE CHARACTERIZATION</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>What is scientific discourse?</p>
    <p>Scientific discourse characterization  Annotation procedures and annotated corpora</p>
    <p>Automated annotation of scientific texts</p>
    <p>Overview of available datasets</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>What is scientific discourse?</p>
    <p>Scientific discourse concerns the characterization of how content is presented, discussed and motivated in scientific literature</p>
    <p>BACKGROUND</p>
    <p>APPROACH</p>
    <p>OUTCOME</p>
    <p>The most effective sources of supervision for training statistical parsers are treebanks.</p>
    <p>Unfortunately, treebanks are expensive, time-consuming to create, and not available for most domains.</p>
    <p>CONTRAST</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>What is scientific discourse?</p>
    <p>Why making scientific discourse explicit? Provide new dimensions to drive the automated</p>
    <p>analysis of scientific publications</p>
    <p>ease the interpretation of the information flow  contextualize contents and characterize their connections with related pieces of research  discover relevant aspects, novelties and future directions  support tasks like targeted information extraction, content retrieval and summarization  assess the quality of content exposition</p>
    <p>Scientific discourse concerns the characterization of how content is presented, discussed and motivated in scientific literature</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Steps towards the characterization and automated annotation of scientific discourse</p>
    <p>Annotation procedure and annotated corpus</p>
    <p>definition of annotation schema  corpus annotation:</p>
    <p>corpus content selection  annotation guidelines and procedure  annotation results</p>
    <p>Automated annotation of scientific texts</p>
    <p>algorithmic approach  feature engineering</p>
    <p>BACKGROUND</p>
    <p>APPROACH</p>
    <p>BACKGROUND</p>
    <p>FUTURE WORK</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Two main approaches to the rhetorical analysis of a text:</p>
    <p>Annotation procedure and annotated corpus</p>
    <p>Zone Analysis: characterization of the global rhetorical status of each text unit (sentence)</p>
    <p>Rhetorical Structure Theory: relations between clauses or larger text segments</p>
    <p>The most effective sources of supervision for training statistical parsers are treebanks.</p>
    <p>Unfortunately, treebanks are expensive, time-consuming to create, and not available for most domains.</p>
    <p>CONTRAST</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Rhetorical Structure Theory (Mann &amp; Thompson)</p>
    <p>Coherent texts consist of minimal units, which are linked to each other, recursively, through rhetorical relations</p>
    <p>thus generating a tree-like representation of a text</p>
    <p>Many neo-pagan religions, such as Wicca, use aspects of ancient Greek religions in their practice; Hellenic polytheism instead focuses exclusively on the old religions, as far as the fragmentary nature of the surviving source material allows.</p>
    <p>Many neopagan religions, such as Wicca, use aspects of ancient Greek</p>
    <p>religions in their practice;</p>
    <p>Hellenic polytheism</p>
    <p>instead focuses exclusively on</p>
    <p>the old religions,</p>
    <p>as far as the fragmentary nature of the</p>
    <p>surviving source material allows.</p>
    <p>Annotation procedure and annotated corpus</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>23 relations (symmetric and not; several extensions proposed)  the text is represented by a recursive tree structure (the most relevant minimal units are usually placed on the top)</p>
    <p>Among others, exploited to:  Check text coherence  Natural Language Generation  Corpus analysis and study of discourse phenomena  Text summarization</p>
    <p>Rhetorical Structure Theory (Mann &amp; Thompson)</p>
    <p>Coherent texts consist of minimal units, which are linked to each other, recursively, through rhetorical relations</p>
    <p>thus generating a tree-like representation of a text</p>
    <p>Annotation procedure and annotated corpus</p>
    <p>Many neopagan religions, such as Wicca, use aspects of ancient Greek</p>
    <p>religions in their practice;</p>
    <p>Hellenic polytheism</p>
    <p>instead focuses exclusively on</p>
    <p>the old religions,</p>
    <p>as far as the fragmentary nature of the</p>
    <p>surviving source material allows.</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Zone Analysis</p>
    <p>Annotation procedure and annotated corpus</p>
    <p>Several annotations schemes and procedures have been proposed to characterize text units with respect to:</p>
    <p>the type and complexity of the discourse elements identified</p>
    <p>the type of text units to which the discourse is applied (sentences, segments of sentences, specific relations or events occurring in these sentences)</p>
    <p>Knowledge Claim discourse Model and Argumentative Zoning</p>
    <p>Core Scientific Concepts</p>
    <p>IMRAD structure</p>
    <p>Dr. Inventor Scientific Discourse Schema</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>The argumentative structure of a scientific article is based on the need of authors to convince the reader of their contributions</p>
    <p>by claiming the ownership of a new piece of knowledge Scientific discourse develops throughout a set of rhetorical moves that are explicit statements, referred to</p>
    <p>as Knowledge Claims, useful to characterize and justify the contributions of a specific piece of work</p>
    <p>Properties of research space</p>
    <p>Properties of new solution (US)</p>
    <p>Properties of existing solution (THEM)</p>
    <p>Relationship between existing and new solution (US and THEM)</p>
    <p>Open domain word sense disambiguation presents several interesting challenges both semantic and computational.</p>
    <p>The proposed methodologies solves the issues related with the high computational cost of knowledge analysis.</p>
    <p>The method proposed by Ray et. al., 2010 stressed the importance of correctly dealing with semantic draft.</p>
    <p>Our solution improves the previous state-of-the-art method (Gil et al., 2012) by exploiting a new set of data sources.</p>
    <p>EXAMPLES OF RHETORICAL MOVES</p>
    <p>Zone Analysis: Knowledge Claim Discourse Model</p>
    <p>Annotation procedure and annotated corpus</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Annotation categories are defined on the basis of who owns the knowledge claim</p>
    <p>AZ Corpus  80 conference articles in computational linguistics  12,188 sentences assigned to one of 7 Categories  Avg. annotator agreement K: 0,71</p>
    <p>Online at (SciXML format): http://www.cl.cam.ac.uk/~sht25/AZ_corpus.html</p>
    <p>AZ Annotation Schema</p>
    <p>Argumentative Zoning Annotation Schema bundles together similar rhetorical moves casting the general argumentation recognition</p>
    <p>Knowledge Claim Discourse Model into a sentence classification task</p>
    <p>Zone Analysis: Argumentative Zoning</p>
    <p>Annotation procedure and annotated corpus</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Argumentative Zoning II Schema (to model typical Chemistry argumentation)</p>
    <p>Test if non-expert humans can annotate the sentences of text from different domains (Computational Linguistics and Chemistry) with</p>
    <p>respect to an extended version of the Argumentative Zoning Schema</p>
    <p>AZ Background</p>
    <p>AZ Other</p>
    <p>AZ Basis</p>
    <p>AZ Contrast</p>
    <p>AZ Own</p>
    <p>AZ Own Data:  30 Chemistry papers  9 Computational Linguistics papers (CL)</p>
    <p>Annotation: 3 annotators experts in CL with different levels of expertise in Chemistry  chemistry intro</p>
    <p>Zone Analysis: Argumentative Zoning cross-domain validity</p>
    <p>Annotation procedure and annotated corpus</p>
    <p>AZ Aim</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Argumentative Zoning II Schema (to model typical Chemistry argumentation)</p>
    <p>Test if non-expert humans can annotate the sentences of text from different domains (Computational Linguistics and Chemistry) with</p>
    <p>respect to an extended version of the Argumentative Zoning Schema</p>
    <p>AZ Background</p>
    <p>AZ Other</p>
    <p>AZ Basis</p>
    <p>AZ Contrast</p>
    <p>AZ Own</p>
    <p>AZ Own AZ Aim Inter-annotator agreement is comparable across domains (k is 0.65 in CL and 0.71 in Chemistry)</p>
    <p>Higher agreement among Chemistry experts  a little improvement of annotation quality with domain knowledge</p>
    <p>Zone Analysis: Argumentative Zoning cross-domain validity</p>
    <p>Annotation procedure and annotated corpus</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Classifier: Nave Bayes Sentence features:</p>
    <p>Structural:  Absolute sentence location  Position of sentence within section and paragraph  Type of headline of current section (15 prototypical types)  Words shared with title or headlines  Significant words (sentences that contain one of the 18 highest TF*IDF words)  contain self-citation</p>
    <p>Sentence-scoped:  Verb (voice, tense, modal)  Contain citation  Most probable previous sentence category  Meta-discourse expression (formulaic expressions, type of agent, type of action)</p>
    <p>Zone Analysis: Argumentative Zoning</p>
    <p>Automated annotation of scientific texts</p>
    <p>Teufel, S., &amp; Moens, M. (2002). Summarizing scientific articles: experiments with relevance and rhetorical status. Computational linguistics, 28(4), 409-445.</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Zone Analysis: Argumentative Zoning</p>
    <p>Automated annotation of scientific texts</p>
    <p>Teufel, S., &amp; Kan, M. Y. (2011). Robust argumentative zoning for sensemaking in scholarly documents (pp. 154-170). Springer Berlin Heidelberg.</p>
    <p>Argumentative zoning sentence classifier robust with respect to noisy input: plain text or textual input generated from</p>
    <p>PDF to text conversion or OCR</p>
    <p>Explicit structure (SciXML) Plain textual contents</p>
    <p>&lt;TITLE&gt;Paper title&lt;/TITLE&gt; &lt;HEDER&gt;Section title&lt;/HEADER&gt; &lt;S&gt;First sentence of the paper.&lt;/S&gt; &lt;S&gt;Second sentence of the paper.&lt;/S&gt; .</p>
    <p>Paper title Section title First sentence of the paper. Second sentence of the paper. .</p>
    <p>Classification without using structural features: Absolute sentence location / Position of sentence within section and paragraph / Type of headline of current section / Words shared with title or headlines / Significant words (TF*IDF) / Is self-citation</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>The agreement with the Gold Standard, even with noisy input data (PDF to text extractor, automatic sentence and paragraph identification and POS tagging) is still respectable and the classifier is still robust and fast to execute</p>
    <p>Classifier: Maximum entropy (automatically spotted and POS tagged sentences)</p>
    <p>Sentence-scoped features:  Normalized number of sentences from the beginning  Overlap with first 100 words of text  Verb (voice, tense, modal)  Contain citation, is self-citation  Set reduced to agent type  Raw tokens, bigrams, trigrams</p>
    <p>Zone Analysis: Argumentative Zoning</p>
    <p>Automated annotation of scientific texts</p>
    <p>Teufel, S., &amp; Kan, M. Y. (2011). Robust argumentative zoning for sensemaking in scholarly documents (pp. 154-170). Springer Berlin Heidelberg.</p>
    <p>Argumentative zoning sentence classifier robust with respect to noisy input: plain text or textual input generated from</p>
    <p>PDF to text conversion or OCR</p>
    <p>F-score with structural</p>
    <p>features</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Zone Analysis: Argumentative Zoning</p>
    <p>Automated annotation of scientific texts</p>
    <p>The linguistic constructs that are used to express the rhetorical functions in a paper are independent from the topic</p>
    <p>Saghdha, D. O., &amp; Teufel, S. (2014). Unsupervised learning of rhetorical structure with un-topic models. In COLING (pp. 2-13).</p>
    <p>Topic-independent template for abstracts of NLP papers</p>
    <p>The problem of _______________________ has received a lot of attention because of its relevance to __________________________________________________. __ proposed an approach based on ____________________________________________________________. In this paper we present a method to _____________________________________________ _____________________________________. We demonstrate the empirical effectiveness of our method reporting experiment on ______________________________________.</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Zone Analysis: Argumentative Zoning</p>
    <p>Automated annotation of scientific texts</p>
    <p>Saghdha, D. O., &amp; Teufel, S. (2014). Unsupervised learning of rhetorical structure with un-topic models. In COLING (pp. 2-13).</p>
    <p>Two language models can be composed by a binary-valued latent variable to generates the words of a paper:</p>
    <p>LDA topic model: to generate the topic dependent words of a document Word distribution of a rhetorical zone: to represent transition probabilities across rhetorical categories of sentences a Markov model is used since the probability of a zone is dependent on the zone of the previous sentence</p>
    <p>The problem of Word Sense Disambiguation has received a lot of attention because of its relevance to the correct interpretation and integration of textual contents. We proposed an approach based on knowledge resources built with unsupervised approaches from a corpus. In this paper we present a method to extend semantic networks to improve their effectiveness on Word Sense Disambiguation. We demonstrate the empirical effectiveness of our method reporting experiment on a wide collection of sense annotated corpora.</p>
    <p>Topic-independent template for abstracts of NLP papers, filled</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Zone Analysis: Argumentative Zoning</p>
    <p>Automated annotation of scientific texts</p>
    <p>Saghdha, D. O., &amp; Teufel, S. (2014). Unsupervised learning of rhetorical structure with un-topic models. In COLING (pp. 2-13).</p>
    <p>Given a number collection of documents, a number of topics and a number of rhetorical zones to discover, this unsupervised approach assign each sentence to:  a distribution of topics  most likely topic  a distribution of rhetorical zones  most likely zone</p>
    <p>The problem of Word Sense Disambiguation has received a lot of attention because of its relevance to the correct interpretation and integration of textual contents.</p>
    <p>TOPIC N. 20 (over 100) ZONE N. 3 (over 10)</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>How good is this approach to cluster sentences into rhetorical zones?</p>
    <p>Dataset: 1000 abstracts annotated with Argumentative Zoning</p>
    <p>Zone clustering approaches:  Boilerplate-LDA (presented in the paper)  Boilerplate-LDA with probability of zone transition independent from adjacent sentences (no Markov model for zone transition)  Boilerplate-LDA without topics  kMeans (FEATURES: tf-idf-transformed lexical frequencies, part-of-speech tags and a location feature computed by dividing the abstract into 5 bins)</p>
    <p>Compared with Gold Standard sentence clustering into zones Results: Boilerplate-LDA (presented in the paper) generates clusters of sentences that are more consistent with Gold Standard clusters</p>
    <p>Zone Analysis: Argumentative Zoning</p>
    <p>Automated annotation of scientific texts</p>
    <p>Saghdha, D. O., &amp; Teufel, S. (2014). Unsupervised learning of rhetorical structure with un-topic models. In COLING (pp. 2-13).</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Can we use learned zones as features to improve supervised classification?</p>
    <p>Dataset: 1000 abstracts annotated with Argumentative Zoning</p>
    <p>Classification approaches: Logistic Regression with history feature and CRF  Base features: tf-idf-transformed lexical frequencies, part-of-speech tags and a location feature computed by dividing the abstract into 5 bins extended with: 1. Boilerplate-LDA zone feature (index of the zone from 1 to 10) 2. Topics that are assigned to the words of a sentence by LDA are set to true (one</p>
    <p>feature per topic) 3. Only topic that is assigned with more frequency set to true (one feature per</p>
    <p>topic)</p>
    <p>Results: Performance of a Logistic Regression and CRF classifier improves with the addition of zone features (item 1, helps to identify the rhetorical zone) and not with the addition of topic features</p>
    <p>Zone Analysis: Argumentative Zoning</p>
    <p>Automated annotation of scientific texts</p>
    <p>Saghdha, D. O., &amp; Teufel, S. (2014). Unsupervised learning of rhetorical structure with un-topic models. In COLING (pp. 2-13).</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Zone Analysis: Argumentative Zoning</p>
    <p>Automated annotation of scientific texts</p>
    <p>Feltrim, V. D., Teufel, S., das Nunes, M. G. V., &amp; Alusio, S. M. (2006). Argumentative zoning applied to critiquing novices scientific abstracts. In Computing Attitude and Affect in Text: Theory and Applications (pp. 233-246). Springer Netherlands.</p>
    <p>SciPo: tools that applies a set of rules to evaluate the coherence of scientific abstracts of novices on the basis of their rhetorical structure spotted by AZ classifier  Argumentative Zoning schema ported to scientific abstract in Portuguese: the category OWN divided into Methodology, Results and Conclusion  Corpus of 52 abstracts annotated  Automated classification experiments with Teufels features ported to Portuguese: Classifier: Nave Bayes (13-folds cross validation) accuracy 74%, K with gold standard 0.65</p>
    <p>Merity, S., Murphy, T., &amp; Curran, J. R. (2009, August). Accurate argumentative zoning with maximum entropy models. In Proceedings of the 2009 Workshop on Text and Citation Analysis for Scholarly Digital Libraries (pp. 19-26). Association for Computational Linguistics.</p>
    <p>sentence features: unigram, bigram, section counter, location inside section and paragraph and length  improvement of sentence classification performance on Argumentative Zoning corpus by using a maximum entropy classifier  by using an HMM with only unigrams and bigrams the classification accuracy improvement is relevant up to an history of the four previous decisions</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Zone Analysis: Argumentative Zoning</p>
    <p>Automated annotation of scientific texts</p>
    <p>Mizuta, Y., &amp; Collier, N. (2004, May). An Annotation Scheme for a Rhetorical Analysis of Biology Articles. In LREC (pp. 1737-1740).</p>
    <p>20 online articles taken from major biology journals annotated in order to develop and refine the annotation schema on the bases of Teufels Argumentative Zoning  extended modified version of AZ Schema to include:</p>
    <p>a finer grained classification of the authors own work  an explicit relation between the data presented and the findings</p>
    <p>Hachey, B., &amp; Grover, C. (2006). Extractive summarisation of legal texts. Artificial Intelligence and Law, 14(4), 305-345.</p>
    <p>adaptation of Argumentative Zoning to the legal domain  unlike scientific texts, the fundamental communicative purpose of a judgment is to legitimise a decision, by showing that it derives, by a legitimate process, from authoritative sources of law  schema categories: FACTS, PROCEEDING, BACKGROUND, FRAMING, DISPOSAL, TEXTUAL, OTHERS</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>A paper is a human readable representation of a scientific investigation: a scientific discourse annotation schema should point out the</p>
    <p>components of the scientific investigation</p>
    <p>ART Corpus  265 papers from the domains of chemistry and biochemistry  39,915 sentences  Avg. annotator agreement K: 0,55</p>
    <p>Online at (SciXML format): https://www.aber.ac.uk/en/cs/r esearch/cb/projects/art/artcorpus/</p>
    <p>Zone Analysis: Core Scientific Concepts</p>
    <p>Annotation procedure and annotated corpus</p>
    <p>Category Description</p>
    <p>Hypothesis An unconfirmed statemen which is a stepping stone of the investigation</p>
    <p>Motivation The reason behind the investigation</p>
    <p>Background Generally expected background knowledge and previous work</p>
    <p>Goal A target state of the investigation where intended discoveries are made</p>
    <p>Object An entity which is the product or main theme of the investigation (advantage / disadvantage)</p>
    <p>Method Means by which the authors seek to achieve the goal of the investigation (old / new  advantage / disadvantage)</p>
    <p>Experiment An experimental method</p>
    <p>Model A statement about a theoretical model or framework</p>
    <p>Observation The data / phenomena recorded in an investigation</p>
    <p>Result Factual statements about the outputs, interpretation of an observation</p>
    <p>Conclusion Statements inferred from observations and results</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Zone Analysis: Core Scientific Concepts</p>
    <p>Automated annotation of scientific texts</p>
    <p>Liakata, M., Saha, S., Dobnik, S., Batchelor, C., &amp; Rebholz-Schuhmann, D. (2012). Automatic recognition of conceptualization zones in scientific articles and two life science applications. Bioinformatics, 28(7)</p>
    <p>Classifiers: SVM (linear), CRF Sentence features:  Structural:</p>
    <p>Absolute sentence location  Section ID (incremental integer, up to 10)  Length and position of sentence within section and paragraph  Type of headline of current section (16 types of prototypical headers)</p>
    <p>Sentence-scoped:  No citations, one citation, +1 citation  Category of previous sentence (not CRF)  Unigrams, bigrams and trigrams lemmatized  Verb POS, passive or not, presence  Verb class (10 classes) obtained by clustering verbs with frequency &gt; 150  Grammatical triples from dependency tree</p>
    <p>Results:  Accuracy: SVM: 51,6% CRF: 50,4%  Most relevant feature sets: bigrams, triples from dependency tree, verbs as well as structural features as history and section heading type (ngram 65,000 features vs 13,000 all other features)  There is not always a direct correlation of annotator agreement and classifier performance: Experiment and Model have an higher F-score but low interannotator agreement</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Zone Analysis: Core Scientific Concepts, multi-class</p>
    <p>Annotation procedure and annotated corpus</p>
    <p>James Ravenscroft, Maria Liakata, Anika Oellrich, and Shyamasree Saha (2016). Multi-label annotation in scientific articles  The Multi-label Cancer Risk Assessment Corpus. LREC</p>
    <p>Dealing with the case in which more than one Core Scientific Concept appears in a single sentence</p>
    <p>Multi-CoreSC Corpus 50 papers from the domain of cancer risk assessment Environmental Health Perspectives (21), Carcinogenesis (15), Toxicological Sciences (9), Journal of Biological Chemistry (3), Occupational and Environmental Medicine (1), PlosOne (1)</p>
    <p>8,501 sentences</p>
    <p>Online at (SciXML format): http://www.sapientaproject.com/wp-content/uploads/2016/05/consensus_annotated.zip</p>
    <p>Bone marrow stromal cells were treated with AhR agonists and bacterial lipopolysaccharide (LPS) to mimic innate inflammatory cytokine responses.</p>
    <p>METHOD GOAL</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Zone Analysis: Core Scientific Concepts, multi-class</p>
    <p>Annotation procedure and annotated corpus</p>
    <p>James Ravenscroft, Maria Liakata, Anika Oellrich, and Shyamasree Saha (2016). Multi-label annotation in scientific articles  The Multi-label Cancer Risk Assessment Corpus. LREC</p>
    <p>Dealing with the case in which more than one Core Scientific Concept appears in a single sentence</p>
    <p>Multi-CoreSC CRA Corpus  3 biology expert annotators  weighted kappa &gt; 0.55 for each ann. pair  12.5% of sentences obtained a multiCoreSC label  multi label conciliation procedure to generate Gold Standard: lower number of labels across annotators in Gold Standard. Labels are ranked with respect to popularity and in case of equal popularity with respect to priority</p>
    <p>Is CoreSC CRF classifier domain indep.? Old: trained on ART corpus, tested on CRA corpus</p>
    <p>Most influential features of CoreSC annotation are domain specific</p>
    <p>Object and Experiment: only two categories that are consistently identified without domain adaptation</p>
    <p>New: trained and tested on CRA corpus</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Zone Analysis: Argumentative Zoning vs Core Scientific Concepts</p>
    <p>Annotation procedure and annotated corpus</p>
    <p>Liakata, M., Teufel, S., Siddharthan, A., &amp; Batchelor, C. R. (2010, May). Corpora for the Conceptualisation and Zoning of Scientific Papers. In LREC.</p>
    <p>AZ-II characterize the ownership of the knowledge claims presented in the paper, thus identifying and motivating the new contributions of the author</p>
    <p>Category Description</p>
    <p>Hypothesis An unconfirmed statemen which is a stepping stone of the investigation</p>
    <p>Motivation The reason behind the investigation</p>
    <p>Background Generally expected background knowledge and previous work</p>
    <p>Goal A target state of the investigation where intended discoveries are made</p>
    <p>Object An entity which is the product or main theme of the investigation (advantage / disadvantage)</p>
    <p>Method Means by which the authors seek to achieve the goal of the investigation (old / new  advantage / disadvantage)</p>
    <p>Experiment An experimental method</p>
    <p>Model A statement about a theoretical model or framework</p>
    <p>Observation The data / phenomena recorded in an investigation</p>
    <p>Result Factual statements about the outputs, interpretation of an observation</p>
    <p>Conclusion Statements inferred from observations and results</p>
    <p>CoreSC describes the structure of the investigation characterizing the high level scientific concept presented in each part of the paper</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Schemata have complementary roles - it would be beneficial to annotate a text with respect to both schemata. In particular:</p>
    <p>AZ-II identifies knowledge claims that permeates several CoreSC concepts  CoreSC has more granularity when dealing with content-related categories</p>
    <p>Zone Analysis: Argumentative Zoning vs Core Scientific Concepts</p>
    <p>Annotation procedure and annotated corpus</p>
    <p>Liakata, M., Teufel, S., Siddharthan, A., &amp; Batchelor, C. R. (2010, May). Corpora for the Conceptualisation and Zoning of Scientific Papers. In LREC.</p>
    <p>AZ-II CoreSC</p>
    <p>AIM</p>
    <p>PREV_OWN</p>
    <p>OTHER</p>
    <p>CO_GRO</p>
    <p>GAP_WEAK</p>
    <p>Goal</p>
    <p>Hypothesis</p>
    <p>Motivation</p>
    <p>Background</p>
    <p>Object</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Introduction &gt; Methods &gt; Results &gt; Discussion  Structure common to most health science journals  Today more complex derived structures are often used</p>
    <p>Zone Analysis: IMRAD</p>
    <p>Annotation procedure and annotated corpus</p>
    <p>Luciana B. Sollaci &amp; Mauricio G. Pereira (July 2004). The introductio, methods, results, and discussion (IMRAD) structure: a fifty-year survey. J Med Libr Assoc. 2004 July; 92(3): 364371. 92 (3)</p>
    <p>Random sample of (n = 1,297) articles published in British Medical Journal, JAMA, The Lancet, and the New England Journal of Medicine, 19351985</p>
    <p>first used in 1940s  in 1970s 80% of compliant papers  since 1980s most of health science papers are compliant</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization Annotation procedure and annotated corpus</p>
    <p>Dr. Inventor Corpus</p>
    <p>CLOTH SIMULATION 10</p>
    <p>papers</p>
    <p>FLUID SIMULATION 10</p>
    <p>papers</p>
    <p>SKINNING 10 papers</p>
    <p>MOTION 10 papers</p>
    <p>40 papers / 10,403 sentences  Multi-layered annotations: discursive structure, citation purpose, summary</p>
    <p>sentence relevance</p>
    <p>Fisas, B., Ronzano, F., &amp; Saggion, H. (2015). On the Discoursive Structure of Computer Graphics Research Papers. In The 9th Linguistic Annotation Workshop held in conjuncion with NAACL 2015 (p. 42).</p>
    <p>Fisas, B., Ronzano, F., &amp; Saggion, H. (2016). A Multi-Layered Annotated Corpus of Scientific Papers. LREC.</p>
    <p>Schema defined by annotating Computer Graphics papers, starting from AZ and CoreSC schemas (15 categories, then reduced to 5 top level + 2 second level)</p>
    <p>Background</p>
    <p>Outcome</p>
    <p>Challenge</p>
    <p>Approach</p>
    <p>Future Work</p>
    <p>Goal</p>
    <p>Hypothesis</p>
    <p>Contribution</p>
    <p>Zone Analysis: Dr. Inventor Scientific Discurse Schema</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Zone Analysis: Dr. Inventor Scientific Discurse Schema</p>
    <p>Annotation procedure and annotated corpus</p>
    <p>Fisas, B., Ronzano, F., &amp; Saggion, H. (2015). On the Discoursive Structure of Computer Graphics Research Papers. In The 9th Linguistic Annotation Workshop held in conjuncion with NAACL 2015 (p. 42).</p>
    <p>Fisas, B., Ronzano, F., &amp; Saggion, H. (2016). A Multi-Layered Annotated Corpus of Scientific Papers. LREC.</p>
    <p>Training Session</p>
    <p>Annotation check after:  5 papers  15 papers  25 papers</p>
    <p>Annotation workflow Annotators</p>
    <p>Distribution of sentence rethorical class (over papers length)</p>
    <p>Future Work</p>
    <p>Outcome</p>
    <p>Approach</p>
    <p>Background</p>
    <p>Challenge</p>
    <p>Avg. annotator agreement K: 0,67</p>
    <p>Online at: http://sempub.taln.upf.edu/dricorpus</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization</p>
    <p>Zone Analysis: Dr. Inventor Scientific Discurse Schema Fisas, B., Ronzano, F., &amp; Saggion, H. (2015). On the Discoursive Structure of Computer Graphics Research</p>
    <p>Papers. In The 9th Linguistic Annotation Workshop held in conjuncion with NAACL 2015 (p. 42). Fisas, B., Ronzano, F., &amp; Saggion, H. (2016). A Multi-Layered Annotated Corpus of Scientific Papers. LREC.</p>
    <p>Automated annotation of scientific texts</p>
    <p>CORPUS: 8,777 sentences that have been manually associated to one of the 5 high level classes CLASSIFIERS: Logistic regression, SVM (linear) FEATURES: sentence position (only structural feat.), unigrams, bigrams, three-grams, dep. tree dept, num. and type of edges, dep. tree tokens, num and syntactic role of citations, category of previous sentence RESULTS:  in general the F-score of each category is proportional to the number of training instances  Future Work has more strongly distinctive linguistic features than Challenge</p>
    <p>Percentage of annotated sentences by category</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization Automated annotation of ABSTRACTS of scientific texts</p>
    <p>Guo, Y., Korhonen, A., Liakata, M., Karolinska, I. S., Sun, L., &amp; Stenius, U. (2010, July). Identifying the information structure of scientific abstracts: an investigation of three different schemes. In Proceedings of the 2010 Workshop on Biomedical Natural Language Processing (pp. 99-107). ACL.</p>
    <p>CORPUS: 1,000 MedLine abstracts concerning Cancer Risk Assessment (7,985 sentences) On-line at: http://www.cl.cam.ac.uk/~yg244/abstract_az.html</p>
    <p>CLASSIFIERS: Nave Bayes, SVM with linear kernel (Weka) FEATURES: location (10 equal parts), unigram, bigram, verb class (60 cluster of frequent verbs), grammatical triples from dependency tree, passive verb</p>
    <p>RESULTS:  SVM outperforms Nave Bayes in all cases (accuracy reported before)  Best features for all schemas: bigrams, verb and unigrams  Worse features for all schemas: history and voice worst (with abstract, the history of the categories is more varied and has less relevance than in the case in which we consider the whole text)</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization Automated annotation of ABSTRACTS of scientific texts</p>
    <p>Hirohata, K., Okazaki, N., Ananiadou, S., Ishizuka, M., &amp; Biocentre, M. I. (2008, January). Identifying Sections in Scientific Abstracts using Conditional Random Fields. In IJCNLP (pp. 381-388).</p>
    <p>CORPUS: 51,000 MedLine abstracts with sentences divided in Objective, Method, Result and Conclusion CLASSIFIERS: SVM (linear kernel), CRF FEATURES: unigrams and bigrams also from next and previous sentence features, relative sentence location</p>
    <p>RESULTS:  CRF outperformed the SVM with features from previous and next sentence showing that is more adequate to classify sentences of scientific abstracts Since features are mainly based on lexical contents of annotated text (unigrams and bigrams), the accuracy strongly improves when a greater dataset is considered</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization Automated annotation of scientific texts: ACTIVE LEARNING</p>
    <p>Guo, Y., Silins, I., Stenius, U., &amp; Korhonen, A. (2013). Active learning-based information structure analysis of full scientific articles and two applications for biomedical literature review. Bioinformatics, 29(11)</p>
    <p>CORPUS: 50 biomedical articles (8,171 sentences) annotated with AZ categories CLASSIFIER: SVM (linear kernel)</p>
    <p>Driven selection of new samples to consider to increase the training set by means of three strategies:  least confident sampling: instance with more classification uncertainty  margin sampling: instance with the smallest margin between the priors of the two most likely labelings  query-by-bagging: a committee of models trained on subset of training instances is created and chosen the instance for which the committees disagree the most (most informative instance)</p>
    <p>FEATURES: unigrams, bigrams, normalized section name, location inside section and paragraph, number of cits and table/figure references, verb class, tense, voice, dep. rels</p>
    <p>Fully supervised accuracy (8,171 instances): 0.84</p>
    <p>RESULTS:  active learning with SVM trained on 6% of the corpus performs surprisingly well with the accuracy of 82%, just 2% lower than fully supervised learning</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Scientific discourse characterization Automated annotation of scientific texts</p>
    <p>Guo, Y., Korhonen, A., &amp; Poibeau, T. (2011, July). A weakly-supervised approach to argumentative zoning of scientific documents. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (pp. 273-283). Association for Computational Linguistics.</p>
    <p>Use of Active learning and semi-supervised approaches to improve discursive sentence classification  Active SVM outperforms the best supervised SVM with a statistically significant difference exploiting only a fraction of the training data</p>
    <p>Guo, Y., Reichart, R., &amp; Korhonen, A. (2013, June). Improved Information Structure Analysis of Scientific Documents Through Discourse and Lexical Constraints. In HLT-NAACL (pp. 928-937).</p>
    <p>Adding manually defined constraints to complement the statistical classification of sentences  Two types of constraints are defined:</p>
    <p>lexical: there is one or more reference to figures and tables, there is one or more citation, there are occurrences of specific word classes  discursive: is the first / last part of the paragraph or section</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Overview of available datasets AZ Corpus: 80 articles computational linguistics</p>
    <p>http://www.cl.cam.ac.uk/~sht25/AZ_corpus.html</p>
    <p>ART Corpus: 265 papers from the domains of chemistry and biochemistry</p>
    <p>https://www.aber.ac.uk/en/cs/research/cb/projects/art/art-corpus/</p>
    <p>MultiCoreSC CRA Corpus: 50 papers from the domain of Cancer Risk Assessment</p>
    <p>http://www.sapientaproject.com/wpcontent/uploads/2016/05/consensus_annotated.zip</p>
    <p>Dr. Inventor Multi-layered Corpus: 40 papers from the domain of Computer Graphics</p>
    <p>http://sempub.taln.upf.edu/dricorpus</p>
    <p>MedLine Abstracts Corpus: 1,000 MedLine abstracts onCancer Risk Assessment</p>
    <p>http://www.cl.cam.ac.uk/~yg244/abstract_az.html</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>The characterization of scientific discourse provides valuable information to enhance several scientific text mining tasks like text quality assessment, information extraction, content retrieval and summarization</p>
    <p>Zone Analysis is the most widespread approach to characterize scientific discourse, often at sentence level</p>
    <p>Annotation schemas often offers complementary views by modeling different aspects of scientific discourse</p>
    <p>Even if minimal, often annotation schemas need to be adapted to the specific domain of the scientific textual contents to characterize</p>
    <p>Supervised approaches are widely explored: classifiers (Nave Bayes, logistic regression, SVM) or sequence labeling approaches (CRF)</p>
    <p>A rich set of annotated corpora is freely available for further experimentation</p>
    <p>Scientific Discourse Characterization</p>
  </div>
  <div class="page">
    <p>CITATION ANALYSIS</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Citations in scientific literature</p>
    <p>How citations are studied?  Citation network analysis</p>
    <p>Citation function</p>
    <p>Citation prediction and recommendation</p>
    <p>Citation-based summarization</p>
    <p>Citation graphs</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Citations in scientific literature</p>
    <p>Citations are the primary device used in scientific literature to relate a piece of work with other relevant (published) materials</p>
    <p>We cite papers to:</p>
    <p>ground the arguments and give the work factual basis  avoid plagiarism (intellectual honesty)  attribute prior or unoriginal work and ideas to the correct sources  allow the reader to determine independently whether the referenced material supports the author's argument in the claimed way (demonstrate assessors and critics you have carried out the necessary research)  enable the reader to independently evaluate the strength and validity of the material the author has used</p>
    <p>Bibliography</p>
    <p>Body of the paper</p>
    <p>CITATION</p>
    <p>In-line citation</p>
    <p>Bibliographic entry</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citations in scientific literature</p>
    <p>Each citation is a directed link from a citing paper to a cited paper</p>
    <p>citing paper cited paper</p>
    <p>In-line citation</p>
    <p>Citation context</p>
    <p>Cited span</p>
    <p>The text of the citing paper surrounding an in-line citation and motivating the same citation is referred to as citation contex</p>
    <p>The excerpt of the cited paper that explains the actual contents cited by the citing paper surrounding is referred to as cited span</p>
    <p>The elements of a citation</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>How citations are studied?</p>
    <p>Citation network analysis</p>
    <p>Citation function</p>
    <p>Citation prediction and recommendation</p>
    <p>Citation-based summarization</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation network analysis Citation networks</p>
    <p>Citation networks:  nodes: papers  arks: directed from citing to cited paper</p>
    <p>The more often a single paper is cited, the more important it seems to be</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation network analysis Bibliographic coupling and co-citation networks</p>
    <p>Bibliographic coupling network:  nodes: papers  arks: undirected, connect pairs of documents that share one or more cited documents Retrospective: is limited to the papers cited by a pair of articles and cannot vary with time</p>
    <p>The more often two papers are cited together, the more likely they are to be part of some research question or</p>
    <p>ongoing problem or conversation topic within the discipline</p>
    <p>coupling strength: 2</p>
    <p>Co-citation network:  nodes: papers  arks: undirected, connect a pair of papers if they are cited by the same document(s) Non-retrospective: may vary by new citations received by the papers in the future</p>
    <p>co-citation strength: 2</p>
    <p>Co-Citation Proximity Index (CPI) can be introduced to account for the placement of citations relative to each other. Documents co-cited at greater relative distances in the full text receive lower CPI values.</p>
    <p>INTERACTIVE EXAMPLE: http://jgoodwin.net/network/cites-slider.html</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation network analysis Author coupling and co-citation networks</p>
    <p>Method to map the research activities of active authors themselves for a more realistic picture</p>
    <p>of the current state of research in a field</p>
    <p>Author co-citation:  nodes: authors  arks: undirected, the number of times the pair of connected authors are cited together by the same article</p>
    <p>cites author</p>
    <p>cites author</p>
    <p>co-citation strength: 2</p>
    <p>Author bibliographic coupling:  nodes: authors  arks: undirected, equals to the number of references that the publications of the pairs of authors have in common</p>
    <p>cite publication</p>
    <p>coupling strength: 2</p>
    <p>Method to study the external and internal as well as recent and historical</p>
    <p>intellectual influences on the field</p>
    <p>cite publication</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation network analysis</p>
    <p>How citation networks are exploited?</p>
    <p>identify hot areas and key authors (authors that are most collaborative or are most highly cited)  centrality, in-degree, outdegree</p>
    <p>community detection (meaningful communities of researchers)  clustering methods</p>
    <p>understand the research habits, trends, and topological patterns of the researchers</p>
    <p>spot and characterize productivity, patterns and trends</p>
    <p>provide complementary data to enhance the analysis of the contents of scientific publications</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation network analysis</p>
    <p>47,742,000 papers with at least one reference or one citation (36,8% of total papers)  528,682,289 internal citations  each paper in the graph is cited on average 4.17 times</p>
    <p>384,413 papers  1,751,463 internal citations  each paper in the graph is cited on average 4.56 times</p>
    <p>February 2016</p>
    <p>October 2016</p>
    <p>Citation networks</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation network analysis Improving detection of scientific topic evolution by citation network</p>
    <p>(Scientific) Topic detection and evolution Discover how and what topics change over time since the evolution of a topic in a</p>
    <p>specific time period can boost the investigation of other topics in subsequent periods</p>
    <p>TOPIC 1</p>
    <p>TOPIC 2</p>
    <p>TOPIC 6</p>
    <p>TOPIC 7</p>
    <p>TOPIC 1</p>
    <p>TOPIC 3</p>
    <p>TOPIC 4</p>
    <p>TOPIC 1</p>
    <p>TOPIC 3</p>
    <p>TOPIC 5</p>
    <p>YEAR 1 YEAR 2 YEAR 3 YEAR 4</p>
    <p>same topic</p>
    <p>related topic</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation network analysis Improving detection of scientific topic evolution by citation network</p>
    <p>He, Q., Chen, B., Pei, J., Qiu, B., Mitra, P., &amp; Giles, L. (2009, November). Detecting topic evolution in scientific literature: how can citations help?. In Proceedings of the 18th ACM conference on Information and knowledge management (pp. 957-966). ACM.</p>
    <p>Once defined a number k of topics, given a collection of documents, a topic detection method generates for each topic z a vocabulary distribution</p>
    <p>so as to maximize the likelihood of the observed data</p>
    <p>TOPIC 1</p>
    <p>TOPIC 2</p>
    <p>[ Word 1: 0,4 Word 2: 0,2 Word 3: 0,4 ]</p>
    <p>[ Word 1: 0,7 Word 2: 0,1 Word 3: 0,2 ]</p>
    <p>Vocabulary distribution Topic</p>
    <p>Given 1  a &gt; b &gt; 1/k, a pair of topics z(T) and z(T-1) respectively computed over document collections at time T and time T-1 is:</p>
    <p>equal: p( z(T) | z(T-1) ) &gt; a  similar: b &lt; p( z(T) | z(T-1) ) &lt; a  new: p( z(T) | z(T-1) ) &lt; b</p>
    <p>TOPIC 4</p>
    <p>TOPIC 5</p>
    <p>TOPIC 1</p>
    <p>TOPIC 2</p>
    <p>TOPIC 3</p>
    <p>TOPIC 2</p>
    <p>time T time T-1</p>
    <p>p( z(T) | z(T-1) ) equal to sim(z(T), z(T-1) )</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation network analysis Improving detection of scientific topic evolution by citation network</p>
    <p>He, Q., Chen, B., Pei, J., Qiu, B., Mitra, P., &amp; Giles, L. (2009, November). Detecting topic evolution in scientific literature: how can citations help?. In Proceedings of the 18th ACM conference on Information and knowledge management (pp. 957-966). ACM.</p>
    <p>Considering a collection of scientific paper spanning a number of years, in order to track yearby-year topic evolution, we can generate the topic of each year by different approaches:  Time independent topic evolution learning</p>
    <p>Accumulative topic evolution learning</p>
    <p>Citation-aware topic evolution learning</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation network analysis Improving detection of scientific topic evolution by citation network</p>
    <p>He, Q., Chen, B., Pei, J., Qiu, B., Mitra, P., &amp; Giles, L. (2009, November). Detecting topic evolution in scientific literature: how can citations help?. In Proceedings of the 18th ACM conference on Information and knowledge management (pp. 957-966). ACM.</p>
    <p>Citation-aware topic evolution learning</p>
    <p>DRAWBACKS</p>
    <p>not all citations are equally important (only few can ne related to the topic of the citing paper)  when historical papers are cited, some out-of-date topic may be wrongly considered</p>
    <p>Inheritance topic model</p>
    <p>Citing paper Autonomous part (new ideas)</p>
    <p>Cited papers Inherited part (previous work)</p>
    <p>The autonomous part and the inherited part of a paper (cited papers) are learned independently</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation network analysis Improving detection of scientific topic evolution by citation network</p>
    <p>He, Q., Chen, B., Pei, J., Qiu, B., Mitra, P., &amp; Giles, L. (2009, November). Detecting topic evolution in scientific literature: how can citations help?. In Proceedings of the 18th ACM conference on Information and knowledge management (pp. 957-966). ACM.</p>
    <p>Evaluation: 650,918 computer and information science papers from CiteSeer from 1993 to 2008</p>
    <p>Time independent topic evolution learning Accumulative topic evolution learning</p>
    <p>Citation-aware topic evolution learning Inheritance topic model</p>
    <p>Evolution of 30 topics studied with different approaches</p>
    <p>C it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>u n</p>
    <p>a w</p>
    <p>a re</p>
    <p>C</p>
    <p>it a</p>
    <p>ti o</p>
    <p>n a</p>
    <p>w a</p>
    <p>re</p>
    <p>Large number of new topics. Several noisy topics</p>
    <p>Historical topics tends to dominate; difficult to detect new ones</p>
    <p>Produce less new topics with respect a ITM since old, cited papers are treated as new ones</p>
    <p>Reach a good balance between new and old topics enabling detection of new ones</p>
    <p>noisy topics new topics similar topics same topics</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation network analysis</p>
    <p>reflects the personal link between scientists</p>
    <p>Results:  degree distribution: power-law, is a scale free network  the average node separation slightly decreases over time: more internal inks are produced with time (co-authorships) increasing network interconnectivity and decreasing diameter  the average degree increases with time  node selection is governed by preferential attachment</p>
    <p>Co-authorship network</p>
    <p>co-authorship strength: 1</p>
    <p>Belman Clart</p>
    <p>TITLE Clart, Belman  Abstract ..</p>
    <p>Barabsi, A. L., Jeong, H., Nda, Z., Ravasz, E., Schubert, A., &amp; Vicsek, T. (2002). Evolution of the social network of scientific collaborations. Physica A: Statistical mechanics and its applications, 311(3), 590-614.</p>
    <p>Dataset: 2 co-authorship networks (1991-1998):  maths: 70,975 authors and 70,901 papers  neuroscience: 209,293 authors, 210,750 papers</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation network analysis</p>
    <p>15 journals classified in ISIs Web of Science dealing with Philosophy and History  12,510 articles dating from 1956 with over 300,000 citations between them Authors co-citation graph shows intellectual influences of individual authors, clustering them by discipline Source: http://www.scottbot.net/HIAL/wp-content/uploads/2013/06/FullPageMapOfHPS.png</p>
    <p>Author co-citation network</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation function</p>
    <p>Not all citations are equal!</p>
    <p>Many research impact and quality indexes are based on citation counts but</p>
    <p>There are different motivation that could explain why an author cites other pieces of research</p>
    <p>criticize a work express contrary or negative judgments</p>
    <p>investigations used as a starting point for the work described</p>
    <p>highlight a positive result</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation function</p>
    <p>Not all citations are equal!</p>
    <p>Many research impact and quality indexes are based on citation counts but</p>
    <p>This paper has 6 citations!</p>
    <p>The approach presented by [1] presents several limitations.</p>
    <p>We compare our system with the concept extraction performance of [1].</p>
    <p>We parse text by means of the concept extraction system presented in [1].</p>
    <p>The main drawback of [1] is its impossibility to scale to large systems.</p>
    <p>The system presented by [1] cant be easily adapted to texts from different domains.</p>
    <p>Our systems extracts concepts by implementing the approach presented by [1]. [1]</p>
    <p>CRITICISM</p>
    <p>CRITICISM</p>
    <p>CRITICISM</p>
    <p>COMPARISON</p>
    <p>USE</p>
    <p>USE</p>
    <p>Half of the citations of this paper criticize aspect of the work presented.</p>
    <p>Two citations of this paper use the approach / tool presented.</p>
    <p>One citation of this paper compares the approach / tool presented.</p>
    <p>CRITICISM</p>
    <p>USE</p>
    <p>COMPARISON</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation function</p>
    <p>Not all citations are equal!</p>
    <p>Many research impact and quality indexes are based on citation counts but</p>
    <p>In-line citation</p>
    <p>Citation context</p>
    <p>In order to understand why a paper is cited it is fundamental to correctly identify the citation context,</p>
    <p>that is the text excerpt(s) of the citing paper that explains and motivates the citation</p>
    <p>The citation context:  may include sentences surrounding the one where the in-line citation occurs  only part of the sentence where the in-line citation occurs can contribute to motivate the citation</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation function Several annotation schemas have been proposed</p>
    <p>to characterize the function of citations</p>
    <p>Conceptual If a concept or a theory of the cited paper is used directly or indirectly in the citing paper in order to lay foundations to build on it or to contribute to the citing paper,</p>
    <p>then the citation is a conceptual one.</p>
    <p>Operational When a concept or theory id referred to as tool [or] when it borrows mathematical or physical techniques, results, references, or conclusions from the cited paper.</p>
    <p>Organic Those [papers] from which concepts or theories are taken to lay the foundations of the citing paper, or papers from which certain results (including numerical ones) are</p>
    <p>taken to develop the ideas in the citing paper, or papers which help to better</p>
    <p>understand certain concepts in the citing paper.</p>
    <p>Perfunctionary Those [papers] which describe alternative approaches are not utilized in the citing papers. references which are used to indicate the fact that a certain method</p>
    <p>employed is routine in the literature, and references which merely contribute to the</p>
    <p>chronological context of the citing paper.</p>
    <p>Evolutionary [The paper] provides a concept or theory to build on, or a mathematical technique to use, or results of an analysis which is used in the development of the citing paper,</p>
    <p>or notation used in the citing paper.</p>
    <p>Juxtapositional [The paper] refers to alternative approaches [and] refers to other analysis used in the citing paper only to make comparisons, refers to other works which may help to</p>
    <p>clarify some ideas but do not contribute to the development of the citing paper, or</p>
    <p>refers to a paper only for references given in the latter.</p>
    <p>Confirmative A reference is confirmative if the author of the citing paper considers the paper referred to as correct.</p>
    <p>Negative The author of the citing paper is not certain about the correctness of the cited paper.</p>
    <p>Moravcsik, M. J., &amp; Murugesan, P. (1975). Some results on the function and quality of citations. Social studies of science, 5(1), 86-92.</p>
    <p>use of theory use of technical method</p>
    <p>own work is based on the cited work</p>
    <p>own work is an alternative to cited work</p>
    <p>work is crucially needed for understanding of citing article</p>
    <p>just a general acknowledgement</p>
    <p>the work confirm the cited paper</p>
    <p>cited paper are criticized</p>
    <p>(30 Articles in Physical Review, Published on Theoretical High Energy Physics from 1968 to 1972)</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation function Several annotation schemas have been proposed</p>
    <p>to characterize the function of citations Spiegel-Rsing, I. (1977). Science studies: Bibliometric and content analysis.</p>
    <p>Social Studies of Science, 97-113.</p>
    <p>research question under investigation.</p>
    <p>comparative purposes in tables and statistics</p>
    <p>the citing text</p>
    <p>citing article)</p>
    <p>in the citing text, in tables or statistics.</p>
    <p>Cited source substantiates a statement or assumption, or points to further information</p>
    <p>criticize the cited paper</p>
    <p>(2,309 citations from Science Studies Vol. 1-4 1971-1974)</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation function Several annotation schemas have been proposed</p>
    <p>to characterize the function of citations</p>
    <p>Teufel, S., Siddharthan, A., &amp; Tidhar, D. (2009, July). An annotation scheme for citation function. In Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue (pp. 80-87). ACL</p>
    <p>Weakness Authors point out a weakness in cited work.</p>
    <p>Contrast Authors make contrast/comparison with cited work (4 categories)</p>
    <p>CoCoGM Contrast/Comparison in Goals or Methods (neutral)</p>
    <p>CoCoR0 Contrast/Comparison in Results (neutral)</p>
    <p>CoCo Unfavourable Contrast/Comparison (current work is better than cited work)</p>
    <p>CoCoXY Contrast between 2 cited methods</p>
    <p>Positive Authors agree with/make use of/show compatibility or similarity with cited work (6 categories),</p>
    <p>PBas author uses cited work as starting point</p>
    <p>PUse author uses tools/algorithms/data</p>
    <p>PModi author adapts or modi_es tools/algorithms/data</p>
    <p>PMot this citation is positive about approach or problem addressed (used to motivate work in current paper)</p>
    <p>PSim author's work and cited work are similar</p>
    <p>PSup author's work and cited work are compatible/ provide support for each other</p>
    <p>Neutral Function of citation is either neutral, or weakly signalled, or different from the three functions stated above</p>
    <p>Corpus CitRAZ: 26 conference articles  584 citations from Computation and Language archive</p>
    <p>Online at: http://www.cl.cam.ac.uk/~sht25/Project_Index/Citraz_Index.html http://www.cl.cam.ac.uk/~sht25/CFC.html</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation function Several annotation schemas have been proposed</p>
    <p>to characterize the function of citations Teufel, S., Siddharthan, A., &amp; Tidhar, D. (2009, July). An annotation scheme for citation function.</p>
    <p>In Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue (pp. 80-87). ACL</p>
    <p>Classifiers: K-nearest neighbours classifier Citation features:  grammar (POS-based) with 1762 cue-phrases (Teufel, 1999)  POS-based recognizer for agents and recognizer for actions that these agents perform (Teufel, 1999)  892 cue-phrases (about 75 per citation function, identified by annotators)  verb tense and voice  modality (whether or not a main verb is modified by an auxiliary, and which auxiliary it is)  location of sentence in the whole paper and in the section or paragraph  self citations</p>
    <p>Results 4 top classes</p>
    <p>All classes</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation function Several annotation schemas have been proposed</p>
    <p>to characterize the function of citations Abu-Jbara, A., Ezra, J., &amp; Radev, D. R. (2013). Purpose and Polarity of Citation: Towards NLP-based</p>
    <p>Bibliometrics. In HLT-NAACL (pp. 596-606).</p>
    <p>Criticism Criticism can be positive or negative. A citing sentence is classified as Criticizing when it</p>
    <p>mentions the weakness/strengths of the cited approach, negatively/positively criticizes the cited</p>
    <p>approach, negatively/positively evaluates the cited source.</p>
    <p>Comparison A citing sentence is classified as Comparison when it compares or contrasts the work in the</p>
    <p>cited paper to the authors work. It overlaps with the first category when the citing sentence says</p>
    <p>one approach is not as good as the other approach. In this case we use the first category.</p>
    <p>Use A citing sentence is classified as Use when the citing paper uses the method, idea or tool of the</p>
    <p>cited paper.</p>
    <p>Substantiation A citing sentence is classified as Substantiating when the results, claims of the citing work</p>
    <p>substantiate, verify the cited paper and support each other.</p>
    <p>Basis A citing sentence is classified as Basis when the author uses the cited work as starting point or</p>
    <p>motivation and extends on the cited work.</p>
    <p>Neutral A citing sentence is classified as Neutral when it is a neutral description of the cited work or if it</p>
    <p>doesnt come under any of the above categories.</p>
    <p>Online at: http://clair.si.umich.edu/corpora/citation_sentiment_umich.tar.gz</p>
    <p>Corpus: 3,271 citations from ACL Anthology Network Corpus, annotated with respect to polarity and purpose</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation function Several annotation schemas have been proposed</p>
    <p>to characterize the function of citations Abu-Jbara, A., Ezra, J., &amp; Radev, D. R. (2013). Purpose and Polarity of Citation: Towards NLP-based</p>
    <p>Bibliometrics. In HLT-NAACL (pp. 596-606). Classifiers: CRF Citation context features: (ordered by relevance)</p>
    <p>Results: Lexical features are more important than structural features</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation function Several annotation schemas have been proposed</p>
    <p>to characterize the function of citations Abu-Jbara, A., Ezra, J., &amp; Radev, D. R. (2013). Purpose and Polarity of Citation: Towards NLP-based</p>
    <p>Bibliometrics. In HLT-NAACL (pp. 596-606). Classifiers: SVM with linear kernel Citation features: (ordered by relevance)</p>
    <p>Results:  Structural features and features characterizing the words surrounding the citation to classify are the most important  Considering the citation context improves classification of subjective categories (exp. Negative)</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation function Several annotation schemas have been proposed</p>
    <p>to characterize the function of citations Athar, A. (2011, June). Sentiment analysis of citations using sentence structure-based features.</p>
    <p>In Proceedings of the ACL 2011 student session (pp. 81-87). Association for Computational Linguistics.</p>
    <p>Features:  unigrams, bigrams and trigrams adding to the lemma also the POS of every token  name of the primary author of the cited paper  science lexicon: 83 polar phrases which have been manually extracted from the development set of 736 citations  presence of subjectivity clues  number of adjectives, adverbs, pronouns, modals and cardinals  number of negation phrases and valence shifter (Opinion Finder)  dependency tree triples Dependency tree used to identify the clause of the sentence where the citation occurs Negated (suffix _neg) the two lemmas after a negation expression (Opinion Finder)</p>
    <p>Online at: http://cl.awaisathar.com/citation-sentiment-corpus/</p>
    <p>Corpus: 8,736 citations from 310 research papers taken from the ACL Anthology, tagged manually as positive, negative or objective</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation function Several annotation schemas have been proposed</p>
    <p>to characterize the function of citations Athar, A. (2011, June). Sentiment analysis of citations using sentence structure-based features.</p>
    <p>In Proceedings of the ACL 2011 student session (pp. 81-87). Association for Computational Linguistics.</p>
    <p>Online at: http://cl.awaisathar.com/citation-sentiment-corpus/</p>
    <p>Corpus: 8,736 citations from 310 research papers taken from the ACL Anthology, tagged manually as positive, negative or objective</p>
    <p>Algorithm: SVM Result:  n-grams and dependency relations are sufficient to model lexical structure that can characterize the polarity of citations  scientific lexicon, word level features, sentence splitting and negation does not help</p>
    <p>Athar, A., &amp; Teufel, S. (2012, July). Detection of implicit citations for sentiment detection. In Proceedings of the Workshop on Detecting Structure in Scholarly Discourse (pp. 18-26). Association for Computational Linguistics.  SVM based approach to identify sentences belonging to the citation context. The information from the citation context improve sentiment analysis performance for citations</p>
    <p>Corpus: 852 papers which cite the top 20 target papers. Citation context sentences are identified and marked as negative, positive, objective/neutral. Online at: http://cl.awaisathar.com/citation-context-corpus/</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation function Several annotation schemas have been proposed</p>
    <p>to characterize the function of citations Shotton, D. (2010). CiTO, the citation typing ontology. Journal of biomedical semantics, 1(1), 1.</p>
    <p>Part of the Semantic Publishing and Referencing Ontologies, includes 41 properties for citation characterization in its most recent version (03/07/2015)</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation function Several annotation schemas have been proposed</p>
    <p>to characterize the function of citations Fisas, B., Ronzano, F., &amp; Saggion, H. (2016). A Multi-Layered Annotated Corpus of Scientific Papers. LREC.</p>
    <p>in the case considered, a requirement, its difficulty, its computational cost, etc.</p>
    <p>STRENGTH A strength in a cited work may refer to its easiness of use, its little</p>
    <p>computational cost, its speed, its novelty, etc.</p>
    <p>EVALUATION Some citations do not only state a strength or a weakness of the cited paper,</p>
    <p>but provide the authors evaluation of the research, by opposing a strength</p>
    <p>with a weakness or by giving his opinion in an explicit (or subtle) way.</p>
    <p>OTHER If a citation can be considered a CRITICISM, but cannot be included in the</p>
    <p>previous sub-purposes, then it should be annotated as CRITICISM_OTHER. COMPARISON SIMILARITY The comparison focuses on the similarities with the authors work.</p>
    <p>DIFFERENCE The comparison focuses on the differences with the authors work.</p>
    <p>USE METHOD If the author uses the method, technique, or algorithm developed by the cited</p>
    <p>paper.</p>
    <p>DATA If the author uses the data produced by the cited paper.</p>
    <p>TOOL If the author uses a tool or software package developed by the cited paper.</p>
    <p>OTHER SUBSTANTIATIO N A citing sentence is classified as SUBSTANTIATION when the cited paper and</p>
    <p>the citing paper support each other.</p>
    <p>BASIS PREVIOUS OWN The author bases the current research on his own previous work.</p>
    <p>OTHERS WORK The author bases the current research on others previous work.</p>
    <p>FUTURE WORK Future work can be developed based on the cited work.</p>
    <p>NEUTRAL DESCRIPTION If the citation is a neutral description of the cited work.</p>
    <p>REFERENCE FOR</p>
    <p>MORE INFO</p>
    <p>If the author refers to a work for obtaining more detailed information about a</p>
    <p>particular subject.</p>
    <p>COMMON</p>
    <p>PRACTICE</p>
    <p>When other authors work are cited as common practices in the knowledge</p>
    <p>field.</p>
    <p>OTHER Other reasons for neutral citations.</p>
    <p>Online at: http://sempub.taln.upf.edu/</p>
    <p>dricorpus</p>
    <p>Dr. Inventor Corpus</p>
    <p>40 Computer Grahics articles  1,575 citations</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation function Several annotation schemas have been proposed</p>
    <p>to characterize the function of citations Valenzuela, M., Ha, V., &amp; Etzioni, O. (2015, April). Identifying meaningful citations.</p>
    <p>In Workshops at the Twenty-Ninth AAAI Conference on Artificial Intelligence.</p>
    <p>Coarse and fine-grained labels for citation type</p>
    <p>Features:  direct citations (total and per section)  indirect citations (total and per section)  author overlap  is considered helpful  in table or figure caption (were comparing)  number of direct citations over all the direct citations  tf-idf similarity between abstracts (citing / cited)  page rank  number of citing papers after transitive closure  research field of paper</p>
    <p>Corpus: 465 citations from ACL anthology Considering direct citations:</p>
    <p>and indirect citations:</p>
    <p>Algorithms: SVM (RBF k.) and random forest Evaluation: SVM accuracy: 0,93</p>
    <p>Most informative feature: direct citations (total and per section) Followed by: author overlap, is considered helpful, number of direct citations over all the direct citations, research field of paper</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation prediction and recommendation Given an in-line citation placeholder,</p>
    <p>predict (recommend) which is the paper that should be cited</p>
    <p>[ ? ]</p>
    <p>In-line citation placeholder</p>
    <p>It analyses the content and conceptual structure of scientific articles with an ontology-based annotation schema the Core Scientific Concept s scheme (CoreSC).</p>
    <p>Search query Cited paper not retrieved among the first 10 results</p>
    <p>No results retrieved</p>
    <p>Cited paper not retrieved among the first 10 results</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation prediction and recommendation</p>
    <p>Several facets can contribute to identify the best cited paper match:  features local to the citation context (e.g. papers with similar citation contexts)  features global of the whole document (e.g. papers with similar title, abstract, shared keywords or authors)  user preferences (i.e. publication and citation history of the author, user profile in a bibliography management system)  citation network (i.e. paper-citation matrix)</p>
    <p>Given an in-line citation placeholder, predict (recommend) which is the paper that should be cited</p>
    <p>[ ? ]</p>
    <p>In-line citation placeholder</p>
    <p>LOCAL CONTEXT GLOBAL</p>
    <p>CONTEXT CITATION NETWORK</p>
    <p>[ ? ]</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation prediction and recommendation Given an in-line citation placeholder,</p>
    <p>predict (recommend) which is the paper that should be cited</p>
    <p>Dealing with citation prediction / recommendation</p>
    <p>Huge search space: progressive reduction of candidate set (lightweight cited papers selection methods for a first coarse-grained selection, candidate cited paper clustering)</p>
    <p>Neural models: estimate the probability that, given a word from the citation context, a document is cited by jointly learning neural representations (embeddings) of words from citation contexts and cited documents</p>
    <p>Citation context identification: models to identify in a paper the candidate citation contexts and, for each of them, the list of top-n candidate cited papers</p>
    <p>Citation motivation: explain why a certain paper should be cited in a given citation context</p>
    <p>Online tool that implements distinct approaches of document level and context level citation recommendation - http://refseer.ist.psu.edu/</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation-based summarization</p>
    <p>The contexts of the citations of a specific paper provide useful information concerning the core topic of the paper together with</p>
    <p>opinions of the research community on the piece of work</p>
    <p>Since citing sentences appear to be somewhat more focused than the abstract and contain additional information not in the abstract, they could be useful as a supplement</p>
    <p>Elkiss, A. et al. 2008). Blind men and elephants: What do citation summaries tell us about a research article?.</p>
    <p>More details and examples of how summarization systems exploit citation-related information will be presented in the following part of this</p>
    <p>tutorial dealing with summarization of scientific literature</p>
    <p>Past studies already presented neural-network approaches to identify named entities [1].</p>
    <p>We parse text by means of the concept extraction system presented in [1].</p>
    <p>[1] propose new approach to spot Named Entities in legal texts.</p>
    <p>The approach described in [1] shows several limitations with respect to scalability.</p>
    <p>[1]</p>
    <p>The inclusion of citation-related information brings to the generation of better summaries. Ronzano, F. et a. An Empirical Assessment of Citation Information in Scientific Summarization.</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Citation graphs</p>
    <p>Arxiv HEP-PH (high energy physics phenomenology) citation graph is from the e-print arXiv January 1993  April 2003 (124 months) https://academicgraphwe.blob.core.windows.net/graph-2016-02-05/index.html</p>
    <p>High-energy physics citation network (2003 KDD cup)</p>
    <p>Patent citation network (2005 KDD cup)</p>
    <p>CiteSeer citation network</p>
    <p>ACL Anthology Network</p>
    <p>OpenCitations</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Citations represent a primary device of scientific literature useful to issue explicit author-created links among publications</p>
    <p>Both the network of citations and the textual contents of citation contexts are exploited in many different tasks including: research collaboration analysis, topic analysis and evolution, citation recommendation, scientific document summarization</p>
    <p>Besides citation counts, the (complex task of) characterization of the purpose of citations can provide deeper insights on the quality of scientific publications and the feedback of the research community</p>
    <p>Citation recommendation system can complement pure scientific literature search engines in helping to cope with scientific information overload</p>
    <p>A rich collection of citation datasets, including citation networks and corpora of citations annotated with respect to their sentiment and purpose, is freely available for further experimentation</p>
    <p>Citation analysis</p>
  </div>
  <div class="page">
    <p>SCIENTIFIC DOCUMENT SUMMARIZATION</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Document summarization overview</p>
    <p>Summarizing scientific articles  Information extraction and template-based generation</p>
    <p>Indicative-informative summaries</p>
    <p>Fact-based citation summaries (C-LexRank)</p>
    <p>Impact-driven summaries</p>
    <p>Non-explicit citations in summaries</p>
    <p>Improving summary coherence</p>
    <p>Generating state-of-the-art reports</p>
    <p>Summarizing patents</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Document summarization overview</p>
    <p>What is a summary? A presentation of the substance of a body of material</p>
    <p>in a condensed form or by reducing it to its main points; an abstract. A short text containing the essential information of a document.</p>
    <p>What is a summarizer?</p>
    <p>An algorithm that selects and presents the most important content of a document</p>
    <p>Scientific document summarization</p>
  </div>
  <div class="page">
    <p>T y</p>
    <p>p e</p>
    <p>s o</p>
    <p>f S</p>
    <p>u m</p>
    <p>m a</p>
    <p>ri e</p>
    <p>s</p>
    <p>one / several documents</p>
    <p>summary purpose</p>
    <p>content</p>
    <p>input language</p>
    <p>formulation</p>
    <p>single document summarization</p>
    <p>multi-document summarization</p>
    <p>indicative summary (what is text about?)</p>
    <p>informative summary (gives information from text)</p>
    <p>generic summary (main points)</p>
    <p>user-focused (answers a query)</p>
    <p>monolingual</p>
    <p>cross-lingual</p>
    <p>extract (sentences from input documents) abstract ((quasi) new text )</p>
    <p>Different types of summaries Summaries should take into account a number of input factors such as</p>
    <p>the audience/reader of the summary</p>
    <p>Spark Jones (2007)</p>
    <p>Scientific document summarization</p>
    <p>Document summarization overview</p>
  </div>
  <div class="page">
    <p>General method to produce extracts of size N a) S = {}</p>
    <p>b) Associate to each sentence a score and put them in list L</p>
    <p>c) Sort sentences in L by score (in ascending order)</p>
    <p>d) While size of S &lt; N, put next sentence in L in S</p>
    <p>e) Show sentences in S in the order they appear in the original text</p>
    <p>Compression parameter  size in number of words of the summary</p>
    <p>compression rate: % of the words or sentences</p>
    <p>Scientific document summarization</p>
    <p>Document summarization overview Summarization by sentence extraction</p>
    <p>Extract from the input document the subset of sentences that contain the most important information</p>
  </div>
  <div class="page">
    <p>Word-distribution measures (Luhn'1958, Nenkova and Vanderwende, 2005)  Term/Word frequency</p>
    <p>Document structure (Edmundson, 1969; Lin and Hovy, 1998)  Position of sentence in document  Relation of sentence to title, abstract, keywords, etc.</p>
    <p>Presence of specific vocabulary (Paice, 1990)  Formulaic-expressions, key-words, etc.</p>
    <p>Centrality information (Barzilay and Elhadad, 1997; Radev et al, 2000; Saggion and Gaizauskas, 2004)  Word-based sentence-sentence relations , centroid  Co-reference</p>
    <p>Rhetorical information (Marcu, 1998; Ono et al., 1994)  How argument develops in sentences (more / less central)</p>
    <p>Semantic (Saggion and Lapalme, 2002; Jones and Paice, 1993)  Domain/Topic template / Information types to cover in summary</p>
    <p>External (Tombros et al, 1998)  Query / User Knowledge</p>
    <p>Scientific document summarization</p>
    <p>Summarization by sentence extraction: sentence relevance Function to assess the contribution of a sentence to a summary,</p>
    <p>developed since the late 50s some still used in the literature</p>
    <p>Document summarization overview</p>
  </div>
  <div class="page">
    <p>Word/term repetition Over pre-processed corpora (stemming, stop-words removal), the inverse document frequency can be used to assess word relevance</p>
    <p>(Edmundson, 1969; Lin and Hovy, 1998) (Tombros et al, 1998)</p>
    <p>Scientific document summarization</p>
    <p>Document summarization overview Summarization by sentence extraction: superficial techniques</p>
    <p>Information about sentence relevance can be provided by: word/term repetition and document structure</p>
    <p>) )(</p>
    <p>log()( termNUMDOC</p>
    <p>NUMDOC termidf )(*)()( tidfttftrelevance</p>
    <p>Document structure  Position of sentence in document</p>
    <p>in news give relevance to lead-paragraph</p>
    <p>in scientific discourse give relevance to sentences under specific section headings</p>
    <p>learn optimal positions in a given textual genre</p>
    <p>Title / Query sentence relevance  similarity between sentence and document title or user need expressed in a query (cosine, jaccard, etc.)</p>
    <p>Information retrieval techniques are useful here</p>
  </div>
  <div class="page">
    <p>Scientific document summarization</p>
    <p>Document summarization overview Summarization by sentence extraction: superficial techniques</p>
    <p>More or less fixed vocabulary indicates the presence of important information in text</p>
    <p>(Paice, 1990; Jones and Paice, 1993)</p>
    <p>Cue-phrases, indicative expressions, formulaic expressions, etc.</p>
    <p>dictionary with expressions (literal or patterns)</p>
    <p>in this {paper | work | article} we....</p>
    <p>{our | my } {results | findings |...} demonstrate ....</p>
    <p>may be organized in categories (results, conclusion, etc.)</p>
    <p>expressions may be weighted</p>
    <p>expressions might be learnt from corpora</p>
  </div>
  <div class="page">
    <p>Features can be combined a la Edmundson to score sentences</p>
    <p>Given training data</p>
    <p>A scoring function can be learnt (regression)</p>
    <p>A sentence classification function (extract | non-extract) can be learnt</p>
    <p>)(.)(.)(.)(.)( SPositionSKeywordSCueSTitleSWeight</p>
    <p>Scientific document summarization</p>
    <p>Document summarization overview Summarization by sentence extraction: feature combinations</p>
    <p>No single source of information will produce the best scoring schema: usually features have to be combined</p>
    <p>(Edmundson, 1969) (Kupiec et al, 1995)</p>
  </div>
  <div class="page">
    <p>Text represented as a graph</p>
    <p>vertices are meaning units such as words or sentences</p>
    <p>edges are connections between units</p>
    <p>Inspired by the PageRank algorithm (Page et al. 1998) several summarization algorithms were proposed</p>
    <p>LexRank (Erkan &amp; Radev, 2004)</p>
    <p>TextRank (Mihalcea &amp; Tarau, 2004)</p>
    <p>Scientific document summarization</p>
    <p>Document summarization overview Summarization by sentence extraction: graph-based techniques</p>
    <p>Lexical similarity between sentences in the document tell us about their relevance: text is represented</p>
    <p>as a connected structure (unlike other superficial approaches)</p>
    <p>(Erkan and Radev, 2004; Mihalcea &amp; Tarau, 2004)</p>
  </div>
  <div class="page">
    <p>N</p>
    <p>j jC</p>
    <p>jPR d</p>
    <p>N</p>
    <p>d iPR</p>
    <p>)( *</p>
    <p>going out of page j</p>
    <p>PageRank values of page j connected to i</p>
    <p>damping factor</p>
    <p>Scientific document summarization</p>
    <p>Document summarization overview</p>
    <p>Summarization by sentence extraction: graph-based techniques Page Rank</p>
    <p>conceived to rank Web pages by relevance</p>
    <p>Web pages form a directed graph</p>
    <p>PageRank computes the relevance (PageRank score) of each Web page thanks to the recursive analysis of the connectivity of the complete network:</p>
  </div>
  <div class="page">
    <p>Scientific document summarization</p>
    <p>Document summarization overview Summarization by sentence extraction:</p>
    <p>graph-based techniques at document level Text graphs for summarization seek to associate a weight</p>
    <p>to sentences based on an analysis of a text graph</p>
    <p>Sentences are vertex (s1, s2, ..., sn)</p>
    <p>There are edges E(sk, sl) connecting sk with sl</p>
    <p>In(si) is the set of of sentences si such that there is an edge E(si, sj)</p>
    <p>Out(si) is the set of of sentences si such that there is an edge E(sj, si)</p>
    <p>Graph generally undirected but could be directed if text order is taken into account (si connects with sj only if i &lt; j)</p>
  </div>
  <div class="page">
    <p>)(* )(</p>
    <p>)(</p>
    <p>),(</p>
    <p>),( *)1()( sjw</p>
    <p>siInsj sjOutsk</p>
    <p>sjsksim</p>
    <p>sjsisim d</p>
    <p>N</p>
    <p>d siw</p>
    <p>)(* )(</p>
    <p>)(</p>
    <p>,</p>
    <p>, *)1()( sjw</p>
    <p>siInsj sjOutsk</p>
    <p>kwj</p>
    <p>iwj ddsiw</p>
    <p>|)log(||)log(|</p>
    <p>|| ,</p>
    <p>sksj</p>
    <p>sksj kwj</p>
    <p>Scientific document summarization</p>
    <p>Document summarization overview Summarization by sentence extraction:</p>
    <p>graph-based techniques at document level LexRank and TextRank score sentences based on</p>
    <p>an iterative procedure and weighting mechanisms similar to PageRank</p>
    <p>Sentence similarity:</p>
    <p>LexRank uses cosine similarity to</p>
    <p>compare sentences</p>
    <p>TextRank uses a kind of jaccard</p>
    <p>coefficient</p>
    <p>Parameters (d, w(s), etc.) need to be</p>
    <p>estimated</p>
    <p>Scores computed iteratively until</p>
    <p>convergence</p>
    <p>LexRank</p>
    <p>TextRank</p>
  </div>
  <div class="page">
    <p>jk</p>
    <p>d ik</p>
    <p>d j</p>
    <p>D i</p>
    <p>Dsim .),(</p>
    <p>),..., 1</p>
    <p>( in</p>
    <p>d i</p>
    <p>d i</p>
    <p>D sim&gt;thr</p>
    <p>sim&lt;=thr</p>
    <p>C A</p>
    <p>B</p>
    <p>D</p>
    <p>E F</p>
    <p>complete graph</p>
    <p>F=2</p>
    <p>C=2</p>
    <p>D=1</p>
    <p>E=3</p>
    <p>B=1</p>
    <p>A=3</p>
    <p>graph after pruning</p>
    <p>degree of node</p>
    <p>Paragraph selection based on graph search techniques:</p>
    <p>best first, etc.</p>
    <p>Scientific document summarization</p>
    <p>Document summarization overview Summarization by sentence extraction: other Information Retrieval Techniques</p>
    <p>The vector space model: paragraph is represented as a vector of terms and weights and similitude between paragraphs is computed using inner product</p>
    <p>(Salton et al. 1997)</p>
  </div>
  <div class="page">
    <p>Humans identify units in ideal summaries and units in automatic summaries</p>
    <p>Units are matched and their overlap assessed</p>
    <p>Text quality assessed by means of questionnaires</p>
    <p>Human evaluation is very expensive</p>
    <p>EVALUATION INTERFACE</p>
    <p>Scientific document summarization</p>
    <p>DUC evaluations</p>
    <p>Document summarization overview Evaluation of automated summaries</p>
    <p>Human assessment of content: check with source document or with ideal summaries, and text quality: grammaticality, coherence, etc.</p>
  </div>
  <div class="page">
    <p>Other ROUGE metrics:</p>
    <p>ROUGE-L: Based on longest common subsequence</p>
    <p>ROUGE-W: weighted longest common subsequence, favours consecutive matches</p>
    <p>ROUGE-S: Skip-bigram recall metric</p>
    <p>Arbitrary in-sequence bigrams are computed</p>
    <p>ROUGE-SU adds unigrams to ROUGE-S</p>
    <p>}Refs{ gram-n</p>
    <p>gram)-count(n</p>
    <p>{Refs}S Sgram-n</p>
    <p>gram)-(ncountmatch</p>
    <p>n-ROUGE</p>
    <p>S S</p>
    <p>Scientific document summarization</p>
    <p>Document summarization overview Evaluation of automated summaries</p>
    <p>ROUGE: Recall-Oriented Understudy for Gisting Evaluation Measures content quality of a summary by comparison with ideal(s) summaries</p>
    <p>based on n-gram counting</p>
    <p>(Lin, 2004)</p>
  </div>
  <div class="page">
    <p>each SCU in tier Ti in the pyramid has weight i</p>
    <p>the best summary is one which contains all units of level n, then all units from n1,</p>
    <p>if Di is the number of SCU in a summary which appear in Ti for summary is:</p>
    <p>X is the number of units in the summary</p>
    <p>n</p>
    <p>i</p>
    <p>i DiD</p>
    <p>n</p>
    <p>it</p>
    <p>t i</p>
    <p>XTj )||(max</p>
    <p>n</p>
    <p>ji</p>
    <p>i</p>
    <p>n</p>
    <p>ji</p>
    <p>i TXjTiMax</p>
    <p>|)|(||</p>
    <p>MaxDScore /</p>
    <p>Scientific document summarization</p>
    <p>Document summarization overview Evaluation of automated summaries</p>
    <p>Pyramid Score based on the distribution of content units (Sus) in a set of ideal summaries,</p>
    <p>similar content units are grouped together</p>
    <p>(Nenkova, Passoneau, McKeown, 2007)</p>
    <p>PYRAMID FROM CONTENT UNITS IN IDEAL SUMMARIES</p>
    <p>w=1</p>
    <p>w=n</p>
    <p>w=n-1</p>
    <p>...</p>
  </div>
  <div class="page">
    <p>MEAD  publicly available toolkit for multi-lingual summarization and evaluation http://www.summarization.com/mead/  implements different algorithms: position-based, centroid-based, it*idf, query</p>
    <p>based summarization  implements evaluation methods: co-selection, relative-utility, content-based</p>
    <p>metrics</p>
    <p>SUMMA  publicly available: http://www.taln.upf.edu/pages/summa.upf/  JAVA library to implement summarization systems  Statistical analysis of documents  Several relevance features and sentence scoring mechanisms available  Multilingual, Multi-document  Implements ROUGE and BLEU summary evaluation</p>
    <p>Scientific document summarization</p>
    <p>Document summarization overview Summarization tools</p>
    <p>Availability of summarization tools: no reinvent the wheel, allow comparison, provide baselines, etc.</p>
    <p>(Radev et al. 2004; Saggion, 2008, 2014)</p>
  </div>
  <div class="page">
    <p>Scientist and other interested parties nowadays face the problem of scientific information overload o PubMed contains more than 24M papers, Elsevier Scopus over 57M, while Thomson</p>
    <p>Reuthers ISIWeb of Knowledge more than 90M. o Current estimates indicate that a research paper is published every 13 seconds</p>
    <p>Scientific text summarization was the first summarization application domain! o Summarization of scientific documents has been addressed using traditional</p>
    <p>relevance features, classification or generic/domain specific scientific information</p>
    <p>Scientific document summarization</p>
    <p>Summarizing Scientific Articles Scientific information overload is going to be more and more problematic</p>
    <p>Summarization can help scientists and other interested partners to access text collections by means of automated summaries</p>
  </div>
  <div class="page">
    <p>Rhetorical classification of sentences  Extracting sentences likely to contain semantic information on objectives,</p>
    <p>goal, own contributions, etc.  classification</p>
    <p>Extracting scientific specific information  Concept based abstracting  information extraction + template-based</p>
    <p>generation</p>
    <p>Extraction generic scientific information  Extracting sentences based on generic information types  information</p>
    <p>extraction + shallow generation</p>
    <p>Relying on the opinion of the scientific community to summarize  Taking advantage of citation sentences to summarize a article  Impact-based summarization  uses the source document  Citation-based summarization  uses the citation sentences</p>
    <p>Scientific document summarization</p>
    <p>Summarizing Scientific Articles Summarization approaches to the Scientific Document</p>
    <p>Summarization has to be adapted to the peculiarities of the scientific discourse: length, document structure, terminology, citations, rhetorical organization, etc.</p>
  </div>
  <div class="page">
    <p>Example in the are of crop husbandry SPECIES (what is studied); CULTIVAR (the variety that is studied); HIGH-LEVEL-PROPERTY</p>
    <p>(the property studied: growth); PEST (a pest that attacks the species); AGENT (the chemical/bio agent used to control the pest); etc.</p>
    <p>Method  Weighted patterns (PEST is a ? pest of SPECIES) are applied to the text to instantiate</p>
    <p>concepts</p>
    <p>Matched strings are analyzed and weighted to extract final values</p>
    <p>Summaries are generated using the strings</p>
    <p>Scientific document summarization</p>
    <p>Summarizing Scientific Articles Domain Specific Summarization</p>
    <p>using Information Extraction and Template-based Generation Summaries in specific scientific domains report information</p>
    <p>on specific and stereotypical domain concepts. The way the information is presented in the summary is also predictable.</p>
    <p>(Oakes and Paice, 2000)</p>
    <p>This paper studies the effect of [AGENT] on the [HLP] of [SPECIES] OR this paper studies the effect of [METHOD] on the [HLP] of [SPECIES] when it is infested by [PEST]</p>
    <p>This paper studies the effect of G. pallida on the yield of potato. An experiment in 1985 and 1986 at York was undertaken.</p>
  </div>
  <div class="page">
    <p>Article Title: Features 3D scanning systems for rapid prototyping (97 sentences)</p>
    <p>Indicative Summary: Describes two non-contact scanning systems, REVERSA and ModelMaker</p>
    <p>Topics: CADAM system; ModelMaker; REVERSA; standard dual view system; system</p>
    <p>Expanding Topics: REVERSA and ModelMaker</p>
    <p>REVERSA is a dual viewpoint non-contact laser scanner which comes complete with scanning software and data manipulation tools.</p>
    <p>The ModelMaker scanning system is a combination of a 3D laser stripe sensor, 6DOF position localizer and a PC...</p>
    <p>ModelMaker can simply be retrofitted to existing arms providing the benefits of a portable CMM with dense depth data sets...</p>
    <p>Scientific document summarization</p>
    <p>Summarizing Scientific Articles Generating Indicative-Informative Summaries of Technical Articles</p>
    <p>Generate a brief indicative summary of the main topics discussed in the paper and expand the topics with useful information about the topics.</p>
    <p>Modelling general scientific information</p>
    <p>(Saggion and Lapalme, 2002)</p>
  </div>
  <div class="page">
    <p>Based on a linguistic &amp; conceptual model of the scientific article  Concepts = author, section, problem, solution, limitations, etc.  Relations = present topic, define, elaborate, conclude, etc.  Patterns for interpretation = dictionary elements + syntax + lexical elements  Templates for generation</p>
    <p>Text analysis: POS tagging + pattern-matching  Sentence scoring: titles (main + section headings) &amp; verb-argument (noun phrase)</p>
    <p>scoring guide sentence selection  Text generation: order information based on dictionary categories, sentence</p>
    <p>fusion, verb transformation (personal (e.g. We describe X)  impersonal (e.g. Describes X) etc.</p>
    <p>Evaluation: text classification, comparison against author abstract, comparison against ideal summaries  Improves over all baselines</p>
    <p>D IC</p>
    <p>T IO</p>
    <p>N A</p>
    <p>R Y</p>
    <p>Scientific document summarization</p>
    <p>Summarizing Scientific Articles Generating Indicative-Informative Summaries of Technical Articles</p>
    <p>Generate a brief indicative summary of the main topics discussed in the paper and expand the topics with useful information about the topics.</p>
    <p>Modelling general scientific information</p>
  </div>
  <div class="page">
    <p>In 2014 National Institute for Standards &amp; Technology (NIST) proposed the BioSumm Shared Task to promote the development of methods for summarizing scientific articles</p>
    <p>Writing surveys / overviews of developments in biomedicine (or any other field) requires the analysis of considerable number of scientific publications</p>
    <p>Author abstracts do not provide information on the lasting influences of a work</p>
    <p>Citations do not provide enough context from the cited paper</p>
    <p>Scientific document summarization</p>
    <p>Summarizing Scientific Articles Citation-based summarization</p>
    <p>New forms of scientific summarization are based on citation networks: a paper is summarized taking into account the opinions or views</p>
    <p>of the scientific community has about a paper.</p>
    <p>https://tac.nist.gov//2014/BiomedSumm/</p>
    <p>BioSumm 2014 &amp; SciSumm 2016</p>
  </div>
  <div class="page">
    <p>Structure of the dataset - Ech Collection is made of 1 Reference Paper + 10 Citing Papers - For each Collection, four 250-words humanwritten summaries of the reference paper</p>
    <p>Scientific document summarization</p>
    <p>Summarizing Scientific Articles Citation-based summarization: BioSumm 2014 &amp; SciSumm 2016</p>
    <p>https://tac.nist.gov//2014/BiomedSumm/</p>
    <p>For each Collection, three tasks are proposed:  Task 1A: identify text spans being cited  Task 1B: identify citation facet  Task 2: create a community-based summary</p>
    <p>http://wing.comp.nus.edu.sg/birndl-jcdl2016/</p>
    <p>AIM</p>
    <p>METHOD</p>
    <p>BioSumm 2014: 30 Coll. for training and 20 Coll. for evaluation SciSumm 2016: 10 Coll. for training and 10 Coll. for development and 10 Coll. For evaluation</p>
  </div>
  <div class="page">
    <p>DataSet  ACL Anthology Network (ANN)</p>
    <p>5 clusters of documents extracted (each on a given topic, matched with specific keyword e.g. dependency parsing)</p>
    <p>Each cluster 5 different documents, each with citations</p>
    <p>For each paper a citation summary was created based on the sentences citing the paper</p>
    <p>Annotators were asked to extract facts from the citation summary (keywords or phrases) that represent the content</p>
    <p>Scientific document summarization</p>
    <p>Summarizing Scientific Articles Citation-based summarization:</p>
    <p>fact-based citation summaries (C-LexRank)</p>
    <p>(Qazvinian and Radev, 2008)</p>
  </div>
  <div class="page">
    <p>Some annotators agreed on some facts (Czech DP, lexical rules, etc.)</p>
    <p>Some annotators found unique facts like: generative model</p>
    <p>A {0,1} matrix can be created which indicates which facts are covered by which citation sentences</p>
    <p>The summary of a paper is created by: creating a Citation Summary Network and selecting citing sentences that cover a varied set of relevant facts</p>
    <p>Sentences well connected in the network (high similarity) should represent shared facts</p>
    <p>Different sentence similarity measures are compared to decide on the most appropriate (evaluated on paper A Statistical Parser for Czech)</p>
    <p>Scientific document summarization</p>
    <p>Summarizing Scientific Articles</p>
    <p>Facts for paper A Statistical Parser for Czech with 54 citations</p>
    <p>(Qazvinian and Radev, 2008)</p>
    <p>Citation-based summarization: fact-based citation summaries (C-LexRank)</p>
  </div>
  <div class="page">
    <p>Network-based clustering is applied to group sentences which share many common facts by a hierarchical agglomerative clustering algorithm</p>
    <p>Evaluation is carried out computing purity where K are the clusters and C are the classes (the facts!)</p>
    <p>Selection of summary sentence from clusters: 1. Cluster Round-Robin (C-RR): Sort the clusters by their size and extract one sentence</p>
    <p>from each cluster, then extract more sentences until compression is reached.</p>
    <p>Baseline methods:  Random summary  LexRank (without initial clustering)</p>
    <p>The best performing system (according to pyramid scores) overall is C-lexrank, followed by Lexrank, and then by C-RR</p>
    <p>||max 1</p>
    <p>),( ji i</p>
    <p>j ck</p>
    <p>N CKpurity</p>
    <p>Scientific document summarization</p>
    <p>Summarizing Scientific Articles</p>
    <p>(Qazvinian and Radev, 2008)</p>
    <p>Citation-based summarization: fact-based citation summaries (C-LexRank)</p>
  </div>
  <div class="page">
    <p>Impact-based summary: a set of sentences from the paper that can reflect the impact of the paper</p>
    <p>Instead of using citation sentences the approach uses sentences from the paper (to avoid including content which is not directly related to the paper to summarize)</p>
    <p>Scientific document summarization</p>
    <p>Summarizing Scientific Articles Citation-based summarization: Impact-driven summaries</p>
    <p>Summarizing the impact of a scientific publication: ... the impact of a paper has to be judged based on the consent of the research community...</p>
    <p>(Mei and Zhai, 2008)</p>
  </div>
  <div class="page">
    <p>Citation context: widow of sentences around the citation</p>
    <p>Approach</p>
    <p>Construct a representation of the impact I of a document d based on d and the citation context C</p>
    <p>Develop a scoring function Score(.) to rank sentences of d reflecting I</p>
    <p>The approach can be seen as a retrieval problem: sentences of d are documents and I is a query: retrieve sentences matching I</p>
    <p>Scientific document summarization</p>
    <p>Summarizing Scientific Articles Citation-based summarization: Impact-driven summaries</p>
    <p>Summarizing the impact of a scientific publication: ... the impact of a paper has to be judged based on the consent of the research community...</p>
    <p>(Mei and Zhai, 2008)</p>
  </div>
  <div class="page">
    <p>Impact Language Model: an unigram model for I (the impact), based on both (i) the document d to summarize and (ii) the citation context C</p>
    <p>probabilities for words in d are estimated using relative frequencies</p>
    <p>probabilities for words in C are estimated from relative frequencies, citation paper impact (based on page rank), and position of the sentence with respect to the citation marker</p>
    <p>Scientific document summarization</p>
    <p>Summarizing Scientific Articles Citation-based summarization: Impact-driven summaries</p>
    <p>Summarizing the impact of a scientific publication: ... the impact of a paper has to be judged based on the consent of the research community...</p>
    <p>(Mei and Zhai, 2008)</p>
  </div>
  <div class="page">
    <p>The scoring function of paper sentences (score(s)) is based on Kullback-Leibler (KL) divergence</p>
    <p>V is the set of words in the vocabulary</p>
    <p>is the Impact Language Model</p>
    <p>is the sentence language model</p>
    <p>))|(log() |())|(log() |(</p>
    <p>)||()(</p>
    <p>II</p>
    <p>Vw</p>
    <p>ss</p>
    <p>Vw</p>
    <p>sI</p>
    <p>wpwpwpwp</p>
    <p>Dsscore</p>
    <p>I  s</p>
    <p>Scientific document summarization</p>
    <p>Summarizing Scientific Articles Citation-based summarization: Impact-driven summaries</p>
    <p>Summarizing the impact of a scientific publication: ... the impact of a paper has to be judged based on the consent of the research community...</p>
    <p>If and are very close, the KL-divergence would be small and Score(s) would be high I s  (Mei and Zhai, 2008)</p>
  </div>
  <div class="page">
    <p>Scientific document summarization</p>
    <p>Citation-based summarization: Impact-driven summaries Summarizing the impact of a scientific publication: ... the impact of a paper has to be</p>
    <p>judged based on the consent of the research community...</p>
    <p>Summarizing Scientific Articles</p>
    <p>Data</p>
    <p>SIGIR papers from 1978 to 2005 (1,303 papers)</p>
    <p>Citation contexts extracted (5 sentences): sentence with citation marker -2,+2</p>
    <p>Only papers with at least 20 citations are considered (14 papers)</p>
    <p>Experts assessed each sentence in the paper and decided if it covers influential content as indicated in the citation contexts</p>
    <p>The influential sentences are considered as the gold standard summaries for evaluation</p>
    <p>(Mei and Zhai, 2008)</p>
  </div>
  <div class="page">
    <p>Scientific document summarization</p>
    <p>Citation-based summarization: Impact-driven summaries Summarizing the impact of a scientific publication: ... the impact of a paper has to be</p>
    <p>judged based on the consent of the research community...</p>
    <p>Summarizing Scientific Articles</p>
    <p>Evaluation</p>
    <p>ROUGE-1 and ROUGE-L are used to compare automatic summaries with gold summaries</p>
    <p>Baselines: LEAD, MEAD, MEAD + Citation Context</p>
    <p>KL-divergence summarizer outperforms all baselines</p>
    <p>Parameters such as authority and proximity of sentence to citation have an impact on the results</p>
    <p>(Mei and Zhai, 2008)</p>
  </div>
  <div class="page">
    <p>A limitation of citation-based approaches to scientific summarizations is the use of explicit citation information</p>
    <p>Explicit citation:</p>
    <p>This approach is one of those described in Eisner (1996)</p>
    <p>Offers very little information about Eisners paper</p>
    <p>Implicit or non-explicit citation sentences may contain useful information on the cited paper</p>
    <p>....the parser searches for the best parse for the sentence. This approach is one of those described in Eisner (1996)</p>
    <p>Non-explicit citation</p>
    <p>Scientific document summarization</p>
    <p>Citation-based summarization: finding non-explicit citations Finding sentences that potentially contain useful information about a cited source,</p>
    <p>but not explicitly cite it  i.e. expanding explicit citations to citation contexts</p>
    <p>Summarizing Scientific Articles</p>
    <p>(Qazvinian and Radev, 2010)</p>
  </div>
  <div class="page">
    <p>Method:</p>
    <p>Construction of a graphical model based on Markov Random Fields (MRF) from the sentences in the document</p>
    <p>Evaluation with respect to gold-standard (F-measure)</p>
    <p>Evaluation with respect to extrinsic citation-based summarization (using pyramid method)</p>
    <p>Scientific document summarization</p>
    <p>Summarizing Scientific Articles</p>
    <p>(Qazvinian and Radev, 2010)</p>
    <p>Citation-based summarization: finding non-explicit citations</p>
  </div>
  <div class="page">
    <p>For each sentence Si, represents an event of being a non-explicit citation</p>
    <p>Observed nodes represent measurable information about sentences (sentence content)</p>
    <p>Hidden nodes represents the state of the sentence (non-explicit citation state)  modelled with a potential function or probability of being at state</p>
    <p>Relation between neighbouring sentences represented with a weighted edge: compatibility function represents i believes about j</p>
    <p>OBSERVED NODES</p>
    <p>HIDDEN NODES</p>
    <p>S1 S2 Sk Sn-1 Sn</p>
    <p>)( ii c</p>
    <p>)|( ijij cc</p>
    <p>ic</p>
    <p>ic</p>
    <p>Scientific document summarization</p>
    <p>Citation-based summarization: finding non-explicit citations</p>
    <p>Summarizing Scientific Articles</p>
    <p>(Qazvinian and Radev, 2010)</p>
  </div>
  <div class="page">
    <p>Scientific document summarization</p>
    <p>Citation-based summarization: finding non-explicit citations</p>
    <p>Summarizing Scientific Articles</p>
    <p>Assumptions about compatibility  if sentence is not non-explicit citation can not say much about other</p>
    <p>sentences</p>
    <p>If sentence is a non-explicit citation, it can say something about neighbouring sentences</p>
    <p>e1 j)cosine(i,</p>
    <p>)|(</p>
    <p>ijijij</p>
    <p>ijij</p>
    <p>Scc</p>
    <p>cc</p>
    <p>OBSERVED NODES</p>
    <p>HIDDEN NODES</p>
    <p>S1 S2 Sk Sn-1 Sn</p>
    <p>(Qazvinian and Radev, 2010)</p>
  </div>
  <div class="page">
    <p>Computation of values of hidden variables (probabilities of being ) is carried out with Belief Propagation (messages are sent from one sentence to the others)</p>
    <p>indicates the neighbours of sentence i in the network</p>
    <p>Messages are initially 0.5 and are updated through iteration (they are considered probabilities)</p>
    <p>ic</p>
    <p>jinek</p>
    <p>ikiijiji</p>
    <p>jinek</p>
    <p>ikiijijijij cmcccPcmcccPcm \)(\)(</p>
    <p>)()|()()()|()()(</p>
    <p>jinek</p>
    <p>ikiijiji</p>
    <p>jinek</p>
    <p>ikiijijijij cmcccPcmcccPcm \)(\)(</p>
    <p>)()|()()()|()()(</p>
    <p>)(ine</p>
    <p>ijm</p>
    <p>Scientific document summarization</p>
    <p>Citation-based summarization: finding non-explicit citations</p>
    <p>Summarizing Scientific Articles</p>
    <p>(Qazvinian and Radev, 2010)</p>
  </div>
  <div class="page">
    <p>Final believe values (i.e. probabilities) are computes with the final values as (with k a normalization factor):</p>
    <p>Choosing a threshold for deciding if the sentence is a non-explicit citation</p>
    <p>The values of are computed with a normalized linear formula that combines  a binary value for the presence of explicit citation</p>
    <p>a binary value for the presence of certain patterns</p>
    <p>the cosine similarity of the sentence to the cited paper</p>
    <p>)(</p>
    <p>)()()( inej</p>
    <p>iijiii cmckcb</p>
    <p>)(</p>
    <p>)()()( inej</p>
    <p>iijiii cmckcb</p>
    <p>)( ii c</p>
    <p>Scientific document summarization</p>
    <p>Citation-based summarization: finding non-explicit citations</p>
    <p>Summarizing Scientific Articles</p>
    <p>(Qazvinian and Radev, 2010)</p>
  </div>
  <div class="page">
    <p>Evaluation dataset: set of 10 documents from the ACL anthology + their implicit citation sentences (human annotated)</p>
    <p>Different network configurations explored (BP1: one neighbour, BP4: 4 neighbours, BPn: all neighbours)</p>
    <p>Baseline systems: B1 selects previous/following sentence if similarity greater than thr. B2 selects any neighbouring sentences (in a 4-sentence window) matching a pattern, SVM (with 3 features) a trained model using all docs minus one for training</p>
    <p>Scientific document summarization</p>
    <p>Citation-based summarization: finding non-explicit citations</p>
    <p>Summarizing Scientific Articles</p>
    <p>(Qazvinian and Radev, 2010)</p>
  </div>
  <div class="page">
    <p>Considering 4 sentences as the context of influence provides the best results</p>
    <p>Network-based approach better than sentence classification</p>
    <p>Using implicit citations for summary generation improves results (pyramid) that use only explicit citations</p>
    <p>F-score for identifying implicit citations</p>
    <p>Scientific document summarization</p>
    <p>Citation-based summarization: finding non-explicit citations</p>
    <p>Summarizing Scientific Articles</p>
    <p>(Qazvinian and Radev, 2010)</p>
  </div>
  <div class="page">
    <p>Problems  Citations may contain material referring to other articles</p>
    <p>Including irrelevant material will waste space</p>
    <p>Ordering sentences in a citation-based summary may affect coherence/cohesion (the order may not be logical)</p>
    <p>Approach  Filtering out unsuitable citation sentences and removing irrelevant</p>
    <p>parts from citation sentences</p>
    <p>Selecting best citation sentences (covering relevant aspects of the cited paper)</p>
    <p>Post-process the sentences to enhance the summary</p>
    <p>Scientific document summarization</p>
    <p>(Abu-Jbara and Radev, 2011)</p>
    <p>Citation-based summarization: improving coherence Citations may produce incoherent summaries,</p>
    <p>so further processing might be needed</p>
    <p>Summarizing Scientific Articles</p>
  </div>
  <div class="page">
    <p>Finding the scope of the reference is achieved by parsing the sentence and extracting the smallest sub-tree rooted S (sentence) which contains the reference</p>
    <p>Sentences are classified as suitable or unsuitable using supervised learning (SVM)</p>
    <p>Sentences are:  classified as Background, Problem, Method, Result and Limitation</p>
    <p>in each class, clustered by a hierarchical agglomerative community finding algorithm</p>
    <p>in each cluster sentences are weighted using the LexRank algorithm</p>
    <p>Sentences are selected based on: their category (B, P, M, R, L), size of the cluster they belong to, and LexRank values</p>
    <p>Finally the sentences are post-processed, the citation marker can be removed or transformed into a pronominal reference (he/she/they)</p>
    <p>A trainable system is used to decide the appropriate transformation</p>
    <p>Scientific document summarization</p>
    <p>Citation-based summarization: improving coherence</p>
    <p>Summarizing Scientific Articles</p>
    <p>(Abu-Jbara and Radev, 2011)</p>
  </div>
  <div class="page">
    <p>Dataset</p>
    <p>55 papers from the ANN corpus are used</p>
    <p>Citation sentences are annotated with labels: Background, Problem, Method, Result, Limitation, Unsuitable</p>
    <p>Citation markers are annotated with replace, remove, or keep</p>
    <p>Evaluation with ROUGE-L</p>
    <p>(5 sentences long) were created for 30 papers out of citation sentences</p>
    <p>Baselines used: MEAD with default settings, LexRank, citation-based summaries (QV08 system previous slides)</p>
    <p>System outperforms all baselines in ROUGE-L (sentence filtering having a high impact in the model)</p>
    <p>System has more coherent summaries than QV08</p>
    <p>Scientific document summarization</p>
    <p>Summarizing Scientific Articles</p>
    <p>Citation-based summarization: improving coherence</p>
    <p>(Abu-Jbara and Radev, 2011)</p>
  </div>
  <div class="page">
    <p>Automatic Related Work Summarization  Combines sentences from target paper and sentences from cited papers</p>
    <p>Topic tree of the state of the related work section (manually constructed)</p>
    <p>Sentences attached to topic based on how well it reflects topic and a mix of author and reference papers are selected for each topic</p>
    <p>Using Keywords  Given an initial query (Word Sense Disambiguation) a precise search for paper</p>
    <p>based on matching on titles and abstracts is carried out and then expanded with papers citing/cited by the initial papers</p>
    <p>For each paper citing sentences are used to generate the surveys</p>
    <p>Sentences are selected based on different methods: Centroid, LexRank, and CLexRank (clustering)</p>
    <p>Pyramid scores show that best system is LexRank</p>
    <p>Scientific document summarization</p>
    <p>Citation-based summarization: generating state-of-the-art reports A state of the art report or a survey of a scientific topic can be considered</p>
    <p>an instance of multi-document summarization</p>
    <p>Summarizing Scientific Articles</p>
    <p>(Hoang and Kan, 2010) (Jha et al., 2013)</p>
  </div>
  <div class="page">
    <p>Characteristics:</p>
    <p>long documents</p>
    <p>long sentences (&gt;500W sentences are common in some sections  claims)</p>
    <p>complicated sentence structure (many embedded clauses and coordination)</p>
    <p>complicated terminology (specific classification codes, technical terms, use of peculiar references, e.g. said</p>
    <p>device, references to other patents, biblio. references, figures, drawings, measurements, chemical compounds, etc.)</p>
    <p>peculiar document structure (title, field of invention, abstract, prior art, claims, description, drawings, etc.)</p>
    <p>Patent Overload!</p>
    <p>the European Patent Office (EPO) : 90M patents 750 patent applications each day</p>
    <p>Derwent World Patent Index: 33M patents</p>
    <p>Google: 87M patents</p>
    <p>Manually creating summaries for patents is unfeasible</p>
    <p>Patent summarization</p>
    <p>Legal documents (US Const.) Art. 1, Sec. 8. The Congress shall have power . . . To promote the progress of science and useful arts, by securing for limited times to authors and inventors the exclusive right to their</p>
    <p>respective writings and discoveries. Objectives: intellectual property protection, secures markets, competitor control , etc. Once a patent is granted knowledge is disclosed and transferred to society</p>
    <p>Summarizing Patents</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Long and complicated sentences</p>
    <p>CLAIMS SECTION OF PATENT cl</p>
    <p>a im</p>
    <p>s tr</p>
    <p>u ct</p>
    <p>u re</p>
    <p>problem for sentence extraction methods since some sentences would be overweighed by traditional methods</p>
    <p>Content peculiarities</p>
    <p>claim vocabulary is very vague and abstract to obfuscate the message: [device for recording a digital information signal in an information track on a magnetic record carrier] instead of tape recorder</p>
    <p>author abstract is also written in vague terms</p>
    <p>noun phrases are extremely long: [device for recording . on a magnetic record carrier]</p>
    <p>a description section elaborates the claims in more concrete terms</p>
  </div>
  <div class="page">
    <p>Patent processing and text analysis</p>
    <p>Segmentation of patents in text segments</p>
    <p>Segmentation of each sentence</p>
    <p>Mention (noun-phrases) identification based on chunking</p>
    <p>Coreference resolution (adaptation of Stanford Coref. Resolution)</p>
    <p>Lexical chain computation (coreference, part-whole, set membership, etc.)</p>
    <p>Matching/aligning claim segments with their descriptions</p>
    <p>Trainable patent summarization Scoring and selection of sub-sentential units and generation of the summary</p>
    <p>based on text generation techniques: use both claims and description for selection of information</p>
    <p>Summarizing Patents</p>
    <p>Patent summarization</p>
    <p>(Codina-Filb et al, 2015)</p>
  </div>
  <div class="page">
    <p>Mention/Lex. Chains features (aggregated and normalized in sentences)  mention frequency  coreference chain length score  meronym and hyperonym chain score  claim relevance structure</p>
    <p>Segment features  best and second best similarities of segment with claims  length  is segment in claim?  segment mentions the patent invention?</p>
    <p>Classical features  similarity to author summary  similarity to patent title  similarity to claims  tf*idf score for segment based on statistics for claims, description, abstract</p>
    <p>Patent summarization</p>
    <p>Trainable patent summarization</p>
    <p>Summarizing Patents</p>
    <p>Segments are scored based on a number of classical and patent specific features</p>
    <p>(Codina-Filb et al, 2015)</p>
  </div>
  <div class="page">
    <p>Data  26,498 sentences scored based on</p>
    <p>their similarity to an ideal abstract</p>
    <p>WEKA linear regression (LR) used to learn optimal weights</p>
    <p>SUMMA used to implement features,</p>
    <p>compute, and select segments</p>
    <p>Good predictive power of the LR model Most features correlate well with relevance</p>
    <p>Patent summarization</p>
    <p>Trainable patent summarization</p>
    <p>Summarizing Patents</p>
    <p>Scorer is implemented with linear regression where weights are adjusted with training data</p>
  </div>
  <div class="page">
    <p>Complete units and adjust grammar</p>
    <p>Remove parts of segments or drop segments</p>
    <p>Increase cohesion:</p>
    <p>Content evaluation: mention recall, precision, f-measure  system outperforms LexRank, Centroid, and LEAD</p>
    <p>Human content evaluation: similar results</p>
    <p>Patent summarization</p>
    <p>Trainable patent summarization</p>
    <p>Summarizing Patents</p>
    <p>Generate an abstract based on the content units selected</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Scientific document summarization</p>
    <p>The information provided by citations is essential to support and improve the generation of summaries of scientific documents</p>
    <p>Several kinds of information can be included in a summary of a scientific publication: the relevant contents of the paper, which parts of the papers had more impact on the research community, the feedback of the research community concerning a specific article, etc.</p>
    <p>Multi-document summarization is useful to help the creation of state-of-the-art reports</p>
    <p>General purpose metrics and techniques have to be adapted in order to assess scientific content</p>
  </div>
  <div class="page">
    <p>Amjad Abu-Jbara, Dragomir R. Radev. Coherent Citation-Based Summarization of Scientific Papers. ACL 2011: 500-509 Anastasios Tombros and Mark Sanderson. 1998. Advantages of query biased summaries in information retrieval. In Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval (SIGIR '98). Ani Nenkova, Rebecca Passonneau, and Kathleen McKeown. 2007. The Pyramid Method: Incorporating human content selection variation in summarization evaluation. ACM Trans. Speech Lang. Process. 4, 2, Article 4 (May 2007). Barzilay, R. and Elhadad, M. 1997. Using lexical chains for text summarization. Advances in Automatic Text Summarization 1999. Cong Duy Vu Hoang and Min-Yen Kan. 2010. Towards automated related work summarization. In Proceedings of the 23rd International Conference on Computational Linguistics: Posters (COLING '10). Association for Computational Linguistics, Stroudsburg, PA, USA, 427-435. Daniel C. Marcu. 1998. The Rhetorical Parsing, Summarization, and Generation of Natural Language Texts. Ph.D. Dissertation. University of Toronto, Toronto, Ont., Canada, Canada. Gerard Salton, Amit Singhal, Mandar Mitra, and Chris Buckley. 1997. Automatic text structuring and summarization. Inf. Process. Manage. 33, 2 (March 1997), 193-207. Gnes Erkan and Dragomir R. Radev. 2004. LexRank: graph-based lexical centrality as salience in text summarization. J. Artif. Int. Res. 22, 1 (December 2004), 457-479. H. P. Edmundson. 1969. New Methods in Automatic Extracting. J. ACM 16, 2 (April 1969), 264-285. H. P. Luhn. 1958. The automatic creation of literature abstracts. IBM J. Res. Dev. 2, 2 (April 1958), 159-165. Horacio Saggion and Guy Lapalme. 2002. Generating indicative-informative summaries with sumUM. Comput. Linguist. 28, 4 (December 2002), 497-526. Horacio Saggion. Creating Summarization Systems with SUMMA. LREC 2014: 4157-4163 Horacio Saggion. SUMMA. A Robust and Adaptable Summarization Tool. TAL 49(2): 103-125 (2008)</p>
    <p>Scientific document summarization</p>
    <p>Cited works (1/3)</p>
  </div>
  <div class="page">
    <p>Scientific document summarization</p>
    <p>Cited works (2/3) Joan Codina-Filb, Nadjet Bouayad-Agha, Alicia Burga, Gerard Casamayor, Simon Mille, Andreas Mller, Horacio Saggion, Leo Wanner, Using genre-specific features for patent summaries, Information Processing &amp; Management, Volume 53, Issue 1, January 2017, Pages 151-174, ISSN 0306-4573 Jones, P.A. and Paice, C.D. A Select and Generate Approach to Automatic Abstracting. 14th Information Retrieval Colloquium. 1993. Julian Kupiec, Jan Pedersen, and Francine Chen. 1995. A trainable document summarizer. In Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval (SIGIR '95). Karen Sprck Jones. 2007. Automatic summarising: The state of the art. Inf. Process. Manage. 43, 6 (November 2007), 1449-1481. Lin, CY. and Hovy, E.. Identifying Topics by Position. ACL 1997. Lin, CY. ROUGE: A Package for Automatic Evaluation of summaries. ACL Summarization Workshop 2004 Mead et al. MEAD - a platform for multidocument multilingual text summarization. In LREC 2004. Nenkova, A. Vanderwende, L. The impact of frequency on summarization. Microsoft Research, Redmond, Washington, Tech. Rep. MSR-TR-2005-101. Oakes, M. and Paice, C.D. Term extraction for automatic abstracting. Page, Lawrence and Brin, Sergey and Motwani, Rajeev and Winograd, Terry (1999) The PageRank Citation Ranking: Bringing Order to the Web. Technical Report. Stanford InfoLab. Paice, C.D. Constructing Literarure Abstracts by Computers: Techniques and Prospects. IP&amp;M 1990. Qiaozhu Mei, ChengXiang Zhai. Generating impact-based summaries for scientific literature. ACL-08: HLT - 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference. Rada Mihalcea, Paul Tarau. 2004. TextRank: Bringing Order into Texts. Proceedings of EMNLP 2004, pages 404411, Barcelona, Spain. Association for Computational Linguistics.</p>
  </div>
  <div class="page">
    <p>Scientific document summarization</p>
    <p>Cited works (3/3) Rahul Jha, Reed Coke, and Dragomir Radev. 2015. Surveyor: a system for generating coherent survey articles for scientific topics. In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI'15). AAAI Press 2167-2173. Seiji Miike, Etsuo Itoh, Kenji Ono, and Kazuo Sumita. 1994. A full-text retrieval system with a dynamic abstract generation function. In Proceedings of the 17th annual international ACM SIGIR conference on Research and development in information retrieval (SIGIR '94) Vahed Qazvinian and Dragomir R. Radev. 2008. Scientific paper summarization using citation summary networks. In Proceedings of the 22nd International Conference on Computational Linguistics - Volume 1 (COLING '08), Vol. 1. Association for Computational Linguistics, Stroudsburg, PA, USA, 689-696. Vahed Qazvinian and Dragomir R. Radev. 2010. Identifying non-explicit citing sentences for citation-based summarization. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL '10). Association for Computational Linguistics, Stroudsburg, PA, USA, 555-564.</p>
  </div>
  <div class="page">
    <p>CHALLENGES, DATASETS AND ARCHITECTURES</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Scientific Literature Mining Challenges</p>
    <p>Datasets and tools</p>
    <p>Structured / semantic publication formats</p>
    <p>Scholary literature architectures</p>
  </div>
  <div class="page">
    <p>Scientific Literature Mining Challenges</p>
    <p>Several challenges have been organized to explore how we can take advantage of scientific literature</p>
    <p>to automatically carry out specific text analysis tasks</p>
    <p>SemEval-2010 Task 5 : Automatic Keyphrase Extraction from Scientific Articles</p>
    <p>SemEval-2017 Task 10: ScientceIE - Extracting Keyphrases and Relations from Scientific Publications</p>
    <p>Challenges, datasets and architectures</p>
  </div>
  <div class="page">
    <p>Scientific Literature Mining Challenges</p>
    <p>Issue: author-name ambiguity (authors that publish with several name variations, different authors sharing the same name)</p>
    <p>Dataset (from Microsoft Academic Graph):  250k (authors + affiliation)  2,5M (papers + conference / journal info)  Author/paper pairs (to evaluate if correct or not) ground truth on manual corrections of Microsoft</p>
    <p>Academic Graph</p>
    <p>Two Tracks: 1. Author-Paper identification: for each author papers that she has written 2. Author disambiguation challenge: group duplicated author names referring to the same author</p>
    <p>Roy, S. B., De Cock, M., Mandava, V., Savanna, S., Dalessandro, B., Perlich, C., ... &amp; Hamner, B. (2013, August). The microsoft academic search dataset and kdd cup 2013. In Proceedings of the 2013 KDD cup 2013 workshop (p. 1). ACM.</p>
    <p>Track 1: extensive feature engineering on the MAG and binary classifier of paper-author pairs Track 2: multi step approach for string name processing and matching</p>
    <p>None of these approaches directly scales sufficiently well for use on the entire Microsoft Academic Search author and publication data</p>
    <p>Challenges, datasets and architectures</p>
  </div>
  <div class="page">
    <p>Scientific Literature Mining Challenges</p>
    <p>Issue: given a research field, rank the relevance of institutions</p>
    <p>Dataset: any dataset publicly available online together with the Microsoft Academic Graph can be used</p>
    <p>Track: Rank a set of institutions with respect to the number of full research papers they get accepted in 2016 conferences: SIGIR, SIGMOD, SIGCOMM, KDD, ICML, FSE, MobiCom, MM</p>
    <p>Roy, S. B., De Cock, M., Mandava, V., Savanna, S., Dalessandro, B., Perlich, C., ... &amp; Hamner, B. (2013, August). The microsoft academic search dataset and kdd cup 2013. In Proceedings of the 2013 KDD cup 2013 workshop (p. 1). ACM.</p>
    <p>Great predictive power of the participation of the institution in the past editions of the conference</p>
    <p>Challenges, datasets and architectures</p>
  </div>
  <div class="page">
    <p>Scientific Literature Mining Challenges</p>
    <p>Issue: assess the query-independent importance of scholarly articles</p>
    <p>Dataset: any dataset publicly available online together with the Microsoft Academic Graph can be used</p>
    <p>Track: Generate static ranking of papers with respect to their relevance</p>
    <p>Wade, A. D., Wang, K., Sun, Y., Gulli, A. 2016. WSDM Cup 2016  Entity Ranking Challenge. Proceedings of the 9th ACM Conference on Web Search and Data Mining, San Francisco, CA.</p>
    <p>Iterative solution that refine citation-graph paper ranking measures by means of the information concerning paper authors and venue of publication</p>
    <p>Challenges, datasets and architectures</p>
  </div>
  <div class="page">
    <p>Scientific Literature Mining Challenges</p>
    <p>Issue: automatically generate semantic publishing RDF datasets from both conference proceedings and papers</p>
    <p>Dataset: CEUR-WS Web proceedings (task 1), CEUR-WS papers in PDF format (task 2), RDF semantic publishing datasets (task 3)</p>
    <p>Tasks (2016): 1. Extract information from CEUR-WS online proceeding (HTML) (what workshop series</p>
    <p>a workshop is part of, affiliations of editors, exact date of workshop and of proceedings publication, distinction between invited and contributed papers)</p>
    <p>Dimou, A., Di Iorio, A., Lange, C., &amp; Vahdati, S. (2016, May). Semantic Publishing ChallengeAssessing the Quality of Scientific Output in Its Ecosystem. In Semantic Web Evaluation Challenge (pp. 243-254). Springer International Publishing.</p>
    <p>Challenges, datasets and architectures</p>
  </div>
  <div class="page">
    <p>Scientific Literature Mining Challenges</p>
    <p>Ronzano, F., Fisas, B., del Bosque, G. C., &amp; Saggion, H. (2015, May). On the automated generation of scholarly publishing linked datasets: the case of CEUR-WS proceedings. In Semantic Web Evaluation Challenge (pp. 177-188). Springer International Publishing.</p>
    <p>Semantic annotator</p>
    <p>Linguisti &amp; structural analyzer</p>
    <p>Annotation sanitizer</p>
    <p>External resources</p>
    <p>linker</p>
    <p>RDF generator</p>
    <p>Linguistic &amp; structural analyzer</p>
    <p>PDF-to-Text converter</p>
    <p>Biblio parser</p>
    <p>Spot ontology / founding body</p>
    <p>mentions</p>
    <p>RDF generator</p>
    <p>Ta sk</p>
    <p>Ta sk</p>
    <p>RDF data model SPARQL evaluation query</p>
    <p>Number and avg. page number of papers in each proceeding</p>
    <p>Challenges, datasets and architectures</p>
  </div>
  <div class="page">
    <p>Scientific Literature Mining Challenges</p>
    <p>Abstract Endogenous small RNAs (miRNAs) regulate gene expression by mechanisms conserved across metazoans. While the number of verified human miRNAs is still expanding, only few have been functionally annotated. To perform genetic screens</p>
    <p>Introduction Since their discovery, the functions of only a handful of microRNAs (miRNAs) have been determined (recently reviewed in Zamore and Haley, 2005). Relevant to carcinogenesis, it was found that let-7 inhibits RAS expression and in lung tumors negatively correlates with RAS levels (Johnson et al., 2005). Furthermore, the</p>
    <p>Results mouse, and zebrafish (Figure 5D). To further substantiate LATS2 as a direct target of miR372&amp;3, we cloned its 3UTR downstream of the firefly luciferase gene (pGL3-LATS2). We transfected either pGL3-LATS2 or the controls pGL3-372 and pGL3-373 (containing a miRcomplementary sequence in their 3UTR) or pGL3 into Tera1 and MCF-7 cells (respectively positive and negative for miR-371-3) ( Figures 4D and S6). As predicted, the 372/373 complementary sequences mediated</p>
    <p>References</p>
    <p>Reference Paper TITLE: A Genetic Screen Implicates miRNA-372 and miRNA-373</p>
    <p>AUTH.: Voorhoeve, M., le Sage, C., Schrier, M., et al.  YEAR: 2006</p>
    <p>C O</p>
    <p>LL E</p>
    <p>C T</p>
    <p>IO N</p>
    <p>A B</p>
    <p>S T</p>
    <p>R A</p>
    <p>C T</p>
    <p>B</p>
    <p>O D</p>
    <p>Y</p>
    <p>LATS2 expression. To directly measure the effect of endogenous Dnd1 on the activity of endogenous miR-372 family, we used sensor molecules containing the luciferase gene under the control of either wild-type LATS2-3UTR or a mutant in the 372 target sites (le Sage et al., 2007 and Voorhoeve et al., 2006). Figure 1H</p>
    <p>Citing Paper 1</p>
    <p>identified. However, the contributions of miR10b, miR-21, and miR-373/520c are not easily discerned (Voorhoeve et al., 2006; Ma et al., 2007; Si et al., 2007). Similarly, the miRNAs</p>
    <p>Citing Paper 10</p>
    <p>In the article. Voorhoeve et al., performed genetic screens of miRNA to investigate its novel functions; which has implicated two of them as oncogenes. They demonstrated that miRNA-372&amp;3 participate in proliferation and tumorigenesis of primary human cells along with oncogenic RAS and active wild-type p53 by numbing the p53 pathway. The authors created</p>
    <p>HUMAN SUMMARY</p>
    <p>CITATION CONTEXT</p>
    <p>CITATION CONTEXT</p>
    <p>CITING SPAN</p>
    <p>CITING SPAN</p>
    <p>Abstract Endogenous small RNAs (miRNAs) regulate gene expression by mechanisms conserved across metazoans. While the number of verified human miRNAs is still expanding, only few have been functionally annotated. To perform genetic screens</p>
    <p>Introduction Since their discovery, the functions of only a handful of microRNAs (miRNAs) have been determined (recently reviewed in Zamore and Haley, 2005). Relevant to carcinogenesis, it was found that let-7 inhibits RAS expression and in lung tumors negatively correlates with RAS levels (Johnson et al., 2005). Furthermore, the</p>
    <p>Results mouse, and zebrafish (Figure 5D). To further substantiate LATS2 as a direct target of miR372&amp;3, we cloned its 3UTR downstream of the firefly luciferase gene (pGL3-LATS2). We transfected either pGL3-LATS2 or the controls pGL3-372 and pGL3-373 (containing a miRcomplementary sequence in their 3UTR) or pGL3 into Tera1 and MCF-7 cells (respectively positive and negative for miR-371-3) ( Figures 4D and S6). As predicted, the 372/373 complementary sequences mediated</p>
    <p>References</p>
    <p>Reference Paper TITLE: A Genetic Screen Implicates miRNA-372 and miRNA-373</p>
    <p>AUTH.: Voorhoeve, M., le Sage, C., Schrier, M., et al.  YEAR: 2006</p>
    <p>C O</p>
    <p>LL E</p>
    <p>C T</p>
    <p>IO N</p>
    <p>A B</p>
    <p>S T</p>
    <p>R A</p>
    <p>C T</p>
    <p>B</p>
    <p>O D</p>
    <p>Y</p>
    <p>LATS2 expression. To directly measure the effect of endogenous Dnd1 on the activity of endogenous miR-372 family, we used sensor molecules containing the luciferase gene under the control of either wild-type LATS2-3UTR or a mutant in the 372 target sites (le Sage et al., 2007 and Voorhoeve et al., 2006). Figure 1H</p>
    <p>Citing Paper 1</p>
    <p>identified. However, the contributions of miR10b, miR-21, and miR-373/520c are not easily discerned (Voorhoeve et al., 2006; Ma et al., 2007; Si et al., 2007). Similarly, the miRNAs</p>
    <p>Citing Paper 10</p>
    <p>In the article. Voorhoeve et al., performed genetic screens of miRNA to investigate its novel functions; which has implicated two of them as oncogenes. They demonstrated that miRNA-372&amp;3 participate in proliferation and tumorigenesis of primary human cells along with oncogenic RAS and active wild-type p53 by numbing the p53 pathway. The authors created</p>
    <p>HUMAN SUMMARY</p>
    <p>CITATION CONTEXT</p>
    <p>CITATION CONTEXT</p>
    <p>CITING SPAN</p>
    <p>CITING SPAN</p>
    <p>Abstract Endogenous small RNAs (miRNAs) regulate gene expression by mechanisms conserved across metazoans. While the number of verified human miRNAs is still expanding, only few have been functionally annotated. To perform genetic screens</p>
    <p>Introduction Since their discovery, the functions of only a handful of microRNAs (miRNAs) have been determined (recently reviewed in Zamore and Haley, 2005). Relevant to carcinogenesis, it was found that let-7 inhibits RAS expression and in lung tumors negatively correlates with RAS levels (Johnson et al., 2005). Furthermore, the</p>
    <p>Results mouse, and zebrafish (Figure 5D). To further substantiate LATS2 as a direct target of miR372&amp;3, we cloned its 3UTR downstream of the firefly luciferase gene (pGL3-LATS2). We transfected either pGL3-LATS2 or the controls pGL3-372 and pGL3-373 (containing a miRcomplementary sequence in their 3UTR) or pGL3 into Tera1 and MCF-7 cells (respectively positive and negative for miR-371-3) ( Figures 4D and S6). As predicted, the 372/373 complementary sequences mediated</p>
    <p>References</p>
    <p>Reference Paper TITLE: A Genetic Screen Implicates miRNA-372 and miRNA-373</p>
    <p>AUTH.: Voorhoeve, M., le Sage, C., Schrier, M., et al.  YEAR: 2006</p>
    <p>C O</p>
    <p>LL E</p>
    <p>C T</p>
    <p>IO N</p>
    <p>A B</p>
    <p>S T</p>
    <p>R A</p>
    <p>C T</p>
    <p>B</p>
    <p>O D</p>
    <p>Y</p>
    <p>LATS2 expression. To directly measure the effect of endogenous Dnd1 on the activity of endogenous miR-372 family, we used sensor molecules containing the luciferase gene under the control of either wild-type LATS2-3UTR or a mutant in the 372 target sites (le Sage et al., 2007 and Voorhoeve et al., 2006). Figure 1H</p>
    <p>Citing Paper 1</p>
    <p>identified. However, the contributions of miR10b, miR-21, and miR-373/520c are not easily discerned (Voorhoeve et al., 2006; Ma et al., 2007; Si et al., 2007). Similarly, the miRNAs</p>
    <p>Citing Paper 10</p>
    <p>In the article. Voorhoeve et al., performed genetic screens of miRNA to investigate its novel functions; which has implicated two of them as oncogenes. They demonstrated that miRNA-372&amp;3 participate in proliferation and tumorigenesis of primary human cells along with oncogenic RAS and active wild-type p53 by numbing the p53 pathway. The authors created</p>
    <p>HUMAN SUMMARY</p>
    <p>CITATION CONTEXT</p>
    <p>CITATION CONTEXT</p>
    <p>CITED SPAN</p>
    <p>CITIED SPAN</p>
    <p>Task 1: For each citation context, identify the spans of text (cited text spans) in the RP that most accurately reflect the citation context Task 2: identify the facet of each cited text span among: Hypothesis, Method, Results, Implication, Discussion Task 3: generate a max 250 words summary considering the community discussion of the reference paper represented by the citation contexts Dataset: 20 training collections + 30 evaluation collections http://wing.comp.nus.edu.sg/cl-scisumm2016/</p>
  </div>
  <div class="page">
    <p>Scientific Literature Mining Challenges SemEval-2010 Task 5 : Automatic Keyphrase Extraction from Scientific Articles Kim, S. N., Medelyan, O., Kan, M. Y., &amp; Baldwin, T. Semeval-2010 task 5: Automatic keyphrase extraction from scientific articles. In Proceedings of the 5th International Workshop on Semantic Evaluation (pp. 21-26). Association for Computational Linguistics.</p>
    <p>100 articles for training and 144 for testing (from ACM Digital Library)  converted by pdftotext  keyphrases present in the text of the papers identified by authors and students</p>
    <p>SemEval-2017 Task 10: ScientceIE - Extracting Keyphrases and Relations from Scientific Publications</p>
    <p>http://alt.qcri.org/semeval2017/task10/ &amp; https://scienceie.github.io/</p>
    <p>Corpus: Science Direct, 500 journal articles evenly distributed among the domains Computer Science, Material Sciences and Physics  training: 350 documents, development: 50 documents, test: 100 documents</p>
    <p>task 1: Identification of keyphrases  task 2: Classification of identified keyphrases (PROCESS, TASK and MATERIAL)  task 3: identification of relations among keyphrases: HYPONYM-OF, SYNONYM-OF, NONE</p>
    <p>Challenges, datasets and architectures</p>
  </div>
  <div class="page">
    <p>Datasets and tools</p>
    <p>The ACL anthology network corpus Radev, D. R., Muthukrishnan, P., Qazvinian, V., &amp; Abu-Jbara, A. (2013). The ACL anthology network corpus. Language Resources and Evaluation, 47(4), 919-944.</p>
    <p>last release: December 2013  PDFbox to convert PDF papers  semi-automated manual editing</p>
    <p>ACL Anthology SearchBench Schfer, U., Kiefer, B., Spurk, C., Steffen, J., &amp; Wang, R. (2011, June). The ACL anthology searchbench. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Systems Demonstrations (pp. 7-13). Association for Computational Linguistics.</p>
    <p>last update: November 2013, 28,000 papers  commercial OCR to parse PDF  integrates CiBRO to visualize citation network</p>
    <p>Challenges, datasets and architectures</p>
  </div>
  <div class="page">
    <p>Datasets and tools</p>
    <p>open access content aggregator  37,634,579 papers with bibliographic record + PDF  6000 journals, collected from over 2300 Open Access repositories around the world (OAI-PMH)  Web API  metadata: authors, abstract, topics, year, provided by OAI</p>
    <p>https://core.ac.uk/</p>
    <p>more than 130,000,000 researcher profiles and 100,000,000 papers from multiple publication databases  Services: Researcher profile extraction (connection with social networks like LinkedIn and VideoLectures), expert finding, social network search, , topic browser , conference analysis Web API</p>
    <p>https://aminer.org/</p>
    <p>Challenges, datasets and architectures</p>
  </div>
  <div class="page">
    <p>Datasets and tools</p>
    <p>Computer science and Neuroscience papers from: ArXiv, DBLP, CiteSeer, OdySci Academic, Aminer  cits. count estimated (statistical model)  keyphrases  citation velocity and acceleration  influential authors</p>
    <p>open access digital library search engine (all docs with full text)  extract and index both metadata and full text  provides access to metadata by means of OAI  index also tables and figures  20,000 to 40,000 new crawled PDF per day  10 PDF downloaded per second</p>
    <p>https://www.semanticscholar.org/</p>
    <p>http://citeseerx.ist.psu.edu/</p>
    <p>Challenges, datasets and architectures</p>
  </div>
  <div class="page">
    <p>Structured / semantic publication formats</p>
    <p>Even if 80% of scientific literature is accessed as PDF documents, structured textual formats to model the contents of scientific publications</p>
    <p>are increasingly spreading</p>
    <p>JATS XML: an de facto standard for archiving and interchange of scientific open-access journals and its contents with XML  Major publishers have their own XML schemas: Elsevier, Springer</p>
    <p>Semantic Web and Scholarly data</p>
    <p>Set of ontologies that support the creation of comprehensive machinereadable RDF metadata for every aspect of semantic publishing and referencing</p>
    <p>SPAR Ontologies</p>
    <p>FRBR-aligned Bibliographic Ontology (FaBiO)  Citation Typing Ontology (CiTO)  Bibliographic Reference Ontology (BiRO)  Citation Counting and Context Characterisation  Ontology (C4O)</p>
    <p>Document Components Ontology (DoCO)  Publishing Status Ontology (PSO)  Publishing Roles Ontology (PRO)  Publishing Workflow Ontology (PWO)  Discourse Elements Ontology (DEO)</p>
    <p>Challenges, datasets and architectures</p>
  </div>
  <div class="page">
    <p>Scholarly literature architectures</p>
    <p>Mendeley Suggest Provide users with articles that help them to keep up-to-date with research in their field</p>
    <p>and explore relevant research that is, as of yet, unknown to them</p>
    <p>Event service: Track user interactions Article service: crowdsurced collection of Mendeley artlcles Profile service: user profile information (academic discipline, etc.)</p>
    <p>Filter out data nod needed by the recommender model</p>
    <p>Multi-model recommendation: collaborative filtering (Mahout), popularitybased model, trending-based model, content-based model</p>
    <p>Consolidate the consistency of the list of recommendation</p>
    <p>Online models to adapt dynamically recommendations to user interactions</p>
    <p>Challenges, datasets and architectures</p>
  </div>
  <div class="page">
    <p>Scholarly literature architectures</p>
    <p>CiteSeer 1. Academic and non-academic classification: SVM  features: document length,</p>
    <p>inclusion of bibliography, etc. 2. Paper de-duplication:</p>
    <p>Exact PDF match: SHA1 digest  Near-duplicate match: based on document signature strings</p>
    <p>Crawler:</p>
    <p>Name disambiguation:</p>
    <p>Challenges, datasets and architectures</p>
  </div>
  <div class="page">
    <p>DR. INVENTOR SCIENTIFIC TEXT MINING FRAMEWORK</p>
    <p>http://drinventor.eu/ FP7 ICT 2013.8.1, Grant no.: 611383</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Dealing with scientific articles in Dr. Inventor</p>
    <p>Dr. Inventor Text Mining Framework</p>
    <p>Architectural overview</p>
    <p>Hands-on Dr. Inventor Framework</p>
  </div>
  <div class="page">
    <p>Dealing with scientific articles in Dr. Inventor</p>
    <p>hetherogeneous input formats (PDF, XML schemas, etc.)</p>
    <p>lack of explicit structural and semantic information</p>
    <p>need to enrich contents by leveraging on external data sources</p>
    <p>lack of convenient facilities to easily access and process contents</p>
    <p>The (bootstrap of) textual analyses of scientific publications</p>
    <p>often still constitutes a time-consuming activity due to:</p>
  </div>
  <div class="page">
    <p>a scientific information mining infrastructure useful to:  analyze publications and track research topics  assess the novelty of ideas  stimulate researchers creativity by suggesting analogies between scientific outcomes</p>
    <p>http://drinventor.eu/ FP7 ICT 2013.8.1, Grant no.: 611383</p>
    <p>Scientific publications</p>
    <p>Text mining Semantic analysis</p>
    <p>Graph mining</p>
    <p>Visual analytics</p>
    <p>Big data</p>
    <p>Dealing with scientific articles in Dr. Inventor</p>
  </div>
  <div class="page">
    <p>Dr. Inventor Text Mining Framework</p>
    <p>http://driframework.readthedocs.io/</p>
    <p>Integrate and customize text mining tools and on-line services to enable and ease a wide range of scientific publication analyses</p>
    <p>Papers are enriched with structural, linguistic and semantic information</p>
    <p>Self-contained library managed by</p>
    <p>Focused on textual content</p>
    <p>Relying on a shared data model (java classes) to represent a paper</p>
    <p>Exposing a convenient API to access the mined information</p>
    <p>Based on to manage textual annotations</p>
  </div>
  <div class="page">
    <p>Architectural overview Dr. Inventor Text Mining Framework</p>
    <p>P D</p>
    <p>F t</p>
    <p>o t</p>
    <p>e x</p>
    <p>t co</p>
    <p>n v</p>
    <p>e rt</p>
    <p>e r</p>
    <p>S e</p>
    <p>n te</p>
    <p>n ce</p>
    <p>s p</p>
    <p>li tt</p>
    <p>e r</p>
    <p>In li</p>
    <p>n e</p>
    <p>c it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>W e</p>
    <p>b b</p>
    <p>a se</p>
    <p>d r</p>
    <p>e fe</p>
    <p>re n</p>
    <p>ce p</p>
    <p>a rs</p>
    <p>e r</p>
    <p>C it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>-a w</p>
    <p>a re</p>
    <p>d e</p>
    <p>p .</p>
    <p>p a</p>
    <p>rs e</p>
    <p>r</p>
    <p>R h</p>
    <p>e to</p>
    <p>ri ca</p>
    <p>l a n</p>
    <p>n o</p>
    <p>ta to</p>
    <p>r</p>
    <p>C o</p>
    <p>re fe</p>
    <p>re n</p>
    <p>ce r</p>
    <p>e s.</p>
    <p>, ca</p>
    <p>u sa</p>
    <p>li ty</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>&amp; g</p>
    <p>ra p</p>
    <p>h b</p>
    <p>u il</p>
    <p>d e</p>
    <p>r</p>
    <p>B a</p>
    <p>b e</p>
    <p>lf y</p>
    <p>W S</p>
    <p>D a</p>
    <p>n d</p>
    <p>E n</p>
    <p>ti ty</p>
    <p>L in</p>
    <p>k e</p>
    <p>r</p>
    <p>E x</p>
    <p>tr a</p>
    <p>ct iv</p>
    <p>e s</p>
    <p>u m</p>
    <p>m a</p>
    <p>ri ze</p>
    <p>r</p>
    <p>Ronzano, F., &amp; Saggion, H. (2015, October). Dr. Inventor Framework: Extracting Structured Information from Scientific Publications. In International Conference on Discovery Science (pp. 209-220). Springer International Publishing.</p>
    <p>Ronzano, F., &amp; Saggion, H. (2016, April). Knowledge Extraction and Modeling from Scientific Publications. In The Semantics, Analytics, Visualization: Enhancing Scholarly Data Workshop, co-located with the 25th International World Wide Web Conference.</p>
  </div>
  <div class="page">
    <p>Architectural overview Dr. Inventor Text Mining Framework</p>
    <p>P D</p>
    <p>F t</p>
    <p>o t</p>
    <p>e x</p>
    <p>t co</p>
    <p>n v</p>
    <p>e rt</p>
    <p>e r</p>
    <p>S e</p>
    <p>n te</p>
    <p>n ce</p>
    <p>s p</p>
    <p>li tt</p>
    <p>e r</p>
    <p>In li</p>
    <p>n e</p>
    <p>c it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>W e</p>
    <p>b b</p>
    <p>a se</p>
    <p>d r</p>
    <p>e fe</p>
    <p>re n</p>
    <p>ce p</p>
    <p>a rs</p>
    <p>e r</p>
    <p>C it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>-a w</p>
    <p>a re</p>
    <p>d e</p>
    <p>p .</p>
    <p>p a</p>
    <p>rs e</p>
    <p>r</p>
    <p>R h</p>
    <p>e to</p>
    <p>ri ca</p>
    <p>l a n</p>
    <p>n o</p>
    <p>ta to</p>
    <p>r</p>
    <p>C o</p>
    <p>re fe</p>
    <p>re n</p>
    <p>ce r</p>
    <p>e s.</p>
    <p>, ca</p>
    <p>u sa</p>
    <p>li ty</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>&amp; g</p>
    <p>ra p</p>
    <p>h b</p>
    <p>u il</p>
    <p>d e</p>
    <p>r</p>
    <p>B a</p>
    <p>b e</p>
    <p>lf y</p>
    <p>W S</p>
    <p>D a</p>
    <p>n d</p>
    <p>E n</p>
    <p>ti ty</p>
    <p>L in</p>
    <p>k e</p>
    <p>r</p>
    <p>E x</p>
    <p>tr a</p>
    <p>ct iv</p>
    <p>e s</p>
    <p>u m</p>
    <p>m a</p>
    <p>ri ze</p>
    <p>r</p>
    <p>Dr. Inventor paper data model</p>
    <p>TITLE</p>
    <p>(SUB)SECTION</p>
    <p>ABSTRACT</p>
    <p>BIBLIOGRAPH IC ENTRY</p>
    <p>CAPTION</p>
    <p>Supported by:</p>
  </div>
  <div class="page">
    <p>Architectural overview Dr. Inventor Text Mining Framework</p>
    <p>P D</p>
    <p>F t</p>
    <p>o t</p>
    <p>e x</p>
    <p>t co</p>
    <p>n v</p>
    <p>e rt</p>
    <p>e r</p>
    <p>S e</p>
    <p>n te</p>
    <p>n ce</p>
    <p>s p</p>
    <p>li tt</p>
    <p>e r</p>
    <p>In li</p>
    <p>n e</p>
    <p>c it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>W e</p>
    <p>b b</p>
    <p>a se</p>
    <p>d r</p>
    <p>e fe</p>
    <p>re n</p>
    <p>ce p</p>
    <p>a rs</p>
    <p>e r</p>
    <p>C it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>-a w</p>
    <p>a re</p>
    <p>d e</p>
    <p>p .</p>
    <p>p a</p>
    <p>rs e</p>
    <p>r</p>
    <p>R h</p>
    <p>e to</p>
    <p>ri ca</p>
    <p>l a n</p>
    <p>n o</p>
    <p>ta to</p>
    <p>r</p>
    <p>C o</p>
    <p>re fe</p>
    <p>re n</p>
    <p>ce r</p>
    <p>e s.</p>
    <p>, ca</p>
    <p>u sa</p>
    <p>li ty</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>&amp; g</p>
    <p>ra p</p>
    <p>h b</p>
    <p>u il</p>
    <p>d e</p>
    <p>r</p>
    <p>B a</p>
    <p>b e</p>
    <p>lf y</p>
    <p>W S</p>
    <p>D a</p>
    <p>n d</p>
    <p>E n</p>
    <p>ti ty</p>
    <p>L in</p>
    <p>k e</p>
    <p>r</p>
    <p>E x</p>
    <p>tr a</p>
    <p>ct iv</p>
    <p>e s</p>
    <p>u m</p>
    <p>m a</p>
    <p>ri ze</p>
    <p>r</p>
    <p>citation spans</p>
    <p>Bibliography</p>
  </div>
  <div class="page">
    <p>Architectural overview Dr. Inventor Text Mining Framework</p>
    <p>P D</p>
    <p>F t</p>
    <p>o t</p>
    <p>e x</p>
    <p>t co</p>
    <p>n v</p>
    <p>e rt</p>
    <p>e r</p>
    <p>S e</p>
    <p>n te</p>
    <p>n ce</p>
    <p>s p</p>
    <p>li tt</p>
    <p>e r</p>
    <p>In li</p>
    <p>n e</p>
    <p>c it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>W e</p>
    <p>b b</p>
    <p>a se</p>
    <p>d r</p>
    <p>e fe</p>
    <p>re n</p>
    <p>ce p</p>
    <p>a rs</p>
    <p>e r</p>
    <p>C it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>-a w</p>
    <p>a re</p>
    <p>d e</p>
    <p>p .</p>
    <p>p a</p>
    <p>rs e</p>
    <p>r</p>
    <p>R h</p>
    <p>e to</p>
    <p>ri ca</p>
    <p>l a n</p>
    <p>n o</p>
    <p>ta to</p>
    <p>r</p>
    <p>C o</p>
    <p>re fe</p>
    <p>re n</p>
    <p>ce r</p>
    <p>e s.</p>
    <p>, ca</p>
    <p>u sa</p>
    <p>li ty</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>&amp; g</p>
    <p>ra p</p>
    <p>h b</p>
    <p>u il</p>
    <p>d e</p>
    <p>r</p>
    <p>B a</p>
    <p>b e</p>
    <p>lf y</p>
    <p>W S</p>
    <p>D a</p>
    <p>n d</p>
    <p>E n</p>
    <p>ti ty</p>
    <p>L in</p>
    <p>k e</p>
    <p>r</p>
    <p>E x</p>
    <p>tr a</p>
    <p>ct iv</p>
    <p>e s</p>
    <p>u m</p>
    <p>m a</p>
    <p>ri ze</p>
    <p>r</p>
    <p>Some alternative phrase alignment approaches have been developed, which do not rely on the Viterbi word alignment. Both (Marcu, 2002) and (Zhang, 2003) consider a sentence pair as different realizations of a sequence of concepts. These alignment approaches segment the sentences into a sequence of phrases.</p>
    <p>Customization of ANNIE sentence splitter</p>
    <p>Rule set adapted to peculiarities of scientific papers by analyzing the most frequent sentence split patterns / errors in a set of 40 Computer Graphics papers</p>
  </div>
  <div class="page">
    <p>Architectural overview Dr. Inventor Text Mining Framework</p>
    <p>P D</p>
    <p>F t</p>
    <p>o t</p>
    <p>e x</p>
    <p>t co</p>
    <p>n v</p>
    <p>e rt</p>
    <p>e r</p>
    <p>S e</p>
    <p>n te</p>
    <p>n ce</p>
    <p>s p</p>
    <p>li tt</p>
    <p>e r</p>
    <p>In li</p>
    <p>n e</p>
    <p>c it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>W e</p>
    <p>b b</p>
    <p>a se</p>
    <p>d r</p>
    <p>e fe</p>
    <p>re n</p>
    <p>ce p</p>
    <p>a rs</p>
    <p>e r</p>
    <p>C it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>-a w</p>
    <p>a re</p>
    <p>d e</p>
    <p>p .</p>
    <p>p a</p>
    <p>rs e</p>
    <p>r</p>
    <p>R h</p>
    <p>e to</p>
    <p>ri ca</p>
    <p>l a n</p>
    <p>n o</p>
    <p>ta to</p>
    <p>r</p>
    <p>C o</p>
    <p>re fe</p>
    <p>re n</p>
    <p>ce r</p>
    <p>e s.</p>
    <p>, ca</p>
    <p>u sa</p>
    <p>li ty</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>&amp; g</p>
    <p>ra p</p>
    <p>h b</p>
    <p>u il</p>
    <p>d e</p>
    <p>r</p>
    <p>B a</p>
    <p>b e</p>
    <p>lf y</p>
    <p>W S</p>
    <p>D a</p>
    <p>n d</p>
    <p>E n</p>
    <p>ti ty</p>
    <p>L in</p>
    <p>k e</p>
    <p>r</p>
    <p>E x</p>
    <p>tr a</p>
    <p>ct iv</p>
    <p>e s</p>
    <p>u m</p>
    <p>m a</p>
    <p>ri ze</p>
    <p>r</p>
    <p>Bibliography AUTHORS</p>
    <p>TITLE</p>
    <p>CONFERENCE</p>
    <p>YEAR</p>
  </div>
  <div class="page">
    <p>Architectural overview Dr. Inventor Text Mining Framework</p>
    <p>P D</p>
    <p>F t</p>
    <p>o t</p>
    <p>e x</p>
    <p>t co</p>
    <p>n v</p>
    <p>e rt</p>
    <p>e r</p>
    <p>S e</p>
    <p>n te</p>
    <p>n ce</p>
    <p>s p</p>
    <p>li tt</p>
    <p>e r</p>
    <p>In li</p>
    <p>n e</p>
    <p>c it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>W e</p>
    <p>b b</p>
    <p>a se</p>
    <p>d r</p>
    <p>e fe</p>
    <p>re n</p>
    <p>ce p</p>
    <p>a rs</p>
    <p>e r</p>
    <p>C it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>-a w</p>
    <p>a re</p>
    <p>d e</p>
    <p>p .</p>
    <p>p a</p>
    <p>rs e</p>
    <p>r</p>
    <p>R h</p>
    <p>e to</p>
    <p>ri ca</p>
    <p>l a n</p>
    <p>n o</p>
    <p>ta to</p>
    <p>r</p>
    <p>C o</p>
    <p>re fe</p>
    <p>re n</p>
    <p>ce r</p>
    <p>e s.</p>
    <p>, ca</p>
    <p>u sa</p>
    <p>li ty</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>&amp; g</p>
    <p>ra p</p>
    <p>h b</p>
    <p>u il</p>
    <p>d e</p>
    <p>r</p>
    <p>B a</p>
    <p>b e</p>
    <p>lf y</p>
    <p>W S</p>
    <p>D a</p>
    <p>n d</p>
    <p>E n</p>
    <p>ti ty</p>
    <p>L in</p>
    <p>k e</p>
    <p>r</p>
    <p>E x</p>
    <p>tr a</p>
    <p>ct iv</p>
    <p>e s</p>
    <p>u m</p>
    <p>m a</p>
    <p>ri ze</p>
    <p>r</p>
    <p>Based on MATE dependency parser Inline citation spans should be considered as a word-token by the parser if they have a syntactic role:</p>
  </div>
  <div class="page">
    <p>Architectural overview Dr. Inventor Text Mining Framework</p>
    <p>P D</p>
    <p>F t</p>
    <p>o t</p>
    <p>e x</p>
    <p>t co</p>
    <p>n v</p>
    <p>e rt</p>
    <p>e r</p>
    <p>S e</p>
    <p>n te</p>
    <p>n ce</p>
    <p>s p</p>
    <p>li tt</p>
    <p>e r</p>
    <p>In li</p>
    <p>n e</p>
    <p>c it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>W e</p>
    <p>b b</p>
    <p>a se</p>
    <p>d r</p>
    <p>e fe</p>
    <p>re n</p>
    <p>ce p</p>
    <p>a rs</p>
    <p>e r</p>
    <p>C it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>-a w</p>
    <p>a re</p>
    <p>d e</p>
    <p>p .</p>
    <p>p a</p>
    <p>rs e</p>
    <p>r</p>
    <p>R h</p>
    <p>e to</p>
    <p>ri ca</p>
    <p>l a n</p>
    <p>n o</p>
    <p>ta to</p>
    <p>r</p>
    <p>C o</p>
    <p>re fe</p>
    <p>re n</p>
    <p>ce r</p>
    <p>e s.</p>
    <p>, ca</p>
    <p>u sa</p>
    <p>li ty</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>&amp; g</p>
    <p>ra p</p>
    <p>h b</p>
    <p>u il</p>
    <p>d e</p>
    <p>r</p>
    <p>B a</p>
    <p>b e</p>
    <p>lf y</p>
    <p>W S</p>
    <p>D a</p>
    <p>n d</p>
    <p>E n</p>
    <p>ti ty</p>
    <p>L in</p>
    <p>k e</p>
    <p>r</p>
    <p>E x</p>
    <p>tr a</p>
    <p>ct iv</p>
    <p>e s</p>
    <p>u m</p>
    <p>m a</p>
    <p>ri ze</p>
    <p>r</p>
    <p>Rhetorical categories: Background, Challenge, Approach, Outcome, Future Work  Linguistic and syntactic sentence features exploited to train Logistic Regression classifier on Dr. Inventor Corpus (40 Computer Graphics papers including 8,777 sentences)</p>
  </div>
  <div class="page">
    <p>Architectural overview Dr. Inventor Text Mining Framework</p>
    <p>P D</p>
    <p>F t</p>
    <p>o t</p>
    <p>e x</p>
    <p>t co</p>
    <p>n v</p>
    <p>e rt</p>
    <p>e r</p>
    <p>S e</p>
    <p>n te</p>
    <p>n ce</p>
    <p>s p</p>
    <p>li tt</p>
    <p>e r</p>
    <p>In li</p>
    <p>n e</p>
    <p>c it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>W e</p>
    <p>b b</p>
    <p>a se</p>
    <p>d r</p>
    <p>e fe</p>
    <p>re n</p>
    <p>ce p</p>
    <p>a rs</p>
    <p>e r</p>
    <p>C it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>-a w</p>
    <p>a re</p>
    <p>d e</p>
    <p>p .</p>
    <p>p a</p>
    <p>rs e</p>
    <p>r</p>
    <p>R h</p>
    <p>e to</p>
    <p>ri ca</p>
    <p>l a n</p>
    <p>n o</p>
    <p>ta to</p>
    <p>r</p>
    <p>C o</p>
    <p>re fe</p>
    <p>re n</p>
    <p>ce r</p>
    <p>e s.</p>
    <p>, ca</p>
    <p>u sa</p>
    <p>li ty</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>&amp; g</p>
    <p>ra p</p>
    <p>h b</p>
    <p>u il</p>
    <p>d e</p>
    <p>r</p>
    <p>B a</p>
    <p>b e</p>
    <p>lf y</p>
    <p>W S</p>
    <p>D a</p>
    <p>n d</p>
    <p>E n</p>
    <p>ti ty</p>
    <p>L in</p>
    <p>k e</p>
    <p>r</p>
    <p>E x</p>
    <p>tr a</p>
    <p>ct iv</p>
    <p>e s</p>
    <p>u m</p>
    <p>m a</p>
    <p>ri ze</p>
    <p>r</p>
    <p>bn:00488805n Feature (machine learning, pattern</p>
    <p>recognition)</p>
    <p>bn:00075149n Summarisation, summarization</p>
    <p>bn:00074060n Statistical</p>
    <p>method, statistic al procedure</p>
  </div>
  <div class="page">
    <p>Architectural overview Dr. Inventor Text Mining Framework</p>
    <p>P D</p>
    <p>F t</p>
    <p>o t</p>
    <p>e x</p>
    <p>t co</p>
    <p>n v</p>
    <p>e rt</p>
    <p>e r</p>
    <p>S e</p>
    <p>n te</p>
    <p>n ce</p>
    <p>s p</p>
    <p>li tt</p>
    <p>e r</p>
    <p>In li</p>
    <p>n e</p>
    <p>c it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>W e</p>
    <p>b b</p>
    <p>a se</p>
    <p>d r</p>
    <p>e fe</p>
    <p>re n</p>
    <p>ce p</p>
    <p>a rs</p>
    <p>e r</p>
    <p>C it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>-a w</p>
    <p>a re</p>
    <p>d e</p>
    <p>p .</p>
    <p>p a</p>
    <p>rs e</p>
    <p>r</p>
    <p>R h</p>
    <p>e to</p>
    <p>ri ca</p>
    <p>l a n</p>
    <p>n o</p>
    <p>ta to</p>
    <p>r</p>
    <p>C o</p>
    <p>re fe</p>
    <p>re n</p>
    <p>ce r</p>
    <p>e s.</p>
    <p>, ca</p>
    <p>u sa</p>
    <p>li ty</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>&amp; g</p>
    <p>ra p</p>
    <p>h b</p>
    <p>u il</p>
    <p>d e</p>
    <p>r</p>
    <p>B a</p>
    <p>b e</p>
    <p>lf y</p>
    <p>W S</p>
    <p>D a</p>
    <p>n d</p>
    <p>E n</p>
    <p>ti ty</p>
    <p>L in</p>
    <p>k e</p>
    <p>r</p>
    <p>E x</p>
    <p>tr a</p>
    <p>ct iv</p>
    <p>e s</p>
    <p>u m</p>
    <p>m a</p>
    <p>ri ze</p>
    <p>r</p>
    <p>These modules</p>
    <p>undergo</p>
    <p>deformation</p>
    <p>They</p>
    <p>implement</p>
    <p>force fields</p>
    <p>These modules undergo deformation caused by force fields. They also implement attractive and repulsive force fields.</p>
    <p>coreferent</p>
    <p>cause</p>
  </div>
  <div class="page">
    <p>Architectural overview Dr. Inventor Text Mining Framework</p>
    <p>P D</p>
    <p>F t</p>
    <p>o t</p>
    <p>e x</p>
    <p>t co</p>
    <p>n v</p>
    <p>e rt</p>
    <p>e r</p>
    <p>S e</p>
    <p>n te</p>
    <p>n ce</p>
    <p>s p</p>
    <p>li tt</p>
    <p>e r</p>
    <p>In li</p>
    <p>n e</p>
    <p>c it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>W e</p>
    <p>b b</p>
    <p>a se</p>
    <p>d r</p>
    <p>e fe</p>
    <p>re n</p>
    <p>ce p</p>
    <p>a rs</p>
    <p>e r</p>
    <p>C it</p>
    <p>a ti</p>
    <p>o n</p>
    <p>-a w</p>
    <p>a re</p>
    <p>d e</p>
    <p>p .</p>
    <p>p a</p>
    <p>rs e</p>
    <p>r</p>
    <p>R h</p>
    <p>e to</p>
    <p>ri ca</p>
    <p>l a n</p>
    <p>n o</p>
    <p>ta to</p>
    <p>r</p>
    <p>C o</p>
    <p>re fe</p>
    <p>re n</p>
    <p>ce r</p>
    <p>e s.</p>
    <p>, ca</p>
    <p>u sa</p>
    <p>li ty</p>
    <p>sp</p>
    <p>o tt</p>
    <p>e r</p>
    <p>&amp; g</p>
    <p>ra p</p>
    <p>h b</p>
    <p>u il</p>
    <p>d e</p>
    <p>r</p>
    <p>B a</p>
    <p>b e</p>
    <p>lf y</p>
    <p>W S</p>
    <p>D a</p>
    <p>n d</p>
    <p>E n</p>
    <p>ti ty</p>
    <p>L in</p>
    <p>k e</p>
    <p>r</p>
    <p>E x</p>
    <p>tr a</p>
    <p>ct iv</p>
    <p>e s</p>
    <p>u m</p>
    <p>m a</p>
    <p>ri ze</p>
    <p>r</p>
    <p>Based on SUMMA text summarization toolkit</p>
    <p>Sentence relevance ranking approaches:  TF-IDF centroid of each section  TF-IDF similarity with title  LexRank / TextRank (soon)  LR of sentence features (soon)</p>
  </div>
  <div class="page">
    <p>Hands-on Dr. Inventor Framework</p>
    <p>Lazy loading  Object caching  Factory Design Pattern to manage resource allocations</p>
    <p>MAVEN:</p>
    <p>&lt;repositories&gt;</p>
    <p>&lt;repository&gt;</p>
    <p>&lt;id&gt;backingdata-repo&lt;/id&gt;</p>
    <p>&lt;name&gt;Backingdata repository&lt;/name&gt;</p>
    <p>&lt;url&gt;http://backingdata.org/dri/library/mavenRepo/&lt;/url&gt;</p>
    <p>&lt;/repository&gt;</p>
    <p>&lt;/repositories&gt;</p>
    <p>&lt;dependency&gt;</p>
    <p>&lt;groupId&gt;edu.upf.taln.dri&lt;/groupId&gt;</p>
    <p>&lt;artifactId&gt;lib&lt;/artifactId&gt;</p>
    <p>&lt;version&gt;1.0&lt;/version&gt;</p>
    <p>&lt;/dependency&gt;</p>
    <p>JAVA:</p>
    <p>Download ZIP file with JAR and dependencies</p>
    <p>Importing the library</p>
    <p>Full documentation and examples at: http://driframework.readthedocs.io/</p>
  </div>
  <div class="page">
    <p>Hands-on Dr. Inventor Framework</p>
    <p>Configure programmatically the library</p>
    <p>Which PDF-to-text converter?</p>
    <p>// To use PDFX:</p>
    <p>Factory.setPDFtoTextConverter(PDFtoTextConvMethod.PDFX);</p>
    <p>// To use GROBID:</p>
    <p>Factory.setPDFtoTextConverter(PDFtoTextConvMethod.GROBID);</p>
    <p>Which modules are enabled?</p>
    <p>// Instantiate the ModuleConfig class - the constructor sets all modules</p>
    <p>// enabled by default</p>
    <p>ModuleConfig modConfigurationObj = new ModuleConfig();</p>
    <p>// Disable the parsing of bibliographic entries by means of online</p>
    <p>// services (Bibsonomy, CrossRef, FreeCite)</p>
    <p>modConfigurationObj.setEnableBibEntryParsing(false);</p>
    <p>// Disable the association of a rhetorical category to the sentences of</p>
    <p>// the paper</p>
    <p>modConfigurationObj.setEnableRhetoricalClassification(false);</p>
    <p>// Improt the configuration parameters set in the ModuleConfig instance</p>
    <p>Factory.setModuleConfig(modConfigurationObj);</p>
    <p>Full documentation and examples at: http://driframework.readthedocs.io/</p>
  </div>
  <div class="page">
    <p>Hands-on Dr. Inventor Framework</p>
    <p>Import PDF / JATS XML from file / URL</p>
    <p>// From File (substitute parsePDF for parseJATS to import JATS file):</p>
    <p>Document doc_PDFfile =</p>
    <p>Factory.getPDFloader().parsePDF(&quot;/my/file/path/PDF_file_name.pdf&quot;);</p>
    <p>// From URL (substitute parsePDF for parseJATS to import JATS file):</p>
    <p>Document doc_PDFURL = Factory.getPDFloader().parsePDF(new</p>
    <p>URL(&quot;http://www2007.org/workshops/paper_45.pdf&quot;));</p>
    <p>Get ordered lists of sentences</p>
    <p>// Only abstract sentences</p>
    <p>List&lt;Sentence&gt; abstract_SentList =</p>
    <p>doc_PDFfile.extractSentences(SentenceSelectorENUM.ONLY_ABSTRACT);</p>
    <p>// Only body sentences</p>
    <p>List&lt;Sentence&gt; abstract_SentList =</p>
    <p>doc_PDFfile.extractSentences(SentenceSelectorENUM.ALL_EXCEPT_ABSTRACT);</p>
    <p>// Only abstract sentences</p>
    <p>List&lt;Sentence&gt; abstract_SentList =</p>
    <p>doc_PDFfile.extractSentences(SentenceSelectorENUM.ALL);</p>
    <p>Full documentation and examples at: http://driframework.readthedocs.io/</p>
  </div>
  <div class="page">
    <p>Hands-on Dr. Inventor Framework Full documentation and examples at: http://driframework.readthedocs.io/</p>
    <p>Print the content of the first sentence of the abstract (by the asString method of the Sentence object instance)</p>
    <p>// Get ordered list of abstract sentences</p>
    <p>List&lt;Sentence&gt; abstract_SentList =</p>
    <p>doc_PDFfile.extractSentences(SentenceSelectorENUM.ONLY_ABSTRACT);</p>
    <p>// Get the first sentence of the abstract</p>
    <p>Sentence firstAbstractSentence = abstract_SentList.get(0);</p>
    <p>// Print all the data associated to the first sentence of the abstract</p>
    <p>System.out.println(firstAbstractSentence.asString(true));</p>
    <p>[SENTENCE] ID: '22047', Text: 'Puppetry has been a popular art form for many centuries in different cultures, which becomes a valuable and fascinating heritage assert.', Rhetorical class: 'DRI_Background' 23 TOKENS ASSOCIATED [BABELNET SYNSET] ID: '22047', Text: 'Puppetry', In-sentence ID: '22047', Babel URL: 'http://babelnet.org/rdf/s00065258n', Synset ID: 'bn:00065258n', DBpedia URL: 'http://dbpedia.org/resource/Puppetry', Global score: '2.958149116792834E-4', Coherence score: '0.09968354430379747', Score: '0.8340262582056893', Source: 'bn:00065258n', Num tokens: '1' [BABELNET SYNSET] ID: '22047', Text: 'art', In-sentence ID: '22047', Babel URL: 'http://babelnet.org/rdf/s00005927n', Synset ID: 'bn:00005927n', DBpedia URL: 'http://dbpedia.org/resource/Art', Global score: '0.023262002991754745',</p>
  </div>
  <div class="page">
    <p>Hands-on Dr. Inventor Framework Full documentation and examples at: http://driframework.readthedocs.io/</p>
    <p>Print the content of the paper sections in document order</p>
    <p>// Get ordered list of document sections</p>
    <p>List&lt;Section&gt; sectionList = doc_PDFfile.extractSections(false);</p>
    <p>for(Section sec : rootSectionList) {</p>
    <p>// Print all the data associated to the section</p>
    <p>System.out.println(sec.asString(true));</p>
    <p>// Get the list of sub-sections</p>
    <p>List&lt;Section&gt; subSection = sec.getSubsections();</p>
    <p>// Get the list of sentences inside the section</p>
    <p>List&lt;Sentence&gt; sentencesOfSection = sec.getSentences();</p>
    <p>}</p>
    <p>[SECTION] ID: '21452', Name: '1. INTRODUCTION', Level: '1', Children sections IDs: '[]', Sentences IDs: '[22053, 22054, 22055, 22056, 22057, 22058, 22059, 22060, 22061, 22062, 22063]' [SECTION] ID: '21453', Name: ' 2. RELATED WORK', Level: '1', Children sections IDs: '[21454, 21455]', Sentences IDs: '[] [SECTION] ID: '21454', Name: ' 2.1. Head Modelling', Level: '2', Children sections IDs: '[]', Sentences IDs: '[22075, 22064, 22065, 22066, 22067, 22068, 22069, 22070, 22071, 22072, 22073, 22074] [SECTION] ID: '21455', Name: ' 2.2 Swept Surface Modelling', Level: '2', Children sections IDs: '[]', Sentences IDs: '[22082, 22083, 22084, 22085, 22086, 22076, 22077, 22078, 22079, 22080, 22081]</p>
  </div>
  <div class="page">
    <p>Hands-on Dr. Inventor Framework Full documentation and examples at: http://driframework.readthedocs.io/</p>
    <p>Print the content of the bibliographic entries / citations</p>
    <p>// Get ordered list of bibliographic entries</p>
    <p>List&lt;Citation&gt; citations = doc_PDFfile.extractCitations();</p>
    <p>for(Citation citation : citations) {</p>
    <p>// Print all the data associated to the citation</p>
    <p>System.out.println(citation.asString(true));</p>
    <p>}</p>
    <p>[CITATION] ID: '21440', Source: '[Bibsonomy]', Title: 'Realtime performance-based facial animation.', Year: '2011', Pages: '77', Bibsonomy URL: 'http://dblp.uni-trier.de/db/journals/tog/tog30.html#WeiseBLP11', Volume: '30', Journal: 'ACM Trans. Graph.', Text: 'Realtime performance-based facial animation T Weise S Bouaziz H Li Pauly M ACM Transactions on Graphics (TOG) 30 4 77' [AUTHOR] Full name: ', Thibaut Weise', First name: ', Thibaut', Surname: 'Weise' [AUTHOR] Full name: ', Sofien Bouaziz', First name: ', Sofien', Surname: 'Bouaziz' [AUTHOR] Full name: ', Hao Li', First name: ', Hao', Surname: 'Li' [AUTHOR] Full name: ', Mark Pauly', First name: ', Mark', Surname: 'Pauly' PUB ID TYPE: DOI - VALUE: http://dx.doi.org/10.1145/2010324.1964972 [CIT MARKER] ID: '40228', Citation ID: '21440', Sentence ID: '22067', Reference text: '10' [CIT MARKER] ID: '40241', Citation ID: '21440', Sentence ID: '22071', Reference text: '10'</p>
  </div>
  <div class="page">
    <p>Hands-on Dr. Inventor Framework</p>
    <p>Get an print the list of sentences of the 10-sentences extractive summary generated by the section title tf-idf similarity method</p>
    <p>// Get ordered list of summary sentences</p>
    <p>List&lt;Sentence&gt; summarySentences_TITLE_10 =</p>
    <p>doc_PDFfile.extractSummary(20, SummaryTypeENUM.TITLE_SIM);</p>
    <p>// Print the text of each sentence</p>
    <p>for(Sentence sent : summarySentences_CENTROID_20){</p>
    <p>System.out.println(sent.getText());</p>
    <p>}</p>
    <p>Full documentation and examples at: http://driframework.readthedocs.io/</p>
    <p>Several high level tasks look for either one-way rewriting between single sentences, like recognizing textual entailment (RTE) ( Dagan et al., 2006 ), or two-way rewritings like paraphrase identification ( Dolan et al., 2004 ) and semantic textual similarity ( Agirre et al., 2012 ). Our system based on type-enriched string rewriting kernels obtains state-of-the-art results on paraphrase identification and answer sentence selection and outperforms comparable methods on RTE. String rewriting kernels ( Bu et al., 2012 ) count the number of common rewritings between two pairs of sentences seen as sequences of words. Following the terminology of string kernels, we use the term string and character instead of sentence and word. A type-enriched string rewriting kernel (TESRK) is simply a string rewriting kernel as defined in Equation 1 but with R a set of typed rewriting rules. However, it cannot match the pair of sentences (C) in the original kb-SRK. We experimented on three tasks: paraphrase identification, recognizing textual entailment and answer sentence selection. Recognizing Textual Entailment asks whether the meaning of a sentence hypothesis can be inferred by reading a sentence text. A SVM classifier with this kernel yields state-of-the-art results in paraphrase identification and answer sentence selection and outperforms comparable systems in recognizing textual entailment.</p>
  </div>
  <div class="page">
    <p>Hands-on Dr. Inventor Framework</p>
    <p>Save and reload a processed paper - serialized as XML</p>
    <p>// Get the raw text contents of the paper</p>
    <p>String rawText = doc_PDFfile.getRawText();</p>
    <p>// Get the XML serialization of the contents of the paper, including</p>
    <p>// all the metadata already extracter</p>
    <p>String XMLText = doc_PDFfile.getXMLString();</p>
    <p>// Save the XML serialization of the contents of the paper to</p>
    <p>// the file: /my_path/stored_paper.xml</p>
    <p>// Reload the contents of the paper from</p>
    <p>// the file: /my_path/stored_paper.xml</p>
    <p>Document doc_PDFfile_Loaded =</p>
    <p>Factory.createNewDocument(&quot;/my_path/stored_paper.xml&quot;);</p>
    <p>Full documentation and examples at: http://driframework.readthedocs.io/</p>
  </div>
  <div class="page">
    <p>GLOBAL CONCLUSIONS AND DISCUSSION  There is considerable room for improvement in the next future with</p>
    <p>respect to the automation of the analysis, aggregation and summarization of scientific literature</p>
    <p>The Natural Language Processing community plays a key role in providing better automated techniques to mine scientific literature</p>
    <p>The investigation of scientific text mining approaches should take into account both their effectiveness and the possibility to scale over large, heterogeneous and dynamic collections of papers</p>
  </div>
  <div class="page">
    <p>Natural Language Processing for Intelligent Access</p>
    <p>to Scientific Information</p>
    <p>Francesco Ronzano and Horacio Saggion Natural Language Processing Group (TALN)</p>
    <p>Universitat Pompeu Fabra, Barcelona, Spain</p>
    <p>Tutorial @ COLING 2016 11th December 2016</p>
    <p>Many thanks for your attention!</p>
  </div>
</Presentation>
