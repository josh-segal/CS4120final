<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>To Search or to Crawl? Towards a Query Optimizer for Text</p>
    <p>Centric Tasks</p>
    <p>Panos Ipeirotis  New York University Eugene Agichtein  Microsoft Research Pranay Jain  Columbia University Luis Gravano  Columbia University</p>
  </div>
  <div class="page">
    <p>Text-Centric Task I: Information Extraction</p>
    <p>Information extraction applications extract structured relations from unstructured text</p>
    <p>May 19 1995, Atlanta -- The Centers for Disease Control and Prevention, which is in the front line of the world's response to the deadly Ebola epidemic in Zaire , is finding itself hard pressed to cope with the crisis</p>
    <p>Date Disease Name Location</p>
    <p>Jan. 1995 Malaria Ethiopia</p>
    <p>July 1995 Mad Cow Disease U.K.</p>
    <p>Feb. 1995 Pneumonia U.S.</p>
    <p>May 1995 Ebola Zaire</p>
    <p>Information Extraction System</p>
    <p>(e.g., NYUs Proteus)</p>
    <p>Disease Outbreaks in The New York Times</p>
    <p>Information Extraction tutorial yesterday by AnHai Doan, Raghu Ramakrishnan, Shivakumar Vaithyanathan</p>
  </div>
  <div class="page">
    <p>Other Text-Centric Tasks</p>
    <p>Task II: Database Selection  Task III: Focused Crawling</p>
    <p>Details in the paper</p>
  </div>
  <div class="page">
    <p>An Abstract View of TextCentric Tasks Output Tokens</p>
    <p>Extraction</p>
    <p>System</p>
    <p>Text Database</p>
    <p>Task Token</p>
    <p>Information Extraction Relation Tuple</p>
    <p>Database Selection Word (+Frequency)</p>
    <p>Focused Crawling Web Page about a Topic</p>
    <p>For the rest of the talk</p>
  </div>
  <div class="page">
    <p>Executing a Text-Centric Task Output Tokens</p>
    <p>Extraction</p>
    <p>System</p>
    <p>Text Database</p>
    <p>Similar to relational world</p>
    <p>Two major execution paradigms  Scan-based: Retrieve and process documents sequentially  Index-based: Query database (e.g., [case fatality rate]), retrieve and process documents in results</p>
    <p>Unlike the relational world</p>
    <p>Indexes are only approximate: index is on keywords, not on tokens of interest  Choice of execution plan affects output completeness (not only speed)</p>
    <p>underlying data distribution dictates what is best</p>
  </div>
  <div class="page">
    <p>Execution Plan Characteristics Output Tokens</p>
    <p>Extraction</p>
    <p>System</p>
    <p>Text Database</p>
    <p>Execution Plans have two main characteristics: Execution Time Recall (fraction of tokens retrieved)</p>
    <p>Question: How do we choose the fastest execution plan for reaching</p>
    <p>a target recall ?</p>
    <p>What is the fastest plan for discovering 10% of the disease outbreaks mentioned in The New York Times archive?</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Description and analysis of crawl- and query-based plans  Scan  Filtered Scan  Iterative Set Expansion  Automatic Query Generation</p>
    <p>Optimization strategy</p>
    <p>Experimental results and conclusions</p>
    <p>Crawl-based</p>
    <p>Query-based (Index-based)</p>
  </div>
  <div class="page">
    <p>Scan Output Tokens</p>
    <p>Extraction</p>
    <p>System</p>
    <p>Text Database</p>
    <p>ScanScan retrieves and processes documents sequentially (until reaching target recall)</p>
    <p>Execution time = |Retrieved Docs|  (R + P)</p>
    <p>Time for retrieving a document</p>
    <p>Question: How many documents does Scan retrieve</p>
    <p>to reach target recall?</p>
    <p>Time for processing a document</p>
    <p>Filtered ScanFiltered Scan uses a classifier to identify and process only promising documents (details in paper)</p>
  </div>
  <div class="page">
    <p>Estimating Recall of Scan Modeling Scan for Token t:  What is the probability of seeing t (with</p>
    <p>frequency g(t)) after retrieving S documents?  A sampling without replacement process</p>
    <p>After retrieving S documents, frequency of token t follows hypergeometric distribution</p>
    <p>Recall for token t is the probability that frequency of t in S docs &gt; 0</p>
    <p>&lt;SARS, China&gt;</p>
    <p>S documents</p>
    <p>Probability of seeing token t after retrieving S</p>
    <p>documents g(t) = frequency of token t</p>
  </div>
  <div class="page">
    <p>Estimating Recall of Scan Modeling Scan:  Multiple sampling without replacement</p>
    <p>processes, one for each token  Overall recall is average recall across</p>
    <p>tokens</p>
    <p>We can compute number of documents required to reach target recall</p>
    <p>&lt;SARS, China&gt;</p>
    <p>&lt;Ebola, Zaire&gt;</p>
    <p>Execution time = |Retrieved Docs|  (R + P)</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Description and analysis of crawl- and query-based plans  Scan  Filtered Scan  Iterative Set Expansion  Automatic Query Generation</p>
    <p>Optimization strategy</p>
    <p>Experimental results and conclusions</p>
    <p>Crawl-based</p>
    <p>Query-based</p>
  </div>
  <div class="page">
    <p>Iterative Set Expansion Output Tokens</p>
    <p>Extraction</p>
    <p>System</p>
    <p>Text Database</p>
    <p>Execution time = |Retrieved Docs| * (R + P) + |Queries| * Q</p>
    <p>Time for retrieving a document</p>
    <p>Time for answering a query</p>
    <p>Question: How many queries and how many documents</p>
    <p>does Iterative Set Expansion need to reach target recall?</p>
    <p>Time for processing a document</p>
    <p>Query</p>
    <p>Generation</p>
    <p>Question: How many queries and how many documents</p>
    <p>does Iterative Set Expansion need to reach target recall?</p>
    <p>(e.g., [Ebola AND Zaire]) (e.g., &lt;Malaria, Ethiopia&gt;)</p>
  </div>
  <div class="page">
    <p>Querying Graph</p>
    <p>The querying graph is a bipartite graph, containing tokens and documents</p>
    <p>Each token (transformed to a keyword query) retrieves documents</p>
    <p>Documents contain tokens</p>
    <p>Tokens Document s</p>
    <p>t1</p>
    <p>t2</p>
    <p>t3</p>
    <p>t4</p>
    <p>t5</p>
    <p>d1</p>
    <p>d2</p>
    <p>d3</p>
    <p>d4</p>
    <p>d5</p>
    <p>&lt;SARS, China&gt;</p>
    <p>&lt;Ebola, Zaire&gt;</p>
    <p>&lt;Malaria, Ethiopia&gt;</p>
    <p>&lt;Cholera, Sudan&gt;</p>
    <p>&lt;H5N1, Vietnam&gt;</p>
  </div>
  <div class="page">
    <p>Using Querying Graph for Analysis</p>
    <p>We need to compute the:  Number of documents retrieved after</p>
    <p>sending Q tokens as queries (estimates time)  Number of tokens that appear in the</p>
    <p>retrieved documents (estimates recall)</p>
    <p>To estimate these we need to compute the:  Degree distribution of the tokens</p>
    <p>discovered by retrieving documents  Degree distribution of the documents</p>
    <p>retrieved by the tokens  (Not the same as the degree distribution of a</p>
    <p>randomly chosen token or document  it is easier to discover documents and tokens with high degrees)</p>
    <p>Tokens Docume nts</p>
    <p>t1</p>
    <p>t2</p>
    <p>t3</p>
    <p>t4</p>
    <p>t5</p>
    <p>d1</p>
    <p>d2</p>
    <p>d3</p>
    <p>d4</p>
    <p>d5</p>
    <p>Elegant analysis framework based on generating functions  details in the paper</p>
    <p>&lt;SARS, China&gt;</p>
    <p>&lt;Ebola, Zaire&gt;</p>
    <p>&lt;Malaria, Ethiopia&gt;</p>
    <p>&lt;Cholera, Sudan&gt;</p>
    <p>&lt;H5N1, Vietnam&gt;</p>
  </div>
  <div class="page">
    <p>Recall Limit: Reachability Graph</p>
    <p>t1 retrieves document d1 that contains t2</p>
    <p>t1</p>
    <p>t2 t3</p>
    <p>t4t5</p>
    <p>Tokens Document s</p>
    <p>t1</p>
    <p>t2</p>
    <p>t3</p>
    <p>t4</p>
    <p>t5</p>
    <p>d1</p>
    <p>d2</p>
    <p>d3</p>
    <p>d4</p>
    <p>d5</p>
    <p>Upper recall limit: determined by the size of the biggest connected component</p>
    <p>Reachability Graph</p>
  </div>
  <div class="page">
    <p>Automatic Query Generation</p>
    <p>Details in the paper</p>
    <p>Iterative Set ExpansionIterative Set Expansion has recall limitation due to iterative nature of query generation</p>
    <p>Automatic Query GenerationAutomatic Query Generation avoids this problem by creating queries offline (using machine learning), which are designed to return documents with tokens</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Description and analysis of crawl- and query-based plans</p>
    <p>Optimization strategy</p>
    <p>Experimental results and conclusions</p>
  </div>
  <div class="page">
    <p>Summary of Cost Analysis</p>
    <p>Our analysis so far:  Takes as input a target recall  Gives as output the time for each plan to reach target recall</p>
    <p>(time = infinity, if plan cannot reach target recall)</p>
    <p>Time and recall depend on task-specific properties of database:  Token degree distribution  Document degree distribution</p>
    <p>Next, we show how to estimate degree distributions on-the-fly</p>
  </div>
  <div class="page">
    <p>Estimating Cost Model ParametersToken and document degree distributions belong to known distribution families</p>
    <p>Can characterize distributions with only a few parameters!</p>
    <p>Task Document Distribution Token Distribution</p>
    <p>Information Extraction Power-law Power-law</p>
    <p>Content Summary Construction Lognormal Power-law (Zipf)</p>
    <p>Focused Resource Discovery Uniform Uniform</p>
  </div>
  <div class="page">
    <p>Parameter Estimation</p>
    <p>Nave solution for parameter estimation:  Start with separate, parameter-estimation phase  Perform random sampling on database  Stop when cross-validation indicates high confidence</p>
    <p>We can do better than this!</p>
    <p>No need for separate sampling phase  Sampling is equivalent to executing the task:</p>
    <p>Piggyback parameter estimation into execution</p>
  </div>
  <div class="page">
    <p>On-the-fly Parameter Estimation</p>
    <p>Pick most promising execution plan for target recall assuming default parameter values</p>
    <p>Start executing task  Update parameter estimates</p>
    <p>during execution  Switch plan if updated statistics</p>
    <p>indicate so Important Only Scan acts as random sampling All other execution plan need parameter adjustment (see paper)</p>
    <p>Correct (but unknown) distribution</p>
    <p>Initial, default estimationUpdated estimationUpdated estimation</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Description and analysis of crawl- and query-based plans</p>
    <p>Optimization strategy</p>
    <p>Experimental results and conclusions</p>
  </div>
  <div class="page">
    <p>Correctness of Theoretical Analysis</p>
    <p>Solid lines: Actual time  Dotted lines: Predicted time with correct parameters</p>
    <p>Task: Disease Outbreaks</p>
    <p>Snowball IE system</p>
    <p>E xe</p>
    <p>cu tio</p>
    <p>n T</p>
    <p>im e</p>
    <p>( se</p>
    <p>cs )</p>
    <p>Scan</p>
    <p>Filt. Scan</p>
    <p>Automatic Query Gen.</p>
    <p>Iterative Set Expansion</p>
  </div>
  <div class="page">
    <p>Experimental Results (Information Extraction)</p>
    <p>Solid lines: Actual time  Green line: Time with optimizer</p>
    <p>(results similar in other experiments  see paper)</p>
    <p>Recall</p>
    <p>E xe</p>
    <p>c u tio</p>
    <p>n T</p>
    <p>im e</p>
    <p>( se</p>
    <p>cs )</p>
    <p>Scan</p>
    <p>Filt. Scan</p>
    <p>Iterative Set Expansion</p>
    <p>Automatic Query Gen.</p>
    <p>OPTIMIZED</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Common execution plans for multiple text-centric tasks</p>
    <p>Analytic models for predicting execution time and recall of various crawl- and query-based plans</p>
    <p>Techniques for on-the-fly parameter estimation</p>
    <p>Optimization framework picks on-the-fly the fastest plan for target recall</p>
  </div>
  <div class="page">
    <p>Future Work</p>
    <p>Incorporate precision and recall of extraction system in framework</p>
    <p>Create non-parametric optimization (i.e., no assumption about distribution families)</p>
    <p>Examine other text-centric tasks and analyze new execution plans</p>
    <p>Create adaptive, next-K optimizer</p>
  </div>
  <div class="page">
    <p>Thank you!</p>
    <p>Task Filtered Scan Iterative Set Expansion</p>
    <p>Automatic Query Generation</p>
    <p>Information Extraction</p>
    <p>Grishman et al., J.of Biomed. Inf. 2002</p>
    <p>Agichtein and Gravano, ICDE 2003</p>
    <p>Agichtein and Gravano, ICDE 2003</p>
    <p>Content Summary Construction</p>
    <p>- Callan et al., SIGMOD 1999</p>
    <p>Ipeirotis and Gravano, VLDB 2002</p>
    <p>Focused Resource Discovery</p>
    <p>Chakrabarti et al., WWW 1999</p>
    <p>- Cohen and Singer, AAAI WIBIS 1996</p>
  </div>
</Presentation>
