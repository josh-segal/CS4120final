<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Bridging the Edge-Cloud Barrier for Real-time Advanced Vision Analytics</p>
    <p>Yiding Wang, Weiyan Wang, Junxue Zhang, Junchen Jiang (UChicago), Kai Chen</p>
    <p>1</p>
  </div>
  <div class="page">
    <p>(Edge-to-cloud) vision analytics are ubiquitous</p>
    <p>Large scale deployment of cameras: traffic monitoring, event detection</p>
    <p>Vehicles/robots with cameras: autonomous driving vehicles/robotics/drones</p>
    <p>Object detection Semantic segmentation !2</p>
  </div>
  <div class="page">
    <p>Advanced applications are demanding</p>
    <p>Example: segmentation and object detection tasks for autonomous driving  Real-time-level interaction requires low latency  High inference accuracy requires high fidelity data and computing resource</p>
    <p>Currently advanced applications run heavy vision inference tasks on the edge.</p>
    <p>Real-time video analytics: the killer app for edge computing Ganesh Ananthanarayanan etc.</p>
    <p>But it makes sense to consider a cloud-based solution.</p>
    <p>!3</p>
  </div>
  <div class="page">
    <p>Potential benefits of the cloud</p>
    <p>Reducing the requirements for edge devices, thus making the large-scale deployment cheap.</p>
    <p>High-end autonomous driving vehicles vs. delivery robots/vehicles</p>
    <p>!4</p>
  </div>
  <div class="page">
    <p>Challenges</p>
    <p>The edge-to-cloud real-time advanced vision applications face strict bandwidth-accuracy trade-off:</p>
    <p>!5</p>
  </div>
  <div class="page">
    <p>Idea #1: cropping Sending only cropped areas of region-of-interest (ROI). (Reinventing Video Streaming for Distributed Vision Analytics, Pakha et al., HotCloud 2018).</p>
    <p>!6</p>
    <p>Limitation: For advanced applications, ROI is is the full frame.  Cannot crop.</p>
  </div>
  <div class="page">
    <p>Idea #2: frame filtering Filtering the relevant frames and streaming them to the cloud. (Scaling Video Analytics On Constrained Edge Nodes, Canel et al., SysML 2019)</p>
    <p>Limitation: Works well for always-on stationary traffic camera feeds, but not for a moving vehicle/robot: relevant objects are always in the scene.</p>
    <p>!7</p>
  </div>
  <div class="page">
    <p>Idea #3: harmless degradation Using a task-specific degradation config. (AWStream: Adaptive Wide-Area Streaming Analytics, Zhang et al., SIGCOMM 2018)</p>
    <p>Mobile cameras: value frame rate. Stationary cameras: value resolution</p>
    <p>Limitation: Advanced applications require both high frame rate and resolution. 4 downsampling13% loss on mIoU, 20% on small yet critical object classes</p>
    <p>!8</p>
    <p>Stationary Camera</p>
    <p>Mobile Camera</p>
    <p>Figures from AWStream</p>
  </div>
  <div class="page">
    <p>Our work</p>
    <p>CloudSeg, an edge-to-cloud framework for advanced vision analytics that achieves both low latency and high inference accuracy with analytics-aware super-resolution.</p>
    <p>CloudSeg saves bandwidth by recovering the high-resolution frames from the low-resolution stream via super-resolution.</p>
    <p>CloudSeg keeps high accuracy via SR tailored for the actual analytics tasks.</p>
    <p>!9</p>
  </div>
  <div class="page">
    <p>Design of CloudSeg framework</p>
    <p>Low extra latency (6.2ms) with an efficient SR model on the GPU server.</p>
    <p>!10</p>
  </div>
  <div class="page">
    <p>Bandwidth usage saving</p>
    <p>With CloudSeg, downsampling 2K frames to 512256 can reduce 13.3 bandwidth usage with 2.6% accuracy (mIoU) loss for semantic segmentation. To achieve the same accuracy, AWStream needs to stream 720p feed, thus CloudSeg can reduce bandwidth use by 6.8 compared with AWStream.</p>
    <p>!11</p>
  </div>
  <div class="page">
    <p>Inference accuracy on critical details</p>
    <p>Some classes in Cityscapes dataset are very insensitive to input resolutions: sky, road, wall, building, etc.</p>
    <p>Others e.g. rider, bicycle, motorcycle, traffic sign/light, person are sensitive to the input quality and also critical to the real-world applications.</p>
    <p>Observation: There is a mismatch between goals of SR and analytics tasks.</p>
    <p>!12</p>
  </div>
  <div class="page">
    <p>Analytics-aware super-resolution</p>
    <p>Target of SR training: reduce the backend model inference accuracy loss</p>
    <p>Especially improve the accuracy on small objects, compared with vanilla SR</p>
    <p>2.6% accuracy loss compared with HR frames</p>
    <p>!13</p>
  </div>
  <div class="page">
    <p>Promising results</p>
    <p>6.8 bandwidth saving compared with AWStream, at same inference accuracy 2.6% accuracy (mIoU) loss compared with original 2K frames (13.3 larger)</p>
    <p>A cc</p>
    <p>ur ac</p>
    <p>y (m</p>
    <p>Io U</p>
    <p>)</p>
    <p>No degradation (20481024)</p>
    <p>AWStream (1440720)</p>
    <p>CloudSeg (512256)</p>
    <p>B an</p>
    <p>dw id</p>
    <p>th C</p>
    <p>on su</p>
    <p>m pt</p>
    <p>io n</p>
    <p>(k bp</p>
    <p>s)</p>
    <p>No degradation (20481024)</p>
    <p>AWStream (1440720)</p>
    <p>CloudSeg (512256)</p>
    <p>!14</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Enabling edge-to-cloud real-time advanced vision analytics is meaningful. The key technical challenge is the strict bandwidth-accuracy trade-off.</p>
    <p>The design of CloudSeg is a first step to tackle the trade-off with analyticsaware super-resolution.</p>
    <p>Promising results: 6.8 bandwidth saving compared with directly downsampling, with negligible drop in accuracy compared with original video.</p>
    <p>!15</p>
  </div>
</Presentation>
