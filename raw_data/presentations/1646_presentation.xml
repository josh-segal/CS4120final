<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>A Coupon Based Throttle-andReward Mechanism for Fair and Efficient I/O Bandwidth Management on Parallel Storage Systems</p>
    <p>Rohan GargTirthak Patel Devesh Tiwari</p>
    <p>GIFT:</p>
  </div>
  <div class="page">
    <p>The Key Idea Behind</p>
  </div>
  <div class="page">
    <p>The Key Idea Behind</p>
    <p>but, first some background</p>
  </div>
  <div class="page">
    <p>Data-intensive Parallel Applications</p>
    <p>I/O Phase</p>
    <p>Compute Phase</p>
    <p>Compute Phase</p>
  </div>
  <div class="page">
    <p>Compute System</p>
    <p>Parallel Storage System</p>
    <p>Data-intensive Parallel Applications</p>
    <p>Compute Nodes (OSCs)</p>
    <p>SION CTRL A</p>
    <p>CTRL B</p>
    <p>CTRL A</p>
    <p>CTRL B</p>
    <p>HBA</p>
    <p>HBA</p>
    <p>HBA</p>
    <p>HBA</p>
    <p>NET</p>
    <p>NET</p>
    <p>NET</p>
    <p>NET</p>
    <p>OSSes OSTs</p>
    <p>MDSes MDTs</p>
    <p>CTRL A</p>
    <p>CTRL B</p>
    <p>HBA</p>
    <p>HBA</p>
    <p>NET</p>
    <p>NET</p>
    <p>I/O Phase</p>
    <p>Compute Phase</p>
    <p>Compute Phase</p>
  </div>
  <div class="page">
    <p>Object Storage Targets (OSTs)</p>
    <p>C A E D B A</p>
    <p>A B C D</p>
    <p>Isovalues on compressed simulation data with bounding error - (32 bits, 3200x2400x42, 1.4 GB) !</p>
    <p>E One application performs I/O</p>
    <p>concurrently to multiple OSTs.</p>
    <p>Parallel applications can cause unmanaged and unpredictable I/O interference!</p>
    <p>GeoScience</p>
  </div>
  <div class="page">
    <p>Object Storage Targets (OSTs)</p>
    <p>C A E D B A</p>
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>MBW</p>
    <p>A A A</p>
    <p>B</p>
    <p>DD C</p>
    <p>B</p>
    <p>OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>A B C D</p>
    <p>Isovalues on compressed simulation data with bounding error - (32 bits, 3200x2400x42, 1.4 GB) !</p>
    <p>GeoScience</p>
    <p>E One application performs I/O</p>
    <p>concurrently to multiple OSTs.</p>
    <p>Parallel applications can cause unmanaged and unpredictable I/O interference!</p>
    <p>Inefficient I/O bandwidth utilization</p>
  </div>
  <div class="page">
    <p>A A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C C</p>
    <p>B</p>
    <p>Traditional</p>
    <p>Time t1</p>
    <p>Time t2</p>
  </div>
  <div class="page">
    <p>A A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C C</p>
    <p>B</p>
    <p>A A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C C</p>
    <p>B</p>
    <p>Traditional</p>
    <p>Time t1</p>
    <p>Time t2</p>
    <p>GIFT</p>
    <p>Time t1</p>
    <p>Time t2</p>
  </div>
  <div class="page">
    <p>GIFTs coupon-based I/O bandwidth allocation appears</p>
    <p>appealing, but</p>
  </div>
  <div class="page">
    <p>GIFTs coupon-based I/O bandwidth allocation appears</p>
    <p>appealing, but</p>
    <p>What are the challenges? What are the favorable</p>
    <p>characteristics?</p>
  </div>
  <div class="page">
    <p>GIFT Enablers</p>
    <p>Repetitive runs</p>
    <p>HPC applications run repeatedly, are frequent, and exhibit similar I/O behavior across different runs.</p>
  </div>
  <div class="page">
    <p>Low-periodicityRepetitive runs</p>
    <p>GIFT Enablers HPC applications run repeatedly, are frequent, and exhibit similar I/O behavior across different runs.</p>
  </div>
  <div class="page">
    <p>HPC applications run repeatedly, are frequent, and exhibit similar I/O behavior across different runs.</p>
    <p>Low-periodicityRepetitive runs Predictable I/O</p>
    <p>GIFT Enablers</p>
  </div>
  <div class="page">
    <p>Parallel applications suffer from non-synchronous I/O progress leading to bandwidth waste.</p>
    <p>Engaging</p>
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>MBW</p>
    <p>A A A</p>
    <p>B</p>
    <p>DD C</p>
    <p>B</p>
    <p>OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>waste</p>
    <p>Significant variation in I/O finish time among MPI processes of the same</p>
    <p>application.</p>
    <p>GIFT Challenges</p>
  </div>
  <div class="page">
    <p>Need for synchronous I/O progress in parallel applications poses new challenges in</p>
    <p>maintaining efficiency and fairness in I/O bandwidth allocation.</p>
    <p>GIFT Challenges</p>
    <p>Lets look at some bandwidth allocation policies and compare them.</p>
  </div>
  <div class="page">
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>MBW</p>
    <p>A A A</p>
    <p>B</p>
    <p>DD C</p>
    <p>B</p>
    <p>OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>MBW</p>
    <p>A A A</p>
    <p>B</p>
    <p>DD C</p>
    <p>B</p>
    <p>OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>Per-OST Fair Share</p>
  </div>
  <div class="page">
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>MBW</p>
    <p>A A A</p>
    <p>B</p>
    <p>DD C</p>
    <p>B</p>
    <p>OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>Per-OST Fair Share</p>
  </div>
  <div class="page">
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>MBW</p>
    <p>A A A</p>
    <p>B</p>
    <p>DD C</p>
    <p>B</p>
    <p>OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>Per-OST Fair Share</p>
    <p>Fair Not synchronous</p>
    <p>B/W waste</p>
  </div>
  <div class="page">
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>MBW</p>
    <p>A A A</p>
    <p>B</p>
    <p>DD C</p>
    <p>B</p>
    <p>OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>MBW</p>
    <p>A A A</p>
    <p>B</p>
    <p>DD C</p>
    <p>B</p>
    <p>OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>Fair Not synchronous</p>
    <p>B/W waste</p>
    <p>Per-OST Fair Share</p>
    <p>Basic Synchronous I/O Progress</p>
  </div>
  <div class="page">
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>MBW</p>
    <p>A A A</p>
    <p>B</p>
    <p>DD C</p>
    <p>B</p>
    <p>OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>Per-OST Fair Share</p>
    <p>Basic Synchronous I/O Progress</p>
    <p>Fair Not synchronous</p>
    <p>B/W waste</p>
  </div>
  <div class="page">
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>MBW</p>
    <p>A A A</p>
    <p>B</p>
    <p>DD C</p>
    <p>B</p>
    <p>OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>B / W Fair</p>
    <p>Not synchronous B/W waste</p>
    <p>Fair Synchronous B/W waste</p>
    <p>Per-OST Fair Share</p>
    <p>Basic Synchronous I/O Progress</p>
  </div>
  <div class="page">
    <p>Fair Not synchronous</p>
    <p>B/W waste</p>
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>MBW</p>
    <p>A A A</p>
    <p>B</p>
    <p>DD C</p>
    <p>B</p>
    <p>OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>Per-OST Fair Share</p>
    <p>Basic Synchronous I/O Progress</p>
    <p>Minimum Bandwidth Wastage</p>
    <p>Fair Synchronous B/W waste</p>
  </div>
  <div class="page">
    <p>Fair Not synchronous</p>
    <p>B/W waste</p>
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>MBW</p>
    <p>A A A</p>
    <p>B</p>
    <p>DD C</p>
    <p>B</p>
    <p>OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>Per-OST Fair Share</p>
    <p>Basic Synchronous I/O Progress</p>
    <p>Minimum Bandwidth Wastage</p>
    <p>Fair Synchronous B/W waste</p>
    <p>Not Fair Synchronous No B/W waste</p>
  </div>
  <div class="page">
    <p>Balances three goals Fairness Synchronous I/O Progress</p>
    <p>Minimize B/W Wastage</p>
  </div>
  <div class="page">
    <p>Three Key Ingredients</p>
    <p>Fairness</p>
    <p>GIFT breaks away from instantaneous fairness and maintains fairness over a long time-window. Barter system for unfair treatment: award compute hours for unfairness in I/O bandwidth allocation. Concept of System Compute Hour Regret Budget</p>
  </div>
  <div class="page">
    <p>Three Key Ingredients</p>
    <p>Synchronous I/O Progress</p>
    <p>GIFTs initial allocation is the same as BSIP scheme and any subsequent readjustments ensure that this property is preserved.</p>
  </div>
  <div class="page">
    <p>Three Key Ingredients</p>
    <p>Minimize B/W Wastage</p>
    <p>GIFT designs a throttle-and-reward mechanism that picks throttle-friendly applications, issues them coupons to reduce b/w waste at a given time, and reward them later (i.e., redeem their coupons).</p>
  </div>
  <div class="page">
    <p>GIFT Workflow</p>
    <p>Determine ThrottleFriendly</p>
    <p>Applications</p>
    <p>Redeem Coupons</p>
    <p>Issue Coupons to</p>
    <p>Throttled Applications</p>
    <p>Decrease Redemption</p>
    <p>Rate</p>
    <p>Perform BSIP Bandwidth Allocation</p>
    <p>Allocate Bandwidth Optimally</p>
    <p>Every Decision Instance</p>
    <p>Increase Redemption</p>
    <p>Rate</p>
    <p>Whom to throttle?</p>
    <p>Which coupons to redeem?</p>
    <p>How much to throttle and expand?</p>
  </div>
  <div class="page">
    <p>Identifying Throttle-Friendly Applications  Careful design leads to</p>
    <p>minimal system regret budget (compute hours given out due to unfair treatment in long term).</p>
    <p>Throttle-friendly apps can also be expanded if deemed beneficial.</p>
    <p>Set of throttle-friendly applications changes over time.NN is the length of receding window.</p>
    <p>is the minimum redemption rate required for an app. to be throttle-eligible.</p>
    <p>Initial redemption</p>
    <p>Coupons issued</p>
    <p>Coupons issued</p>
    <p>Coupons issued</p>
    <p>Coupons redeemed</p>
  </div>
  <div class="page">
    <p>Careful Coupon Redemption GIFT redeems coupons only when it does not</p>
    <p>require throttling other applications. Spare B/W available. A has an outstanding coupon worth 15%.</p>
    <p>A (38%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>C (38%)</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%) A (42%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>C (33%)</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%)</p>
    <p>C (33%)</p>
    <p>A (33%)</p>
  </div>
  <div class="page">
    <p>Careful Coupon Redemption GIFT redeems coupons only when it does not</p>
    <p>require throttling other applications. Spare B/W available. A has an outstanding coupon worth 15%.</p>
    <p>B/W can be divided equally, but GIFT</p>
    <p>does not.</p>
    <p>A (38%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>C (38%)</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%) A (42%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>C (33%)</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%)</p>
    <p>C (33%)</p>
    <p>A (33%)</p>
  </div>
  <div class="page">
    <p>Careful Coupon Redemption GIFT redeems coupons only when it does not</p>
    <p>require throttling other applications. Spare B/W available. A has an outstanding coupon worth 15%.</p>
    <p>B/W can be divided equally, but GIFT</p>
    <p>does not.</p>
    <p>A (38%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>C (38%)</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%) A (42%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>C (33%)</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%)</p>
    <p>C (33%)</p>
    <p>A (33%)</p>
    <p>Instead, GIFT (partially) redeems As coupon, but</p>
    <p>w/o throttling C.</p>
  </div>
  <div class="page">
    <p>One may argue that if spare I/O bandwidth is available, applications</p>
    <p>would have naturally been allocated that I/O bandwidth.</p>
    <p>So, how does GIFT reduce wasted bandwidth?</p>
  </div>
  <div class="page">
    <p>Issue coupon worth 15% b/w on one OST to app. A</p>
    <p>A (35%)</p>
    <p>B (65%)</p>
    <p>OST 1 OST 2</p>
    <p>B (65%)</p>
    <p>B / W</p>
    <p>Redeem app. As coupon with 9% b/w on one OST</p>
    <p>A (42%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>C (33%)</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%)</p>
    <p>Redeem app. As coupon with 6% b/w on one OST</p>
    <p>A (39%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>C (36%)</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%)</p>
    <p>Instance k1 Instance k2 Instance k3</p>
    <p>A (50%)</p>
    <p>B (50%)</p>
    <p>OST 1 OST 2</p>
    <p>B (50%)</p>
    <p>B / W</p>
    <p>A (38%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>C (38%)</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%)A (38%)</p>
    <p>C (38%)</p>
    <p>GIFT</p>
    <p>BSIP</p>
  </div>
  <div class="page">
    <p>Issue coupon worth 15% b/w on one OST to app. A</p>
    <p>A (35%)</p>
    <p>B (65%)</p>
    <p>OST 1 OST 2</p>
    <p>B (65%)</p>
    <p>B / W</p>
    <p>Redeem app. As coupon with 9% b/w on one OST</p>
    <p>A (42%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>C (33%)</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%)</p>
    <p>Redeem app. As coupon with 6% b/w on one OST</p>
    <p>A (39%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>C (36%)</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%)</p>
    <p>Instance k1 Instance k2 Instance k3</p>
    <p>A (50%)</p>
    <p>B (50%)</p>
    <p>OST 1 OST 2</p>
    <p>B (50%)</p>
    <p>B / W</p>
    <p>A (38%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>C (38%)</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%)A (38%)</p>
    <p>C (38%)</p>
    <p>GIFT</p>
    <p>BSIP</p>
  </div>
  <div class="page">
    <p>Issue coupon worth 15% b/w on one OST to app. A</p>
    <p>A (35%)</p>
    <p>B (65%)</p>
    <p>OST 1 OST 2</p>
    <p>B (65%)</p>
    <p>B / W</p>
    <p>Redeem app. As coupon with 9% b/w on one OST</p>
    <p>A (42%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>C (33%)</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%)</p>
    <p>Redeem app. As coupon with 6% b/w on one OST</p>
    <p>A (39%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>C (36%)</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%)</p>
    <p>Instance k1 Instance k2 Instance k3</p>
    <p>A (50%)</p>
    <p>B (50%)</p>
    <p>OST 1 OST 2</p>
    <p>B (50%)</p>
    <p>B / W</p>
    <p>A (38%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>C (38%)</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%)</p>
    <p>B (25%)</p>
    <p>OST 1 OST 2</p>
    <p>B (25%)</p>
    <p>D (25%)</p>
    <p>E (25%)</p>
    <p>F (25%)A (38%)</p>
    <p>C (38%)</p>
    <p>GIFT</p>
    <p>BSIP</p>
  </div>
  <div class="page">
    <p>Optimal I/O Bandwidth Allocation How much to throttle and whom to expand by how much? Formulated as a linear programming optimization problem Subject to constraints o All I/O requests of an application</p>
    <p>issued across all OSTs should get the same B/W for synch. I/O progress</p>
    <p>o The final B/W allocation should be fair o All OSTs are constrained by their full</p>
    <p>capacityj = 2 j = 3</p>
    <p>A B C</p>
    <p>max$ &quot;$</p>
    <p>$ %&amp;&quot;</p>
    <p>%</p>
    <p>Set of all OSTs</p>
    <p>Set of all apps on OST j</p>
    <p>B/w allocation of app i</p>
    <p>j = 1</p>
    <p>A D C A D</p>
  </div>
  <div class="page">
    <p>GIFT: A Coupon Based Throttle-and-Reward Mechanism for Fair and Efficient I/O Bandwidth Management on Parallel Storage Systems</p>
    <p>Tirthak Patel Northeastern University</p>
    <p>Rohan Garg Nutanix</p>
    <p>Devesh Tiwari Northeastern University</p>
    <p>Abstract Large-scale parallel applications are highly data-intensive</p>
    <p>and perform terabytes of I/O routinely. Unfortunately, on a large-scale system where multiple applications run concurrently, I/O contention negatively affects system efficiency and causes unfair bandwidth allocation among applications. To address these challenges, this paper introduces GIFT, a principled dynamic approach to achieve fairness among competing applications and improve system efficiency.</p>
    <p>Problem Space and Gaps in Existing Approaches. Increase in computing power has enabled scientists to expedite the scientific discovery process, but scientific applications produce more and more analysis and checkpoint data, worsening their I/O bottleneck [7, 45]. Many applications spend 15-40% of their execution time performing I/O, which is expected to increase for exascale systems [12, 15, 22, 31, 53, 55]. Unfortunately, multiple concurrent applications on a large-scale system lead to severe I/O contention, limiting the usability of future HPC systems [11, 45].</p>
    <p>Recognizing the importance of the problem, there have been numerous efforts to mitigate I/O contention from both I/O throughput and fairness perspectives [13, 14, 17, 25, 37, 42, 75, 76, 78, 88, 89]. Unfortunately, ensuring fairness and maximizing throughput are conflicting objectives, and it is challenging to strike a balance between them under I/O contention. For parallel HPC applications, the side-effect of I/O contention is further amplified because of the need for synchronous I/O progress. HPC applications are inherently tightly synchronized; during an I/O phase, MPI processes of an HPC application must wait for all processes to finish their I/O before resuming computation (i.e., synchronous I/O progress among MPI processes is required) [28, 31, 39, 57, 90].</p>
    <p>MPI processes of an HPC application perform parallel I/O access to multiple back-end storage targets (e.g., an array of disks) concurrently. These back-end storage targets are shared among concurrently running applications and have different degree of sharing over time and hence, a varying level of contention. A varying level of I/O contention at the shared back-end parallel storage system makes different MPI processes progress at different rates and hence, leads</p>
    <p>to non-synchronous I/O progress. In Sec. 2, we quantify nonsynchronous I/O progress as a key source of inefficiency in shared parallel storage systems. It results in (1) wastage of compute cycles on compute nodes, and (2) reduction in effective system I/O bandwidth (i.e., the bandwidth that contributes toward synchronous I/O progress), since full bandwidth is not utilized toward synchronous I/O progress.</p>
    <p>Recent works have noted that non-synchronous I/O progress degrades application and system performances on modern supercomputers like Mira, Edison, Cori, and Titan [9, 31, 32, 39, 69, 83]. Thus, there is an emerging interest in improving the quality-of-service (QoS) of parallel storage systems [24, 80, 86]. Previous works have proposed rulebased or ad-hoc bandwidth allocation strategies for HPC storage [14, 17, 23, 36, 42, 88, 89]. However, existing approaches do not systematically implement synchronous I/O progress to balance the competing objectives: improving effective system I/O bandwidth and improving fairness.</p>
    <p>To bridge this solution gap, this paper describes GIFT, a coupon-based bandwidth allocation approach to ensure synchronous I/O progress of HPC applications while maximizing I/O bandwidth utilization and ensuring fairness among concurrent applications on parallel storage systems.</p>
    <p>Summary of the GIFT Approach. GIFT introduces two key ideas: (1) Relaxing the fairness window: GIFT breaks away from the traditional concept of instantaneous fairness at each I/O request, and instead, ensures fairness over multiple I/O phases and runs of an application. This opportunity is enabled by exploiting the observation that HPC applications have multiple I/O phases during a run and are highly repetitive, often exhibiting similar behavior across runs; and (2) Throttle-and-reward approach for I/O bandwidth allocation: GIFT opportunistically throttles the I/O bandwidth of certain applications at times in an attempt to improve the overall effective system I/O bandwidth (i.e., it minimizes the wasted I/O bandwidth that does not contribute toward synchronous I/O progress). GIFTs throttle-and-reward approach intelligently exploits instantaneous opportunities to improve effective system I/O bandwidth. Further, relaxing the fairness window enables GIFT to reward the throttled application at a later point to ensure fairness.</p>
    <p>More GIFT Design and Implementation Details</p>
    <p>IT S</p>
    <p>IN</p>
    <p>TH E</p>
    <p>PA PE</p>
    <p>R !</p>
    <p>Mathematical formulation of throttlefriendly application selection</p>
    <p>Balancing system regret budget vs. stability of throttling decisions</p>
    <p>Details of bandwidth allocation optimization solution</p>
    <p>Design parameters and their impact</p>
    <p>GIFT prototype implementation details</p>
  </div>
  <div class="page">
    <p>Evaluation and Analysis</p>
  </div>
  <div class="page">
    <p>Experimental Methodology</p>
    <p>FUSE-based prototype for</p>
    <p>testbed-based evaluation</p>
    <p>Testbed evaluation uses job characteristics from Stampede2, Mira and Theta supercomputers:</p>
    <p>Number of nodes, compute time, amount of data I/O, I/O interval, job inter-arrival time, backfilling scheduling</p>
    <p>strategy, etc.</p>
    <p>Refer to the paper for more details and simulation-based set-up.</p>
  </div>
  <div class="page">
    <p>Min. B/W Waste (MBW)</p>
    <p>Basic Synch-I/O Progress (BSIP)</p>
    <p>Per-OST Fair Share (POFS)</p>
    <p>Competing Strategies</p>
    <p>A A A</p>
    <p>B</p>
    <p>D D</p>
    <p>C</p>
    <p>B</p>
    <p>E</p>
    <p>POFS BSIP</p>
    <p>A A A</p>
    <p>B</p>
    <p>D C</p>
    <p>B</p>
    <p>E</p>
    <p>D</p>
    <p>OST 1 OST 2 OST 3OST 1 OST 2 OST 3</p>
    <p>MBW</p>
    <p>A A A</p>
    <p>B</p>
    <p>DD C</p>
    <p>B</p>
    <p>OST 1 OST 2 OST 3</p>
    <p>B / W</p>
    <p>Throttle Randomly (RND) Throttle Small App (TSA)</p>
    <p>Other selective-throttle/expand-focused heuristics</p>
    <p>Throttle Most Frequent App (TMF) Expand Small App (ESA)</p>
  </div>
  <div class="page">
    <p>GIFT improves system I/O bandwidth, mean app IO time and runtime</p>
    <p>GIFT real-system prototype improves the system bandwidth my more than 15% and app I/O time by more than 10%, compared to POFS.</p>
  </div>
  <div class="page">
    <p>GIFTs fairness is comparable to BSIP and is much fairer than MBW</p>
    <p>POFS is the baseline for fairness.</p>
  </div>
  <div class="page">
    <p>GIFTs fairness is comparable to BSIP and is much fairer than MBW</p>
    <p>POFS is the baseline for fairness. Avg. I/O time degradation for degraded apps is only</p>
  </div>
  <div class="page">
    <p>Simulation-based results confirm real-system prototype results</p>
    <p>Simulation results show even larger improvements because (1) longer time window, and (2) larger system scale.</p>
    <p>GIFT can even improve the overall system throughput.</p>
  </div>
  <div class="page">
    <p>GIFT is not inherently biased against certain types of I/O behaviors.</p>
    <p>Applications with different I/O behaviors observe an improvement with GIFT</p>
  </div>
  <div class="page">
    <p>GIFT needs to award outstanding compute node hours for coupons which are not redeemed. GIFT can bound these hours</p>
    <p>at a low-level even under pessimistic scenarios.</p>
    <p>GIFTs system regret budget needed to award outstanding hours is low(a) Mean App I/O Time (b) Mean App Runtime (c) Effective System I/O B/w (d) System Throughput</p>
    <p>Figure 7: GIFTs implementation provides improvement for both application- and system- level objectives (higher is better).</p>
    <p>Scheduling Policies. We evaluate GIFT against seven competing I/O scheduling policies: Per-OST Fair Share (POFS), Basic Synchronous I/O Progress (BSIP), Minimum Bandwidth Wastage (MBW), Throttle Small Applications (TSA), Expand Small Applications (ESA), Throttle Most Frequent Applications (TMF), and Throttle Randomly (RND). POFS, BSIP, and MBW are implemented as discussed in Sec. 2. TSA attempts to increase the effective system bandwidth by throttling small applications, while ESA attempts to improve the system throughput by increasing the bandwidth allocation for longer-running, smaller applications that generally do small I/O [2, 4, 5]. We also compare against other simple, intuitive strategies such as TMF and RND, which pick the most frequently appearing and random applications for bandwidth throttling, respectively. POFS is used as the baseline policy.</p>
    <p>Objective Metrics. Application I/O Time is the amount of time spent in I/O by an application during its run. Application Run Time is the run time of the application. Effective System Bandwidth is the average effective I/O bandwidth during the run of an application set, defined as overall system bandwidth minus the wasted bandwidth (Sec. 2). System Throughput is the number of jobs completed per unit time.</p>
    <p>GIFTs real-system implementation provides better application- and system- level performances. First, our results show that GIFT outperforms all competing techniques significantly. Fig. 7 (a)-(d) show that GIFT performs better for mean application I/O time, mean application runtime, effective system bandwidth, and system throughput, respectively. The mean application I/O time with GIFT is 10% better than with POFS, and 3.5% better than the next best technique, BSIP. Interestingly, when applications are throttled based on their characteristics (TSA, ESA, and TMF), or are arbitrarily throttled (RND), the performance remains similar to that of BSIP. This shows that nave, rule-based techniques cannot match the performance delivered by the GIFT approach.</p>
    <p>GIFT also improves the effective system bandwidth by more than 17% compared to POFS and other techniques, except MBW. Expectedly, MBW improves the effective system bandwidth the highest because it solely focuses on this metric. Next, we note that by compromising fairness one could design techniques that solely focus on improving system throughput (e.g., favor small jobs). GIFT does not compromise fairness,</p>
    <p>Figure 8: GIFT implementation bounds outstanding node-hours using application- and system-level redemption rate thresholds.</p>
    <p>and it neither directly manipulates nor aims to improve the system job throughput, but by virtue of reducing I/O bandwidth waste and mean application I/O time, GIFT yields 2% improvement in system throughput. We note that even a small improvement in system throughput leads to large monetary savings in operational cost of HPC systems [18, 71, 84].</p>
    <p>Next, we recall that GIFT gives out compute node-hours as regret, but it is minimal compared to the system throughput improvement it enables (2% savings in total compute nodehours). Fig. 8 shows that GIFT gave out less than 0.06% hours of total compute node-hours from the system regret budget in a more than two-day long experimental run  this result shows that application- and system-level redemption rate thresholds keep the system regret budget under control. Even if one were to award outstanding node-hours every day, GIFT would give out only 0.12% of node-hours, which is much smaller than the gains in system throughput (2%); this trend is also later supported by simulation results.</p>
    <p>Next, we discuss the effectiveness of GIFT in terms of fairness. First, recall that the design of GIFT introduces two ideas: (1) opportunistically rewarding applications, and (2) compensating unfairness in I/O performance via additional compute hours. These ideas do not naturally align with the traditional notion of fairness - where a scheme tends to distribute the benefits equally among all applications and the currency of fairness measurement remains the same. In contrast, GIFT is designed to distribute the benefit opportunistically among applications because, as discussed earlier, distributing the benefits equally among all applications leads to benefit (system bandwidth) wastage due to non-synchronous I/O progress. GIFT achieves fairness by compensating I/O unfairness with compute resources. Therefore, GIFTs performance cannot be directly compared with POFS to establish its fairness effectiveness. Nevertheless, we provide this comparison for completeness and to demonstrate that GIFT is not unfair.</p>
    <p>Testbed evaluation Simulation evaluation</p>
  </div>
  <div class="page">
    <p>GIFT is open-sourced at https://github.com/GoodwillComputingLab/GIFT</p>
    <p>Where is my gift in all this?</p>
  </div>
</Presentation>
