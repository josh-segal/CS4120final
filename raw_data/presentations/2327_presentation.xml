<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>On-demand, Spot, or Both: Dynamic Resource Allocation for Executing</p>
    <p>Batch Jobs in the Cloud</p>
    <p>Ishai Menache (MSR)</p>
    <p>Ohad Shamir (Weizmann)</p>
    <p>Navendu Jain (MSR)</p>
    <p>ICAC2014</p>
  </div>
  <div class="page">
    <p>Background</p>
    <p>Cloud is a growing business</p>
    <p>More purchasing options, more variety</p>
    <p>Which/when/where resource should I rent??</p>
    <p>Pricing calculators, auto-scale mechanisms exist, but not enough</p>
    <p>Need to automatically adjust purchasing decisions as a function of dynamically evolving conditions/workloads.</p>
  </div>
  <div class="page">
    <p>Background</p>
    <p>This work: Automated resource allocation for batch jobs</p>
    <p>Focus on compute instances</p>
    <p>Available options:</p>
    <p>On-demand</p>
    <p>Spot</p>
    <p>Reserved (not in this work)</p>
  </div>
  <div class="page">
    <p>The basic tradeoff</p>
    <p>On demand: guaranteed, but expensive</p>
    <p>Spot: usually cheaper, but interruptions/delays</p>
    <p>EC2 case studies  Spot instances are often used</p>
    <p>However no principled mechanisms to choose between on-demand and spot instances.7/2/2014 4</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>The model (jobs, allocations)</p>
    <p>The online-learning algorithm</p>
    <p>Experiments</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>The job model</p>
    <p>Arrival (A)</p>
    <p>Job size (z) [instance hr]</p>
    <p>Parallelism constraint (c)</p>
    <p>Value function</p>
    <p>E.g., strict deadline (d)</p>
    <p>Utility: ()-Cost(resources)</p>
    <p>Objective: Maximize job utilities</p>
    <p>instances</p>
    <p>z</p>
    <p>timedA</p>
    <p>c</p>
  </div>
  <div class="page">
    <p>Job resource allocation</p>
    <p>For simplicity, we restrict attention to single size</p>
    <p>Decisions per job: # on-demand, [# spot, bid]</p>
    <p>Can modify decisions every hour</p>
    <p>Allocation/payment</p>
    <p>On-demand:</p>
    <p>Fixed price per-instance-hr</p>
    <p>Spot:</p>
    <p>Varying price (e.g., 5 min resolution)</p>
    <p>Get instances (and pay) only if bid above market price</p>
    <p>Pay the market price</p>
    <p>market price</p>
    <p>hr</p>
    <p>bid</p>
  </div>
  <div class="page">
    <p>Algorithm in a nutshell</p>
    <p>A set of parameterized policies</p>
    <p>Attach a policy to each arriving job</p>
    <p>Policy picked at random  Successful policies have higher probability of being</p>
    <p>chosen</p>
    <p>Probabilities updated after each job departure</p>
    <p>Online-learning algorithm is essentially about how to update the probabilities.  Ensures good performance even though we don't</p>
    <p>know in advance which policies will work well</p>
  </div>
  <div class="page">
    <p>Parameterized policies</p>
    <p>demand when M hours from deadline b. Rate-centric: Fixed rate   [0,1] of on-demand</p>
    <p>instances</p>
    <p>b. Variable bid</p>
    <p>+</p>
    <p>Policy: deadline/rate centric + Fixed/variable bid</p>
  </div>
  <div class="page">
    <p>Online-learning algorithm</p>
    <p>Main loop: for each job j  For each policy</p>
    <p>Calculate</p>
    <p>Set    ()</p>
    <p>Note: () cannot be evaluated immediately  delayed feedback</p>
    <p>Delayed feedback not standard in onlinelearning  required developing a tailored algorithm</p>
  </div>
  <div class="page">
    <p>Algorithm guarantees</p>
    <p>Criterion: Regret</p>
    <p>max</p>
    <p>()</p>
    <p>()</p>
    <p>Theorem: Regret vanishes to zero as total number of jobs (J) increases</p>
    <p>Regret proportional to 1/sqrt(J)</p>
    <p>Policy chosen by alg for job j</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Simplified assumptions:</p>
    <p>No checkpointing overhead</p>
    <p>No delays in obtaining requested instances</p>
    <p>Synthetic data</p>
    <p>Facilitates debugging the algorithm</p>
    <p>Real data</p>
    <p>EC2 spot-price history</p>
    <p>Map-reduce job traces</p>
  </div>
  <div class="page">
    <p>Simulations - synthetic data</p>
    <p>Setup:</p>
    <p>A pool of hundreds of policies</p>
    <p>Job size drawn uniformly at random</p>
    <p>Deadline/value also drawn at random, proportionally to size</p>
    <p>Spot price is a stochastic process; in each experiment, we change its characteristics</p>
  </div>
  <div class="page">
    <p>Simulations - synthetic data</p>
    <p>on-demand price is 0.25</p>
    <p>Experiment 1: Relatively low spot price (0.1+0.05x, where x is a Gaussian RV)  Outcome: Algorithm</p>
    <p>converges to using only spot instances with fixed bid=0.25.</p>
    <p>chosen policy</p>
  </div>
  <div class="page">
    <p>Simulations - synthetic data</p>
    <p>Experiment 2: spot-price as before for first 10% of jobs, then becomes 0.2+0.05x  Outcome: algorithm converges to using only on-demand instances</p>
    <p>alg</p>
  </div>
  <div class="page">
    <p>Simulations - synthetic data</p>
    <p>Experiment 3:</p>
    <p>We let the spot price alternate between 0 for an hour and 0.3 for the next hour</p>
    <p>Best policies are variable-bid policies with  = 0 (price prediction based only on the last price)</p>
  </div>
  <div class="page">
    <p>Simulations  real data</p>
    <p>Setup:</p>
    <p>Translate map-reduce jobs to our job model</p>
    <p>Deadline taken as the job actual termination time from traces</p>
    <p>Value added synthetically</p>
  </div>
  <div class="page">
    <p>Simulations  real data</p>
    <p>Spot-price as shown below</p>
    <p>Policy evolvement  first, alg uses both fixed and variable bid policies; however, when price becomes more stable, alg prefers fixed bid strategies</p>
    <p>Avg regret of our alg is 34 times better than the average regret</p>
  </div>
  <div class="page">
    <p>Related work</p>
    <p>Building statistical models for spot-prices [BBST13, JTB11]</p>
    <p>On-demand/spot assignment for bag of tasks [VOK13]</p>
    <p>Reserved instances [SDIE13]</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Online learning algorithm for choosing between on-demand and spot instances</p>
    <p>+ No probabilistic assumptions</p>
    <p>+ Incorporates a variety of policies</p>
    <p>+ Incorporates job deadlines</p>
    <p>+ Can be extended to many other resource allocation scenarios in cloud computing</p>
    <p>Future directions:</p>
    <p>More scenarios</p>
    <p>Including reserved instances 7/2/2014 20</p>
  </div>
</Presentation>
