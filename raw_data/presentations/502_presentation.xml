<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Shuoyang Ding Hainan Xu Philipp Koehn</p>
    <p>The Fourth Conference on Machine Translation Florence, Italy</p>
    <p>August 1st, 2019</p>
  </div>
  <div class="page">
    <p>Revisiting Six Challenges  poor out-of-domain performance</p>
    <p>poor low-resource performance</p>
    <p>low frequency words</p>
    <p>long sentences</p>
    <p>attention is not word alignment</p>
    <p>large beam does not help</p>
    <p>[Koehn and Knowles 2017]</p>
  </div>
  <div class="page">
    <p>Revisiting Six Challenges  poor out-of-domain performance</p>
    <p>poor low-resource performance</p>
    <p>low frequency words</p>
    <p>long sentences</p>
    <p>attention is not word alignment  large beam does not help</p>
    <p>[Koehn and Knowles 2017]</p>
  </div>
  <div class="page">
    <p>A Model Interpretation Problem</p>
  </div>
  <div class="page">
    <p>A Model Interpretation Problem</p>
  </div>
  <div class="page">
    <p>Related Findings Outside MT</p>
    <p>Attention is not Explanation [Jain and Wallace NAACL 2019]</p>
    <p>Is Attention Interpretable? (Spoiler: No) [Serrano and Smith ACL 2019]</p>
    <p>We also have empirical results that corroborate these findings.</p>
    <p>and we have method that works better!</p>
  </div>
  <div class="page">
    <p>Saliency: Identifying Important Features</p>
  </div>
  <div class="page">
    <p>Recap</p>
  </div>
  <div class="page">
    <p>Recap</p>
  </div>
  <div class="page">
    <p>Focus on solten</p>
  </div>
  <div class="page">
    <p>Perturbation</p>
  </div>
  <div class="page">
    <p>Perturbation</p>
  </div>
  <div class="page">
    <p>Assumption</p>
    <p>The output score is more sensitive to perturbations in important features.</p>
  </div>
  <div class="page">
    <p>E.g.</p>
  </div>
  <div class="page">
    <p>E.g.</p>
  </div>
  <div class="page">
    <p>E.g.</p>
  </div>
  <div class="page">
    <p>Saliency</p>
  </div>
  <div class="page">
    <p>Saliency</p>
    <p>when :</p>
  </div>
  <div class="page">
    <p>Saliency</p>
  </div>
  <div class="page">
    <p>Whats good about this?</p>
  </div>
  <div class="page">
    <p>Prior Work on Saliency</p>
    <p>Widely used and studied in Computer Vision! [Simonyan et al. 2013][Springenberg et al. 2014] [Smilkov et al. 2017]</p>
    <p>Also in a few NLP work for qualitative analysis [Aubakirova and Bansal 2016][Li et al. 2016][Ding et al. 2017] [Arras et al. 2016;2017][Mudrakarta et al. 2018]</p>
  </div>
  <div class="page">
    <p>SmoothGrad  Gradients are very local measure of sensitivity.</p>
    <p>Highly non-linear models may have pathological points where the gradients are noisy.</p>
    <p>Solution: calculate saliency for multiple copies of the same input corrupted with gaussian noise, and average the saliency of copies.</p>
    <p>[Smilkov et al. 2017]</p>
  </div>
  <div class="page">
    <p>Establishing Saliency for Words</p>
  </div>
  <div class="page">
    <p>Feature in Computer Vision</p>
    <p>Photo Credit: Hainan Xu</p>
  </div>
  <div class="page">
    <p>Feature in NLP</p>
    <p>Its straight-forward to compute saliency for a single dimension of the word embedding.</p>
  </div>
  <div class="page">
    <p>Feature in NLP</p>
    <p>But how to compose the saliency of each dimension into the saliency of a word?</p>
  </div>
  <div class="page">
    <p>Our Proposal</p>
    <p>Consider word embedding look-up as a dot product between the embedding matrix and an one-hot vector.</p>
  </div>
  <div class="page">
    <p>Our Proposal</p>
    <p>The 1 in the one-hot vector denotes the identity of the input word.</p>
  </div>
  <div class="page">
    <p>Our Proposal</p>
    <p>Lets perturb that 1 like a real value! i.e. take gradients with regard to the 1.</p>
  </div>
  <div class="page">
    <p>Our Proposal</p>
    <p>i</p>
    <p>ei  y ei</p>
    <p>(, )range:</p>
  </div>
  <div class="page">
    <p>Experiment</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Evaluation of interpretations is tricky!</p>
    <p>Fortunately, theres human judgments to rely on.</p>
    <p>Need to do force decoding with NMT model.</p>
  </div>
  <div class="page">
    <p>Setup</p>
    <p>Architecture: Convolutional S2S, LSTM, Transformer (with fairseq default hyperparameters)</p>
    <p>Dataset: Following Zenkel et al. [2019], which covers de-en, fr-en and ro-en.</p>
    <p>SmoothGrad hyper-parameters: N=30 and =0.15</p>
  </div>
  <div class="page">
    <p>Baselines  Attention weights</p>
    <p>Smoothed Attention: forward pass on multiple corrupted input samples, then average the attention weights over samples</p>
    <p>[Li et al. 2016]: compute element-wise absolute value of embedding gradients, then average over embedding dimensions</p>
    <p>[Li et al. 2016] + SmoothGrad</p>
  </div>
  <div class="page">
    <p>Convolutional S2S on de-en</p>
    <p>A ER</p>
    <p>A tt</p>
    <p>en tio</p>
    <p>n</p>
    <p>Sm oo</p>
    <p>th ed</p>
    <p>A tt</p>
    <p>en tio</p>
    <p>n</p>
    <p>Li +G</p>
    <p>ra d</p>
    <p>Li +S</p>
    <p>m oo</p>
    <p>th G</p>
    <p>ra d</p>
    <p>O ur</p>
    <p>s+ G</p>
    <p>ra d</p>
    <p>O ur</p>
    <p>s+ Sm</p>
    <p>oo th</p>
    <p>G ra</p>
    <p>d</p>
    <p>fa st</p>
    <p>-a lig</p>
    <p>n</p>
    <p>Ze nk</p>
    <p>el e</p>
    <p>t a l.</p>
    <p>[2 01</p>
    <p>G IZ</p>
    <p>A ++</p>
  </div>
  <div class="page">
    <p>Attention on de-en</p>
    <p>A ER</p>
    <p>C on</p>
    <p>v</p>
    <p>LS TM</p>
    <p>Tr an</p>
    <p>sf or</p>
    <p>m er</p>
    <p>fa st</p>
    <p>-a lig</p>
    <p>n</p>
    <p>Ze nk</p>
    <p>el e</p>
    <p>t a l.</p>
    <p>[2 01</p>
    <p>G IZ</p>
    <p>A ++</p>
  </div>
  <div class="page">
    <p>Ours+SmoothGrad on de-en</p>
    <p>A ER</p>
    <p>C on</p>
    <p>v</p>
    <p>LS TM</p>
    <p>Tr an</p>
    <p>sf or</p>
    <p>m er</p>
    <p>fa st</p>
    <p>-a lig</p>
    <p>n</p>
    <p>Ze nk</p>
    <p>el e</p>
    <p>t a l.</p>
    <p>[2 01</p>
    <p>G IZ</p>
    <p>A ++</p>
  </div>
  <div class="page">
    <p>Li vs. Ours</p>
  </div>
  <div class="page">
    <p>Li vs. Ours</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Conclusion  Saliency + proper word-level score formulation is a</p>
    <p>better interpretation method than attention</p>
    <p>NMT models do learn interpretable alignments. We just need to properly uncover them!</p>
    <p>Paper Code Slides</p>
    <p>https://github.com/shuoyangd/meerkat</p>
  </div>
</Presentation>
