<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Yizhi Liu*, Yao Wang*, Ruofei Yu, Mu Li, Vin Sharma, Yida Wang</p>
    <p>Amazon Web Services</p>
    <p>*Equal contribution</p>
    <p>Optimizing CNN Model Inference on CPUs</p>
  </div>
  <div class="page">
    <p>Convolutional Neural Network</p>
  </div>
  <div class="page">
    <p>Optimization  Optimization in existing work mostly focus on single operator acceleration.  We consider tensor-level and graph-level joint optimization.</p>
  </div>
  <div class="page">
    <p>Performance Our solution (NeoCPU) achieved competitive performance and scalability across various of cloud and edge CPUs.</p>
  </div>
  <div class="page">
    <p>Optimizing CNN Model Inference on CPUs</p>
    <p>USENIX ATC 19</p>
  </div>
</Presentation>
