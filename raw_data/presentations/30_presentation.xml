<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Yale University Department of Computer Science</p>
    <p>On Self Adaptive Routing in Dynamic Environments  An Evaluation and Design Using a Simple, Probabilistic Scheme</p>
    <p>Haiyong Xie Yale University</p>
    <p>Lili Qiu Microsoft Research</p>
    <p>Yang Richard Yang Yale University</p>
    <p>Yin Zhang AT&amp;T  Research</p>
    <p>YALEU/DCS/TR-1289 July 2004</p>
  </div>
  <div class="page">
    <p>On Self Adaptive Routing in Dynamic Environments  An Evaluation and Design Using a Simple, Probabilistic Scheme</p>
    <p>Haiyong Xie Yale University</p>
    <p>Lili Qiu Microsoft Research</p>
    <p>Yang Richard Yang Yale University</p>
    <p>Yin Zhang AT&amp;T  Research</p>
    <p>Abstract</p>
    <p>Recently we have seen an emergent trend of self adaptive routing in both Internet and wireless ad hoc networks. Although there are previous methods for computing the traffic equilibria of self adaptive routing (e.g., selfish routing), these methods use computationally demanding algorithms and require that a precise analytical model of the network be given. Also, it remains an open question how to design an adaptive routing scheme which ensures convergence to traffic equilibria in practice. In this paper we propose a simple, efficient, distributed probabilistic routing scheme for self adaptive routing in dynamic, realistic environments. Using both analysis and extensive simulations, we show that our scheme can converge to the desired traffic equilibrium (either useroptimal or network-optimal) very quickly. We find that user-optimal routing can achieve very close to optimal average latency in dynamic environments, but such performance often comes at the cost of seriously overloading certain links. To avoid link overloads, we improve adaptive routing by optimizing average user latency and link utilization simultaneously. Our evaluation shows that there is a trade-off between optimizing dual objectives, but the degradation in average latency is only marginal for typical link utilization requirements.</p>
    <p>Recently we have seen an emergent trend of adaptive routing in both Internet and wireless ad hoc networks. In Internet, recent studies [32, 36] have shown that there is inherent inefficiency in IP routing from the users perspectives. In response to this observation, we have seen a trend to allow end hosts to adaptively choose routes themselves either by using source routing (e.g., Nimrod [14]) or by using overlay routing (e.g., Detour [32] or RON [2]). Such end-to-end route selection is self adaptive, in that it allows end users to select routes to optimize their own performance without considering system-wide criteria [28]. In wireless ad hoc networks, source routing, such as DSR [19], allows wireless users to selfishly select low-latency routes (e.g., [18]), thus resulting in self adaptive routing. This emergence of self adaptive routing poses challenging research questions regarding both design of routing protocols and evaluation of traffic equilibrium behavior.</p>
    <p>In terms of design of routing protocols, it remains an open research question how to design an adaptive routing scheme that ensures convergence to traffic equilibria in realistic settings. Although there are several previous designs, some fundamental issues remain to be addressed. In particular, it is unclear how adaptive routing schemes should probe the network in order to effectively discover efficient routes. If a protocol uses an ineffective probing scheme, high-quality routes may not be discovered. Furthermore, it is unclear how the routing paths should be adjusted in a distributed way and still converge to the optimal paths without causing oscillations.</p>
    <p>In terms of evaluation of traffic equilibrium behavior, an important yet challenging question is how to evaluate the performance of self adaptive routing in large networks. While there is previous work on this subject from both theoretical perspectives (e.g., [23, 30]) and practical perspectives (e.g., [28]), several issues remain to be addressed. First, how to efficiently compute traffic equilibria in large networks is an open problem. The traditional algorithms</p>
  </div>
  <div class="page">
    <p>used to derive traffic equilibria (e.g., the Frank Wolfe algorithm [15]) are computationally expensive, and hard to scale to large networks. Second, such algorithms require an analytical model of the network, e.g., link latency functions, be known, which may not be the case. For example, there are no simple analytical expressions for packet delay in wireless networks, where delay is caused by queuing, MAC layer contention, and retransmissions. Moreover, such algorithms can derive equilibria only in a static environment. In reality, networks can be highly dynamic and routing works in a distributed fashion. So it is important to capture the dynamic process.</p>
    <p>In this paper, we propose a routing scheme to address the above issues. Our scheme has the following requirements. First, viewed as a mechanism for computing equilibrium, the scheme should be simple and efficient, and thus can be used to evaluate large scale networks. It should not require a precise network model, and thus can be applied in various settings (i.e., both wired and wireless networks). It should also be able to model adaptive routing in a dynamic environment, and be able to capture the potential overhead of adaptive routing. Second, viewed as a protocol for computing network routes, the scheme should be distributed and with low protocol overhead. The design should provide insight in designing adaptive routing protocols with different objectives (e.g., user optimal or network optimal). The protocol should address the key issues of how to probe networks and how to adjust routing paths to guarantee convergence.</p>
    <p>Specifically, the routing scheme we propose and study in this paper is a probabilistic routing scheme. On the data path, each packet is forwarded to a neighbor picked according to a probability distribution defined for each destination. Our scheme keeps states only for destinations with active traffic, and thus the state overhead is low. On the control path, a protocol resembling distance-vector routing maintains these probabilities. Upon receiving a routing update from a neighbor, a router updates its routing probabilities.</p>
    <p>Our probability update scheme is motivated by the two time-scale stochastic approximation scheme proposed by Borkar and Kumar in [10] and the Q-routing scheme proposed by Littman and Boyan in [26]. However, these two schemes use path-based per-packet feedback and update. As a consequence, their protocols require the cooperation between the routing layer and the transport layer. Furthermore, the routing overhead of their protocols can be high. In comparison, our scheme aggregates routing updates; thus the overhead of our scheme is comparable to that of a load-adaptive routing scheme such as QoS routing. In a low-load environment (e.g., one where the latency of a link is not sensitive to the amount of traffic), our update algorithm is equivalent to the distributed Bellman-Ford algorithm [5].</p>
    <p>Our update scheme is also motivated by the distributed gradient projection algorithms, e.g., see [4, 7, 17, 31, 37, 38, 39]. However, these algorithms assume quasi-static environments, namely, the effect of a routing update can be observed immediately, while our scheme allows the effects of routing updates to settle down gradually. Thus our scheme captures network dynamics, and can be both a computing scheme and a realistic routing scheme. Also, our routing scheme is probabilistic and has lower complexity than the previous gradient projection algorithms, which are deterministic.</p>
    <p>We use our scheme to implement two types of adaptive routing: user-optimal routing and network-optimal routing. The user-optimal routing converges to the Wardrop equilibria [40] in the Cesaro sense, where at Wardrop equilibria, users do not have incentives to unilaterally change their routes. The network-optimal routing converges to the minimum latency. The former is achieved by having neighbors exchange information about link latency, while the latter is achieved by having neighbors exchange information about marginal link latency.</p>
    <p>We analyze the convergence of our scheme and evaluate its dynamics through extensive simulations. Our simulations show that our routing scheme responds to traffic stimuli (whether in the form of impulse, or step function, or linear function) and converges to new equilibria very quickly.</p>
    <p>Utilizing our efficient routing scheme, we study how to choose routes to optimize end-user performance and link utilization simultaneously. This is an important problem in traffic engineering for adaptive networks [28], because optimizing end-user performance alone sometimes causes link overload (which is undesirable from network operators point of view), while optimizing network utilization alone may degrade end-user performance. To achieve good user performance without overloading the network, we introduce a link utilization threshold. We</p>
  </div>
  <div class="page">
    <p>update the routing probabilities as before when the utilization of a link is below the threshold; on the other hand, when the utilization of a link is above the threshold, we shift traffic to less loaded links. We evaluate the trade-off between user latency and link utilization and show that the degradation in end-user performance is only marginal for typical link utilization requirements.</p>
    <p>In summary, our contributions are as follows.</p>
    <p>First, we develop a routing scheme to achieve user-optimal routing and network-optimal routing. This scheme can be used both as a simple, efficient computing mechanism to compute traffic equilibrium in a dynamic network without a precise analytical model, and as a routing scheme to determine network routes in a distributed way.</p>
    <p>Second, we prove the convergence of our routing scheme, and demonstrate its efficiency and responsiveness using extensive simulations.</p>
    <p>Third, we extend the routing scheme to optimize both end-user performance and link utilization simultaneously. Our evaluation shows that the routing scheme is able to achieve low link utilization while maintaining good end-user performance.</p>
    <p>The remainder of this paper is organized as follows. In Section 2, we describe our routing scheme. In Section 3, we analyze the convergence of our scheme for implementing user-optimal routing and network-optimal routing. In Section 4, we describe our evaluation methodology. We present extensive evaluations on the performance and dynamics of the routing scheme in Section 5. We examine how to optimize end-user performance and link utilization simultaneously in Section 6. We discuss related work in Section 7 and conclude in Section 8.</p>
    <p>The routing scheme we consider consists of a data-path component and a control-path component. The datapath component is common while the control-path component is different for different routing objectives.</p>
    <p>We first present the data path. Consider node i in the network. Assume that node i has n(i) neighbors, represented by the set N(i).</p>
    <p>p j ik</p>
    <p>dest. k</p>
    <p>neigh. j</p>
    <p>Figure 1. Forwarding table of node i.</p>
    <p>Similar to distance-vector routing, the routing scheme we consider maintains states for active destinations. In other words, the forwarding table of node i consists of one row for each active destination. The active destinations may be all overlay nodes in an overlay network or all active sinks in a wireless ad hoc network. Below when we say destinations, we mean active destinations. Figure 1 illustrates the forwarding table of node i.</p>
    <p>For destination k, node i maintains a routing probability pikj for each neighbor j. Note that</p>
    <p>j p ik j = 1</p>
    <p>and pikj  0. Whenever node i receives a packet destined to node k, it forwards the packet to neighbor j with probability pikj .</p>
  </div>
  <div class="page">
    <p>Note that this probabilistic routing scheme generalizes the normal Internet routing. More specifically, if only one neighbor has a positive routing probability, the probability must be 1, and thus we have the traditional singlepath routing. We can also implement the scheme of OSPF routing with equal-weight splitting by assigning equal probabilities to the neighbor(s) on the shortest path(s) to a given destination.</p>
    <p>The forwarding table of a node is updated by the control path. We consider two implementations of the control path: the first one achieves user-optimal routing, while the second one achieves network-optimal routing.</p>
    <p>User-optimal routing is also called Wardrop routing [40, 1, 3], which is defined in the context of transportation networks as follows [40]: The journey times on all the routes actually used are equal and less than those which would be experienced by a single vehicle on any unused route. Wardrop routing is especially interesting since it achieves traffic equilibria when each user individually optimizes the performance of its traffic. In other words, at a Wardrop equilibrium, users do not have incentives to unilaterally change their routes.</p>
    <p>In the context of computer networks, we define user-optimal routing in a similar way. For a given demand, i.e., a source-destination pair with a given amount of traffic, the routes with positive traffic should have equal latency, no larger than those of the routes not used for this particular source-destination pair.</p>
    <p>Note that although user-optimal routing is a multi-path routing scheme, in this situation the paths used have the same latency, so the chance of packet re-ordering is low, and therefore the potential performance penalty at the transport layer, e.g., TCP, is small. In addition, several TCP enhancements have been proposed to cope with packet re-ordering under multi-path routing(e.g., [8] and [42]).</p>
    <p>To achieve user-optimal routing, we implement the control path asynchronously, where each node sends its updates to its neighbors after some delay. Note that our protocol is asynchronous. Below we describe the implementation at a given node i.</p>
    <p>First, for destination k, node i maintains the following data items for each neighbor j:</p>
    <p>The latency lij of the link from node i to its neighbor j. This latency consists of propagation delay and the average queuing delay during the interval between the previous update and the current time. It is also possible that the receiver j maintains lij. We will further discuss how to measure l</p>
    <p>i j at the end of this</p>
    <p>subsection.</p>
    <p>The estimated delay, Likj , from i to destination k through node j. Node i also receives the most recently reported latency Ljk from neighbor j. Note that this report is generated by node j at sometime in the past. Also note that destination k always reports zero delay to itself.</p>
    <p>The internal probability qikj from node i to destination k through neighbor j. This probability is used mainly for internal update. As we will show later in Section 3.3, the set of internal probabilities {qikj } converges (in the Cesaro sense) with probability one to the set of Cesaro-Wardrop equilibria, which is an extension to the notion of a Wardrop equilibrium as introduced in [10].</p>
    <p>The routing probability pikj from node i to destination k through neighbor j. Note that the routing probability will change after each update and remain the same until next update. As we will show later, the set of routing probabilities {pikj } are -approximate of {q</p>
    <p>ik j } and thus will converge to the set of -approximate Cesaro</p>
    <p>Wardrop equilibria with probability one.</p>
    <p>After receiving the n-th update Ljk from neighbor j at time ikj (n), node i first updates its delay estimation of Likj , i.e., the estimated delay to destination k through node j. This update has two steps. Node i first computes the</p>
  </div>
  <div class="page">
    <p>value of a new sample: ikj = l</p>
    <p>i j + L</p>
    <p>jk. (1)</p>
    <p>Then it updates the new delay estimation as:</p>
    <p>Likj = (1  (n))L ik j + (n)</p>
    <p>ik j , (2)</p>
    <p>where (n)  [0, 1] is the delay learning factor. Note that we take ikj as current delay sample with noise. Therefore, we use (2) to adapt delay estimation and make it robust in the presence of noise. When (n) is larger, delay estimation is more sensitive to noise; however, (n) cannot be too small. Otherwise, delay estimation is not responsive enough to network dynamics.</p>
    <p>Node i then computes its overall delay estimation Lik to destination k as:</p>
    <p>Lik =</p>
    <p>jN(i)</p>
    <p>pikj L jk j , (3)</p>
    <p>where N(i) represents the set of node is neighbors. Node i reports Lik to its neighbors after some delay. This delay is a random value between T/2 and T to avoid routing update synchronization, where T is a constant.</p>
    <p>Node i then updates its internal routing probabilities as follows. Suppose that this is the n-th time node i updates its routing probabilities. For all neighbors j, node i computes:</p>
    <p>qikj = q ik j + (n</p>
    <p>)[qikj (L ik  Likj ) +</p>
    <p>ik j ], (4)</p>
    <p>where (n) &gt; 0 is the routing learning factor for the n-th update, and ikj are i.i.d. random routing vectors distributed uniformly on the unit ball of dimension N(i). The objective of adding the i.i.d. uniform random routing vectors is to add disturbance to avoid non-Wardrop solutions. Note that we use (n) and (4) to smooth out the noise in estimations.</p>
    <p>After computing the above routing probabilities, node i projects the routing vector consisting of the routing probabilities to the subspace of [0, 1]N(i), where the sum of the routing probabilities is 1. The reason for the projection is to ensure that the vector is a valid probability vector. That is, node i computes the projected value of the new routing probability by solving the following optimization problem:</p>
    <p>minimize</p>
    <p>jN(i)</p>
    <p>(xj  q ik j )</p>
    <p>subject to</p>
    <p>jN(i)</p>
    <p>xj = 1 (6)</p>
    <p>over 0  xj  1 for all j. (7)</p>
    <p>The computed values of xj then become the new internal routing vector. To ensure that the network probes all possible neighbors, node i computes routing probabilities p from the just</p>
    <p>updated internal routing probabilities q by adding uniform routing probabilities to them:</p>
    <p>pikj = (1  )q ik j +</p>
    <p>N(i) , (8)</p>
    <p>where  is a small constant number. Finally, a few comments about measuring lij. The preceding description specifies that the transmitter (i.e., node</p>
    <p>i) measures lij. To achieve this, node i first measures the (fixed) propagation and transmission delay from node i to node j. Then during the protocol run, node i keeps track of its transmission queue to determine the queueing delay. An alternative is that the receiver j measures lij. Thus instead of sending L</p>
    <p>jk, node j sends ikj to node</p>
  </div>
  <div class="page">
    <p>i. An interesting advantage of this approach is that it does not need clock synchronization among the nodes. Specifically, in order to measure lij, node i time-stamps a packet (with its local clock), and node j computes the link delay of the packet by computing the difference between the time it receives the packet (in its local clock) and that of the time stamp of the packet (when node i receives the packet in its local clock). Thus the estimation of lij may have a constant offset due to the difference between the clocks of nodes i and j, assuming constant clock drift. However, it can be checked that the values of ikj , L</p>
    <p>ik and Likj have an offset which is just the clock difference between node i and the destination, which is independent of node j. Thus due to the structure of the routing probability update (i.e., the update of (4) depends only on Lik  Likj ), the offset is canceled and there is no need for clock synchronization. The overhead of this approach is that it needs to time-stamp packets. In the remaining of the paper we use the first approach for measuring lij. It is easily extended to use the second approach. Figure 2 summarizes the protocol at node i for destination k.</p>
    <p>. Assume pikj is routing probability to neighbor j.</p>
    <p>repeat after some random delay in a range send Lik to all neighbors</p>
    <p>repeat after receiving an update Ljk from neighbor j compute Likj for neighbor j using (2) compute Lik =</p>
    <p>jN(i) p ik j L</p>
    <p>ik j</p>
    <p>using (3) update qik</p>
    <p>j and pik</p>
    <p>j for all neighbors j</p>
    <p>update q according to (4) do projection on q as in (5) compute p as in (8)</p>
    <p>Figure 2. Protocol to implement user-optimal routing.</p>
    <p>Our second implementation is network-optimal routing, which minimizes total latency over all traffic. In [3], Beckmann, McGuire, and Winsten showed that the total latency is minimized if and only if all traffic travels along paths with minimum marginal cost. In network settings, marginal cost is equivalent to marginal link latency, i.e., mcij = l</p>
    <p>i j +f</p>
    <p>i js i j, where s</p>
    <p>i j is the rate of change in the latency from node i to node j at traffic amount f</p>
    <p>i j. Compared</p>
    <p>with user-optimal routing where delays along different paths are minimized, we replace lij with mc i j to achieve</p>
    <p>network-optimal routing. Similar to lij, mc i j is estimated without knowing the analytical expression.</p>
    <p>In this section we analyze the convergence of our routing scheme.</p>
    <p>We first study Figure 3 to gain intuition. The figure shows the phase diagram of a node with two links leading to a given destination. The x-axis is the routing probability of link 2 while the y-axis is the routing probability of link 1. Note that the only valid probability vector will be p1  0, p2  0, and p1 + p2 = 1.</p>
    <p>We identify five cases. In the first three cases, both links have traffic. In case (a), link 1 has higher latency. Thus the probability of link 1 is reduced while that of link 2 is increased. The dashed line points to the updated</p>
  </div>
  <div class="page">
    <p>(c)</p>
    <p>p</p>
    <p>p</p>
    <p>(a)</p>
    <p>(b)</p>
    <p>Figure 3. Illustration of the update on routing probabilities.</p>
    <p>routing probabilities before projection. Then projection along the dotted line brings the routing probabilities back to a valid routing vector satisfying p1  0, p2  0, and p1 + p2 = 1. In case (b), link 1 has lower latency. Thus the probabilities are adjusted and then projected back to the space. In case (c), link 1 and 2 have the same latency and therefore their routing probabilities are not changed. Note that this is a stable state, i.e., the state will no longer change. In the next two cases, one link has no traffic. Without loss of generality, we consider the case that link 1 has all of the traffic while link 2 has no traffic. If the latency of link 1 is smaller than that of link 2 (case (d)), then the algorithm will not change the state of the network. On the other hand, if the latency of link 1 is higher than that of link 2 (case (e)), then the probability of link 2 is increased and the network is on the correct trajectory to the final state.</p>
    <p>l 4 1</p>
    <p>= 3</p>
    <p>l = 12 1</p>
    <p>l = 14 2</p>
    <p>l = 14 3</p>
    <p>l = 33 2</p>
    <p>Figure 4. An example of the need of multi-hop update.</p>
    <p>The above discussion applies to only a single node. A node may stay at a local equilibrium and wait for its downstream nodes to converge. Figure 4 shows an example. In this figure, traffic originates from node 1 to node 4. Routing probabilities, pi4 = [pi4j ]j=1,2,3,4, i = 1, 2, 3, 4, are labeled along with nodes. Node 1 is at (local) equilibrium (namely case (d) if we think the link from node 1 to node 4 as link 1 in the above discussion). However, node 2 is not at equilibrium (namely case (e) if we think the link from node 2 to node 3 as link 1 in the above discussion). Thus the update of node 2 will eventually cause node 1 to update. Our small random probing will allow node 2 to measure the latency from node 2 to node 4.</p>
    <p>We make the following assumptions in our convergence analysis. More technical assumptions on the stochastic process, such as the packet arrival process and network connectivity, can be found in the complete version of this paper [41]. Note that our assumptions are similar to those by Borkar and Kumar in [10], which are standard in the convergence analysis of two time-scale stochastic iterative algorithms [9, 11, 35]. Our delay assumption is similar to that of [38] on asynchronous distributed gradient algorithms.</p>
  </div>
  <div class="page">
    <p>A1 We assume that the latency of the link from node i to node j is represented by the function lij(x), where x is the load of this link. We assume that this function is continuous, non-decreasing, and bounded. We also assume that the latency functions are chosen such that both the user-optimal and network-optimal settings satisfy the monotone condition to guarantee that the network has a unique Wardrop or optimal equilibrium. Note that although we make assumptions about the properties of the latency functions, our protocol does not need to know the analytical expressions.</p>
    <p>A2 We assume that the Feller property holds, i.e., the updates are frequent enough compared with the change rate in the underlying network states. In our protocol, the interval between two updates sent by one node to each of its neighbors is randomly distributed in [T/2, T], where T is a constant. Also, we assume that the number of packets sent in each interval is finite with a constant bound.</p>
    <p>A3 We assume that {(n)} used in delay estimation satisfy the following conditions:</p>
    <p>n : (n)  (n + 1) &gt; 0,</p>
    <p>n</p>
    <p>(n) = ,</p>
    <p>n</p>
    <p>(n)2 &lt; ,</p>
    <p>and</p>
    <p>n</p>
    <p>(((n)  (n + 1))/(n))r &lt;</p>
    <p>for some r  1.</p>
    <p>A4 We assume that {(n)} used in routing probability update satisfy the following conditions:</p>
    <p>n : (n)  (n + 1) &gt; 0,</p>
    <p>n</p>
    <p>(n) = ,</p>
    <p>n</p>
    <p>(n)2 &lt; ,</p>
    <p>and</p>
    <p>n</p>
    <p>((n)/(n))s &lt;</p>
    <p>for some s  1.</p>
    <p>Note that the above assumptions are common for most previous analyses. In particular, the last two assumptions (A3 and A4) are essential to guarantee convergence for stochastic iterative algorithms (see, e.g., [6]). Intuitively, learning factors {(n)} and {(n)} represent the step sizes of updating delay estimation and routing probability, respectively. The sum of step sizes (</p>
    <p>n (n) or</p>
    <p>n (n)) should be unbounded in order to reach equilibrium. On the other hand, the range of</p>
    <p>n  2(n) and</p>
    <p>n  2(n) guarantees that the variance of delay estimation and routing</p>
    <p>probability is bounded. Therefore, diminishing step sizes satisfying the above assumptions guarantees that the stochastic iterative algorithms converge to the solution almost surely. Furthermore, the range of</p>
    <p>n((n)/(n)) s</p>
    <p>guarantees that delay estimation has larger step sizes. In other words, the delay estimation should be relatively stabilized before the next routing probability update occurs. Our algorithm uses varying learning factors. It is possible to use constant learning factors as well. For stochastic approximation algorithms with constant learning factors, we refer interested readers to [35].</p>
  </div>
  <div class="page">
    <p>Consider valid routing probability vectors at all nodes. Let H denote the subset: {y : yikj &gt; 0  L ik j =</p>
    <p>jN(i) y ik j Lik j }. Let Hs denote the set {y  H : y</p>
    <p>ik j &gt; 0  L</p>
    <p>ik j = minjN(i) L</p>
    <p>ik j }.</p>
    <p>Note that we can use L to denote either the true latency or the maintained state. When L is the true latency, Hs is the set of Wardrop equilibria. When L is the maintained state, which is (properly normalized) time average of the true latency, Hs becomes the set of so called Cesaro-Wardrop equilibria [10]. Under a Cesaro-Wardrop equilibrium, a link is assigned a positive flow only if the (properly normalized) time-averaged delay along the link is minimal.</p>
    <p>Below we use L to denote the maintained state and prove the convergence of the internal routing probabilities {qikj } to Hs, the set of Cesaro-Wardrop equilibria. More specifically, we have the following convergence result:</p>
    <p>Theorem 1 If the assumptions are satisfied, the protocol in Figure 2 converges to the set H. Furthermore, the internal routing probabilities q converge in Hs almost surely.</p>
    <p>Please see the Appendix for a complete proof of the above theorem. The proof is modeled after [10] but adapted to our link-based aggregated update scheme. To give the readers some intuition about the proof, below we present the major steps of the proof. The readers can skip to the next section without loss of continuity.</p>
    <p>In order to prove the above theorem, we need to show that (1) routing probability converges; (2) delay estimation converges under stationary routing probability; and (3) when routing probability and delay estimation converge, the internal routing probabilities converge in Hs almost surely. Thus, our proof consists of three steps as follows.</p>
    <p>In the first step of the proof, we show that the routing probabilities converge after the algorithm runs for a sufficiently long time. The major challenge in this step is that we need to find a converging sequence to bound the difference of routing probabilities. By combining and rewriting delay estimation and routing probability update equations, we derive a function of the two learning factors to bound the difference of routing probabilities at different times in a given small time interval. We then apply Borel-Cantelli Lemma and assumptions A1-A4 to show the convergence. In particular, the assumption that the range of</p>
    <p>n((n)/(n)) s is bounded is crucial in</p>
    <p>order to apply Borel-Cantelli Lemma. In the second step of the proof, we prove the convergence of the expected delay with respect to stationary</p>
    <p>routing probabilities (which is a result of the first step). The intuition behind the proof is that routing probability update has smaller step sizes in order for delay estimation to stabilize before the next routing probability update occurs. Again, the major challenge here is to find a converging bound for the expected delay. We consider delay estimation in a give small time interval. By rewriting the delay estimation equation (2), we derive a closed form expression for the difference of delays, which consists of terms of martingales and bounded delays. We then apply the convergence result in the first step, martingale convergence theorem and Gronwalls Lemma to derive the convergence of delay estimation.</p>
    <p>In the last step of the proof, we derive the convergence of internal routing probabilities in Hs based on the results of the previous two steps. Recall that we add the i.i.d. uniform random routing vectors in (4) and (8) to introduce disturbance to escape from non-Wardrop solutions H \ Hs. Specifically, we show that for any given demand, delays are equalized along paths with positive traffic. The major challenges in this step are to show that internal routing probabilities converge and that the expected delays converge to equalized delays along different paths with positive traffic. To simplify the analysis and make the problem more tractable, we adopt the standard O.D.E. approach to projected stochastic approximation algorithms and consider the continuous version of our discretized routing update scheme. We then prove that internal routing probabilities converge by taking the discrete routing update scheme (4) as an approximation of its continuous version in the O.D.E. approach. Similarly, we show that for any given demand, delays with respect to the converged positive routing probabilities converge to the same value. Afterwards, we show that non-Wardrop solutions in H \ Hs are unstable and that the i.i.d. uniform random routing vectors allow us to avoid them.</p>
  </div>
  <div class="page">
    <p>As for the network-optimal routing scheme, a similar proof can be constructed.</p>
    <p>We implement the above routing schemes in ns-2 [27] and evaluate their performance and dynamics through extensive simulations. Below we describe the network topologies, traffic demands, and performance metrics used in our evaluation.</p>
    <p>Network Topologies: Rocketfuel applies effective techniques to obtain fairly complete ISP maps [33]. We use three POP-level topologies published by the authors: ATT, Sprint, and Tiscali. Link capacities of these topologies are derived by scaling up the OSPF weights of the links by a constant factor. To focus on the core of the network, we exclude all of the leaf nodes (i.e., nodes with only one neighbor). Table 1 summarizes the three topologies.</p>
    <p>ISP #Nodes #Edges</p>
    <p>ATT 30 126 Sprint 19 100 Tiscali 32 140</p>
    <p>Table 1. ISP topologies as measured by Rocketfuel.</p>
    <p>Traffic Demands: We consider different ways of generating synthetic traffic demands for our evaluation. One possible approach is based on the gravity model [43], which has been shown to provide a reasonable approximation to real traffic demands.</p>
    <p>However, we find that when using the gravity model, the network becomes stabilized too quickly to demonstrate evolution dynamics (i.e., how convergence is reached). In addition, under the gravity model, we find it difficult to generate traffic demands that stress the entire network to a sufficient level  in most cases there are only a handful of congested links while most links are under-utilized.</p>
    <p>Therefore, in order to better demonstrate the evolution dynamics of convergence, we use another way of generating synthetic traffic demands. We randomly pick two nodes as the source and destination and assign a Pareto traffic flow to them. The traffic rate rij of the flow from node i to j is 20% of the minimum link bandwidth along the shortest hop-count path from node i to j. We continue doing this until all nodes are assigned with an outgoing traffic flow. In our evaluation, the average link utilization ranges from 10% to 20% under the three network topologies we study.</p>
    <p>Traffic Stimuli: To evaluate how a network converges, we introduce a traffic stimulus as follows. We first feed a given demand matrix to a network to let it converge. Then we introduce a traffic stimulus to the network. The maximum traffic rate of flow from node i to j during the traffic stimulus, Rij, is three times the original rate rij. When the traffic rates achieve their maximum values, most low-capacity links are saturated and the average link utilization ranges from 20% to 50% with the network topologies in our evaluation. We apply the following three stimuli commonly used in control theory:</p>
    <p>Traffic spike: The traffic rate of each flow originating from node i to j increases suddenly to the highest rate Rij and lasts for only a short period of time; then it decreases to the original level rij. This represents a traffic burst and tests how the system adapts to the disturbance.</p>
    <p>Step function: The traffic rate of each flow originating from node i to j increases to Rij and remains at that level afterwards. This represents the transition of traffic levels in the network and tests how the system responds and evolves accordingly.</p>
    <p>Linear function: The traffic rate of each flow originating from node i to j increases linearly to the maximum rate Rij over a relatively long period of time, and remains at that maximum level afterwards. This represents</p>
  </div>
  <div class="page">
    <p>the gradual transitions of traffic levels and tests how the system keeps up with the gradually changing traffic.</p>
    <p>Performance Metrics: We consider the following three performance metrics: average latency, average convergence time, and link utilization.</p>
    <p>The average latency reflects the end-to-end user performance, which is the major concern for both useroptimal and network-optimal routing schemes. The average latency is computed for all source-destination pairs, weighted by the amount of traffic flowing from the source to destination.</p>
    <p>The average convergence time reflects the speed at which the network stabilizes. We consider a network as converged at time t+1 when</p>
    <p>i xi,t+1  xi,t  5%</p>
    <p>i xi,t where xi,t is the routing matrix at node i during time t, and A is `2 norm of matrix A. When the network converges, the latency variance is small, and this can be used as a criterion for convergence.</p>
    <p>The link utilization reflects the objectives of network operators, who want to avoid link overloads in their networks.</p>
    <p>av er</p>
    <p>ag e</p>
    <p>la te</p>
    <p>nc y</p>
    <p>(m s)</p>
    <p>time (s)</p>
    <p>user-optimal network-optimal</p>
    <p>(a) ATT</p>
    <p>av er</p>
    <p>ag e</p>
    <p>la te</p>
    <p>nc y</p>
    <p>(m s)</p>
    <p>time (s)</p>
    <p>user-optimal network-optimal</p>
    <p>(b) Sprint</p>
    <p>av er</p>
    <p>ag e</p>
    <p>la te</p>
    <p>nc y</p>
    <p>(m s)</p>
    <p>time (s)</p>
    <p>user-optimal network-optimal</p>
    <p>(c) Tiscali</p>
    <p>Figure 5. Dynamics of user-optimal and network-optimal Routing.</p>
    <p>av er</p>
    <p>ag e</p>
    <p>la te</p>
    <p>nc y</p>
    <p>(m s)</p>
    <p>time (s)</p>
    <p>user-optimal network-optimal</p>
    <p>(a) Spike stimulus</p>
    <p>av er</p>
    <p>ag e</p>
    <p>la te</p>
    <p>nc y</p>
    <p>(m s)</p>
    <p>time (s)</p>
    <p>user-optimal network-optimal</p>
    <p>(b) Step stimulus</p>
    <p>av er</p>
    <p>ag e</p>
    <p>la te</p>
    <p>nc y</p>
    <p>(m s)</p>
    <p>time (s)</p>
    <p>user-optimal network-optimal</p>
    <p>(c) Linear stimulus</p>
    <p>Figure 6. Responsiveness of routing schemes.</p>
  </div>
  <div class="page">
    <p>We first study the performance of adaptive routing schemes under realistic self-similar traffic demands and with links using drop-tail queues. Figure 5 shows the average latency for the three topologies under user-optimal and network-optimal routing. We make the following observations.</p>
    <p>First, both user-optimal and network-optimal routing converge quickly to stable states, with comparable fluctuation during the learning stage.</p>
    <p>Second, the performance of user-optimal routing is similar to that of network-optimal routing. This result further supports the observations in [28] that the performance degradation of user-optimal routing is not significant.</p>
    <p>Third, network topologies play an important role in the speed of convergence. As shown in the figure, both ATT and Sprint topologies hurtle through the learning stage and converge almost immediately after the simulation starts. In contrast, the Tiscali network experiences a short period of learning stage with high latency before converging to a stable stage with fluctuating average latency.</p>
    <p>Fourth, at stable states, the average latency of both routing schemes has small fluctuation (within about 10%). The fluctuation after convergence in both routing schemes are comparable.</p>
    <p>Because all three topologies exhibit similar convergence properties, and the Tiscali topology has a distinct learning stage and stabilized stage, in the following subsections we focus on evaluation using the Tiscali topology.</p>
    <p>We now evaluate the responsiveness and stability of the routing schemes under different traffic stimuli in the forms of a spike, a step function, and a linear function.</p>
    <p>We apply each of the traffic stimuli to the network at 13 second after the network has converged. The highest traffic rate during a stimulus is 3 times the original traffic rate. Both spike and step stimuli increase the traffic level to the highest rate at time 13 second. The spike stimulus maintains the highest traffic rate for 2 seconds and then decreases to the original level, while the step stimulus keeps the highest rate until the simulation ends. Linear stimulus increases the rate gradually to the highest rate from time 13 second to 20 second (with an increase interval of 0.2 ms) and then maintains that rate to the end of the simulation.</p>
    <p>Figure 6 shows how the two routing schemes respond to the stimuli in the Tiscali network topology. As we can see, both user-optimal and network-optimal routing schemes react to the stimuli and stabilize very quickly. For the spike stimulus, the network returns to the original stable state almost immediately after the spike disappears. For the step stimulus, the network settles to the new steady state in a very short time. For the linear stimulus, the network follows the increasing traffic closely as the traffic rate increases gradually from 13 second to 20 second; after the linear stimulus stops increasing at 20 second, the network converges quickly.</p>
    <p>We have shown that our algorithms perform very well under realistic traffic demands and that the algorithms are responsive to various traffic stimuli in the preceding subsections. Next, we evaluate how our algorithms perform when the network topology is changing due to link failures.</p>
    <p>When evaluating the adaptiveness of our algorithms to link failures, we run our algorithms with self-similar traffic demands and different network topologies until they converge; we then randomly disconnect 5% of the links from the network (the network is still connected).</p>
    <p>Figure 7 shows the responsiveness of our user-optimal routing algorithm to link failures with the Tiscali network topology. The link failures occur at 25 second. We observe that the average latency increases immediately after the link failures. After a short period of time, the routing algorithm starts to converge. The converged average latency after the link failures is about 25% higher than that without link failures. The result shows that the algorithm adapts well to dynamic environments with link failures. The results using other routing algorithms and topologies are consistent.</p>
  </div>
  <div class="page">
    <p>A ve</p>
    <p>ra ge</p>
    <p>l at</p>
    <p>en cy</p>
    <p>( m</p>
    <p>s)</p>
    <p>Time (s)</p>
    <p>link failures at time 25s</p>
    <p>with link failures without link failures</p>
    <p>Figure 7. Adaptiveness to link failures.</p>
    <p>av er</p>
    <p>ag e</p>
    <p>la te</p>
    <p>nc y</p>
    <p>(m s)</p>
    <p>time (s)</p>
    <p>user-optimal shortest hop-count</p>
    <p>(a) Pareto traffic</p>
    <p>av er</p>
    <p>ag e</p>
    <p>la te</p>
    <p>nc y</p>
    <p>(m s)</p>
    <p>time (s)</p>
    <p>user-optimal shortest hop-count</p>
    <p>(b) Spike stimulus</p>
    <p>er ag</p>
    <p>e la</p>
    <p>te nc</p>
    <p>y (m</p>
    <p>s) time (s)</p>
    <p>user-optimal shortest hop-count</p>
    <p>(c) Step stimulus</p>
    <p>av er</p>
    <p>ag e</p>
    <p>la te</p>
    <p>nc y</p>
    <p>(m s)</p>
    <p>time (s)</p>
    <p>user-optimal shortest hop-count</p>
    <p>(d) Linear stimulus</p>
    <p>Figure 8. Comparison between user-optimal and shortest path routing.</p>
    <p>In this subsection, we evaluate the benefits of user-optimal routing over shortest hop-count routing (i.e., rtProtoDV in ns-2) under both self-similar traffic and traffic stimuli. Figure 8 summarizes the results. As we can see, user-optimal routing out-performs shortest hop-count routing by 20% - 30% in most cases. This is consistent with our expectation, since shortest hop-count routing minimizes hop-count instead of user latency.</p>
    <p>In this subsection, we consider the following issue: how to make the network converge faster and be more responsive.</p>
    <p>Recall that we implement the routing update in two steps. First, a node updates its delay estimations to all of the destinations using exponential averaging. The parameter used in exponential averaging is called the delay learning factor. Next, the node updates its routing probability using the results in the previous step; the parameter used in this step is called the routing learning factor. Note that in our analysis we use decreasing sequences while in our evaluation we use fixed values. We evaluate the impact of various control parameters, namely the delay learning factor, the routing learning factor, and the period of updating routing probability vectors.</p>
    <p>Delay Learning Factor: We first evaluate the effect of the delay learning factor, which is used in updating delay estimations. Recall that we adopt delay learning factor (n) and Equation (2) to smooth out noise introduced in estimating link latency and marginal link latency.</p>
    <p>Figure 9(a) summarizes the results. We find that a large delay learning factor leads to faster convergence but high fluctuation. In comparison, a small learning factor makes the algorithm not responsive to network dynamics, resulting in slow convergence. It is very important to choose appropriate values for delay learning factor in order for the routing algorithm to be both robust to noise and responsive to network dynamics. Our results suggest that a preferable learning factor would range between 0.4 and 0.6.</p>
  </div>
  <div class="page">
    <p>a v</p>
    <p>e ra</p>
    <p>g e l</p>
    <p>a te</p>
    <p>n c y</p>
    <p>( m</p>
    <p>s)</p>
    <p>time (s)</p>
    <p>delay learning factor 0.1 0.2 0.4 0.6</p>
    <p>(a) Delay learning factor</p>
    <p>a v</p>
    <p>e ra</p>
    <p>g e l</p>
    <p>a te</p>
    <p>n c y</p>
    <p>( m</p>
    <p>s) time (s)</p>
    <p>routing learning factor 0.1 0.2 0.4 0.6</p>
    <p>(b) Routing learning factor</p>
    <p>a v</p>
    <p>e ra</p>
    <p>g e l</p>
    <p>a te</p>
    <p>n c y</p>
    <p>( m</p>
    <p>s)</p>
    <p>time (s)</p>
    <p>update period 0.2 ms 0.4 ms 0.6 ms 0.8 ms</p>
    <p>(c) Update period</p>
    <p>Figure 9. Impacts of different parameters.</p>
    <p>Routing Learning Factor: Figure 9(b) shows how the routing learning factor affects the convergence speed. The network starts to converge more quickly when using eager learning (with a higher learning factor) than lazy learning. However, we also observe that a higher factor leads to more fluctuation, e.g., the curve corresponding to a factor of 0.6 has more fluctuation compared to that of 0.2 and 0.4. A preferable learning factor would range between 0.2 and 0.4. Note that similar to delay learning factor, a large routing learning factor makes the algorithm sensitive to noise, and leads to undesired fluctuations after convergence; and a small factor makes the algorithm less responsive and slows down convergence rate, as shown in the figure.</p>
    <p>C um</p>
    <p>ul at</p>
    <p>iv e</p>
    <p>pr ob</p>
    <p>ab il</p>
    <p>it y</p>
    <p>number of hops</p>
    <p>before convergence after convergence</p>
    <p>(a) ATT</p>
    <p>C um</p>
    <p>ul at</p>
    <p>iv e</p>
    <p>pr ob</p>
    <p>ab il</p>
    <p>it y</p>
    <p>number of hops</p>
    <p>before convergence after convergence</p>
    <p>C um</p>
    <p>ul at</p>
    <p>iv e</p>
    <p>pr ob</p>
    <p>ab il</p>
    <p>it y</p>
    <p>number of hops</p>
    <p>before convergence after convergence</p>
    <p>(b) Sprint</p>
    <p>C um</p>
    <p>ul at</p>
    <p>iv e</p>
    <p>pr ob</p>
    <p>ab il</p>
    <p>it y</p>
    <p>number of hops</p>
    <p>before convergence after convergence</p>
    <p>(c) Tiscali</p>
    <p>Figure 10. Cumulative probability of packets being delivered in a number of hops.</p>
    <p>Period of Routing Update: The last parameter we evaluate is the period of updating the routing probability vectors. As Figure 9(c) shows, an eager update scheme (with shorter update period) leads to faster convergence and less fluctuations compared with lazy update. We have the same observation when evaluating the impact of larger update periods; therefore, only the results of shorter update periods are presented here in the interest of space. We observe that eager update scheme is preferable for fast convergence and high responsiveness. We also note that a shorter update period introduces more control traffic between neighboring routers. However, the overhead is low and localized, and the routing schemes with a shorter update period still scale very well.</p>
    <p>In summary, the three parameters we evaluate have important impacts on convergence and fluctuation. A relatively short update period and medium routing learning factor can be combined to provide enough sensitivity to the dynamics of the network. Empirical evaluation can help serve as basis for setting values for these parameters.</p>
  </div>
  <div class="page">
    <p>The two routing schemes studied in this paper are both probabilistic routing. After our schemes converge, if there are no probing probabilities, no packet will visit the same node twice. More specifically, after convergence and without the small probing probabilities, a node will not assign a positive routing probability to a neighbor with a higher latency. Assuming no link has zero latency (which is true in almost all scenarios), we have that no packet can visit the same node twice. However, during the transition process and with the small probing probabilities, it is possible for a packet to take detours; therefore a packet may visit the same node multiple times.1 Note that even if a packet visits the same node multiple times, it will not loop forever because of the probabilistic nature of the scheme.</p>
    <p>In this subsection, we quantify the effects of the transition process and the probing probabilities on path lengths as follows. Consider a given destination d. We take all of the routing probability vectors at all of the nodes at time t for destination d. These vectors altogether represent a snapshot of the state of the network at that time. We construct a Markov transition matrix Pd as follows. The i-th row of the matrix Pd is the routing probability vector for destination d at node i. Note that the d-th row of Pd will have a value 1 at the d-th entry and 0 otherwise, indicating that node d is an absorbing state. Consider a source node s. Let s be the row probability vector with 1 for source node s and 0 for all other nodes. Then according to the property of Markov matrices [21], the probability that a packet starting from source node s arrives at the destination node d in h hops is the d-th entry of the row vector sP</p>
    <p>h d</p>
    <p>. Figure 10 shows the results of the cumulative distribution of the lengths of routing paths. In our evaluations, we</p>
    <p>have a constant probing probability 0.08 at all nodes. We randomly choose a source node s and a destination node d. We take snapshots of the complete routing probabilities Pd at 5 second after simulation starts (the network has not converged yet) and at a random time after the network converges. We then compute the cumulative distribution of the number of hops that a packet sent from s to d traverses in the network. As we can see, the number of hops a packet traverses from the source to the destination is significantly lower after the network has converged. For example, before the network converges, the probability of delivering packets within 10 hops is 88%, 60%, and 70% in ATT, Sprint, and Tiscali topologies, respectively; in comparison, the corresponding probabilities increase to 100%, 91%, and 86% after the network converges.</p>
    <p>So far, we have considered routing for optimizing latency. As shown in [28], optimizing the average user latency alone sometimes causes link overload, which is undesirable from the network operators point of view [16]. Ideally, we would like to achieve low user latency while avoiding link overload. In this section, we study how to optimize routing for both metrics simultaneously.</p>
    <p>Our method is to introduce a link utilization threshold. Whenever a links utilization exceeds the threshold, the routing scheme will shift some traffic from the highly utilized link to other under-utilized links. This is done by updating the routing probability vector for the corresponding destination. When all of the outgoing links experience higher utilization than the threshold (i.e., there are no under-utilized links), the routing scheme distributes the traffic evenly among all outgoing links.</p>
    <p>In our experiments, we use several utilization thresholds: 20%, 50%, 80%, and 100%. We apply spike, step, and linear stimuli to evaluate the responsiveness and stability of different routing schemes. Figure 11 shows the average latency of user-optimal routing scheme with the Tiscali network topology.</p>
  </div>
  <div class="page">
    <p>av er</p>
    <p>ag e</p>
    <p>la te</p>
    <p>nc y</p>
    <p>(m s)</p>
    <p>time (s)</p>
    <p>(a) Spike stimulus</p>
    <p>av er</p>
    <p>ag e</p>
    <p>la te</p>
    <p>nc y</p>
    <p>(m s)</p>
    <p>time (s)</p>
    <p>(b) Step stimulus</p>
    <p>av er</p>
    <p>ag e</p>
    <p>la te</p>
    <p>nc y</p>
    <p>(m s)</p>
    <p>time (s)</p>
    <p>(c) Linear stimulus</p>
    <p>Figure 11. User-optimal routing combined with load optimization: average user latency for various link utilization thresholds.</p>
    <p>We make the following observations. First, both routing schemes are very responsive to the traffic stimuli: they closely track the changes in traffic and become stabilized as soon as the traffic stops changing. Second, comparing the results with those in Figure 6, which are obtained solely by optimizing user latency, we observe that by trying to minimize the maximum link utilization, the network experiences higher latency; this is especially clear when the utilization threshold is below 20%. In comparison, the latency increase is only marginal when we increase link utilization threshold to 50% or higher. This is because when the threshold is high, only a few links are above the threshold; as a result, only a small portion of traffic needs to be re-routed through less loaded paths.</p>
    <p>av er</p>
    <p>ag e</p>
    <p>la te</p>
    <p>nc y</p>
    <p>(m s)</p>
    <p>time (s)</p>
    <p>user-optimal network-optimal</p>
    <p>(a) Spike stimulus</p>
    <p>av er</p>
    <p>ag e</p>
    <p>la te</p>
    <p>nc y</p>
    <p>(m s)</p>
    <p>time (s)</p>
    <p>user-optimal network-optimal</p>
    <p>(b) Step stimulus</p>
    <p>av er</p>
    <p>ag e</p>
    <p>la te</p>
    <p>nc y</p>
    <p>(m s)</p>
    <p>time (s)</p>
    <p>user-optimal network-optimal</p>
    <p>(c) Linear stimulus</p>
    <p>Figure 12. Comparison between user-optimal and network-optimal routing schemes: average latency when the link utilization threshold is 20%.</p>
    <p>Next we compare the user- and network-optimal routings. Figure 12 summarizes the results. As it shows, useroptimal routing and network-optimal routing exhibit similar latency and convergence speed, both adapting quickly to changes in traffic.</p>
    <p>User-optimal routing achieves Wardrop equilibrium [40]. In [3, 40], the authors showed that uncooperative traffic can be modeled as network flows, and the flow paths between any source and destination pair have the same latency. Based on the observation that such an equilibrium flow is an optimal solution to a related convex program, Beckmann et al. [3] proved the existence and uniqueness of traffic equilibrium for user-optimal routing. Most previous studies have been concerned with user-optimal routing with an infinite number of users, i.e., infinitesimal</p>
  </div>
  <div class="page">
    <p>demand. In [22], Korilis, Lazar, and Orda considered a finite number of users and studied the conditions for the existence of Nash equilibria. They showed that there may exist multiple Nash equilibria and that although it is possible to use Rosens Diagonal Strict Concavity [29] to establish uniqueness, this condition generally does not apply. In [12], Boulogne, Altman, Pourtallier, and Kameda studied the conditions for the existence of a Nash equilibrium in a mixed network, i.e., a network where some users control a substantial amount of traffic and other users generate infinitesimal amount of traffic.</p>
    <p>Network-optimal routing in a centralized setting has been studied previously, and many optimization techniques have been proposed. For a survey, please see [5]. There are also previous distributed algorithms for computing optimal traffic equilibrium, e.g., see [7] for a complete survey; however, they do not use the probabilistic routing scheme.</p>
    <p>The authors in [28] study the performance of self adaptive routing and its impact on traffic engineering under traffic equilibria.</p>
    <p>Our routing scheme is based on reinforcement learning [20]. In [13, 26], Littman and Boyan first applied reinforcement learning to routing and proposed the Q-routing scheme. The Q-routing scheme is further revised in [24, 34]. Their scheme is per-packet based, however, and only supports single path routing. The work closest to ours is [10] by Borkar and Kumar. In this significant work, they formally prove the convergence of their scheme and our proof models after theirs. We avoid per-packet feedback to have a more efficient distributed implementation.</p>
    <p>In this paper, we develop routing schemes to achieve user-optimal and network-optimal routing. Viewed as a mechanism for computing equilibrium, our scheme is simple and efficient; thus it can be used to evaluate the performance of large scale networks. Moreover, it does not require analytical network models, and is able to model user-optimal and network-optimal routing in a dynamic environment. It is also able to capture the potential overhead of the routing convergence process. Viewed as a protocol for determining routes in a network, our scheme is simple and distributed; and the scheme has low protocol overhead. We analyze the convergence of the routing scheme, and demonstrate its efficiency and responsiveness through extensive simulations.</p>
    <p>In addition, we adapt the routing scheme to optimize end-user performance and link utilization simultaneously. We evaluate the trade-off between the two objectives and show that the degradation in end-user performance is only marginal for typical link utilization requirements.</p>
    <p>There are a number of avenues for future work. First, by having routers compute user-optimal routing, we know that the users will have no incentives in deviating from the routing protocol. However, when the routers also consider traffic engineering objectives (i.e., jointly optimize for both user latency and link utilization), the resulting routing will deviate from user-optimal routing. A thorough understanding of the interactions between users routing incentives and traffic engineering is needed. Second, it remains an interesting question how to design routing protocols and compute traffic equilibria when users are optimizing for other end-to-end performance metrics, such as loss and throughput. In order to optimize latency, our scheme reduces contention, and thus has the potential to increase throughput. Also, the probabilistic routing scheme investigated here may offer a way to efficiently compute traffic equilibria for such metrics.</p>
    <p>We thank Sekhar Tatikonda for insightful discussions. We also thank Theodore Jewell and Sheng Zhong for many discussions.</p>
    <p>A Proof of Theorem 1</p>
    <p>In order to prove Theorem 1, we introduce the following notations. Let (n, t) = min{l  n : l</p>
    <p>k=n (k)  t}, where t &gt; 0. Define interval In = [</p>
    <p>ik j (n),</p>
    <p>ik j ((n, t))], where</p>
    <p>ik j (n) is the time when the n-th update takes</p>
  </div>
  <div class="page">
    <p>place at node i with respect to neighbor j and destination k. Let P ik denote the simplex of probability vectors of node i with respect to destination k. Denote by Ni the</p>
    <p>number of neighbors of node i. Let pik(n) = [pik1 (n), ..., p ik Ni (n)]T  P ik denote the probability vector of node</p>
    <p>i for destination node k. We define Qik and qik(n) similarly. Define P =</p>
    <p>i,k P ik and Q =</p>
    <p>i,k Q ik. Let</p>
    <p>q(t)  Q denote the vector of all the routing probabilities at all nodes at time t, and the value of q(t) is computed using Equation (4). p(t)  P is defined similarly as well.</p>
    <p>We prove Theorem 1 through a series of lemmas. Specifically, we show that routing probability converges by Lemma 1; we then show that delay estimation converges under stationary routing probability by Lemma 2, 3, and 4; lastly, we show that when routing probability and delay estimation converge, the internal routing probabilities converge in Hs almost surely.</p>
    <p>We first derive the following lemma to show that routing probability converges:</p>
    <p>Lemma 1 lim n</p>
    <p>sup tIn</p>
    <p>q(t)  q(ikj (n)) = 0, a.s.</p>
    <p>Proof Let {ik(n)} =</p>
    <p>jN(i){ ik j (m)}, rearranged in increasing order. Suppose that</p>
    <p>ik j (n) =</p>
    <p>ik(n) and</p>
    <p>ikj ((n, t)) =  ik(nh) with n = n0 &lt; n1 &lt; ... &lt; nh denoting the integers for which</p>
    <p>ik(n + l) = ik(nl), 0</p>
    <p>l  h. Let Xl be the number of updates received by node i during the interval [ ik j (n + l),</p>
    <p>ik j (n + l + 1)]. Let</p>
    <p>Ml be the set of m such that the m-th update takes place during this interval. Note that |Ml| = Xl. Therefore, (nl) is the most recent step size used to update routing probabilities at time</p>
    <p>ik j (n + l) at node i. Since {(m)}</p>
    <p>is non-increasing, we have (nl)  (m) for all m  Ml. We also have nl  n + l, implying (nl)  (n + l). Hence</p>
    <p>sup tIn</p>
    <p>q(t)  q(ikj (n))  C1</p>
    <p>h</p>
    <p>l=0</p>
    <p>mMl</p>
    <p>(m)</p>
    <p>C1</p>
    <p>h</p>
    <p>l=0</p>
    <p>Xl(nl)</p>
    <p>= C1</p>
    <p>h</p>
    <p>l=0</p>
    <p>a(n + l)Xl( (nl)</p>
    <p>a(n + l) )</p>
    <p>C1</p>
    <p>h</p>
    <p>l=0</p>
    <p>a(n + l)Xl( (n + l)</p>
    <p>a(n + l) )</p>
    <p>C2t</p>
    <p>h l=0 (n + l)Xl(</p>
    <p>(n+l) (n+l)</p>
    <p>) h</p>
    <p>l=0 (n + l) ,</p>
    <p>where C1 is a suitable positive constant in the above derivation. The facts that (nl)  (m), |Ml| = Xl, and (nl)  (n + l) are used in deriving the above inequalities. In the last step, the fact that</p>
    <p>h l=0 (n + l) =</p>
    <p>(n,t) l=n (l)  [t, t + ((n, t))] is used in the derivation as well. We choose C2  C1(t + (1))/t. Next we show that the right hand side of the above inequality will tend to zero almost surely if Xl((n +</p>
    <p>l)/(n + l))  0 almost surely. More specifically, for any  &gt; 0 and s &gt; 1, and a suitable constant K &gt; 0,</p>
    <p>l</p>
    <p>P</p>
    <p>(</p>
    <p>Xl</p>
    <p>(</p>
    <p>(n + l)</p>
    <p>(n + l)</p>
    <p>)</p>
    <p>)</p>
    <p>sK</p>
    <p>l</p>
    <p>(</p>
    <p>(l)</p>
    <p>(l)</p>
    <p>)s</p>
    <p>&lt; .</p>
  </div>
  <div class="page">
    <p>Note that E[(Xl) s] &lt; . By applying assumption (A4) and Borel-Cantelli Lemma, we can see that the desired</p>
    <p>claim holds. 2</p>
    <p>we then show that delay estimation converges under stationary routing probability by the following lemmas (Lemma 2, 3, and 4):</p>
    <p>Lemma 2</p>
    <p>lim n</p>
    <p>n+l1</p>
    <p>m=n</p>
    <p>(m)[ikj (m + 1)   ik j (n)] = 0, a.s.</p>
    <p>Proof Delay estimations are propagated backward from neighbors of destination node k to node j and then to node i along the reverse paths from i through j to k. At any instant when node i receives updates from j, the updates are aggregation of a series of earlier updates received by js neighbors. Let Tn be the maximum time lag in the updates, namely, the earliest estimation at some node en route to k from i is n  Tn. Let D</p>
    <p>ik j (n) be the end to end</p>
    <p>delay, it can be seen that ikj (m + 1)   ik j (n)  C1(n  Tn)D</p>
    <p>ik j (n), where C1 is a suitably chosen constant</p>
    <p>(note that {(n)} is a non-increasing sequence). Therefore,</p>
    <p>n+l1</p>
    <p>m=n</p>
    <p>(m)[ikj (m + 1)   ik j (n)]</p>
    <p>C2</p>
    <p>n+l1</p>
    <p>m=n</p>
    <p>(m)(n  Tn)D ik j (n).</p>
    <p>Notice that</p>
    <p>n+l1</p>
    <p>m=n</p>
    <p>P((m)(n  Tn)D ik j (n)  )</p>
    <p>2 n+l1</p>
    <p>m=n</p>
    <p>((m)(n  Tn)) 2E[(Dikj (n))</p>
    <p>C3</p>
    <p>n+lTn1</p>
    <p>m=nTn</p>
    <p>((m))2 &lt; .</p>
    <p>In (9), we assume that E[(Dikj (n)) 2] &lt; . Therefore, by applying Borel-Cantelli Lemma, we can see that the</p>
    <p>right hand side of the above inequality tends to zero almost surely. 2</p>
    <p>Define Dikj (p(n)) = Ep(n)[</p>
    <p>ik j (n)]</p>
    <p>where p(n) = p(ikj (n)). We have the following lemma:</p>
    <p>Lemma 3</p>
    <p>lim n</p>
    <p>n+l1</p>
    <p>m=n</p>
    <p>a(m)[Dikj (p( ik j (n)))</p>
    <p>ik j (n)] = 0, a.s.</p>
    <p>Proof Let Z(t) denote the state of the underlying network at time t. Z(t) can be seen as a continuous-time controlled Markov chain with state space S =</p>
    <p>L l=1 Sl for some L  1, where Sl is a locally compact topological</p>
    <p>space with the randomized control given by p(t), which is the vector of all the routing probabilities at time t.</p>
  </div>
  <div class="page">
    <p>Z(t) will be a time-homogeneous Markov chain on S if p() is held fixed at a specific state. Let Ft denote the right-continuous completion of the corresponding -field. Set Fn = Fik</p>
    <p>j (n), for n  1, the sum</p>
    <p>n</p>
    <p>m=1</p>
    <p>(m) (</p>
    <p>ikj (m)  Ep(ik j</p>
    <p>(n))[ ik j (n)|Fm1]</p>
    <p>)</p>
    <p>is seen to be a zero mean martingale. Using standard martingale analysis techniques, we can prove that the above martingale converges almost surely. The desired claim then follows Borel-Cantelli Lemma. Note that Dikj (p(</p>
    <p>ik j (n))) represents the expected delay from i through j to k, with respect to the unique limiting stationary</p>
    <p>law for {Z(ikj (m))} under p(n). 2</p>
    <p>In order to make delay estimation a continuous function, we take a linear interpolation approach. We define L(t) to linearly interpolate Likj (n) by letting L(t) = L</p>
    <p>ik j (n) on [t(n), t(n + 1)], where t(n) =</p>
    <p>n m=1 (m) and</p>
    <p>t(0) = 0, for n  0. Let T be a constant and T &gt; 0, then we have the following lemma:</p>
    <p>Lemma 4 lim n</p>
    <p>sup t(n)tt(n)+T</p>
    <p>Dikj (p(n))  L(t) = 0, a.s.</p>
    <p>Proof Let An = n+l1</p>
    <p>m=n (m)[ ik j (m + 1)</p>
    <p>ik j (n)], and Bn =</p>
    <p>n+l1 m=n (m)[</p>
    <p>ik j (n)D</p>
    <p>ik j (p(</p>
    <p>ik j (n)))],</p>
    <p>for t(n)  t(n + l)  t(n) + t, rewrite L(t(n + l)) as</p>
    <p>L(t(n + l)) = L(t(n)) + n+l1</p>
    <p>m=n</p>
    <p>(m)[ikj (m + 1)  L(t(m))]</p>
    <p>= L(t(n)) + n+l1</p>
    <p>m=n</p>
    <p>(m)[ikj (m + 1)   ik j (n)]</p>
    <p>+</p>
    <p>n+l1</p>
    <p>m=n</p>
    <p>(m)[ikj (n)  D ik j (p(</p>
    <p>ik j (n)))]</p>
    <p>+ n+l1</p>
    <p>m=n</p>
    <p>(m)[Dikj (p( ik j (n)))  L(t(m))].</p>
    <p>Therefore,</p>
    <p>L(t(n + l)) = L(t(n)) + An + Bn + o(1)</p>
    <p>+</p>
    <p>t(n+l)</p>
    <p>t(n) (Dikj (p(n))  L(t))dt.</p>
    <p>Along with Lemma 1, Lemma 2, and Lemma 3, the desired claim can be derived by a standard argument based on Gronwalls Lemma. 2</p>
    <p>Lastly, we show that when routing probability and delay estimation converge, the internal routing probabilities converge in Hs almost surely.</p>
    <p>Define (n) = n1</p>
    <p>m=0 (m), (0) = 0, and q ik j ((n)) = q</p>
    <p>ik j (n), n  0. Therefore, q() is a linear interpolation</p>
    <p>of q() on each interval [(n), (n+1)]. By using standard O.D.E. approach to projected stochastic approximation algorithms (see, e.g., [25]), we can derive the following P -valued O.D.E.:</p>
    <p>yikj (t) = y ik j (t)[</p>
    <p>Ni</p>
    <p>m=1</p>
    <p>yikm(t)D ik m(y(t))  D</p>
    <p>ik j (y(t))] (10)</p>
  </div>
  <div class="page">
    <p>where m  N(i). Therefore, q() tracks (10). Let P denote the space of probability measures on P with Prohorov topology. A pair (q, v) in P  P is a</p>
    <p>Cesaro-Wardrop equilibrium if both of the following two conditions are satisfied:</p>
    <p>ik j &gt; 0. Here E</p>
    <p>[Dikm(p)] =</p>
    <p>Dikm(y)v dy, i.e., E[] denotes the</p>
    <p>expectation with respect to v.</p>
    <p>Define empirical measures v(t) as follows:</p>
    <p>P</p>
    <p>fdv(t) = 1</p>
    <p>t</p>
    <p>t</p>
    <p>where t &gt; 0 and f  C(P). Then we have the following lemmas to show that both of the above conditions are satisfied asymptotically.</p>
    <p>Lemma 5 Every limit point of v(t)  P is invariant under O.D.E. (10) as t  , a.s.</p>
    <p>Proof Suppose that v(tn)  v  P  as tn  . Let t : P  P denote the map mapping y(0) to y(t) for</p>
    <p>O.D.E. (10) for t &gt; 0. Consider function f  C(P) satisfying</p>
    <p>tn</p>
    <p>tn</p>
    <p>fdv.</p>
    <p>For t &gt; 0,</p>
    <p>lim n</p>
    <p>tn</p>
    <p>f(q())d = lim n</p>
    <p>tn</p>
    <p>tn+t</p>
    <p>t</p>
    <p>f(q())d</p>
    <p>= lim n</p>
    <p>tn</p>
    <p>tn</p>
    <p>=</p>
    <p>f  tdv.</p>
    <p>Therefore, for any limit point of v(t)  P  is invariant as t   since t &gt; 0 is arbitrary in the above equations. 2</p>
    <p>According to Lemma 5, we denote by (q, v) a limit point of (q, v(t)) as t  . Note that v is invariant under (10) by the previous lemma.</p>
    <p>Lemma 6 E[Dikj (p)] = minm E [Dikm(p)], if q</p>
    <p>ik j &gt; 0.</p>
    <p>Proof Suppose q(tn)  q , v(tn)  v</p>
    <p>in P as tn  . Since q() approximates (10). Let   P and ikm &gt; 0 if and only if (q</p>
    <p>)ikm &gt; 0. we have</p>
    <p>m</p>
    <p>ikmn( qikm(tn)</p>
    <p>qikm(0) ) =</p>
    <p>tn</p>
    <p>tn</p>
  </div>
  <div class="page">
    <p>Note that the term o(tn) collects the error terms that are asymptotically negligible. Without loss of generality, we assume that qikm &gt; 0. The right-hand side becomes</p>
    <p>tn(E [(pik)T Dik(p)]  (ik)T E[Dik(p)]) + o(tn) (12)</p>
    <p>as n  ; while the left-hand side remains bounded by our choice of . Therefore, by dividing both sides by tn, we have</p>
    <p>E[(pik)T Dik(p)]  (ik)T E[Dik(p)] = 0 (13)</p>
    <p>as tn  , which is true for all  mutually absolutely continuous with respect to q . Therefore, E[Dikm(p)] is</p>
    <p>independent of m if (q)ikm &gt; 0. 2</p>
    <p>Now we prove Theorem 1 as follows. Let (q, v) be a limit point of (q(t), v(t)) as t   and (q, v) satisfies the following two conditions: (1) v is invariant; (2) E[Dikj (p)] = minmE</p>
    <p>[Dikm(p)] if (q )ikj &gt; 0, according to</p>
    <p>Lemma 5 and 6. Given that we have proved Lemma 5 and 6, we need only to prove that if (q)ikj = 0, then</p>
    <p>E[Dikj (p)]  minmE [Dikm(p)]</p>
    <p>for all j. We prove the theorem by contradiction. Assume that there exists a j such that (q)ikj = 0 and E</p>
    <p>[Dikj (p)] &lt; E [Dikm0]   where (q</p>
    <p>)ikm0 &gt; 0 and E[Dikm0(p)] = minmE</p>
    <p>[Dikm(p)], for some  &gt; 0. Let tn be defined as in the proof of Lemma 6. Let  = (q + m0)/2, where m0 is a point mass at m0. Similarly to the proof of Lemma 6, we have (11) and (12). (12) is positive for sufficiently large n in view of choice of  and Equation (13). Therefore, (12) is actually O()tn and increasing to +. However, the left-hand side of Equation (11) is approaching to  because qikm0(tn)  (q</p>
    <p>)ikm0 = 0 according to our assumption. Therefore our previous assumption yields a contradiction.</p>
    <p>References</p>
    <p>[1] E. Altman, T. Boulogne, R. E. Azouzi, and T. Jimenez. A survey on networking games. Telecommunication Systems, Nov. 2000.</p>
    <p>[2] D. G. Andersen, H. Balakrishnan, M. F. Kaashoek, and R. Morris. Resilient overlay networks. In Proceedings of the 18th Annual ACM Symposium on Operating Systems Principles, Banff, Canada, Oct. 2001.</p>
    <p>[3] M. Beckmann, C. B. McGuire, and C. B. Winsten. Studies in the Economics of Transportation. Yale University Press, 1956.</p>
    <p>[4] D. P. Bertsekas, E. M. Gafni, and R. G. Gallager. Second derivative algorithms for minimum delay distributed routing in networks. IEEE Transactions on Communications, COM-32(8):911919, 1984.</p>
    <p>[5] D. P. Bertsekas and R. Gallager. Data Networks. Prentice-Hall, Second Edition, 1992.</p>
    <p>[6] D. P. Bertsekas and J. N. Tsitsiklis. Neuro-dynamic Programming. Athena Scientific, 1996.</p>
    <p>[7] D. P. Bertsekas and J. N. Tsitsiklis. Parallel and Distributed Computation: Numerical Methods. Athena Scientific, 1997.</p>
    <p>[8] S. Bohacek, J. Hespanha, J. Lee, C. Lim, and K. Obraczka. TCP-PR: TCP for persistent packet reordering. In Proceedings of the IEEE 23rd International Conference on Distributed Computing Systems, May 2003.</p>
    <p>[9] V. Borkar. Stochastic approximation with two time scales. Systems and Control Letter, 29:291294, Feb. 1997.</p>
  </div>
  <div class="page">
    <p>[10] V. Borkar and P. R. Kumar. Dynamic Cesaro-Wardrop equilibration in networks. IEEE Transactions on Automatic Control, 48(3):382396, Mar. 2003.</p>
    <p>[11] V. Borkar and S. Meyn. The O.D.E. method for convergence of stochastic approximation and reinforcement learning. SIAM Journal on Control, 38(2):447469, 2000.</p>
    <p>[12] T. Boulogne, E. Altman, O. Pourtallier, and H. Kameda. Mixed equilibrium for multiclass routing games. IEEE Transactions on Automatic Control, 47(6):903916, June 2002.</p>
    <p>[13] J. A. Boyan and M. L. Littman. Advances in Neural Information Processing Systems, volume 6, chapter Packet routing in dynamically changing networks: A reinforcement learning approach, pages 671678. Morgan Kaufmann, San Francisco, CA, 1993.</p>
    <p>[14] I. Castineyra, N. Chiappa, and M. Steenstrup. The Nimrod Routing Architecture, RFC 1992, Aug. 1996.</p>
    <p>[15] M. Florian and D. Hearn. Network Routing, chapter 6, Network equilibrium models and algorithms, pages 485550. Elsevier Science, 1995.</p>
    <p>[16] B. Fortz, J. Rexford, and M. Thorup. Traffic engineering with traditional IP routing protocols. IEEE Communication Magazine, Oct. 2002.</p>
    <p>[17] R. G. Gallager. A minimum delay routing algorithm using distributed computation. IEEE Transactions on Communications, COM-25(1):7385, 1977.</p>
    <p>[18] P. Gupta and P. R. Kumar. A system and traffic dependent adaptive routing algorithm for ad hoc networks. In Proceedings of IEEE 36th Conference on Decision and Control, San Diego, CA, 1997.</p>
    <p>[19] D. B. Johnson and D. A. Malt. Mobile Computing, chapter Dynamic Source Routing in Ad Hoc Wireless Networks, Chapter 5, (Tomasz Imielinski and Hank Korth, eds.). Kluwer Academic Publishers, 1996.</p>
    <p>[20] L. Kaelbling, M. Littman, and A. Moore. Reinforcement learning: A survey. Journal of Artificial Intelligence Research, 4:237285, 1996.</p>
    <p>[21] S. Karlin and H. M. Taylor. A First Course in Stochastic Processes. Academic Press, second edition, 1975.</p>
    <p>[22] Y. A. Korilis, A. A. Lazar, and A. Orda. Architecting noncooperative networks. IEEE Journal of Selected Areas in Communications, 13(7):12411251, Sept. 1995.</p>
    <p>[23] E. Koutsoupias and C. Papadimitriou. Worst-case equilibria. In Proceedings of the 16th Annual Symposium on Theoretical Aspects of Computer Science, 1999.</p>
    <p>[24] S. Kumar. Confidence based dual reinforcement Q-routing: an on-line adaptive network routing algorithm. Technical Report AI98-267, Department of Computer Sciences, The University of Texas, Austin, Texas, U.S.A., 1998.</p>
    <p>[25] H. J. Kushner and G. G. Yin. Stochastic Approximation Algorithms and Applications. Springer Verlag, New York, NY, 1997.</p>
    <p>[26] M. L. Littman and J. A. Boyan. A distributed reinforcement learning scheme for network routing. In Proceedings of the 1993 International Workshop on Applications of Neural Networks to Telecommunications, pages 4551, Hillsdale NJ, 1993.</p>
    <p>[27] Network Simulator  ns-2. http://www.isi.edu/nsnam/ns/.</p>
  </div>
  <div class="page">
    <p>[28] L. Qiu, Y. R. Yang, Y. Zhang, and S. Shenker. On selfish routing in Internet-like environments. In Proceedings of ACM SIGCOMM 03, Karlsruhe, Germany, Aug. 2003.</p>
    <p>[29] J. B. Rosen. Existence and uniqueness of equilibrium points for concave n-person games. Econometrica, 33:520534, July 1965.</p>
    <p>[30] T. Roughgarden and E. Tardos. How bad is selfish routing? Journal of ACM, 49(2):236259, 2002.</p>
    <p>[31] B. A. Sanders. An asynchronous distributed flow control algorithm for rate allocation in computer networks. IEEE Trans. on Computer, 37:779787, 1988.</p>
    <p>[32] S. Savage, T. Anderson, A. Aggarwal, D. Becker, N. Cardwell, A. Collins, E. Hoffman, J. Snell, A. Vahdat, G. Voelker, and J. Zahorjan. Detour: a case for informed Internet routing and transport. In IEEE Micro, volume 19, pages 5059, Jan. 1999.</p>
    <p>[33] N. Spring, R. Mahajan, and D. Wetherall. Rocketfuel: An ISP topology mapping engine. Available from www.cs.washington.edu/research/networking/rocketfuel/.</p>
    <p>[34] D. Subramanian, P. Druschel, and J. Chen. Ants and reinforcement learning: A case study in routing in dynamic networks. In IJCAI (2), pages 832839, 1997.</p>
    <p>[35] V. Tadic and S. Meyn. Asymptotic properties of two time-scale stochastic approximation algorithms with constant step sizes. In Proceedings of the 2003 American Control Conference, June 2003.</p>
    <p>[36] H. Tangmunarunkit, R. Govindan, S. Shenker, and D. Estrin. The impact of routing policy on Internet paths. In Proceedings of IEEE INFOCOM 01, Anchorage, AK, Apr. 2001.</p>
    <p>[37] W. K. Tsai. Optimal Quasi-static Routing for Virtual Circuit Networks Subjected to Stochastic Inputs. PhD thesis, MIT, 1986.</p>
    <p>[38] J. N. Tsitsiklis and D. P. Bertsekas. Distributed asynchronous optimal routing in data networks. IEEE Transactions on Automatic Control, 31:325332, 1986.</p>
    <p>[39] J. N. Tsitsiklis, D. P. Bertsekas, and M. Athans. Distributed asynchronous deterministic and stochastic gradient optimization algorithms. IEEE Transactions on Automatic Control, 31(9):803812, 1986.</p>
    <p>[40] J. G. Wardrop. Some theoretical aspects of road traffic research. In Proceedings of the Institute of Civil Engineers, Part II, volume 1, pages 325378, 1952.</p>
    <p>[41] H. Xie, L. Qiu, Y. R. Yang, and Y. Zhang. On self adaptive routing in dynamic environments  an evaluation and design using a simple, probabilistic scheme. Technical Report YALEU/DCS/TR1289, Computer Science Department, Yale University, May 2004.</p>
    <p>[42] M. Zhang, B. Karp, S. Floyd, and L. Peterson. RR-TCP: A reordering-robust TCP with DSACK. In Proceedings of ICNP 2003, Nov. 2003.</p>
    <p>[43] Y. Zhang, M. Roughan, N. Duffield, and A. Greenberg. Fast accurate computation of large-scale IP traffic matrices from link loads. In Proceedings of ACM SIGMETRICS, June 2003.</p>
  </div>
</Presentation>
