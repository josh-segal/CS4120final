<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>The Design and Implementation of Open vSwitch</p>
    <p>Ben Pfaff</p>
    <p>Justin Pettit</p>
    <p>Teemu Koponen</p>
    <p>Ethan J. Jackson</p>
    <p>Andy Zhou</p>
    <p>Jarno Rajahalme</p>
    <p>Jesse Gross</p>
    <p>Alex Wang</p>
    <p>Jonathan Stringer</p>
    <p>Pravin Shelar</p>
    <p>Keith Amidon</p>
    <p>Martin Casado</p>
    <p>VMware Awake Networks</p>
  </div>
  <div class="page">
    <p>What is Open vSwitch?</p>
    <p>From openvswitch.org:</p>
    <p>Open vSwitch is a production quality, multilayer virtual switch licensed under the open source Apache 2.0 license. It is designed to enable massive network automation through programmatic extension, while still supporting standard</p>
    <p>management interfaces and protocols (e.g. NetFlow, sFlow, SPAN, RSPAN, CLI, LACP, 802.1ag).</p>
  </div>
  <div class="page">
    <p>Where is Open vSwitch Used?</p>
    <p>Broad support:  Linux, FreeBSD, NetBSD, Windows, ESX</p>
    <p>KVM, Xen, Docker, VirtualBox, Hyper-V,</p>
    <p>OpenStack, CloudStack, OpenNebula,</p>
    <p>Widely used:  Most popular OpenStack networking backend</p>
    <p>Default network stack in XenServer</p>
    <p>1,440 hits in Google Scholar</p>
    <p>Thousands of subscribers to OVS mailing lists</p>
  </div>
  <div class="page">
    <p>Open vSwitch Architecture</p>
    <p>kernel moduleovs-vswitchd Netlink</p>
    <p>u se</p>
    <p>r ke</p>
    <p>rn e</p>
    <p>l</p>
    <p>VM 1 VM nVMs</p>
    <p>Controller</p>
    <p>Hypervisor</p>
    <p>...</p>
    <p>ovsdb-server</p>
    <p>VM 2</p>
    <p>OVSDB</p>
    <p>NICs</p>
    <p>O VSDB</p>
    <p>O pe</p>
    <p>nF lo</p>
    <p>w</p>
  </div>
  <div class="page">
    <p>Table 0</p>
    <p>Flow 1</p>
    <p>Flow 2</p>
    <p>...</p>
    <p>OpenFlow tables</p>
    <p>Use Case: Network Virtualization</p>
    <p>Table 1 Flow 1</p>
    <p>Flow 2</p>
    <p>...</p>
    <p>Table 24 Flow 1</p>
    <p>Flow 2</p>
    <p>...</p>
    <p>...</p>
    <p>Physical to Logical</p>
    <p>L2 Lookup</p>
    <p>Logical to Physical</p>
    <p>...</p>
    <p>packet ingress</p>
    <p>packet egress</p>
    <p>OpenFlow Pipeline</p>
  </div>
  <div class="page">
    <p>Table 0</p>
    <p>Flow 1</p>
    <p>Flow 2</p>
    <p>...</p>
    <p>OpenFlow tables</p>
    <p>Implications for Forwarding Performance</p>
    <p>Table 1 Flow 1</p>
    <p>Flow 2</p>
    <p>...</p>
    <p>Table 24 Flow 1</p>
    <p>Flow 2</p>
    <p>...</p>
    <p>packet ingress ...</p>
    <p>packet egress</p>
    <p>Physical to Logical</p>
    <p>L2 Lookup</p>
    <p>Logical to Physical</p>
    <p>...</p>
    <p>k 0 hash</p>
    <p>lookups k</p>
    <p>lookups</p>
    <p>k 24</p>
    <p>hash lookups</p>
    <p>...</p>
  </div>
  <div class="page">
    <p>Non-solutions</p>
    <p>All of these helped:  Multithreading</p>
    <p>Userspace RCU  Batching packet processing  Classifier optimizations  Microoptimizations</p>
    <p>None of it helped enough: % versus x.</p>
    <p>Classification is expensive on general-purpose CPUs!</p>
  </div>
  <div class="page">
    <p>OVS Cache v1: Microflow Cache Microflow:  Complete set of packet</p>
    <p>headers and metadata  Suitable for hash table  Shaded data below:</p>
    <p>Eth IP TCP payload</p>
    <p>OpenFlow Tables</p>
    <p>Microflow Cache</p>
    <p>u se</p>
    <p>rs p</p>
    <p>a c e</p>
    <p>ke rn</p>
    <p>e l</p>
    <p>OpenFlow Controller (in theory)</p>
    <p>hit</p>
    <p>miss</p>
  </div>
  <div class="page">
    <p>Table 0</p>
    <p>Flow 1</p>
    <p>Flow 2</p>
    <p>...</p>
    <p>OpenFlow tables</p>
    <p>Speedup with Microflow Cache</p>
    <p>Table 1 Flow 1</p>
    <p>Flow 2</p>
    <p>...</p>
    <p>Table 24 Flow 1</p>
    <p>Flow 2</p>
    <p>...</p>
    <p>...</p>
    <p>Physical to Logical</p>
    <p>L2 Lookup</p>
    <p>Logical to Physical</p>
    <p>...</p>
    <p>k 0 hash</p>
    <p>lookups k</p>
    <p>lookups</p>
    <p>k 24</p>
    <p>hash lookups</p>
    <p>...</p>
    <p>From 100+ hash lookups per packet, to just 1!</p>
    <p>Micro flow</p>
    <p>cach e</p>
    <p>(1 ha sh lo</p>
    <p>okup )</p>
    <p>packet egress</p>
    <p>packet ingress</p>
  </div>
  <div class="page">
    <p>Microflow Caching in Practice</p>
    <p>Tremendous speedup for most workloads  Problematic traffic patterns:</p>
    <p>Port scans  Malicious  Accidental (!)</p>
    <p>Peer-to-peer rendezvous applications  Some kinds of network testing</p>
    <p>All of this traffic has lots of short-lived microflows  Fundamental caching problem: low hit rate</p>
  </div>
  <div class="page">
    <p>Table 0</p>
    <p>Flow 1</p>
    <p>Flow 2</p>
    <p>...</p>
    <p>OpenFlow tables</p>
    <p>Using a More Expensive Cache</p>
    <p>Table 1 Flow 1</p>
    <p>Flow 2</p>
    <p>...</p>
    <p>Table 24 Flow 1</p>
    <p>Flow 2</p>
    <p>...</p>
    <p>packet ingress ...</p>
    <p>packet egress</p>
    <p>Physical to Logical</p>
    <p>L2 Lookup</p>
    <p>Logical to Physical</p>
    <p>...</p>
    <p>k 0 hash</p>
    <p>lookups k</p>
    <p>lookups k</p>
    <p>lookups</p>
    <p>k 24</p>
    <p>hash lookups</p>
    <p>...</p>
    <p>If k c &lt;&lt; k</p>
    <p>Cach e (k c</p>
    <p>hash look</p>
    <p>ups)</p>
  </div>
  <div class="page">
    <p>Naive Approach to Populating Cache</p>
    <p>Combine tables 0...24 into one flow table. Easy! Usually, kc &lt;&lt; k0 + k1 +  + k24. But:</p>
    <p>Table 0</p>
    <p>ip_src=a</p>
    <p>ip_src=b</p>
    <p>ip_src=c</p>
    <p>ip_src=d</p>
    <p>Table 1</p>
    <p>ip_dst=e</p>
    <p>ip_dst=f</p>
    <p>ip_dst=g</p>
    <p>ip_dst=h</p>
    <p>Table 0+1+...+24</p>
    <p>ip_src=a, ip_dst=e, , eth_dst=i</p>
    <p>ip_src=a, ip_dst=e, , eth_dst=j</p>
    <p>ip_src=a, ip_dst=e, , eth_dst=k</p>
    <p>...</p>
    <p>ip_src=d, ip_dst=h, , eth_dst=k</p>
    <p>ip_src=d, ip_dst=h, , eth_dst=m</p>
    <p>=</p>
    <p>n 1 flows n</p>
    <p>up to n 1  n</p>
    <p>Table 24</p>
    <p>eth_dst=i</p>
    <p>eth_dst=j</p>
    <p>eth_dst=k</p>
    <p>eth_dst=m</p>
    <p>n 24</p>
    <p>flows</p>
    <p>Crossproduct Problem</p>
  </div>
  <div class="page">
    <p>Lazy Approach to Populating Cache</p>
    <p>Solution: Build cache of combined megaflows lazily as packets arrive.</p>
    <p>Table 0</p>
    <p>ip_src=a</p>
    <p>ip_src=b</p>
    <p>ip_src=c</p>
    <p>ip_src=d</p>
    <p>Table 1</p>
    <p>ip_dst=e</p>
    <p>ip_dst=f</p>
    <p>ip_dst=g</p>
    <p>ip_dst=h</p>
    <p>Megaflow Cache</p>
    <p>ip_src=a, ip_dst=f, , eth_dst=i</p>
    <p>ip_src=c, ip_dst=g, , eth_dst=k</p>
    <p>ip_src=d, ip_dst=e, , eth_dst=m</p>
    <p>=</p>
    <p>Table 24</p>
    <p>eth_dst=i</p>
    <p>eth_dst=j</p>
    <p>eth_dst=k</p>
    <p>eth_dst=m</p>
    <p>Same (or better!) table lookups as naive approach. Traffic locality yields practical cache size.</p>
    <p>populated dynamically only from actually observed</p>
    <p>packets</p>
    <p>...</p>
    <p>......</p>
    <p>n 1 flows n</p>
  </div>
  <div class="page">
    <p>OVS Cache v2: Megaflow Cache</p>
    <p>OpenFlow Tables</p>
    <p>Megaflow Cache</p>
    <p>u se</p>
    <p>rs p</p>
    <p>a c e</p>
    <p>ke rn</p>
    <p>e l</p>
    <p>hit</p>
    <p>miss</p>
  </div>
  <div class="page">
    <p>Making Megaflows Better</p>
    <p>Megaflows are more effective when they match fewer fields.  Megaflows that match TCP ports are almost like microflows!</p>
    <p>Described approach matches every field that appears in any flow table</p>
    <p>Requirements:  online</p>
    <p>fast</p>
    <p>Contribution: Megaflow generation improvements (Section 5).</p>
  </div>
  <div class="page">
    <p>Megaflow vs. Microflow Cache Performance</p>
    <p>Microflow cache:  k0 + k1 +  + k24 lookups for first packet in microflow</p>
    <p>1 lookup for later packets in microflow</p>
    <p>Megaflow cache:  kc lookups for (almost) every packet</p>
    <p>kc &gt; 1 is normal, so megaflows perform worse in common case!</p>
    <p>Best of both worlds would be:  kc lookups for first packet in microflow</p>
    <p>1 lookup for later packets in microflow</p>
  </div>
  <div class="page">
    <p>OVS Cache v3: Dual Caches</p>
    <p>OpenFlow Tables</p>
    <p>Microflow Cache</p>
    <p>Megaflow Cache</p>
    <p>u se</p>
    <p>rs p</p>
    <p>a c e</p>
    <p>ke rn</p>
    <p>e l</p>
    <p>hit</p>
    <p>miss</p>
    <p>M hit</p>
  </div>
  <div class="page">
    <p>Parting Thoughts</p>
    <p>Architectural tension: expressibility vs. performance  OpenFlow is expressive but troublesome to make fast on x86</p>
    <p>Performance requirements can make applications avoid OpenFlow</p>
    <p>Caching provides OVS with expressibility and performance  Applications can freely evolve decoupled from performance</p>
    <p>Specialized code would be slower!</p>
    <p>Starting from a more general problem produced better results</p>
  </div>
</Presentation>
