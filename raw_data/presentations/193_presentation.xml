<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Similarity Search: A Matching Based Approach</p>
    <p>Rui Zhang</p>
    <p>The University of Melbourne July 2006</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Traditional approach to similarity search</p>
    <p>Deficiencies of the traditional approach</p>
    <p>Our proposal: the n-match query</p>
    <p>Algorithms to process the n-match query</p>
    <p>Experimental results</p>
    <p>Conclusions and future work</p>
  </div>
  <div class="page">
    <p>Similarity Search : Traditional Approach</p>
    <p>Objects represented by multidimensional vectors</p>
    <p>The traditional approach to similarity search: kNN query Q = ( 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)</p>
    <p>Elevation Aspect Slope Hillshade (9am) Hillshade (noon) Hillshade (3pm)</p>
    <p>ID d1 d2 d3 d4 d5 d6 d7 d8 d9 d10 Dist</p>
    <p>P1 1.1 1 1.2 1.6 1.1 1.6 1.2 1.2 1 1</p>
    <p>P2 1.4 1.4 1.4 1.5 1.4 1 1.2 1.2 1 1</p>
    <p>P3 1 1 1 1 1 1 2 1 2 2</p>
    <p>P4 20 20 21 20 22 20 20 19 20 20</p>
    <p>P5 19 21 20 20 20 21 18 20 22 20</p>
    <p>P6 21 21 18 19 20 19 21 20 20 20</p>
  </div>
  <div class="page">
    <p>Deficiencies of the Traditional Approach</p>
    <p>Deficiencies</p>
    <p>Distance is affected by a few dimensions with high dissimilarity</p>
    <p>Partial similarities can not be discovered</p>
    <p>The traditional approach to similarity search: kNN query Q = ( 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)</p>
    <p>ID d1 d2 d3 d4 d5 d6 d7 d8 d9 d10 Dist</p>
    <p>P1 1.1 1 1.2 1.6 1.1 1.6 1.2 1.2 1 1</p>
    <p>P2 1.4 1.4 1.4 1.5 1.4 1 1.2 1.2 1 1</p>
    <p>P3 1 1 1 1 1 1 2 1 2 2</p>
    <p>P4 20 20 21 20 22 20 20 19 20 20</p>
    <p>P5 19 21 20 20 20 21 18 20 22 20</p>
    <p>P6 21 21 18 19 20 19 21 20 20 20</p>
  </div>
  <div class="page">
    <p>The N-Match Query : Warm-Up</p>
    <p>Description  Matches between two objects in n dimensions. (n  d)  The n dimensions are chosen dynamically to make the two objects m</p>
    <p>atch best.</p>
    <p>How to define a match  Exact match  Match with tolerance</p>
    <p>The similarity search example Q = ( 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)</p>
    <p>ID d1 d2 d3 d4 d5 d6 d7 d8 d9 d10 Dist</p>
    <p>P1 1.1 1 1.2 1.6 1.1 1.6 1.2 1.2 1 1</p>
    <p>P2 1.4 1.4 1.4 1.5 1.4 1 1.2 1.2 1 1</p>
    <p>P3 1 1 1 1 1 1 2 1 2 2</p>
    <p>P4 20 20 21 20 22 20 20 19 20 20</p>
    <p>P5 19 21 20 20 20 21 18 20 22 20</p>
    <p>P6 21 21 18 19 20 19 21 20 20 20</p>
    <p>n = 6</p>
  </div>
  <div class="page">
    <p>The N-Match Query : The Definition  The n-match difference</p>
    <p>Given two d-dimensional points P(p1, p2, , pd) and Q(q1, q2, , qd), let i = |pi - qi|, i=1,,d. Sort the array {1 , , d} in increasing order and let the sorted array be {1, , d}. Then n is the n-match difference between P and Q.</p>
    <p>The n-match query Given a d-dimensional database DB, a query point Q and an integer n (nd), find the point P  DB that has the smallest n-match difference to Q. P is called the n-match of Q.</p>
    <p>The similarity search example Q = ( 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)</p>
    <p>ID d1 d2 d3 d4 d5 d6 d7 d8 d9 d10 Dist</p>
    <p>P1 1.1 1 1.2 1.6 1.1 1.6 1.2 1.2 1 1</p>
    <p>P2 1.4 1.4 1.4 1.5 1.4 1 1.2 1.2 1 1</p>
    <p>P3 1 1 1 1 1 1 2 1 2 2</p>
    <p>P4 20 20 21 20 22 20 20 19 20 20</p>
    <p>P5 19 21 20 20 20 21 18 20 22 20</p>
    <p>P6 21 21 18 19 20 19 21 20 20 20</p>
    <p>n = 6n = 7n = 8</p>
  </div>
  <div class="page">
    <p>The N-Match Query : Extensions  The k-n-match query</p>
    <p>Given a d-dimensional database DB, a query point Q, an integer k, and an int eger n, find a set S which consists of k points from DB so that for any point P 1S and any point P2DB-S, P1s n-match difference is smaller than P2s n-m atch difference. S is called the k-n-match of Q.</p>
    <p>The frequent k-n-match query Given a d-dimensional database DB, a query point Q, an integer k, and an integer range [n0, n1] within [1,d], let S0, , Si be the answer sets of k-n0-match, , k-n1-match, respectively, find a set T of k points, so that for any point P1T and any point P2DB-T, P1s number of appearances in S0, , Si is larger than or equal to P2s number of appearances in S0, , Si .</p>
    <p>The similarity search example Q = ( 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)</p>
    <p>ID d1 d2 d3 d4 d5 d6 d7 d8 d9 d10 Dist</p>
    <p>P1 1.1 1 1.2 1.6 1.1 1.6 1.2 1.2 1 1</p>
    <p>P2 1.4 1.4 1.4 1.5 1.4 1 1.2 1.2 1 1</p>
    <p>P3 1 1 1 1 1 1 2 1 2 2</p>
    <p>P4 20 20 21 20 22 20 20 19 20 20</p>
    <p>P5 19 21 20 20 20 21 18 20 22 20</p>
    <p>P6 21 21 18 19 20 19 21 20 20 20</p>
    <p>n = 6</p>
  </div>
  <div class="page">
    <p>Cost Model  The multiple system information retrieval model</p>
    <p>Objects are stored in different systems and scored by each system  Each system can sort the objects according to their scores  A query retrieves the scores of objects from different systems and then</p>
    <p>combine them using some aggregation function</p>
    <p>The cost  Retrieval of scores  proportional to the number of scores retrieved</p>
    <p>The goal  To minimize the scores retrieved</p>
    <p>System 1: Color</p>
    <p>Object ID Score</p>
    <p>System 1: Color</p>
    <p>Object ID Score</p>
    <p>System 3: Texture</p>
    <p>Object ID Score</p>
    <p>System 2: Shape</p>
    <p>Object ID Score</p>
    <p>System 2: Shape</p>
    <p>Object ID Score</p>
    <p>System 3: Texture</p>
    <p>Object ID Score</p>
    <p>Q : color=red &amp; shape=round &amp; texture cloud</p>
  </div>
  <div class="page">
    <p>The AD Algorithm  The AD algorithm for the k-n-match query</p>
    <p>Locate the querys attributes in every dimension  Retrieve the objects attributes from the querys attributes in both directions  The objects attributes are retrieved in Ascending order of their Differences to</p>
    <p>the querys attributes. An n-match is found when it appears n times.</p>
    <p>System 1: Color</p>
    <p>Object ID Score</p>
    <p>System 2: Shape</p>
    <p>Object ID Score</p>
    <p>System 3: Texture</p>
    <p>Object ID Score</p>
    <p>Q : color=red &amp; shape=round &amp; texture cloud</p>
    <p>Q : ( 3.0 , 7.0 , 4.0 )</p>
    <p>d1 d2 d3</p>
    <p>Auxiliary structures  Next attribute to retrieve g[2d]</p>
    <p>Number of appearances appear[c]</p>
    <p>Answer set S</p>
    <p>d1 d2 d3</p>
    <p>{ }</p>
    <p>{ 3 }</p>
    <p>d1 d2 d3</p>
    <p>{ 3 , 2 }</p>
    <p>Attr Attr Attr</p>
  </div>
  <div class="page">
    <p>The AD Algorithm : Extensions</p>
    <p>The AD algorithm for the frequent k-n-match query  The frequent k-n-match query</p>
    <p>Given an integer range [n0, n1], find k-n0-match, k-(n0+1)-match, ... , kn1-match of the query, S0, S1, ... , Si.</p>
    <p>Find k objects that appear most frequently in S0, S1, ... , Si.</p>
    <p>Retrieve the same number of attributes as processing a k-n1-match query.</p>
    <p>Disk based solutions for the (frequent) k-n-match query</p>
    <p>Disk based AD algorithm  Sort each dimension and store them sequentially on the disk  When reaching the end of a disk page, read the next page from disk</p>
    <p>Existing indexing techniques  Tree-like structures: R-trees, k-d-trees  Mapping based indexing: space-filling curves, iDistance  Sequential scan  Compression based approach (VA-file)</p>
  </div>
  <div class="page">
    <p>Experiments : Effectiveness  Searching by k-n-match</p>
    <p>COIL-100 database  54 features extracted, such as color histograms, area moments</p>
    <p>Searching by frequent k-n-match  UCI Machine learning repository  Competitors:</p>
    <p>IGrid  Human-Computer Interactive NN search</p>
    <p>(HCINN)</p>
    <p>k-n-match query, k=4</p>
    <p>n Images returned</p>
    <p>kNN query</p>
    <p>k Images returned</p>
    <p>Data sets (d) IGrid HCINN Freq. k-n-match</p>
    <p>Ionosphere (34) 80.1% 86% 87.5%</p>
    <p>Segmentation (19) 79.9% 83% 87.3%</p>
    <p>Wdbc (30) 87.1% N.A. 92.5%</p>
    <p>Glass (9) 58.6% N.A. 67.8%</p>
    <p>Iris (4) 88.9% N.A. 89.6%</p>
  </div>
  <div class="page">
    <p>Experiments : Efficiency  Disk based algorithms for the Frequent k-n-mach query</p>
    <p>Texture dataset (68,040 records); uniform dataset (100,000 records)  Competitors:</p>
    <p>The AD algorithm  VA-file  Sequential scan</p>
  </div>
  <div class="page">
    <p>Experiments : Efficiency (continued)  Comparison with other similarity search techniques</p>
    <p>Texture dataset ; synthetic dataset  Competitors:</p>
    <p>Frequent k-n-match query using the AD algorithm  IGrid  Human-Computer Interactive NN search (HCINN)</p>
  </div>
  <div class="page">
    <p>Conclusions and Future Work  Conclusions</p>
    <p>We proposed a new approach to do similarity search, that is, the kn-match query. It has the advantage of being tolerant to noise and a ble to discover partial similarity.</p>
    <p>If we dont choose a good n value, the results of the k-n-match quer y may not be good enough to find full similarity, so we further propos e the frequent k-n-match query to address this problem.</p>
    <p>We proposed the AD algorithm, which is optimal for both the k-n-mat ch query and the frequent k-n-match query under the multiple syste m information retrieval model. We also apply it in a disk based mod el.</p>
    <p>Based on an extensive experimental study, we see that the frequent k-n-match query is more effective in similarity search than existing t echniques such as IGrid and Human-Computer Interactive NN sear ch. We also see that the frequent k-n-match query can be processe d more efficiently than other techniques by our proposed AD algorith m in a disk based model.</p>
    <p>Future work  We may perform more experiments to see whether the traditional k</p>
    <p>NN search can always be replaced by frequent k-n-match search; if not, in which scenarios we should use it?</p>
  </div>
  <div class="page">
    <p>Questions?</p>
    <p>My contact  Email: rui@csse.unimelb.edu.au  Website: http://www.csse.unimelb.edu.au/~rui</p>
  </div>
</Presentation>
