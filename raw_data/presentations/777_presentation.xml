<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Towards a Model of Computer Systems Research</p>
    <p>Tom Anderson University of Washington</p>
  </div>
  <div class="page">
    <p>P2P vs. Systems Research</p>
    <p>P2P</p>
    <p>No centralized control Emergent behavior Heavy tailed distributions Incentives matter Randomness helps</p>
    <p>Systems Research</p>
    <p>No centralized control Emergent behavior Heavy tailed distributions? Incentives matter? Randomness hurts?</p>
    <p>This talk:</p>
    <p>Explain systems research using tools from P2P systems research</p>
    <p>Suggest some mechanisms to better align author and conference incentives</p>
  </div>
  <div class="page">
    <p>Mean Score + StdDev NSDI 08</p>
  </div>
  <div class="page">
    <p>Mean Score + StdDev OSDI 06</p>
  </div>
  <div class="page">
    <p>Mean Score + StdDev SOSP 07</p>
  </div>
  <div class="page">
    <p>Randomness is Fundamental?</p>
    <p>Little consensus as to what constitutes merit  Importance of problem?  Creativity of solution?  Completeness of evaluation?  Effectiveness of presentation?  All of the above?</p>
    <p>Large #s of submissions makes consistency hard to achieve</p>
    <p>Small PC, huge workload, burnout, lack of attention to detail</p>
    <p>Large PC, lower workload, less consistency</p>
  </div>
  <div class="page">
    <p>SIGCOMM 06 Experiment</p>
    <p>Manage randomness explicitly  Large PC, split between light and heavy  Light + heavy PC: bin into accept, marginal, reject</p>
    <p>With as few reviews as possible  Add reviews for papers with high variance  Add reviews for papers at the margin</p>
    <p>Program committee meeting (just heavy PC)  Pre-accept half the papers  Pre-select 2x to discuss  Each paper under discussion read by at least 5 from heavy PC  Result: success disaster</p>
    <p>Little basis for discriminating between papers at the boundary</p>
  </div>
  <div class="page">
    <p>Two Models of Distribution of Merit</p>
  </div>
  <div class="page">
    <p>Citation Distribution for SOSP</p>
  </div>
  <div class="page">
    <p>Incentives for Marginal Effort</p>
    <p>With unit merit and no noise:  Impulse function at accept threshold</p>
    <p>With unit merit and noise, single conference:  Gaussian function at accept threshold</p>
    <p>With unit merit, high noise, and multiple conferences:  Peak incentive well below accept threshold  Repeated attempts without improving paper</p>
    <p>Wed like effort to reflect the underlying merit of the idea  Good ideas are pursued, even after publication  Mediocre ideas are published, and the author quickly moves on</p>
  </div>
  <div class="page">
    <p>A Modest Suggestion</p>
    <p>Reward, like merit, should be a continuous function</p>
    <p>Publish rank and error bars for every paper accepted at a conference</p>
    <p>Computed automatically from individual PC ranking  Post-hoc (benefit from perspectives of all reviewers)</p>
    <p>After some time has elapsed, re-rank  Encourage continued effort on good ideas  Like test in time, but applied to all published papers</p>
  </div>
  <div class="page">
    <p>Afternoon Discussion Topics  Double-blind vs. single-blind reviews  Should authors disclose previous reviews of the same</p>
    <p>paper?  Are author-rebuttals useful?  When should ``open reviews'' be used?  Should we review the reviewers?  CS-wide citation reporting and indexing  Travel reduction  Decoupling publication from presentation  How do we quantify the merit of a conference?  Do PCs tend to favor PC-authored papers?  How random are PC decisions?  How big is the rejected-paper tumbleweed?</p>
  </div>
  <div class="page">
    <p>Afternoon Discussion Topics  Is there a correlation between PC size and conference impact?  Does overlapping membership between PCs decrease diversity?  Is there a correlation between number of papers accepted and</p>
    <p>quality?  Do overall scores predict what gets accepted?  What do authors like and dislike about reviews?  How to handle suspected author misbehavior  How to handle suspected reviewer misbehavior  When, why, and how to shepherd  Reviews of review-management software  Proposals for new or improved review-management features</p>
  </div>
</Presentation>
