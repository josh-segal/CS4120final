<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>A Joint Model</p>
    <p>of Text and Aspect Ratings  for Sentiment Summarization</p>
    <p>Ivan Titov University of Illinois</p>
    <p>at Urbana-Champaign</p>
    <p>Ryan McDonald Google Inc.</p>
  </div>
  <div class="page">
    <p>User Generated (Text) Content</p>
  </div>
  <div class="page">
    <p>User Generated Content</p>
    <p>Abundant source of information  Diverse source (expert to novice to biased to spam)  Data often contains structured labels</p>
  </div>
  <div class="page">
    <p>What to do with annotations?</p>
    <p>Traditional view: use them as training data  Train a model and run/eval it on new data  Isnt this just a contrived task?  Not always:</p>
    <p>Train sentiment classifiers on reviews use it 4 blogs  Train review ratings, apply on phrases or sentences  Train on one blog, apply to unannotated blogs</p>
  </div>
  <div class="page">
    <p>Leverage Annotations for Related Problems  Can we use ... ?</p>
    <p>Star ratings to predict phrase level sentiment  Star ratings to segment the text  Del.icio.us tags to place ads / improve ranking  Helpfulness rankings to extract QA pairs  Helpfulness rankings to build language models  ...</p>
    <p>Auxiliary tasks are closely related to signals provided by the user</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation and Mention Extraction Problem  Multi-Aspect Sentiment Model  Empirical evaluation</p>
  </div>
  <div class="page">
    <p>Extraction Problem</p>
    <p>Focus on models for mention extraction  Can we use aspect ratings?</p>
  </div>
  <div class="page">
    <p>Extraction Problem</p>
    <p>Focus on models for mention extraction  Can we use aspect ratings?</p>
  </div>
  <div class="page">
    <p>Extraction Problem</p>
    <p>Focus on models for mention extraction  Can we use aspect ratings?</p>
  </div>
  <div class="page">
    <p>Extraction Problem</p>
    <p>Focus on models for mention extraction  Can we use aspect ratings?</p>
  </div>
  <div class="page">
    <p>Extraction Problem</p>
    <p>Focus on models for mention extraction  Can we use aspect ratings?</p>
  </div>
  <div class="page">
    <p>Extraction Problem</p>
    <p>Focus on models for mention extraction  Can we use aspect ratings?</p>
  </div>
  <div class="page">
    <p>Extraction Problem</p>
    <p>Focus on models for mention extraction  Can we use aspect ratings?</p>
  </div>
  <div class="page">
    <p>Extraction Problem</p>
    <p>Focus on models for mention extraction  Can we use aspect ratings?</p>
  </div>
  <div class="page">
    <p>Sentiment Summarization</p>
    <p>Take a set of reviews for an entity and summarize them  Aspect-based summarization (Hu &amp; Liu 2004)</p>
    <p>Summarize along key aspects</p>
    <p>Many real world manual examples, e.g., Zagat.com</p>
  </div>
  <div class="page">
    <p>Three Tasks</p>
  </div>
  <div class="page">
    <p>Three Tasks  Identify Ratable Aspects</p>
    <p>Often we know this (pros-cons, tech specs, ontologies)</p>
  </div>
  <div class="page">
    <p>Three Tasks  Identify Ratable Aspects</p>
    <p>Often we know this (pros-cons, tech specs, ontologies)  Extract Mentions</p>
    <p>We always have to do this</p>
  </div>
  <div class="page">
    <p>Three Tasks  Identify Ratable Aspects</p>
    <p>Often we know this (pros-cons, tech specs, ontologies)  Extract Mentions</p>
    <p>We always have to do this  Aggregate Sentiment</p>
    <p>Again, we often know this (star ratings, eg, TripAdvisor)</p>
  </div>
  <div class="page">
    <p>Three Tasks  Identify Ratable Aspects</p>
    <p>Often we know this (pros-cons, tech specs, ontologies)  Extract Mentions</p>
    <p>We always have to do this  Aggregate Sentiment</p>
    <p>Again, we often know this (star ratings, eg, TripAdvisor)</p>
  </div>
  <div class="page">
    <p>Aspect Identification and Extraction</p>
    <p>Common method: String-based extraction (Hu &amp; Liu 04)  Use frequently occurring nouns that are modified by opinion</p>
    <p>words as relevant aspects</p>
    <p>Long list of aspects (keywords)  Use of topic models :</p>
    <p>Mult-Grain Latent Dirichlet Allocation (Titov &amp; McDonald 08)</p>
  </div>
  <div class="page">
    <p>Topic Models  for Summarization  Topic models:</p>
    <p>Induce semantic topics discussed in text  Each topic is a distribution of words (language model)  MG-LDA discovers topics which correspond to ratable</p>
    <p>aspects (Titov &amp; McDonald 08)  Topic models can be used to classify text fragments</p>
    <p>Example of induced topics for domain Mp3:</p>
    <p>Sound Quality</p>
    <p>sound</p>
    <p>quality</p>
    <p>headphones</p>
    <p>volume</p>
    <p>bass</p>
    <p>earphones</p>
    <p>ear</p>
    <p>rock</p>
    <p>settings</p>
    <p>Features</p>
    <p>games</p>
    <p>features</p>
    <p>clock</p>
    <p>contacts</p>
    <p>calendar</p>
    <p>alarm</p>
    <p>notes</p>
    <p>game</p>
    <p>quiz</p>
    <p>PC Connection</p>
    <p>usb</p>
    <p>pc</p>
    <p>windows</p>
    <p>port</p>
    <p>transfer</p>
    <p>computer</p>
    <p>mac</p>
    <p>software</p>
    <p>cable</p>
    <p>Tech Problems</p>
    <p>reset</p>
    <p>noise</p>
    <p>backlight</p>
    <p>slow</p>
    <p>freeze</p>
    <p>turn</p>
    <p>remove</p>
    <p>playing</p>
    <p>hot</p>
  </div>
  <div class="page">
    <p>Topic Models  for Summarization</p>
    <p>Drawbacks:  Topics are not labeled  Topics might not correspond to key aspects  We unlikely to induce the same aspects as the ones for</p>
    <p>which we have user-provided sentiment ratings</p>
    <p>? sound</p>
    <p>quality</p>
    <p>headphones</p>
    <p>volume</p>
    <p>bass</p>
    <p>earphones</p>
    <p>ear</p>
    <p>rock</p>
    <p>settings</p>
    <p>?</p>
    <p>games</p>
    <p>features</p>
    <p>clock</p>
    <p>contacts</p>
    <p>calendar</p>
    <p>alarm</p>
    <p>notes</p>
    <p>game</p>
    <p>quiz</p>
    <p>?</p>
    <p>usb</p>
    <p>pc</p>
    <p>windows</p>
    <p>port</p>
    <p>transfer</p>
    <p>computer</p>
    <p>mac</p>
    <p>software</p>
    <p>cable</p>
    <p>?</p>
    <p>reset</p>
    <p>noise</p>
    <p>backlight</p>
    <p>slow</p>
    <p>freeze</p>
    <p>turn</p>
    <p>remove</p>
    <p>playing</p>
    <p>hot</p>
  </div>
  <div class="page">
    <p>Aspect Ratings</p>
    <p>Available on an increasing number of websites</p>
    <p>Give us two things  Important aspects  Signals that are</p>
    <p>correlated to the text Idea</p>
    <p>Correlate topics with user provided aspect rankings Aspects are labeled!!</p>
    <p>Their quality should be better!!</p>
  </div>
  <div class="page">
    <p>Hypotheses</p>
    <p>Topics corresponding to ratable aspects can be potentially discovered from co-occurrence information</p>
    <p>The most predictive features of an aspect ratings are features derived from text segments discussing these rated aspects</p>
    <p>We build a joint statistical model of aspect ratings and text to induce the topics corresponding to rated aspects</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation and Mention Extraction Problem  Multi-Aspect Sentiment Model  Empirical evaluation</p>
  </div>
  <div class="page">
    <p>Supervised LDA</p>
    <p>Can augment topic models to generate observed signals  S-LDA (Blei &amp; McAuliffe 08 NIPS)  Use document labels to guide topic construction  We take this insight and extend it to segmentation</p>
  </div>
  <div class="page">
    <p>Multi-Aspect Sentiment Model  For each aspect rating</p>
    <p>Add a MaxEnt classifier to the model  Associate one topic to each classifier  MaxEnt classifier uses only words from that topic to</p>
    <p>predict rating</p>
    <p>Example:  We have a rated aspect Location  We associate 1st topic in the model to this aspect  Only ngrams with words from 1st topic are used to</p>
    <p>predict the rating for Location</p>
  </div>
  <div class="page">
    <p>We need to marginalize over topics z and overall sentiment yov</p>
    <p>ov</p>
    <p>y</p>
    <p>y</p>
    <p>...</p>
    <p>...</p>
    <p>w M</p>
    <p>A</p>
    <p>N</p>
    <p>z</p>
    <p>Multi-Aspect Sentiment Model Aspect ratings</p>
    <p>Overall sentiment variable Models fact that aspect rankings are correlated</p>
    <p>If we optimize the models jointly then topics will correspond directly to aspects</p>
    <p>Can be any topic model</p>
  </div>
  <div class="page">
    <p>Shared by all aspects, models overall sentiment</p>
    <p>MAS: Efficient Modification</p>
    <p>All ngram features</p>
    <p>Aspect-specific words, is a fraction of words in assigned to</p>
    <p>Vector of topic assignments</p>
  </div>
  <div class="page">
    <p>Inference</p>
    <p>Collapsed Gibbs (Griffiths &amp; Steyvers 04)  A sample from the chain used to approx:</p>
    <p>Distribution of words in topics  Distribution of topics in text fragments</p>
    <p>Learning of Max-Ent weights is done in parallel to running a chain (Neal 92):  i.e. topic model and MaxEnt weights are learned jointly!</p>
    <p>We tried variational techniques, but they didnt work for our models</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation and Mention Extraction Problem  Multi-Aspect Sentiment Model  Empirical evaluation</p>
  </div>
  <div class="page">
    <p>Multi-Aspect Sentiment Model</p>
    <p>10,000 reviews from TripAdvisor.com  service, location, rooms aspects  Tied first three topics to these aspects ratings</p>
    <p>The first three topics correspond to associated aspects!!</p>
    <p>First 3 Local Topics Service Location Rooms</p>
    <p>staff hotel room</p>
    <p>friendly walk bathroom</p>
    <p>helpful location shower</p>
    <p>service station bed</p>
    <p>desk metro tv</p>
    <p>concierge walking small</p>
    <p>excellent away water</p>
    <p>reception right clean</p>
    <p>pleasant minute comfortable</p>
  </div>
  <div class="page">
    <p>Multi-Aspect Sentiment Model</p>
    <p>Semantic models of aspects ... what does this buy us?  Can use model directly to extract mentions of aspects</p>
  </div>
  <div class="page">
    <p>Aspect Mention Extraction</p>
    <p>Location</p>
    <p>Service</p>
    <p>Compared to a supervised MaxEnt model</p>
  </div>
  <div class="page">
    <p>Multiple Topics per Aspect Classifier  Required when an aspect is diverse</p>
    <p>e.g., Rooms = bed, bathroom, noise, view, ... Rooms</p>
    <p>rooms room room room room room check room bathroom</p>
    <p>clean noise clean floor bathroom clean arrived noise room</p>
    <p>hotel night bed view shower rooms time night shower</p>
    <p>room street comfortable rooms air comfortable day street tv</p>
    <p>small did rooms suite water bed airport did bed</p>
    <p>nice air bathroom got did small early air small</p>
    <p>comfortable rooms small views like beds room rooms water</p>
    <p>modern door beds given hot nice luggage noisy towels</p>
    <p>good open nice quite towel bathroom took open bath</p>
  </div>
  <div class="page">
    <p>Multiple topics per</p>
    <p>aspect Rooms</p>
    <p>Aspect Mention Extraction</p>
  </div>
  <div class="page">
    <p>Topics not associated to the rated aspects:</p>
    <p>Not Associated topics in MAS</p>
    <p>Food Pricing</p>
    <p>breakfast $</p>
    <p>free night</p>
    <p>coffee parking</p>
    <p>internet rate</p>
    <p>morning price</p>
    <p>buffet paid</p>
    <p>day day</p>
    <p>wine euros</p>
    <p>nice got</p>
    <p>Getting there Parking</p>
    <p>shuttle parking</p>
    <p>bus car</p>
    <p>taxi lot</p>
    <p>ride valet</p>
    <p>train park</p>
    <p>hour garage</p>
    <p>station free</p>
    <p>cab street</p>
    <p>took parked</p>
    <p>Spa Bathroom</p>
    <p>pool shower</p>
    <p>tub water</p>
    <p>hot hot</p>
    <p>indoor bathroom</p>
    <p>swimming towels</p>
    <p>outdoor toilet</p>
    <p>spa tub</p>
    <p>heated bath</p>
    <p>use pressure</p>
  </div>
  <div class="page">
    <p>Summary  A joint model of text and sentiment ratings for extracting</p>
    <p>text for sentiment summaries</p>
    <p>The model uses aspect ratings to discover corresponding topics</p>
    <p>No text labeled with aspects is required  Accuracy is comparable to supervised models</p>
    <p>Models generalize to any segmentation problem where there are correlated signals</p>
    <p>e.g., del.icio.us bookmarks, blog labels, helpfulness, ...  Related model: (Branavan et al. ACL 08): joint model for</p>
    <p>predicting key-phrases</p>
  </div>
  <div class="page">
    <p>Thanks</p>
    <p>Sasha Blair-Goldensohn, David Blei and Fernando Pereira, Dan Roth for discussion and suggestions</p>
    <p>Google, NY for hosting Ivan Titov during summer 2007</p>
  </div>
  <div class="page">
    <p>MG-LDA  Draw global topic word dist.  Draw local topic word dist.  For each document d:</p>
  </div>
  <div class="page">
    <p>LDA  Problem with LDA (and most other topic models)</p>
    <p>Co-occurrences modeled at document level  Topics are about instances not aspects</p>
    <p>e.g., iPod versus Creative Labs  Often clusters are meaningless</p>
    <p>(Service??) Topic 0: product player did support bought work unit problem $ (Creative Labs) Topic 1: gigabeat deleted waiting jukebox creative playback (iPod) Topic 11: ipod apple mac firewire dock itunes x display aac Most topics are incoherent. Only 4 out of first 40 can be viewed as aspects.</p>
  </div>
  <div class="page">
    <p>LDA  Generative model of text  Sample multinomial word</p>
    <p>distributions for each topic</p>
    <p>The for each document d:</p>
  </div>
  <div class="page">
    <p>LDA</p>
    <p>Simple solutions: LDA over sentences  Co-occurrence counts too sparse  Can use sliding window, but results look like LDA  Still cant distinguish aspect topics from the rest</p>
    <p>Another solution: Multi-grain topic models  Model local topics (aspects) and global topics (types)  Creates a bottleneck for local topics  Words generated from sliding window</p>
  </div>
  <div class="page">
    <p>Varying Granularity</p>
    <p>Global topic London: London, tube,  , Tower, Thames  global topic dist is assigned to the document</p>
    <p>Local topics:  Location: transport, station, walk, bus, minute.  View: view, window  local topic dist is assigned to current sliding window</p>
    <p>... public transport in London is straightforward, the tube station is about an 8 minute walk  or you can get a bus for  1.50 .... We had a stunning view (from the floor to ceiling window) of the Tower and the Thames.</p>
  </div>
</Presentation>
