<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Seamless Operating System Integration of Peer-to-Peer DMA Between SSDs and GPUs Shai Bergman | Tanya Brokhman | Tzachi Cohen | Mark Silberstein</p>
    <p>ACSL - Technion</p>
    <p>SPIN:</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>Summary What do we do?</p>
    <p>Enable efficient file I/O for GPUs</p>
    <p>Why?</p>
    <p>Support diverse I/O workloads involving GPUs</p>
    <p>How?</p>
    <p>Make P2P a first class citizen within the file I/O stack</p>
    <p>Results</p>
    <p>Better throughput Standard file API</p>
    <p>cross-GPU portability</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>Fast data transfers</p>
    <p>Bounded by extra copy</p>
    <p>Data resides in SSD</p>
    <p>Background CPU mediated data</p>
    <p>transfers introduce extra latency with lower</p>
    <p>throughput</p>
    <p>CPUIO - CPU mediated transfer</p>
    <p>PCIe</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>Eliminates redundant copies</p>
    <p>Not involved in data path</p>
    <p>Better power efficiency</p>
    <p>Higher throughput &amp; lower latency</p>
    <p>Background</p>
    <p>[1] J. Zhang, D. Donofrio, J. Shalf, M. T. Kandemir, and M. Jung, NVMMU: A Non-volatile Memory Management Unit for Heterogeneous GPU-SSD Architectures,</p>
    <p>[2] H.-W. Tseng, Y. Liu, M. Gahagan, J. Li, Y. Jin, and S. Swanson, Gullfoss: Accelerating and Simplifying Data Movement Among Heterogeneous Computing and Storage Resources,</p>
    <p>[3] M. Shihab, K. Taht, and M. Jung, GPUDrive: Reconsidering Storage Accesses for GPU Acceleration, [4] H.-W. Tseng, Q. Zhao, Y. Zhou, M. Gahagan, and S. Swanson, Morpheus: creating application objects efficiently for heterogeneous</p>
    <p>computing, [5]Project Donard. https://github.com/sbates130272/donard, 2015.</p>
    <p>GPU vendors support P2P</p>
    <p>&amp;</p>
    <p>PCIe</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>S p</p>
    <p>e e</p>
    <p>d u</p>
    <p>p</p>
    <p>Block size</p>
    <p>CPUIO P2P</p>
    <p>P2P is not a silver bullet</p>
    <p>P2P is great!*</p>
    <p>* But wait  only for certain data access patterns</p>
    <p>33x 7.6x</p>
    <p>Sequential reads (e.g. grep)</p>
    <p>P2P is not a silver bullet!</p>
    <p>**data is not preloaded to the page cache</p>
    <p>4.2x</p>
    <p>CPUIO - CPU mediated transfer</p>
    <p>Large sequential reads: P2P ~1.4x SpeedupShort sequential reads: P2P ~33x Slower than CPUIO?</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>Hard to utilize</p>
    <p>Non-standard API | No misaligned accesses | LVM/MDADM incompatible</p>
    <p>No Page Cache Integration</p>
    <p>No read ahead | Cannot utilize P$ for data reuse</p>
    <p>Observations What went wrong?</p>
    <p>P2P bypasses the kernel!</p>
    <p>No file consistency</p>
    <p>Can read stale data | Requires explicit flushes to SSD</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>Objective What do we want?</p>
    <p>Regular file I/O to GPU memory</p>
    <p>int fd;</p>
    <p>...</p>
    <p>//open file</p>
    <p>...</p>
    <p>pread64(fd,gpu_buffer,20*1024,0);</p>
    <p>...</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>SPIN: Contributions</p>
    <p>Combine Page Cache and P2P Interleave system memory and SSD when possible</p>
    <p>GPU Read Ahead Activate read ahead mechanism when determined beneficial. Nested page cache within CPU memory for GPU Use</p>
    <p>Standard File API  Underlying block device</p>
    <p>support (RAID, LVM)</p>
    <p>Data Consistency + POSIX file semantics Keep POSIX file semantics + data consistency, even when CPU + GPU work on the same file</p>
    <p>Activate P2P when beneficial</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>NVMe SS D</p>
    <p>SPIN</p>
    <p>P-router P-Read Ahead policy</p>
    <p>P-cache checker</p>
    <p>P2PDMA</p>
    <p>VFS Page cache</p>
    <p>Block Layer</p>
    <p>NVMe Driver</p>
    <p>GPU</p>
    <p>GPU buffer</p>
    <p>GPU addr. extraction</p>
    <p>Current FS API</p>
    <p>file</p>
    <p>PCIe</p>
    <p>P 2</p>
    <p>P D</p>
    <p>M A</p>
    <p>t ra</p>
    <p>n sf</p>
    <p>e r</p>
    <p>fd GPU</p>
    <p>buffer</p>
    <p>pread( , )</p>
    <p>GPU RA</p>
    <p>CPU PC</p>
    <p>SPIN: High level overview</p>
    <p>RQ</p>
    <p>From Compatible SSD? Destined to GPU? Part of a sequential read? Data resides in page cache?</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>NVMe SS D</p>
    <p>SPIN</p>
    <p>P-router P-Read Ahead policy</p>
    <p>P-cache checker</p>
    <p>P2PDMA</p>
    <p>VFS Page cache</p>
    <p>Block Layer</p>
    <p>NVMe Driver</p>
    <p>GPU</p>
    <p>GPU buffer</p>
    <p>GPU addr. extraction</p>
    <p>Current FS API</p>
    <p>file</p>
    <p>PCIe</p>
    <p>P 2</p>
    <p>P D</p>
    <p>M A</p>
    <p>t ra</p>
    <p>n sf</p>
    <p>e r</p>
    <p>fd GPU</p>
    <p>buffer</p>
    <p>pread( , )</p>
    <p>GPU RA</p>
    <p>CPU PC</p>
    <p>SPIN: High level overview RQ</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>NVMe SS D</p>
    <p>SPIN</p>
    <p>P-router P-Read Ahead policy</p>
    <p>P-cache checker</p>
    <p>P2PDMA</p>
    <p>VFS Page cache</p>
    <p>Block Layer</p>
    <p>NVMe Driver</p>
    <p>GPU</p>
    <p>GPU buffer</p>
    <p>GPU addr. extraction</p>
    <p>Current FS API</p>
    <p>file</p>
    <p>PCIe</p>
    <p>P 2</p>
    <p>P D</p>
    <p>M A</p>
    <p>t ra</p>
    <p>n sf</p>
    <p>e r</p>
    <p>fd GPU</p>
    <p>buffer</p>
    <p>pread( , )</p>
    <p>GPU RA</p>
    <p>CPU PC</p>
    <p>SPIN: High level overview</p>
    <p>RQ</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>NVMe SS D</p>
    <p>SPIN</p>
    <p>P-router P-Read Ahead policy</p>
    <p>P-cache checker</p>
    <p>P2PDMA</p>
    <p>VFS Page cache</p>
    <p>Block Layer</p>
    <p>NVMe Driver</p>
    <p>GPU</p>
    <p>GPU buffer</p>
    <p>GPU addr. extraction</p>
    <p>Current FS API</p>
    <p>file</p>
    <p>PCIe</p>
    <p>P 2</p>
    <p>P D</p>
    <p>M A</p>
    <p>t ra</p>
    <p>n sf</p>
    <p>e r</p>
    <p>fd GPU</p>
    <p>buffer</p>
    <p>pread( , )</p>
    <p>GPU RA</p>
    <p>CPU PC</p>
    <p>SPIN: High level overview RQ</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>NVMe SS D</p>
    <p>SPIN</p>
    <p>P-router P-Read Ahead policy</p>
    <p>P-cache checker</p>
    <p>P2PDMA</p>
    <p>VFS Page cache</p>
    <p>Block Layer</p>
    <p>NVMe Driver</p>
    <p>GPU</p>
    <p>GPU buffer</p>
    <p>GPU addr. extraction</p>
    <p>Current FS API</p>
    <p>file</p>
    <p>PCIe</p>
    <p>P 2</p>
    <p>P D</p>
    <p>M A</p>
    <p>t ra</p>
    <p>n sf</p>
    <p>e r</p>
    <p>fd GPU</p>
    <p>buffer</p>
    <p>pread( , )</p>
    <p>GPU RA</p>
    <p>CPU PC</p>
    <p>SPIN: High level overview</p>
    <p>RQ</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>NVMe SS D</p>
    <p>SPIN</p>
    <p>P-router P-Read Ahead policy</p>
    <p>P-cache checker</p>
    <p>P2PDMA</p>
    <p>VFS Page cache</p>
    <p>Block Layer</p>
    <p>NVMe Driver</p>
    <p>GPU</p>
    <p>GPU buffer</p>
    <p>GPU addr. extraction</p>
    <p>Current FS API</p>
    <p>file</p>
    <p>PCIe</p>
    <p>P 2</p>
    <p>P D</p>
    <p>M A</p>
    <p>t ra</p>
    <p>n sf</p>
    <p>e r</p>
    <p>fd GPU</p>
    <p>buffer</p>
    <p>pread( , )</p>
    <p>GPU RA</p>
    <p>CPU PC</p>
    <p>SPIN: High level overview RQRQ</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>NVMe SS D</p>
    <p>SPIN</p>
    <p>P-router P-Read Ahead policy</p>
    <p>P-cache checker</p>
    <p>P2PDMA</p>
    <p>VFS Page cache</p>
    <p>Block Layer</p>
    <p>NVMe Driver</p>
    <p>GPU</p>
    <p>GPU buffer</p>
    <p>GPU addr. extraction</p>
    <p>Current FS API</p>
    <p>file</p>
    <p>PCIe</p>
    <p>P 2</p>
    <p>P D</p>
    <p>M A</p>
    <p>t ra</p>
    <p>n sf</p>
    <p>e r</p>
    <p>fd GPU</p>
    <p>buffer</p>
    <p>pread( , )</p>
    <p>GPU RA</p>
    <p>CPU PC</p>
    <p>SPIN: High level overview</p>
    <p>P-cache checker P-cache checker</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>SPIN: Combine page cache and P2P</p>
    <p>Sometimes the requested data resides in the P$</p>
    <p>e.g due to previous usage of the data by CPU</p>
    <p>a n</p>
    <p>sf e</p>
    <p>r T</p>
    <p>im e</p>
    <p>[ u</p>
    <p>se c]</p>
    <p>Request Size [KiB]</p>
    <p>P2P</p>
    <p>P$</p>
    <p>Transferring data from P$ is faster!</p>
    <p>Transfer time from P$ and SSD P2P vs request size</p>
    <p>Lower is better</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>SPIN: Combine page cache and P2P</p>
    <p>pread64(fd,gpu_dest,5*4096,0); //5 pages of 4KiB</p>
    <p>Page cache is empty:</p>
    <p>PCIe</p>
    <p>Memory Bus</p>
    <p>Transfer P2P!</p>
    <p>P-cache checker</p>
    <p>Page Cache</p>
    <p>EMPTY</p>
    <p>Page #0 Page #1 Page #2 Page #3 Page #4</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>Page #0 Page #1 Page #2 Page #3 Page #4</p>
    <p>SPIN: Combine page cache and P2P</p>
    <p>pread64(fd,gpu_destk,5*4096,0); //5 pages of 4KiB</p>
    <p>All pread64 contents in P$:</p>
    <p>PCIe</p>
    <p>Memory Bus</p>
    <p>Transfer from memory (CPUIO)</p>
    <p>P-cache checker</p>
    <p>Page #0 Page #1 Page #2 Page #3 Page #4</p>
    <p>Page Cache</p>
    <p>EMPTY</p>
    <p>Page Cache</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>Page #0 Page #1 Page #2 Page #3 Page #4</p>
    <p>SPIN: Combine page cache and P2P</p>
    <p>pread64(fd,gpu_dest,5*4096,0); //5 pages of 4KiB</p>
    <p>Some of the data is in P$?</p>
    <p>PCIe</p>
    <p>Memory Bus</p>
    <p>Page #0 Page #1 Page #2 Page #3 Page #4</p>
    <p>Page Cache</p>
    <p>EMPTY</p>
    <p>Page Cache</p>
    <p>?</p>
    <p>?#p1#p3 #p0 #p2 #p4</p>
    <p>Fine grained interleaving is a bad idea!</p>
    <p>Page resides in SSD only</p>
    <p>Page resides in SSD and P$</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>Page #0 Page #1 Page #2 Page #3 Page #4</p>
    <p>SPIN: Combine page cache and P2P</p>
    <p>pread64(fd,gpu_dest,5*4096,0); //5 pages of 4KiB</p>
    <p>Page #0 Page #1 Page #2 Page #3 Page #4</p>
    <p>Page resides in SSD only</p>
    <p>Page resides in SSD and P$</p>
    <p>Single transfer of 20KiB via P2P: 74.3us</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>SPIN: Combine page cache and P2P SSDs:</p>
    <p>- Short IO requests are less efficient (low parallelism) - Invocation overhead per request</p>
    <p>Fine grained interleaving = poor performance!</p>
    <p>Optimization Problem: Find the transfer schedule to minimize transfer time</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>Tr a</p>
    <p>n sf</p>
    <p>e r</p>
    <p>T im</p>
    <p>e [</p>
    <p>se c]</p>
    <p>Request Size [KiB]</p>
    <p>P2P</p>
    <p>P$</p>
    <p>SPIN: Combine page cache and P2P</p>
    <p>We model the SSD and RAM performance characteristics: - Assume P2P transfer time as piece-wise linear - Assume RAM transfer time as linear</p>
    <p>To solve the problem &amp; get an optimal schedule we need:</p>
    <p>2  - P2P transfer time for a given request size</p>
    <p>$  - P$ transfer time for a given request size</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>SPIN: Combine page cache and P2P</p>
    <p>Solution is polynomial in number of blocks</p>
    <p>We apply a greedy heuristic: - Examine every 3 consecutive data chunks</p>
    <p>Costly to calculate for every transfer</p>
    <p>Chunk #n Chunk #n+1 Chunk #n+2</p>
    <p>Page resides in SSD only</p>
    <p>Page resides in SSD and P$</p>
    <p>2  +  + 1 + | + 2|</p>
    <p>. 2 || + $ | + 1| + 2 | + 2|</p>
    <p>Calculate:</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>SPIN: Combine page cache and P2P</p>
    <p>Solution is polynomial in number of blocks</p>
    <p>We apply a greedy heuristic: - Examine every 3 consecutive data chunks</p>
    <p>Costly to calculate for every transfer</p>
    <p>Chunk #n Chunk #n+1 Chunk #n+2</p>
    <p>Page resides in SSD only</p>
    <p>Page resides in SSD and P$</p>
    <p>2  +  + 1 + | + 2|</p>
    <p>. 2 || + $ | + 1| + 2 | + 2|</p>
    <p>Calculate:</p>
    <p>Greedy Heuristic is only 1.6% slower than optimal</p>
    <p>scheduling</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>SPIN: Implementation: P2P &amp; P$ Transfers</p>
    <p>NVMe SS D</p>
    <p>SPIN</p>
    <p>P-router P-Read Ahead policy</p>
    <p>P-cache checker</p>
    <p>P2PDMA</p>
    <p>VFS Page cache</p>
    <p>Block Layer</p>
    <p>NVMe Driver</p>
    <p>GPU</p>
    <p>GPU buffer</p>
    <p>GPU addr. extraction</p>
    <p>Current FS API</p>
    <p>file</p>
    <p>PCIe</p>
    <p>P 2</p>
    <p>P D</p>
    <p>M A</p>
    <p>t ra</p>
    <p>n sf</p>
    <p>e r</p>
    <p>fd GPU</p>
    <p>buffer</p>
    <p>pread( , )</p>
    <p>GPU RA</p>
    <p>CPU PC</p>
    <p>P2P: Address tunneling mechanism</p>
    <p>P$: Memcpy from P$ to GPU mapped memory</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>SPIN: Implementation &amp; Evaluation</p>
    <p>SPIN is implemented as a kernel module, patched</p>
    <p>NVME module &amp; an LD_PRELOAD library</p>
    <p>No kernel modifications are required</p>
    <p>System Specs:</p>
    <p>- Intel P3700 NVME SSD</p>
    <p>- AMD Radeon R9 Fury &amp; NVIDIA Tesla K40c</p>
    <p>- Ubuntu + Linux kernel 3.19</p>
    <p>- Intel Core i7-5930K (6 Phys Cores) &amp; X99 Chipset</p>
    <p>- 24GB DDR4 RAM</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>SPIN: Implementation &amp; Evaluation</p>
    <p>We have evaluated the following:</p>
    <p>Threaded IO (TIOtest) Benchmark (1-4 threads):</p>
    <p>- Sequential reads (including software RAID)</p>
    <p>- Random reads/writes</p>
    <p>- Effects of P$ residency on read throughput</p>
    <p>- Effects CPU &amp; I/O stress on read throughput</p>
    <p>Application Benchmarks</p>
    <p>- Aerial imagery rendering</p>
    <p>- GPU accelerated log server</p>
    <p>- Image collage utilizing GPUFS</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>SPIN: Implementation &amp; Evaluation</p>
    <p>Effect of P$ on Read Throughput</p>
    <p>Potential performance gains for producer-consumer workloads</p>
    <p>R e</p>
    <p>la ti</p>
    <p>ve t</p>
    <p>h ro</p>
    <p>u g</p>
    <p>h p</p>
    <p>u t</p>
    <p>%</p>
    <p>% of file in page cache</p>
    <p>SPIN P2PDMA CPUIO</p>
    <p>Thpt [MB/sec]:</p>
    <p>*512B reads</p>
    <p>No data in P$, less than 5%</p>
    <p>overhead</p>
    <p>All data in P$, less than 5%</p>
    <p>overhead</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>SPIN: Implementation &amp; Evaluation</p>
    <p>GPU Accelerated Log Server</p>
    <p>- Store a log into SSD</p>
    <p>- Analyze log using GPU acceleration for string matching</p>
    <p>- Similar to fail2ban</p>
    <p>Real time configuration: - Log arrives to server - Server stores logs in SSD - GPU analyzes logs by reading file</p>
    <p>Offline configuration: - Log is already in SSD</p>
    <p>- GPU analyzes logs by reading file</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>SPIN: Implementation &amp; Evaluation</p>
    <p>GPU Accelerated Log Server</p>
    <p>- Store a log into SSD</p>
    <p>- Analyze log using GPU acceleration for string matching</p>
    <p>- Similar to fail2ban</p>
    <p>Real time configuration: - Log arrives to server - Server stores logs in SSD - GPU analyzes logs by reading file</p>
    <p>Offline configuration: - Log is already in SSD</p>
    <p>- GPU analyzes logs by reading file</p>
    <p>We want our application to work efficiently in any</p>
    <p>configuration</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>SPIN: Implementation &amp; Evaluation</p>
    <p>GPU Accelerated Log Server</p>
    <p>Real Time configuration</p>
    <p>P2P CPUIO SPIN</p>
    <p>B W</p>
    <p>[ M</p>
    <p>B P</p>
    <p>S ]</p>
    <p>Transfer Mechanism</p>
    <p>Offline configuration</p>
    <p>P2P CPUIO SPIN</p>
    <p>B W</p>
    <p>[ M</p>
    <p>B P</p>
    <p>S ]</p>
    <p>Transfer Mechanism</p>
    <p>Data resides in p$ and SSD SPIN reads data from P$</p>
    <p>Data resides in SSD only SPIN utilizes P2P</p>
    <p>I/ O</p>
    <p>C o</p>
    <p>n te</p>
    <p>n ti</p>
    <p>o n</p>
    <p>A d</p>
    <p>d it</p>
    <p>io n</p>
    <p>a l</p>
    <p>h o</p>
    <p>p</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Background</p>
    <p>Objective</p>
    <p>SPIN</p>
    <p>Conclusion</p>
    <p>SPIN: Conclusion</p>
    <p>Thank you!</p>
    <p>shaiberg1@tx.technion.ac.il github.com/acsl-technion/spin</p>
    <p>- SPIN seamlessly integrates P2P as a first class citizen</p>
    <p>into the file I/O stack</p>
    <p>- SPIN utilizes several mechanisms to speed up data</p>
    <p>transfers transparently</p>
    <p>- With SPIN, the same code performs well under all</p>
    <p>setups</p>
  </div>
</Presentation>
