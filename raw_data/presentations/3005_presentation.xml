<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Dont Get Caught In the Cold, Warm-up Your JVM</p>
    <p>Understand and Eliminate JVM Warm-up Overhead in Data-parallel Systems</p>
    <p>David Lion, Adrian Chiu, Hailong Sun*, Xin Zhuang, Nikola Grcevski, Ding Yuan</p>
    <p>University of Toronto, *Beihang University, Vena Solutions</p>
  </div>
  <div class="page">
    <p>The JVM is Popular</p>
    <p>Systems are increasingly built on the JVM</p>
    <p>Popular for big data applications</p>
    <p>Increasingly used on latency-sensitive queries</p>
  </div>
  <div class="page">
    <p>JVM Performance is Mysterious</p>
    <p>JVM performance has come a long way, but it will never match native code. - Quora User</p>
    <p>The most obvious outdated Java Performance fallacy is that it is slow. - InfoQ User</p>
    <p>Most work performed by HDFS and MapReduce is I/O, so Java is acceptable. - Hypertable Developer</p>
    <p>If you scale your application Java is likely fast enough for you. - StackOverflow user</p>
  </div>
  <div class="page">
    <p>An Analysis of JVM Overhead</p>
    <p>Surprisingly, warm-up overhead is the bottleneck</p>
    <p>Bottlenecks I/O intensive workloads (33% in 1GB HDFS read)</p>
    <p>Warm-up time stays constant (21s - Spark query)</p>
    <p>Multi-layer systems aggravate the problem</p>
    <p>There is a contradiction between parallelizing long running jobs into short tasks, and amortizing</p>
    <p>JVM warm-up overhead through long tasks.</p>
  </div>
  <div class="page">
    <p>HotTub: Eliminate Warm-up Overhead</p>
    <p>New JVM that can be reused across jobs</p>
    <p>OpenJDK 8 HotTub 0</p>
    <p>Spark Query 100GB</p>
    <p>R u</p>
    <p>n ti m</p>
    <p>e (</p>
    <p>s )</p>
    <p>OpenJDK 8 HotTub 0</p>
    <p>Hive Query 100GB</p>
    <p>R u</p>
    <p>n ti m</p>
    <p>e (</p>
    <p>s )</p>
    <p>OpenJDK 8 HotTub 0</p>
    <p>HDFS 1MB Read</p>
    <p>R u</p>
    <p>n ti m</p>
    <p>e (</p>
    <p>s )</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>JVM Analysis</p>
    <p>Warm-up overhead bottlenecks I/O intensive workloads</p>
    <p>Warm-up overhead is constant</p>
    <p>Warm-up overhead increased on multi-layer systems</p>
    <p>HotTub: eliminate warm-up with reuse</p>
    <p>Demo</p>
  </div>
  <div class="page">
    <p>Methodology</p>
    <p>Study HDFS, Spark, and Hive on Tez</p>
    <p>Queries from BigBench [Ghazal13] (TPC-DS)</p>
    <p>Server components are fully warmed up</p>
    <p>10 node cluster: 16 virtual cores, 128GB RAM, 10GbE</p>
    <p>Instrument OpenJDK 8 to measure warm-up overhead</p>
    <p>Understanding overall slowdown is complicated</p>
    <p>Blocked time analysis [Ousterhout15]</p>
    <p>Subtract warm-up overhead and simulate scheduling</p>
  </div>
  <div class="page">
    <p>HDFS: I/O Bottleneck is Warm-up</p>
    <p>Warm-up time remains relatively constant across data sizes</p>
    <p>Same classes loaded, same methods JIT-compiled</p>
    <p>HDFS Sequential Read Interpreter Class loading</p>
    <p>Size (GB)</p>
    <p>T im</p>
    <p>e (</p>
    <p>s )</p>
  </div>
  <div class="page">
    <p>HDFS: I/O Bottleneck is Warm-up</p>
    <p>Warm-up time remains relatively constant across data sizes</p>
    <p>Same classes loaded, same methods JIT-compiled</p>
    <p>Warm-up more than 33% of execution for 1GB</p>
    <p>HDFS Sequential Read Interpreter Class loading Warm-up %</p>
    <p>Size (GB)</p>
    <p>T im</p>
    <p>e (</p>
    <p>s )</p>
    <p>% R</p>
    <p>u n</p>
    <p>ti m</p>
    <p>e</p>
  </div>
  <div class="page">
    <p>Zooming into HDFS Read Overhead</p>
    <p>1GB file bottlenecked by client initialization warm-up overhead</p>
    <p>21% of entire execution is class loading at initialization</p>
    <p>Warm-up overhead dwarfs disk I/O</p>
    <p>Read</p>
    <p>Client init</p>
    <p>HDFS 1GB Sequential Read Compiled/native Interpreter Class loading</p>
    <p>Time (s)</p>
  </div>
  <div class="page">
    <p>ack</p>
    <p>HDFS Datanode I/O Compiled/native Interpreter Class loading</p>
    <p>Time (ms)</p>
    <p>HDFS Packet Overhead</p>
    <p>Datanode first sends acknowledgement to begin the read</p>
    <p>Datanode</p>
    <p>Client</p>
  </div>
  <div class="page">
    <p>parse DN ack</p>
    <p>ack</p>
    <p>HDFS Datanode I/O Compiled/native Interpreter Class loading</p>
    <p>Time (ms)</p>
    <p>HDFS Packet Overhead</p>
    <p>Client processing acknowledgement is very slow</p>
    <p>Bottleneck is class loading</p>
    <p>Datanode</p>
    <p>Client</p>
  </div>
  <div class="page">
    <p>parse DN ack</p>
    <p>sendfile 1-38</p>
    <p>ack</p>
    <p>HDFS Datanode I/O Compiled/native Interpreter Class loading</p>
    <p>Time (ms)</p>
    <p>HDFS Packet Overhead</p>
    <p>Datanode already started to send packets</p>
    <p>Datanode</p>
    <p>Client</p>
  </div>
  <div class="page">
    <p>read pckt. 1</p>
    <p>parse DN ack</p>
    <p>sendfile 1-38</p>
    <p>ack</p>
    <p>HDFS Datanode I/O Compiled/native Interpreter Class loading</p>
    <p>Time (ms)</p>
    <p>HDFS Packet Overhead</p>
    <p>The client spends all of its time in warm-up</p>
    <p>CRC checksum interpretation is the bottleneck</p>
    <p>Datanode</p>
    <p>Client</p>
  </div>
  <div class="page">
    <p>read pckt. 1</p>
    <p>parse DN ack</p>
    <p>wait</p>
    <p>sendfile 1-38</p>
    <p>ack</p>
    <p>HDFS Datanode I/O Compiled/native Interpreter Class loading</p>
    <p>Time (ms)</p>
    <p>HDFS Packet Overhead</p>
    <p>Datanode must wait because sendfile buffer is full</p>
    <p>Datanode</p>
    <p>Client</p>
  </div>
  <div class="page">
    <p>read pckt. 3</p>
    <p>read pckt. 2</p>
    <p>read pckt. 1</p>
    <p>parse DN ack</p>
    <p>sendfile 39-109</p>
    <p>wait</p>
    <p>sendfile 1-38</p>
    <p>ack</p>
    <p>HDFS Datanode I/O Compiled/native Interpreter Class loading</p>
    <p>Time (ms)</p>
    <p>HDFS Packet Overhead</p>
    <p>Warm-up overhead slows even the actual I/O path</p>
    <p>109 packets sent before client finishes processing 3</p>
    <p>Datanode</p>
    <p>Client</p>
  </div>
  <div class="page">
    <p>Warm-up Over Study Interpreter Class loading</p>
    <p>T im</p>
    <p>e (</p>
    <p>s )</p>
    <p>Spark and Hive Warm-up Overhead</p>
    <p>Warm-up overhead is constant</p>
    <p>Average - Spark: 21s, Hive: 13s</p>
    <p>Spark HiveScale Factor (GB)</p>
  </div>
  <div class="page">
    <p>Warm-up Over Study Interpreter Class loading Warm-up %</p>
    <p>T im</p>
    <p>e (</p>
    <p>s )</p>
    <p>% R</p>
    <p>u n</p>
    <p>ti m</p>
    <p>e</p>
    <p>Spark and Hive Warm-up Overhead</p>
    <p>Up to 40% of runtime spent in warm-up overhead</p>
    <p>Spark queries run faster, but have more warm-up overhead</p>
    <p>Spark HiveScale Factor (GB)</p>
  </div>
  <div class="page">
    <p>Client Classes</p>
    <p>C la</p>
    <p>s s e</p>
    <p>s L</p>
    <p>o a</p>
    <p>d e</p>
    <p>d</p>
    <p>Spark Package Classes</p>
    <p>More Layers More Overhead</p>
    <p>Spark client loads 3 times more classes than Hive</p>
    <p>19,066 classes</p>
    <p>More classes generally leads to more interpretation time</p>
    <p>Because more unique methods are invoked</p>
  </div>
  <div class="page">
    <p>JVM Reuse is Hard at Application Layer</p>
    <p>Spark and Tez already try to reuse JVMs</p>
    <p>But only within a job</p>
    <p>Many challenges exist when reusing JVMs</p>
    <p>Need to ensure same classes are used  Need to reset all static data</p>
    <p>3rd party libraries make this even harder</p>
    <p>Close file descriptors  Kill threads</p>
    <p>Signals</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>JVM Analysis</p>
    <p>Warm-up overhead bottlenecks I/O intensive workloads</p>
    <p>Warm-up overhead is constant</p>
    <p>Warm-up overhead increased on multi-layer systems</p>
    <p>HotTub: eliminate warm-up with reuse</p>
    <p>Demo</p>
  </div>
  <div class="page">
    <p>HotTub: Reuse JVMs</p>
    <p>Modify OpenJDK 8 to reuse warm JVMs</p>
    <p>Keeps a pool of warm JVM processes</p>
    <p>Data-parallel systems have lots of opportunity for reuse</p>
    <p>Drop-in replacement</p>
  </div>
  <div class="page">
    <p>HotTub: Initial Run</p>
    <p>If no JVM exists create a new one $java</p>
    <p>reusable JVM</p>
    <p>exists?</p>
  </div>
  <div class="page">
    <p>HotTub: Initial Run</p>
    <p>If no JVM exists create a new one</p>
    <p>Run application normally</p>
    <p>$java</p>
    <p>reusable JVM</p>
    <p>exists?</p>
    <p>exec new JVM</p>
    <p>Run App.</p>
    <p>false</p>
  </div>
  <div class="page">
    <p>JVMJVMJVM</p>
    <p>HotTub: Initial Run</p>
    <p>If no JVM exists create a new one</p>
    <p>Run application normally</p>
    <p>Reset JVM before adding to the pool</p>
    <p>Clean up any threads</p>
    <p>Reset static data to type default</p>
    <p>Close file descriptors</p>
    <p>$java</p>
    <p>reusable JVM</p>
    <p>exists?</p>
    <p>exec new JVM</p>
    <p>JVM pool</p>
    <p>Run App.</p>
    <p>reset JVM</p>
    <p>false</p>
  </div>
  <div class="page">
    <p>JVMJVMJVM</p>
    <p>HotTub: Reuse Run</p>
    <p>Choose existing JVM from pool</p>
    <p>Ensure loaded classes are correct</p>
    <p>Reinitialize all static data</p>
    <p>$java</p>
    <p>reusable JVM</p>
    <p>exists?</p>
    <p>reinit. JVM</p>
    <p>exec new JVM</p>
    <p>JVM pool</p>
    <p>Run App.</p>
    <p>reset JVM</p>
    <p>true</p>
    <p>false</p>
  </div>
  <div class="page">
    <p>HotTub Demo</p>
  </div>
  <div class="page">
    <p>HDFS Read OpenJDK 8 HotTub</p>
    <p>File Size</p>
    <p>R u</p>
    <p>n ti m</p>
    <p>e s (</p>
    <p>s )</p>
    <p>Best Worst 0</p>
    <p>Spark 100GB OpenJDK 8 HotTub</p>
    <p>BigBench Query (Speedup)</p>
    <p>R u</p>
    <p>n ti m</p>
    <p>e s (</p>
    <p>s )</p>
    <p>Best Worst 0</p>
    <p>Hive 100GB OpenJDK 8 HotTub</p>
    <p>BigBench Query (Speedup)</p>
    <p>R u</p>
    <p>n ti m</p>
    <p>e s (</p>
    <p>s )</p>
    <p>HotTub Evaluation</p>
    <p>Constant improvement across different workloads on a system</p>
    <p>Reusing a JVM from a different query has similar results</p>
  </div>
  <div class="page">
    <p>Limitations</p>
    <p>Security: limit reuse to same Linux user</p>
    <p>Could see loaded classes and compiled methods</p>
    <p>Similar to timing channel</p>
    <p>Not useful for long running JVMs</p>
    <p>Breaks the JVM specification for class initialization on edge cases</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>Garbage collection overhead in data-parallel systems</p>
    <p>Yak [Nguyen'16], Taurus [Maas'16], Broom [Gog'15], etc</p>
    <p>Not warm-up overhead</p>
    <p>Studies on data-parallel systems</p>
    <p>[Ousterhout'15], [Pavlo'09], etc</p>
    <p>Not targeting the JVM</p>
    <p>Studies on the cost of scalability [McSherry'15]</p>
    <p>Work on JVM unrelated to data-parallel systems</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Warm-up overhead is the bottleneck</p>
    <p>Bottlenecks even I/O intensive workloads</p>
    <p>Warm-up time stays constant  Bad when parallelizing with JVMs</p>
    <p>Multi-layer systems aggravate warm-up overhead</p>
    <p>HotTub: eliminate warm-up through transparent JVM reuse</p>
    <p>Open sourced at: https://github.com/dsrg-uoft/hottub</p>
    <p>Thank You</p>
  </div>
  <div class="page">
    <p>Extra Slides</p>
  </div>
  <div class="page">
    <p>HotTub Overheads</p>
    <p>Memory: In our tests an idle JVM took around 1GB memory</p>
    <p>Can configure pool size (ideally pool is rarely idle)</p>
    <p>Garbage collection: ~200ms</p>
    <p>Few roots, most objects are dead  All stacks ended + Static data set to type default (null)</p>
    <p>Class reinitialization:</p>
    <p>Spark executor: 400ms, Spark Client: 720ms</p>
    <p>Hive container: 350ms</p>
    <p>Not overhead, but cannot be skipped on reuse</p>
  </div>
  <div class="page">
    <p>Spark and Hive Study</p>
    <p>Complete results</p>
    <p>GC not a factor for these short queries</p>
  </div>
  <div class="page">
    <p>HotTub Iterations</p>
    <p>1MB HDFS Read performed repeatedly</p>
    <p>Run 0 is a new JVM</p>
  </div>
  <div class="page">
    <p>HotTub Cross-Query</p>
    <p>Spark 100GB</p>
    <p>Run training query 4 times then run testing query</p>
  </div>
  <div class="page">
    <p>Custom Class Loaders</p>
    <p>Instance re-created each run</p>
    <p>No consistency issues</p>
    <p>Cannot reuse</p>
  </div>
  <div class="page">
    <p>HotTub Consistency Limitations</p>
    <p>Timing dependencies</p>
    <p>Unpredictable and dangerous practice</p>
    <p>HotTub initializes classes before runtime</p>
    <p>Class A Loaded</p>
    <p>ClassA.a = 0</p>
    <p>foo()</p>
    <p>ClassA.a = 1</p>
    <p>Class B Loaded</p>
    <p>ClassB.b = 2</p>
    <p>foo()</p>
    <p>ClassA.a = 2</p>
  </div>
  <div class="page">
    <p>HotTub Consistency Limitations</p>
    <p>Timing dependencies</p>
    <p>foo() could be called multiple times before B is initialized</p>
    <p>Class dependence cycles</p>
    <p>Problem for normal JVMs too</p>
  </div>
  <div class="page">
    <p>Instrumentation</p>
    <p>Goal: track changes between interpreter and compiled code</p>
    <p>Returns are hard to track</p>
    <p>parameters0x2a0</p>
    <p>ret addr: 0x8f00x2a8</p>
    <p>JVM stackaddr</p>
    <p>ret addr stack</p>
    <p>stack addr ret addr</p>
  </div>
  <div class="page">
    <p>Instrumentation</p>
    <p>Copy original return address to thread local stack</p>
    <p>parameters0x2a0</p>
    <p>ret addr: 0x8f00x2a8</p>
    <p>JVM stackaddr</p>
    <p>ret addr stack</p>
    <p>stack addr ret addr</p>
  </div>
  <div class="page">
    <p>Instrumentation</p>
    <p>Copy our return handler into the return address</p>
    <p>parameters0x2a0</p>
    <p>ret addr: 0x6700x2a8</p>
    <p>JVM stackaddr</p>
    <p>ret addr stack</p>
    <p>stack addr ret addr</p>
  </div>
  <div class="page">
    <p>Instrumentation</p>
    <p>Return calls into our ret_handler</p>
    <p>Record mode change and pop original return address</p>
    <p>parameters0x2a0</p>
    <p>ret addr: 0x6700x2a8</p>
    <p>JVM stackaddr</p>
    <p>ret addr stack</p>
    <p>stack addr ret addr</p>
  </div>
  <div class="page">
    <p>Instrumentation</p>
    <p>Jump to original return address</p>
    <p>parameters0x2a0</p>
    <p>ret addr: 0x6700x2a8</p>
    <p>JVM stackaddr</p>
    <p>ret addr stack</p>
    <p>stack addr ret addr</p>
  </div>
  <div class="page">
    <p>Spark and Hive Parallelization</p>
    <p>Parallelization: split long running jobs into short tasks  JVM warm-up overhead amortized when long running</p>
    <p>Jobs are smaller and faster than ever  90% of Facebooks analytics jobs &lt;100GB input</p>
    <p>Majority of Hadoop workloads read and write &lt;1GB per-task  [Ousterhout13] show a trend in increasingly short running jobs</p>
    <p>Hive on Tez: 1 JVM per task, Spark: 1 JVM per node</p>
  </div>
</Presentation>
