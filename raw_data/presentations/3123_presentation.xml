<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Alice in Warningland A Large-Scale Field Study of</p>
    <p>Browser Security Warning Effectiveness</p>
    <p>Devdatta Akhawe UC Berkeley</p>
    <p>Adrienne Porter Felt</p>
    <p>Google, Inc.</p>
  </div>
  <div class="page">
    <p>Given a choice between dancing pigs and security, the user will pick dancing pigs every time</p>
    <p>Felten and McGraw Securing Java</p>
  </div>
  <div class="page">
    <p>a growing body of measurement studies make clear that ...[users] are oblivious to security cues [and] ignore certificate error warnings</p>
    <p>Herley The Plight of The Targeted Attacker</p>
    <p>at Scale 2010</p>
  </div>
  <div class="page">
    <p>Evidence from experimental studies indicates that most people dont read computer warnings, dont understand them, or simply dont heed them, even when the situation is clearly hazardous.</p>
    <p>Bravo-Lillo Bridging the Gap in Computer Security</p>
    <p>Warnings 2011</p>
  </div>
  <div class="page"/>
  <div class="page"/>
  <div class="page">
    <p>Firefox Malware Warning</p>
  </div>
  <div class="page">
    <p>Chrome SSL Warning</p>
  </div>
  <div class="page">
    <p>Firefox SSL Warning</p>
  </div>
  <div class="page">
    <p>today</p>
    <p>A large scale measurement of user responses to</p>
    <p>modern warnings in situ</p>
  </div>
  <div class="page">
    <p>today</p>
    <p>A large scale measurement of user responses to</p>
    <p>modern warnings in situ</p>
  </div>
  <div class="page">
    <p>What did we measure?</p>
  </div>
  <div class="page">
    <p>Clickthrough Rate</p>
    <p># warnings ignored # warnings shown</p>
    <p>(across all users)</p>
  </div>
  <div class="page">
    <p>What is the ideal click through rate?</p>
  </div>
  <div class="page">
    <p>Why aim for a 0% rate?</p>
    <p>Low false positives =&gt; protecting users</p>
    <p>The Google Safe Browsing list (malware/phishing warnings) has low false positives</p>
    <p>High false positives ? (SSL Warnings)</p>
    <p>Low clickthrough incentivizes websites to fix their SSL errors</p>
    <p>False positives annoy users and browsers should reduce the number of false warnings to achieve 0% clickthrough rate</p>
  </div>
  <div class="page">
    <p>How did we measure it?</p>
  </div>
  <div class="page">
    <p>Browser Telemetry</p>
    <p>A mechanism for browsers to collect pseudonymous performance and quality data from end users</p>
    <p>Users opt-in to sharing data with the browser vendors</p>
    <p>Users have to opt-out in pre-release builds (e.g., Nightly)</p>
  </div>
  <div class="page">
    <p>Data Collection</p>
    <p>We implemented probes to measure number of times a warning shown and number of times ignored</p>
    <p>For both Google Chrome and Mozilla Firefoxs malware, phishing, and SSL warnings</p>
    <p>Data collected:</p>
    <p>April 28-May 31 for Google Chrome</p>
    <p>May 1-May 31 for Mozilla Firefox</p>
  </div>
  <div class="page">
    <p>Limitations</p>
    <p>No data on demographics or browsing habits of users except for OS and release channel</p>
    <p>Users might be biased towards clicking because they agreed to share data</p>
    <p>We present aggregate data across all users</p>
    <p>Individual users could be over-represented</p>
    <p>Over-represented users in Google Chrome still contribute fewer than 1% of the total warnings</p>
  </div>
  <div class="page">
    <p>Limitations: Iframes</p>
    <p>Our original Mozilla Firefox implementation did not ignore warnings in iframes</p>
    <p>Since warnings in iframes might not be visible, this caused us to measure a lower click-through rate</p>
    <p>Chrome never shows a warning in an iframe</p>
    <p>Bug fixed in Firefox 23, but we only have prerelease data</p>
    <p>Impact is ~2 percentage points for Malware/phishing warnings so we use old numbers</p>
    <p>Impact is ~25 percentage points for SSL warnings, so we use new numbers</p>
  </div>
  <div class="page">
    <p>Details about the data</p>
    <p>Google Chrome</p>
    <p>~6M malware warnings (~2.1M users)</p>
    <p>~386K phishing warnings (~204K users)</p>
    <p>~16.7M SSL Warnings (~4.5M users)</p>
    <p>Mozilla Firefox (nearly 1% of all users)</p>
    <p>~2.1M malware warnings</p>
    <p>~100K phishing warnings</p>
    <p>10,976 SSL Warnings (pre-release only)</p>
    <p>~2M Add Exception dialogs</p>
  </div>
  <div class="page">
    <p>What did we find?</p>
  </div>
  <div class="page">
    <p>Results</p>
  </div>
  <div class="page">
    <p>Less than 25%! Firefox rates &lt; Chrome Rates</p>
  </div>
  <div class="page">
    <p>Firefox Malware Warning</p>
    <p>User only needs to click on Ignore</p>
  </div>
  <div class="page">
    <p>User has to click Advanced and then</p>
    <p>Ignore</p>
  </div>
  <div class="page">
    <p>But higher clickthrough</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Rational?</p>
    <p>This rate fluctuates a lot</p>
  </div>
  <div class="page">
    <p>What about demographics?</p>
  </div>
  <div class="page">
    <p>Operating System &amp;</p>
    <p>Release Channel</p>
  </div>
  <div class="page">
    <p>Operating System &amp;</p>
    <p>Release Channel</p>
  </div>
  <div class="page">
    <p>Results by Release</p>
    <p>A release channel is a way for browsers and developers to test out bleeding edge features  Useful for developers, often unstable</p>
    <p>Different channels further ahead in release train</p>
    <p>For example, on May 27, 2013  Stable = Firefox v21, Beta = Firefox v22, Aurora</p>
    <p>(i.e., Dev) = Firefox v23, Nightly = Firefox v24</p>
    <p>Hypothesis: Earlier channels correspond to greater technical skill of user</p>
  </div>
  <div class="page">
    <p>Impact of Demographics</p>
    <p>Operating System</p>
    <p>Malware Firefox</p>
    <p>Malware Chrome</p>
    <p>Phishing Firefox</p>
    <p>Phishing Chrome</p>
    <p>Windows 7.1% 23.5% 8.9% 17.9%</p>
    <p>MacOS 11.2% 16.6% 12.5% 17.0%</p>
    <p>Linux 18.2% 13.9% 34.8% 31.0%</p>
    <p>Channel Malware Firefox</p>
    <p>Malware Chrome</p>
    <p>Phishing Firefox</p>
    <p>Phishing Chrome</p>
    <p>Stable 7.2% 23.2% 9.1% 18.0%</p>
    <p>Beta 8.7% 22.0% 11.2% 28.1%</p>
    <p>Dev 9.4% 28.1% 11.6% 22.0%</p>
    <p>Nightly 7.1% 54.8% 25.9% 20.4%</p>
  </div>
  <div class="page">
    <p>Impact of Demographics</p>
    <p>Operating System</p>
    <p>Malware Firefox</p>
    <p>Malware Chrome</p>
    <p>Phishing Firefox</p>
    <p>Phishing Chrome</p>
    <p>Windows 7.1% 23.5% 8.9% 17.9%</p>
    <p>MacOS 11.2% 16.6% 12.5% 17.0%</p>
    <p>Linux 18.2% 13.9% 34.8% 31.0%</p>
    <p>Channel Malware Firefox</p>
    <p>Malware Chrome</p>
    <p>Phishing Firefox</p>
    <p>Phishing Chrome</p>
    <p>Stable 7.2% 23.2% 9.1% 18.0%</p>
    <p>Beta 8.7% 22.0% 11.2% 28.1%</p>
    <p>Dev 9.4% 28.1% 11.6% 22.0%</p>
    <p>Nightly 7.1% 54.8% 25.9% 20.4%</p>
    <p>Linux clickthrough rates much higher (except Chrome malware)</p>
    <p>Operating System</p>
    <p>Malware Firefox</p>
    <p>Malware Chrome</p>
    <p>Phishing Firefox</p>
    <p>Phishing Chrome</p>
  </div>
  <div class="page">
    <p>Impact of Demographics</p>
    <p>Operating System</p>
    <p>Malware Firefox</p>
    <p>Malware Chrome</p>
    <p>Phishing Firefox</p>
    <p>Phishing Chrome</p>
    <p>Windows 7.1% 23.5% 8.9% 17.9%</p>
    <p>MacOS 11.2% 16.6% 12.5% 17.0%</p>
    <p>Linux 18.2% 13.9% 34.8% 31.0%</p>
    <p>Channel Malware Firefox</p>
    <p>Malware Chrome</p>
    <p>Phishing Firefox</p>
    <p>Phishing Chrome</p>
    <p>Stable 7.2% 23.2% 9.1% 18.0%</p>
    <p>Beta 8.7% 22.0% 11.2% 28.1%</p>
    <p>Dev 9.4% 28.1% 11.6% 22.0%</p>
    <p>Nightly 7.1% 54.8% 25.9% 20.4%</p>
    <p>Clickthrough rates higher for Firefox developer releases</p>
  </div>
  <div class="page">
    <p>Does a greater degree of technical skill corresponds to reduced risk aversion?</p>
    <p>(if Linux /developer releases =&gt; more technical skill)</p>
  </div>
  <div class="page">
    <p>Results by Date</p>
    <p>For Google Chrome malware warnings, the clickthrough rates range from 11.2% to 24.9% for different weeks</p>
    <p>We do not see any such effect for Mozilla Firefox</p>
    <p>Possibly because Google Chrome shows a toplevel warning for secondary resources</p>
    <p>For example, malware ad on youtube.com causes Chrome to show warning for YouTube, while Mozilla silently blocks it</p>
  </div>
  <div class="page">
    <p>Results</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Possible Reasons</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Firefox SSL Warning</p>
  </div>
  <div class="page">
    <p>Possible Reasons</p>
  </div>
  <div class="page">
    <p>Only 1 click to ignore</p>
    <p>Chrome SSL Warning</p>
  </div>
  <div class="page">
    <p>Two clicks to</p>
    <p>Firefox SSL Warning</p>
  </div>
  <div class="page">
    <p>Third click to confirm</p>
    <p>Firefox SSL Add Exception dialog</p>
  </div>
  <div class="page">
    <p>Firefox SSL warning requires more clicks and has lower clickthrough rate</p>
    <p>But, previously</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Possible Reasons</p>
  </div>
  <div class="page">
    <p>Certificate Pinning</p>
    <p>Browser does not allow user to bypass errors for high-profile pinned sites</p>
    <p>Chrome ships with a bigger list of such highprofile sites</p>
    <p>Nearly 20% of all warnings are non-bypassable on Chrome vs. 1% for Firefox</p>
  </div>
  <div class="page">
    <p>Set of all SSL errors hit by Firefox Firefox Clickthroughs</p>
    <p>Set of all SSL errors hit by Chrome Chrome Clickthroughs</p>
    <p>Pinned, non bypassable</p>
    <p>~56% of errors are ignored</p>
    <p>Firefox users heeding warnings for high profile sites?</p>
  </div>
  <div class="page">
    <p>Possible Reasons</p>
  </div>
  <div class="page">
    <p>Remember Exception checked by</p>
    <p>default</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Possible Reasons</p>
  </div>
  <div class="page">
    <p>What about demographics?</p>
  </div>
  <div class="page">
    <p>Results</p>
    <p>Operating System</p>
    <p>Firefox Chrome</p>
    <p>Windows 32.5% 71.1%</p>
    <p>MacOS 39.3% 68.8%</p>
    <p>Linux 58.7% 64.2%</p>
    <p>Android NC 64.6%</p>
    <p>Channel Firefox Chrome</p>
    <p>Stable NC 70.2%</p>
    <p>Beta 32.2% 73.3%</p>
    <p>Dev 35.0% 75.9%</p>
    <p>Nightly 43.0% 74.0%</p>
    <p>Similar effect as for Firefox malware</p>
  </div>
  <div class="page">
    <p>Results</p>
  </div>
  <div class="page">
    <p>High level explanation of error in main warning,</p>
    <p>more in Help Me Understand</p>
    <p>Chrome SSL Warning</p>
  </div>
  <div class="page">
    <p>Google Chrome</p>
    <p>Error Type Percentage of Total Clickthrough Rate</p>
    <p>Self-Signed Cert 56.0% 81.8%</p>
    <p>Wrong Domain Name 25.0% 62.8%</p>
    <p>Expired Certificate 17.6% 57.4%</p>
    <p>Other 1.4% -</p>
    <p>Network view systems can reduce SSL warnings by up to 75%</p>
    <p>But not a panacea: name errors account for at least 25% of errors</p>
  </div>
  <div class="page">
    <p>Google Chrome</p>
    <p>Error Type Percentage of Total Clickthrough Rate</p>
    <p>Self-Signed Cert 56.0% 81.8%</p>
    <p>Wrong Domain Name 25.0% 62.8%</p>
    <p>Expired Certificate 17.6% 57.4%</p>
    <p>Other 1.4% -</p>
    <p>More common warnings have</p>
    <p>higher clickthrough rate</p>
  </div>
  <div class="page">
    <p>Error Type only mentioned on</p>
    <p>secondary dialog</p>
    <p>Firefox SSL Add Exception dialog</p>
  </div>
  <div class="page">
    <p>Mozilla Firefox</p>
    <p>Error Type Percentage of Total Clickthrough Rate</p>
    <p>Untrusted Issuer 38% 87.1%</p>
    <p>Untrusted, Name Mismatch 26.4% 87.9%</p>
    <p>Name Mismatch 15.7% 80.3%</p>
    <p>Expired 10.2% 80.7%</p>
    <p>Expired, Untrusted, Name 4.7% 87.6%</p>
    <p>Expired, Untrusted 4.1% 83.6%</p>
    <p>Expired, Name Mismatch 0.7% 85.2%</p>
    <p>None of the above &lt;0.1% 77.9%</p>
    <p>Not much difference by error type.</p>
    <p>Maybe users make a decision</p>
    <p>at the very first click?</p>
  </div>
  <div class="page">
    <p>Discussion</p>
    <p>24.4 point difference between clickthrough rates for expired &amp; self-signed certs (Chrome)</p>
    <p>Maybe untrusted issuer errors only occur on unimportant sites</p>
    <p>Maybe expired certificates are a surprise to users and thus users are cautious</p>
    <p>Lower clickthrough rate when site that used to work without warning shows a warning</p>
  </div>
  <div class="page">
    <p>Results</p>
  </div>
  <div class="page">
    <p>Chrome: Time by outcome</p>
    <p>Ignore Warning</p>
    <p>Heed Warning</p>
    <p>Less time spent on warning if warning</p>
    <p>ignored</p>
  </div>
  <div class="page">
    <p>Chrome: Time by Error Type</p>
    <p>Less time spent on more common</p>
    <p>warnings</p>
  </div>
  <div class="page">
    <p>Implications</p>
  </div>
  <div class="page">
    <p>Warning Effectiveness</p>
    <p>Save for the Chrome SSL Warning, all other warnings ignored only under 33% of times</p>
    <p>Chrome SSL Warning ignored 70.2% of times</p>
    <p>Positive results with other warnings suggest this can be improved</p>
    <p>Warning design can impact user behavior</p>
    <p>Security practitioners should not ignore the role of the user</p>
  </div>
  <div class="page">
    <p>User Attention</p>
    <p>Our data contradict the stereotype of wholly oblivious users with no interest in security.</p>
    <p>24 point difference between clickthrough rates for untrusted issuer and expired cert errors for Google Chrome</p>
    <p>21.3% of Mozilla Firefox users who clicked on Add Exception unticked Permanently Store This Exception</p>
  </div>
  <div class="page">
    <p>Comparison with Previous Work</p>
    <p>Difference between lab studies and field measurements</p>
    <p>Lab studies focused on old warning designs</p>
    <p>Or participant trust in lab environment affected results?</p>
  </div>
  <div class="page">
    <p>During our study we observed a strong disparity between our participants actions during the laboratory tasks and their selfreported &quot;would be&quot; actions during similar tasks in everyday computer practices. Our participants attributed this disparity to the laboratory environment and the security it offered</p>
    <p>Sotirakopoulos et al. On the challenges of Usable</p>
    <p>Security Lab Studies</p>
  </div>
  <div class="page">
    <p>Comparison with Previous Work</p>
    <p>Difference between lab studies and field measurements</p>
    <p>Lab studies focused on old warning designs</p>
    <p>Or participant trust in lab environment affected results?</p>
    <p>Renewed emphasis on field study needed</p>
    <p>Experience Sampling</p>
    <p>Network based measurements</p>
    <p>Real world deception studies</p>
  </div>
  <div class="page">
    <p>Theory of Warning Fatigue</p>
    <p>We observe behavior consistent with theory of warning fatigue</p>
    <p>Common errors clicked through faster and more frequently</p>
    <p>Security practitioners should limit the number of warnings raised</p>
  </div>
  <div class="page">
    <p>In Conclusion</p>
  </div>
  <div class="page">
    <p>We find that browser security warnings can be effective, although</p>
    <p>they can be improved.</p>
    <p>We also find evidence that warning mechanism design can have a</p>
    <p>tremendous impact on user behavior.</p>
  </div>
  <div class="page">
    <p>Thanks for Listening!</p>
    <p>evil@berkeley.edu www.cs.berkeley.edu/~devdatta</p>
  </div>
</Presentation>
