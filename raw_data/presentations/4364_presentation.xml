<?xml version="1.0" ?>
<Presentation>
  <div class="page"/>
  <div class="page">
    <p>Introduction</p>
  </div>
  <div class="page">
    <p>Image credit (https://blog.bufferapp.com/)</p>
  </div>
  <div class="page">
    <p>[ORG France] defeated [ORG Croatia] in [MISC World Cup] final at [LOC Luzhniki Stadium].</p>
    <p>Why important?  Provide inputs to downstream applications  Searching  Recommendation  Knowledge graph construction</p>
    <p>What is Name Tagging?</p>
  </div>
  <div class="page">
    <p>CR7 or TK8</p>
    <p>News VS Tweet</p>
    <p>Limited Textual Context  Performs much worse on</p>
    <p>social media data</p>
  </div>
  <div class="page">
    <p>Language Variations</p>
    <p>Bad segmentation</p>
    <p>Within word white spaces</p>
    <p>I luv juuustin</p>
    <p>Alison wonderlandxDiploxjuaz B2B ayee</p>
    <p>LETS GO L A K E R S</p>
  </div>
  <div class="page">
    <p>Difficult cases based on text only</p>
    <p>Modern Baseball played an intimate surprise set at Shea</p>
    <p>Karl-Anthony Towns named unanimous 2015-2016 NBA Rookie of the Year</p>
  </div>
  <div class="page">
    <p>Colts Have 4th Best QB Situation in NFL with Andrew Luck #ColtStrong</p>
    <p>[ORG Colts] Have 4th Best QB Situation in [ORG NFL] with [PER Andrew Luck] #ColtStrong</p>
    <p>Multimedia Input: image-sentence pair</p>
    <p>Output: tagging results on sentence</p>
  </div>
  <div class="page">
    <p>Overview</p>
  </div>
  <div class="page">
    <p>Sequence Labeling Model  Bidirectional Long-short-term-memory-networks (BLSTM)</p>
    <p>Word representations Generations  Conditional-random-fields (CRF)</p>
    <p>Joint tags prediction  State-of-the-art for news articles ( )</p>
    <p>Visual attention model (Bahdanau et al., 2014)  Extract visual features from image regions that are most related</p>
    <p>to accompanying sentence  Modulation Gate before CRFs</p>
    <p>Combine word representation with visual features based on their relatedness</p>
  </div>
  <div class="page">
    <p>Model</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>and are the input, memory and hidden state at time t respectively. and are weight matrices. is the element-wise product functions and is the element-wise sigmoid function</p>
  </div>
  <div class="page">
    <p>Input sentence</p>
    <p>Input image</p>
    <p>Outputs from convolutional layer</p>
    <p>Attention calculate</p>
    <p>Context Vector</p>
  </div>
  <div class="page">
    <p>Visual context</p>
    <p>Word representation</p>
    <p>Visually tuned word representation</p>
  </div>
  <div class="page">
    <p>Experiments</p>
  </div>
  <div class="page">
    <p>Snap Caption Dataset and Twitter DataSet (image+text)  Topics: Sports, concerts and other social events  Named Entity Types: Person, Organization, Location and MISC</p>
    <p>Training Develement Testing</p>
    <p>Snap Sentence 4,817 1,032 1,033</p>
    <p>Tokens 39,035 8,334 8,110</p>
    <p>Twitter Sentence 4,290 1,432 1,459</p>
    <p>Tokens 68,655 22,872 23,051</p>
    <p>Size of the dataset in numbers of sentences and tokens</p>
  </div>
  <div class="page">
    <p>Model Snap Captions Tweets</p>
    <p>Precision Recall F1 Precision Recall F1</p>
    <p>BLSTM-CRF 57.71 58.65 58.18 78.88 77.47 78.17</p>
    <p>+Global Image Vector 61.49 57.84 59.61 79.75 77.32 78.51</p>
    <p>+Visual Attention 65.53 57.03 60.98 80.81 77.36 79.05</p>
    <p>Gate controlled visual attention 66.67 57.84 61.94 81.62 79.90 80.75</p>
  </div>
  <div class="page"/>
  <div class="page"/>
  <div class="page">
    <p>Future Work</p>
  </div>
  <div class="page">
    <p>Fine Grained Name Tagging</p>
    <p>San Francisco Giants New York Giants Belfast Giants</p>
    <p>[PER CR7] &amp; [PER Messi] shake hands</p>
    <p>Joint Multimodal Grounding and Name Tagging</p>
    <p>Giants won the game</p>
  </div>
  <div class="page"/>
</Presentation>
