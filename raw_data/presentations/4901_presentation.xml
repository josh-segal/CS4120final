<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Vector Architectures Vs. Superscalar and VLIW</p>
    <p>for Embedded Media Benchmarks</p>
    <p>Christos Kozyrakis David Patterson</p>
    <p>Stanford University U.C. Berkeley</p>
    <p>http://csl.stanford.edu/~christos</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Ideal processor for embedded media processing  High performance for media tasks</p>
    <p>Low cost  Small code size, low power consumption, highly integrated</p>
    <p>Low power consumption (for portable applications)</p>
    <p>Low design complexity</p>
    <p>Easy to program with HLLs</p>
    <p>Scalable</p>
    <p>This work  How efficient is a simple vector processor for embedded media</p>
    <p>processing?  No cache, no wide issue, no out-of-order execution</p>
    <p>How does it compare to superscalar and VLIW embedded designs?</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation</p>
    <p>Overview of VIRAM architecture</p>
    <p>Multimedia instruction set, processor organization, vectorizing compiler</p>
    <p>EEMBC benchmarks &amp; alternative architectures</p>
    <p>Evaluation</p>
    <p>Instruction set analysis &amp; code size comparison</p>
    <p>Performance comparison</p>
    <p>VIRAM scalability study</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>VIRAM Instruction Set</p>
    <p>Vector load-store instruction set for media processing</p>
    <p>Coprocessor extension to MIPS architecture</p>
    <p>Architecture state</p>
    <p>32 general-purpose vector registers</p>
    <p>16 flag registers</p>
    <p>Scalar registers for control, addresses, strides, etc</p>
    <p>Vector instructions</p>
    <p>Arithmetic: integer, floating-point, logical</p>
    <p>Load-store: unit-stride, strided, indexed</p>
    <p>Misc: vector &amp; flag processing (pop count, insert/extract)</p>
    <p>90 unique instructions</p>
  </div>
  <div class="page">
    <p>VIRAM ISA Enhancements</p>
    <p>Multimedia processing</p>
    <p>Support for multiple data-types (64b/32b/16b)</p>
    <p>Element &amp; operation width specified with control register</p>
    <p>Saturated and fixed-point arithmetic</p>
    <p>Flexible multiply-add model without accumulators</p>
    <p>Simple element permutations for reductions and FFTs</p>
    <p>Conditional execution using the flag registers</p>
    <p>General-purpose systems</p>
    <p>TLB-based virtual memory</p>
    <p>Separate TLB for vector loads &amp; stores</p>
    <p>Hardware support for reduced context switch overhead</p>
    <p>Valid/dirty bits for vector registers</p>
    <p>Support for lazy save/restore of vector state</p>
  </div>
  <div class="page">
    <p>VIRAM Processor Microarchitecture</p>
  </div>
  <div class="page">
    <p>VIRAM Chip</p>
    <p>D R</p>
    <p>A M</p>
    <p>D R</p>
    <p>A M</p>
    <p>D R</p>
    <p>A M</p>
    <p>D R</p>
    <p>A M</p>
    <p>D R</p>
    <p>A M</p>
    <p>D R</p>
    <p>A M</p>
    <p>D R</p>
    <p>A M</p>
    <p>D R</p>
    <p>A M</p>
    <p>LANE LANE LANE LANE</p>
    <p>MIPS Core</p>
    <p>IO-FPU</p>
    <p>Vector DRAM Control</p>
    <p>0.18m CMOS (IBM)  Features</p>
    <p>8KB vector register file</p>
    <p>2 256-bit integer ALUs</p>
    <p>1 256-bit FPU</p>
    <p>13MB DRAM</p>
    <p>325mm2 die area</p>
    <p>125M transistors</p>
    <p>200 MHz, 2 Watts</p>
    <p>Peak vector performance  Integer: 1.6/3.2/6.4 Gop/s</p>
    <p>(64b/32b/16b)</p>
    <p>Fixed-point: 2.4/4.8/9.6 Gop/s (64b/32b/16b)</p>
    <p>FP: 1.6 Gflop/s (32b)</p>
  </div>
  <div class="page">
    <p>Vectorizing Compiler</p>
    <p>Based on Cray PDGCS compiler</p>
    <p>Used with all vector and MPP Cray machines</p>
    <p>Extensive vectorization capabilities</p>
    <p>Including outer-loop vectorization</p>
    <p>Vectorization of narrow operations and reductions</p>
    <p>Optimizer</p>
    <p>C</p>
    <p>Fortran95</p>
    <p>C++</p>
    <p>Frontends Code Generators</p>
    <p>Crays</p>
    <p>PDGCS</p>
    <p>T3D, T3E</p>
    <p>X1(SV2), VIRAM</p>
    <p>C90, T90, SV1</p>
  </div>
  <div class="page">
    <p>EEMBC Benchmarks</p>
    <p>The de-facto industrial standard for embedded CPUs</p>
    <p>Used consumer &amp; telecommunication categories  Representative of workload for multimedia devices with</p>
    <p>wireless/broadband capabilities</p>
    <p>C code, EEMBC reference input data</p>
    <p>Consumer category  Image processing tasks for digital camera devices</p>
    <p>Rgb2cmyk &amp; rgb2yiq conversions, convolutional filter, jpeg encode &amp; decode</p>
    <p>Telecommunication category  Encoding/decoding tasks for DSL/wireless</p>
    <p>Autocorrelation compression, convolutional encoder, DSL bit allocation, FFT, Viterbi decoding</p>
  </div>
  <div class="page">
    <p>EEMBC Metrics</p>
    <p>Performance: repeats/second (throughput)</p>
    <p>Use geometric means to summarize scores</p>
    <p>Code size and static data size in bytes</p>
    <p>Data sizes the same for the processors we discuss</p>
    <p>Pitfall with caching behavior</p>
    <p>Fundamentally, no temporal locality in most benchmarks</p>
    <p>Repeating kernel on same (small) data creates locality</p>
    <p>Unfair advantage for cache based architectures</p>
    <p>VIRAM has no data cache for vector loads/stores</p>
  </div>
  <div class="page">
    <p>Embedded Processors</p>
    <p>VLIW+ DSP</p>
    <p>VelociTI</p>
    <p>Trimedia</p>
    <p>Power</p>
    <p>(W)</p>
    <p>Clock</p>
    <p>(MHz)</p>
    <p>Cache L1I/L1D/L2</p>
    <p>(KB)</p>
    <p>OOO</p>
    <p>Issue WidthChipArchitecture</p>
  </div>
  <div class="page">
    <p>Degree of Vectorization</p>
    <p>Rg b2</p>
    <p>cm yk</p>
    <p>Rg b2</p>
    <p>yi q</p>
    <p>Fi lte</p>
    <p>r</p>
    <p>Cj pe</p>
    <p>g</p>
    <p>Dj pe</p>
    <p>g</p>
    <p>Au to</p>
    <p>co r</p>
    <p>Co nv</p>
    <p>en c</p>
    <p>Bi ta</p>
    <p>l Ff</p>
    <p>t</p>
    <p>Vi te</p>
    <p>rb i</p>
    <p>% o</p>
    <p>f D</p>
    <p>y n</p>
    <p>a m</p>
    <p>ic O</p>
    <p>p e ra</p>
    <p>ti o</p>
    <p>n s</p>
    <p>Vector Operations Scalar Operations</p>
    <p>Typical degree of vectorization is 90%  Even for Viterbi decoding which is partially vectorizable</p>
    <p>ISA &amp; compiler can capture the data parallelism in EEMBC</p>
    <p>Great potential for vector hardware</p>
  </div>
  <div class="page">
    <p>Rg b2</p>
    <p>cm yk Fil</p>
    <p>ter Cj</p>
    <p>pe g</p>
    <p>Dj pe</p>
    <p>g</p>
    <p>Co nv</p>
    <p>en c</p>
    <p>Vit erb</p>
    <p>i</p>
    <p>Rg b2</p>
    <p>yiq Cj</p>
    <p>pe g</p>
    <p>Dj pe</p>
    <p>g</p>
    <p>Au toc</p>
    <p>or Bi tal FftV</p>
    <p>ec to</p>
    <p>r L en</p>
    <p>gt h</p>
    <p>(E le</p>
    <p>m en</p>
    <p>ts )</p>
    <p>Average Maximum Supported</p>
    <p>Vector Length</p>
    <p>Short vectors  Unavoidable with Viterbi, artifact of code with Cjpeg/Djpeg</p>
    <p>Even shortest length operations have ~20 16-bit elements  More parallelism than 128-bit SSE/Altivec can capture</p>
  </div>
  <div class="page">
    <p>Code Size</p>
    <p>VIRAM high code density due to</p>
    <p>No loop unrolling/software pipelining, compact expression of strided/indexed/permutation patterns, no small loops</p>
    <p>Vectors: a code compression technique for RISC</p>
    <p>VI RA</p>
    <p>M x8</p>
    <p>Po w er</p>
    <p>PC M</p>
    <p>IP S</p>
    <p>VL IW</p>
    <p>(c c)</p>
    <p>VL IW</p>
    <p>(o pt</p>
    <p>)</p>
    <p>VI RA</p>
    <p>M x8</p>
    <p>Po w er</p>
    <p>PC M</p>
    <p>IP S</p>
    <p>VL IW</p>
    <p>(c c)</p>
    <p>VL IW</p>
    <p>(o pt</p>
    <p>)</p>
    <p>N o</p>
    <p>rm a li ze</p>
    <p>d C</p>
    <p>o d</p>
    <p>e S</p>
    <p>iz e</p>
    <p>Consumer Telecommunications</p>
  </div>
  <div class="page">
    <p>Comparison: Performance</p>
    <p>Rg b2</p>
    <p>cm yk</p>
    <p>Rg b2</p>
    <p>yi q</p>
    <p>Fi lte</p>
    <p>r</p>
    <p>Cj pe</p>
    <p>g</p>
    <p>Dj pe</p>
    <p>g</p>
    <p>Au to</p>
    <p>co r</p>
    <p>Co nv</p>
    <p>en c</p>
    <p>Bi ta</p>
    <p>l Ff</p>
    <p>t</p>
    <p>Vi te</p>
    <p>rb i</p>
    <p>G eo</p>
    <p>m . M</p>
    <p>ea n</p>
    <p>P e</p>
    <p>rf o</p>
    <p>rm a</p>
    <p>n c</p>
    <p>e</p>
    <p>VIRAM PowerPC VLIW (cc) VLIW (opt)</p>
    <p>200MHz, cache-less, single-issue VIRAM is</p>
    <p>100% faster than 1-GHz, 4-way OOO processor</p>
    <p>40% faster than manually-optimized VLIW with SIMD/DSP</p>
    <p>VIRAM can sustain high computation throughput</p>
    <p>Up to 16 (32-bit) to 32 (16-bit) arithmetic ops/cycle</p>
    <p>VIRAM can hide latency of accesses to DRAM</p>
  </div>
  <div class="page">
    <p>Comparison: Performance/MHz</p>
    <p>Rg b2</p>
    <p>cm yk</p>
    <p>Rg b2</p>
    <p>yi q</p>
    <p>Fi lte</p>
    <p>r</p>
    <p>Cj pe</p>
    <p>g</p>
    <p>Dj pe</p>
    <p>g</p>
    <p>Au to</p>
    <p>co r</p>
    <p>Co nv</p>
    <p>en c</p>
    <p>Bi ta</p>
    <p>l Ff</p>
    <p>t</p>
    <p>Vi te</p>
    <p>rb i</p>
    <p>G eo</p>
    <p>m . M</p>
    <p>ea n</p>
    <p>P e rf</p>
    <p>o rm</p>
    <p>a n</p>
    <p>c e /M</p>
    <p>H z</p>
    <p>VIRAM PowerPC VLIW (cc) VLIW (opt)</p>
    <p>VIRAM Vs 4-way OOO &amp; VLIW with compiler code</p>
    <p>10x-50x with long vectors, 2x-5x with short vectors</p>
    <p>VIRAM Vs VLIW with manually optimized code</p>
    <p>VLIW within 50% of VIRAM</p>
    <p>VIRAM would benefit from the same optimizations</p>
    <p>Similar results if normalized by power or complexity</p>
  </div>
  <div class="page">
    <p>VIRAM Scalability</p>
    <p>Same executable, frequency, and memory system</p>
    <p>Decreased efficiency for 8 lanes</p>
    <p>Short vector lengths, conflicts in the memory system</p>
    <p>Difficult to hide overhead with short execution times</p>
    <p>Overall: 2.5x with 4 lanes, 3.5x with 8 lanes</p>
    <p>Can you scale similarly a superscalar processor?</p>
    <p>Rgbcmyk Rgbyiq Filter Cjpeg Djpeg Autocor Convenc Bital Fft Viterbi Geom. Mean</p>
    <p>P e</p>
    <p>rf o</p>
    <p>rm a</p>
    <p>n c</p>
    <p>e</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Vectors architectures are great match for embedded multimedia processing</p>
    <p>Combined high performance, low power, low complexity</p>
    <p>Add a vector unit to your media-processor!</p>
    <p>VIRAM code density</p>
    <p>Similar to x86, 5-10 times better than optimized VLIW</p>
    <p>VIRAM performance  With compiler vectorization and no hand-tuning</p>
    <p>2x performance of 4-way OOO superscalar</p>
    <p>Even if OOO runs at 5x the clock frequency</p>
    <p>50% faster than manually-optimized 5 to 8-way VLIW</p>
    <p>Even if VLIW has hand-inserted SIMD and DSP support</p>
  </div>
</Presentation>
