<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>No Metrics Are Perfect: Adversarial REward Learning</p>
    <p>for Visual Storytelling</p>
    <p>Xin Wang*, Wenhu Chen*, Yuan-Fang Wang, William Wang</p>
  </div>
  <div class="page">
    <p>Caption: Two young kids with backpacks sitting on the porch.</p>
    <p>Image Captioning</p>
  </div>
  <div class="page">
    <p>Visual Storytelling</p>
    <p>Story: The brother did not want to talk to his sister. The siblings made up. They started to talk and smile. Their parents showed up. They were happy to see them.</p>
    <p>Story: The brother did not want to talk to his sister. The siblings made up. They started to talk and smile. Their parents showed up. They were happy to see them.</p>
    <p>Imagination</p>
    <p>Story: The brother did not want to talk to his sister. The siblings made up. They started to talk and smile. Their parents showed up. They were happy to see them.</p>
    <p>Emotion Subjectiveness</p>
  </div>
  <div class="page">
    <p>Story #2: The brother and sister were ready for the first day of school. They were excited to go to their first day and meet new friends. They told their mom how happy they were. They said they were going to make a lot of new friends. Then they got up and got ready to get in the car.</p>
    <p>Visual Storytelling</p>
  </div>
  <div class="page">
    <p>Behavioral cloning methods (e.g. MLE) are not good enough for visual storytelling</p>
  </div>
  <div class="page">
    <p>Reinforcement Learning</p>
    <p>o Directly optimize the existing metrics  BLEU, METEOR, ROUGE, CIDEr  Reduce exposure bias</p>
    <p>Reinforcement Learning (RL)</p>
    <p>Environment</p>
    <p>Reward Function</p>
    <p>Optimal Policy</p>
    <p>Rennie 2017, Self-critical Sequence Training for Image Captioning</p>
  </div>
  <div class="page">
    <p>We had a great time to have a lot of the. They were to be a of the. They were to be in the. The and it were to be the. The, and it were to be the.</p>
    <p>Average METEOR score: 40.2 (SOTA model: 35.0)</p>
  </div>
  <div class="page">
    <p>I had a great time at the restaurant today. The food was delicious. I had a lot of food. I had a great time.</p>
    <p>BLEU-4 score: 0</p>
  </div>
  <div class="page">
    <p>No Metrics Are Perfect!</p>
  </div>
  <div class="page">
    <p>Inverse Reinforcement Learning</p>
    <p>Inverse Reinforcement Learning (IRL)</p>
    <p>Environment</p>
    <p>Reward Function</p>
    <p>Optimal Policy</p>
    <p>Reinforcement Learning (RL)</p>
    <p>Environment</p>
    <p>Reward Function</p>
    <p>Optimal Policy</p>
    <p>Reinforcement Learning</p>
  </div>
  <div class="page">
    <p>Adversarial REward Learning (AREL)</p>
    <p>Environment</p>
    <p>Adversarial Objective</p>
    <p>Policy ModelReward Model</p>
    <p>Reward</p>
    <p>Generated Story</p>
    <p>Reference Story</p>
    <p>RL</p>
    <p>Inverse RL</p>
  </div>
  <div class="page">
    <p>Policy Model &quot;</p>
    <p>CN N</p>
    <p>My brother recently graduated college.</p>
    <p>It was a formal cap and gown event.</p>
    <p>My mom and dad attended.</p>
    <p>Later, my aunt and grandma showed up.</p>
    <p>When the event was over he even got congratulated by the mascot.</p>
    <p>Encoder Decoder</p>
  </div>
  <div class="page">
    <p>Reward Model $</p>
    <p>Story Convolution FC layerPooling</p>
    <p>CN N</p>
    <p>my mom and dad</p>
    <p>attended .</p>
    <p>&lt;EOS&gt;</p>
    <p>Reward</p>
    <p>+</p>
    <p>Kim 2014, Convolutional Neural Networks for Sentence Classification</p>
  </div>
  <div class="page">
    <p>Associating Reward with Story</p>
    <p>Approximate data distribution Partition function</p>
    <p>Story</p>
    <p>Optimal reward function $ () is achieved when</p>
    <p>LeCun et al. 2006, A tutorial on energy-based learning</p>
    <p>Energy-based models associate an energy value $() with a sample , modeling the data as a Boltzmann distribution</p>
    <p>$  = exp ($())</p>
    <p>Reward Function Reward Boltzmann Distribution</p>
  </div>
  <div class="page">
    <p>AREL Objective</p>
    <p>The objective of Reward Model $:</p>
    <p>Empirical distribution Policy distribution</p>
    <p>Reward Boltzmann distribution</p>
    <p>The objective of Policy Model &quot;:</p>
    <p>Therefore, we define an adversarial objective with KL-divergence</p>
  </div>
  <div class="page">
    <p>Reward Visualization</p>
  </div>
  <div class="page">
    <p>Method BLEU-1 BLEU-2 BLEU-3 BLEU-4 METEOR ROUGE CIDEr Seq2seq (Huang et al.) - - - - 31.4 - HierAttRNN (Yu et al.) - - 21.0 - 34.1 29.5 7.5 AREL (ours) 63.7 39.0 23.1 14.0 35.0 29.6 9.5</p>
    <p>Automatic Evaluation</p>
    <p>Method BLEU-1 BLEU-2 BLEU-3 BLEU-4 METEOR ROUGE CIDEr Seq2seq (Huang et al.) - - - - 31.4 - HierAttRNN (Yu et al.) - - 21.0 - 34.1 29.5 7.5 XE 62.3 38.2 22.5 13.7 34.8 29.7 8.7 AREL (ours) 63.7 39.0 23.1 14.0 35.0 29.6 9.5</p>
    <p>Method BLEU-1 BLEU-2 BLEU-3 BLEU-4 METEOR ROUGE CIDEr Seq2seq (Huang et al.) - - - - 31.4 - HierAttRNN (Yu et al.) - - 21.0 - 34.1 29.5 7.5 XE 62.3 38.2 22.5 13.7 34.8 29.7 8.7 BLEU-RL 62.1 38.0 22.6 13.9 34.6 29.0 8.9 METEOR-RL 68.1 35.0 15.4 6.8 40.2 30.0 1.2 ROUGE-RL 58.1 18.5 1.6 0.0 27.0 33.8 0.0 CIDEr-RL 61.9 37.8 22.5 13.8 34.9 29.7 8.1 AREL (ours) 63.7 39.0 23.1 14.0 35.0 29.6 9.5</p>
    <p>Method BLEU-1 BLEU-2 BLEU-3 BLEU-4 METEOR ROUGE CIDEr Seq2seq (Huang et al.) - - - - 31.4 - HierAttRNN (Yu et al.) - - 21.0 - 34.1 29.5 7.5 XE 62.3 38.2 22.5 13.7 34.8 29.7 8.7 BLEU-RL 62.1 38.0 22.6 13.9 34.6 29.0 8.9 METEOR-RL 68.1 35.0 15.4 6.8 40.2 30.0 1.2 ROUGE-RL 58.1 18.5 1.6 0.0 27.0 33.8 0.0 CIDEr-RL 61.9 37.8 22.5 13.8 34.9 29.7 8.1 AREL (ours) 63.7 39.0 23.1 14.0 35.0 29.6 9.5</p>
    <p>Method BLEU-1 BLEU-2 BLEU-3 BLEU-4 METEOR ROUGE CIDEr Seq2seq (Huang et al.) - - - - 31.4 - HierAttRNN (Yu et al.) - - 21.0 - 34.1 29.5 7.5 XE 62.3 38.2 22.5 13.7 34.8 29.7 8.7 BLEU-RL 62.1 38.0 22.6 13.9 34.6 29.0 8.9 METEOR-RL 68.1 35.0 15.4 6.8 40.2 30.0 1.2 ROUGE-RL 58.1 18.5 1.6 0.0 27.0 33.8 0.0 CIDEr-RL 61.9 37.8 22.5 13.8 34.9 29.7 8.1 GAN 62.8 38.8 23.0 14.0 35.0 29.5 9.0 AREL (ours) 63.7 39.0 23.1 14.0 35.0 29.6 9.5</p>
    <p>Huang et al. 2016, Visual Storytelling Yu et al. 2017, Hierarchically-Attentive RNN for Album Summarization and Storytelling</p>
  </div>
  <div class="page">
    <p>Human Evaluation</p>
    <p>XE BLEU-RL CIDEr-RL GAN AREL</p>
    <p>Turing Test</p>
    <p>Win Unsure</p>
  </div>
  <div class="page">
    <p>Human Evaluation</p>
    <p>Relevance: the story accurately describes what is happening in the photo stream and covers the main objects. Expressiveness: coherence, grammatically and semantically correct, no repetition, expressive language style. Concreteness: the story should narrate concretely what is in the images rather than giving very general descriptions.</p>
    <p>Pairwise Comparison</p>
  </div>
  <div class="page">
    <p>XE-ss We took a trip to the mountains.</p>
    <p>There were many different kinds of different kinds.</p>
    <p>We had a great time.</p>
    <p>He was a great time.</p>
    <p>It was a beautiful day.XE-ss</p>
    <p>We took a trip to the mountains.</p>
    <p>There were many different kinds of different kinds.</p>
    <p>We had a great time.</p>
    <p>He was a great time.</p>
    <p>It was a beautiful day.</p>
    <p>AREL The family decided to take a trip to the countryside.</p>
    <p>There were so many different kinds of things to see.</p>
    <p>The family decided to go on a hike. I had a great time.</p>
    <p>At the end of the day, we were able to take a picture of the beautiful scenery.</p>
    <p>Humancreated Story</p>
    <p>We went on a hike yesterday.</p>
    <p>There were a lot of strange plants there.</p>
    <p>I had a great time. We drank a lot of water while we were hiking.</p>
    <p>The view was spectacular.</p>
    <p>XE-ss We took a trip to the mountains.</p>
    <p>There were many different kinds of different kinds.</p>
    <p>We had a great time.</p>
    <p>He was a great time.</p>
    <p>It was a beautiful day.</p>
    <p>AREL The family decided to take a trip to the countryside.</p>
    <p>There were so many different kinds of things to see.</p>
    <p>The family decided to go on a hike. I had a great time.</p>
    <p>At the end of the day, we were able to take a picture of the beautiful scenery.</p>
  </div>
  <div class="page">
    <p>Takeaway</p>
    <p>o Generating and evaluating stories are both challenging due to the complicated nature of stories</p>
    <p>o No existing metrics are perfect for either training or testing o AREL is a better learning framework for visual storytelling</p>
    <p>Can be applied to other generation tasks o Our approach is model-agnostic</p>
    <p>Advanced models  better performance</p>
  </div>
  <div class="page">
    <p>Thanks!</p>
    <p>Paper: https://arxiv.org/abs/1804.09160 Code: https://github.com/littlekobe/AREL</p>
  </div>
</Presentation>
