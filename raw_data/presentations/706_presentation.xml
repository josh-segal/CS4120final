<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Shenggang Wan, Qiang Cao, Jianzhong Huang, Siyi Li, Xin Li, Shenghui Zhan, Li Yu, Changsheng Xie, Xubin He</p>
    <p>Victim Disk First: An Asymmetric Cache to Boost the Performance of Disk Arrays under Faulty Conditions</p>
  </div>
  <div class="page">
    <p>Contents</p>
    <p>Motivation and Background 1</p>
    <p>RGR: A new cache metric 2</p>
    <p>VDF 3</p>
    <p>Evaluation 4</p>
    <p>Conclusions 5</p>
  </div>
  <div class="page">
    <p>Background USENIX ATC 11</p>
    <p>Some important targets of modern storage systems  Performance : Throughput or Response Time  Reliability : MTTDL Mean Time To Data Loss  Others : such as spatial utilization, scalability,</p>
    <p>manageability, power and so on</p>
  </div>
  <div class="page">
    <p>RAID USENIX ATC 11</p>
    <p>Redundant Array of Inexpensive Disks  Classifications :</p>
    <p>No redundancy RAID, e.g. RAID-0  Mirror-based RAID, e.g. RAID-1, RAID-10  Parity-based RAID, e.g. RAID-4, RAID-5, RAID-6,</p>
    <p>provides high performance, reliability with high spatial utilization</p>
  </div>
  <div class="page">
    <p>Weakness of Parity-based RAID USENIX ATC 11</p>
    <p>High decoding cost  To CPU, it is recognized as computational complexity  To the storage device?</p>
    <p>Extra Reconstruction I/O for User Requests  Extra Reconstruction I/O for System Recovery</p>
  </div>
  <div class="page">
    <p>Example USENIX ATC 11</p>
    <p>Different I/O cost of user requests</p>
    <p>Storage/Buffer Cache</p>
    <p>RAID Algorithm Layer</p>
    <p>Miss to a Surviving Disk</p>
    <p>Request to a Surviving Disk</p>
    <p>Storage/Buffer Cache</p>
    <p>RAID Algorithm Layer</p>
    <p>Miss to a Faulty Disk</p>
    <p>Requests to all Surviving Disks</p>
  </div>
  <div class="page">
    <p>Existing Solutions USENIX ATC 11</p>
    <p>Cache  Take disk or disk array as Cache: redirection of reads,</p>
    <p>piggy-backing of writes, WorkOut  Memory level cache: MICRO</p>
    <p>Others  Data layout  Scheduling</p>
  </div>
  <div class="page">
    <p>VDF: A Solution in Memory Level USENIX ATC 11</p>
    <p>Observation : Different costs between access to the faulty data and surviving data as shown in the example.</p>
    <p>Our solution : Victim Disk(s) First (VDF): Give higher priority to cache the blocks from the faulty disks when a disk array fails, thus reducing the I/ Os directed to the faulty disks and reducing the extra reconstruction I/O for user requests.</p>
  </div>
  <div class="page">
    <p>RGR: A new cache metric USENIX ATC 11</p>
    <p>Miss Ratio, the old metric to cache, limited in description of faulty condition.</p>
    <p>Requests Generation Ratio (RGR):  The ratio of the number of the</p>
    <p>requested blocks to the surviving disks and the number of the requested blocks to buffer cache, j/i in figure.</p>
    <p>It takes into account different miss situations.</p>
    <p>It can be used to describe the performance and the reliability in faulty condition, quantitatively and directly.</p>
    <p>Storage/Buffer Cache RAID Algorithm Layer</p>
    <p>i</p>
    <p>j</p>
  </div>
  <div class="page">
    <p>Formal Description of RGR USENIX ATC 11</p>
    <p>T : Total number of data blocks in a disk array.</p>
    <p>pi : Access probability of each block.  MPi : Miss penalty of each block.</p>
  </div>
  <div class="page">
    <p>RGR and Performance USENIX ATC 11</p>
    <p>BW: Total serviceability of all surviving disks in terms of I/O bandwidth.</p>
    <p>BWU: I/O bandwidth available to user workload, throughput.</p>
    <p>BWR: I/O bandwidth for a reconstruction workload.</p>
  </div>
  <div class="page">
    <p>RGR and Reliabilty USENIX ATC 11</p>
  </div>
  <div class="page">
    <p>VDF and RGR USENIX ATC 11</p>
    <p>Essentially, VDF is to replace the block with minimum (pi*MPi) rather than only the pi, compared to the traditional cache algorithms.</p>
    <p>In many cases, the MPi of blocks from faulty disks is larger than MPi of blocks from surviving disks and tend to be kept in cache more probably, so we named this scheme as Victim Disk First.</p>
  </div>
  <div class="page">
    <p>Case Study USENIX ATC 11</p>
    <p>Only read requests are considered here  Usually, users are more sensitive to read latency.  Non-volatile memory is deployed as a write cache.</p>
    <p>RAID-5 is evaluated: one of the most popular parity-based RAID structures.  MPi of blocks from surviving disk is 1.  MPi of blocks from faulty disk is n-1, n is the number of disks.</p>
    <p>Two popular cache algorithms: LRU and LFU  LRU: Reciprocal of the interval access sequence number is used</p>
    <p>as pi of each block in cache, relatively.  LFU: Access frequency is chosen here.</p>
  </div>
  <div class="page">
    <p>Normal mode/faulty mode USENIX ATC 11</p>
    <p>VDF cache only takes effect in faulty condition.</p>
    <p>Two types of stacks are employed to make a smooth conversion.</p>
    <p>Global stack takes charge in fault-free condition.</p>
    <p>Local stacks take charge in faulty condition.</p>
  </div>
  <div class="page">
    <p>VDF-LRU USENIX ATC 11</p>
    <p>1/(GTS-TS) is pi  1 or (n-1) is MPi</p>
    <p>based on the miss conditions</p>
    <p>Choose the max ((GTS-TS)*MPi) to evict</p>
  </div>
  <div class="page">
    <p>VDF-LFU USENIX ATC 11</p>
    <p>F is pi  1 or (n-1) is MPi</p>
    <p>based on the miss conditions</p>
    <p>Choose the min (F*MPi) to evict</p>
  </div>
  <div class="page">
    <p>Simulation USENIX ATC 11</p>
    <p>Targets: Effect of VDF on reducing RGR</p>
    <p>Traces:  SPC-1-web: (Storage Performance Council)  LM-TBE DTRS: (Microsoft)</p>
    <p>Simulator: VDF-Sim (about 3000 lines in C)</p>
  </div>
  <div class="page">
    <p>SPC Web Results of 8 disks USENIX ATC 11</p>
    <p>LRU 1.747 1.747 1.741 1.528 0.717 0.227</p>
    <p>VDF-LRU 1.743 1.619 1.273 1.048 0.549 0.226</p>
    <p>LFU 1.747 1.747 1.711 1.404 0.632 0.227</p>
    <p>VDF-LFU 1.575 1.189 0.988 0.904 0.477 0.226</p>
    <p>R G</p>
    <p>R</p>
  </div>
  <div class="page">
    <p>SPC Web Results of 262144 blocks USENIX ATC 11</p>
    <p>LRU 1.592 1.655 1.709 1.741</p>
    <p>VDF-LRU 1.364 1.337 1.308 1.273</p>
    <p>LFU 1.565 1.627 1.679 1.711</p>
    <p>VDF-LFU 1.000 0.984 0.981 0.988</p>
    <p>R G</p>
    <p>R</p>
  </div>
  <div class="page">
    <p>LM-TBE Results USENIX ATC 11</p>
  </div>
  <div class="page">
    <p>DTRS Results USENIX ATC 11</p>
  </div>
  <div class="page">
    <p>Prototype USENIX ATC 11</p>
    <p>Targets: Effect of VDF on improving the throughput and shortening the reconstruction duration (MTTR).</p>
    <p>Trace: SPC-1-web</p>
  </div>
  <div class="page">
    <p>Architecture USENIX ATC 11</p>
    <p>Collected block miss information from VDFSim, with the real timestamp (micro second level).</p>
    <p>Play the collected requests to the MD device, using direct I/O to bypass file system cache.</p>
  </div>
  <div class="page">
    <p>Methodology USENIX ATC 11</p>
    <p>Open-loop testing  Requests are re-played according to their</p>
    <p>timestamps (fixed BWu).  To find the effect on reconstruction duration</p>
    <p>(MTTR).</p>
    <p>Close-loop testing  Requests are re-played one by one.  To find the effect on throughput.</p>
  </div>
  <div class="page">
    <p>Open-loop Testing Results USENIX ATC 11</p>
    <p>60GB dataset: 15GB to reconstruct with 5 disks, 12GB with 6 disks</p>
  </div>
  <div class="page">
    <p>Results by Changing Numbers of Blocks</p>
    <p>USENIX ATC 11</p>
  </div>
  <div class="page">
    <p>Future Work USENIX ATC 11</p>
    <p>Integrate VDF into more general cache algorithms.</p>
    <p>Apply VDF to other RAID levels such as RAID-6 to evaluate the impact of VDF on concurrent failures.</p>
  </div>
  <div class="page">
    <p>Conclusions USENIX ATC 11</p>
    <p>We present an asymmetric buffer cache replacement strategy, named Victim (or faulty) Disk(s) First (VDF) cache, to improve the reliability and performance of a RAID-based storage system, particularly under faulty conditions.</p>
    <p>The basic idea of VDF is to treat the faulty disks more favorably, or give a higher priority to cache the data associated with the faulty disks. The benefit of this scheme is to reduce number of the cache miss directed to the faulty disk, and thus to reduce the I/O requests to the surviving disks overall.</p>
    <p>Our results based on both simulation and prototyping implementation have demonstrated the effectiveness of VDF in terms of reduced disk I/O activities and a faster recovery.</p>
  </div>
  <div class="page">
    <p>Acknowledgments USENIX ATC 11</p>
    <p>Our thorough shepherd, Erez Zadok, for his very detailed comments and helpful suggestions.</p>
    <p>The anonymous reviewers for their invaluable comments.</p>
    <p>National Basic Research 973 Program of China, the National Natural Science Foundation of China, the National 863 Program of China, and the Innovative Foundation of Wuhan National Laboratory for Optoelectronics.</p>
    <p>U.S. National Science Foundation (NSF).</p>
  </div>
  <div class="page">
    <p>Questions?</p>
  </div>
</Presentation>
