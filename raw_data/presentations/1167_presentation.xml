<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>STRADS-AP: Simplifying Distributed Machine</p>
    <p>Learning Programming without Introducing a New</p>
    <p>Programming Model</p>
    <p>Jin Kyu Kim1, Abutalib Aghayev1, Garth A. Gibson1,2,3, Eric P. Xing1,4</p>
    <p>Jin Kyu Kim  July 20191</p>
  </div>
  <div class="page">
    <p>Distributed ML Programming is Difficult</p>
    <p>Jin Kyu Kim  July 2019</p>
    <p>Distributed Machine Learning (ML) development flow</p>
    <p>New</p>
    <p>Model</p>
    <p>Sequential</p>
    <p>Algorithm</p>
    <p>Sequential Program</p>
    <p>In Python, Java, R,</p>
    <p>Matlab, C/C++</p>
    <p>Distributed Program</p>
    <p>on high-level frameworks</p>
    <p>such as Spark/Hadoop/</p>
    <p>GraphLab/PS ML researchers</p>
    <p>Gap</p>
    <p>- Mold a sequential ML program to a framework-specific programming model - Change data structure design and computation routine - Often deliver suboptimal performance</p>
    <p>The cost of using high-level frameworks</p>
    <p>STRADS-AP aims to simplify conversion of sequential ML program into a</p>
    <p>distributed ML program almost mechanically</p>
  </div>
  <div class="page">
    <p>Jin Kyu Kim  July 20193</p>
    <p>Easy Conversion of Seq. ML into Dist. ML // part1: pretraining declare data structure D for input declare data structure P for parameters</p>
    <p>// part2: training for(iter=0; iter&lt;MAX; iter++) for(i=0; i&lt;N; i++){ read a part of input D and parameter P write to a part of parameters P</p>
    <p>} Structure pattern of targeting ML programs</p>
    <p>Sequential data structures (i.e. map, vector) for input data and model parameters  Challenge1: scalability limit</p>
    <p>Source of parallelism: repetitive, static control flow, reorderable  Challenge2: data dependencies among loop bodies</p>
  </div>
  <div class="page">
    <p>Jin Kyu Kim  July 20194</p>
    <p>Easy Conversion of Seq. ML into Dist. ML // part1: pretraining declare data structure D for input declare data structure P for parameters</p>
    <p>// part2: training for(iter=0; iter&lt;MAX; iter++) for(i=0; i&lt;N; i++){ read a part of input D and parameter P write to a part of parameters P</p>
    <p>} Structure pattern of targeting ML programs</p>
    <p>Sequential data structures (i.e. map, vector) for input data and model parameters  Challenge1: scalability limit</p>
    <p>Source of parallelism: repetitive, static control flow, reorderable  Challenge2: data dependencies among loop bodies</p>
    <p>declare distributed data structures D declare distributed data structures P for(iter=0; iter&lt;MAX; iter++) ParallelFor(N,[D,P](int i){ read a part of input D and parameter P write to a part of parameters P</p>
    <p>}) STRADS-AP Distributed Program</p>
    <p>Solution1: distributed data structures (i.e. dmap, dvector)  allows index based random R/W access from any node</p>
    <p>Solution2: parallel loops (Sync/AsyncFor)  parallelize loop bodies with different consistency level</p>
  </div>
  <div class="page">
    <p>Jin Kyu Kim  July 20195</p>
    <p>STRADS-AP Workflow</p>
    <p>STRADS-AP code</p>
    <p>fill the lack of C++ languages reflection capability</p>
    <p>STRADS-AP preprocessor</p>
    <p>STRADS-AP runtime</p>
    <p>Native compiler</p>
    <p>STRADS-AP debugging</p>
  </div>
  <div class="page">
    <p>Jin Kyu Kim  July 20196</p>
    <p>Presentation schedule</p>
    <p>STRADS-AP presentation at 3pm Wed July 10 in Track II</p>
  </div>
</Presentation>
