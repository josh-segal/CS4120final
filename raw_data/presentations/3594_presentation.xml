<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>HUMAN DISTINGUISHABLE VISUAL KEY FINGERPRINTS</p>
    <p>USENIX Security '20</p>
    <p>Mozhgan Azimpourkivi1, Umut Topkara1, and Bogdan Carbunar2</p>
    <p>August 2020</p>
  </div>
  <div class="page">
    <p>Key Fingerprints (KF) 2</p>
    <p>q Compact version of a crypto key q Used for authentication</p>
    <p>q Easier to compare by humans against reference value</p>
  </div>
  <div class="page">
    <p>Key Fingerprint Authentication 3</p>
    <p>Trusted Reference</p>
    <p>Crypto Key</p>
    <p>IP Address</p>
    <p>Bitcoin Address</p>
    <p>Human Verifier</p>
    <p>Device ID</p>
    <p>File</p>
    <p>Key Fingerprint</p>
    <p>Key Fingerprint Generator (KFG)</p>
  </div>
  <div class="page">
    <p>MitM Adversary</p>
    <p>Generate and inject string whose key representation is human-indistinguishable from expected value</p>
    <p>Crypto Key</p>
    <p>IP Address</p>
    <p>Bitcoin Address</p>
    <p>Human Verifier</p>
    <p>Device ID</p>
    <p>File</p>
    <p>Key Fingerprint Generator (KFG)</p>
    <p>bc1qar0sr rr7xfkvy5 l643lybsw 9re59gtmz zw5mdq</p>
    <p>Corrupted Fingerprint</p>
    <p>bc1qar0sr rr7xfkvy5 l643lydnw 9re59gtzz wf5mdq</p>
    <p>Trusted Reference</p>
    <p>bc1qar0sr rr7xfkvy5 l643lybsw 9re59gtmz zw5mdq</p>
    <p>bc1qar0sr rr7xfkvy5 l643lydnw 9re59gtzz wf5mdq</p>
    <p>Adversary Model</p>
  </div>
  <div class="page">
    <p>Applications 5</p>
  </div>
  <div class="page">
    <p>Example Key Fingerprints (KF) 6</p>
    <p>OpenSSH Visual Host Key</p>
    <p>Vash Unicorn</p>
    <p>Textual representation Visual representation</p>
    <p>Alphanumeric Pronounceable words</p>
    <p>Sentences</p>
    <p>learning equal education bent collar religion new shelf angle table train sad keep meal</p>
    <p>The basket ends your right cat on his linen. Her range repeats her nerve.</p>
    <p>Tan, Joshua, et al. &quot;Can unicorns help users compare crypto key fingerprints?.&quot; Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. 2017.</p>
  </div>
  <div class="page">
    <p>Vash: Visual KFG (VKFG) 7</p>
    <p>q Tan et al., CHI17:</p>
    <p>q Visual representations verified faster and easier than text-based</p>
    <p>q Generate images using</p>
    <p>q Set of rules</p>
    <p>q Hand curated functions</p>
    <p>q Human visual system limitations</p>
    <p>q Human error rate &gt; 10%</p>
  </div>
  <div class="page">
    <p>CEAL: DNN for KFG</p>
    <p>Generate realistic images to improve usability</p>
    <p>Input Vector</p>
    <p>Fingerprint Image</p>
    <p>GAN-based Image</p>
    <p>GeneratorInputString</p>
    <p>Ke y</p>
    <p>Fi ng</p>
    <p>er pr</p>
    <p>in t</p>
    <p>G en</p>
    <p>er at</p>
    <p>io n</p>
    <p>Input Mapper</p>
  </div>
  <div class="page">
    <p>Visual Key Fingerprint Generator</p>
    <p>Internal Representations</p>
    <p>Key Fingerprint Visual Key Fingerprint Generator</p>
    <p>-1</p>
    <p>+1</p>
    <p>Another Key Fingerprint</p>
    <p>H um</p>
    <p>an D</p>
    <p>is tin</p>
    <p>gu is</p>
    <p>ha bl</p>
    <p>e</p>
    <p>Si ng</p>
    <p>le -v</p>
    <p>al ue</p>
    <p>ch</p>
    <p>an ge</p>
  </div>
  <div class="page">
    <p>CEAL (CrEdential Assurance Label) 10</p>
    <p>q Fingerprints should be realistic and human-distinguishable q Remove humans from evaluation process</p>
    <p>Fingerprint Image</p>
    <p>GeneratorInput String</p>
    <p>Input Mapper</p>
    <p>Training Process</p>
    <p>Input Vector</p>
  </div>
  <div class="page">
    <p>CL-GAN 11</p>
    <p>Same vs. Different</p>
    <p>Realism Discriminator</p>
    <p>Real vs. Fake</p>
    <p>Generator Network</p>
    <p>(Gceal)</p>
    <p>Pre-trained Human</p>
    <p>Perception Discriminator</p>
    <p>(HPD)</p>
    <p>+ FeedbackReal Images</p>
    <p>Vector Representations (Slightly Different)</p>
    <p>-1</p>
    <p>+1</p>
  </div>
  <div class="page">
    <p>Human Perception Discriminator (HPD) 12</p>
    <p>Contrastive loss</p>
    <p>Same (0) Different (1)</p>
    <p>Cross entropy loss (&quot;#$)</p>
    <p>Eu cl</p>
    <p>id ea</p>
    <p>n D</p>
    <p>is ta</p>
    <p>nc e</p>
    <p>O1</p>
    <p>O2</p>
    <p>&amp;1</p>
    <p>&amp;2</p>
    <p>Inception.v1 up to Mixed_5c</p>
    <p>Inception.v1 up to Mixed_5c</p>
  </div>
  <div class="page">
    <p>HPD Evaluation 13</p>
    <p>q Training: &gt; 26,000 image pairs q 558 labeled by Mechanical Turk (MTurk) workers</p>
    <p>q Each image labeled by up to 100 workers q 26,244 synthetically generated images</p>
    <p>q 84% Precision, 82% F1-score q Holdout subset of 112 image pairs</p>
  </div>
  <div class="page">
    <p>Major vs. Minor Components 14</p>
    <p>Input</p>
    <p>Vector</p>
    <p>Major components</p>
    <p>Minor components</p>
    <p>q Some components are equivalent of others q We can train some components to be major</p>
  </div>
  <div class="page">
    <p>CL-GAN generator 15</p>
    <p>CEAL Generator Network</p>
    <p>=512</p>
    <p>Major components</p>
    <p>Minor components</p>
  </div>
  <div class="page">
    <p>Train Majors for Distinguishability</p>
    <p>Generator Network (Gceal)</p>
    <p>Human Distinguishable</p>
    <p>Major Minor</p>
    <p>-1</p>
    <p>+1  Major Minor</p>
    <p>Input Vectors Key Fingerprints</p>
  </div>
  <div class="page">
    <p>Train Minors 17</p>
    <p>Generator Network (Gceal)</p>
    <p>Human Indistinguishable</p>
    <p>Major Minor</p>
    <p>-1</p>
    <p>+1 Major Minor</p>
    <p>Input Vectors Key Fingerprints</p>
  </div>
  <div class="page">
    <p>Train Majors for Diversity</p>
    <p>Generator Network (Gceal)</p>
    <p>Human Distinguishable</p>
    <p>Major Minor</p>
    <p>+1</p>
    <p>+1  Minor</p>
    <p>Input Vectors Key Fingerprints</p>
  </div>
  <div class="page">
    <p>(G, d)-adversary [Dechand et al. Usenix 16]</p>
    <p>q Generate target keys (G bits)</p>
    <p>q Generate attack keys different in d bits from target</p>
    <p>q Generate corresponding visual key fingerprints</p>
    <p>q Use a HPD to filter similar fingerprints to target</p>
    <p>Target Key</p>
    <p>Attack Key</p>
    <p>Different in d positions</p>
    <p>G bit keys 19</p>
  </div>
  <div class="page">
    <p>CEAL Under (G, d)-attack 20</p>
    <p>Attack Dataset</p>
    <p>Dataset Size</p>
    <p># Attacks Identified by HPD-Attacker</p>
    <p>Human Verified Attacks</p>
    <p>(123,1)adversary</p>
    <p>(123,d)adversary</p>
    <p>Evaluate potential attack images using 374 MTurk workers</p>
  </div>
  <div class="page">
    <p>(G, d) Attack Examples 21</p>
    <p>Targets</p>
    <p>Attacks</p>
    <p>Humans labeled as different Humans labeled as same</p>
  </div>
  <div class="page">
    <p>CEAL vs. Vash 22</p>
    <p>q Generate 10,000 random Vash and CEAL images q Compare all key fingerprint pairs using HPD</p>
    <p>q Approx. 50 million image pair comparisons</p>
    <p>VKFG Attack Dataset Size # Attacks</p>
    <p>Identified by HPD Human</p>
    <p>Verified Attacks CEAL ~50M 1 0 (0%)</p>
    <p>Vash ~50M 150 24 (16%)</p>
    <p>Attack datasets of 10,000 random images</p>
  </div>
  <div class="page">
    <p>Conclusions 23</p>
    <p>q CEAL: Visual key fingerprint generation solution q Human-distinguishable fingerprints q Resilient to powerful adversaries</p>
    <p>q CEAL improves on state-of-the-art Vash q Resilient to attack q Fast to compare: 2.73s for CEAL vs. 3.03s for Vash</p>
    <p>q Incentive to adversaries to improve HPD q Applications to CAPTCHA</p>
  </div>
  <div class="page">
    <p>Backup Slides</p>
  </div>
  <div class="page">
    <p>Input Mapper 25</p>
    <p>BCH(!=255, &quot;=123, dmin =19) for CL-GAN dmin = min Hamming distance between codewords</p>
    <p>PRNG</p>
    <p>ECC</p>
    <p>Input Mapper</p>
    <p>Input Binary String</p>
    <p>Major Components</p>
    <p>Minor Components</p>
    <p># = 123 bits</p>
    <p>M = 255 codeword bits +</p>
  </div>
  <div class="page">
    <p>Attack Success Relation to d 26</p>
    <p>The break ratio of 1 million target CEAL images for each value of d, the Hamming distance between the attack and the target binary fingerprints, according to (left) HPD_model_1 and (right) HPD_attacker.</p>
  </div>
  <div class="page">
    <p>Datasets for Training HPD 27</p>
    <p>Dataset Name # Image Pairs Labels Labeled Synthetic Image Pairs 558 Mixed</p>
    <p>Unrealistic DCGAN Image Pairs 11,072 Same</p>
    <p>Minor Change Image Pairs Dataset 7,040 Same</p>
    <p>Blob Image Pairs Dataset 2,108 Different</p>
    <p>Enhanced Synthetic Image Pairs Dataset 5000 Different</p>
    <p>Total 26,802 Mixed</p>
    <p>Ground Truth Human Perception and Synthetic Image Pair Datasets we used to train HPD</p>
  </div>
  <div class="page">
    <p>HPD Performance on Vash Images 28</p>
    <p>Model F1 FPR FNR Recall Precision</p>
    <p>HPD_model_1 0.76 0.21 0.14 0.86 0.69</p>
    <p>Performance of HPD over 120 labeled Vash images</p>
  </div>
  <div class="page">
    <p>CEAL vs. Vash: Time to Verify 29</p>
    <p>Vash: 3.03s (SD=5.42s) avg over 150 attacks CEAL: 2.73s (SD=2.33s) avg over 48 attacks</p>
  </div>
</Presentation>
