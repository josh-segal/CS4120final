<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Understanding Sources of Inefficiency in</p>
    <p>General-Purpose Chips Rehan Hameed</p>
    <p>Wajahat Qadeer</p>
    <p>Megan Wachs</p>
    <p>Omid Azizi</p>
    <p>Alex Solomatnikov Benjamin Lee</p>
    <p>Stephen Richardson</p>
    <p>Christos Kozyrakis</p>
    <p>Mark Horowitz</p>
  </div>
  <div class="page">
    <p>GP Processors Are Inefficient</p>
    <p>Processors work well for a broad range of applications</p>
    <p>Have well amortized NRE</p>
    <p>For a specific performance target, energy and area efficiency is low</p>
    <p>Processors are power limited</p>
    <p>Hard to meet performance and energy of emerging applications  Enhancement of low-quality video, analysis and capture motion in 3D, etc</p>
    <p>At fixed power, more ops/sec requires lower energy/op</p>
    <p>Emerging</p>
    <p>Applications vs.</p>
    <p>Nehalem</p>
  </div>
  <div class="page">
    <p>More Efficient Computing Is Possible</p>
    <p>Embedded media devices perform GOP/s</p>
    <p>Cell phones, video cameras, etc</p>
    <p>Efficiency of processors inadequate for these devices</p>
    <p>ASICs needed to meet stringent efficiency requirements</p>
    <p>ASICs are difficult to design and inflexible</p>
    <p>Emerging</p>
    <p>Applications</p>
    <p>ASIC</p>
  </div>
  <div class="page">
    <p>An Example</p>
    <p>High definition video encoding is ubiquitous</p>
    <p>Cell phones, camcorders, point and shoot cameras, etc.</p>
    <p>A small ASIC does it</p>
    <p>Can easily satisfy performance and efficiency requirements</p>
    <p>Very challenging for processors</p>
    <p>What makes the processors inefficient compared to ASICs?</p>
    <p>What does it to take to make a processor as efficient as an ASIC?</p>
    <p>How much programmability do you lose?</p>
  </div>
  <div class="page">
    <p>CMP Energy Breakdown</p>
    <p>Assume everything but functional unit is overhead</p>
    <p>Only 20x improvement in efficiency</p>
    <p>For HD H.264 encoder</p>
    <p>2.8GHz Pentium 4 is 500x worse in energy*</p>
    <p>Four processor Tensilica based CMP is also 500x worse in energy*</p>
    <p>* Chen, T.-C., et al., &quot;Analysis and architecture design of an HDTV720p 30 frames/s H.264/AVC encoder,&quot; Circuits and</p>
    <p>Systems for Video Technology, IEEE Transactions on, vol.16, no.6, pp. 673-688, June 2006.</p>
  </div>
  <div class="page">
    <p>Achieving ASIC Efficiencies: Getting to 500x</p>
    <p>Need basic ops that are extremely low-energy</p>
    <p>Function units have overheads over raw operations</p>
    <p>8-16 bit operations have energy of sub pJ  Function unit energy for RISC was around 5pJ</p>
    <p>And then dont mess it up</p>
    <p>No communication energy / op  This includes register and memory fetch</p>
    <p>Merging of many simple operations into mega ops  Eliminate the need to store / communicate intermediate results</p>
  </div>
  <div class="page">
    <p>How Much Specialization Is Needed?</p>
    <p>How far will general purpose optimizations go?</p>
    <p>Can we stay clear of application specific optimizations?</p>
    <p>How close to ASIC efficiencies will this achieve?</p>
    <p>Better understand nature of various overheads</p>
    <p>What are the long poles that need to be removed</p>
    <p>Is there an incremental path from GP to ASIC</p>
    <p>Is it possible to create an intermediate solution?</p>
  </div>
  <div class="page">
    <p>Case Study</p>
    <p>Use Tensilica to create optimized processors</p>
    <p>Transform CMP into an efficient HD H.264 encoder</p>
    <p>To better understand the sources of overhead in processor</p>
    <p>Why H.264 Encoder?</p>
    <p>Its everywhere</p>
    <p>Variety of computation motifs  data parallel to control intensive</p>
    <p>Good software and hardware implementations exist  ASIC H.264 solutions demonstrate a large energy advantage</p>
  </div>
  <div class="page">
    <p>Optimization Strategy For Case Study</p>
    <p>Two optimization stages</p>
    <p>General purpose, data parallel optimizations</p>
    <p>SIMD, VLIW, reduced register and data path widths  Operation fusion  limited to two inputs and one output</p>
    <p>Similar to Intels SSE instructions</p>
    <p>Application specific optimizations  Arbitrary new compute operations</p>
    <p>Closely couple data storage and data-path structures</p>
  </div>
  <div class="page">
    <p>Industry standard for video compression</p>
    <p>Digital television, DVD-video, mobile TV, internet video, etc.</p>
    <p>What Is H.264?</p>
    <p>Prediction Transform/</p>
    <p>Quantize</p>
    <p>Entropy</p>
    <p>Encode</p>
    <p>Inter</p>
    <p>prediction</p>
    <p>Intra</p>
    <p>prediction (IP)</p>
    <p>Integer and Fractional Motion</p>
    <p>Estimation (IME, FME)</p>
    <p>CABAC</p>
  </div>
  <div class="page">
    <p>Data Parallel</p>
    <p>Computational Motifs Mapping</p>
    <p>Prediction Transform/</p>
    <p>Quantize</p>
    <p>Entropy</p>
    <p>Encode</p>
    <p>Inter</p>
    <p>prediction</p>
    <p>Intra</p>
    <p>prediction</p>
    <p>Sequential</p>
  </div>
  <div class="page">
    <p>H.264 Encoder - Uni-processor Performance</p>
    <p>IME and FME dominate total execution time</p>
    <p>CABAC is small but dictates final gain</p>
  </div>
  <div class="page">
    <p>H.264  Macroblock Pipeline</p>
  </div>
  <div class="page">
    <p>Base CMP vs. ASIC</p>
    <p>Huge efficiency gap</p>
    <p>4-proc CMP 250x slower</p>
    <p>500x extra energy</p>
    <p>Manycore doesnt help</p>
    <p>Energy/frame remains same</p>
    <p>Performance improves</p>
  </div>
  <div class="page">
    <p>General Purpose Extensions: SIMD &amp; ILP</p>
    <p>SIMD</p>
    <p>Up to 18-way SIMD in reduced precision</p>
    <p>VLIW</p>
    <p>Up to 3-slot VLIW</p>
    <p>Load</p>
    <p>Add</p>
    <p>Load</p>
    <p>Add</p>
    <p>Load</p>
    <p>Add</p>
    <p>accumulator</p>
  </div>
  <div class="page">
    <p>SIMD and ILP - Results</p>
    <p>Order of magnitude improvement in performance, energy</p>
    <p>For data parallel algorithms</p>
    <p>But ASIC still better by roughly 2 orders of magnitude</p>
  </div>
  <div class="page">
    <p>SIMD and ILP  Results</p>
    <p>Most of energy dissipation is still an overhead 17</p>
    <p>Good news: we made the FU more efficient</p>
    <p>Reduced the power of the op by 4x  By bit width / simplification</p>
    <p>Bad news: overhead decreased by only 2x</p>
  </div>
  <div class="page">
    <p>Operation Fusion</p>
    <p>Compiler can find interesting instructions to merge</p>
    <p>Tensilicas Xpres</p>
    <p>We did this manually</p>
    <p>Tried to create instructions that might be possible</p>
    <p>Might be free in future machines</p>
    <p>Common instruction might be present in GP</p>
  </div>
  <div class="page">
    <p>Operation Fusion  Not A Big Gain</p>
    <p>Helps a little, so it is good if free</p>
  </div>
  <div class="page">
    <p>Data Parallel Optimization Summary</p>
    <p>Great for data parallel applications</p>
    <p>Improve energy efficiency by 10x over CPU</p>
    <p>But CABAC largely remains unaffected</p>
    <p>Overheads still dominate</p>
    <p>Basic operations are very low-energy</p>
    <p>Even with 15-20 operations per instruction, get 90% overhead</p>
    <p>Data movement dominates computation</p>
    <p>To get ASIC efficiency need more compute/overhead</p>
    <p>Find functions with large compute/low communication</p>
    <p>Aggregate work in large chunks to create highly optimized FUs</p>
    <p>Merge data-storage and data-path structures</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Magic Instructions</p>
    <p>Fuse computational unit to storage</p>
    <p>Create specialized data storage structures</p>
    <p>Require modest memory bandwidth to keep full</p>
    <p>Internal data motion is hard wired</p>
    <p>Use all the local data for computation</p>
    <p>Arbitrary new low-power compute operations</p>
    <p>Large effect on energy efficiency and performance</p>
    <p>Merged</p>
    <p>Register / Hardware Block</p>
  </div>
  <div class="page">
    <p>Magic Instructions  SAD</p>
    <p>sum = sum + abs(xref  xcur)</p>
    <p>Looking for the difference between two images</p>
    <p>Hundreds of SAD calculations to get one image difference  Need to test many different position to find the best</p>
    <p>Data for each calculation is nearly the same</p>
    <p>Search</p>
    <p>Center</p>
    <p>Candidate</p>
    <p>Block</p>
    <p>Candidate</p>
    <p>Motion Vector</p>
  </div>
  <div class="page">
    <p>Magic Instructions - SAD</p>
    <p>SIMD implementation</p>
    <p>Limited to 16 operations per cycle</p>
    <p>Horizontal data-reuse requires many shift operations</p>
    <p>No vertical data reuse means wasted cache energy</p>
    <p>Significant register file access energy</p>
    <p>Search</p>
    <p>Center</p>
    <p>Magic  Serial in, parallel out structure</p>
    <p>Enables 256 SADs/cycle which reduces fetch energy</p>
    <p>Vertical data-reuse results in reduced DCache energy</p>
    <p>Dedicated paths to compute reduce register access energy</p>
  </div>
  <div class="page">
    <p>Custom SAD instruction Hardware</p>
    <p>Reference Pixel Registers:</p>
    <p>Horizontal and vertical shift with</p>
    <p>parallel access to all rows</p>
    <p>Four 4x1 SAD Units</p>
    <p>B it</p>
    <p>W ri</p>
    <p>te P</p>
    <p>or tFour 4x1 SAD Units</p>
    <p>Four 4x1 SAD Units</p>
    <p>Four 4x1 SAD Units</p>
  </div>
  <div class="page">
    <p>Fractional Motion Estimation</p>
    <p>Take the output from the integer motion estimation</p>
    <p>Run again against base image shifted by of a pixel</p>
    <p>Need to do this in X and Y</p>
    <p>Search</p>
    <p>Center</p>
    <p>Candidate</p>
    <p>Block</p>
    <p>Candidate</p>
    <p>Motion Vector</p>
  </div>
  <div class="page">
    <p>Generating the Shifted Images:</p>
    <p>Pixel Upsampling</p>
    <p>xn = x-2  5x-1 + 20x0 + 20x1  5x2 + x3</p>
    <p>FIR filter requiring one new pixel per computation</p>
    <p>Regular register files require 5 transfers per op</p>
    <p>Wasted energy in instruction fetch and register file</p>
    <p>Augment register files with a custom shift register</p>
    <p>Parallel access of entries to create custom FIR arithmetic unit</p>
    <p>Result dissipates 1/30th of energy of traditional approach</p>
  </div>
  <div class="page">
    <p>Custom FME</p>
    <p>Custom upsampling datapath</p>
  </div>
  <div class="page">
    <p>Custom FME</p>
    <p>Custom upsampling datapath</p>
  </div>
  <div class="page">
    <p>Custom FME</p>
    <p>Custom upsampling datapath</p>
  </div>
  <div class="page">
    <p>List Of Other Magic Instructions</p>
    <p>Hadamard/DCT</p>
    <p>Matrix transpose unit</p>
    <p>Operation fusion with no limitation on number of operands</p>
    <p>Intra Prediction</p>
    <p>Customized interconnections for different prediction modes</p>
    <p>CABAC</p>
    <p>FIFO structures in binarization module</p>
    <p>Fundamentally different computation fused with no restrictions</p>
    <p>Not many were needed</p>
  </div>
  <div class="page">
    <p>Magic Instructions - Energy</p>
    <p>Efficiency orders of magnitude better than GP</p>
    <p>Within 3X of ASIC energy efficiency</p>
  </div>
  <div class="page">
    <p>Magic instructions - Results</p>
    <p>Over 35% energy now in ALU</p>
    <p>Overheads are well-amortized  up to 256 ops / instruction</p>
    <p>More data re-use within the data-path</p>
    <p>Most of the code involves magic instructions 33</p>
  </div>
  <div class="page">
    <p>Magic Instructions Summary</p>
    <p>Optimization strategy similar across all algorithms</p>
    <p>Closely couple data storage and data path structures</p>
    <p>Maximize data reuse inside the datapath</p>
    <p>Commonly used hardware structures and techniques</p>
    <p>Shift registers with parallel access to internal values</p>
    <p>Direct computation of the desired output  Eliminate the generation (and storage) of intermediate results</p>
    <p>Hundreds of extremely low-power ops per instruction</p>
    <p>Works well for both data parallel and sequential algorithms</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Many operations are very simple and low energy</p>
    <p>They SIMD/Vector parallelize well, but overheads still dominate</p>
    <p>To get ASIC efficiencies, need 100s ops/instruction  Specialized hardware/memory</p>
    <p>Building ASIC hardware in a processor worked well</p>
    <p>Easier than building an ASIC, since it was incremental</p>
    <p>Start with strong software development environment  Add and debug only the hardware you need</p>
    <p>Efficient hardware requires customization</p>
    <p>We should make doing chip customization feasible</p>
    <p>And that means we should design chip generators and not chips</p>
  </div>
</Presentation>
