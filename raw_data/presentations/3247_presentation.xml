<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>C O M P U T A T I O N A L R E S E A R C H D I V I S I O N</p>
    <p>BIPSBIPS</p>
    <p>Tuning Sparse Matrix Vector Multiplication for multi-core SMPs</p>
    <p>Samuel Williams1,2, Richard Vuduc3, Leonid Oliker1,2, John Shalf2, Katherine Yelick1,2, James Demmel1,2</p>
    <p>samw@cs.berkeley.edu</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Overview</p>
    <p>Multicore is the de facto performance solution for the next decade</p>
    <p>Examined Sparse Matrix Vector Multiplication (SpMV) kernel  Important HPC kernel  Memory intensive  Challenging for multicore</p>
    <p>Present two autotuned threaded implementations:  Pthread, cache-based implementation  Cell local store-based implementation</p>
    <p>Benchmarked performance across 4 diverse multicore architectures  Intel Xeon (Clovertown)  AMD Opteron  Sun Niagara2  IBM Cell Broadband Engine</p>
    <p>Compare with leading MPI implementation(PETSc) with an autotuned serial kernel (OSKI)</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Sparse Matrix Vector Multiplication</p>
    <p>Sparse Matrix  Most entries are 0.0  Performance advantage in only</p>
    <p>storing/operating on the nonzeros  Requires significant meta data</p>
    <p>Evaluate y=Ax  A is a sparse matrix  x &amp; y are dense vectors</p>
    <p>Challenges  Difficult to exploit ILP(bad for superscalar),  Difficult to exploit DLP(bad for SIMD)  Irregular memory access to source vector  Difficult to load balance  Very low computational intensity (often &gt;6 bytes/flop)</p>
    <p>A x y</p>
  </div>
  <div class="page">
    <p>C O M P U T A T I O N A L R E S E A R C H D I V I S I O N</p>
    <p>BIPSBIPS</p>
    <p>Dataset (Matrices) Multicore SMPs</p>
    <p>Test Suite</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Matrices Used</p>
    <p>Pruned original SPARSITY suite down to 14  none should fit in cache  Subdivided them into 4 categories  Rank ranges from 2K to 1M</p>
    <p>Dense</p>
    <p>Protein FEM /</p>
    <p>Spheres FEM /</p>
    <p>Cantilever Wind</p>
    <p>Tunnel FEM / Harbor</p>
    <p>QCD FEM / Ship</p>
    <p>Economics Epidemiology</p>
    <p>FEM / Accelerator</p>
    <p>Circuit webbase</p>
    <p>LP</p>
    <p>Well Structured (sorted by nonzeros/row)</p>
    <p>Poorly Structured hodgepodge</p>
    <p>Extreme Aspect Ratio (linear programming)</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Multicore SMP Systems</p>
    <p>Core2</p>
    <p>FSB</p>
    <p>Fully Buffered DRAM</p>
    <p>Core2</p>
    <p>Chipset (4x64b controllers)</p>
    <p>Core2 Core2</p>
    <p>Core2</p>
    <p>FSB</p>
    <p>Core2</p>
    <p>Core2 Core2</p>
    <p>Intel Clovertown C</p>
    <p>ro ss</p>
    <p>ba r</p>
    <p>S w</p>
    <p>itc h</p>
    <p>Fully Buffered DRAM</p>
    <p>S ha</p>
    <p>re d</p>
    <p>L2 (</p>
    <p>ay )</p>
    <p>G B</p>
    <p>/s (f</p>
    <p>ill )</p>
    <p>B /s</p>
    <p>(w rit</p>
    <p>et hr</p>
    <p>u)</p>
    <p>Sun Niagara2</p>
    <p>AMD Opteron</p>
    <p>Opteron</p>
    <p>Opteron</p>
    <p>Memory Controller / HT</p>
    <p>Opteron</p>
    <p>Opteron</p>
    <p>Memory Controller / HT</p>
    <p>DDR2 DRAM DDR2 DRAM</p>
    <p>XDR DRAM</p>
    <p>E IB</p>
    <p>(R ing N</p>
    <p>etw ork)</p>
    <p>&lt;&lt;20GB/s each</p>
    <p>direction</p>
    <p>SPE256K</p>
    <p>PPE512K L2</p>
    <p>MFC</p>
    <p>BIF</p>
    <p>XDR</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>XDR DRAM</p>
    <p>E IB</p>
    <p>(R ing N</p>
    <p>etw ork)</p>
    <p>SPE 256K</p>
    <p>PPE 512K L2</p>
    <p>MFC</p>
    <p>BIF</p>
    <p>XDR</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>IBM Cell Blade</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Multicore SMP Systems</p>
    <p>(memory hierarchy)</p>
    <p>Core2</p>
    <p>FSB</p>
    <p>Fully Buffered DRAM</p>
    <p>Core2</p>
    <p>Chipset (4x64b controllers)</p>
    <p>Core2 Core2</p>
    <p>Core2</p>
    <p>FSB</p>
    <p>Core2</p>
    <p>Core2 Core2</p>
    <p>Intel Clovertown C</p>
    <p>ro ss</p>
    <p>ba r</p>
    <p>S w</p>
    <p>itc h</p>
    <p>Fully Buffered DRAM</p>
    <p>S ha</p>
    <p>re d</p>
    <p>L2 (</p>
    <p>ay )</p>
    <p>G B</p>
    <p>/s (f</p>
    <p>ill )</p>
    <p>B /s</p>
    <p>(w rit</p>
    <p>et hr</p>
    <p>u)</p>
    <p>Sun Niagara2</p>
    <p>AMD Opteron</p>
    <p>Opteron</p>
    <p>Opteron</p>
    <p>Memory Controller / HT</p>
    <p>Opteron</p>
    <p>Opteron</p>
    <p>Memory Controller / HT</p>
    <p>DDR2 DRAM DDR2 DRAM</p>
    <p>XDR DRAM</p>
    <p>E IB</p>
    <p>(R ing N</p>
    <p>etw ork)</p>
    <p>&lt;&lt;20GB/s each</p>
    <p>direction</p>
    <p>SPE256K</p>
    <p>PPE512K L2</p>
    <p>MFC</p>
    <p>BIF</p>
    <p>XDR</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>XDR DRAM</p>
    <p>E IB</p>
    <p>(R ing N</p>
    <p>etw ork)</p>
    <p>SPE 256K</p>
    <p>PPE 512K L2</p>
    <p>MFC</p>
    <p>BIF</p>
    <p>XDR</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>IBM Cell Blade</p>
    <p>Co nve</p>
    <p>ntio nal</p>
    <p>Ca che</p>
    <p>-ba sed</p>
    <p>Me mo</p>
    <p>ry H iera</p>
    <p>rch y</p>
    <p>Dis join</p>
    <p>t Lo cal</p>
    <p>St ore</p>
    <p>Me mo</p>
    <p>ry H iera</p>
    <p>rch y</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Multicore SMP Systems</p>
    <p>(cache)</p>
    <p>Core2</p>
    <p>FSB</p>
    <p>Fully Buffered DRAM</p>
    <p>Core2</p>
    <p>Chipset (4x64b controllers)</p>
    <p>Core2 Core2</p>
    <p>Core2</p>
    <p>FSB</p>
    <p>Core2</p>
    <p>Core2 Core2</p>
    <p>Intel Clovertown C</p>
    <p>ro ss</p>
    <p>ba r</p>
    <p>S w</p>
    <p>itc h</p>
    <p>Fully Buffered DRAM</p>
    <p>S ha</p>
    <p>re d</p>
    <p>L2 (</p>
    <p>ay )</p>
    <p>G B</p>
    <p>/s (f</p>
    <p>ill )</p>
    <p>B /s</p>
    <p>(w rit</p>
    <p>et hr</p>
    <p>u)</p>
    <p>Sun Niagara2</p>
    <p>AMD Opteron</p>
    <p>Opteron</p>
    <p>Opteron</p>
    <p>Memory Controller / HT</p>
    <p>Opteron</p>
    <p>Opteron</p>
    <p>Memory Controller / HT</p>
    <p>DDR2 DRAM DDR2 DRAM</p>
    <p>XDR DRAM</p>
    <p>E IB</p>
    <p>(R ing N</p>
    <p>etw ork)</p>
    <p>&lt;&lt;20GB/s each</p>
    <p>direction</p>
    <p>SPE256K</p>
    <p>PPE512K L2</p>
    <p>MFC</p>
    <p>BIF</p>
    <p>XDR</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>XDR DRAM</p>
    <p>E IB</p>
    <p>(R ing N</p>
    <p>etw ork)</p>
    <p>SPE 256K</p>
    <p>PPE 512K L2</p>
    <p>MFC</p>
    <p>BIF</p>
    <p>XDR</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>IBM Cell Blade</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Multicore SMP Systems</p>
    <p>(peak flops)</p>
    <p>Core2</p>
    <p>FSB</p>
    <p>Fully Buffered DRAM</p>
    <p>Core2</p>
    <p>Chipset (4x64b controllers)</p>
    <p>Core2 Core2</p>
    <p>Core2</p>
    <p>FSB</p>
    <p>Core2</p>
    <p>Core2 Core2</p>
    <p>Intel Clovertown C</p>
    <p>ro ss</p>
    <p>ba r</p>
    <p>S w</p>
    <p>itc h</p>
    <p>Fully Buffered DRAM</p>
    <p>S ha</p>
    <p>re d</p>
    <p>L2 (</p>
    <p>ay )</p>
    <p>G B</p>
    <p>/s (f</p>
    <p>ill )</p>
    <p>B /s</p>
    <p>(w rit</p>
    <p>et hr</p>
    <p>u)</p>
    <p>Sun Niagara2</p>
    <p>AMD Opteron</p>
    <p>Opteron</p>
    <p>Opteron</p>
    <p>Memory Controller / HT</p>
    <p>Opteron</p>
    <p>Opteron</p>
    <p>Memory Controller / HT</p>
    <p>DDR2 DRAM DDR2 DRAM</p>
    <p>XDR DRAM</p>
    <p>E IB</p>
    <p>(R ing N</p>
    <p>etw ork)</p>
    <p>&lt;&lt;20GB/s each</p>
    <p>direction</p>
    <p>SPE256K</p>
    <p>PPE512K L2</p>
    <p>MFC</p>
    <p>BIF</p>
    <p>XDR</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>XDR DRAM</p>
    <p>E IB</p>
    <p>(R ing N</p>
    <p>etw ork)</p>
    <p>SPE 256K</p>
    <p>PPE 512K L2</p>
    <p>MFC</p>
    <p>BIF</p>
    <p>XDR</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>IBM Cell Blade</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Multicore SMP Systems</p>
    <p>(peak read bandwidth)</p>
    <p>Core2</p>
    <p>FSB</p>
    <p>Fully Buffered DRAM</p>
    <p>Core2</p>
    <p>Chipset (4x64b controllers)</p>
    <p>Core2 Core2</p>
    <p>Core2</p>
    <p>FSB</p>
    <p>Core2</p>
    <p>Core2 Core2</p>
    <p>Intel Clovertown C</p>
    <p>ro ss</p>
    <p>ba r</p>
    <p>S w</p>
    <p>itc h</p>
    <p>Fully Buffered DRAM</p>
    <p>S ha</p>
    <p>re d</p>
    <p>L2 (</p>
    <p>ay )</p>
    <p>G B</p>
    <p>/s (f</p>
    <p>ill )</p>
    <p>B /s</p>
    <p>(w rit</p>
    <p>et hr</p>
    <p>u)</p>
    <p>Sun Niagara2</p>
    <p>AMD Opteron</p>
    <p>Opteron</p>
    <p>Opteron</p>
    <p>Memory Controller / HT</p>
    <p>Opteron</p>
    <p>Opteron</p>
    <p>Memory Controller / HT</p>
    <p>DDR2 DRAM DDR2 DRAM</p>
    <p>XDR DRAM</p>
    <p>E IB</p>
    <p>(R ing N</p>
    <p>etw ork)</p>
    <p>&lt;&lt;20GB/s each</p>
    <p>direction</p>
    <p>SPE256K</p>
    <p>PPE512K L2</p>
    <p>MFC</p>
    <p>BIF</p>
    <p>XDR</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>XDR DRAM</p>
    <p>E IB</p>
    <p>(R ing N</p>
    <p>etw ork)</p>
    <p>SPE 256K</p>
    <p>PPE 512K L2</p>
    <p>MFC</p>
    <p>BIF</p>
    <p>XDR</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>IBM Cell Blade</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Multicore SMP Systems</p>
    <p>(NUMA)</p>
    <p>Core2</p>
    <p>FSB</p>
    <p>Fully Buffered DRAM</p>
    <p>Core2</p>
    <p>Chipset (4x64b controllers)</p>
    <p>Core2 Core2</p>
    <p>Core2</p>
    <p>FSB</p>
    <p>Core2</p>
    <p>Core2 Core2</p>
    <p>Intel Clovertown C</p>
    <p>ro ss</p>
    <p>ba r</p>
    <p>S w</p>
    <p>itc h</p>
    <p>Fully Buffered DRAM</p>
    <p>S ha</p>
    <p>re d</p>
    <p>L2 (</p>
    <p>ay )</p>
    <p>G B</p>
    <p>/s (f</p>
    <p>ill )</p>
    <p>B /s</p>
    <p>(w rit</p>
    <p>et hr</p>
    <p>u)</p>
    <p>Sun Niagara2</p>
    <p>AMD Opteron</p>
    <p>Opteron</p>
    <p>Opteron</p>
    <p>Memory Controller / HT</p>
    <p>Opteron</p>
    <p>Opteron</p>
    <p>Memory Controller / HT</p>
    <p>DDR2 DRAM DDR2 DRAM</p>
    <p>XDR DRAM</p>
    <p>E IB</p>
    <p>(R ing N</p>
    <p>etw ork)</p>
    <p>&lt;&lt;20GB/s each</p>
    <p>direction</p>
    <p>SPE256K</p>
    <p>PPE512K L2</p>
    <p>MFC</p>
    <p>BIF</p>
    <p>XDR</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>SPE256KMFC</p>
    <p>XDR DRAM</p>
    <p>E IB</p>
    <p>(R ing N</p>
    <p>etw ork)</p>
    <p>SPE 256K</p>
    <p>PPE 512K L2</p>
    <p>MFC</p>
    <p>BIF</p>
    <p>XDR</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>SPE 256K MFC</p>
    <p>IBM Cell Blade</p>
    <p>U ni</p>
    <p>fo rm</p>
    <p>M em</p>
    <p>or y</p>
    <p>A cc</p>
    <p>es s</p>
    <p>N on</p>
    <p>-U ni</p>
    <p>fo rm</p>
    <p>M em</p>
    <p>or y</p>
    <p>A cc</p>
    <p>es s</p>
  </div>
  <div class="page">
    <p>C O M P U T A T I O N A L R E S E A R C H D I V I S I O N</p>
    <p>BIPSBIPS</p>
    <p>Nave Implementation For cache-based machines Included a median performance number</p>
  </div>
  <div class="page">
    <p>BIPSBIPS vanilla C Performance Intel Clovertown AMD Opteron</p>
    <p>Sun Niagara2  Vanilla C implementation  Matrix stored in CSR (compressed</p>
    <p>sparse row)  Explored compiler options - only</p>
    <p>the best is presented here</p>
  </div>
  <div class="page">
    <p>C O M P U T A T I O N A L R E S E A R C H D I V I S I O N</p>
    <p>BIPSBIPS</p>
    <p>Optimized for multicore/threading Variety of shared memory programming models are acceptable(not just Pthreads) More colors = more optimizations = more work</p>
    <p>Pthread Implementation</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Parallelization</p>
    <p>Matrix partitioned by rows and balanced by the number of nonzeros</p>
    <p>SPMD like approach  A barrier() is called before and after the SpMV kernel  Each sub matrix stored separately in CSR  Load balancing can be challenging</p>
    <p># of threads explored in powers of 2 (in paper)</p>
    <p>A</p>
    <p>x</p>
    <p>y</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Nave Parallel Performance</p>
    <p>Nave Pthreads</p>
    <p>Nave Single Thread</p>
    <p>Intel Clovertown AMD Opteron</p>
    <p>Sun Niagara2</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Nave Parallel Performance</p>
    <p>Nave Pthreads</p>
    <p>Nave Single Thread</p>
    <p>Intel Clovertown AMD Opteron</p>
    <p>Sun Niagara2</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Nave Parallel Performance</p>
    <p>Nave Pthreads</p>
    <p>Nave Single Thread</p>
    <p>Intel Clovertown AMD Opteron</p>
    <p>Sun Niagara2</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Case for Autotuning</p>
    <p>How do we deliver good performance across all these architectures, across all matrices without exhaustively optimizing every combination</p>
    <p>Autotuning  Write a Perl script that generates all possible optimizations  Heuristically, or exhaustively search the optimizations  Existing SpMV solution: OSKI (developed at UCB)</p>
    <p>This work:  Optimizations geared for multi-core/-threading  generates SSE/SIMD intrinsics, prefetching, loop</p>
    <p>transformations, alternate data structures, etc  prototype for parallel OSKI</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Exploiting NUMA, Affinity</p>
    <p>Bandwidth on the Opteron(and Cell) can vary substantially based on placement of data</p>
    <p>Bind each sub matrix and the thread to process it together</p>
    <p>Explored libnuma, Linux, and Solaris routines  Adjacent blocks bound to adjacent cores</p>
    <p>Opteron</p>
    <p>DDR2 DRAM</p>
    <p>Opteron</p>
    <p>DDR2 DRAM</p>
    <p>Opteron</p>
    <p>DDR2 DRAM</p>
    <p>Opteron</p>
    <p>DDR2 DRAM</p>
    <p>Opteron</p>
    <p>DDR2 DRAM</p>
    <p>Opteron</p>
    <p>DDR2 DRAM</p>
    <p>Single Thread Multiple Threads,</p>
    <p>One memory controller Multiple Threads,</p>
    <p>Both memory controllers</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Performance (+NUMA)</p>
    <p>+NUMA/Affinity</p>
    <p>Nave Pthreads</p>
    <p>Nave Single Thread</p>
    <p>Intel Clovertown AMD Opteron</p>
    <p>Sun Niagara2</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Performance (+SW Prefetching)</p>
    <p>+Software Prefetching</p>
    <p>+NUMA/Affinity</p>
    <p>Nave Pthreads</p>
    <p>Nave Single Thread</p>
    <p>Intel Clovertown AMD Opteron</p>
    <p>Sun Niagara2</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Matrix Compression</p>
    <p>For memory bound kernels, minimizing memory traffic should maximize performance</p>
    <p>Compress the meta data  Exploit structure to eliminate meta data</p>
    <p>Heuristic: select the compression that minimizes the matrix size:  power of 2 register blocking  CSR/COO format  16b/32b indices  etc</p>
    <p>Side effect: matrix may be minimized to the point where it fits entirely in cache</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Performance (+matrix compression)</p>
    <p>+Matrix Compression</p>
    <p>+Software Prefetching</p>
    <p>+NUMA/Affinity</p>
    <p>Nave Pthreads</p>
    <p>Nave Single Thread</p>
    <p>Intel Clovertown AMD Opteron</p>
    <p>Sun Niagara2</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Cache and TLB Blocking</p>
    <p>Accesses to the matrix and destination vector are streaming  But, access to the source vector can be random  Reorganize matrix (and thus access pattern) to maximize reuse.  Applies equally to TLB blocking (caching PTEs)</p>
    <p>Heuristic: block destination, then keep adding more columns as long as the number of source vector cache lines(or pages) touched is less than the cache(or TLB). Apply all previous optimizations individually to each cache block.</p>
    <p>Search: neither, cache, cache&amp;TLB</p>
    <p>Better locality at the expense of confusing the hardware prefetchers.</p>
    <p>A</p>
    <p>x</p>
    <p>y</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Performance (+cache blocking)</p>
    <p>+Cache/TLB Blocking</p>
    <p>+Matrix Compression</p>
    <p>+Software Prefetching</p>
    <p>+NUMA/Affinity</p>
    <p>Nave Pthreads</p>
    <p>Nave Single Thread</p>
    <p>Intel Clovertown AMD Opteron</p>
    <p>Sun Niagara2</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Banks, Ranks, and DIMMs</p>
    <p>In this SPMD approach, as the number of threads increases, so to does the number of concurrent streams to memory.</p>
    <p>Most memory controllers have finite capability to reorder the requests. (DMA can avoid or minimize this)</p>
    <p>Addressing/Bank conflicts become increasingly likely</p>
    <p>Add more DIMMs, configuration of ranks can help  Clovertown system was already fully populated</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Performance (more DIMMs, )</p>
    <p>+More DIMMs, Rank configuration, etc</p>
    <p>+Cache/TLB Blocking</p>
    <p>+Matrix Compression</p>
    <p>+Software Prefetching</p>
    <p>+NUMA/Affinity</p>
    <p>Nave Pthreads</p>
    <p>Nave Single Thread</p>
    <p>Intel Clovertown AMD Opteron</p>
    <p>Sun Niagara2</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Performance (more DIMMs, )</p>
    <p>+More DIMMs, Rank configuration, etc</p>
    <p>+Cache/TLB Blocking</p>
    <p>+Matrix Compression</p>
    <p>+Software Prefetching</p>
    <p>+NUMA/Affinity</p>
    <p>Nave Pthreads</p>
    <p>Nave Single Thread</p>
    <p>Intel Clovertown AMD Opteron</p>
    <p>Sun Niagara2</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Performance (more DIMMs, )</p>
    <p>+More DIMMs, Rank configuration, etc</p>
    <p>+Cache/TLB Blocking</p>
    <p>+Matrix Compression</p>
    <p>+Software Prefetching</p>
    <p>+NUMA/Affinity</p>
    <p>Nave Pthreads</p>
    <p>Nave Single Thread</p>
    <p>Intel Clovertown AMD Opteron</p>
    <p>Sun Niagara2</p>
  </div>
  <div class="page">
    <p>C O M P U T A T I O N A L R E S E A R C H D I V I S I O N</p>
    <p>BIPSBIPS</p>
    <p>Comments Performance</p>
    <p>Cell Implementation</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Cell Implementation</p>
    <p>No vanilla C implementation (aside from the PPE)  Even SIMDized double precision is extremely weak</p>
    <p>Scalar double precision is unbearable  Minimum register blocking is 2x1 (SIMDizable)  Can increase memory traffic by 66%</p>
    <p>Cache blocking optimization is transformed into local store blocking  Spatial and temporal locality is captured by software when</p>
    <p>the matrix is optimized  In essence, the high bits of column indices are grouped into DMA</p>
    <p>lists  No branch prediction</p>
    <p>Replace branches with conditional operations  In some cases, what were optional optimizations on cache based</p>
    <p>machines, are requirements for correctness on Cell</p>
    <p>Despite the performance, Cell is still handicapped by double precision</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Performance Intel Clovertown AMD Opteron</p>
    <p>Sun Niagara2 IBM Cell Broadband Engine</p>
  </div>
  <div class="page">
    <p>BIPSBIPS</p>
    <p>Intel Clovertown AMD Opteron</p>
    <p>Sun Niagara2</p>
    <p>Performance</p>
    <p>IBM Cell Broadband Engine 39% of peak flops 89% of bandwidth</p>
  </div>
  <div class="page">
    <p>C O M P U T A T I O N A L R E S E A R C H D I V I S I O N</p>
    <p>BIPSBIPS</p>
    <p>Multicore MPI Implementation This is the default approach to programming multicore</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Multicore MPI Implementation</p>
    <p>Used PETSc with shared memory MPICH  Used OSKI (developed @ UCB) to optimize each thread  = Highly optimized MPI</p>
    <p>MPI(autotuned) Pthreads(autotuned)Nave Single Thread</p>
    <p>Intel Clovertown AMD Opteron</p>
  </div>
  <div class="page">
    <p>C O M P U T A T I O N A L R E S E A R C H D I V I S I O N</p>
    <p>BIPSBIPS</p>
    <p>Summary</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Median Performance &amp; Efficiency</p>
    <p>Used digital power meter to measure sustained system power  FBDIMM drives up Clovertown and Niagara2 power  Right: sustained MFlop/s / sustained Watts</p>
    <p>Default approach(MPI) achieves very low performance and efficiency</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Summary</p>
    <p>Paradoxically, the most complex/advanced architectures required the most tuning, and delivered the lowest performance.</p>
    <p>Most machines achieved less than 50-60% of DRAM bandwidth  Niagara2 delivered both very good performance and productivity  Cell delivered very good performance and efficiency</p>
    <p>90% of memory bandwidth  High power efficiency  Easily understood performance  Extra traffic = lower performance (future work can address this)</p>
    <p>multicore specific autotuned implementation significantly outperformed a state of the art MPI implementation  Matrix compression geared towards multicore  NUMA  Prefetching</p>
  </div>
  <div class="page">
    <p>BIPSBIPS Acknowledgments</p>
    <p>UC Berkeley  RADLab Cluster (Opterons)  PSI cluster(Clovertowns)</p>
    <p>Sun Microsystems  Niagara2</p>
    <p>Forschungszentrum Jlich  Cell blade cluster</p>
  </div>
  <div class="page">
    <p>C O M P U T A T I O N A L R E S E A R C H D I V I S I O N</p>
    <p>BIPSBIPS</p>
    <p>Questions?</p>
  </div>
</Presentation>
