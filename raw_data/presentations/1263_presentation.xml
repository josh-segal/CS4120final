<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>ALERT: Accurate Learning for Energy and Timeliness</p>
    <p>Chengcheng Wan, Muhammad Husni Santriaji, Eri Rogers, Henry Hoffmann, Michael Maire and Shan Lu</p>
  </div>
  <div class="page">
    <p>DNN is Deployed Everywhere</p>
    <p>Weather forecast</p>
    <p>QA robot</p>
    <p>Auto driving</p>
    <p>Smart city</p>
    <p>Trading</p>
    <p>Text generator</p>
  </div>
  <div class="page">
    <p>AL E</p>
    <p>DNN System</p>
    <p>DNN Deployment is Challenging. ?</p>
    <p>Road</p>
    <p>Challenges  Configuration space is huge  Environment may change dynamically  Must be low overhead</p>
  </div>
  <div class="page">
    <p>Previous Work</p>
    <p>Previous Works Challenges</p>
    <p>Low Overhead</p>
    <p>Dynamic Environment</p>
    <p>Huge Space of Configuration</p>
    <p>DNN design</p>
    <p>Resource Management</p>
    <p>[1] H. Hoffmann et. al. Jouleguard: energy guarantees for approximate applications. SOSP, 2015. [2] C. Imes et. al. Poet: a portable approach to minimizing energy under soft real-time constraints. RTAS, 2015 [3] N. Mishra et. al. CALOREE: learning control for predictable latency and low energy. ASPLOS, 2018. [4] A. Rahmani et. al. SPECTR: formal supervisory control and coordination for many-core systems resource management. ASPLOS, 2018.</p>
  </div>
  <div class="page">
    <p>Our ALERT System</p>
    <p>A L E R T AL</p>
    <p>E</p>
    <p>Measurement</p>
    <p>DNN &amp; Power Cap Selection</p>
    <p>DNN System</p>
    <p>?</p>
    <p>Road</p>
    <p>Feedback-based estimation</p>
    <p>Challenges  Configuration space is huge  Environment may change dynamically  Must be low overhead</p>
  </div>
  <div class="page">
    <p>Our ALERT System</p>
    <p>A L E R T AL</p>
    <p>E</p>
    <p>Measurement</p>
    <p>Feedback-based estimation</p>
    <p>DNN &amp; Power Cap Selection</p>
    <p>DNN System</p>
    <p>?</p>
    <p>Road</p>
    <p>Challenges  Configuration space is huge  Environment may change dynamically  Must be low overhead</p>
  </div>
  <div class="page">
    <p>Evaluation Highlights</p>
    <p>ALERT satisfies LAE constraints.</p>
    <p>Probabilistic design overcomes dynamic variability efficiently.</p>
    <p>ALERT achieves 93-99% of Oracles performance</p>
    <p>Coordinating App- and Sys- level improves performance.</p>
    <p>Reduces 13% energy and 27% error over prior approach</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Understanding DNN Deployment Challenges</p>
    <p>ALERT Run-time Inference Management</p>
    <p>Experiments and Results</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Understanding DNN Deployment Challenges</p>
    <p>ALERT Run-time Inference Management</p>
    <p>Experiments and Results</p>
  </div>
  <div class="page">
    <p>Experiment Settings</p>
    <p>Platforms ODroid, CPUs, GPU44</p>
    <p>DNNs ResNet50, VGG16,</p>
    <p>RNN, Bert</p>
  </div>
  <div class="page">
    <p>To p</p>
    <p>-5 E</p>
    <p>rr o r</p>
    <p>R a te</p>
    <p>( %</p>
    <p>)</p>
    <p>Inference Time of One Image (s)</p>
    <p>MobileNet-v1 (=1)</p>
    <p>MobileNet-v2 (=1.3)</p>
    <p>ResNet50</p>
    <p>NasNet-large</p>
    <p>PnasNet-large</p>
    <p>Tradeoffs from DNNs</p>
    <p>High accuracy comes with long latency.</p>
  </div>
  <div class="page">
    <p>A ve</p>
    <p>ra g</p>
    <p>e E</p>
    <p>n e rg</p>
    <p>y (J</p>
    <p>)</p>
    <p>Inference Time of One Image (s) 12</p>
    <p>Tradeoffs from System Settings</p>
    <p>Power limit setting (W)</p>
    <p>Least Energy</p>
    <p>Fastest</p>
    <p>No setting is optimal for both energy and latency.</p>
  </div>
  <div class="page">
    <p>Run-time Variability</p>
  </div>
  <div class="page">
    <p>Run-time Variability</p>
    <p>Latency variation increased by co-located jobs. Without co-locate job With co-locate job</p>
  </div>
  <div class="page">
    <p>Potential Solutions</p>
    <p>ve ra</p>
    <p>g e</p>
    <p>E n e rg</p>
    <p>y (J</p>
    <p>)</p>
    <p>Constraint Settings (deadline  accuracy_goal)</p>
    <p>Sys-level App-level Combined</p>
    <p>Deadline 0.1s 0.2s 0.3s 0.4s 0.5s 0.6s 0.7s Combining both level achieves best performance.</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Understanding DNN Deployment Challenges</p>
    <p>ALERT Run-time Inference Management</p>
    <p>Experiments and Results</p>
  </div>
  <div class="page">
    <p>Three Dimensions &amp; Two Tasks</p>
    <p>Minimize Energy With accuracy goal and inference deadline</p>
    <p>AL E</p>
    <p>Inference Deadline</p>
    <p>Accuracy Goal</p>
    <p>Energy Consumption Goal</p>
    <p>Maximize Accuracy With energy consumption goal and inference deadline</p>
  </div>
  <div class="page">
    <p>Configurations Constraints</p>
    <p>&lt;X</p>
    <p>&lt;Y</p>
    <p>Optimization</p>
    <p>max( )</p>
    <p>Maximize Accuracy Task</p>
    <p>A L</p>
    <p>E 2,2 2,3</p>
    <p>D N</p>
    <p>N s</p>
    <p>Power cap</p>
  </div>
  <div class="page">
    <p>How to estimate the inference latency?  Two key challenges</p>
    <p>Runtime variation: The inference time may be different even for same the configuration</p>
    <p>L</p>
    <p>Profiling</p>
    <p>Runtime 51</p>
  </div>
  <div class="page">
    <p>How to estimate the inference latency?  Two key challenges</p>
    <p>Runtime variation</p>
    <p>Too many combinations of DNNs and resources</p>
    <p>L</p>
    <p>X</p>
    <p>X</p>
    <p>X X</p>
    <p>X</p>
    <p>X</p>
    <p>X X X</p>
    <p>D N</p>
    <p>N s</p>
    <p>d l</p>
    <p>d</p>
    <p>Power Cap p1 p2  pk</p>
  </div>
  <div class="page">
    <p>Potential Solution</p>
    <p>Kalman filter</p>
    <p>Estimate latency for each configuration</p>
    <p>Use recent execution history</p>
    <p>L</p>
    <p>DNN2, P1 43 58 49 51</p>
    <p>DNN1, P2 3031</p>
    <p>History Prediction</p>
  </div>
  <div class="page">
    <p>Potential Solution: drawback</p>
    <p>Cannot solve the problem</p>
    <p>Not enough history for each configuration</p>
    <p>L</p>
    <p>DNN2, P1 43 58 49 51</p>
    <p>DNN1, P2 3031</p>
    <p>History Prediction</p>
    <p>DNN1, P1 ?</p>
    <p>DNN2, P2 ?</p>
  </div>
  <div class="page">
    <p>How to estimate the inference latency?</p>
    <p>Global Slow-down factor</p>
    <p>Use recent execution history under any DNN or resources</p>
    <p>L</p>
    <p>150%</p>
    <p>DNN2, P1</p>
    <p>DNN1, P2</p>
    <p>DNN1, P1</p>
    <p>DNN2, P2</p>
    <p>?</p>
    <p>?</p>
  </div>
  <div class="page">
    <p>How to estimate the inference latency?</p>
    <p>Mean estimation is not sufficient</p>
    <p>The variation might be too big to provide a good prediction.</p>
    <p>Different implications on DNN selection</p>
    <p>L</p>
    <p>Sequence 1 52 43 58 49 50</p>
    <p>Sequence 2 51 50 49 49 50</p>
    <p>History Prediction</p>
    <p>Mean Variation</p>
  </div>
  <div class="page">
    <p>How to estimate the inference latency?</p>
    <p>Global Slow-down factor</p>
    <p>Use recent execution history under any DNN or resources</p>
    <p>Estimate its distribution: mean and variance</p>
    <p>L</p>
    <p>History 52 43 58 49 50</p>
    <p>Mean Variation</p>
  </div>
  <div class="page">
    <p>How to estimate accuracy under a deadline?</p>
    <p>A  Can inference be finished before deadline?</p>
    <p>If yes, training accuracy of the selected DNN</p>
    <p>If not, random guess accuracy</p>
    <p>Unless its an Anytime DNN. Inference Accuracy</p>
    <p>Time</p>
    <p>!&quot;</p>
    <p>#&quot;,%</p>
    <p>!&amp;'()</p>
  </div>
  <div class="page">
    <p>What is an Anytime DNN?</p>
    <p>A</p>
    <p>Traditional DNN</p>
    <p>Anytime DNN Timeline</p>
    <p>Deadline</p>
    <p>Road</p>
    <p>Chocolate Ground Road</p>
    <p>[1] C. Wan et. al. Orthogonalized SGD and Nested Architectures for Anytime Neural Networks . ICML, 2020.</p>
  </div>
  <div class="page">
    <p>How to estimate accuracy under a deadline?</p>
    <p>A  Can inference be finished before deadline?</p>
    <p>If yes, training accuracy of the selected DNN</p>
    <p>If not,  Traditional DNN: random guess accuracy.  Anytime DNN: accuracy of the last output</p>
    <p>Traditional DNNAnytime DNN</p>
    <p>Inference Accuracy</p>
    <p>Time</p>
    <p>!&quot;</p>
    <p>#&quot;</p>
    <p>!&amp;'()</p>
    <p>Time</p>
    <p>!&quot; !* !+</p>
    <p>Inference Accuracy</p>
    <p>#+#*#&quot;</p>
    <p>!&amp;'()</p>
  </div>
  <div class="page">
    <p>How to estimate accuracy under a deadline?</p>
    <p>A AccuracyLatency Relation</p>
    <p>Latency Distribution</p>
    <p>Expectation of Accuracy</p>
  </div>
  <div class="page">
    <p>How to manage energy?</p>
    <p>Power-cap as a knob to configure system resource</p>
    <p>Idle power: other process may still consume energy when DNN inference has finished</p>
    <p>E</p>
    <p>Power</p>
    <p>Time</p>
    <p>DNN active1</p>
    <p>DNN active2</p>
    <p>DNN Idle</p>
    <p>New input Latency Target</p>
  </div>
  <div class="page">
    <p>time</p>
    <p>Power setting  time</p>
    <p>How to estimate the energy consumption?</p>
    <p>Estimate energy from power</p>
    <p>DNN active power is power setting</p>
    <p>DNN idle power is estimated by Kalman filter</p>
    <p>E</p>
    <p>Power</p>
    <p>Time</p>
    <p>DNN active</p>
    <p>DNN Idle</p>
    <p>New input Latency Target</p>
  </div>
  <div class="page">
    <p>Our ALERT System</p>
    <p>A L E R T AL</p>
    <p>E</p>
    <p>DNN &amp; Power Cap Selection</p>
    <p>Measurement</p>
    <p>Feedback-based estimation</p>
    <p>DNN System</p>
    <p>?</p>
    <p>Road</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Understanding DNN Deployment Challenges</p>
    <p>ALERT Run-time Inference Management</p>
    <p>Experiments and Results</p>
  </div>
  <div class="page">
    <p>Experiment Settings</p>
    <p>CPUs, GPU</p>
    <p>Sparse ResNet50, RNN</p>
  </div>
  <div class="page">
    <p>Schemes</p>
    <p>Oracles</p>
    <p>Oracle: Change configuration for every input. Assume perfect knowledge of future. Emulated from profiling result.</p>
    <p>Oracle-static: Same configuration for all inputs.</p>
    <p>Baselines</p>
    <p>Sys-only: Only adjust power-cap  App-only: Use an Anytime DNN  No-coord: Anytime DNN without coordination with power-cap</p>
  </div>
  <div class="page">
    <p>Minimize Energy</p>
    <p>App-only Sys-only No-coord Sys+App(ALERT) Oracle</p>
    <p>Evaluation: Scheduler Performance</p>
    <p>Average performance normalized to Oracle_Static (Smaller is better)</p>
    <p>Violations (%)</p>
  </div>
  <div class="page">
    <p>Minimize Error</p>
    <p>App-only Sys-only No-coord Sys+App(ALERT) Oracle</p>
    <p>Evaluation: Scheduler Performance</p>
    <p>Average performance normalized to Oracle_Static (Smaller is better)</p>
    <p>Violations (%)</p>
  </div>
  <div class="page">
    <p>How ALERT Works with Traditional DNN</p>
    <p>Meet requirements in most cases</p>
    <p>Quickly detect contention changes</p>
    <p>Use anytime DNN under unstable environment</p>
  </div>
  <div class="page">
    <p>How ALERT Works with Traditional DNN</p>
    <p>Meet requirements in most cases</p>
    <p>Quickly detect contention changes</p>
    <p>Use anytime DNN under unstable environment</p>
  </div>
  <div class="page">
    <p>How ALERT Works with Anytime +Traditional DNN</p>
    <p>Meet requirements in most cases</p>
    <p>Quickly detect contention changes</p>
    <p>Use anytime DNN under unstable environment</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Understand DNN inference challenges</p>
    <p>ALERT Run-time inference System</p>
    <p>High performance and energy efficiency</p>
  </div>
</Presentation>
