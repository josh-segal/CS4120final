<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Huaxiu Yao1,2, Ying Wei2, Junzhou Huang1, Zhenhui Li2</p>
    <p>Hierarchical Structured Meta-learning</p>
    <p>Oral: Thu Jun 13th 09:35 -- 09:40 AM @ Room 103 Poster: Thu Jun 13th 06:30 -- 09:00 PM @ Pacific Ballroom #183</p>
  </div>
  <div class="page">
    <p>Gradient-based Meta-learning (MAML [1])</p>
    <p>Is global initialization enough?</p>
    <p>[1] Finn, Chelsea, Pieter Abbeel, and Sergey Levine. &quot;Model-agnostic meta-learning for fast adaptation of deep networks.&quot; Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017. http://people.eecs.berkeley.edu/~cbfinn/_files/metalearning_frontiers_2018_small.pdf</p>
  </div>
  <div class="page">
    <p>Task-specific Meta-learning (MT-Net [2])</p>
    <p>Should the initialization be tailored to each task?</p>
    <p>[2] Lee, Yoonho, and Seungjin Choi. &quot;Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace.&quot; International Conference on Machine Learning. 2018.</p>
  </div>
  <div class="page">
    <p>Human Beings: Knowledge Organization and Reuse</p>
    <p>[3] Gershman, Samuel J., David M. Blei, and Yael Niv. &quot;Context, learning, and extinction.&quot; Psychological review 117.1 (2010): 197. [4] Gershman, Samuel J., et al. &quot;Statistical computations underlying the dynamics of memory updating.&quot; PLoS computational biology 10.11 (2014): e1003939.</p>
    <p>store play</p>
    <p>supermarket</p>
    <p>reading</p>
  </div>
  <div class="page">
    <p>Our Solution: Hierarchically Structured Meta-learning</p>
    <p>Organize tasks by hierarchical clustering  Adapt the global initialization to each cluster of tasks</p>
    <p>Balance between generalization and customization</p>
  </div>
  <div class="page">
    <p>HSML: Optimization</p>
    <p>Incrementally increase the clusters as tasks sequentially arrive.  Criterion for adding a clusterevaluate the average loss over Q epochs</p>
    <p>Overall optimization problem</p>
    <p>Extension to continual adaptation</p>
  </div>
  <div class="page">
    <p>Analysis</p>
    <p>For task , training and testing samples are i.i.d. drawn from  The initialization of HSML (K clusters) can be represented as  According to [5], the assumptions are is -smooth and has a -Lipschitz Hessian,</p>
    <p>step size at the -step satisfying with total steps  The generalization of base learner is bounded by , where</p>
    <p>MAML can be regarded as a special case of HSML, i.e.,  After proving , s.t., , we conclude that HSML achieves a tighter generalization</p>
    <p>bound than MAML</p>
    <p>[5] Kuzborskij, Ilja, and Christoph Lampert. &quot;Data-Dependent Stability of Stochastic Gradient Descent.&quot; International Conference on Machine Learning. 2018.</p>
  </div>
  <div class="page">
    <p>Experiments: Toy Regression</p>
    <p>4 sync family functionsSin, Line, Cubic, Quadratic  K-shot: K samples are used as training (each task)</p>
    <p>Data</p>
    <p>Base model</p>
    <p>2 layers FC with 40 neurons each</p>
  </div>
  <div class="page">
    <p>Experiments: Toy Regression</p>
    <p>Quantitative results</p>
    <p>Method 5-shot 10-shot</p>
    <p>Global shared (MAML)</p>
    <p>Task-specific (MUMOMAML[6])</p>
    <p>Our method (HSML)</p>
    <p>Comparison on regression MSEs  Comparison in the continual adaptation scenario</p>
    <p>[6] Vuorio, Risto, Shao-Hua Sun, Hexiang Hu, and Joseph J. Lim. &quot;Toward Multimodal Model-Agnostic Meta-Learning.&quot; arXiv preprint arXiv:1812.07172 (2018).</p>
  </div>
  <div class="page">
    <p>Experiments: Toy Regression</p>
    <p>Cluster assignment interpretation</p>
    <p>Qualitive results  Regression results</p>
  </div>
  <div class="page">
    <p>Experiments: Few-shot Classification</p>
    <p>4 image classification datasetsBird, Texture, Aircraft, Fungi  5-way, 1-shot</p>
    <p>Data</p>
    <p>Base model</p>
    <p>a convolutional network with 4 convolution blocks</p>
  </div>
  <div class="page">
    <p>Experiments: Few-shot Classification</p>
    <p>Quantitative results  Comparison on accuracy  Comparison in the continual</p>
    <p>adaptation scenario</p>
    <p>Method Bird Textu re</p>
    <p>Aircr aft</p>
    <p>Fungi</p>
    <p>Global shared (MAML)</p>
    <p>Task-specific ( MUMOMAML[6</p>
    <p>])</p>
    <p>Our method (HSML)</p>
    <p>[6] Vuorio, Risto, Shao-Hua Sun, Hexiang Hu, and Joseph J. Lim. &quot;Toward Multimodal Model-Agnostic Meta-Learning.&quot; arXiv preprint arXiv:1812.07172 (2018).</p>
  </div>
  <div class="page">
    <p>Experiments: Few-shot Classification</p>
    <p>Cluster assignment interpretation</p>
    <p>Qualitive results</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>HSML simultaneously customizes task knowledge and preserves knowledge generalization via the hierarchical clustering structure.</p>
    <p>Experiments demonstrate the effectiveness and interpretability of HSML in both toy regression and few-shot classification problems.</p>
  </div>
  <div class="page">
    <p>THANK YOU Oral: Thu Jun 13th 09:35 -- 09:40 AM @ Room 103 Poster: Thu Jun 13th 06:30 -- 09:00 PM @ Pacific Ballroom #183</p>
  </div>
</Presentation>
