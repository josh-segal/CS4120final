<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Diagnosing performance changes by comparing request flows!</p>
    <p>Raja Sambasivan! Alice Zheng, Michael De Rosa, Elie Krevat,</p>
    <p>Spencer Whitman, Michael Stroucken, William Wang, Lianghong Xu, Greg Ganger!</p>
    <p>!</p>
    <p>Carnegie Mellon! Microsoft Research! Google !</p>
  </div>
  <div class="page">
    <p>Perf. diagnosis in distributed systems!  Very difficult and time consuming!</p>
    <p>Root cause could be in any component! !</p>
    <p>Request-flow comparison!  Helps localize performance changes!  Key insight: Changes manifest as</p>
    <p>mutations in request timing/structure! !</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 2</p>
  </div>
  <div class="page">
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 3</p>
    <p>Perf. debugging a feature addition!</p>
    <p>Client Clients Client Client!</p>
    <p>Servers</p>
    <p>Storage nodes!</p>
    <p>NFS server!</p>
    <p>Servers Metadata!</p>
    <p>server!</p>
  </div>
  <div class="page">
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 4</p>
    <p>Perf. debugging a feature addition!  Before addition:!</p>
    <p>Every file access needs a MDS access!</p>
    <p>Client!</p>
    <p>Storage nodes!</p>
    <p>NFS server!</p>
    <p>Metadata! server!</p>
    <p>(1)! (2)!</p>
    <p>(3)! (4)!</p>
    <p>(5)!</p>
    <p>(6)!</p>
  </div>
  <div class="page">
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 5</p>
    <p>Perf. debugging a feature addition!  After: Metadata prefetched to clients !</p>
    <p>Most requests dont need MDS access!</p>
    <p>Client!</p>
    <p>Storage nodes!</p>
    <p>NFS server!</p>
    <p>Metadata! server!</p>
    <p>(1)!</p>
    <p>(2)</p>
    <p>(3)!</p>
  </div>
  <div class="page">
    <p>Perf. debugging a feature addition!  Adding metadata prefetching reduced</p>
    <p>performance instead of improving it (!)!</p>
    <p>How to efficiently diagnose this?!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 6</p>
  </div>
  <div class="page">
    <p>Request-flow comparison will show!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 7</p>
    <p>Precursor!</p>
    <p>NFS Lookup Call!</p>
    <p>MDS DB Lock</p>
    <p>MDS DB Unlock!</p>
    <p>NFS Lookup Reply!</p>
    <p>Mutation! NFS Lookup Call!</p>
    <p>MDS DB Lock!</p>
    <p>MDS DB Unlock!</p>
    <p>NFS Lookup Reply!</p>
  </div>
  <div class="page">
    <p>Request-flow comparison will show!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 8</p>
    <p>Precursor!</p>
    <p>NFS Lookup Call!</p>
    <p>MDS DB Lock</p>
    <p>MDS DB Unlock!</p>
    <p>NFS Lookup Reply!</p>
    <p>Mutation! NFS Lookup Call!</p>
    <p>MDS DB Lock!</p>
    <p>MDS DB Unlock!</p>
    <p>NFS Lookup Reply!</p>
    <p>Root cause localized by showing how mutation and precursor differ!</p>
  </div>
  <div class="page">
    <p>Request-flow comparison!  Identifies distribution changes!</p>
    <p>Distinct from anomaly detection!  E.g., Magpie, Pinpoint, etc.!</p>
    <p>Satisfies many use cases!  Performance regressions/degradations!  Eliminating the system as the culprit!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 9</p>
  </div>
  <div class="page">
    <p>Contributions!  Heuristics for identifying mutations,</p>
    <p>precursors, and for ranking them!  Implementation in Spectroscope!</p>
    <p>Use of Spectroscope to diagnose!  Unsolved problems in Ursa Minor!  Problems in Google services !</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 10</p>
  </div>
  <div class="page">
    <p>Spectroscope workflow!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 11</p>
    <p>Non-problem period graphs!</p>
    <p>Problem period graphs!</p>
    <p>Categorization!</p>
    <p>Response-time mutation identification!</p>
    <p>Structural mutation identification!</p>
    <p>UI layer!</p>
    <p>Ranking!</p>
  </div>
  <div class="page">
    <p>Graphs via end-to-end tracing!  Used in research &amp; production systems!</p>
    <p>E.g., Magpie, X-Trace, Googles Dapper!</p>
    <p>Works as follows:!  Tracks trace points touched by requests!  Request-flow graphs obtained by</p>
    <p>stitching together trace points accessed!</p>
    <p>Yields &lt; 1% overhead w/req. sampling ! Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 12</p>
  </div>
  <div class="page">
    <p>SN1 Reply!</p>
    <p>Reply!</p>
    <p>Example: Graph for a striped read!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 13</p>
    <p>NFS Read Call!</p>
    <p>Cache Miss!</p>
    <p>SN1 Read Call!</p>
    <p>SN2 Read Call!</p>
    <p>NFS Reply!10s! 10s!</p>
    <p>Response-time:! 8,120s!</p>
    <p>Work on SN1!</p>
    <p>Work on SN2!</p>
  </div>
  <div class="page">
    <p>SN1 Reply!</p>
    <p>Reply!</p>
    <p>Example: Graph for a striped read!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 14</p>
    <p>NFS Read Call!</p>
    <p>Cache Miss!</p>
    <p>SN1 Read Call!</p>
    <p>SN2 Read Call!</p>
    <p>NFS Reply!10s! 10s!</p>
    <p>Response-time:! 8,120s!</p>
    <p>Work on SN1!</p>
    <p>Work on SN2!</p>
    <p>Nodes show trace points &amp; edges show latencies</p>
  </div>
  <div class="page">
    <p>Spectroscope workflow!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 15</p>
    <p>Non-problem period graphs</p>
    <p>Problem period graphs</p>
    <p>Categorization</p>
    <p>Response-time mutation identification</p>
    <p>Structural mutation identification</p>
    <p>Ranking</p>
    <p>UI layer</p>
  </div>
  <div class="page">
    <p>Categorization step!  Necessary since it is meaningless to</p>
    <p>compare individual requests flows!</p>
    <p>Groups together similar request flows!  Categories: basic unit for comparisons!  Allows for mutation identification by</p>
    <p>comparing per-category distributions !</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 16</p>
  </div>
  <div class="page">
    <p>Choosing what to bin into a category!  Our choice: identically structured reqs!</p>
    <p>Uses same path/similar cost expectation!</p>
    <p>Same path/similar costs notion is valid!  For 8899% of Ursa Minor categories!  For 4769% of Bigtable categories!</p>
    <p>Lower value due to sparser trace points!  Lower value also due to contention !</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 17</p>
    <p>Aside: Categorization can be used to localize problematic sources of variance!</p>
  </div>
  <div class="page">
    <p>Spectroscope workflow!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 18</p>
    <p>Non-problem period graphs!</p>
    <p>Problem period graphs!</p>
    <p>Categorization!</p>
    <p>Response-time mutation identification!</p>
    <p>Structural mutation identification!</p>
    <p>Ranking!</p>
    <p>UI layer!</p>
  </div>
  <div class="page">
    <p>Type 1: Response-time mutations!  Requests that:!</p>
    <p>are structurally identical in both periods!  have larger problem period latencies!</p>
    <p>Root cause localized by !  identifying interactions responsible !</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 19</p>
  </div>
  <div class="page">
    <p>Categories w/response-time mutations!</p>
    <p>Identified via use of a hypothesis test!  Sets apart natural variance from mutations!  Also used to find interactions responsible!</p>
    <p>!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 20</p>
    <p>Category 1</p>
    <p>Response-time</p>
    <p>Fr eq</p>
    <p>ue nc</p>
    <p>y</p>
    <p>Category 2!</p>
    <p>Fr eq</p>
    <p>ue nc</p>
    <p>y</p>
    <p>Response-time</p>
  </div>
  <div class="page">
    <p>Categories w/response-time mutations!</p>
    <p>Identified via use of a hypothesis test!  Sets apart natural variance from mutations!  Also used to find interactions responsible!</p>
    <p>!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 21</p>
    <p>Category 1</p>
    <p>Response-time</p>
    <p>Fr eq</p>
    <p>ue nc</p>
    <p>y</p>
    <p>Category 2!</p>
    <p>Fr eq</p>
    <p>ue nc</p>
    <p>y</p>
    <p>Response-time IDd as containing mutations!</p>
    <p>Not IDd as containing mutations!</p>
  </div>
  <div class="page">
    <p>Response-time mutation example!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 22</p>
    <p>Avg. problem response time:!</p>
    <p>Avg. non-problem response time:! 110s!</p>
    <p>Avg. 10s! !</p>
    <p>Avg. 20s! Avg. 1,000s ! !</p>
    <p>Avg. 80s! !</p>
    <p>NFS Read Call!</p>
    <p>SN1 Read Start</p>
    <p>SN1 Read End!</p>
    <p>NFS Read Reply!</p>
  </div>
  <div class="page">
    <p>Response-time mutation example!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 23</p>
    <p>Avg. problem response time:!</p>
    <p>Avg. non-problem response time:! 110s!</p>
    <p>Avg. 10s! !</p>
    <p>Avg. 20s! Avg. 1,000s ! !</p>
    <p>Avg. 80s! !</p>
    <p>NFS Read Call!</p>
    <p>SN1 Read Start</p>
    <p>SN1 Read End!</p>
    <p>NFS Read Reply!Problem localized by IDing responsible interaction</p>
  </div>
  <div class="page">
    <p>Type 2: Structural mutations!  Requests that:!</p>
    <p>take different paths in the problem period!</p>
    <p>Root caused localized by!  identifying their precursors!</p>
    <p>Likely path during the non-problem period!  iding how mutation &amp; precursor differ!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 24</p>
  </div>
  <div class="page">
    <p>IDing categories w/structural mutations!  Assume similar workloads executed!</p>
    <p>Categories with more problem period requests contain mutations!</p>
    <p>Reverse true for precursor categories!</p>
    <p>Threshold used to differentiate natural variance from categories w/mutations!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 25</p>
  </div>
  <div class="page">
    <p>Mapping mutations to precursors!</p>
    <p>Accomplished using three heuristics!  See paper for details! ! !</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 26</p>
    <p>NP: 300! P: 800!</p>
    <p>Structural Mutation!</p>
    <p>Read!</p>
    <p>?</p>
    <p>Precursors! Read!</p>
    <p>NP: 1,000! P: 150! NP: 480!P: 460!</p>
    <p>Write!</p>
  </div>
  <div class="page">
    <p>Example structural mutation!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 27</p>
    <p>Precursor!</p>
    <p>NFS Lookup Call!</p>
    <p>MDS DB Lock</p>
    <p>MDS DB Unlock!</p>
    <p>NFS Lookup Reply!</p>
    <p>Mutation! NFS Lookup Call!</p>
    <p>MDS DB Lock!</p>
    <p>MDS DB Unlock!</p>
    <p>NFS Lookup Reply!</p>
  </div>
  <div class="page">
    <p>Example structural mutation!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 28</p>
    <p>Precursor!</p>
    <p>NFS Lookup Call!</p>
    <p>MDS DB Lock</p>
    <p>MDS DB Unlock!</p>
    <p>NFS Lookup Reply!</p>
    <p>Mutation! NFS Lookup Call!</p>
    <p>MDS DB Lock!</p>
    <p>MDS DB Unlock!</p>
    <p>NFS Lookup Reply!</p>
    <p>Root cause localized by showing how mutation and precursor differ!</p>
  </div>
  <div class="page">
    <p>Ranking of categories w/mutations!  Necessary for two reasons!</p>
    <p>There may be more than one problem!  One problem may yield many mutations!</p>
    <p>Rank based on:!  # of reqs affected *  in response time!</p>
    <p>!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 29</p>
  </div>
  <div class="page">
    <p>Spectroscope workflow!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 30</p>
    <p>Non-problem period graphs!</p>
    <p>Problem period graphs!</p>
    <p>Categorization!</p>
    <p>Response-time mutation identification!</p>
    <p>Structural mutation identification!</p>
    <p>Ranking!</p>
    <p>UI layer!</p>
  </div>
  <div class="page">
    <p>Putting it all together: The UI!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 31</p>
    <p>Ranked list !</p>
    <p>!1. Structural! 2. Response ! time!</p>
    <p>Precursor!</p>
    <p>NFS Lookup Call!</p>
    <p>MDS DB Lock</p>
    <p>MDS DB Unlock!</p>
    <p>NFS Lookup Reply!</p>
    <p>Mutation! NFS Lookup Call!</p>
    <p>MDS DB Lock!</p>
    <p>MDS DB Unlock!</p>
    <p>NFS Lookup Reply!</p>
  </div>
  <div class="page">
    <p>Putting it all together: The UI!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 32</p>
    <p>Ranked list !</p>
    <p>!1. Structural! 2. Response ! time!</p>
    <p>Mutation!</p>
    <p>Avg. 10s! ! Avg. 20s! Avg. 100s ! ! Avg. 80s! !</p>
    <p>NFS Read Call!</p>
    <p>SN1 Read Start</p>
    <p>SN1 Read End!</p>
    <p>NFS Read Reply!</p>
  </div>
  <div class="page">
    <p>Outline!  Introduction!  End-to-end tracing &amp; Spectroscope!  Ursa Minor &amp; Google case studies!  Summary!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 33</p>
  </div>
  <div class="page">
    <p>Ursa Minor case studies!  Used Spectroscope to diagnose real</p>
    <p>performance problems in Ursa Minor!  Four were previously unsolved!</p>
    <p>Evaluated ranked list by measuring!  % of top 10 results that were relevant!  % of total results that were relevant!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 34</p>
  </div>
  <div class="page">
    <p>Prefetch Config. RMWs Creates 500us delay</p>
    <p>Spikes</p>
    <p>% total ! relevant!</p>
    <p>Quantitative results!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 35</p>
    <p>N/A</p>
    <p>% top 10 relevant</p>
  </div>
  <div class="page">
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 36</p>
    <p>Ursa Minor 5-component config!</p>
    <p>Client!</p>
    <p>Storage nodes!</p>
    <p>NFS server!</p>
    <p>Metadata! server!</p>
    <p>(1)! (2)!</p>
    <p>(3)! (4)!</p>
    <p>(5)</p>
    <p>(6)!</p>
    <p>All case studies use this configuration!</p>
  </div>
  <div class="page">
    <p>Case 1: MDS configuration problem!  Problem: Slowdown in key benchmarks</p>
    <p>seen after large code merge!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 37</p>
  </div>
  <div class="page">
    <p>Comparing request flows!  Identified 128 mutation categories:!</p>
    <p>Most contained structural mutations!  Mutations and precursors differed only</p>
    <p>in the storage node accessed!</p>
    <p>Localized bug to unexpected interaction between MDS &amp; the data storage node!  But, unclear why this was happening!</p>
    <p>!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 38</p>
  </div>
  <div class="page">
    <p>Further localization!  Thought mutations may be caused by</p>
    <p>changes in low-level parameters!  E.g., function call parameters, etc.!</p>
    <p>Identified parameters that separated 1stranked mutation from its precursors!  Showed changes in encoding params!  Localized root cause to two config files !</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 39</p>
    <p>Root cause: Change to an obscure config file</p>
  </div>
  <div class="page">
    <p>Inter-cluster perf. at Google !  Load tests run on same software in two</p>
    <p>datacenters yielded very different perf.!  Developers said perf. should be similar!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 40</p>
  </div>
  <div class="page">
    <p>Comparing request flows!  Revealed many mutations!</p>
    <p>High-ranked ones were response-time!</p>
    <p>Responsible interactions found both within the service and in dependencies!  Led us to suspect root cause was issue</p>
    <p>with the slower load tests datacenter !</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 41</p>
    <p>Root cause: Shared Bigtable in slower load tests datacenter was not working properly</p>
  </div>
  <div class="page">
    <p>Summary!  Introduced request-flow comparison as</p>
    <p>a new way to diagnose perf. changes!</p>
    <p>Presented algorithms for localizing problems by identifying mutations!</p>
    <p>Showed utility of our approach by using it to diagnose real, unsolved problems!</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 42</p>
  </div>
  <div class="page">
    <p>Related work (I)! [Abd-El-Malek05b]: Ursa Minor: versatile cluster-based storage.</p>
    <p>Michael Abd-El-Malek, William V. Courtright II, Chuck Cranor, Gregory R. Ganger, James Hendricks, Andrew J. Klosterman, Michael Mesnier, Manish Prasad, Brandon Salmon, Raja R. Sambasivan, Shafeeq Sinnamohideen, John D. Strunk, Eno Thereska, Matthew Wachs, Jay J. Wylie. FAST, 2005.!</p>
    <p>! [Barham04]: Using Magpie for request extraction and workload</p>
    <p>modelling. Paul Barham, Austin Donnelly, Rebecca Isaacs, Richard Mortier. OSDI, 2004.!</p>
    <p>! [Chen04]: Path-based failure and evolution management. Mike</p>
    <p>Y. Chen, Anthony Accardi, Emre Kiciman, Jim Lloyd, Dave Patterson, Armando Fox, Eric Brewer. NSDI, 2004.!</p>
    <p>! ! ! !</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 43</p>
  </div>
  <div class="page">
    <p>Related work (II)! [Cohen05]: Capturing, indexing, and retrieving system history.</p>
    <p>Ira Cohen, Steve Zhang, Moises Goldszmidt, Terrence Kelly, Armando Fox. SOSP, 2005.!</p>
    <p>! [Fonseca07]: X-Trace: A Pervasive Network Tracing</p>
    <p>Framework. Rodrigo Fonseca, George Porter, Randy H. Katz, Scott Shenker, Ion Stoica. NSDI, 2007.!</p>
    <p>! [Hendricks06]: Improving small file performance in object</p>
    <p>based storage. James Hendricks, Raja R. Sambasivan, Shafeeq Sinnamohideen, Gregory R. Ganger. Technical Report CMU-PDL-06-104, 2006.!</p>
    <p>! ! ! ! !</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 44</p>
  </div>
  <div class="page">
    <p>Related work (III)! [Reynolds06]: Detecting the unexpected in distributed systems.</p>
    <p>Patrick Reynolds, Charles Killian, Janet L. Wiener, Jeffrey C. Mogul, Mehul A. Shah, Amin Vahdat. NSDI, 2006.!</p>
    <p>! [Sambasivan07]: Categorizing and differencing system</p>
    <p>behaviours. Raja R. Sambasivan, Alice X. Zheng, Eno Thereska. HotAC II, 2007.!</p>
    <p>! [Sambasivan10]: Diagnosing performance problems by</p>
    <p>visualizing and comparing system behaviours. Raja R. Sambasivan, Alice X. Zheng, Elie Krevat, Spencer Whitman, Michael Stroucken, William Wang, Lianghong Xu, Gregory R. Ganger. CMU-PDL-10-103. !</p>
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 45</p>
  </div>
  <div class="page">
    <p>Raja Sambasivan  March 11!http://www.pdl.cmu.edu/ 46</p>
    <p>Related work (IV)! [Sambasivan11]: Automation without predictability is a recipe</p>
    <p>for failure. Raja R. Sambasivan and Gregory R. Ganger. Technical Report CMU-PDL-11-101, 2011.!</p>
    <p>! [Sigelman10]: Dapper, a large-scale distributed tracing</p>
    <p>infrastructure. Benjamin H. Sigelman, Luiz Andre  Barroso, Mike Burrows, Pat Stephenson, Manoj Plakal, Donald Beaver, Saul Jaspan, Chandan Shanbhag. Technical report 2010-1, 2008.!</p>
    <p>! [Thereska06b]: Stardust: tracking activity in a distributed</p>
    <p>storage system. Eno Thereska, Brandon Salmon, John Strunk, Matthew Wachs, Michael Abd-El-Malek, Julio Lopez, Gregory R. Ganger. SIGMETRICS, 2006.!</p>
    <p>! !</p>
  </div>
</Presentation>
