<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Application-Managed Flash</p>
    <p>Sungjin Lee, Ming Liu, Sangwoo Jun, Shuotao Xu, Jihong Kim and Arvind</p>
    <p>Massachusetts Institute of Technology Seoul National University</p>
    <p>February 22-25, 2016</p>
  </div>
  <div class="page">
    <p>NAND Flash and FTL</p>
    <p>NAND flash SSDs have become the preferred storage devices in consumer electronics and datacenters</p>
    <p>FTL plays an important role in flash management  The principal virtue of FTL is providing interoperability with the ex</p>
    <p>isting block I/O abstraction</p>
    <p>NAND Flash</p>
    <p>Databases File-systems KV Store</p>
    <p>Flash Device</p>
    <p>Host System</p>
    <p>Block I/O Layer</p>
    <p>Overwriting restriction</p>
    <p>Limited P/E cycles</p>
    <p>Bad blocks Asymmetric I/O</p>
    <p>operation Flash Translation Layer (FTL)</p>
  </div>
  <div class="page">
    <p>FTL is a Complex Piece of Software</p>
    <p>Requires significant hardware resources (e.g., 4 CPUs / 1-4 GB DRAM)  Incurs extra I/Os for flash management (e.g., GC)  Badly affects the behaviors of host applications</p>
    <p>FTL runs complicated firmware algorithms to avoid in-place updates and manage unreliable NAND substrates</p>
    <p>Flash Translation Layer (FTL)</p>
    <p>NAND Flash</p>
    <p>Databases File-systems KV Store</p>
    <p>Address Remapping</p>
    <p>Garbage Collection</p>
    <p>I/O Scheduling</p>
    <p>Wear-leveling &amp; Bad-block</p>
    <p>Flash Device</p>
    <p>Host System</p>
    <p>Block I/O Layer</p>
  </div>
  <div class="page">
    <p>Databases File-systems KV Store</p>
    <p>..But, Its Functionality is Mostly Useless</p>
    <p>Many host applications manage underlying storage in a log-like manner, mostly avoiding in-place updates</p>
    <p>NAND Flash</p>
    <p>Log-structured Host Applications</p>
    <p>Block I/O Layer</p>
    <p>Flash Device</p>
    <p>Host System Object-to-storage</p>
    <p>Remapping Versioning &amp;</p>
    <p>Cleaning I/O Scheduling</p>
    <p>Flash Translation Layer (FTL)</p>
    <p>Address Remapping</p>
    <p>Garbage Collection</p>
    <p>I/O Scheduling</p>
    <p>Wear-leveling &amp; Bad-block</p>
    <p>This duplicate management not only (1) incurs serious performance penalties but also (2) wastes hardware resources</p>
    <p>Address Remapping</p>
    <p>Garbage Collection</p>
    <p>I/O Scheduling</p>
    <p>Wear-leveling &amp; Bad-block</p>
    <p>Flash Translation Layer (FTL)</p>
    <p>Duplicate Management</p>
  </div>
  <div class="page">
    <p>Which Applications???</p>
    <p>F2FS</p>
    <p>WAFL</p>
    <p>Btrfs NILFS</p>
    <p>RethinkDBLevelDB RocksDB</p>
    <p>FlexVol</p>
    <p>BlueSky</p>
    <p>LogBase</p>
    <p>Hyder</p>
    <p>SpriteLFS</p>
    <p>BigTable</p>
    <p>MongoDB</p>
    <p>Cassandra</p>
    <p>HDFS</p>
    <p>Which Applications</p>
    <p>???LSM-Tree</p>
    <p>File Systems</p>
    <p>Key-value Stores Databases</p>
    <p>Storage Virtualization</p>
  </div>
  <div class="page">
    <p>Question:</p>
    <p>What if we removed FTL from storage devices and allowed host applications to directly manage NAND flash?</p>
  </div>
  <div class="page">
    <p>Application-Managed Flash (AMF)</p>
    <p>Host Applications (Log-structured)</p>
    <p>Block I/O Layer</p>
    <p>Flash Device</p>
    <p>Host System Object-to-storage</p>
    <p>Remapping Versioning &amp;</p>
    <p>Cleaning I/O Scheduling</p>
    <p>NAND Flash</p>
    <p>Flash Translation Layer (FTL)</p>
    <p>Address Remapping</p>
    <p>Garbage Collection</p>
    <p>I/O Scheduling</p>
    <p>Wear-leveling &amp; Bad-block</p>
    <p>NAND Flash</p>
    <p>Light-weight Flash Translation Layer</p>
    <p>(2) The host runs almost all of the complicated algorithms - Reuse existing algorithms to manage storage devices</p>
    <p>(1) The device runs essential device management algorithms - Manages unreliable NAND flash and hides internal storage architectures</p>
    <p>AMF Block I/O Layer (AMF I/O)</p>
    <p>(3) A new AMF block I/O abstraction enables us to separate the roles of the host and the device</p>
    <p>Log-structured Host Applications</p>
    <p>Object-to-storage Remapping</p>
    <p>Versioning &amp; Cleaning</p>
    <p>I/O Scheduling</p>
  </div>
  <div class="page">
    <p>AMF Block I/O Abstraction (AMF I/O)</p>
    <p>AMF I/O is similar to a conventional block I/O interface  A linear array of fixed-size sectors (e.g., 4 KB) with existing</p>
    <p>I/O primitives (e.g., READ and WRITE)</p>
    <p>Host Applications</p>
    <p>A logical layout exposed to applications Sector (4KB) READ and WRITE</p>
    <p>AMF Block I/O LayerHost System</p>
    <p>Flash Device</p>
    <p>Minimize changes in existing host applications</p>
  </div>
  <div class="page">
    <p>Append-only Segment</p>
    <p>Segment: a group of 4 KB sectors (e.g., several MB)  A unit of free-space allocation and free-space reclamation</p>
    <p>Append-only: overwrite of data is prohibited</p>
    <p>Host Applications</p>
    <p>Host System AMF Block I/O Layer</p>
    <p>Flash Device  Segment (MB)</p>
    <p>Appending new data (WRITE)Overwrite TRIMAppending</p>
    <p>Only sequential writes with no in-place updates  Minimize the functionality of the FTL</p>
  </div>
  <div class="page">
    <p>Case Study with AMF</p>
    <p>F2FS</p>
    <p>WAFL</p>
    <p>Btrfs NILFS</p>
    <p>RethinkDBLevelDB RocksDB</p>
    <p>FlexVol</p>
    <p>BlueSky</p>
    <p>LogBase</p>
    <p>Hyder</p>
    <p>SpriteLFS</p>
    <p>BigTable</p>
    <p>MongoDB</p>
    <p>Cassandra</p>
    <p>HDFS</p>
    <p>LSM-Tree</p>
    <p>File Systems</p>
    <p>Key-value Stores Databases</p>
    <p>Storage Virtualization</p>
    <p>Which Applications</p>
    <p>???</p>
  </div>
  <div class="page">
    <p>Case Study with File System</p>
    <p>Host Applications (Log-structured)</p>
    <p>AMF Block I/O Layer</p>
    <p>Object-to-storage Remapping</p>
    <p>Versioning &amp; Cleaning</p>
    <p>I/O Scheduling</p>
    <p>NAND Flash</p>
    <p>AMF Log-structured File System (ALFS)</p>
    <p>(based on F2FS)</p>
    <p>Host System</p>
    <p>Flash Device AMF Flash Translation Layer (AFTL) Segment-level Address</p>
    <p>Remapping Wear-leveling &amp;</p>
    <p>Bad-block</p>
  </div>
  <div class="page">
    <p>ALFS F2FS</p>
    <p>&lt;A comparison of source-code lines of F2FS and ALFS&gt;</p>
    <p>AMF Log-structured File System (ALFS)</p>
    <p>ALFS is based on the F2FS file system  How did we modify F2FS for ALFS?</p>
    <p>Eliminate in-place updates  F2FS overwrites check-points and inode-map blocks</p>
    <p>Change the TRIM policy  TRIM is issued to individual sectors</p>
    <p>How many new codes were added?</p>
  </div>
  <div class="page">
    <p>How Conventional LFS (F2FS) Works</p>
    <p>LFS</p>
    <p>PFTL</p>
    <p>Check-Point Segment</p>
    <p>Inode-Map Segment</p>
    <p>Data Segment 0</p>
    <p>Data Segment 1</p>
    <p>Data Segment 2Segment</p>
    <p>Block with 2 pages</p>
    <p>* PFTL: page-level FTL</p>
  </div>
  <div class="page">
    <p>How Conventional LFS (F2FS) Works</p>
    <p>LFS CP</p>
    <p>Check-Point Segment</p>
    <p>Inode-Map Segment</p>
    <p>CP</p>
    <p>Data Segment 0</p>
    <p>Data Segment 1</p>
    <p>Data Segment 2</p>
    <p>IM #0</p>
    <p>A B C D E B F GCP IM #0</p>
    <p>B</p>
    <p>Invalid</p>
    <p>Check-point and inode-map blocks are overwritten</p>
    <p>CP</p>
    <p>PFTL</p>
    <p>* PFTL: page-level FTL</p>
  </div>
  <div class="page">
    <p>How Conventional LFS (F2FS) Works</p>
    <p>LFS CP</p>
    <p>Check-Point Segment</p>
    <p>Inode-Map Segment</p>
    <p>CP</p>
    <p>Data Segment 0</p>
    <p>Data Segment 1</p>
    <p>Data Segment 2</p>
    <p>IM #0</p>
    <p>A B C D E B F GCP IM #0</p>
    <p>B</p>
    <p>IM #0</p>
    <p>A B C D E F GBCP CP CP IM #0</p>
    <p>The FTL appends incoming data to NAND flash</p>
    <p>PFTL</p>
    <p>* PFTL: page-level FTL</p>
  </div>
  <div class="page">
    <p>How Conventional LFS (F2FS) Works</p>
    <p>LFS CP</p>
    <p>Check-Point Segment</p>
    <p>Inode-Map Segment</p>
    <p>CP</p>
    <p>Data Segment 0</p>
    <p>Data Segment 1</p>
    <p>Data Segment 2</p>
    <p>IM #0</p>
    <p>A B C D E B F GCP IM #0</p>
    <p>B</p>
    <p>IM #0</p>
    <p>A B C D E F GBCP CP CP IM #0</p>
    <p>A C D E</p>
    <p>The FTL triggers garbage collection</p>
    <p>A C D E</p>
    <p>: 4 page copies and 4 block erasures</p>
    <p>PFTL</p>
    <p>* PFTL: page-level FTL</p>
  </div>
  <div class="page">
    <p>How Conventional LFS (F2FS) Works</p>
    <p>LFS CP</p>
    <p>Check-Point Segment</p>
    <p>Inode-Map Segment</p>
    <p>CP</p>
    <p>Data Segment 0</p>
    <p>Data Segment 1</p>
    <p>Data Segment 2</p>
    <p>IM #0</p>
    <p>A B C D E B F GCP IM #0</p>
    <p>B</p>
    <p>IM #0</p>
    <p>A B C D E F GBCP CP CP IM #0</p>
    <p>A C D EA C D E</p>
    <p>The LFS triggers garbage collection</p>
    <p>A C DA C D</p>
    <p>A C DDA C</p>
    <p>TRIM</p>
    <p>: 3 page copies</p>
    <p>PFTL</p>
    <p>* PFTL: page-level FTL</p>
  </div>
  <div class="page">
    <p>How ALFS Works</p>
    <p>ALFS</p>
    <p>AFTL</p>
    <p>Check-Point Segment</p>
    <p>Inode-Map Segment</p>
    <p>Data Segment 0</p>
    <p>Data Segment 1</p>
    <p>Data Segment 2Segment</p>
    <p>Segment with 2 flash blocks</p>
  </div>
  <div class="page">
    <p>How ALFS Works</p>
    <p>ALFS</p>
    <p>AFTL</p>
    <p>Check-Point Segment</p>
    <p>Inode-Map Segment</p>
    <p>Data Segment 0</p>
    <p>Data Segment 1</p>
    <p>Data Segment 2</p>
    <p>A B C D E B F GCP IM #0</p>
    <p>CP IM #0</p>
    <p>BCPCP IM #0</p>
    <p>CP</p>
    <p>CP A B C D IM #0</p>
    <p>CP E B F G IM #0</p>
    <p>CP</p>
    <p>No in-place updates</p>
    <p>No obsolete pages  GC is not necessary</p>
  </div>
  <div class="page">
    <p>How ALFS Works</p>
    <p>ALFS</p>
    <p>AFTL</p>
    <p>Check-Point Segment</p>
    <p>Inode-Map Segment</p>
    <p>CP IM #0</p>
    <p>CP IM #0</p>
    <p>CPCP IM #0</p>
    <p>CP</p>
    <p>CP A B C D IM #0</p>
    <p>CP E B F G IM #0</p>
    <p>CP</p>
    <p>Data Segment 0</p>
    <p>Data Segment 1</p>
    <p>Data Segment 2</p>
    <p>A B C D E B F GB A C DA C D</p>
    <p>A B C D</p>
    <p>TRIM</p>
    <p>A C D</p>
    <p>The ALFS triggers garbage collection : 3 page copies and 2 block erasures</p>
  </div>
  <div class="page">
    <p>Comparison of F2FS and AMF</p>
    <p>F2FS AMF</p>
    <p>File System PFTL File System</p>
    <p>Duplicate Management</p>
  </div>
  <div class="page">
    <p>Experimental Setup</p>
    <p>Implemented ALFS and AFTL in the Linux kernel 3.13</p>
    <p>Compared AMF with different file-systems  Two file-systems: EXT4 and F2FS with page-level FTL (PFTL)</p>
    <p>Ran all of them in our in-house SSD platform  BlueDBM developed by MIT</p>
  </div>
  <div class="page">
    <p>Performance with FIO</p>
    <p>For random writes, AMF shows better throughput  F2FS is badly affected by the duplicate management problem</p>
  </div>
  <div class="page">
    <p>Performance with Databases</p>
    <p>AMF outperforms EXT4 with more advanced GC policies  F2FS shows the worst performance</p>
  </div>
  <div class="page">
    <p>Erasure Counts</p>
    <p>AMF achieves 6% and 37% better lifetimes than EXT4 and F2FS, respectively, on average</p>
  </div>
  <div class="page">
    <p>Resource (DRAM &amp; CPU)</p>
    <p>FTL mapping table size</p>
    <p>Host CPU usage</p>
    <p>SSD Capacity Block-level FTL Hybrid FTL Page-level FTL AMF</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>We proposed the Application-Managed Flash (AMF) architecture.  AMF was based on a new block I/O interface, called AMF IO, which ex</p>
    <p>posed flash storage as append-only segments  Based on AMF IO, we implemented a new FTL scheme (AFTL) and a new</p>
    <p>file system (ALFS) in the Linux kernel and evaluated them using our inhouse SSD prototype</p>
    <p>Our results showed that DRAM in the flash controller was reduced by 128X and performance was improved by 80%</p>
    <p>Future Work  We are doing case studies with key-value stores, database systems, and</p>
    <p>storage virtualization platforms</p>
  </div>
  <div class="page">
    <p>Source Code</p>
    <p>All of the software/hardware is being developed under the GPL license</p>
    <p>Please refer to our Git repositories  Hardware Platform:</p>
    <p>https://github.com/sangwoojun/bluedbm.git  FTL: https://github.com/chamdoo/bdbm_drv.git  File-System: https://bitbucket.org/chamdoo/risa-f2fs</p>
    <p>Thank you!</p>
  </div>
</Presentation>
