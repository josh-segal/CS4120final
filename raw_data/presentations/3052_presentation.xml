<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Sharing, Protection, and Compatibility for Reconfigurable Fabric with AmorphOS</p>
    <p>A H M E D K H AWA J A 1 , J O S H U A L A N D G R A F 1 , R O H I T H P R A K A S H 1 M I C H A E L W E I 2 , E R I C S C H K U F Z A 2 , C H R I S T O P H E R J . R O S S B A C H 1 , 2</p>
  </div>
  <div class="page">
    <p>Motivation Bigger, faster FPGAs deployed in the cloud</p>
    <p>Microsoft Catapult/Azure  Amazon F1</p>
    <p>FPGAs: Reconfigurable Accelerators  ASIC Prototyping, Video &amp; Image Proc., DNN, Blockchain  Potential solution to accelerator provisioning challenge</p>
    <p>Our position: FPGAs will be shared  Sharing requires protection  Abstraction layers provide compatibility  Beneficiary: provider  consolidation</p>
  </div>
  <div class="page">
    <p>FPGA Background Field Programmable Gate Array (FPGA)  Reconfigurable interconnect  custom data paths  FPGAs attached as coprocessors to a CPU</p>
    <p>FPGA Build Cycle  Synthesis: HDL  Netlist (~seconds)  Place and Route: Netlist  Bitstream (~min--hours)  Reconfiguration/Partial Reconfiguration (PR)</p>
    <p>Production systems: No multi-tenancy</p>
    <p>Emerging/Research Systems use fixed slots/PR  Fixed-sized slots  fragmentation (50% or more)  Elastic resource management needed</p>
  </div>
  <div class="page">
    <p>Host</p>
    <p>bus</p>
    <p>AmorphOS Goals Protected Sharing/Isolation  Mutually distrustful applications</p>
    <p>Compatibility / Portability  HDL written to AmorphOS interfaces  14 benchmarks run unchanged on Microsoft</p>
    <p>Catapult and Amazon F1</p>
    <p>Elasticity  User logic scales with resource availability  Sharing density scales with availability</p>
    <p>DRAM</p>
    <p>App A</p>
    <p>App B FPGA Fabric</p>
    <p>I/O QSFP</p>
    <p>USB</p>
    <p>eth</p>
    <p>I2C</p>
    <p>App A</p>
    <p>App B</p>
    <p>App A</p>
    <p>App B FPGA FabricFPGA FabricApp A</p>
    <p>App A</p>
    <p>App B</p>
    <p>App B</p>
  </div>
  <div class="page">
    <p>AmorphOS Abstractions  Zone: Allocatable Unit of Fabric</p>
    <p>1 Global zone  N dynamically sized, sub-dividable PR zones</p>
    <p>Hull: OS/Protection Layer  Memory Protection, I/O Mediation</p>
    <p>Morphlet: Protection Domain  Extends Process abstraction  Encapsulate user logic on PR or global zone</p>
    <p>Registry: Bitstream Cache  Hides latency of place-and-route (PaR)</p>
    <p>FPGA FabricFPGA FabricFPGA Fabric</p>
    <p>Global Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>PR Zone</p>
    <p>Morph let</p>
    <p>Host</p>
    <p>bus</p>
    <p>A</p>
    <p>B Morph letC</p>
    <p>Morphlet</p>
    <p>Morphlets Bitstream &lt;A,B&gt; 0x0a1</p>
    <p>&lt;A,B,C&gt; 0x0fb01</p>
    <p>&lt;B,C&gt; 0x11ad</p>
    <p>Re gi</p>
    <p>st ry</p>
  </div>
  <div class="page">
    <p>Scheduling Morphlets Tradeoff  Fixed zones + PR  fast, fragmentation  Global zone + PaR  eliminates fragmentation, slow</p>
    <p>AmorphOS: best of both worlds  Low Latency Mode</p>
    <p>Fixed zones + PR  Default Morphlet bitstream</p>
    <p>High Throughput Mode  Combine multiple Morphlets  Co-schedule on a global zone</p>
  </div>
  <div class="page">
    <p>FPGA Fabric</p>
    <p>Host DRAM</p>
    <p>FPGA Fabric</p>
    <p>Morphlet AApp A Morphlet A</p>
    <p>Host DRAM</p>
    <p>FPGA Fabric</p>
    <p>Morphlet A</p>
    <p>App A</p>
    <p>App B</p>
    <p>Morphlet A</p>
    <p>Morphlet B</p>
    <p>Host DRAM</p>
    <p>FPGA FabricMorphlet A</p>
    <p>App A</p>
    <p>App B</p>
    <p>Morphlet A</p>
    <p>Morphlet B</p>
    <p>Host DRAM App A</p>
    <p>Morphlet A App B</p>
    <p>Morphlet B App C</p>
    <p>Morphlet C App D</p>
    <p>Morphlet D</p>
    <p>Morphlet A'' Morphlet B' Morphlet C Morphlet D</p>
    <p>T0 T1 T2 T3</p>
    <p>Low-Latency Mode High-Throughput Mode Low-Latency Mode High-Throughput Mode</p>
    <p>Scheduling Case Study</p>
  </div>
  <div class="page">
    <p>AmorphOS Hull Hardens and extends vendor Shells  Microsoft Catapult  Amazon F1</p>
    <p>AmorphOS Interfaces  Control: CntrlReg  Virtual Memory: AMI  Bulk Data Transfer: Simple-PCIe</p>
    <p>SoftReg PCIe</p>
    <p>BAR-1-AXI4-Lite DMA-AXI4</p>
    <p>Catapult Shell</p>
    <p>F1 Shell</p>
    <p>Catapult Accelerator</p>
    <p>F1 Accelerator</p>
    <p>AmorphOS HullMorphlet AMICntrlReg PCIe</p>
  </div>
  <div class="page">
    <p>AmorphOS Hull Hardens and extends vendor Shells  Microsoft Catapult  Amazon F1</p>
    <p>AmorphOS Interfaces  Control: CntrlReg  Virtual Memory: AMI  Bulk Data Transfer: Simple-PCIe</p>
    <p>Multiplexing of interfaces  Isolation/data protection  Scalable, 32 accelerators</p>
    <p>Tree of multiplexers</p>
    <p>Morphlet0</p>
    <p>AMICntrlReg PCIe</p>
    <p>Morphlet1</p>
    <p>AMICntrlReg PCIe</p>
    <p>Morphlet2</p>
    <p>AMICntrlReg PCIe</p>
    <p>Morphlet3</p>
    <p>AMICntrlReg PCIe</p>
    <p>Catapult Shell</p>
    <p>AMICntrlReg PCIe</p>
  </div>
  <div class="page">
    <p>Implementation &amp; Methodology Catapult Prototype  Altera Mt. Granite Stratix V GS 2x4GB DDR3, Windows Server  Segment-based protection, partial reconfiguration (PR)</p>
    <p>Amazon F1 Prototype  Xilinx UltraScale+ VU9P, 4x16GB GDDR4, CentOS 7.5  No PR, but much more fabric than Catapult</p>
    <p>Workloads  DNNWeaver  DNN inference  MemDrive  Memory Bandwidth  Bitcoin  blockchain hashing  CHStone  11 accelerators (e.g. AES, jpeg, etc)</p>
  </div>
  <div class="page">
    <p>Sy st</p>
    <p>em T</p>
    <p>hr ou</p>
    <p>gh pu</p>
    <p>t</p>
    <p>Number of Morphlets</p>
    <p>MemDrive Bitcoin DNNWeaver</p>
    <p>Scalability</p>
    <p>F1: Xilinx UltraScale+ VU9P, 4x16GB GDDR4, CentOS 7.5  Higher is better, Homogenous Morphlets</p>
    <p>MemDrive: BW contention Bitcoin: compute-bound</p>
    <p>DNNWeaver:  32X density  23X throughput</p>
    <p>Takeaway: Massive throughput/density improvement possible, awareness of contended resources necessary</p>
  </div>
  <div class="page">
    <p>Ru n</p>
    <p>Ti m</p>
    <p>e (s</p>
    <p>)</p>
    <p>End-to-End Bitcoin Run Time</p>
    <p>No Sharing Two PR Zones AmorphOS (HT)</p>
    <p>Throughput</p>
    <p>8 Bitcoin Morphlets  Catapult Altera Stratix V GS 2x4GB DDR3, Windows  Registry pre-populated: ctxt sw. 200ms  Log Scale, Lower is better</p>
    <p>No-Sharing: serialized</p>
    <p>Fixed Zones: worse than no sharing due to down-scaling!</p>
    <p>Takeaway: Co-scheduling on a global zone can perform better than fixed-sized slots and PR</p>
    <p>(Catapult, F1) (e.g. Intel, Chen14)</p>
  </div>
  <div class="page">
    <p>Partitioning Policies Non-Sharing (baseline)  Everything runs serially  Single context</p>
    <p>Global Zone  Multiple Morphlets  No fixed size zones</p>
    <p>Single-level zone policy  Two PR zones  One Morphlet each</p>
    <p>Co-schedule  Multiple Morphlets in</p>
    <p>a single PR zone</p>
    <p>Subdivide  Divide top-level PR zone into</p>
    <p>smaller PR zones</p>
  </div>
  <div class="page">
    <p>Partitioning Policies</p>
    <p>Bitcoin Morphlets  Catapult: Altera Mt. Granite Stratix V GS 2x4GB DDR3, Windows  Registry pre-populated: ctxt sw. 200ms  Higher is better</p>
    <p>Single-level partititioning Better than recursive subdivision (cause: downscaling)</p>
    <p>Non-sharing: serialized  Global: multi-context on global zone  Single-level: only two fixed slots  Co-schedule: morph multiple in fixed slot  Subdivide: hierarchical partitions</p>
    <p>Co-schedule on global zone best</p>
    <p>Takeaway:  Hierarchical PR on limited HW not worth it  See paper for projections on F1</p>
  </div>
  <div class="page">
    <p>Related Work Access to OS-managed resources</p>
    <p>Borph: So [TECS 08, Thesis 07]</p>
    <p>Leap: Adler [FPGA 11]  CoRAM: Chung [FPGA 11]</p>
    <p>First-class OS support  HThreads: Peck [FPL06], ReconOS: Lbbers [TECS 09] -- extend threading to FPGA SoCs</p>
    <p>MURAC: Hamilton [FCCM 14]  extend process abstraction to FPGAs</p>
    <p>Single-application Frameworks  Catapult: Putnam [ISCA 14] / Amazon F1</p>
    <p>Fixed-slot + PR  OpenStack support: Chen [CF 14], Byma [FCCM 14]; Fahmy [CLOUDCOM 15];  Disaggregated FPGAs: Weerasinghe [UIC-ATC-ScalCom 15]</p>
    <p>Overlays  Zuma: Brant [FCCM 12],</p>
    <p>Hoplite: Kapre [FPL 15],  ReconOS+Zuma: [ReConfig 14] 15</p>
  </div>
  <div class="page">
    <p>Conclusions &amp; Future Work Compatibility Improved  without restricting programming model  Comprehensive set of stable interfaces  Port AmorphOS per platform not each accelerator per platform</p>
    <p>Scalability achieved within and across accelerators  AmorphOS transparently scales morphlets up/down  Powerful combination of slots/Partial Reconfiguration and full FPGA bitstreams</p>
    <p>Future work  Transparently scale across multiple FPGAs  Scale across more than just FPGAs  Open source AmorphOS/port to more platforms</p>
    <p>Questions?</p>
  </div>
</Presentation>
