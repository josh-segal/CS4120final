<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Information-Theoretic Listening Paris Smaragdis Machine Listening Group MIT Media Lab</p>
  </div>
  <div class="page">
    <p>Outline  Defining a global goal for computational audition</p>
    <p>Example 1: Developing a representation</p>
    <p>Example 2: Developing grouping functions</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Auditory Goals  Goals of computational audition are</p>
    <p>all over the place, should they?</p>
    <p>Lack of formal rigor in most theories</p>
    <p>Computational listening is fitting</p>
    <p>psychoacoustic experiment data</p>
  </div>
  <div class="page">
    <p>Auditory Development  What really made audition?</p>
    <p>How did our hearing evolve?</p>
    <p>How did our environment shape</p>
    <p>our hearing?</p>
    <p>Can we evolve, rather than</p>
    <p>instruct, a machine to listen?</p>
  </div>
  <div class="page">
    <p>Goals of our Sensory System  Distinguish independent events</p>
    <p>Object formation  Gestalt grouping</p>
    <p>Minimize thinking and effort  Perceive as few objects as possible  Think as little as possible</p>
  </div>
  <div class="page">
    <p>Entropy Minimization as a Sensory Goal</p>
    <p>Long history between entropy and perception  Barlow, Attneave, Attick, Redlich, etc ...</p>
    <p>Entropy can measure statistical dependencies</p>
    <p>Entropy can measure economy  in both thought (algorithmic entropy)  and information (Shannon entropy)</p>
  </div>
  <div class="page">
    <p>What is Entropy?  Shannon Entropy:</p>
    <p>A measure of:  Order  Predictability  Information  Correlations  Simplicity  Stability  Redundancy  ...</p>
    <p>H(x)  Px(x) log Px (x) dx</p>
    <p>High entropy = Little order  Low entropy = Lots of order</p>
  </div>
  <div class="page">
    <p>Representation in Audition</p>
    <p>Frequency decompositions  Cochlear hint  Easier to look at data!</p>
    <p>Sinusoidal bases  Signal processing framework</p>
  </div>
  <div class="page">
    <p>Evolving a Representation  Develop a basis decomposition</p>
    <p>Bases should be statistically independent  Satisfaction of minimal entropy idea</p>
    <p>Decomposition should be data driven  Account for different domains</p>
  </div>
  <div class="page">
    <p>Method  Use bits of natural sounds to derive bases</p>
    <p>Analyze these bits with ICA</p>
    <p>S W X  W(i ) indep of W( j )i, j</p>
    <p>s k 1 reshape</p>
    <p>S n m</p>
  </div>
  <div class="page">
    <p>Results  We obtain sinusoidal</p>
    <p>bases!</p>
    <p>Transform is driven by the environment</p>
    <p>Uniform procedure for different domains</p>
  </div>
  <div class="page">
    <p>Auditory Grouping  Heuristics</p>
    <p>Hard to implement on computers</p>
    <p>Require even more heuristics to resolve ambiguity</p>
    <p>Weak definitions</p>
    <p>Bootstrapped to individual domains</p>
    <p>Vision Gestalt  Auditory Gestalt</p>
    <p>Common AM</p>
    <p>Common FM</p>
    <p>Good Continuation</p>
  </div>
  <div class="page">
    <p>Method</p>
    <p>Parameterized Auditory Scene</p>
    <p>s(t,n)</p>
    <p>Density Estimation</p>
    <p>Ps(i)</p>
    <p>Shannon Entropy Calculation</p>
    <p>H(s)  Ps (i, ..., j) ln Ps (i,..., j) i,...,j</p>
    <p>Goal: Find grouping that minimizes scene entropy</p>
  </div>
  <div class="page">
    <p>Common Modulation - Frequency  Scene Description:</p>
    <p>s(t,n) {cos(r f1(t) t), cos( f2 (t)t)}</p>
    <p>f1  f2 if n 0.5</p>
    <p>Time</p>
    <p>n = 0.5</p>
    <p>F re</p>
    <p>qu en</p>
    <p>cy</p>
    <p>Entropy Measurement:</p>
  </div>
  <div class="page">
    <p>Common Modulation - Amplitude  Scene Description:</p>
    <p>s(t,n) {a1(t) cos(r f0 t), a2 (t) cos f0 t }</p>
    <p>a1 a2 if n 0.5</p>
    <p>Entropy Measurement:</p>
    <p>Time</p>
    <p>n = 0.5</p>
    <p>S in</p>
    <p>e 1</p>
    <p>A m</p>
    <p>pl it</p>
    <p>ud e</p>
    <p>S in</p>
    <p>e 2</p>
    <p>A m</p>
    <p>pl it</p>
    <p>ud e</p>
  </div>
  <div class="page">
    <p>Common Modulation - Onset/Offset  Entropy Measurement: Scene Description:</p>
    <p>S in</p>
    <p>e 1</p>
    <p>A m</p>
    <p>pl it</p>
    <p>ud e</p>
    <p>S in</p>
    <p>e 2</p>
    <p>A m</p>
    <p>pl it</p>
    <p>ud e</p>
    <p>n = 0.5</p>
    <p>Time</p>
  </div>
  <div class="page">
    <p>Similarity/Proximity - Harmonicity I</p>
    <p>s(t,n) {cos( f0 t), cos(n f0 t)}</p>
    <p>Entropy Measurement: Scene Description:</p>
    <p>Time</p>
    <p>F re</p>
    <p>qu en</p>
    <p>cy</p>
  </div>
  <div class="page">
    <p>Similarity/Proximity - Harmonicity II</p>
    <p>s(t,n) {cos( f0 t), cos(2 f0 t), cos(nf0 t )}</p>
    <p>Entropy Measurement: Scene Description:</p>
    <p>Time</p>
    <p>F re</p>
    <p>qu en</p>
    <p>cy</p>
  </div>
  <div class="page">
    <p>Simple Scene Analysis Example</p>
    <p>Simple scene:  5 Sinusoids  2 Groups</p>
    <p>Simulated Annealing Algorithm  Input: Raw sinusoids  Goal: Entropy minimization  Output: Expected grouping</p>
  </div>
  <div class="page">
    <p>Important Notes  No definition of time</p>
    <p>Developed a concept of frequency</p>
    <p>No parameter estimation requirement  Operations on data not parameters</p>
    <p>No parameter setting!</p>
  </div>
  <div class="page">
    <p>Conclusions  Elegant and consistent formulation</p>
    <p>No constraint over data representation  Uniform over different domains (Cross-modal!)  No parameter estimation  No parameter tuning!</p>
    <p>Biological plausibility  Barlow et al ...</p>
    <p>Insight to perception development</p>
  </div>
  <div class="page">
    <p>Future Work</p>
    <p>Good Cost Function?  Joint entropy vs entropy of sums  Shannon entropy vs Kolmogorov complexity  Joint-statistics (cumulants, moments)</p>
    <p>Incorporate time  Sounds have time dependencies Im ignoring</p>
    <p>Generalize to include perceptual functions</p>
  </div>
  <div class="page">
    <p>Teasers  Dissonance and Entropy</p>
    <p>Pitch Detection</p>
    <p>Instrument Recognition</p>
    <p>H(Maj chord)H(Min chord)H(Dim chord) H(5th|pythagorean)H(5th|equal temperament)</p>
    <p>argmin f</p>
    <p>(H(s(t),cos(f(t)t)))</p>
    <p>argmin template</p>
    <p>(H(s(t),template(t)))</p>
  </div>
</Presentation>
