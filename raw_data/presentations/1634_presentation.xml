<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Finesse: Fine-Grained Feature Locality based Fast Resemblance Detection for Post-Deduplication</p>
    <p>Delta Compression</p>
    <p>Yucheng Zhang Hubei University of Technology</p>
    <p>Wen Xia Harbin Institute of Technology, Shenzhen &amp; Peng Cheng Laboratory</p>
    <p>Dan Feng Huazhong University of Science and Technology</p>
    <p>Hong Jiang University of Texas at Arlington</p>
    <p>Yu Hua Huazhong University of Science and Technology</p>
    <p>Qiang Wang Huazhong University of Science and Technology</p>
  </div>
  <div class="page">
    <p>Big data era</p>
    <p>Amount of digital data in the world will reach 44 ZB by 2020</p>
    <p>Background</p>
    <p>Redundant data in backup systems</p>
    <p>About 88-90% of the data in EMC and Symantecs backup systems are duplicate (FAST'12, USENIX ATC'15)</p>
  </div>
  <div class="page">
    <p>Data deduplication</p>
    <p>Remove duplicate chunks according to their fingerprints, only store one unique chunks</p>
    <p>Drawback: cannot remove redundant data among nonduplicate but very similar chunks</p>
    <p>Data Reduction Technologies</p>
  </div>
  <div class="page">
    <p>Data Reduction Technologies</p>
    <p>Delta compression</p>
    <p>Achieve 2X more compression ratio beyond deduplication (FAST'12, Performance'14, Sigmod'17)</p>
    <p>Chunk1</p>
    <p>Chunk2</p>
    <p>(similar to Chunk1)</p>
    <p>Regions of</p>
    <p>Difference</p>
    <p>Delta Compression Chunk2 = Base Chunk</p>
    <p>(chunk1) +</p>
    <p>delta(chunk1,chunk2)</p>
  </div>
  <div class="page">
    <p>Detecting delta compression candidates</p>
    <p>Resemblance Detection</p>
    <p>Traditional N-transform Super-Feature Generally, It extracts a fixed number of features from a</p>
    <p>chunk and grouping N features (N=12) into M SFs (e.g., M=3) for matching. One SF matching means the two chunks are very similar</p>
    <p>Feature extraction is time-consuming: Requiring N linear transformations for each fingerprint to generate N-dimensional hash value sets (features)</p>
  </div>
  <div class="page">
    <p>F A S T 2 0 1 9A chunk</p>
    <p>shingle 1</p>
    <p>shingle 1 (S1): FAST shingle 2 (S2): AST2 shingle 3 (S3): ST20 shingle 4 (S4): T201 shingle 5 (S5): 2019</p>
    <p>A simple example: extracting 4 features from a string</p>
    <p>Rabin fingerprinting:</p>
    <p>S1 &gt; R1 S2 &gt; R2 S3 &gt; R3 S4 &gt; R4 S5 &gt; R5</p>
  </div>
  <div class="page">
    <p>F A S T 2 0 1 9A chunk</p>
    <p>shingle 1</p>
    <p>shingle 1 (S1): FAST shingle 2 (S2): AST2 shingle 3 (S3): ST20 shingle 4 (S4): T201 shingle 5 (S5): 2019</p>
    <p>A simple example: extracting 4 features from a string</p>
    <p>Rabin fingerprinting:</p>
    <p>S1 &gt; R1 S2 &gt; R2 S3 &gt; R3 S4 &gt; R4 S5 &gt; R5</p>
    <p>R1 &gt; R11 , R12 , R13 , R14 R2 &gt; R21 , R22 , R23 , R24 R3 &gt; R31 , R32 , R33 , R34 R4 &gt; R41 , R42 , R43 , R44 R5 &gt; R51 , R52 , R53 , R54</p>
    <p>Feature 1:max{R11,R21,R31,R41}</p>
    <p>Feature 2:max{R12,R22,R32,R42}</p>
    <p>Feature 3:max{R13,R23,R33,R43}</p>
    <p>Feature 4:max{R14,R24,R34,R44}</p>
    <p>Feature extraction</p>
  </div>
  <div class="page">
    <p>F A S T 2 0 1 9A chunk</p>
    <p>shingle 1</p>
    <p>shingle 1 (S1): FAST shingle 2 (S2): AST2 shingle 3 (S3): ST20 shingle 4 (S4): T201 shingle 5 (S5): 2019</p>
    <p>A simple example: extracting 4 features from a string</p>
    <p>Rabin fingerprinting:</p>
    <p>S1 &gt; R1 S2 &gt; R2 S3 &gt; R3 S4 &gt; R4 S5 &gt; R5</p>
    <p>R1 &gt; R11 , R12 , R13 , R14 R2 &gt; R21 , R22 , R23 , R24 R3 &gt; R31 , R32 , R33 , R34 R4 &gt; R41 , R42 , R43 , R44 R5 &gt; R51 , R52 , R53 , R54</p>
    <p>Feature 1:max{R11,R21,R31,R41}</p>
    <p>Feature 2:max{R12,R22,R32,R42}</p>
    <p>Feature 3:max{R13,R23,R33,R43}</p>
    <p>Feature 4:max{R14,R24,R34,R44}</p>
    <p>Feature extraction</p>
    <p>N-transform Super-Feature is compute-intensive because it requires too many linear transformations</p>
  </div>
  <div class="page">
    <p>ObservationFine-grained Feature Locality</p>
  </div>
  <div class="page">
    <p>ObservationFine-grained Feature Locality</p>
    <p>Datasets WEB TAR RDB SYN VMA VMB</p>
    <p>Avg. # of identical subchunks</p>
    <p>Avg. # of subchunks owning the same features</p>
    <p>All identified chunks are all divided into 12 equal-sized subchunks</p>
    <p>Most of the corresponding subchunk pairs in the detected similar chunks have the same features</p>
  </div>
  <div class="page">
    <p>Design of Finesse</p>
    <p>Finesse, a fast resemblance detection approach that exploits the fine-grained feature locality</p>
    <p>Step1: Feature extraction  Dividing a chunk into N equal-sized subchunks,</p>
    <p>computing Rabin fingerprints for all shingles in the chunk, and selecting the maximum fingerprints in each subchunk as features to obtain N features</p>
    <p>Advantages: Do not require the time-consuming linear transformations for extracting more features, only need to divide the chunk into more subchunks</p>
  </div>
  <div class="page">
    <p>Design of Finesse</p>
    <p>Step2: Feature grouping  Principle: features in an SF should be extracted from the</p>
    <p>subchunks distributed uniformly across the chunk.</p>
  </div>
  <div class="page">
    <p>Design of Finesse</p>
    <p>Step2: Feature grouping</p>
  </div>
  <div class="page">
    <p>Computational Overheads</p>
    <p>Approaches Operations</p>
    <p>N-transform SF</p>
    <p>Rabin fingerprinting</p>
    <p>N linear transformations</p>
    <p>N conditional branches for feature selection</p>
    <p>Finesse</p>
    <p>Rabin fingerprinting</p>
    <p>Computational overhead required to process one shingle.</p>
  </div>
  <div class="page">
    <p>Datasets</p>
    <p>Name Size DR Workload descriptions</p>
    <p>WEB 367 GB 4.21 135 days snapshots of the website: news.sina.com</p>
    <p>TAR 112 GB 1.70 258 versions of Linux kernel source code. Each version is packaged as a tar file</p>
    <p>RDB 540 GB 12.25 100 backups of the redis key-value store database</p>
    <p>SYN 330 GB 13.07 176 synthetic backups by simulating file create/delete/modify operations</p>
    <p>VMA 117 GB 1.61 78 virtual machine images of different OS release versions, including Fedora, CentOS, Debian, etc</p>
    <p>VMB 321 GB 10.45 20 backups of an Ubuntu 12.04 VM image in use by a research group</p>
    <p>iondeduplicataftersizedatatotal</p>
    <p>iondeduplicatbeforesizedatatotal =DR</p>
  </div>
  <div class="page">
    <p>Resemblance Detection Efficiency</p>
    <p>ncompressiodeltaaftersizetotal</p>
    <p>ncompressiodeltabefoersizetotal DCR =</p>
    <p>ncompressiodeltabeforesizedatachunk</p>
    <p>ncompressiodeltaaftersizedatachunk DCE =</p>
  </div>
  <div class="page">
    <p>Resemblance Detection Efficiency</p>
    <p>ncompressiodeltaaftersizetotal</p>
    <p>ncompressiodeltabefoersizetotal DCR =</p>
    <p>ncompressiodeltabeforesizedatachunk</p>
    <p>ncompressiodeltaaftersizedatachunk DCE =</p>
    <p>Finesse achieves the similar resemblance detection efficiency as N-transform SF approach</p>
  </div>
  <div class="page">
    <p>Similarity Computing Speed</p>
  </div>
  <div class="page">
    <p>Similarity Computing Speed</p>
    <p>Finesse is about 3X faster than N-transform SF approach</p>
  </div>
  <div class="page">
    <p>System Throughput</p>
  </div>
  <div class="page">
    <p>System Throughput</p>
    <p>The system based on the Finesse approach outperforms the one</p>
    <p>based on N-transform SF by 41%-85% in total system throughput</p>
  </div>
  <div class="page">
    <p>We observed fine-grained feature locality among similar chunks in backup workloads</p>
    <p>We proposed Finesse, a fast resemblance detection based on fine-grained feature locality</p>
    <p>Our experimental results suggest Finesse runs 3X faster than N-transform SF for resemblance detection</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Questions?</p>
    <p>Thank you!</p>
  </div>
</Presentation>
