<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Predicting Computer System Failures Using</p>
    <p>Support Vector Machines</p>
    <p>Errin W. Fulpa Glenn A. Finkb Jereme N. Haackb</p>
    <p>aWake Forest University</p>
    <p>Department of Computer Science</p>
    <p>Winston-Salem NC, USA</p>
    <p>bPacific Northwest National</p>
    <p>Laboratory</p>
    <p>Richland WA, USA</p>
    <p>Pacific Northwest NATIONAL LABORATORY</p>
    <p>USENIX Workshop on the Analysis of System Logs December 7, 2008</p>
    <p>System Event Prediction 1</p>
    <p>High-Performance Computing Trends</p>
    <p>PROJECTED PERFORMANCE DEVELOPMENT</p>
    <p>X X X X</p>
    <p>X X X X</p>
    <p>X X X X</p>
    <p>X X X X</p>
    <p>X X X X</p>
    <p>X X X X</p>
    <p>X X X X</p>
    <p>X X</p>
    <p>X X X X X X</p>
    <p>X X</p>
    <p>X X X X X X X</p>
    <p>X X X</p>
    <p>X X X X X X X</p>
    <p>X X X X</p>
    <p>X</p>
    <p>X X X X</p>
    <p>X X X X</p>
    <p>X X X X</p>
    <p>X X X X X</p>
    <p>X X X X</p>
    <p>X X X X</p>
    <p>X X X X</p>
    <p>X</p>
    <p>SUM</p>
    <p>N=1</p>
    <p>N=500</p>
    <p>JUN JUN JUN JUN JUN JUN JUN JUN JUN JUN JUN JUN JUN JUN JUNNOV NOV NOV NOV NOV NOV NOV NOV NOV NOV NOV NOV NOV NOV NOV</p>
    <p>ARCHITECTURES</p>
    <p>CCCLUUUSSSTEEERRR COOONSTTTELLLLATTTAA IONNNNSS</p>
    <p>SIIIMDDD</p>
    <p>MMMPPPP</p>
    <p>SSSMP</p>
    <p>SINNNGLLLE PRRRROCCCCESSSSSORRRR</p>
    <p>JUN JUN JUN JUN JUN JUN JUN JUN JUN JUN JUN JUN JUN JUN JUNNOV NOV NOV NOV NOV NOV NOV NOV NOV NOV NOV NOV NOV NOV NOV</p>
    <p>Expected that computing will continue to double each year  Petaflop systems listed on top500.org</p>
    <p>However CPU clock rates will see limited increases</p>
    <p>Computing improvements achieved with more processors  IBM Blue Gene at LLNL has 212,992 processors</p>
    <p>System failures will become more problematic</p>
  </div>
  <div class="page">
    <p>System Event Prediction 2</p>
    <p>System Events</p>
    <p>There are several critical system events  Hardware failure, software failure, and user error</p>
    <p>Frequency will increase as systems become larger (cluster)</p>
    <p>Resulting in lower overall system utilization</p>
    <p>Cannot easily improve failure rates, can we manage failure?  Smarter scheduling of applications and services</p>
    <p>Minimize the impact of failure</p>
    <p>Accurate event predictions are key for event management  Are predictions possible? How accurate?</p>
    <p>Need system status information to make predictions</p>
    <p>System Event Prediction 3</p>
    <p>System Status Information</p>
    <p>Almost every computer maintains a system log file  Provide information about system events</p>
    <p>syslog is actually general-purpose logging facility [Lon01]</p>
    <p>An event represents a change in system state  Include hardware failures, software failures, and security</p>
    <p>Host Facility Level Tag Time Message</p>
    <p>Entries contain information such as: time, message, and tag  Time identifies when the message was recorded</p>
    <p>Message describes the event, typically natural language</p>
    <p>Tag represents criticality, low values are more important</p>
  </div>
  <div class="page">
    <p>System Event Prediction 4</p>
    <p>Log Files</p>
    <p>Host Facility Level Tag Time Message</p>
    <p>Log file is a list of messages, can be analyzed for  Auditing, determine the cause of an event (past)</p>
    <p>Predicting important events (future)</p>
    <p>System Event Prediction 5</p>
    <p>Example System Event to Predict</p>
    <p>An interesting event is disk failure  By 2018 [large systems] could have</p>
    <p>any time [SG07]</p>
    <p>Predicting disk failure is important</p>
    <p>Easy to identify event in the log...</p>
    <p>Predict failure as early as possible  n messages M = {m1, m1, ..., mn}  Assume mn is the event</p>
    <p>Min depth d and max lead l</p>
    <p>Are all messages the same?</p>
    <p>M</p>
    <p>depth</p>
    <p>lead</p>
    <p>time</p>
  </div>
  <div class="page">
    <p>System Event Prediction 6</p>
    <p>SMART</p>
    <p>Self-Monitoring Analysis &amp; Reporting Technology (SMART)  SMART disks monitor their health and performance</p>
    <p>Attributes describe current state, each attribute has unique ID</p>
    <p>Many different types of messages (Attribute and Value) Attribute Meaning</p>
    <p>Pinheiro et.al. investigated Google hard drive failure [PWB07]  Some SMART parameters do correlate with drive failure</p>
    <p>Conclude SMART messages alone may not be sufficient</p>
    <p>System Event Prediction 7</p>
    <p>Disk Failure Prediction</p>
    <p>What features (information) should be considered?  A message contains criticality, message, and time</p>
    <p>Is there a series of messages that tend to be a precursor?</p>
    <p>Consider a sequence of messages arriving (ordered by time)  Is it possible to classify into failure and non-failure classes?</p>
    <p>Other approaches have considered Bayesian Nets and HMM</p>
    <p>x 10 9</p>
    <p>time (seconds)</p>
    <p>ta g</p>
    <p>n u</p>
    <p>m b</p>
    <p>e r</p>
    <p>h198.129.146.158</p>
    <p>x 10 9</p>
    <p>time (seconds)</p>
    <p>ta g</p>
    <p>n u</p>
    <p>m b</p>
    <p>e r</p>
    <p>h198.129.146.227</p>
    <p>x 10 9</p>
    <p>time (seconds)</p>
    <p>ta g</p>
    <p>n u</p>
    <p>m b</p>
    <p>e r</p>
    <p>h198.129.149.180</p>
  </div>
  <div class="page">
    <p>System Event Prediction 8</p>
    <p>Support Vector Machines</p>
    <p>Support Vector Machine (SVM) is a classification algorithm  Consider a set of samples from two different classes</p>
    <p>Each vector consists of features describing the sample</p>
    <p>SVM finds a hyperplane separating the classes in hyperspace</p>
    <p>The vectors closest to the plane are the support vectors</p>
    <p>Great for aggregate statistics, what about series?  Interested in using sequences of messages as features</p>
    <p>System Event Prediction 9</p>
    <p>Spectrum Kernel</p>
    <p>A spectrum kernel considers k length sequences as features  The frequency of the sequence is the feature value</p>
    <p>Assume two symbols {A, B} and sequence length k = 2  There are 2k possible sequences (features) (AA, AB, BA, BB)</p>
    <p>Value of a feature is the number of occurrences</p>
    <p>M = {A, A, B, A, A, B, B, A} AA: 2</p>
    <p>AB: 2</p>
    <p>BA: 2</p>
    <p>BB: 1</p>
    <p>There are bk possible sequences, were b is number of symbols</p>
    <p>How does this work for syslog messages?</p>
  </div>
  <div class="page">
    <p>System Event Prediction 10</p>
    <p>tag Sequences</p>
    <p>Each message has a tag that indicates criticality  Sequence of messages represented by sequence of tag values</p>
    <p>x 10 9</p>
    <p>time (seconds)</p>
    <p>ta g n</p>
    <p>u m</p>
    <p>b e r</p>
    <p>h198.129.146.158</p>
    <p>-50 0 50 100 150 200 0</p>
    <p>p e rc</p>
    <p>e n t o f a ll</p>
    <p>m e ss</p>
    <p>a g e s</p>
    <p>tag number</p>
    <p>Example tag Levels</p>
    <p>Need to reduce number of symbols, assume three levels</p>
    <p>high (tag &lt; 10), medium (10 &lt;tag&lt; 140), low (tag&gt; 140)</p>
    <p>Given a series of messages M , process using a sliding window  Count the number of occurrences of k-length sequences</p>
    <p>System Event Prediction 11</p>
    <p>Example tag Processing</p>
    <p>Let M = {148, 148, 158, 40, 158, 188, 188, 88, 158, 188}  Assume b = 3 and k = 5, then 35 = 243 possible features</p>
    <p>tag Encoding (e) Sequence f (base 10)</p>
    <p>Feature number is ft+1 = mod (b  ft, bk) + e  Vector for M would be (160:1, 215:2, 233:1, 239:2)</p>
  </div>
  <div class="page">
    <p>System Event Prediction 12</p>
    <p>System Data used for Experiments</p>
    <p>About 24 months of syslog files from 1024 node Linux cluster  Averaged 3.24 messages an hour (78 a day) per machine</p>
    <p>Observed 120 disk failure events</p>
    <p>tag number</p>
    <p>p e rc</p>
    <p>e n t o f a ll</p>
    <p>m e ss</p>
    <p>a g e s</p>
    <p>Distribution of Message tags and Intervals Used</p>
    <p>Non-fail disk Fail disk</p>
    <p>tag number</p>
    <p>p e rc</p>
    <p>e n t o f a ll</p>
    <p>m e ss</p>
    <p>a g e s</p>
    <p>Distribution of Message tags and Intervals Used</p>
    <p>Non-fail disk Fail disk</p>
    <p>Tag values ranged from 0 to 189  61 unique tag messages were observed during this time</p>
    <p>System Event Prediction 13</p>
    <p>Prediction Experiments</p>
    <p>Sets of M =1200 messages (15 days) collected per machine  From first message, processed d = {400, 600, 800, 1000, 1100}</p>
    <p>One SVM considered aggregate features occurring within d  Number of occurrences for each tag value</p>
    <p>Another SVM also considered tag sequences occurring within d  Sequences consisted of 5 messages, there were 19 tag ranges</p>
    <p>M time</p>
    <p>d = 400 d = 600</p>
    <p>d = 800 d = 1000</p>
    <p>d = 1200</p>
    <p>tag number</p>
    <p>p e</p>
    <p>rc e</p>
    <p>n t</p>
    <p>o f</p>
    <p>a ll</p>
    <p>m e</p>
    <p>ss a</p>
    <p>g e</p>
    <p>s</p>
    <p>Distribution of Message tags and Intervals Used</p>
  </div>
  <div class="page">
    <p>System Event Prediction 14</p>
    <p>Prediction Results</p>
    <p>Accuracy, precision, recall, and ROC recorded per experiment  Where acc= T P +T N</p>
    <p>P +N , prec= T P</p>
    <p>T P +F P , and recall= T P</p>
    <p>P</p>
    <p>number of messages processed (M)</p>
    <p>p e rc</p>
    <p>e n t a cc</p>
    <p>u ra</p>
    <p>cy Percent Accuracy as Number of Messages Increases</p>
    <p>combined features aggregate features failure event</p>
    <p>number of messages processed (M)</p>
    <p>p re</p>
    <p>ci si</p>
    <p>o n</p>
    <p>Precision as Number of Messages Increases</p>
    <p>combined features aggregate features failure event</p>
    <p>More messages improved prediction results  Combined were better, 73% accuracy with 200 message lead</p>
    <p>System Event Prediction 15</p>
    <p>Prediction Results</p>
    <p>number of messages processed (M)</p>
    <p>p e rc</p>
    <p>e n t re</p>
    <p>ca ll</p>
    <p>Percent Recall as Number of Messages Increases</p>
    <p>combined features aggregate features failure event</p>
    <p>false positive rate</p>
    <p>tr u e p</p>
    <p>o si</p>
    <p>tiv e r</p>
    <p>a te</p>
    <p>ROC for Different SVM Classifiers</p>
    <p>combined at 1000 msg aggregate at 1000 msg combined at 400 msg aggregate at 400 msg random guess</p>
    <p>ROC curve can be used to compare classifiers/predictions [Faw06]  Closer to the north-west, the better the performance</p>
    <p>Some issues with false negatives</p>
    <p>Combined features performed better, typically 4% to 5% increase</p>
  </div>
  <div class="page">
    <p>System Event Prediction 16</p>
    <p>Feature Weights</p>
    <p>Use of a linear kernel for the SVM allows for feature analysis  Larger weight (positive or negative) indicates a feature useful</p>
    <p>feature</p>
    <p>w e ig</p>
    <p>h t</p>
    <p>Feature Weights for Failure Prediction</p>
    <p>x 10 6</p>
    <p>feature</p>
    <p>w e ig</p>
    <p>h t</p>
    <p>Feature Weights for Failure Prediction</p>
    <p>Of 2,476,289 features, only 2,251 were useful  Of the useful features 22 were aggregate, remaining were</p>
    <p>sequences</p>
    <p>System Event Prediction 17</p>
    <p>Runtime Performance</p>
    <p>For the combined feature experiments  Training time averaged 7 minutes 38 seconds</p>
    <p>Tesing time averaged 0.21 seconds</p>
  </div>
  <div class="page">
    <p>System Event Prediction 18</p>
    <p>Conclusions and Future Work</p>
    <p>Using syslog data to predict disk failures  Spectrum-kernel SVM predicted with 73% 100 msg lead</p>
    <p>Message sequences did improve performance</p>
    <p>Several areas for improvement  determine k and b, add new features, ...</p>
    <p>How does message rate impact performance?</p>
    <p>Need more and different data</p>
    <p>Consider other interesting events  Other failures, since disk failure = node failure  Can this be useful for security?</p>
    <p>Multi-system analysis</p>
    <p>Possible to create a reduced message system? [YM05]</p>
    <p>System Event Prediction 19</p>
    <p>References [Faw06] Tom Fawcett. An introduction to roc analysis. Pattern Recognition Letters, 7, 2006.</p>
    <p>[Lon01] C. Lonvick. The BSD Syslog Protocol. RFC 3164 (Informational), August 2001.</p>
    <p>[PWB07] Eduardo Pinheiro, Wolf-Dietrich Weber, and Luiz Andre Barroso. Failure trends in a large disk drive population. In</p>
    <p>Proceedings of the USENIX Conference on File and Storage Technologies, pages 1729, 2007.</p>
    <p>[SG07] Bianca Schroeder and Garth A Gibson. Understanding failures in petascale computers. Journal of Physics: Conference</p>
    <p>Series, (28), 2007.</p>
    <p>[YM05] Kenji Yamanishi and Yuko Maruyama. Dynamic syslog mining for network failure monitoring. In Proceedings of the</p>
    <p>Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, pages 499508, 2005.</p>
  </div>
  <div class="page">
    <p>System Event Prediction 20</p>
    <p>Other Prediction Stats</p>
    <p>Accuracy</p>
    <p>M = 400 600 800 1000 1100</p>
    <p>Agg 64 65 65 68 70 Comb 67 69 72 73 74</p>
    <p>Precision</p>
    <p>M = 400 600 800 1000 1100</p>
    <p>Agg 64 66 67 69 72 Comb 67 69 72 73 74</p>
    <p>Recall</p>
    <p>M = 400 600 800 1000 1100</p>
    <p>Agg 62 63 63 66 66 Comb 63 66 68 69 70</p>
    <p>F-score</p>
    <p>M = 400 600 800 1000 1100</p>
    <p>Agg 63 64 65 67 69 Comb 66 68 71 71 73</p>
  </div>
</Presentation>
