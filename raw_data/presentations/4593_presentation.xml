<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Efficient Search in Large Textual Collections with Redundancy</p>
    <p>Jiangong Zhang Torsten Suel CIS Department</p>
    <p>Polytechnic University Brooklyn, NY 11201</p>
  </div>
  <div class="page">
    <p>Motivation of Our Framework  Search engines only index and search the most</p>
    <p>recent snapshot of the web.  Can we efficiently support full text search over</p>
    <p>large web archives?  Internet archive has limited archive search ability.</p>
    <p>(http://www.archive.org)  One challenge: achieving a reasonable index</p>
    <p>when there are many similar pages (e.g., different versions of the same page).</p>
  </div>
  <div class="page">
    <p>Our Main Work  We propose a new and general framework to</p>
    <p>efficiently index and search large web page collections with redundancy.</p>
    <p>It supports efficient updates.  It applies to many scenarios:</p>
    <p>o archive search o redundant web collections o email and personal files o versioning file systems o distributed indexing</p>
  </div>
  <div class="page">
    <p>Outlines  Technical background  Difficulties of archive search  Basic idea of our framework  Detailed description of our framework  Experimental evaluation  Related work  Conclusions</p>
  </div>
  <div class="page">
    <p>Architecture of Search Engines</p>
    <p>Crawler: retrieves web pages from Internet  Doc Servers: Store web pages.  Index Servers: Store index and process queries.  Query Integrator &amp; Web Server: Front End.</p>
  </div>
  <div class="page">
    <p>Structure of Inverted Lists</p>
    <p>An inverted index consists of inverted lists.  Each inverted list is a sequence of postings.  Inverted lists are sorted and compressed.  Query processing needs to traverse inverted lists.</p>
  </div>
  <div class="page">
    <p>Term-Based Ranking</p>
  </div>
  <div class="page">
    <p>Why is archive search more difficult?</p>
  </div>
  <div class="page">
    <p>Update of Search Engines</p>
    <p>Old pages are replaced by new updated pages.  None existing pages are deleted.  New pages are inserted.  Index size wont change a lot.</p>
  </div>
  <div class="page">
    <p>Update of Archive Search</p>
    <p>New and changed pages are inserted.  Normally there is no deletion.  Its possible to have multiple versions of one page.</p>
  </div>
  <div class="page">
    <p>Challenges of Archive Search</p>
    <p>The size of inverted index is proportional to the number of versions.</p>
    <p>There are challenges both in performance and index size with traditional techniques.</p>
  </div>
  <div class="page">
    <p>Our Contribution  We propose a new and general framework to efficiently</p>
    <p>index and search large web page collections with redundancy.</p>
    <p>We propose the use of content-dependent partition techniques (e.g., winnowing S. Schleimer [SIGMOD 2003]) to avoid repeatedly indexing the same content.</p>
    <p>We discuss different scenarios for our framework and provide efficient update mechanism.</p>
    <p>We evaluate the benefits through experiments on real search engine query traces and web pages.</p>
  </div>
  <div class="page">
    <p>Description of our framework</p>
    <p>Use content-dependent partition techniques to split each document into a number of fragments.</p>
    <p>Index these fragments instead of the complete documents. This allows us to avoid repeatedly indexing fragments with the same contents (subject to certain sharing policies).</p>
    <p>Design modified algorithms for query processing that efficiently stitch the fragments back together.</p>
    <p>By identifying each fragment by a hash of its content, we can support very efficient updates on such indexes.</p>
  </div>
  <div class="page">
    <p>Overview of Our Framework</p>
    <p>Content-dependent partition: Winnowing  Sharing policies: Local Sharing and Global</p>
    <p>Sharing  Modified query processing  Efficient updates</p>
  </div>
  <div class="page">
    <p>Content Dependent Partitioning</p>
    <p>Goal: Partition a page into a set of fragments.  Fragments have roughly equivalent size.  Two similar pages will have many fragments in</p>
    <p>common.  A small modification in the page can only impact</p>
    <p>the current fragment plus the adjacent ones.  We adopt the Winnowing Algorithm [S. Schleimer,</p>
    <p>et al. (SIGMOD03)].</p>
  </div>
  <div class="page">
    <p>Winnowing Algorithm</p>
    <p>Uses two hash functions to partition a string (or file).  Use the following rules to determine the partitioning:</p>
    <p>Choose a hash function to map substrings of some fixed small size to integer values. Choose a larger window size and slide this window over the hash value array. Use the following rules to partition the file.  Suppose the current hash value is strictly smaller than all other values in the window, cut directly before it.  Suppose there are several positions in the current window with the same minimum value. If we have</p>
    <p>previously cut directly before one of these positions, no cut is applied in this step. Otherwise, cut before the rightmost such position.</p>
  </div>
  <div class="page">
    <p>Modifications in Our Approach</p>
    <p>We do not want to split terms into different fragments.  Convert page into by hashing each term into an</p>
    <p>unsigned char.  Apply winnowing on this array. Thus, the window size is</p>
    <p>the number of terms.</p>
  </div>
  <div class="page">
    <p>Local Sharing Policy</p>
    <p>Local Sharing: We avoid re-indexing of a fragment if it has previously occurred in a version of the same page.</p>
    <p>Number of Fragments that need to be indexed: 4 + 5 + 4 = 13 fragments (Total 18)</p>
  </div>
  <div class="page">
    <p>Global Sharing Policy</p>
    <p>Global Sharing: We allow unrestricted redundancy elimination across pages. If a fragment has previously occurred in any other page, it is not indexed again.</p>
    <p>Fragments Indexed: 4 + 5 + 2 = 11 fragments (Total 18)</p>
  </div>
  <div class="page">
    <p>Data Structures on Index Server</p>
    <p>Inverted Index: Consists of inverted lists sorted by docID.  Dictionary: stores a point of the start of the inverted list</p>
    <p>for each term, plus other statistical information.  Page Table: stores complete URL, length of doc,</p>
    <p>pagerank, and other useful information related to doc.</p>
  </div>
  <div class="page">
    <p>Additional Data Structures</p>
    <p>Doc/Version Table: stores information about a page and its various versions.</p>
    <p>Hash Table: stores a hash value of the content of each distinct fragment.</p>
    <p>Reuse Table: stores in which other pages a frag occurs.</p>
  </div>
  <div class="page">
    <p>Local Sharing Query Processing</p>
    <p>Identify pages that contain all query words (whether or not they occur in the same version).</p>
    <p>Check if any version of the obtained page contains all words. Compute the actual score for a page or version.</p>
    <p>Require additional computational and memory cost.  Details depend on sharing policy.</p>
  </div>
  <div class="page">
    <p>Global Sharing Query Processing</p>
    <p>Identify pages that contain all query words (whether or not they occur in the same version).</p>
    <p>Check if any version of the obtained page contains all words. Compute the actual score for a page or version.</p>
    <p>Require additional computational and memory cost.  Details depend on sharing policy.</p>
  </div>
  <div class="page">
    <p>Efficient Index Update</p>
    <p>Partition page into fragments.  Look up hashes of the fragments in the hash table, index only those</p>
    <p>fragments that do not find a match (while discarding the others).  Update or insert the appropriate records in the various tables (doc/version</p>
    <p>table, hash table, reuse table).  All new postings are first inserted in a main-memory structure and later</p>
    <p>periodically merged into disk based structures.</p>
  </div>
  <div class="page">
    <p>Cumulative Change of Frags</p>
    <p>Experiments use data set from Stanford WebBase: total of 6,356,374 versions of pages from 2,528,362 distinct URLs.</p>
    <p>Both are under local sharing policy.  Benefit keeps increasing along with versions.  Smaller window size obtain higher benefits.</p>
  </div>
  <div class="page">
    <p>Reduction of Frag &amp; Pos Number</p>
    <p>There is a significant additional benefit due to sharing between different pages.</p>
    <p>Global sharing performs better than local sharing in size.  Different versions of the same page are more similar than different</p>
    <p>pages.</p>
  </div>
  <div class="page">
    <p>Index Size &amp; Query Processing</p>
  </div>
  <div class="page">
    <p>Application Scenarios</p>
    <p>Archive Search  Redundant Web Collections  Email and Personal Files  Versioning File Systems  Distributed Indexing</p>
  </div>
  <div class="page">
    <p>Related Work  Inverted Index Compression</p>
    <p>F. Scholer, et al. (SIGIR02), V. Ahn and A. Moffat (ADC04), S. Heman (CWI05), D. Blandford and G. Blelloch (DCC02), F. Silvestri, et al. (SIGIR04)</p>
    <p>File Partitioning and Redundancy Elimination A. Tridgell and P. MacKerras (TR96), S. Rhea, et al. (WWW03), A. N. Spring and D. Wetherall (SIGCOMM00), T. Schwarz, et al. (ICDCS1990), P. Kulkarni, et al. (USENIX04), A. Muthitacharoen (SOSP01), L. Cox, et al. (OSDI02), S. Quinlan and S. Dorward (FAST02), R. Karp and M. Rabin (87), S. Sahinalp and U. Vishkin (FOCS02), D. Teodosiu, et al. (TR06), S. Schleimer (SIGMOD03)</p>
    <p>Find duplications in web collection J. Cho (SIGMOD00), A. Broder (WWW97)</p>
    <p>Index Updates L. Lim, et al. (WWW03), E. Brown, et al. (VLDB94), A. Tomasic, et al. (SIGMOD94), T.Chiueh and L. Huang (TR99)</p>
    <p>Indexing of Redundant Contents A. Broder, et al. (EDBT06), M. Herscovici, et al. (ECIR07)</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Find the similarity between pages and avoid repeatedly indexing the same contents.</p>
    <p>Q &amp; A</p>
    <p>Thank You !!!</p>
  </div>
</Presentation>
