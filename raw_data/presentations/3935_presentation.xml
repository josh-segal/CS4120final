<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Provenance Artifact Identification in the</p>
    <p>Atmospheric Composition Processing System (ACPS)</p>
    <p>Curt Tilmes NASA/UMBC</p>
    <p>Yelena Yesha UMBC</p>
    <p>Milton Halem UMBC</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>Background  Earth Science Processing Artifacts  Persistence  Actionable Identifiers  Earth Science Data Versions  Granularity  ArchiveSets  Persistent URLs  Artifact Web Server  Semantic Web and Linked Data</p>
  </div>
  <div class="page">
    <p>Earth Science</p>
    <p>http://data.giss.nasa.gov/gistemp/graphs/</p>
    <p>http://macuv.gsfc.nasa.gov/ozone.md</p>
  </div>
  <div class="page">
    <p>Climategate</p>
    <p>scandals including the `climategate' e-mail row had eroded public trust in scientists</p>
    <p>this crisis of public confidence should be a wake-up call for researchers</p>
    <p>the world had now entered an era in which people expected more transparency.</p>
    <p>http://news.bbc.co.uk/2/hi/ science/nature/8525879.stm</p>
    <p>Saturday, Feb 20, 2010</p>
  </div>
  <div class="page">
    <p>Background</p>
    <p>Modern research in earth science often involves sifting through mounds of data from a variety of sources (field sensors, satellite data, etc.) and applying various algorithms to reduce/transform/massage that data in various ways</p>
    <p>The data are likely the result of the work of hundreds of individuals from multiple organizations over decades.</p>
    <p>They are stored in multiple long term archives (which often change over time as well).</p>
    <p>This science relies on representing the provenance of such scientific results in a manner conducive to exploration, understanding and reproducibility.</p>
    <p>We need persistent identifiers to represent the artifacts of processing and their relationships.</p>
  </div>
  <div class="page">
    <p>Earth Science Processing Artifacts</p>
    <p>All of the artifacts involved in the provenance of a scientific result:  Data  Algorithms  Documentation  Sensors/Instruments/Instrument platforms  People (reputation)  Organizations (reputation)  Published scientific papers (add to credibility)  Computer systems, Hardware, OS, Libraries, Software  Abstract things like a data transformation event, Software</p>
    <p>Build Event or a validation experiment  An ephemeral execution of a web service</p>
  </div>
  <div class="page">
    <p>Persistence</p>
    <p>The provenance graph associated with a published component of the scientific literature should live as long as the publication is scientifically valid. (In fact, you could use a citation chain to determine which data are referenced.)</p>
    <p>It is intended that the lifetime of a [persistent identifier] be permanent. That is, the [persistent identifier] will be globally unique forever, and may well be used as a reference to a resource well beyond the lifetime of the resource it identifies or of any naming authority involved in the assignment of its name.</p>
    <p>http://www.doi.org/doi_presentations/overview_slides_4Dec2007/071205DOIOverview.ppt</p>
  </div>
  <div class="page">
    <p>Actionable Identifiers</p>
    <p>'Actionable' Identifier = Can I click on it?  What happens if the resource itself is no longer around? We</p>
    <p>(NASA archive) delete old, obsolete data that takes up expensive space.</p>
    <p>Even if the data are gone, the identifier should still be valid.</p>
    <p>What happens if valuable data is moved from one steward to another? (We do this all the time...)  An entire archive taken over by another organization  A single dataset within the archive moved from one organization</p>
    <p>to another  What about data served from multiple locations?  What about data served in multiple formats?</p>
  </div>
  <div class="page">
    <p>Earth Science Data Versions</p>
    <p>Versions  Every algorithm has strict configuration management with</p>
    <p>versions mapping to revisions  What does version mean to data?  Consider Algorithm X of version 1.2 is used to produce file A  If we revise algorithm X and reprocess with version 1.3, the</p>
    <p>produced file A is different, we note in its metadata that it was produced with version 1.3</p>
    <p>Now what happens if we recalibrate the instrument that produced the data that was fed to algorithm X?</p>
  </div>
  <div class="page">
    <p>Granularity</p>
    <p>Dealing with data at the extremes of granularity is awkward:  All data from all places for all times  A single measurement of some property for a single place at a</p>
    <p>single instant in time.</p>
    <p>Convention breaks down data into granules where neither the size of a single granule nor the total number of granules in a dataset are overwhelming.</p>
    <p>For a large amount of very consistent data, we can define:  A consistent granule definition (spatial/temporal/other)  A Granule Key that can uniquely identify a granule in a dataset.  A well-defined mechanism for iterating through the granules in a</p>
    <p>dataset.</p>
  </div>
  <div class="page">
    <p>Earth Science Data Type</p>
    <p>Earth Science Data Type (ESDT) defines a short key for each standard data product:  A specific algorithm (with published Algorithm Theoretical Basis</p>
    <p>Document 'ATBD')  A specific data format  A specific data Granularity</p>
  </div>
  <div class="page">
    <p>Granularity Example: OMTO3</p>
    <p>ESDT=OMTO3 Granularity = Orbital Granule Key = 20718</p>
  </div>
  <div class="page">
    <p>Granularity Example: MODIS 8day LSR</p>
    <p>ESDT=MOD09A1 Granularity = 8DayTiled Granule Key = 2000353,12,17 (year/doy,Hor., Ver.)</p>
  </div>
  <div class="page">
    <p>ArchiveSets</p>
    <p>The ACPS uses ArchiveSets to differentiate processing runs, experiments, etc.</p>
    <p>The key concept is that {ArchiveSet,ESDT,Granule Key} is always unique at a point in time.</p>
    <p>If a newly created file matches one already in the ArchiveSet, the old one is automatically removed from the 'current' ArchiveSet.</p>
    <p>We call {ArchiveSet,ESDT} a DataSet.  A Granularity Iterator can be used to enumerate all the</p>
    <p>Granule Keys in a DataSet.  Timestamps are used to precisely maintain the granule</p>
    <p>membership at any historic point in time, so {DataSet,Timestamp} refers uniquely to a set of files, none of which have the same Granule Key.</p>
  </div>
  <div class="page">
    <p>PURL: Persistent URL</p>
    <p>Very simple indirect mapping that redirects from a PURL to a URL with standard HTTP redirect</p>
    <p>Includes partial redirects to relocate whole hierarchies</p>
    <p>&lt;scheme&gt;://&lt;PURL resolver&gt;/&lt;name&gt;</p>
    <p>http://purl.org/mypath/mylocalid</p>
    <p>http://purl.org/NET/ACPS/&lt;ArtifactType&gt;/ &lt;ArtifactIdentifier&gt;</p>
  </div>
  <div class="page">
    <p>PURL Examples</p>
    <p>http://purl.org/NET/ACPS/Granularity/Orbital</p>
    <p>http://purl.org/NET/ACPS/ESDT/OMTO3</p>
    <p>http://purl.org/NET/ACPS/APP/OMTO3/v1.2.5</p>
    <p>http://purl.org/NET/ACPS/DataEvent/52782</p>
    <p>http://purl.org/NET/ACPS/BuildEvent/125526</p>
    <p>http://purl.org/NET/ACPS/Granule/17/OMTO3/28794</p>
    <p>http://purl.org/NET/ACPS/Granule/17/OMTO3/28794/20091201T17:15:28</p>
    <p>http://purl.org/NET/ACPS/Dataset/17/OMTO3/20091201T17:15:28</p>
    <p>Data Citations can include the 'DataSet' identifier, fully qualified with a timestamp to refer to a specific set of granules.</p>
  </div>
  <div class="page">
    <p>Artifact Web Server</p>
    <p>Each identifier is 'actionable' and will return the metadata (or data) associated with that artifact, including the relationships with other artifacts.</p>
    <p>Maintain the metadata and relationship graph even if the data themselves are deleted.</p>
    <p>Multiple fomats returned based on HTTP ContentType/Accept headers:  YAML  A human friendly format useful for debugging and</p>
    <p>testing.  XML  The modern standard for data interchange, easy to parse</p>
    <p>and transform  JSON  A lightweight data-interchange language that is</p>
    <p>particularly easy to incorporate into dynamic web sites.  RDF/OWL  Suitable for ingest into triple stores supporting</p>
    <p>complex queries, reasoning and data mining.</p>
  </div>
  <div class="page">
    <p>Semantic Web and Linked Data</p>
    <p>The RDF/OWL representation allows our provenance graphs to be easily traversed and handled by standard Semantic Web software.</p>
    <p>We can also establish equivalences and relationships with other entities following the principles of Linked Data, linking to scientific literature publications, standard instrument identifiers, scientist identifiers, etc.</p>
    <p>We plan to be compatible with OPM RDF/OWL representations, and are also experimenting with Proof Markup Language (PML).</p>
  </div>
</Presentation>
