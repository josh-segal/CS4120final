<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Discretized Streams An Efficient and Fault-Tolerant Model for Stream Processing on Large Clusters</p>
    <p>Matei Zaharia, Tathagata Das, Haoyuan Li, Scott Shenker, Ion Stoica UC BERKELEY</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Many important applications need to process large data streams arriving in real time  User activity statistics (e.g. Facebooks Puma)  Spam detection  Traffic estimation  Network intrusion detection</p>
    <p>Our target: large-scale apps that must run on tens-hundreds of nodes with O(1 sec) latency</p>
  </div>
  <div class="page">
    <p>Challenge</p>
    <p>To run at large scale, system has to be both:  Fault-tolerant: recover quickly from failures and</p>
    <p>stragglers  Cost-efficient: do not require significant hardware</p>
    <p>beyond that needed for basic processing</p>
    <p>Existing streaming systems dont have both properties</p>
  </div>
  <div class="page">
    <p>Traditional Streaming Systems</p>
    <p>Record-at-a-time processing model  Each node has mutable state  For each record, update state &amp; send new records</p>
    <p>mutable state</p>
    <p>node 1</p>
    <p>node 3</p>
    <p>input records push</p>
    <p>node 2 input records</p>
  </div>
  <div class="page">
    <p>Traditional Streaming Systems</p>
    <p>Fault tolerance via replication or upstream backup:</p>
    <p>node 1</p>
    <p>node 3</p>
    <p>node 2</p>
    <p>node 1</p>
    <p>node 3</p>
    <p>node 2</p>
    <p>synchronization</p>
    <p>node 1</p>
    <p>node 3</p>
    <p>node 2</p>
    <p>standby</p>
    <p>input</p>
    <p>input</p>
    <p>input</p>
    <p>input</p>
  </div>
  <div class="page">
    <p>Traditional Streaming Systems</p>
    <p>Fault tolerance via replication or upstream backup:</p>
    <p>node 1</p>
    <p>node 3</p>
    <p>node 2</p>
    <p>node 1</p>
    <p>node 3</p>
    <p>node 2</p>
    <p>synchronization</p>
    <p>node 1</p>
    <p>node 3</p>
    <p>node 2</p>
    <p>standby</p>
    <p>input</p>
    <p>input</p>
    <p>input</p>
    <p>input</p>
    <p>Fast recovery, but 2x hardware cost</p>
    <p>Only need 1 standby, but slow to recover</p>
  </div>
  <div class="page">
    <p>Traditional Streaming Systems</p>
    <p>Fault tolerance via replication or upstream backup:</p>
    <p>node 1</p>
    <p>node 3</p>
    <p>node 2</p>
    <p>node 1</p>
    <p>node 3</p>
    <p>node 2</p>
    <p>synchronization</p>
    <p>node 1</p>
    <p>node 3</p>
    <p>node 2</p>
    <p>standby</p>
    <p>input</p>
    <p>input</p>
    <p>input</p>
    <p>input</p>
    <p>Neither approach tolerates stragglers</p>
  </div>
  <div class="page">
    <p>Observation</p>
    <p>Batch processing models for clusters (e.g. MapReduce) provide fault tolerance efficiently  Divide job into deterministic tasks  Rerun failed/slow tasks in parallel on other nodes</p>
    <p>Idea: run a streaming computation as a series of very small, deterministic batches  Same recovery schemes at much smaller timescale  Work to make batch size as small as possible</p>
  </div>
  <div class="page">
    <p>Discretized Stream Processing</p>
    <p>t = 1:</p>
    <p>t = 2:</p>
    <p>stream 1 stream 2</p>
    <p>batch operation</p>
    <p>pull input</p>
    <p>input</p>
    <p>immutable dataset (stored reliably)</p>
    <p>immutable dataset (output or state); stored in memory without replication</p>
  </div>
  <div class="page">
    <p>Parallel Recovery</p>
    <p>Checkpoint state datasets periodically  If a node fails/straggles, recompute its dataset</p>
    <p>partitions in parallel on other nodes map</p>
    <p>input dataset</p>
    <p>Faster recovery than upstream backup, without the cost of replication</p>
    <p>output dataset</p>
  </div>
  <div class="page">
    <p>How Fast Can It Go?</p>
    <p>Prototype built on the Spark in-memory computing engine can process 2 GB/s (20M records/s) of data on 50 nodes at sub-second latency</p>
    <p>st er</p>
    <p>T h</p>
    <p>ro u</p>
    <p>g h</p>
    <p>p u</p>
    <p>t (G</p>
    <p>B /s</p>
    <p>)</p>
    <p># of Nodes in Cluster</p>
    <p>Grep</p>
    <p>st er</p>
    <p>T h</p>
    <p>ro u</p>
    <p>g h</p>
    <p>p u</p>
    <p>t (G</p>
    <p>B /s</p>
    <p>)</p>
    <p># of Nodes in Cluster</p>
    <p>WordCount</p>
    <p>st er</p>
    <p>T h</p>
    <p>ro u</p>
    <p>g h</p>
    <p>p u</p>
    <p>t (G</p>
    <p>B /s</p>
    <p>)</p>
    <p># of Nodes in Cluster</p>
    <p>Grep</p>
    <p>st er</p>
    <p>T h</p>
    <p>ro u</p>
    <p>g h</p>
    <p>p u</p>
    <p>t (G</p>
    <p>B /s</p>
    <p>)</p>
    <p># of Nodes in Cluster</p>
    <p>WordCount</p>
    <p>Max throughput within a given latency bound (1 or 2s)</p>
  </div>
  <div class="page">
    <p>How Fast Can It Go?</p>
    <p>Recovers from failures within 1 second</p>
    <p>Failure Happens</p>
    <p>In te</p>
    <p>rv al</p>
    <p>P ro</p>
    <p>ce ss</p>
    <p>in g</p>
    <p>T</p>
    <p>im e</p>
    <p>(s )</p>
    <p>Time (s)</p>
    <p>Sliding WordCount on 10 nodes with 30s checkpoint interval</p>
  </div>
  <div class="page">
    <p>Programming Model</p>
    <p>A discretized stream (D-stream) is a sequence of immutable, partitioned datasets  Specifically, resilient distributed datasets (RDDs),</p>
    <p>the storage abstraction in Spark</p>
    <p>Deterministic transformations operators produce new streams</p>
  </div>
  <div class="page">
    <p>API</p>
    <p>LINQ-like language-integrated API in Scala  New stateful operators for windowing pageViews = readStream(&quot;...&quot;, &quot;1s&quot;) !</p>
    <p>ones = pageViews.map(ev =&gt; (ev.url, 1)) !</p>
    <p>counts = ones.runningReduce(_ + _) !</p>
    <p>t = 1:</p>
    <p>t = 2:</p>
    <p>pageViews! ones ! counts !</p>
    <p>map reduce</p>
    <p>. . .</p>
    <p>= RDD = partition</p>
    <p>Scala function literal</p>
    <p>sliding = ones.reduceByWindow( ! 5s, _ + _, _ - _) !</p>
    <p>Incremental version with add and subtract functions</p>
  </div>
  <div class="page">
    <p>Other Benefits of Discretized Streams</p>
    <p>Consistency: each record is processed atomically</p>
    <p>Unification with batch processing:  Combining streams with historical data</p>
    <p>! pageViews.join(historicCounts).map(...) !</p>
    <p>Interactive ad-hoc queries on stream state ! pageViews.slice(21:00, 21:05).topK(10)</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>D-Streams forgo traditional streaming wisdom by batching data in small timesteps</p>
    <p>Enable efficient, new parallel recovery scheme</p>
    <p>Let users seamlessly intermix streaming, batch and interactive queries</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>Bulk incremental processing (CBP, Comet)  Periodic (~5 min) batch jobs on Hadoop/Dryad  On-disk, replicated FS for storage instead of RDDs</p>
    <p>Hadoop Online  Does not recover stateful ops or allow multi-stage jobs</p>
    <p>Streaming databases  Record-at-a-time processing, generally replication for FT</p>
    <p>Parallel recovery (MapReduce, GFS, RAMCloud, etc)  Hwang et al [ICDE07] have a parallel recovery protocol for</p>
    <p>streams, but only allow 1 failure &amp; do not handle stragglers</p>
  </div>
  <div class="page">
    <p>Timing Considerations</p>
    <p>D-streams group input into intervals based on when records arrive at the system</p>
    <p>For apps that need to group by an external time and tolerate network delays, support:  Slack time: delay starting a batch for a short fixed</p>
    <p>time to give records a chance to arrive  Application-level correction: e.g. give a result for</p>
    <p>time t at time t+1, then use later records to update incrementally at time t+5</p>
  </div>
  <div class="page">
    <p>D-Streams vs. Traditional Streaming</p>
    <p>Concern Discretized Streams Record-at-a-time Systems</p>
    <p>Latency 0.52s 1-100 ms</p>
    <p>Consistency Yes, batch-level Not in msg. passing systems; some DBs use waiting</p>
    <p>Failures Parallel recovery Replication or upstream bkp.</p>
    <p>Stragglers Speculation Typically not handled</p>
    <p>Unification with batch</p>
    <p>Ad-hoc queries from Spark shell, join w. RDD</p>
    <p>Not in msg. passing systems; in some DBs</p>
  </div>
</Presentation>
