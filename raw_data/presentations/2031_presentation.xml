<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Institute for Software Integrated Systems Vanderbilt University</p>
    <p>Xingyu Zhou, Robert Canady, Shunxing Bao, Aniruddha Gokhale DOC-VU Group, Dept of EECS</p>
    <p>Vanderbilt University, Nashville, TN 37235</p>
    <p>Cost-effective Hardware Accelerator Recommendation for Edge Computing</p>
  </div>
  <div class="page">
    <p>Outline  Current Edge HW Acc Status  Challenge for HW Acc Deployment  Solution Overview  Case Study  Conclusion</p>
  </div>
  <div class="page">
    <p>What are HW Accelerators?  Accelerating computations  For general or specific task settings</p>
    <p>CPU (most general) GPU (better suited for stream processing) FPGA (general in thoery but difficult to use) ASIC (specific)</p>
  </div>
  <div class="page">
    <p>Why Hardware Accelerators on Edge?</p>
    <p>Heterogeneous data sources from sensors;  More compute intense processing requirements</p>
    <p>especially from image or video;  Realistic physical constraints(power,size,cost. etc)</p>
  </div>
  <div class="page">
    <p>Challenge: which accelerator is best suited for application needs?</p>
    <p>Too many different hardware devices potential for edge</p>
    <p>+  Current selection and evaluation research either single device or</p>
    <p>even low-level circuit design</p>
    <p>=  Need to understand applicability of these accelerator technologies</p>
    <p>for at-scale, edge-based applications</p>
  </div>
  <div class="page">
    <p>Metrics for HW Acceleration Evaluation</p>
    <p>Latency =&gt; Application Response  Power =&gt; Electricity Cost  Commercial Cost =&gt; Market Price</p>
    <p>V. Sze, T.-J. Yang, Y.-H. Chen, J. Emer, &quot;Efficient Processing of Deep Neural Networks: A Tutorial and Survey,&quot; Proceedings of the IEEE, vol. 105, no. 12, pp. 2295-2329, December 2017.</p>
  </div>
  <div class="page">
    <p>Overall Goal for HW Selection</p>
    <p>Define One HW Acceleration Strategy: (1) HW Acceleration Task Realization on Device (2) HW Acceleration Device Placement (location,time)</p>
    <p>Minimize deployment cost under constraints Current goal: minimize cost with design latency limit</p>
  </div>
  <div class="page">
    <p>Cost Evaluation Workflow Part I 1. Application design</p>
    <p>choose applications that can be accelerated ResNet50 (Classification) + TinyYolo (Detection)</p>
  </div>
  <div class="page">
    <p>Cost Evaluation Workflow Part II 3. Per-Device Benchmarking</p>
    <p>record time and power consumption 4. Deployment Cost Approximation</p>
    <p>= devCost (hardware market price) + deployCost (for design topology and time cycle)</p>
  </div>
  <div class="page">
    <p>Per-device Applicability Validation Applicability Test on Relative High Dimension Data: Object Classification tasks on a set of 500 images with a resolution of 640  480. Vehicle Detection tasks on a road traffic video consisting of 874 frames with a resolution of 1280  720.</p>
  </div>
  <div class="page">
    <p>At-Scale Approximatation</p>
    <p>Design Topology Potential Scenarios: 1. unmanned shopping using object</p>
    <p>classification 2. surveillance using detection</p>
    <p>Reliability-Driven System Deployment Goal: 1. should guarantee to handle no less than</p>
    <p>half (2 of 4) of input loads from every fog group (3 groups) with an overall confidence level of 99%</p>
  </div>
  <div class="page">
    <p>At-Scale Approximatation</p>
    <p>Bandwidth Setting: standard IEEE802 Wifi with 135Mbps</p>
  </div>
  <div class="page">
    <p>At-Scale Approximatation Settings: Increasing input strength for a 24-month deployment cycle</p>
    <p>Ultra96 (FPGA) Jetson Nano (embedded GPU)</p>
  </div>
  <div class="page">
    <p>Summary &amp; Limitations</p>
    <p>Presents a simple evaluation procedure as a recommendation system to help users select an accelerator hardware device for their applications deployed across the cloud to edge spectrum</p>
    <p>Cons: 1. A pure strategy of one single type of device is considered 2. One single type of acceleration task is set for all devices Plan to investigate at-scale deployment of RNN and GAN in edge scenarios; 3. Assume an ideal device task scheduling and device parallelism 4. Have not taken interference effects between device executions into consideration</p>
  </div>
  <div class="page">
    <p>Thank You! Q&amp;A</p>
  </div>
</Presentation>
