<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Reliable Writeback for Client-Side Flash Caches</p>
    <p>Dai Qin, Angela Demke Brown, Ashvin Goel University of Toronto</p>
  </div>
  <div class="page">
    <p>Client-Side SSD Caching  Data centers using</p>
    <p>centralized storage for ease of management</p>
    <p>SSD is used as caching layer on client side  Hides network latency  Reduces storage contention  Provides good throughput</p>
    <p>for price Centralized Storage</p>
    <p>Network</p>
  </div>
  <div class="page">
    <p>Client-Side Caching Architecture</p>
    <p>Block layer read/write request</p>
    <p>Network hit miss</p>
    <p>Map</p>
    <p>Storage LBA Cache LBA</p>
    <p>A B</p>
    <p>SSD A B</p>
    <p>Centralized Storage</p>
    <p>Client Side</p>
  </div>
  <div class="page">
    <p>Write-through  Writes are sent to storage synchronously</p>
    <p>Reliable but writes have high latency</p>
    <p>Write-back  Writes are acknowledged to application once</p>
    <p>they are cached on SSD, dirty cache blocks are sent to storage asynchronously</p>
    <p>Reduces write latency but unreliable  Client failure can cause data inconsistency &amp; loss</p>
    <p>Write-Back Caching</p>
  </div>
  <div class="page">
    <p>Destructive failure</p>
    <p>SSD device destroyed  Example: fire</p>
    <p>Problem: dirty blocks on SSD cache are lost</p>
    <p>Result: storage may be inconsistent</p>
    <p>Types of Client Failures</p>
    <p>Centralized Storage</p>
    <p>Network</p>
  </div>
  <div class="page">
    <p>Recoverable Failure</p>
    <p>Data on SSD device available on recovery  Example: power failure</p>
    <p>Problem: recovery requires a persistent mapping  Converts every write into 2</p>
    <p>writes to SSD</p>
    <p>Types of Client Failures</p>
    <p>Storage LBA Cache LBA</p>
    <p>A1 B</p>
    <p>SSD A B</p>
    <p>Network</p>
  </div>
  <div class="page">
    <p>Our Contributions  Goal: provide consistency and durability for</p>
    <p>client-side, write-back caching</p>
    <p>Consistency: all data written until some point in time is available after failure</p>
    <p>Durability: data confirmed as written is not lost after failure</p>
    <p>Results for write-intensive workloads:  20-70% higher IOPS than write-through, with</p>
    <p>same reliability  Same IOPS as write-back, so long as SSD device</p>
    <p>does not fail permanently</p>
  </div>
  <div class="page">
    <p>Storage Interface</p>
    <p>Time</p>
    <p>Read0 Write1 Write2 Cache Flush</p>
    <p>Cache Flush</p>
    <p>Epoch</p>
    <p>Disk</p>
  </div>
  <div class="page">
    <p>Overview of Our Approach  Two policies</p>
    <p>Write-Back Flush for destructive failures  Write-Back Persist for recoverable failures</p>
    <p>Insight: caching system should provide exactly the same storage interface as physical device</p>
    <p>Benefits  Storage applications get the same consistency</p>
    <p>and durability guarantees transparently  System is efficient because it provides minimal</p>
    <p>guarantees</p>
  </div>
  <div class="page">
    <p>Write-Back Flush Policy  On read and write, similar to write</p>
    <p>back  All writes are cached on SSD device</p>
    <p>Dirty blocks are sent to storage asynchronously</p>
    <p>On cache flush command  Flush all remaining dirty</p>
    <p>blocks to storage</p>
    <p>Storage LBA Cache LBA</p>
    <p>A1 B</p>
    <p>SSD A B</p>
    <p>Storage LBA Cache LBA</p>
    <p>A1 A1</p>
  </div>
  <div class="page">
    <p>Write-Back Persist Policy  On read and write, similar to</p>
    <p>write-back  All writes are cached on SSD</p>
    <p>device  Dirty blocks are sent to</p>
    <p>storage asynchronously</p>
    <p>On cache flush  Persist mapping to SSD</p>
    <p>atomically</p>
    <p>Storage LBA Cache LBA</p>
    <p>A1 B</p>
    <p>SSD A B</p>
    <p>Storage LBA Cache LBA</p>
  </div>
  <div class="page">
    <p>Write-back Flush vs. Persist</p>
    <p>Reliability Latency</p>
    <p>Recoverable Failure</p>
    <p>Destructive Failure</p>
    <p>Write Flush</p>
    <p>Write Through Yes Yes High Low</p>
    <p>Write-back Flush Yes Yes Low High</p>
    <p>Write-back Persist Yes No Low Low</p>
    <p>Write Back No No Low None</p>
  </div>
  <div class="page">
    <p>Design and Implementation  Use copy-on-write BTree for the mapping table</p>
    <p>Table is persisted to SSD device  Atomically for correctness  Incrementally and sequentially for efficiency</p>
    <p>Optimizations  Ascending order flushing  Epoch-based flushing</p>
    <p>Other details described in the paper</p>
  </div>
  <div class="page">
    <p>Evaluation - Setup</p>
    <p>iSCSI storage server</p>
    <p>Software RAID 6 13 Hitachi disks, 7200 RPM</p>
    <p>Client</p>
  </div>
  <div class="page">
    <p>Workloads  webserver: read heavy</p>
    <p>Small config: 4GB  Large config: 14GB</p>
    <p>ms_nfs: write heavy  Small config: 6.5GB, 87% writes  Large config: 22GB, 57% writes</p>
    <p>varmail: sync heavy  Size: 4GB  50-100 random writes between syncs</p>
    <p>Experiment  Run for 20 minutes  Measured IOPS in the last 10 minutes of run</p>
  </div>
  <div class="page">
    <p>Comparing Write Policies</p>
  </div>
  <div class="page">
    <p>Designed and implemented a client-side SSD caching system  Uses a write-back caching policy for performance  Provides the same consistency and durability</p>
    <p>guarantees as underlying storage by leveraging write barriers issued by applications</p>
    <p>Designed two policies  Flush policy works for destructive and</p>
    <p>recoverable failure  Persist policy works for recoverable failure,</p>
    <p>improving performance over flush policy</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Thanks</p>
  </div>
</Presentation>
