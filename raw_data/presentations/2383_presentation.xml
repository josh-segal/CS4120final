<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Laboratory for Education and Research in Secure Systems Engineering (LERSSE)</p>
    <p>Networked Systems Laboratory (NetSysLab)</p>
    <p>Department of Electrical &amp; Computer Engineering</p>
    <p>Key Challenges in Defending Against</p>
    <p>Malicious Socialbots</p>
    <p>Yazan Boshmaf, Ildar Muslukhov, Konstantin Beznosov, Matei Ripeanu</p>
    <p>Posi%on Paper</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Problem Motivation</p>
    <p>Socialbots</p>
    <p>OSN Security Challenges</p>
  </div>
  <div class="page">
    <p>Problem Motivation</p>
  </div>
  <div class="page">
    <p>Reaching Out to Millions</p>
    <p>Obama Raised Half a Billion Online in 2008</p>
  </div>
  <div class="page">
    <p>Mobilizing the Masses</p>
    <p>Photo credit: Peter Macdiarmid, Getty Images Photo credit: Steve Crisp, Reuters</p>
    <p>The Arab Spring, January 2011 - Now</p>
    <p>Salem et al. Civil movements: The impact of Facebook and Twitter. The Arab Social Media Report, 2011</p>
  </div>
  <div class="page">
    <p>Predicting the Future: Elections</p>
    <p>YouGov Tweetminster Actual</p>
    <p>Conservative Lib Dem Labour</p>
    <p>Twitter elections predictions (Tweetminster) outperform market research (YouGov)</p>
    <p>(Source: Jemima Koss, The Guardian, May 2010)</p>
  </div>
  <div class="page">
    <p>TABLE I MULTIPLE REGRESSION RESULTS FOR OPINIONFINDER VS. 6 GPOMS</p>
    <p>MOOD DIMENSIONS.</p>
    <p>Parameters Coeff. Std.Err. t p Calm (X1) 1.731 1.348 1.284 0.20460 Alert (X2) 0.199 2.319 0.086 0.932 Sure (X3) 3.897 0.613 6.356 4.25e-08 ? ? ? Vital (X4) 1.763 0.595 2.965 0.004?? Kind (X5) 1.687 1.377 1.226 0.226</p>
    <p>Happy (X6) 2.770 0.578 4.790 1.30e-05 ?? Summary Residual Std.Err Adj.R2 F6,55 p</p>
    <p>Calm, Alert, Sure, Vital, Kind and Happy. The multiple linear regression results are provided in</p>
    <p>Table I (coefficient and p-values), and indicate that YOF is significantly correlated with X3 (Sure), X4 (Vital) and X6 (Happy), but not with X1 (Calm), X2 (Alert) and X5 (Kind). We therefore conclude that certain GPOMS mood dimension partially overlap with the mood values provided by OpinionFinder, but not necessarily all mood dimensions that may be important in describing the various components of public mood e.g. the varied mood response to the Presidential election. The GPOMS thus provides a unique perspective on public mood states not captured by uni-dimensional tools such as OpinionFinder.</p>
    <p>D. Bivariate Granger Causality Analysis of Mood vs. DJIA prices</p>
    <p>After establishing that our mood time series responds to significant socio-cultural events such as the Presidential election and Thanksgiving, we are concerned with the question whether other variations of the publics mood state correlate with changes in the stock market, in particular DJIA closing values. To answer this question, we apply the econometric technique of Granger causality analysis to the daily time series produced by GPOMS and OpinionFinder vs. the DJIA. Granger causality analysis rests on the assumption that if a variable X causes Y then changes in X will systematically occur before changes in Y . We will thus find that the lagged values of X will exhibit a statistically significant correlation with Y . Correlation however does not prove causation. We therefore use Granger causality analysis in a similar fashion to [10]; we are not testing actual causation but whether one time series has predictive information about the other or not7.</p>
    <p>Our DJIA time series, denoted Dt, is defined to reflect daily changes in stock market value, i.e. its values are the delta between day t and day t  1: Dt = DJIAt  DJIAt1. To test whether our mood time series predicts changes in stock market values we compare the variance explained by two linear models as shown in Eq. 3 and Eq. 4. The first model (L1) uses only n lagged values of Dt, i.e. (Dt1,    , Dtn) for prediction, while the second model L2 uses the n lagged values of both Dt and the GPOMS plus the OpinionFinder mood time series denoted Xt1,    , Xtn.</p>
    <p>We perform the Granger causality analysis according to model L1 and L2 shown in Eq. 3 and 4 for the period of time between February 28 to November 3, 2008 to exclude the exceptional public mood response to the Presidential Election and Thanksgiving from the comparison. GPOMS and OpinionFinder time series were produced for 342,255 tweets in that period, and the daily Dow Jones Industrial Average (DJIA) was retrieved from Yahoo! Finance for each day8.</p>
    <p>L1 : Dt =  + nX</p>
    <p>i=1</p>
    <p>iDti + t (3)</p>
    <p>L2 : Dt =  + nX</p>
    <p>i=1</p>
    <p>iDti + nX</p>
    <p>i=1</p>
    <p>iXti + t (4)</p>
    <p>Based on the results of our Granger causality (shown in Table II), we can reject the null hypothesis that the mood time series do not predict DJIA values, i.e. {1,2, ,n} 6= 0 with a high level of confidence. However, this result only applies to 1 GPOMS mood dimension. We observe that X1 (i.e. Calm) has the highest Granger causality relation with DJIA for lags ranging from 2 to 6 days (p-values &lt; 0.05). The other four mood dimensions of GPOMS do not have significant causal relations with changes in the stock market, and neither does the OpinionFinder time series.</p>
    <p>To visualize the correlation between X1 and the DJIA in more detail, we plot both time series in Fig. 3. To maintain the same scale, we convert the DJIA delta values Dt and mood index value Xt to z-scores as shown in Eq. 1.</p>
    <p>-2</p>
    <p>-1</p>
    <p>D J IA</p>
    <p>z -s</p>
    <p>c o</p>
    <p>re</p>
    <p>Aug 09 Aug 29 Sep 18 Oct 08 Oct 28</p>
    <p>-2</p>
    <p>-1</p>
    <p>-2</p>
    <p>-1</p>
    <p>-2</p>
    <p>-1</p>
    <p>D J IA</p>
    <p>z -s</p>
    <p>c o</p>
    <p>re C</p>
    <p>a lm</p>
    <p>z -s</p>
    <p>c o</p>
    <p>re</p>
    <p>C a</p>
    <p>lm z</p>
    <p>-s c o re</p>
    <p>bank</p>
    <p>bail-out</p>
    <p>Fig. 3. A panel of three graphs. The top graph shows the overlap of the day-to-day difference of DJIA values (blue: ZDt ) with the GPOMS Calm time series (red: ZXt ) that has been lagged by 3 days. Where the two graphs overlap the Calm time series predict changes in the DJIA closing values that occur 3 days later. Areas of significant congruence are marked by gray areas. The middle and bottom graphs show the separate DJIA and GPOMS Calm time series.</p>
    <p>As can be seen in Fig. 3 both time series frequently overlap or point in the same direction. Changes in past values of Calm (t  3 ) predicts a similar rise or fall in DJIA values (t =</p>
    <p>Predicting the Future: Markets</p>
    <p>Twitter mood (Calm) predicts Dow Jones Industrial Average (DJIA)</p>
    <p>Bollen et al. Twitter mood predicts the stock market. J. Comp. Sc. March, 2011.</p>
    <p>Day-to-day Overlap</p>
    <p>Calm lagged by 3 days</p>
  </div>
  <div class="page">
    <p>Socialbots</p>
  </div>
  <div class="page">
    <p>Bots and Socialbots</p>
    <p>+ Automation</p>
    <p>software (to pass off as human)</p>
    <p>Social media account</p>
    <p>Socialbot</p>
    <p>Computer program used to perform highly repetitive operations (AI?)</p>
  </div>
  <div class="page">
    <p>Rise of the Socialbots</p>
    <p>The Web Ecology Project (Social Engineering), 2011</p>
    <p>Zack Coburn and Greg Marra, Olin College, 2010</p>
    <p>ACM Interactions Magazine Cover Story, April 2012</p>
  </div>
  <div class="page">
    <p>Misusing Socialbots on a Large Scale?</p>
    <p>Infiltration Misinformation Data collection</p>
    <p>An automated social engineering tool for:</p>
    <p>Boshmaf et al. The Socialbot Network: When Bots Socialize for Fame and Money. ACSAC11</p>
  </div>
  <div class="page">
    <p>OSN Security</p>
  </div>
  <div class="page">
    <p>Tolerate Socialbots</p>
  </div>
  <div class="page">
    <p>Adversarial Machine Learning</p>
    <p>Facebook Immune System</p>
    <p>Tao Stein Facebook</p>
    <p>stein@fb.com</p>
    <p>Erdong Chen Facebook</p>
    <p>rogerc@fb.com</p>
    <p>Karan Mangla Facebook</p>
    <p>kmangla@fb.com</p>
    <p>Abstract Popular Internet sites are under attack all the time from phishers, fraudsters, and spammers. They aim to steal user information and expose users to unwanted spam. The attackers have vast resources at their disposal. They are well-funded, with full-time skilled labor, control over compromised and infected accounts, and access to global botnets. Protecting our users is a challenging adversarial learning problem with extreme scale and load requirements. Over the past several years we have built and deployed a coherent, scalable, and extensible realtime system to protect our users and the social graph. This Immune System performs realtime checks and classifications on every read and write action. As of March 2011, this is 25B checks per day, reaching 650K per second at peak. The system also generates signals for use as feedback in classifiers and other components. We believe this system has contributed to making Facebook the safest place on the Internet for people and their information. This paper outlines the design of the Facebook Immune System, the challenges we have faced and overcome, and the challenges we continue to face.</p>
    <p>Keywords Machine Learning, Adversarial Learning, Security, Social Network Security</p>
    <p>Algorithmically, protecting the graph is an adversarial learning problem. Adversarial learning differs from more traditional learning in one important way: the attacker creating the pattern does not want the pattern to be learned. For many learning problems the pattern creator wants better learning and the interests of the learner and the pattern creator are aligned and the pattern creator may even be oblivious to the efforts of the learner. For example, the receiver of ranked search results wants better search ranking and may be oblivious to the efforts being done to improve ranking. The pattern creator will not actively work to subvert the learning and may even</p>
    <p>Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. EuroSys Social Network Systems (SNS) 2011 April 10, 2011, Salzburg Copyright c 2011 ACM Jan 1, 2011. . . $10.00</p>
    <p>voluntarily give hints to aid learning. In adversarial learning, the attacker works to hide patterns and subvert detection. To be effective, the system must respond fast and target the features that are most expensive for the attacker to change, being careful also not to overfit on the superficial features that are easy for the attacker to change.</p>
    <p>Attacker Detects</p>
    <p>Defender Responds</p>
    <p>Begin Attack</p>
    <p>Initial Detection</p>
    <p>Attacker Controls</p>
    <p>Defender Controls</p>
    <p>Attack Detect</p>
    <p>Defense Mutate</p>
    <p>Figure 1. The adversarial cycle. This diagram shows the adversarial cycle. The attacker controls the upper phases and the defender controls the bottom phases. In both Attack and Detect phases the attacker is only limited by its own resources and global ratelimits. During Attack, the attack has not yet been detected and is largely unfettered. During Detect, the attack has been detected but the system is forming a coherent response. This includes the time to train a model or expand the set of bad attack vectors and upload the patterns to online classifier services. The response can form continuously with some models being deployed earlier than others. During Defense, the attack has been rendered ineffective. The attacker may eventually detect this and begin Mutate to work around the defense mechanism. This cycle can repeat indefinitely. The defender seeks to shorten Attack and Detect while lengthening Defense and Mutate. The attacker seeks the opposite, to shorten the bottom phases while lengthening Attack and Detect. This cycle illustrates why detection and response latencies are so important for effective defense.</p>
    <p>Adversarial learning is a cyclical process shown in Figure 1. An example will make the process more concrete. Several years ago phishers would attack the graph using spammy messages with predictable subject lines. The messages included links to phishing sites. They sent out these messages repeatedly from compromised accounts to hundreds of friends of the compromised accounts. The predictable text patterns and volume made these straightforward to detect and filter. To overcome this filtering, attackers obfuscated by inserting punctuation, HTML tags, and images into their messages. As well, the attackers varied their distribution channels to evade detection. The system responded to this by using mark as spam feed</p>
  </div>
  <div class="page">
    <p>Graph-theoretic Defense Techniques</p>
    <p>Honest region</p>
    <p>Sybil region</p>
    <p>Attack edges</p>
    <p>Sybil detection via social networks1</p>
    <p>With adversary running large-scale infiltration2</p>
    <p>Honest node</p>
  </div>
  <div class="page">
    <p>Prevent Socialbots</p>
  </div>
  <div class="page">
    <p>Observation: Its all about automation Prevent it and the socialbot threat will go away (almost surely) Not an easy job!</p>
  </div>
  <div class="page">
    <p>Challenges</p>
    <p>Solve at least one</p>
  </div>
  <div class="page">
    <p>OSN Vulnerabilities: Ineffective CAPTCHAs</p>
  </div>
  <div class="page">
    <p>OSN Vulnerabilities: Ineffective CAPTCHAs</p>
    <p>Koobface Botnet CAPTCHA-solving businesses</p>
    <p>Motoyama et al. Re: CAPTCHAs-Understanding CAPTCHA-Solving Services in an Economic Context. Usenix Security, 2010 Baltazar et al. The Real Face of Koobface: The Largest Web2.0 Botnet Explained. Trend Micro Threat Research, 2009</p>
  </div>
  <div class="page">
    <p>OSN Vulnerabilities: Ineffective CAPTCHAs</p>
    <p>Koobface Botnet CAPTCHA-solving businesses</p>
    <p>Motoyama et al. Re: CAPTCHAs-Understanding CAPTCHA-Solving Services in an Economic Context. Usenix Security, 2010 Baltazar et al. The Real Face of Koobface: The Largest Web2.0 Botnet Explained. Trend Micro Threat Research, 2009</p>
  </div>
  <div class="page">
    <p>#1</p>
    <p>Design a reverse Turing test that is usable and effective even against illegitimate human solvers</p>
  </div>
  <div class="page">
    <p>How about Social Authentication?</p>
    <p>An'Example' Use personal social knowledge to challenge users</p>
    <p>Kim et al. Social authentication: Harder than it looks. FC12</p>
  </div>
  <div class="page">
    <p>Histogram'of'A\ack'Advantage' When'the'number'of'challenge'images'is'1,'</p>
    <p>many'people'are'vulnerable'to'impersona.on.'</p>
    <p>Even'for'5'challenge'images,'</p>
    <p>some'people'can'be'impersonated'with'probability'100%.'</p>
    <p>Kim et al. Social authentication: Harder than it looks. FC12</p>
  </div>
  <div class="page">
    <p>OSN Vulnerabilities: Fake (Sybil) User Accounts and Profiles</p>
  </div>
  <div class="page">
    <p>#2</p>
    <p>Guarantee an anonymous, yet credible, online-offline identity binding in online and open-access systems</p>
  </div>
  <div class="page">
    <p>How can we deal with Sybils?</p>
    <p>Centralized trusted authority</p>
    <p>Tie identities to resources</p>
    <p>Use external information</p>
  </div>
  <div class="page">
    <p>OSN Vulnerabilities: Large-Scale Network Crawls</p>
  </div>
  <div class="page">
    <p>#3</p>
    <p>Effectively limit large-scale Sybil crawls of OSNs without restricting users social experience.</p>
  </div>
  <div class="page">
    <p>How about using a credit network?</p>
    <p>A B 5</p>
    <p>F G</p>
    <p>Fig. 5. More complex credit network, with credit available (cij ) shown for each link. In this example, A can transfer 1 credit to D along the path A ! B ! C ! D. Note that, for simplicity, the links not on this path are only shown as dashed lines.</p>
    <p>can be used for payments between nodes that do not directly extend credit to each other. For this purpose, nodes can route credit to a node via network paths that traverse over links with available credit. (See Figures 4 and 5.)</p>
    <p>Formally, a credit network is a directed graph G = (V, E) where V is the set of nodes and E is the set of labeled edges. Each directed edge (a, b) ! E is labeled with a dynamic scalar value cab, called the credit available, and is initialized to Cab. Intuitively, Cab represents the initial credit allocation that b gives to a, and cab represents the amount of unconsumed credit that b has extended to a. Note that cab &quot; 0 at all times.</p>
    <p>Transactions between two nodes in a credit network are contingent upon the availability of credit along network paths connecting the nodes. If a node a wishes to obtain a favor or resource from b, then a path</p>
    <p>a # u1 # ... # un # b</p>
    <p>(which could just be a # b) must exist where credits are available on each (i, j) link (i.e., cij &gt; 0). If so, the credit available on each directed edge cij on the path from a to b is decreased and the credit available on each directed edge cji on the reverse path is increased. As a result of this action, each node pays credits to its successor on the path to b, in exchange for the favor or service a obtains from b.</p>
    <p>Further, each directed edge, (a, b), is assigned an initial credit allocation Cab by the destination node b. The system must exercise care when assigning credit allocations. For instance, when a new social link is created, the requesting node should be required to grant the accepting node some initial credit but not vice-versa, to prevent an attacker from obtaining credit by initiating social links.</p>
    <p>X</p>
    <p>X2</p>
    <p>X3</p>
    <p>Rest of the network</p>
    <p>Fig. 6. Credit networks leading to Sybil tolerance. User X can create any number of identities (X1, X2, X3) and arbitrarily assign the credit available between them. However, does not enable any additional available credit with nodes in the rest of the network.</p>
    <p>tolerant to Sybil attacks. Specifically, we argue that a Sybil attacker cannot increase the credit available to her from the rest of the network.</p>
    <p>An attacker can mount a Sybil attack by creating many different identities in the social network, each corresponding to a different node in the credit network. However, per our assumptions about credit assignment to links, having many user accounts does not by itself allow the attacker to obtain additional available credit with other users (though she can create an arbitrary number of links with arbitrary credit between her Sybil identities).</p>
    <p>As shown in Figure 6, the total amount of credit available to a single user is the sum of the credit available on her links to other (human) users. An attacker with an arbitrary number of Sybil identities has exactly the same available credit as the attacker with just one identity; in this case, the relevant set of edges is the cut between the subgraph consisting of the attackers Sybil identities and the rest of the network. Any credit available on edges between the attackers Sybil identities does not matter, because it does not enable additional purchases from legitimate nodes. Thus, available credit in a credit network is resilient to Sybil attacks [27].</p>
    <p>C. Challenges building credit network-based Sybil tolerance</p>
    <p>We now discuss the key challenges associated with building credit network-based Sybil tolerance systems. This includes</p>
    <p>Well-behaved nodes Misbehaving (possibly Sybil) nodes</p>
    <p>Edge cut</p>
    <p>Fig. 7. Edge cut between well-behaved nodes (hollow) and misbehaving nodes (solid). The total credit available to the misbehaving nodes is 5 (3+2), regardless of the number of Sybil identities created. Note that the links that are not along the edge cut are shown as dashed lines, for simplicity.</p>
  </div>
  <div class="page">
    <p>A B 5</p>
    <p>F G</p>
    <p>Fig. 5. More complex credit network, with credit available (cij ) shown for each link. In this example, A can transfer 1 credit to D along the path A ! B ! C ! D. Note that, for simplicity, the links not on this path are only shown as dashed lines.</p>
    <p>can be used for payments between nodes that do not directly extend credit to each other. For this purpose, nodes can route credit to a node via network paths that traverse over links with available credit. (See Figures 4 and 5.)</p>
    <p>Formally, a credit network is a directed graph G = (V, E) where V is the set of nodes and E is the set of labeled edges. Each directed edge (a, b) ! E is labeled with a dynamic scalar value cab, called the credit available, and is initialized to Cab. Intuitively, Cab represents the initial credit allocation that b gives to a, and cab represents the amount of unconsumed credit that b has extended to a. Note that cab &quot; 0 at all times.</p>
    <p>Transactions between two nodes in a credit network are contingent upon the availability of credit along network paths connecting the nodes. If a node a wishes to obtain a favor or resource from b, then a path</p>
    <p>a # u1 # ... # un # b</p>
    <p>(which could just be a # b) must exist where credits are available on each (i, j) link (i.e., cij &gt; 0). If so, the credit available on each directed edge cij on the path from a to b is decreased and the credit available on each directed edge cji on the reverse path is increased. As a result of this action, each node pays credits to its successor on the path to b, in exchange for the favor or service a obtains from b.</p>
    <p>Further, each directed edge, (a, b), is assigned an initial credit allocation Cab by the destination node b. The system must exercise care when assigning credit allocations. For instance, when a new social link is created, the requesting node should be required to grant the accepting node some initial credit but not vice-versa, to prevent an attacker from obtaining credit by initiating social links.</p>
    <p>X</p>
    <p>X2</p>
    <p>X3</p>
    <p>Rest of the network</p>
    <p>Fig. 6. Credit networks leading to Sybil tolerance. User X can create any number of identities (X1, X2, X3) and arbitrarily assign the credit available between them. However, does not enable any additional available credit with nodes in the rest of the network.</p>
    <p>tolerant to Sybil attacks. Specifically, we argue that a Sybil attacker cannot increase the credit available to her from the rest of the network.</p>
    <p>An attacker can mount a Sybil attack by creating many different identities in the social network, each corresponding to a different node in the credit network. However, per our assumptions about credit assignment to links, having many user accounts does not by itself allow the attacker to obtain additional available credit with other users (though she can create an arbitrary number of links with arbitrary credit between her Sybil identities).</p>
    <p>As shown in Figure 6, the total amount of credit available to a single user is the sum of the credit available on her links to other (human) users. An attacker with an arbitrary number of Sybil identities has exactly the same available credit as the attacker with just one identity; in this case, the relevant set of edges is the cut between the subgraph consisting of the attackers Sybil identities and the rest of the network. Any credit available on edges between the attackers Sybil identities does not matter, because it does not enable additional purchases from legitimate nodes. Thus, available credit in a credit network is resilient to Sybil attacks [27].</p>
    <p>C. Challenges building credit network-based Sybil tolerance</p>
    <p>We now discuss the key challenges associated with building credit network-based Sybil tolerance systems. This includes</p>
    <p>Well-behaved nodes Misbehaving (possibly Sybil) nodes</p>
    <p>Edge cut</p>
    <p>Fig. 7. Edge cut between well-behaved nodes (hollow) and misbehaving nodes (solid). The total credit available to the misbehaving nodes is 5 (3+2), regardless of the number of Sybil identities created. Note that the links that are not along the edge cut are shown as dashed lines, for simplicity.</p>
    <p>Small edge cut</p>
    <p>Assump9on #1</p>
    <p>Assump9on #2</p>
  </div>
  <div class="page">
    <p>OSN Vulnerabilities: Exploitable Platforms and APIs</p>
  </div>
  <div class="page">
    <p>#4</p>
    <p>Detect abusive and automated usage of OSN platforms and their social APIs across the Internet</p>
  </div>
  <div class="page">
    <p>OSN Vulnerabilities: Poorly Designed Privacy/Security Controls</p>
  </div>
  <div class="page">
    <p>#5</p>
    <p>Develop usable OSN security and privacy controls that help users make more informed decisions</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Take-home message(s)  Large-scale infiltration is feasible</p>
    <p>has serious privacy and security implications</p>
    <p>Socialbots make it difficult for OSN security defenses and their users to detect their true nature  defending against such bots raises a set of</p>
    <p>unique challenges</p>
    <p>Effective, socio-technical defenses less vulnerable to both human and technical exploits are needed</p>
  </div>
  <div class="page">
    <p>Yazan Boshmaf</p>
    <p>Ildar Muslukhov</p>
    <p>Konstantin Beznosov</p>
    <p>Matei Ripeanu</p>
    <p>Key Challenges in Defending Against Malicious Socialbots</p>
    <p>Funded by:</p>
  </div>
  <div class="page">
    <p>Backup</p>
  </div>
  <div class="page">
    <p>Socialbot Network: Concept</p>
    <p>Botmaster</p>
    <p>C&amp;C Channel</p>
    <p>SocialBots</p>
    <p>Online Social Network</p>
    <p>BotHerder SocialBot</p>
    <p>Infiltrated user (randomly picked)</p>
    <p>Infiltrated user (with mutual friends)</p>
    <p>Boshmaf et al. The Socialbot Network: When Bots Socialize for Fame and Money. ACSAC11</p>
  </div>
  <div class="page">
    <p>Prototype Architecture</p>
    <p>Commands, Botcargo</p>
    <p>G ra</p>
    <p>p h A</p>
    <p>PI +</p>
    <p>H TT</p>
    <p>P</p>
    <p>Facebook Servers</p>
    <p>b1</p>
    <p>bi</p>
    <p>Socialbot</p>
    <p>API Wrapper</p>
    <p>HTTP Scraper</p>
    <p>Native Controller</p>
    <p>bi Botmaster</p>
    <p>BotUpdater</p>
    <p>C&amp;C Engine</p>
    <p>Master Controller</p>
    <p>Websites &amp; APIs</p>
    <p>Blurbs, Tokens</p>
    <p>bi</p>
    <p>Our Machine</p>
    <p>HTTP</p>
  </div>
  <div class="page">
    <p>Methodology</p>
    <p>Prototype on Facebook  102 Socialbots, single Botmaster  Operated for 8 weeks (Spring 2011)  Single machine</p>
    <p>Different IPs  HTTP proxy emulating different</p>
    <p>browsers and OSs  Approved by UBC ethics board</p>
  </div>
  <div class="page">
    <p>Most Users Decide Within Three Days</p>
    <p>N um</p>
    <p>be r o</p>
    <p>f p ro</p>
    <p>fil es</p>
    <p>Figure 3: Degree distribution of the generated random sample of Facebook user profiles.</p>
    <p>o f a</p>
    <p>cc ep</p>
    <p>te d</p>
    <p>re qu</p>
    <p>es ts</p>
    <p>(C D</p>
    <p>F)</p>
    <p>Figure 4: Cumulative distribution of number of days and accepted friendship requests.</p>
    <p>A cc</p>
    <p>ep ta</p>
    <p>nc e</p>
    <p>ra te</p>
    <p>(% )</p>
    <p>Figure 5: Overall infiltration as a function of number of mutual friends.</p>
    <p>We carefully designed our experiment in order to reduce any potential risk at the user side by following known practices [7], and got the approval of our universitys behavioral research ethics board. We strongly encrypted and properly anonymized all collected data, which we have completely deleted after we finished our planned data analysis.</p>
    <p>Each socialbot ran the same software and was equipped with only one native command; status_update. We implemented the generic operations described in Table 1 using two techniques: API calls and HTTP-request templates, which we now briefly describe. First, we exploited Facebooks Graph API [1] to carry out the social-interaction operations. The API, however, requires the user (i.e., the socialbot in this case) to be logged in to Facebook at the time of any API call. To avoid this, we developed a Facebook application that fetches permanent OAuth 2.0 access tokens that allow each socialbot to send API calls without the need to login. Second, for the social-structure operations, we used pre-recorded HTTP-request templates that allow each socialbot to send friendship requests as if they were sent from a browser. We used an API provided by iheartquotes.com to pull random quotes and blurbs which we used as messages for the status updates. As for the botmaster software, we implemented the botworker to interface with three useful websites: decaptcher.com; a CAPTCHA-breaking business, hotornot.com; a photo-sharing website, and mail.ru; an email provider. We also implemented the botupdater with an enhanced functionality to update the HTTP-request templates, along with any new native commands. Finally, we implemented all master commands described in Table 2.</p>
    <p>The master command rand_connect requires some extra attention. On Facebook, each profile has a unique ID that is represented by a 64-bit integer and is assigned at the time the profile is created. In order to get a uniform sample of Facebook profiles, we decided to use a simple random sampling technique called rejection sampling [34], which we now descirbe. First, we generated 64-bit integers at random, but with a range that is reduced to the known ID ranges used by Facebook [15]. Next, we tested whether each generated ID mapped to a real profile by probing the profile page using this ID. Finally, if the profile existed, we included the profile ID in the random sample only if this profile was not isolated. We define an isolated user profile as a profile that does not display its friends list or has no friends of Facebook.</p>
    <p>We deployed the simple two-state native controller and the</p>
    <p>three-phase, many-state master controller. We acknowledge, however, that more sophisticated controllers could be used that, for instance, employ some machine learning algorithms in order to improve the potential infiltration.</p>
    <p>bots were able to send a total of 8,570 friendship requests, out of which 3,055 requests were accepted by the infiltrated users. We divide the following discussion according to the three phases of the master controller.</p>
    <p>which are physically hosted on one machine for simplicity. A botherder, however, could resort to a more sophisticated deployment such as a P2P overlay network. Even though we could have built the socialbots automatically using the botworker, we decided to create them manually as we had no intention to support any CAPTCHA-breaking business. In total, we created 49 socialbots that had male user profiles (referred to as m-socialbots), and 53 socialbots that had female user profiles (referred to as f-socialbots).</p>
    <p>profile IDs. These IDs passed the inclusion criteria we discussed in Section 4.2. Figure 3 shows the degree distribution of this sample.4</p>
    <p>Based on a pilot study, we decided to send 25 friendship requests per socialbot per day in order to avoid CAPTCHAs. The socialbots took 2 days to send friendship requests to all of the 5, 053 profiles. In total, exactly 2, 391 requests were sent from m-socialbots and 2, 662 from f-socialbots. We kept monitoring the status of the requests for 6 days. Overall, 976 requests were accepted with an average acceptance rate of 19.3%. In particular, 381 of the accepted requests were sent from m-socialbots (15.9% acceptance rate), and 595 were sent from f-socialbots (22.3% acceptance rate). About 86% of the infiltrated profiles accepted the requests within the first three days of the requests being sent, as shown in Figure 4. Overall, the SbN spent two weeks in the bootstrapping phase. For most of that time, however, the SbN was setting idle.</p>
  </div>
  <div class="page">
    <p>Too Many Friends: Too Many Bots?</p>
    <p>f-socialbots m-socialbots</p>
    <p>N um</p>
    <p>be r o</p>
    <p>f p ro</p>
    <p>fil es</p>
    <p>Figure 4: Degree distribution of the generated random sample of Facebook user profiles during the bootstrapping phase, with a sample size of 5,053 valid profile identities.</p>
    <p>% o</p>
    <p>f a cc</p>
    <p>ep te</p>
    <p>d re</p>
    <p>qu es</p>
    <p>ts (C</p>
    <p>D F)</p>
    <p>Figure 5: Cumulative distribution function of number of days it took to observe a fraction of the overall accepted friendship requests during the bootstrapping phase.</p>
    <p>Number of mutual friends</p>
    <p>A cc</p>
    <p>ep ta</p>
    <p>nc e</p>
    <p>ra te</p>
    <p>(% )</p>
    <p>Figure 6: Average acceptance rate of the resulted infiltration as a function of the number of mutual friends the socialbots has with the infiltrated users. (95% conf.)</p>
    <p>Number of friends</p>
    <p>A cc</p>
    <p>ep ta</p>
    <p>nc e</p>
    <p>ra te</p>
    <p>(% )</p>
    <p>10</p>
    <p>Figure 7: Average acceptance rate as a function of the number of friends a user profile has during the bootstrapping phase. (for the requests sent by m-socialbots, 95% conf.)</p>
    <p>Number of friends</p>
    <p>A cc</p>
    <p>ep ta</p>
    <p>nc e</p>
    <p>ra te</p>
    <p>(% )</p>
    <p>10</p>
    <p>Figure 8: Average acceptance rate as a function of the number of friends a user profile has during the bootstrapping phase. (for the requests sent by f-socialbots, 95% conf.)</p>
    <p>Number of infiltrated profiles</p>
    <p>N um</p>
    <p>be r o</p>
    <p>f s oc</p>
    <p>ia lb</p>
    <p>ot s</p>
    <p>Figure 9: Distribution of the overall infiltration among the socialbots. A point in the figure represents how many socialbots infiltrated the corresponding number of user profiles.</p>
    <p>N um</p>
    <p>be r o</p>
    <p>f p ro</p>
    <p>fil es</p>
    <p>Figure 4: Degree distribution of the generated random sample of Facebook user profiles during the bootstrapping phase, with a sample size of 5,053 valid profile identities.</p>
    <p>% o</p>
    <p>f a cc</p>
    <p>ep te</p>
    <p>d re</p>
    <p>qu es</p>
    <p>ts (C</p>
    <p>D F)</p>
    <p>Figure 5: Cumulative distribution function of number of days it took to observe a fraction of the overall accepted friendship requests during the bootstrapping phase.</p>
    <p>Number of mutual friends</p>
    <p>A cc</p>
    <p>ep ta</p>
    <p>nc e</p>
    <p>ra te</p>
    <p>(% )</p>
    <p>Figure 6: Average acceptance rate of the resulted infiltration as a function of the number of mutual friends the socialbots has with the infiltrated users. (95% conf.)</p>
    <p>Number of friends A</p>
    <p>cc ep</p>
    <p>ta nc</p>
    <p>e ra</p>
    <p>te (%</p>
    <p>)</p>
    <p>10</p>
    <p>Figure 7: Average acceptance rate as a function of the number of friends a user profile has during the bootstrapping phase. (for the requests sent by m-socialbots, 95% conf.)</p>
    <p>Number of friends</p>
    <p>A cc</p>
    <p>ep ta</p>
    <p>nc e</p>
    <p>ra te</p>
    <p>(% )</p>
    <p>10</p>
    <p>Figure 8: Average acceptance rate as a function of the number of friends a user profile has during the bootstrapping phase. (for the requests sent by f-socialbots, 95% conf.)</p>
    <p>Number of infiltrated profiles</p>
    <p>N um</p>
    <p>be r o</p>
    <p>f s oc</p>
    <p>ia lb</p>
    <p>ot s</p>
    <p>Figure 9: Distribution of the overall infiltration among the socialbots. A point in the figure represents how many socialbots infiltrated the corresponding number of user profiles.</p>
  </div>
  <div class="page">
    <p>Mutual Friends Matter</p>
    <p>Bootstrapping 1 10 100 1000</p>
    <p>Number of friends</p>
    <p>N um</p>
    <p>be r o</p>
    <p>f p ro</p>
    <p>fil es</p>
    <p>Figure 4: Degree distribution of the generated random sample of Facebook user profiles during the bootstrapping phase, with a sample size of 5,053 valid profile identities.</p>
    <p>% o</p>
    <p>f a cc</p>
    <p>ep te</p>
    <p>d re</p>
    <p>qu es</p>
    <p>ts (C</p>
    <p>D F)</p>
    <p>Figure 5: Cumulative distribution function of number of days it took to observe a fraction of the overall accepted friendship requests during the bootstrapping phase.</p>
    <p>Number of mutual friends</p>
    <p>A cc</p>
    <p>ep ta</p>
    <p>nc e</p>
    <p>ra te</p>
    <p>(% )</p>
    <p>Figure 6: Average acceptance rate of the resulted infiltration as a function of the number of mutual friends the socialbots has with the infiltrated users. (95% conf.)</p>
    <p>Number of friends</p>
    <p>A cc</p>
    <p>ep ta</p>
    <p>nc e</p>
    <p>ra te</p>
    <p>(% )</p>
    <p>10</p>
    <p>Figure 7: Average acceptance rate as a function of the number of friends a user profile has during the bootstrapping phase. (for the requests sent by m-socialbots, 95% conf.)</p>
    <p>Number of friends</p>
    <p>A cc</p>
    <p>ep ta</p>
    <p>nc e</p>
    <p>ra te</p>
    <p>(% )</p>
    <p>10</p>
    <p>Figure 8: Average acceptance rate as a function of the number of friends a user profile has during the bootstrapping phase. (for the requests sent by f-socialbots, 95% conf.)</p>
    <p>Number of infiltrated profiles</p>
    <p>N um</p>
    <p>be r o</p>
    <p>f s oc</p>
    <p>ia lb</p>
    <p>ot s</p>
    <p>Figure 9: Distribution of the overall infiltration among the socialbots. A point in the figure represents how many socialbots infiltrated the corresponding number of user profiles.</p>
  </div>
  <div class="page">
    <p>Successful Infiltration is Team Work</p>
    <p>Figure 6: Data revelation of selected profile info before and after a large-scale infiltration.</p>
    <p>Number of friends</p>
    <p>A cc</p>
    <p>ep ta</p>
    <p>nc e</p>
    <p>ra te</p>
    <p>(% )</p>
    <p>m-socialbots f-socialbots</p>
    <p>Figure 7: Infiltration as a function of number of friends a user profile has.</p>
    <p>Number of infiltrated profiles</p>
    <p>um be</p>
    <p>r o f s</p>
    <p>oc ia</p>
    <p>lb ot</p>
    <p>s</p>
    <p>Figure 8: The distribution of number of infiltrated profiles among the socialbots.</p>
    <p>time, the socialbots added 3, 517 more user profiles from their extended neighborhoods, out of which 2, 079 profiles were successfully infiltrated. This resulted in an average acceptance rate of 59.1%, which, interestingly, depends on how many mutual friends the socialbots had with the infiltrated users, and can increase up to 80% as shown in Figure 5.</p>
    <p>By the end of the eighth week, we decided to take the SbN down as it resulted in a heavy trac with Facebook. In total, the SbN generated approximately 250GB inbound and 3GB outbound trac. We consider the operation time a conservative estimate of the real performance of the SbN as we paused it several times for debugging and data analysis, especially during the bootstrapping phase. We believe that operating the SbN for a longer time is expected to increase the average acceptance rate as the propagation phase will have a higher contribution.</p>
    <p>large set of users data. We were able to collect news feeds, users profile information, and wall messages. We decided, however, to only focus on users data that have monetary value such as Personally Identifiable Information (PII).</p>
    <p>After excluding all remaining friendships between the socialbot, the total size of all direct neighborhoods of the socialbots was 3,055 profiles. The total size of all extended neighborhoods, on the other hand, was as large as 1,085,785 profiles. In Table 3, we compare users data revelation of some PII before and after operating the SbN, as a percentage of the neighborhoods size.</p>
    <p>To emphasize its significance, we visualize the data revelation dierence of selected profile information in Figure 6. We include all user profiles from both the direct and the extended neighborhoods of the socialbots, which added up to 1,088,840 profiles. Each bar in the figure is annotated with two numbers in x/y format, where x and y represent the number of profiles with accessible profile information before and after a large-scale infiltration, respectively.</p>
    <p>previous section and focus on four main points: the observed users behavior, the eectiveness of the Facebook Immune System, the infiltration performance of the socialbots, and the expected implications on other software systems.</p>
    <p>Table 3: Data revelation as % of neighborhoods size. Neighborhoods Direct(%) Extended(%) Profile Info Before After Before After Gender 69.1 69.2 84.2 84.2 Birth Date 03.5 72.4 04.5 53.8 Married To 02.9 06.4 03.9 04.9 Worked At 02.8 04.0 02.8 03.2 School Name 10.8 19.7 12.0 20.4 Current City 25.4 42.9 27.8 41.6 Home City 26.5 46.2 29.2 45.2 Mail Address 00.9 19.0 00.7 01.3 Email Address 02.4 71.8 02.6 04.1 Phone Number 00.9 21.1 01.0 01.5 IM Account ID 00.6 10.9 00.5 00.8 Average 13.3 34.9 15.4 23.7</p>
    <p>ask: are the infiltrated profiles real after all, or are they just other socailbots? To begin with, notice that during the bootstrapping phase, the socialbots targeted profiles that were picked at random out of millions of user profiles, and thus, it is highly unlikely to have picked mostly socialbots. We also support this argument by the following analysis of</p>
    <p>the observed users behavior. First of all, consider Figure 5. The big jump in the acceptance rate from users who were picked at random to those with whom the socialbots had some mutual friends is expected. It directly exhibits the eect of the triadic closure principle, which predicts that having mutual friends will improve the liklihood of accepting a friendship request as discussed in Section 3.4.2. The triadic closure, interestingly, also operated from the users side; the socialbots received a total of 331 friendship requests from their extended neighborhoods. Second, the behavior depicted in Figure 4 matches the</p>
    <p>ocial statistics about real users on Facebook: 50% of the 750 million active Facebook users log on in any given day [3], and thus, it is expected that approximately half of the accepted friendship requests are observed within one day of the requests being sent. Third and last, the users who were infiltrated during the</p>
    <p>bootstrapping phase, that is, those who were selected at random, showed another expected behavior [39]: the more friends they had, the higher the chance was that they accepted a friendship request from a socialbot (i.e., a stranger), as shown in Figure 7.</p>
  </div>
  <div class="page">
    <p>Private Data Exposed</p>
    <p>Socialbots: 102, their friends: 3,055, their friends friends: 1,085,785</p>
    <p>IM account iden9fiers</p>
    <p>Postal address</p>
    <p>Phone number</p>
    <p>E-mail address</p>
    <p>Th ou</p>
    <p>sa nd</p>
    <p>s</p>
    <p>Before AOer</p>
  </div>
  <div class="page">
    <p>Web-based Botnet Integration</p>
    <p>OSN</p>
    <p>Channel</p>
    <p>Socialbots</p>
    <p>Online Social Network</p>
    <p>Botmaster Botherder</p>
    <p>Infected Machines</p>
    <p>Botnet + Socialbot Network</p>
    <p>C&amp;C Channel</p>
  </div>
  <div class="page">
    <p>Advice: OSNs and Security Research</p>
  </div>
</Presentation>
