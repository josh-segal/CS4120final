<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Learning the Empirical Hardness of Combinatorial Auctions</p>
    <p>Kevin Leyton-Brown Eugene Nudelman Yoav Shoham</p>
    <p>Computer Science Stanford University</p>
    <p>Thanks to: Carla Gomes, Bart Selman, Rmon Bjar Ioannis Vetsikas, and Henry Kautz</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 2</p>
    <p>Introduction</p>
    <p>Recent trend: study of average/empirical hardness as opposed to the worst-case complexity (NP-Hardness) [Cheeseman et al.; Selman et al.]</p>
    <p>Our proposal: predict the running time of an algorithm on a particular instance based on features of that instance Today:</p>
    <p>a methodology for doing this its application to the combinatorial auction winner determination problem (WDP)</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 3</p>
    <p>Why?</p>
    <p>Predict running time for its own sake build algorithm portfolios</p>
    <p>Theoretical understanding of hardness tune distributions for hardness improve algorithms</p>
    <p>Problem specific WDP: design bidding rules</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 4</p>
    <p>Related Work Decision problems:</p>
    <p>phase transitions in solvability, corresponding to hardness spike [Cheeseman et al.; Selman et al.] solution invariants: e.g., backbone [Gomes et al.]</p>
    <p>Optimization problems: experimental:</p>
    <p>reduce to decision problem [Zhang et al.]  introduce backbone concepts [Walsh et al.]</p>
    <p>theoretical:  polynomial/exponential transition in search algorithms</p>
    <p>[Zhang]  predict A* nodes expanded for problem distribution [Korf,</p>
    <p>Reid]</p>
    <p>Learning dynamic restart policies [Kautz et al.]</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 5</p>
    <p>Combinatorial Auctions</p>
    <p>Auctioneer sells a set of non-homogeneous items Bidders often have complex valuations</p>
    <p>complementarities  e.g. V(TV &amp; VCR) &gt; V(TV) + V(VCR)</p>
    <p>substitutabilities  V(TV1 &amp; TV2) &lt; V(TV1) + V(TV2)</p>
    <p>Solution: allow bids on bundles of goods achieves a higher revenue and social welfare than separate auctions</p>
    <p>Two hard problems: Expressing valuations Determining optimal allocation</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 6</p>
    <p>Winner Determination Problem</p>
    <p>Equivalent to weighted set packing Input: m bids Objective: find revenue-maximizing nonconflicting allocation</p>
    <p>Even constant factor approximation is NP-Hard Square-root approximation known Polynomial in the number of bids</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 7</p>
    <p>WDP Case Study</p>
    <p>Difficulty: highly parameterized, complex distributions Hard to analyze theoretically</p>
    <p>large variation in edge costs and branching factors throughout the search tree [Korf, Reid, Zhang]</p>
    <p>Too many parameters to vary systematically [Walsh et al., Gomes et. al.] Parameters affect expected optimum: difficult to transform to decision problem [Zhang et al.]</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 8</p>
    <p>Methodology</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 9</p>
    <p>Methodology</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 10</p>
    <p>Methodology</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 11</p>
    <p>WDP Distributions</p>
    <p>Legacy (7 distributions) sample bid sizes/prices independently from simple statistical distributions</p>
    <p>Combinatorial Auctions Test Suite (CATS) Attempted to model bidder valuations to provide more motivated CA distributions</p>
    <p>weighted graph 3. matching: FAA take-off &amp; landing auctions 4. scheduling: single resource, multiple deadlines</p>
    <p>for each agent [Wellman]</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 12</p>
    <p>Methodology</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 13</p>
    <p>Problem Size</p>
    <p>Some sources of hardness well-understood hold these constant to focus on unknown sources of hardness</p>
    <p>Common: input size Problem size is affected by preprocessing techniques! (e.g. arc-consistency) WDP: dominated bids can be removed (raw #bids, #goods) is a very misleading measure of size for legacy distributions</p>
    <p>we fix size as (#non-dominated bids, #goods)</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 14</p>
    <p>Raw vs. Non-Dominated Bids (64 goods, target of 2000 non-dominated bids)</p>
    <p>N um</p>
    <p>be r</p>
    <p>of N</p>
    <p>on -D</p>
    <p>om in</p>
    <p>at ed</p>
    <p>B id</p>
    <p>s (a</p>
    <p>ve ra</p>
    <p>ge o</p>
    <p>ve r</p>
    <p>un s)</p>
    <p>L1 L2 L3 L4 L5 L6 L7</p>
    <p>L1: Uniform Random</p>
    <p>L4: Decay</p>
    <p>L5: Normal</p>
    <p>L6: Exponential L2: Weighted Random</p>
    <p>L7: Binomial L3: Uniform</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 15</p>
    <p>Methodology</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 16</p>
    <p>Features</p>
    <p>No automatic way to construct features must come from domain knowledge</p>
    <p>We require features to be: polynomial-time computable distribution-independent</p>
    <p>We identified 35 features after using various statistical feature selection techniques, we were left with 25</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 17</p>
    <p>Features</p>
    <p>Bid Good Graph (BGG) 1. Bid node degree stats 2. Good node degree stats</p>
    <p>Price-based features 9. std. deviation 10. stdev price/#goods 11. stdev price/ #goods</p>
    <p>Bid Graph (BG) 3. node degree stats 4. edge density 5. clustering coef. and</p>
    <p>deviation 6. avg. min. path. length 7. ratio of 5 &amp; 6 8. node eccentricity stats</p>
    <p>LP Relaxation 12. L1, L2, L norms of</p>
    <p>integer slack vector</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 18</p>
    <p>Methodology</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 19</p>
    <p>Experimental Setup</p>
    <p>Sample parameters uniformly from range of acceptable values 3 separate datasets:</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 20</p>
    <p>Gross Hardness (256 goods, 1000 bids)</p>
    <p>-1 0</p>
    <p>Paths</p>
    <p>Scheduling</p>
    <p>L6 L2</p>
    <p>Regions</p>
    <p>L4 Arbitrary</p>
    <p>L7 L3</p>
    <p>Running Time log10(sec)</p>
    <p>Distribution 500 instances</p>
    <p>in each</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 21</p>
    <p>Methodology</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 22</p>
    <p>Learning</p>
    <p>Classification: misleading error measure Statistical regression: learn a continuous function of features that predicts log of running time Supervised learning: data broken into 80% training set, 20% test set Started with simplest technique: linear regression</p>
    <p>find a hyperplane that minimizes root mean squared error (RMSE) on training data</p>
    <p>Linear regression is useful: as a (surprisingly good) baseline yields a very interpretable model with understandable variables</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 23</p>
    <p>LR: Error</p>
    <p>C o</p>
    <p>u n</p>
    <p>t</p>
    <p>Absolute Error</p>
    <p>Dataset RMSE MAE</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 24</p>
    <p>LR: Subset Selection</p>
    <p>R M</p>
    <p>S E</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 25</p>
    <p>LR: Cost of Omission (subset size 7)</p>
    <p>Cost of Omission</p>
    <p>BG: Edge Density</p>
    <p>BG: Clustering Coefficient</p>
    <p>BGG: Avg Good Degree</p>
    <p>BGG: Min Good Degree</p>
    <p>LP: L1 Norm</p>
    <p>BG: Degree Deviation</p>
    <p>BGG: Min Bid Degree</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 26</p>
    <p>Non-Linear Approaches</p>
    <p>Linear regression doesnt consider interactions between variables; likely to underfit data Consider 2nd degree polynomials Variables = pairwise products of original features</p>
    <p>total of 325 variables (cf. clauses/variables)</p>
    <p>More predictability, less interpretability</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 27</p>
    <p>Quadratic vs Linear Regression</p>
    <p>Linear Quadratic</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 28</p>
    <p>C o</p>
    <p>u n</p>
    <p>t</p>
    <p>Absolute Error</p>
    <p>Linear Quadratic</p>
    <p>Quadratic vs Linear Regression</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 29</p>
    <p>QR: RMSE vs. Subset Size</p>
    <p>RMSE of the complete model</p>
    <p>RMSE of the linear model</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 30</p>
    <p>Cost of Omission (subset size 6)</p>
    <p>Clustering coefficient * Average minimum path</p>
    <p>length</p>
    <p>BGG min good degree * BGG max bid degree</p>
    <p>Clustering deviation * Integer slack L1 norm</p>
    <p>BGG min good degree * Clustering coefficient</p>
    <p>Integer slack L1 norm</p>
    <p>BG edge density * Integer slack L1 norm</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 31</p>
    <p>Whats Next?</p>
    <p>Constructing algorithm portfolios combine several uncorrelated algorithms good initial results for WDP</p>
    <p>Tuning distributions for hardness releasing new version of CATS</p>
  </div>
  <div class="page">
    <p>September 12, 2004 Constraint Programming 2002, Cornell 32</p>
    <p>Summary</p>
    <p>Algorithms are predictable Empirical hardness can be studied in a disciplined way</p>
    <p>Once again: Structure matters! Uniform distributions arent the best testbeds Constraint graphs are very useful Hypothesis: good heuristics make good features (e.g. LP)</p>
    <p>Our methodology is general and can be applied to other problems!</p>
  </div>
</Presentation>
