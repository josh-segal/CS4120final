<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>AutoSSD: an Autonomic SSD Architecture</p>
    <p>Bryan S. Kim (Seoul National University, Korea)</p>
    <p>Hyun Suk Yang (Hongik University, Korea)</p>
    <p>Sang Lyul Min (Seoul National University, Korea)</p>
  </div>
  <div class="page">
    <p>Flash memory ubiquity</p>
    <p>NAND flash</p>
    <p>memory</p>
    <p>Flash-based</p>
    <p>storage</p>
    <p>Devices and</p>
    <p>applications</p>
    <p>* Images from various sources via google search</p>
    <p>ConclusionDesignBackground Evaluation</p>
  </div>
  <div class="page">
    <p>Performance issues with SSDs</p>
    <p>http://www.zdnet.com/article/why-ssds-dont-perform/</p>
    <p>The Tail at Scale, Communications of the ACM, vol 56, no. 2</p>
    <p>https://storagemojo.com/2015/06/03/why-its-hard-to-meet-slas-with-ssds/</p>
    <p>http://appleinsider.com/articles/11/07/25/performance_variation_found_in_ssds_shipping_with_new_macbook_airs</p>
    <p>ConclusionDesignBackground Evaluation</p>
  </div>
  <div class="page">
    <p>Performance issues with SSDs</p>
    <p>* Graph from SNIA solid state storage performance test specification</p>
    <p>ConclusionDesignBackground Evaluation</p>
  </div>
  <div class="page">
    <p>All because of garbage collection?</p>
    <p>Dean et al, CACM 2013</p>
    <p>[GC]  can increase read latency by a factor of 100</p>
    <p>Kim et al, USENIX FAST 2015</p>
    <p>garbage collection is the source of this problem</p>
    <p>Kang et al, ACM TECS 2017</p>
    <p>GC induces a long-latency problem</p>
    <p>Yan et al, USENIX FAST 2017</p>
    <p>The core problem  is the well-known and notorious garbage collection</p>
    <p>ConclusionDesignBackground Evaluation</p>
  </div>
  <div class="page">
    <p>FTL tasks as necessary evil</p>
    <p>No in-place update</p>
    <p>Asymmetric granularity</p>
    <p>Error &amp; disturbance</p>
    <p>Bad blocks</p>
    <p>FTL</p>
    <p>tasks</p>
    <p>Mapping</p>
    <p>Garbage collection</p>
    <p>Wearleveling</p>
    <p>Read scrubbing</p>
    <p>Read retry Bad block management</p>
    <p>Flash memory</p>
    <p>quirks</p>
    <p>ConclusionDesignBackground Evaluation</p>
  </div>
  <div class="page">
    <p>Existing approaches</p>
    <p>Implement FTL in host</p>
    <p>FTL is implemented in the host system</p>
    <p>Fusion I/O, Baidus Software-Defined Flash, Open-channel SSD, etc</p>
    <p>Exposed flash memory quirks</p>
    <p>Add control interface</p>
    <p>Host explicitly manages FTL tasks running inside the device</p>
    <p>NVMes advanced background operation / predictable latency mode</p>
    <p>Ad-hoc interface extension and suboptimal host-centric decisions</p>
    <p>Exploit workload idleness</p>
    <p>SSD schedules background tasks while host is idle</p>
    <p>HIOS (ISCA 14), ITEX (TC 14), RL-assisted GC (TECS 17)</p>
    <p>Heavy dependence on host workload</p>
    <p>Reconstruct data using redundancy</p>
    <p>When blocked by background tasks, reconstruct data using RAID-like parity</p>
    <p>ttFlash (FAST 17)</p>
    <p>Increased internal traffic and reduced storage efficiency</p>
    <p>ConclusionDesignBackground Evaluation</p>
  </div>
  <div class="page">
    <p>Our approach</p>
    <p>Autonomic SSD</p>
    <p>Flash</p>
    <p>chip</p>
    <p>Flash memory</p>
    <p>Subsystem</p>
    <p>Host system</p>
    <p>Flash channel</p>
    <p>Flash</p>
    <p>chip</p>
    <p>Flash</p>
    <p>chip</p>
    <p>Flash</p>
    <p>chip</p>
    <p>Flash channel</p>
    <p>Flash</p>
    <p>chip</p>
    <p>Flash</p>
    <p>chip</p>
    <p>Flash</p>
    <p>chip</p>
    <p>Flash channel</p>
    <p>Flash</p>
    <p>chip</p>
    <p>Flash</p>
    <p>chip</p>
    <p>Scheduling</p>
    <p>Subsystem</p>
    <p>Flash Translation Layer</p>
    <p>Host</p>
    <p>request</p>
    <p>handling Garbage</p>
    <p>collection</p>
    <p>Read</p>
    <p>scrubbing</p>
    <p>Other</p>
    <p>mgmt</p>
    <p>tasks</p>
    <p>Task</p>
    <p>queues Flash</p>
    <p>memory</p>
    <p>subsystem</p>
    <p>queue</p>
    <p>Share controller</p>
    <p>Share</p>
    <p>weight</p>
    <p>Key system states</p>
    <p>(# of clean blocks,</p>
    <p>read count, etc)</p>
    <p>ConclusionDesignBackground Evaluation</p>
  </div>
  <div class="page">
    <p>Autonomic SSD</p>
    <p>Flash</p>
    <p>chip</p>
    <p>Flash memory</p>
    <p>Subsystem</p>
    <p>Host system</p>
    <p>Flash channel</p>
    <p>Flash</p>
    <p>chip</p>
    <p>Flash</p>
    <p>chip</p>
    <p>Flash</p>
    <p>chip</p>
    <p>Flash channel</p>
    <p>Flash</p>
    <p>chip</p>
    <p>Flash</p>
    <p>chip</p>
    <p>Flash</p>
    <p>chip</p>
    <p>Flash channel</p>
    <p>Flash</p>
    <p>chip</p>
    <p>Flash</p>
    <p>chip</p>
    <p>Scheduling</p>
    <p>Subsystem</p>
    <p>Flash Translation Layer</p>
    <p>Host</p>
    <p>request</p>
    <p>handling Garbage</p>
    <p>collection</p>
    <p>Read</p>
    <p>scrubbing</p>
    <p>Other</p>
    <p>mgmt</p>
    <p>tasks</p>
    <p>Task</p>
    <p>queues Flash</p>
    <p>memory</p>
    <p>subsystem</p>
    <p>queue</p>
    <p>Share controller</p>
    <p>Share</p>
    <p>weight</p>
    <p>Key system states</p>
    <p>(# of clean blocks,</p>
    <p>read count, etc)</p>
    <p>Autonomic SSD</p>
    <p>Virtualization of flash memory resources</p>
    <p>Simple and effective scheduler</p>
    <p>Dynamic share control through feedback</p>
    <p>ConclusionDesignBackground Evaluation</p>
  </div>
  <div class="page">
    <p>SSD architecture that self-manages FTL tasks</p>
    <p>Virtualization of the flash memory subsystem</p>
    <p>Each FTL task is given an illusion of a dedicated flash memory subsystem</p>
    <p>Decouples algorithm and scheduling</p>
    <p>Makes each task oblivious of others</p>
    <p>Allows seamless integration of new FTL tasks</p>
    <p>Share enforcement with debit scheduling</p>
    <p>Each task is given a share that limits the number of resources it can simultaneously use</p>
    <p>Simple  no complex computation and bookkeeping</p>
    <p>Approximated fairness without explicit tracking of time</p>
    <p>Share-based resource reservation</p>
    <p>Feedback control of share</p>
    <p>Each tasks share is adjusted reactively to the changes in system states</p>
    <p>Number of free blocks represent the urgency of the garbage collection task</p>
    <p>Maximum read count represents the urgency of the read scrubbing task</p>
    <p>ConclusionDesignBackground Evaluation</p>
  </div>
  <div class="page">
    <p>Debit scheduling</p>
    <p>Debit scheduler  Limits # of outstanding requests per-task</p>
    <p>Increment on issuing request  Decrement on receiving response</p>
    <p>Debit limit is proportional to the share</p>
    <p>A0B0</p>
    <p>B1</p>
    <p>B3</p>
    <p>A0</p>
    <p>Chip 0</p>
    <p>Chip 1</p>
    <p>Chip 2</p>
    <p>Chip 3</p>
    <p>A2</p>
    <p>B0 B0B1</p>
    <p>Chip 0 queue</p>
    <p>Task A queue</p>
    <p>Task B queue</p>
    <p>Chip 1 queue</p>
    <p>Chip 2 queue</p>
    <p>Chip 3 queue</p>
    <p>Task A</p>
    <p>Debit</p>
    <p>Debt limit</p>
    <p>Task B</p>
    <p>Issue task As request</p>
    <p>to chip 2</p>
    <p>Chip 0</p>
    <p>queue full</p>
    <p>At max</p>
    <p>debt</p>
    <p>A0B0</p>
    <p>B1A0</p>
    <p>Chip 0</p>
    <p>Chip 1</p>
    <p>Chip 2</p>
    <p>Chip 3</p>
    <p>A2B0 B0B1</p>
    <p>Chip 0 queue</p>
    <p>Task A queue</p>
    <p>Task B queue</p>
    <p>Chip 1 queue</p>
    <p>Chip 2 queue</p>
    <p>Chip 3 queue</p>
    <p>Task A</p>
    <p>Debit</p>
    <p>Debt limit</p>
    <p>Task B</p>
    <p>Iss ue</p>
    <p>ta sk</p>
    <p>B s</p>
    <p>req ue</p>
    <p>st</p>
    <p>to ch</p>
    <p>ip 1</p>
    <p>Chip 0</p>
    <p>queue full</p>
    <p>Task Bs request</p>
    <p>completed</p>
    <p>ConclusionDesignBackground Evaluation</p>
  </div>
  <div class="page">
    <p>Share controller</p>
    <p>Share controller  Monitors key system states</p>
    <p># free blocks for GC  Max read count for RS</p>
    <p>Adjusts shares to maintain stable states</p>
    <p>Debit Scheduler</p>
    <p>Host requests</p>
    <p>GC requests</p>
    <p>Scheduled requests</p>
    <p>Sys state: # free blks,</p>
    <p>Max read cnt</p>
    <p>Share controller</p>
    <p>Host share</p>
    <p>GC share</p>
    <p>RS requests</p>
    <p>RS share</p>
    <p>ConclusionDesignBackground Evaluation</p>
  </div>
  <div class="page">
    <p>Share controller</p>
    <p>Share controller  Monitors key system states</p>
    <p># free blocks for GC  Max read count for RS</p>
    <p>Adjusts shares to maintain stable states</p>
    <p>ConclusionDesignBackground Evaluation</p>
    <p>Control function:</p>
    <p>SA[t] = PA  eA [t] + IA  SA [t-1]</p>
    <p>Share @ t Share @ t-1Error @ t</p>
    <p>Proportional coeff (0PA)</p>
    <p>Integral coeff (0IA&lt;1)</p>
  </div>
  <div class="page">
    <p>Evaluation environment &amp; methodology</p>
    <p>Storage system configuration</p>
    <p>200GB storage with 28% over-provisioning</p>
    <p>Garbage collection: reclaims space for writes</p>
    <p>Read scrubbing: preventatively migrates data before data loss</p>
    <p>Map caching: selectively keeps mapping data in memory</p>
    <p>Workload configuration</p>
    <p>Synthetic I/O</p>
    <p>8 real-world I/O traces collected from MS production servers</p>
    <p>With original dispatch time</p>
    <p>With half the original dispatch time (2x intensity)</p>
    <p>ConclusionDesignBackground Evaluation</p>
  </div>
  <div class="page">
    <p>I/O trace results</p>
    <p>Vanilla : schedule in order of arrival RAIN : RAID-like parity + prioritized scheduling QoSFC : WFQ + P control AutoSSD : debit + PI control</p>
    <p>ConclusionDesignBackground Evaluation</p>
    <p>DAP-DS DAP-PS DTRS LM-TBE MSN-CFS MSN-BEFS RAD-AS RAD-BE geomean</p>
    <p>N o</p>
    <p>r m</p>
    <p>. 6</p>
    <p>n in</p>
    <p>e s</p>
    <p>Q o</p>
    <p>S</p>
    <p>DAP-DS DAP-PS DTRS LM-TBE MSN-CFS MSN-BEFS RAD-AS RAD-BE geomean</p>
    <p>N o r m</p>
    <p>. a v g .</p>
    <p>R T</p>
    <p>for MSN-BEFS</p>
    <p>for RAD-AS</p>
    <p>on average 51% reduction</p>
    <p>for LM-TBE</p>
  </div>
  <div class="page">
    <p>RAD-AS LM-TBE</p>
    <p>Microscopic view</p>
    <p>ConclusionDesignBackground Evaluation</p>
    <p>A v</p>
    <p>e ra</p>
    <p>g e r</p>
    <p>e sp</p>
    <p>o n</p>
    <p>se t</p>
    <p>im e (</p>
    <p>m s)</p>
    <p>Time (seconds)</p>
    <p>RAIN QoSFC AutoSSD</p>
    <p>G C</p>
    <p>s h</p>
    <p>a re</p>
    <p>N u</p>
    <p>m b</p>
    <p>e r</p>
    <p>o f</p>
    <p>fr e e b</p>
    <p>lo c k</p>
    <p>s</p>
    <p>Time (seconds)</p>
    <p># of free blocks GC share</p>
    <p>A v</p>
    <p>e ra</p>
    <p>g e r</p>
    <p>e sp</p>
    <p>o n</p>
    <p>se t</p>
    <p>im e (</p>
    <p>m s)</p>
    <p>Time (seconds)</p>
    <p>RAIN QoSFC AutoSSD</p>
    <p>R S</p>
    <p>s h</p>
    <p>a re</p>
    <p>M a x</p>
    <p>r e a d</p>
    <p>c o</p>
    <p>u n</p>
    <p>t x</p>
    <p>Time (seconds)</p>
    <p>Max read count RS share</p>
  </div>
  <div class="page">
    <p>Static share vs. dynamic share</p>
    <p>MSN-BEFS</p>
    <p>ConclusionDesignBackground Evaluation</p>
    <p>C u m</p>
    <p>u la</p>
    <p>ti v e p</p>
    <p>ro b</p>
    <p>a b il</p>
    <p>it y</p>
    <p>Response time (ms)</p>
    <p>GC: Dynamic share</p>
    <p>GC: 5% share</p>
    <p>GC: 10% share</p>
    <p>GC: 20% share</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>SSD architecture that self-manages FTL tasks</p>
    <p>Virtualization of flash memory resources</p>
    <p>Share enforcement with debit scheduling</p>
    <p>Feedback control of share</p>
    <p>ConclusionDesignBackground Evaluation</p>
    <p>Autonomic SSD architecture</p>
    <p>reduces average response time</p>
    <p>by up to 18.0%</p>
    <p>reduces 99.9% QoS</p>
    <p>by up to 67.2%</p>
    <p>reduces 99.9999% QoS</p>
    <p>by up to 77.6%</p>
  </div>
  <div class="page">
    <p>Thank you!</p>
    <p>ConclusionDesignBackground Evaluation</p>
  </div>
</Presentation>
