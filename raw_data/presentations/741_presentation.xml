<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>UC Berkeley</p>
    <p>Spark Cluster Computing with Working Sets</p>
    <p>Matei Zaharia, Mosharaf Chowdhury, Michael Franklin, Scott Shenker, Ion Stoica</p>
  </div>
  <div class="page">
    <p>Background MapReduce and Dryad raised level of abstraction in cluster programming by hiding scaling &amp; faults</p>
    <p>However, these systems provide a limited programming model: acyclic data flow</p>
    <p>Can we design similarly powerful abstractions for a broader class of applications?</p>
  </div>
  <div class="page">
    <p>Spark Goals Support applications with working sets (datasets reused across parallel operations)  Iterative jobs (common in machine learning)  Interactive data mining</p>
    <p>Retain MapReduces fault tolerance &amp; scalability</p>
    <p>Experiment with programmability  Integrate into Scala programming language  Support interactive use from Scala interpreter</p>
  </div>
  <div class="page">
    <p>Programming Model Resilient distributed datasets (RDDs)  Created from HDFS files or parallelized arrays  Can be transformed with map and filter  Can be cached across parallel operations</p>
    <p>Parallel operations on RDDs  Reduce, collect, foreach</p>
    <p>Shared variables  Accumulators (addonly), broadcast variables</p>
  </div>
  <div class="page">
    <p>Example: Log Mining Load error messages from a log into memory, then interactively search for various patterns</p>
    <p>lines = spark.textFile(hdfs://...)</p>
    <p>errors = lines.filter(_.startsWith(ERROR))</p>
    <p>messages = errors.map(_.split(\t)(2))</p>
    <p>cachedMsgs = messages.cache()</p>
    <p>Block 1</p>
    <p>Block 2</p>
    <p>Block 3</p>
    <p>Worker</p>
    <p>Worker</p>
    <p>Worker</p>
    <p>Driver</p>
    <p>cachedMsgs.filter(_.contains(foo)).count</p>
    <p>cachedMsgs.filter(_.contains(bar)).count</p>
    <p>. . .</p>
    <p>tasks</p>
    <p>results</p>
    <p>Cache 1</p>
    <p>Cache 2</p>
    <p>Cache 3</p>
    <p>Base RDD Transformed RDD</p>
    <p>Cached RDD Parallel operation</p>
  </div>
  <div class="page">
    <p>RDD Representation Each RDD object maintains lineage information that can be used to reconstruct lost partitions</p>
    <p>Ex: cachedMsgs = textFile(...).filter(_.contains(error)) .map(_.split(\t)(2)) .cache()</p>
    <p>HdfsRDD path: hdfs://</p>
    <p>FilteredRDD func: contains(...)</p>
    <p>MappedRDD func: split()</p>
    <p>CachedRDD</p>
  </div>
  <div class="page">
    <p>Example: Logistic Regression</p>
    <p>Goal: find best line separating two sets of points</p>
    <p>+</p>
    <p>+ +</p>
    <p>+</p>
    <p>+</p>
    <p>+</p>
    <p>+ +</p>
    <p>+</p>
    <p>+</p>
    <p>target</p>
    <p>random initial line</p>
  </div>
  <div class="page">
    <p>Logistic Regression Code val data = spark.textFile(...).map(readPoint).cache()</p>
    <p>var w = Vector.random(D)</p>
    <p>for (i &lt;- 1 to ITERATIONS) { val gradient = data.map(p =&gt; { val scale = (1/(1+exp(-p.y*(w dot p.x))) - 1) * p.y scale * p.x }).reduce(_ + _) w -= gradient }</p>
    <p>println(&quot;Final w: &quot; + w)</p>
  </div>
  <div class="page">
    <p>Logistic Regression Performance</p>
    <p>first iteration 174 s further iterations 6 s</p>
  </div>
  <div class="page">
    <p>Demo</p>
  </div>
  <div class="page">
    <p>Conclusions &amp; Future Work</p>
    <p>Spark provides a limited but efficient set of fault tolerant distributed memory abstractions  Resilient distributed datasets (RDDs)  Restricted shared variables</p>
    <p>In future work, plan to further extend this model:  More RDD transformations (e.g. shuffle)  More RDD persistence options (e.g. disk + memory)  Updatable RDDs (for incremental or streaming jobs)  Data sharing across applications</p>
  </div>
  <div class="page">
    <p>Related Work DryadLINQ  Build queries through languageintegrated SQL operations on lazy datasets  Cannot have a dataset persist across queries  No concept of shared variables for broadcast etc</p>
    <p>Pig and Hive  Query languages that can call into Java/Python/etc UDFs  No support for caching a datasets across queries</p>
    <p>OpenMP  Compiler extension for parallel loops in C++  Annotate variables as readonly or accumulator above loop  Cluster version exists, but not faulttolerant</p>
    <p>Twister and Haloop  Iterative MapReduce implementations using caching  Cant define multiple distributed datasets, run multiple map &amp; reduce pairs</p>
    <p>on them, or decide which operations to run next interactively</p>
  </div>
</Presentation>
