<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Estimating Bidders Valuation Distributions</p>
    <p>in Online Auctions</p>
    <p>Albert Xin Jiang, Kevin Leyton-Brown Department of Computer Science</p>
    <p>University of British Columbia</p>
  </div>
  <div class="page">
    <p>Bidding Agents</p>
    <p>Given a valuation function, compute a bidding strategy that maximizes EU</p>
    <p>notwithstanding Wilson Doctrine: mechanisms should be detail-free</p>
    <p>Motivating example: how should agents behave in a sequence of eBay auctions?</p>
    <p>Game Theoretic Approach</p>
    <p>[Milgrom</p>
    <p>&amp; Weber, 1982], much subsequent work from econ.</p>
    <p>model the situation as a Bayesian game</p>
    <p>compute and then play a Bayes-Nash equilibrium of the game</p>
    <p>when other bidders</p>
    <p>valuations are not known, estimate them from history</p>
    <p>drawbacks:</p>
    <p>rationality of other agents may be in doubt</p>
    <p>intractability of computing equilibrium</p>
    <p>multiple equilibria</p>
    <p>Decision Theoretic Approach</p>
    <p>[Boutilier et al. 1999; Byde</p>
    <p>et al. 2005]</p>
    <p>learn the behavior of other bidders from historical data</p>
    <p>treat other bidders as part of the environment</p>
    <p>play an optimal strategy in the resulting single-agent decision problem</p>
  </div>
  <div class="page">
    <p>Learning Valuation/Price Distributions</p>
    <p>Whether the GT or DT approach is taken, a shared subproblem</p>
    <p>is using historical data to estimate distribution of bidders</p>
    <p>bid amounts</p>
    <p>or valuations</p>
    <p>[Athey</p>
    <p>&amp; Haile, 2000], various other papers in econometrics:</p>
    <p>assume that bidders are perfectly rational and follow equilibrium strategies</p>
    <p>estimation of valuation distributions in various auction types given observed bids</p>
    <p>[Byde, 2002], [Stone et al. 2003], [Greenwald &amp; Boyan, 2004], [MacKie-Mason et al. 2004], [Osepayshvili</p>
    <p>et al. 2005]:</p>
    <p>estimate the distribution of the final prices</p>
    <p>in (e.g.) English auctions based on selling price and number of agents</p>
    <p>[Boutilier et al. 1999]:</p>
    <p>a decision-theoretic MDP approach to bidding in sequential first-price auctions for complementary goods</p>
    <p>for the case where these sequential auctions are repeated, discusses learning a distribution of other agents</p>
    <p>highest bid for each good, based on winning bids</p>
    <p>uses EM: the agents own bid wins, hiding the highest bid by other agents</p>
  </div>
  <div class="page">
    <p>Talk Outline</p>
    <p>Background</p>
    <p>Online Auction Model and Learning Problem</p>
    <p>Bidding in Sequential Auctions</p>
    <p>Experimental Evaluation</p>
  </div>
  <div class="page">
    <p>Online Auction Model</p>
    <p>A (possibly repeated) online English auction such as eBay  m potential bidders, with m drawn from a distribution g(m)</p>
    <p>let n denote the number of bidders who place (accepted) bids in the auction</p>
    <p>each bidder i has an independent private valuation drawn from distribution f(v)</p>
    <p>Bidding dynamics</p>
    <p>start with reserve price of zero</p>
    <p>bidders sequentially place proxy bids (each bidder gets only one bid)</p>
    <p>auctioneer maintains current price: second-highest proxy amount declared so far</p>
    <p>if a new bid is less than the current price, it is dropped</p>
    <p>Bidding history</p>
    <p>some bidders</p>
    <p>proxy bid amounts will be perfectly observed (denote this set of bids xo )</p>
    <p>any bidder who placed a proxy bid and was outbid (n-1 such bidders)</p>
    <p>however, some bids will be hidden</p>
    <p>(denote this set xh )</p>
    <p>highest bid (one bidder)</p>
    <p>revealed only up to the second-highest bidders proxy amount</p>
    <p>any bid which was lower than the current price when it was placed (m</p>
    <p>n bidders)</p>
    <p>either the bidder leaves or the bid is rejected</p>
  </div>
  <div class="page">
    <p>Bidding Example</p>
    <p>highestcurrent price</p>
  </div>
  <div class="page">
    <p>Learning the Distributions f(v) and g(m)</p>
    <p>Data: a set of auction histories</p>
    <p>number of bidders and bids distributed identically in each auction</p>
    <p>Simple technique</p>
    <p>for estimating f(v) and g(m):</p>
    <p>ignore hidden bids, considering only xo and n from each auction</p>
    <p>use any standard density estimation technique to learn the distributions</p>
    <p>essentially this is the straightforward price estimation technique described earlier</p>
    <p>Problem:</p>
    <p>the simple technique ignores the hidden bids and so introduces bias</p>
    <p>g(m) will be skewed towards small values because n</p>
    <p>m</p>
    <p>f(v) may be</p>
    <p>skewed towards small values because it ignores the winning bid</p>
    <p>skewed towards large values because ignores dropped, losing bids</p>
  </div>
  <div class="page">
    <p>EM Algorithm</p>
    <p>Solution: use EM</p>
    <p>to account for hidden bids</p>
    <p>similar in spirit to the approach described above by Boutilier et al. (1999)</p>
    <p>however, in our setting some losing bids are also hidden; the number of bidders is uncertain; expected number of hidden bids depends on xo and f(v)</p>
    <p>E step: generate the missing data</p>
    <p>given estimates of f', g' and bidding model</p>
    <p>for each observation xo , repeat until N samples of xh have been generated:</p>
    <p>sample m from g'(m | m</p>
    <p>n)</p>
    <p>simulate bidding process until m</p>
    <p>n + 1 bids have been generated:</p>
    <p>Draw a sample from f'(v) to represent a new bid</p>
    <p>If the sampled bid exceeds the next bid in xo , replace the bid with the next bid from xo . Otherwise, add the sampled bid to xh</p>
    <p>if xh does not contain exactly one bid that exceeds the highest bid in xo , reject sample</p>
    <p>M step:</p>
    <p>update f '(v) and g'(m) to maximize the likelihood of the bids</p>
    <p>xo</p>
    <p>xh</p>
    <p>depends on functional form of f', g'; either analytic or using e.g. simulated annealing</p>
  </div>
  <div class="page">
    <p>Learning f(v) and g(m) in a Game Theoretic Setting</p>
    <p>The approach described above is decision-theoretic</p>
    <p>What if we want to take a game-theoretic approach?</p>
    <p>Athey</p>
    <p>&amp; Haile, (2000) discuss estimation in the game theoretic setting</p>
    <p>however, they generally assume that number of bidders is known</p>
    <p>brief discussion of unknown number of bidders, but not relevant to our online auction setting</p>
    <p>let f(v) be the distribution of bidders valuations (instead of bid amounts)</p>
    <p>g(m) remains the distribution of number of bidders, as before</p>
    <p>given a bidders valuation v, what is his bid amount?</p>
    <p>solve for Bayes-Nash equilibrium of the auction game: bid function b(v |f, g)</p>
    <p>EM algorithm</p>
    <p>to estimate f and g in a GT setting:</p>
    <p>E step: for each sample given observation xo :</p>
    <p>sample m from g'(m | m</p>
    <p>n)</p>
    <p>compute observed bidders</p>
    <p>valuations vo from xo by inverting the bid function</p>
    <p>generate new bidders with valuations vh who place hidden bids xh = b(vh |f', g')</p>
    <p>simulate the auction until m</p>
    <p>n + 1 bids are generated, where exactly one hidden bid is higher than the highest observed bid</p>
    <p>M step: update f' and g' to maximize likelihood of the valuations vo</p>
    <p>vh</p>
  </div>
  <div class="page">
    <p>Talk Outline</p>
    <p>Background</p>
    <p>Online Auction Model and Learning Problem</p>
    <p>Building an Agent</p>
    <p>Experimental Evaluation</p>
  </div>
  <div class="page">
    <p>Building an Agent</p>
    <p>Consider the construction of a decision-theoretic agent to participate in a finite sequence of auctions</p>
    <p>(under our online auction model)</p>
    <p>given estimates f'(v) and g'(m), what are the optimal bidding strategies?</p>
    <p>Auction environment  k sequential, single-good online auctions for possibly non-identical goods</p>
    <p>we want only one item</p>
    <p>e.g. buying a Playstation</p>
    <p>denote our valuation for the item in auction j as vj and our bid as bj</p>
    <p>let Uj denote expected payoff at time j, conditional on not having won already</p>
    <p>a function of our valuations for the goods in the auctions j, , k</p>
    <p>Greenwald &amp; Boyan</p>
    <p>(2004) and Arora et al. (2003) analyzed similar domains</p>
    <p>using similar reasoning, we derive the optimal bidding strategy for our model</p>
  </div>
  <div class="page">
    <p>Computing the Optimal Strategy</p>
    <p>Optimal bidding:</p>
    <p>is the EU of the bidding strategy that maximizes Uj+1</p>
    <p>(derived in the paper)</p>
    <p>first term: payoff from current auction; second term: payoff from future auctions</p>
    <p>note that Uj+1</p>
    <p>depends on the distribution of the highest bid:</p>
    <p>and that Fj1 depends in turn on f(v), g(m)</p>
    <p>thus we must estimate f(v), g(m) to build a decision theoretic agent in this setting</p>
    <p>Our agent computes U*j+1</p>
    <p>by approximating an integral using Monte Carlo sampling, again relying on our model of the auction</p>
  </div>
  <div class="page">
    <p>Elaborations</p>
    <p>Auctions that overlap in time</p>
    <p>note that while the optimal bid in auction j does not depend on fj1, it does depend on fl1 for l &gt; j</p>
    <p>If an auction l receives a set of (observed) bids bl before auction j has ended, we can compute a posterior estimate of fl1(v), and thus a better bid for auction j</p>
    <p>sample from fl1(v) by simulating auction l according to our auction model</p>
    <p>What about the game theoretic approach?</p>
    <p>If each bidder (other than our agent) only participates in one auction:</p>
    <p>dominant strategy is to bid truthfully: b(v) = v</p>
    <p>we can use the decision-theoretic approach</p>
    <p>If other bidders participate in more than one auction</p>
    <p>[Milgrom</p>
    <p>&amp; Weber, 1982]</p>
    <p>equilibrium strategy gets more complex (both strategically and computationally)</p>
    <p>depends on entry, exit policies of other agents</p>
    <p>If we have to estimate f and g, presumably other agents do too. How should we account for the possibility that they will learn incorrect distributions?</p>
    <p>success in this domain is much harder to benchmark experimentally</p>
    <p>do we believe that all agents will follow an equilibrium strategy on eBay?</p>
  </div>
  <div class="page">
    <p>Talk Outline</p>
    <p>Background</p>
    <p>Online Auction Model and Learning Problem</p>
    <p>Building an Agent</p>
    <p>Experimental Evaluation</p>
  </div>
  <div class="page">
    <p>Experiments</p>
    <p>We compared our EM approach against the simple approach I.</p>
    <p>Synthetic data: sequence of auctions for identical items, known distribution families</p>
    <p>II.</p>
    <p>Synthetic data: sequence of auctions for non-identical items, known distribution families</p>
    <p>III.</p>
    <p>Synthetic data: sequence of auctions for identical items, unknown distribution families</p>
    <p>IV.</p>
    <p>eBay data: auctions for Playstation</p>
    <p>For each dataset, we ask two questions: 1.</p>
    <p>Which approach gives better estimates</p>
    <p>of the distributions f(v), g(m), f1(v)?</p>
    <p>Which approach gives better expected payoffs</p>
    <p>under the decision-theoretic bidding model?</p>
  </div>
  <div class="page">
    <p>Data Set I: Identical Items</p>
    <p>Synthetic Data: f(v) is a normal distribution; g(m) is a Poisson distribution</p>
    <p>Bidding history of 40 auctions is generated for each instance.</p>
    <p>Both learning approaches use the correct (normal &amp; Poisson) families of distributions to estimate f(v) and g(m)</p>
    <p>Question 1: which approach made a better estimate of f(v), g(m), f1(v)?</p>
    <p>EM approach consistently has lower KL divergence than the simple approach</p>
    <p>statistically significant difference: Wilcoxon</p>
    <p>sign-rank test (non-parametric)</p>
    <p>6 4 2 0 2 4 6 8 10 12 14 0</p>
    <p>Bid Amount</p>
    <p>Distribution of Bids</p>
    <p>true simple EM</p>
  </div>
  <div class="page">
    <p>Data Set I: Comparing Expected Payoffs</p>
    <p>Sequence of eight new auctions, after learning from the 40-auction history</p>
    <p>in the new auctions, we still use the true g(m) and f(v)</p>
    <p>Question 2: following the optimal strategy with the EM estimates</p>
    <p>gives higher expected payoffs than following this strategy with the simple approachs estimates</p>
    <p>simple EM</p>
    <p>R eg</p>
    <p>re t</p>
    <p>Payoff Regrets</p>
  </div>
  <div class="page">
    <p>Data Set II: Non-identical Items</p>
    <p>The mean of f(v) depends linearly on some unknown parameter a</p>
    <p>Both approaches use linear regression to estimate the linear coefficients</p>
    <p>Question 1: EM approach gives (stat. significantly) better estimates</p>
    <p>Question 2: EM approach achieves significantly better expected payoffs</p>
    <p>a</p>
    <p>m e a n o</p>
    <p>f f(</p>
    <p>x| a )</p>
    <p>The mean of f(x|a) versus a</p>
    <p>true simple EM</p>
  </div>
  <div class="page">
    <p>Data Set III: Unknown distributions</p>
    <p>Identical items. Distribution families for f(v) and g(m) are unknown</p>
    <p>ground truth: f(v) is Gamma distributed; g(m) is a mixture of two Poissons</p>
    <p>Use kernel density estimation to estimate f(v) and g(m)</p>
    <p>Result: the EM approach gives better estimates</p>
    <p>(significantly lower KL divergence); both approaches achieved similar payoffs</p>
    <p>(difference not significant)</p>
    <p>10 5 0 5 10 15 20 25 30 35 0</p>
    <p>Bid Amount</p>
    <p>Distribution of Highest Bid</p>
    <p>true simple kernel EM kernel</p>
  </div>
  <div class="page">
    <p>simple simple kernel EM EM kernel</p>
    <p>R eg</p>
    <p>re t</p>
    <p>Payoff Regrets</p>
    <p>Data Set IV: eBay Data</p>
    <p>considered only one-day auctions with at least 3 bidders</p>
    <p>Problem: highest bids not available</p>
    <p>Workaround: pretend</p>
    <p>second-highest bid is the highest bid</p>
    <p>justification: this shifted</p>
    <p>data set should have similar characteristics to the actual bidding history</p>
    <p>Compared four approaches:</p>
    <p>EM, simple approaches estimating normal and Poisson distributions</p>
    <p>EM, simple approaches using kernel density estimation</p>
    <p>Question 1: no ground truth for this data setdropped bids are really dropped, etc.</p>
    <p>Question 2: the EM approaches achieve significantly higher expected payoffs than the simple approaches.</p>
  </div>
  <div class="page">
    <p>Conclusion &amp; Future Work</p>
    <p>Bidding agents in online auction settings</p>
    <p>face the problem of estimating</p>
    <p>distribution of bid amounts;</p>
    <p>distribution of number of bidders from incomplete auction data</p>
    <p>We proposed a learning approach based on EM</p>
    <p>We considered the application of building a decision theoretic agent</p>
    <p>for sequences of online auctions</p>
    <p>We showed in experiments that our EM approach never did worse and usually did better than the straightforward approach, on both synthetic and real-world data</p>
    <p>Thank you for your attention!</p>
  </div>
</Presentation>
