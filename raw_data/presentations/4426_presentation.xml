<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Personalized Language Model for Query Auto-Completion</p>
    <p>Aaron Jaech and Mari Ostendorf University of Washington</p>
  </div>
  <div class="page">
    <p>Query Auto-Completion  Search engine suggests queries as</p>
    <p>the user types</p>
    <p>Idea from Park &amp; Chiba (2017): Use an LSTM to generate completions  Memory savings over most popular</p>
    <p>completion  Handles previously unseen prefixes</p>
    <p>Can we do better by adapting the LM to provide personalized suggestions?</p>
  </div>
  <div class="page">
    <p>RNN Language Model Adaptation</p>
    <p>Learn an embedding, c, for each user and use it to adapt the predictions</p>
    <p>Method #1: Concatenate the user embedding with the input at each step*  Same as applying a constant linear shift to</p>
    <p>the bias vector (in recurrent &amp; output layers)  Leaves most of the recurrent model</p>
    <p>parameters unchanged  Method #2: Low-rank adaptation of</p>
    <p>recurrent weight matrix (FactorCell model)</p>
    <p>Concatenating the user embedding is the same as shifting the bias.</p>
    <p>&quot; =</p>
    <p>' =  &quot; ')*,',  +  =   ')*,' +  +</p>
    <p>user embedding</p>
    <p>word embedding</p>
    <p>Adjust b and W!</p>
    <p>0</p>
    <p>* Referred to here as ConcatCell (Mikolov&amp; Zweig, 2012)</p>
  </div>
  <div class="page">
    <p>W0 +WA = c</p>
    <p>LLLL cR Low-rank adaptationGeneric weightsAdapted weights</p>
    <p>(e + h) x h (e + h) x h k x (e + h) x r r x h x k1 x k k x 1</p>
    <p>FactorCell Model</p>
    <p>The adaptation matrix is formed from a product of the context embedding with left and right bases.</p>
    <p>The two bases tensors (L and R) hold k different rank r matrices, each the same size as W. Context vectors give a weighted combination.</p>
  </div>
  <div class="page">
    <p>Learning</p>
    <p>User embeddings, recurrent layer weights and {L, R} tensor learned jointly</p>
    <p>Need online learning to adapt to users that were not previously seen  In joint training, learn a cold-start embedding for set of infrequent users  During evaluation</p>
    <p>Initialize each users embedding with learned cold-start vector  Make query suggestions  After user selects a query, back-propagate and only update the user embedding</p>
  </div>
  <div class="page">
    <p>Data &amp; Experiments  Using AOL 2006 Query Log data, 173K</p>
    <p>users and 12 million queries for training</p>
    <p>User embedding size = 32, LSTM size = 600</p>
    <p>Evaluate on 500K queries with disjoint user population</p>
    <p>Mean reciprocal rank (MRR) as a metric</p>
  </div>
  <div class="page">
    <p>Experimental Results</p>
    <p>M ea n Re</p>
    <p>ci pr oc al R an k</p>
    <p>Performance for users with &gt; 50 queries</p>
    <p>Benefit improves over time!</p>
  </div>
  <div class="page">
    <p>Qualitative Comparison What queries are boosted the most after searching for high school softball and math homework help?</p>
    <p>FactorCell ConcatCell high school musical horoscope</p>
    <p>chris brown high school musical</p>
    <p>funnyjunk.com homes for sale</p>
    <p>funbrain.com modular homes</p>
    <p>chat room hair styles</p>
    <p>Queries that most decrease in likelihood with the FactorCell include travel agencies and plane tickets.</p>
  </div>
  <div class="page">
    <p>Recent Related Work: Florini &amp; Lu, NAACL 2018</p>
    <p>Also personalized LSTM for query prediction  ConcatCell adaptation framework  User embedding learned separately  No online learning  Assessed on two datasets, but different split of AOL data  Confirms benefit of adapted LM</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Personalization helps and the benefit increases as more queries are seen  Stronger adaptation of the recurrent layer (FactorCell) gives better</p>
    <p>results than concatenating a user vector  No extra latency/computation due to caching of adapted weight matrix</p>
    <p>Try out the FactorCell on your data  http://github.com/ajaech/query_completion</p>
  </div>
  <div class="page">
    <p>THANKS!</p>
  </div>
  <div class="page">
    <p>Qualitative Comparison What queries are boosted the most after searching for prada handbags and versace eyewear?</p>
    <p>FactorCell ConcatCell neiman marcus craigslist nyc</p>
    <p>pottery barn myspace layours</p>
    <p>jc penny verizon wireless</p>
    <p>verizon wireless jensen ackles</p>
    <p>bed bath and beyond</p>
    <p>webster dictionary</p>
  </div>
  <div class="page">
    <p>Backup Slides</p>
  </div>
  <div class="page">
    <p>FactorCell Model</p>
    <p>W0 +WA = Low-rank adaptationGeneric weightsAdapted weights</p>
    <p>c LLLL</p>
    <p>cR The adapted weight matrix is a drop-in replacement for W</p>
    <p>h1 h2 h3 h4</p>
    <p>&lt;START&gt; THE YELLOW FOX</p>
    <p>THE YELLOW FOX JUMPED</p>
    <p>Much larger change in recurrent layer than what ConcatCell does</p>
    <p>'1* = ( W4 + W0 ',' + )</p>
  </div>
  <div class="page">
    <p>Prefix and query length</p>
    <p>Longer queries are more difficult  Suggestion quality improves as prefix length increases</p>
  </div>
</Presentation>
