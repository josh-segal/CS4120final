<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>(C) 2003 Milo Martin</p>
    <p>Using Destination-Set Prediction to Improve the Latency/Bandwidth</p>
    <p>Tradeoff in Shared-Memory Multiprocessors</p>
    <p>Milo Martin, Pacia Harper, Dan Sorin, Mark Hill, and David Wood</p>
    <p>University of Wisconsin Duke University</p>
    <p>Wisconsin Multifacet Project http://www.cs.wisc.edu/multifacet/</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 2</p>
    <p>Broadcast snooping  Evolved from bus to switched interconnect + Direct data response (no indirection)  Extra traffic (due to broadcast)</p>
    <p>Cache-Coherence: A Latency/Bandwidth Tradeoff</p>
    <p>Average Miss</p>
    <p>Latency</p>
    <p>Bandwidth usage (Cost)</p>
    <p>Broadcast Snooping</p>
    <p>Burns bandwidth for low latency</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 3</p>
    <p>Directory protocols  Send to directory which forwards as needed + Avoids broadcast  Adds latency for cache-to-cache misses</p>
    <p>Cache-Coherence: A Latency/Bandwidth Tradeoff</p>
    <p>Average Miss</p>
    <p>Latency</p>
    <p>Bandwidth usage</p>
    <p>Sacrifices latency for scalability</p>
    <p>Directory Protocol</p>
    <p>Broadcast Snooping</p>
    <p>(Cost)</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 4</p>
    <p>Approach: Destination-set Prediction  Learn from past coherence behavior  Predict destinations for each coherence request  Correct prediction avoid indirection &amp; broadcast</p>
    <p>Cache-Coherence: A Latency/Bandwidth Tradeoff</p>
    <p>Average Miss</p>
    <p>Latency</p>
    <p>Bandwidth usage</p>
    <p>Directory Protocol</p>
    <p>Broadcast Snooping</p>
    <p>Ideal</p>
    <p>Goal: move toward ideal design point (Cost)</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 5</p>
    <p>Interconnect</p>
    <p>$</p>
    <p>P M $</p>
    <p>P M $</p>
    <p>P M $</p>
    <p>P M</p>
    <p>System Model  Processor/memory nodes</p>
    <p>Destination-set predictor</p>
    <p>Directory state</p>
    <p>Destination-set predictor</p>
    <p>Network Interface</p>
    <p>Caches</p>
    <p>Processor</p>
    <p>Memory</p>
    <p>D ire</p>
    <p>c to</p>
    <p>ry</p>
    <p>ControllerPredictor</p>
    <p>? ?</p>
    <p>Home</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 6</p>
    <p>Contributions</p>
    <p>Destination-set predictors are:  Simple: single-level, cache-like structures  Low-cost: 64kBs (size similar to L2 tags)  Effective: significantly closer to ideal</p>
    <p>Exploit spatial predictability  Aggregate spatially-related information  Capture spatial predictability  better accuracy  Reduces predictor sizes</p>
    <p>Workload characterization for predictor design  Commercial and technical workloads  See paper</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 7</p>
    <p>Outline</p>
    <p>Introduction  Quantifying potential benefit</p>
    <p>Protocols</p>
    <p>Predictors</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 8</p>
    <p>Potential Benefit: Question 1 of 2</p>
    <p>Average Miss</p>
    <p>Latency</p>
    <p>Bandwidth use</p>
    <p>Directory Protocol</p>
    <p>Broadcast Snooping</p>
    <p>Ideal</p>
    <p>#1</p>
    <p>Yes!</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 9</p>
    <p>Potential Benefit: Question 2 of 2</p>
    <p>Average Miss</p>
    <p>Latency</p>
    <p>Bandwidth use</p>
    <p>Directory Protocol</p>
    <p>Broadcast Snooping</p>
    <p>Ideal</p>
    <p>#2</p>
    <p>Broadcast is overkill (see paper for histogram)</p>
    <p>The gap will grow with more processors</p>
    <p>Yes!</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 10</p>
    <p>Outline</p>
    <p>Introduction  Quantifying potential benefit</p>
    <p>Protocols</p>
    <p>Predictors</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 11</p>
    <p>No worse than base protocols</p>
    <p>Protocols for Destination-Set Prediction</p>
    <p>Protocol goals</p>
    <p>Allow direct responses for correct predictions</p>
    <p>Average Miss</p>
    <p>Latency</p>
    <p>Bandwidth use</p>
    <p>Directory Protocol</p>
    <p>Broadcast Snooping Ideal</p>
    <p>Predict broadcast =</p>
    <p>Predict minimal set =</p>
    <p>A continuum: erase snooping/directory duality</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 12</p>
    <p>Protocols for Destination-Set Prediction</p>
    <p>Many possible protocols for implementation  Multicast snooping [Bilir et al.] &amp; [Sorin et al.]  Predictive directory protocols [Acacio et al.]  Token Coherence [Martin et al.]</p>
    <p>Requestor predicts recipients  Always include directory + self (minimal set)</p>
    <p>Directory at home memory audits predictions  Tracks sharers/owner (just like directory protocol)  sufficient  acts as snooping (direct response)  insufficient  acts as directory (forward request)</p>
    <p>Protocol not the main focus of this work</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 13</p>
    <p>Outline</p>
    <p>Introduction  Quantifying potential benefit</p>
    <p>Protocols</p>
    <p>Predictors</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 14</p>
    <p>Requests Predictions</p>
    <p>Training Information 1. Responses to own requests 2. Coherence requests from others (read &amp; write)</p>
    <p>Predictor Design Space</p>
    <p>Basic organization  One predictor at each processors L2 cache</p>
    <p>Accessed in parallel with L2 tags</p>
    <p>No modifications to processor core</p>
    <p>Destination-Set Predictor</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 15</p>
    <p>Our Destination-Set Predictors</p>
    <p>All simple cache-like (tagged) predictors  Index with data block address  Single-level predictor</p>
    <p>Prediction  On tag miss, send to minimal set (directory &amp; self)  Otherwise, generate prediction (as described next)</p>
    <p>Evaluation intermingled  Three predictors (more in paper)  Exploit spatial predictability  Limit predictor size  Runtime result</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 16</p>
    <p>Evaluation Methods</p>
    <p>Six multiprocessor workloads  Online transaction processing (OLTP)  Java middleware (SPECjbb)  Static and dynamic web serving (Apache &amp; Slash)  Scientific applications (Barnes &amp; Ocean)</p>
    <p>Simulation environment  Full-system simulation using Simics  16-processor SPARC MOSI multiprocessor  Many parameters (see paper)  Traces (for exploration) &amp; timing simulation (for</p>
    <p>runtime results)</p>
    <p>See Simulating a $2M Server on $2K PC [IEEE Computer, Feb 2003]</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 17</p>
    <p>Trace-based Predictor Evaluation</p>
    <p>Directory</p>
    <p>Snooping</p>
    <p>OLTP workload</p>
    <p>Corresponds to latency</p>
    <p>Corresponds to bandwidth</p>
    <p>Quickly explore design space</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 18</p>
    <p>Predictor #1: Broadcast-if-shared</p>
    <p>Performance of snooping, fewer broadcasts  Broadcast for shared data  Minimal set for private data</p>
    <p>Each entry: valid bit, 2-bit counter  Decrement on data from memory  Increment on data from a processor  Increment other processors request</p>
    <p>Prediction  If counter &gt; 1 then broadcast  Otherwise, send only to minimal set</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 19</p>
    <p>Predictor #1: Broadcast-if-shared</p>
    <p>Unbounded predictor, indexed with datablock (64B)</p>
    <p>Performance of snooping with less traffic</p>
    <p>Directory</p>
    <p>Snooping</p>
    <p>Broadcast-if-shared</p>
    <p>OLTP workload</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 20</p>
    <p>Predictor #2: Owner</p>
    <p>Traffic similar to directory, fewer indirections  Predict one extra processor (the owner)  Pairwise sharing, write part of migratory sharing</p>
    <p>Each entry: valid bit, predicted owner ID  Set owner on data from other processor  Set owner on others request to write  Unset owner on response from memory</p>
    <p>Prediction  If valid then predict owner + minimal set  Otherwise, send only to minimal set</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 21</p>
    <p>Predictor #2: Owner</p>
    <p>Traffic of directory with higher performance</p>
    <p>Directory</p>
    <p>Snooping</p>
    <p>Broadcast-if-shared</p>
    <p>Owner</p>
    <p>OLTP workload</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 22</p>
    <p>Predictor #3: Group</p>
    <p>Try to achieve ideal bandwidth/latency  Detect groups of sharers  Temporary groups or logical partitions (LPAR)</p>
    <p>Each entry: N 2-bit counters  Response or request from another processor</p>
    <p>Increment corresponding counter  Train down by occasionally decrement all counters</p>
    <p>(every 2N increments)</p>
    <p>Prediction  Begin with minimal set  For each processor, if the corresponding counter &gt; 1,</p>
    <p>add it in the predicted set</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 23</p>
    <p>Predictor #3: Group</p>
    <p>A design point between directory and snooping protocols</p>
    <p>Directory</p>
    <p>Snooping</p>
    <p>Broadcast-if-shared</p>
    <p>Owner</p>
    <p>Group</p>
    <p>OLTP workload</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 24</p>
    <p>Indexing Design Space</p>
    <p>Index by cache block (64B)  Works well (as shown)</p>
    <p>Index by program counter (PC)  Simple schemes not as effective with PCs</p>
    <p>See paper</p>
    <p>Index by macroblock (256B or 1024B)  Exploit spatial predictability of sharing misses</p>
    <p>Aggregate information for spatially-related blocks</p>
    <p>E.g., reading a shared buffer, process migration</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 25</p>
    <p>Macroblock Indexing</p>
    <p>Broadcast-if-shared</p>
    <p>Owner</p>
    <p>Group</p>
    <p>Directory</p>
    <p>Snooping</p>
    <p>OLTP workload</p>
    <p>Legend</p>
    <p>Macroblock indexing is an improvement Group improves substantially (30%  10%)</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 26</p>
    <p>Finite Size Predictors</p>
    <p>8192 entries  32kB to 64kB predictor</p>
    <p>2-4% of L2 cache size (smaller than L2 tags)</p>
    <p>Broadcast-if-shared</p>
    <p>Owner</p>
    <p>Group</p>
    <p>Directory</p>
    <p>Snooping</p>
    <p>unbounded 8192 entries</p>
    <p>Legend</p>
    <p>OLTP workload, 1024B macroblock index</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 27</p>
    <p>Runtime Results</p>
    <p>What point in the design space to simulate?  As available bandwidth  infinite</p>
    <p>snooping performs best (no indirections)  As available bandwidth  0,</p>
    <p>directory performs best (bandwidth efficient)</p>
    <p>Bandwidth/latency  cost/performance tradeoff  Cost is difficult to quantify (cost of chip bandwidth)  Other associated costs (snoop b/w, power use)  Bandwidth under-design will reduce performance</p>
    <p>Our evaluation: measure runtime &amp; traffic  Simulate plentiful (but limited) bandwidth</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 28</p>
    <p>Runtime Results: OLTP</p>
    <p>1/2 runtime of directory, 2/3 traffic of snooping</p>
    <p>Broadcast-if-shared Owner</p>
    <p>Group</p>
    <p>Directory</p>
    <p>Snooping</p>
    <p>Mostly data traffic</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 29</p>
    <p>More Runtime Results</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 30</p>
    <p>Conclusions</p>
    <p>Destination-set prediction is effective  Provides better bandwidth/latency tradeoffs</p>
    <p>(Not just the extremes of snooping and directory)</p>
    <p>Significant benefit from macroblock indexing</p>
    <p>Result summary: 90% the performance of snooping, only 15% more bandwidth than directory</p>
    <p>Simple, low-cost predictors  Many further improvements possible</p>
    <p>One current disadvantage: protocol complexity  Solution: use Token Coherence [ISCA 2003]</p>
  </div>
  <div class="page">
    <p>Destination-Set Prediction  ISCA03 - Milo Martin slide 31</p>
  </div>
</Presentation>
