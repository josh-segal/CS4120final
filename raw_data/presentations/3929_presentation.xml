<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>The data, they are a-changin (ReComp: Your Data Will Not Stay Smart Forever)</p>
    <p>Paolo Missier, Jacek Cala, Eldarina Wijaya School of Computing Science,</p>
    <p>Newcastle University {firstname.lastname}@ncl.ac.uk</p>
    <p>TAPP16</p>
    <p>McLean, VA, USA June, 2016</p>
    <p>(*) Painting by Johannes Moreelse</p>
    <p>(*)</p>
    <p>Panta Rhei (Heraclitus, through Plato)</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>Data to Knowledge</p>
    <p>Lots of Data</p>
    <p>Big Analytics Machine</p>
    <p>Valuable Knowledge</p>
    <p>Meta-knowledge</p>
    <p>Algorithms Tools</p>
    <p>Middleware Reference datasets</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>The missing element: time</p>
    <p>Lots of Data</p>
    <p>Big Analytics Machine</p>
    <p>Valuable Knowledge</p>
    <p>V3</p>
    <p>V2</p>
    <p>V1</p>
    <p>Meta-knowledge</p>
    <p>Algorithms Tools</p>
    <p>Middleware Reference datasets</p>
    <p>t</p>
    <p>t</p>
    <p>t</p>
    <p>Your Data Will Not Stay Smart Forever</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>ReComp</p>
    <p>Observe change  In input data  In meta-knowledge</p>
    <p>Assess and measure  knowledge decay</p>
    <p>Estimate  Cost and benefits of refresh</p>
    <p>Enact  Reproduce (analytics)</p>
    <p>processes</p>
    <p>Lots of Data</p>
    <p>The Big Analytics Machine</p>
    <p>Valuable Knowledge</p>
    <p>V3</p>
    <p>V2</p>
    <p>V1</p>
    <p>Meta-knowledge</p>
    <p>Algorithms Tools</p>
    <p>Middleware Reference datasets</p>
    <p>t</p>
    <p>t</p>
    <p>t</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>The ReComp decision support system Observe change</p>
    <p>Assess and measure</p>
    <p>Estimate</p>
    <p>Enact</p>
    <p>Change Events</p>
    <p>Diff(.,.) functions</p>
    <p>utility functions</p>
    <p>Impact estimation</p>
    <p>Cost estimates Reproducibility assessment</p>
    <p>ReComp Decision Support System</p>
    <p>History of Knowledge Assets and their metadata</p>
    <p>Re-computation recommendations</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>ReComp concerns</p>
    <p>Structure  Data flow</p>
    <p>Provenance</p>
    <p>Reproducibility - Virtualisation - Smart re-run</p>
    <p>Scope: Which instances?  Frequency: how often?  Re-run Extent: how much?</p>
    <p>Change Events</p>
    <p>Diff(.,.) functions</p>
    <p>utility functions</p>
    <p>Impact estimation</p>
    <p>Cost estimates Reproducibility assessment</p>
    <p>ReComp Decision Support System</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>Observability / transparency</p>
    <p>White box</p>
    <p>Black box</p>
    <p>Structure (static view)</p>
    <p>Dataflow - eScience Central, Taverna,</p>
    <p>VisTrails Scripting: - R, Matlab, Python...</p>
    <p>- Packaged components - Third party services</p>
    <p>Data dependencies (runtime view)</p>
    <p>Provenance recording:  Inputs,  Reference datasets,  Component versions,  Outputs</p>
    <p>Input  Outputs  No data dependencies  No details on individual</p>
    <p>components Cost  Detailed resource monitoring</p>
    <p>Cloud    Wall clock time  Service pricing  Setup time (eg model</p>
    <p>learning)</p>
    <p>This talk: White box ReComp -- initial experiments</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>Example: genomics / variant interpretation</p>
    <p>SVI is a classifier of likely variant deleteriousness:</p>
    <p>y = {(v, class)|v  varset, class  {red, amber, green}}</p>
    <p>Uncertain diagnosis</p>
    <p>Definitely deleterious</p>
    <p>Definitely benign</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>OMIM and ClinVar changes</p>
    <p>Sources of changes: - Patient variants  improved sequencing / variant calling - ClinVar, OMIM evolve rapidly - New reference data sources</p>
    <p>CLINVAR / OMIM relevant changes over time for a patient cohort (Newcastle Institute of Genetics Medicine)</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>x11</p>
    <p>x12 y11</p>
    <p>P</p>
    <p>D11 D12</p>
    <p>White box ReComp For each run i:</p>
    <p>Observables: Inputs X = {xi1, x12, } Outputs y = {yi1, yi2,} Dependencies D11, D12, ... Variable-granularity provenance prov(y) Granular Cost(y)  single-block level Granular Process structure P  workflow graph</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>White-box provenance</p>
    <p>entity(om, [prov:type = OMIM, version = v])</p>
    <p>entity(ph, [prov:type = prov:collection])</p>
    <p>entity(cv, [prov:type = CV, version = v])</p>
    <p>entity(vars, [prov:type = prov:collection])</p>
    <p>used(PtG, om, [prov:role = dep])</p>
    <p>used(PtG, ph, [prov:role = input])</p>
    <p>used(vClass, cv, [prov:role = dep])</p>
    <p>used(vClass, vars, [prov:role = input])</p>
    <p>x11</p>
    <p>x12 y11</p>
    <p>P</p>
    <p>D11 D12</p>
    <p>Coarse:</p>
    <p>used(Pj, dij, [prov : role = dep]), di,j 2 Di 2 DGranular:</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>A history of runs</p>
    <p>x11</p>
    <p>x12 y1</p>
    <p>P</p>
    <p>D11 DCV</p>
    <p>Run 1, Patient A</p>
    <p>x21</p>
    <p>x22 y2</p>
    <p>P</p>
    <p>D21 DCV</p>
    <p>Run 2, Patient B</p>
    <p>History database: H = {h(y, v) = hP v, Dv, xv, prov(yv), cost(yv)i}</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>ReComp questions</p>
    <p>Scope: Which instances? Which patients within the cohort are going to be affected by change in input/reference data?</p>
    <p>Re-run Extent: how much? Where in each process instance is the reference data used?</p>
    <p>Impact: why bother? For each patient in scope, how likely is that any patients diagnosis will change?</p>
    <p>Frequency: how often? How often are updates available for the resources we depend on?</p>
    <p>x11</p>
    <p>x12 y11</p>
    <p>P</p>
    <p>D11 D12</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>Available Metadata</p>
    <p>di OM(OM v, OM v</p>
    <p>di CV (CV v, CV v</p>
    <p>{var 2 V |varstatus(var, CV v) 6= varstatus(var, CV v 0 )}</p>
    <p>[ CV v 0 \ CV v [ CV v \ CV v</p>
    <p>H = {h(y, v) = hP v, Dv, xv, prov(yv), cost(yv)i}</p>
    <p>di d(D v i , D</p>
    <p>v0</p>
    <p>i )</p>
    <p>di in(x v i , x</p>
    <p>v0</p>
    <p>i )</p>
    <p>di out</p>
    <p>(yv i</p>
    <p>, yv 0</p>
    <p>i</p>
    <p>)</p>
    <p>Example:</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>The ClinVar diff function  two steps</p>
    <p>ADDED REMOVED RETAINED</p>
    <p>CVv\CVv CVv CVv CVv\CVv</p>
    <p>{ var  V| varstatus(var, CVv) }  { pathogenic, benign } REMOVED</p>
    <p>{ var  V| varstatus(var, CVv)  { pathogenic, benign } }</p>
    <p>ADDED</p>
    <p>{ var  V| varstatus(var, CVv)  varstatus(var, CVv)  ( varstatus(var, CVv)  { pathogenic, benign }  varstatus(var, CVv)  { pathogenic, benign } ) }</p>
    <p>RETAINED</p>
    <p>Up to 99%selectivity</p>
    <p>CVREM</p>
    <p>CVCHG</p>
    <p>CVADD</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>Given observed changes in resources</p>
    <p>History instance:</p>
    <p>di d(D v i , D</p>
    <p>v0</p>
    <p>i )</p>
    <p>h(y, v) = hP v, Dv, xv, prov(yv), cost(yv)i 2 H</p>
    <p>Case 1: Granular provenance</p>
    <p>dij 2 di d(D v i , D</p>
    <p>v0</p>
    <p>i )</p>
    <p>is in the scope S  H if used(Pj, dij, [prov:role = dep]) 2 prov(yv)</p>
    <p>Pj is added to Pscope(y)</p>
    <p>see for instance Smart Run Manager [1]</p>
    <p>[1] Ludscher, B., Altintas, I., Berkley, C., Higgins, D., Jaeger-Frank, E., Jones, M., Lee, E., Tao, J., Zhao, Y.: Scientific Workflow Management and the Kepler System. Concurrency and Computation: Practice &amp; Experience, Special Issue on Scientific Workflows, 2005, Wiley.</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>Scoping: Any instance that depends on any Dij is in scope:</p>
    <p>Pscope = {Pj}, where:</p>
    <p>For each</p>
    <p>Case 2: Coarse-grained provenance</p>
    <p>dij 2 di d(D v i , D</p>
    <p>v0</p>
    <p>i )</p>
    <p>Re-run Extent: The mechanism from the fine-grained case still works</p>
    <p>used(Pj, Di, [prov:role = dep]), dij 2 Di</p>
    <p>This is trivial for a homogenenous run population, but H may contain run history for many different workflows!</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>Assessing impact and cost</p>
    <p>Approach: small-scale re-comp over the population in scope 1. Sample instances S  S from the population in scope S 2. Perform partial re-run on each instance h(yi,v)  S,</p>
    <p>generating new outputs yi 3. Compute 4. Assess impact (user-defined) and cost(y) 5. Estimate cost difference diff(cost(y), cost(y))</p>
    <p>di out</p>
    <p>(yv i</p>
    <p>, yv 0</p>
    <p>i</p>
    <p>)</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>ReComp user dashboard and architecture</p>
    <p>ReComp decision dashboard</p>
    <p>Execute Curate</p>
    <p>Select/ prioritise</p>
    <p>pr os</p>
    <p>pe ct</p>
    <p>iv e</p>
    <p>pr ov</p>
    <p>en an</p>
    <p>ce</p>
    <p>cu ra</p>
    <p>tio n</p>
    <p>(Y w or kf lo w )</p>
    <p>Meta-Knowledge Repository</p>
    <p>Research Objects</p>
    <p>Change Impact</p>
    <p>Analysis</p>
    <p>Cost Estimation</p>
    <p>Differential Analysis</p>
    <p>Reproducibility Assessment</p>
    <p>- Utility functions - Priorities policies - Data similarity functions</p>
    <p>domain knowledge</p>
    <p>runtime monitor</p>
    <p>Logging</p>
    <p>Runtime Provenance recorder</p>
    <p>runtime monitor</p>
    <p>Logging</p>
    <p>Runtime Provenance recorder</p>
    <p>Python</p>
    <p>WP1</p>
    <p>- provenance - logs - data and process versions - process dependencies</p>
    <p>(other analytics environments)</p>
    <p>ReComp is a Decision Support System Impact, cost assessment  ReComp user dashboard</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>Current status and Challenges</p>
    <p>Implementation in progress Small scale experiments on scoping / partial re-run - Test cohort of about 50 (real) patients - Short workflows runs (about 15 mins), observable cost savings - (preliminary results) Main challenge: deliver a generic and reusable DSS From eScience Central  To generic dataflow, scripting (Python) From eSc prov traces  PROV-compliant but idiosincratic patterns Python  noWorkflow traces To: Canonical PROV patterns + queries + H DB implementation</p>
    <p>ReComp: http://recomp.org.uk/</p>
  </div>
  <div class="page">
    <p>TA P</p>
    <p>P 1</p>
    <p>M is</p>
    <p>si er</p>
    <p>, 2 01</p>
    <p>References</p>
    <p>[1] Ludscher, B., Altintas, I., Berkley, C., Higgins, D., Jaeger-Frank, E., Jones, M., Lee, E., Tao, J., Zhao, Y.: Scientific Workflow Management and the Kepler System. Concurrency and Computation: Practice &amp; Experience, Special Issue on Scientific Workflows, 2005, Wiley.</p>
    <p>[2] Ikeda, Robert, Semih Salihoglu, and Jennifer Widom. Provenance-Based Refresh in Data-Oriented Workflows. In Procs CIKM, 2011</p>
    <p>[3] R. Ikeda and J. Widom. Panda: A system for provenance and data. Procs TaPP10, 33:18, 2010.</p>
    <p>[4] D. Koop, E. Santos, B. Bauer, M. Troyer, J. Freire, and C. T. Silva. Bridging workflow and data provenance using strong links. In Scientific and statistical database management, pages 397415. Springer, 2010. ISBN 3642138179.</p>
    <p>[5] P. Missier, E. Wijaya, R. Kirby, and M. Keogh. SVI: a simple single-nucleotide Human Variant Interpretation tool for Clinical Use. In Procs. 11th International conference on Data Integration in the Life Sciences, Los Angeles, CA, 2015. Springer.</p>
  </div>
</Presentation>
