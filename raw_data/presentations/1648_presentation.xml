<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Uncovering Access, Reuse, and Sharing Characteristics of I/OIntensive Files on Large-Scale</p>
    <p>Production HPC Systems</p>
    <p>Tirthak Patel Northeastern University</p>
    <p>Devesh Tiwari Northeastern University</p>
    <p>Suren Byna, Glenn K. Lockwood, Nicholas J. Wright</p>
    <p>Lawrence Berkley National Laboratory</p>
    <p>Philip Carns, Robert Ross Argonne National Laboratory</p>
  </div>
  <div class="page">
    <p>HPC systems suffer from severe I/O bottleneck!</p>
  </div>
  <div class="page">
    <p>What is This Study About? In-depth characterization and analysis of access, reuse, and sharing characteristics of I/O-intensive</p>
    <p>files on a top 500 supercomputer.</p>
  </div>
  <div class="page">
    <p>What is This Study About? In-depth characterization and analysis of access, reuse, and sharing characteristics of I/O-intensive</p>
    <p>files on a top 500 supercomputer.</p>
    <p>Examples include: (1) whether HPC files are ready-heavy, write-heavy, or both; (2) sharing of a file across multiple applications; (3) I/O variability within a run across runs!</p>
  </div>
  <div class="page">
    <p>Our Study Platform</p>
    <p>Shared Parallel Storage System (scratch space)</p>
  </div>
  <div class="page">
    <p>Our Study Platform</p>
    <p>Application-level I/O tracing using Darshan</p>
    <p>to collect file I/O access patterns</p>
  </div>
  <div class="page">
    <p>Take it with a grain of salt! (or three)</p>
    <p>Some information is not available for correlation. Performing what-if analysis and beyond Darshans tracing capability is not possible.</p>
    <p>Findings may be true for other systems, but we dont make this claim. Inherently influenced by NERSC policies, filesystem, and workloads.</p>
    <p>Burst buffer effects do not threaten the validity today but needs to be revisited in a few years.</p>
  </div>
  <div class="page">
    <p>Terms &amp; Definitions Identifying</p>
    <p>I/O-intensive files</p>
    <p>The files that transfer &gt;100 GB and are accessed by multiple applications</p>
  </div>
  <div class="page">
    <p>Terms &amp; Definitions Identifying</p>
    <p>I/O-intensive files Dominant I/O type for</p>
    <p>I/O-intensive files</p>
    <p>The files that transfer &gt;100 GB and are accessed by multiple applications</p>
    <p>Write-Heavy (WH) Files (~7%) Read-Write (RW) Files (~71%) Read-Heavy (RH) Files (~22%)8 PB of data transfer, 8.5k files,</p>
    <p>~400k jobs</p>
  </div>
  <div class="page">
    <p>Terms &amp; Definitions Classification of jobs / runs accessing files</p>
    <p>Traditionally, HPC applications are assumed to perform both read and write I/O during the same run in different phases, but</p>
    <p>does that continue to remain true?</p>
  </div>
  <div class="page">
    <p>Terms &amp; Definitions Classification of jobs/ runs accessing files</p>
    <p>Runs can be classified as read runs (68%) or write runs (32%)</p>
  </div>
  <div class="page">
    <p>Terms &amp; Definitions Classification of jobs / runs accessing files</p>
    <p>Runs can be classified as read runs (68%) or write runs (32%)</p>
    <p>Non-monolithic applications provide the opportunity to better schedule</p>
    <p>different components of a large workflow to avoid I/O contention</p>
    <p>among different workflows.</p>
    <p>.anFS/alice/, and the associated POSIX ACLs protect user files.</p>
    <p>result of a workflow execution at very minimal cost. This allows the user to utilize the intermediate data for future analysis. We have implemented provenance support on top of the distributed database infrastructure (Figure 3) between the storage server (workflow table, anFS wf) and AFEs (Dataset task collection membership table, tcid oid). Recall that anFS wf stores information about the task and the AFE on which the task is executed; tcid oid stores the task collection to data object mapping and will also need to be maintained on the storage server. Upon receiving a provenance query regarding a dataset, AnalyzeThis searches the anFS dirent table to get the anFS inode of the file, which is used to get the object id. The object id is then used to retrieve the task collection id from the tcid oid table. The task collection id is used to obtain the AFE id from the anFS wf table. Alternatively, if tcid oid is not maintained on the storage server as well, we can broadcast to the AFEs to determine the task collection id for a data object id. Further analysis of the lineage is performed on that AFE. Using the task collection id and the attribute page we get the task collection attribute page number. Using the predefined attribute oset all the information regarding the task is fetched. The task provenance from multiple AFEs is merged with similar job-level information that is maintained at the storage server in the anFS wf table.</p>
    <p>of the following: (1) client desktop computer that submits analysis workflows, (2) storage server within the AnalyzeThis appliance, and (3) the networked machines that emulate the AFEs (four AFEs are connected to the storage server). For the desktop computer and the storage server, we used a 1.8 GHz Intel Xeon E5-2603 processor. We emulated the AFEs using Atom machines with RAM disks, to mimic the flash controller and the internal flash chips with high I/O bandwidth to the controller. The Atom-based AFEs use a single 1.8 GHz Atom processor as the controller, a 3 GB RAM disk as the flash chip, and a 1 Gbps Ethernet connection to the storage server within the AnalyzeThis appliance. All servers run the Linux kernel 2.6.32-279. anFS oers a read and write bandwidth of 120 MB/s and 80 MB/s, respectively.</p>
    <p>Software: AnalyzeThis has been implemented using 10 K lines of C code. We extended the OSD iSCSI target emulator from the open-osd project [33], for the AFE target. The task executions in an AFE are serialized by spawning a dedicated thread, which mimics dedicating a device controller for active processing. For the AFE-OSD driver in the storage server, we extended the OSD initiator driver in the Linux kernel. We also extended exoFS [12] to synchronize the OSD object id space with the userspace anFS. anFS has been implemented using FUSE [13], and it keeps track of metadata using SQLite [48].</p>
    <p>Scientific Workflows: We used several real-world complex workflows. We used Montage [27], Brain Atlas [28], Sipros [54], and Grep [14] workflows. The DAG representa</p>
    <p>ExoFS</p>
    <p>AFE-OSD Initiator</p>
    <p>anFS (FUSE)</p>
    <p>Storage Server (Xeon 1.8GHz 64GB RAM)</p>
    <p>(Xeon 1.8GHz 64GB RAM)</p>
    <p>AFE Emulator</p>
    <p>AnalyzeThis Appliance</p>
    <p>G b</p>
    <p>E</p>
    <p>Network Switch</p>
    <p>AFE-OSD Target</p>
    <p>Atom 1.8GHz 4GB RAM</p>
    <p>RAM Disk</p>
    <p>RD: 1.2GB/s WR: 450MB/s</p>
    <p>Offline Data Analysis via anFS</p>
    <p>Data Analysis with AnalyzeThis</p>
    <p>Client Desktop</p>
    <p>Computer</p>
    <p>Figure 4: AnalyzeThis testbed.</p>
    <p>(a) Montage Workflow</p>
    <p>b</p>
    <p>b</p>
    <p>b</p>
    <p>b b</p>
    <p>c</p>
    <p>a mImgtblfits b tbl mProjectPP</p>
    <p>mAdd mJPEG</p>
    <p>c jpg</p>
    <p>mOverlaps mDiffFit</p>
    <p>mBgModel mBgExec</p>
    <p>Input/Output Data Analysis Kernel</p>
    <p>a</p>
    <p>a align_warpimage b header reslice</p>
    <p>softmean slicerd slice convert</p>
    <p>Input/Output Data Analysis Kernel</p>
    <p>e graphic</p>
    <p>b a b a b a ba b</p>
    <p>c params</p>
    <p>c c c c</p>
    <p>a b a b a b a b</p>
    <p>a b</p>
    <p>d d d</p>
    <p>e e e</p>
    <p>a a a a a a a a a a b</p>
    <p>c c c c c c c c c c</p>
    <p>d e</p>
    <p>f g h</p>
    <p>a siprosFT2 b DB filtering</p>
    <p>assembly d psm.txt</p>
    <p>Input/Output Data Analysis Kernel</p>
    <p>e pep.txt</p>
    <p>c sip</p>
    <p>f pro.txt g pro2psm.txt h pro2pep.txt</p>
    <p>(c) Sipros Workflow(b) Brain Atlas Workflow</p>
    <p>Figure 5: The DAGs representing the workflows.</p>
    <p>tions and the details of the workflows are shown in Figure 5 and Table 1. The Montage workflow [27] creates a mosaic with 10 as</p>
    <p>tronomy images. It uses 8 analysis kernels, and is composed of 36 tasks, several of which can be parallelized to run on the AFEs. The Brain workflow [28] creates population-based brain atlases from the fMRI Data Centers archive of high resolution anatomical data, and is part of the first provenance challenge [28] used in our provenance evaluation. The Sipros workflow runs DNA search algorithms with database files to identify and quantify proteins and their variants from various community proteomics studies. It consists of 12 analysis tasks, and uses three analysis kernels. The Grep workflow counts the occurrences of ANSI C keywords in the Linux source files.</p>
    <p>Input Intermediate Output Total Object</p>
    <p>(MB) (#)</p>
    <p>Montage 51 222 153 426 113 Brain 70 155 20 245 35 Sipros 84 87 1 172 45 Grep 463 363 1 827 13</p>
    <p>Table 1: Workflow input, output and intermediate data size.</p>
  </div>
  <div class="page">
    <p>File Reuse Characteristics</p>
  </div>
  <div class="page">
    <p>Inter-Arrival of Runs Inter-arrival times of read and write runs</p>
    <p>accessing the same I/O-intensive files</p>
    <p>R WR R W W WRRWRuns with File Access</p>
    <p>Number of Consecutive Read Runs</p>
    <p>Number of Consecutive Write Runs</p>
    <p>Inter-Arrival Time of Read Runs</p>
    <p>Inter-Arrival Time of Write Runs</p>
  </div>
  <div class="page">
    <p>Read &amp; Write Run Inter-arrival Times</p>
    <p>Most I/O-intensive files get re-accessed after a relatively long period (&gt;50 hours) - much longer than the avg. runtime of jobs!</p>
    <p>The inter-arrival times for both read and write runs are similar.</p>
    <p>R WR R W W WRRWRuns with File Access</p>
    <p>Number of Consecutive Read Runs</p>
    <p>Number of Consecutive Write Runs</p>
    <p>Inter-Arrival Time of Read Runs</p>
    <p>Inter-Arrival Time of Write Runs</p>
  </div>
  <div class="page">
    <p>Consecutive Runs of the Same Type</p>
    <p>Some HPC files experience a very long string of consecutive read runs, in contrast with smaller consecutive write runs.</p>
    <p>R WR R W W WRRWRuns with File Access</p>
    <p>Number of Consecutive Read Runs</p>
    <p>Number of Consecutive Write Runs</p>
    <p>Inter-Arrival Time of Read Runs</p>
    <p>Inter-Arrival Time of Write Runs</p>
    <p>Partitioning of I/O servers to separately serve RH files (which perform many consecutive reads) and RW files (for read and write runs) can boost I/O</p>
    <p>performance.</p>
  </div>
  <div class="page">
    <p>File Sharing Across Applications</p>
  </div>
  <div class="page">
    <p>File Sharing Across Applications</p>
    <p>Majority (~86%) of files accessed by multiple applications are RW files. Only 12% of these shared files are RH files and only</p>
    <p>at least 2 apps</p>
  </div>
  <div class="page">
    <p>File Sharing Across Applications</p>
    <p>The producer and the consumer are launched significantly apart in time - potential caching across applications has to be</p>
    <p>carefully managed.</p>
  </div>
  <div class="page">
    <p>Data Transfer Characteristics Per I/O Run and Per OST</p>
  </div>
  <div class="page">
    <p>Hypothesis The total amount of data read is higher than the total amount of data written. The number of read</p>
    <p>runs are higher than the number of write runs.</p>
    <p>Is it accurate to hypothesize that the amount of data read per run is higher than the amount of</p>
    <p>data written per run?</p>
    <p>R WR R W W WRRWRuns with File Access</p>
    <p>Number of Consecutive Read Runs</p>
    <p>Number of Consecutive Write Runs</p>
    <p>Inter-Arrival Time of Read Runs</p>
    <p>Inter-Arrival Time of Write Runs</p>
  </div>
  <div class="page">
    <p>Data Transfer Per Read &amp; Write Run</p>
    <p>Surprisingly, write runs transfer more amount of data than read runs per run. This finding can be exploited to manage</p>
    <p>I/O contention better at the system-level by limiting the number of concurrently executing write runs.</p>
  </div>
  <div class="page">
    <p>Hypothesis</p>
    <p>OST are capacity-balanced and have similar amount of data transfer.</p>
    <p>OST 1 OST 2 OST 248OST 247</p>
    <p>............</p>
  </div>
  <div class="page">
    <p>Data Transfer Per OST</p>
    <p>OSTs are balanced in terms of number of files but not amount of data transferred per OST -- emphasizing the need for dynamic file migration, and replication of read-only data.</p>
  </div>
  <div class="page">
    <p>I/O Variability</p>
  </div>
  <div class="page">
    <p>Faster ranks having to wait for the slower ranks to</p>
    <p>finish I/O before they can resume computation, thus wasting precious compute cycles on the HPC system</p>
    <p>Intra-run I/O Variability</p>
    <p>A</p>
    <p>A</p>
    <p>B AA</p>
  </div>
  <div class="page">
    <p>Faster ranks having to wait for the slower ranks to</p>
    <p>finish I/O before they can resume computation, thus wasting precious compute cycles on the HPC system</p>
    <p>Intra-run I/O Variability</p>
    <p>High degree of variability in I/O time of ranks/processes with</p>
    <p>similar I/O size belonging to the same application.</p>
    <p>A</p>
    <p>A</p>
    <p>B AA</p>
  </div>
  <div class="page">
    <p>Inter-run I/O Variability</p>
    <p>A B A B A C A C</p>
    <p>Time t1 Time t2</p>
  </div>
  <div class="page">
    <p>Inter-run I/O Variability</p>
    <p>HPC files have consistent run-to-run data transfer behavior but observe significantly different I/O time across runs.</p>
    <p>Read-heavy files which have the least variability in I/O data size, but the most variability in I/O time - indicating the need</p>
    <p>for special attention to read-heavy files.</p>
    <p>A B A B A C A C</p>
    <p>Time t1 Time t2</p>
  </div>
  <div class="page">
    <p>Conclusion  There is an open opportunity to leverage the favorable</p>
    <p>characteristics of HPC I/O (classifiable files, single-I/O-type runs, long inter-arrival times) to better manage HPC I/O.</p>
    <p>Lack of coordinated I/O management at the OST level exacerbates the I/O variability and contention challenges.</p>
    <p>Inter-run and intra-run I/O variability not only cause runtime variability but also waste I/O bandwidth and compute cycles</p>
  </div>
</Presentation>
