<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>On Zone Balancing of Peer to Peer Networks: Analysis of Random Node Join</p>
    <p>Xiaoming Wang, Yueping Zhang, Xiafeng Li, and Dmitri Loguinov</p>
    <p>Computer Science Texas A&amp;M University College Station, TX 77843</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>Motivation</p>
    <p>P2P Simulations</p>
    <p>Single-point Multi-point</p>
    <p>Conclusion</p>
    <p>Random Split</p>
    <p>Center Split</p>
    <p>Random d-sampling</p>
    <p>Deterministic d-sampling</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Structured P2P systems construct DHTs (Distributed Hash Tables) for efficient routing  Chord, CAN, de Bruijn</p>
    <p>Data objects are hashed into some virtual coordinate spaces</p>
    <p>Each user holds a zone in the DHT space  Stores data objects within</p>
    <p>its zone and answers queries for these objects C</p>
    <p>E</p>
    <p>D</p>
    <p>B</p>
    <p>A</p>
    <p>An instance of zone partition</p>
  </div>
  <div class="page">
    <p>Motivation 2</p>
    <p>Notice that the amount of user load is proportional to zone size  Imbalance can lead to hotspots and lower</p>
    <p>performance</p>
    <p>In addition, graph structure is unbalanced  Which leads to increased diameter, smaller node</p>
    <p>degree, lower bisection width</p>
    <p>Our paper studies how zone-balancing decisions during node join affect the resulting zone sizes  We derive the probability bounds on the maximum and</p>
    <p>minimum zone sizes</p>
  </div>
  <div class="page">
    <p>Basics</p>
    <p>Consider a system with n users  Assume a sequential join process</p>
    <p>Define two metrics for load balancing:</p>
    <p>Even partition</p>
    <p>maxmin</p>
    <p>We focus on the bounds of these two metrics that hold with probability 1  n ( &gt; 0)</p>
    <p>avg</p>
    <p>fmax = max / avg</p>
    <p>avg</p>
    <p>fmin = avg / min</p>
    <p>Random partition</p>
  </div>
  <div class="page">
    <p>Random Join Process</p>
    <p>Each new user randomly samples one or more existing peers and splits one of their zones</p>
    <p>The join decision includes two factors:</p>
    <p>Splitting</p>
    <p>Random Center Sampling</p>
    <p>Single-Point Multi-Point</p>
  </div>
  <div class="page">
    <p>Random Join Process 2</p>
    <p>We will compare these algorithms in terms of fmax and fmin  The optimal bound for the two metrics is 2</p>
    <p>No method can achieve better load-balancing</p>
    <p>Due to the time limit, we skip the single-point algorithms  Summary for random and center splits:</p>
  </div>
  <div class="page">
    <p>A Big Map</p>
    <p>Motivation</p>
    <p>P2P Simulations</p>
    <p>Single-point</p>
    <p>Conclusion</p>
    <p>Random Split</p>
    <p>Center Split</p>
    <p>Multi-point Random d-sampling</p>
    <p>Deterministic d-sampling</p>
  </div>
  <div class="page">
    <p>Multi-Point Center-Split  Next we examine multi-point schemes</p>
    <p>We use center-split for the rest of the talk</p>
    <p>Greedy methods  Motivated by the power of two choices</p>
    <p>Idea: extend the center-split model to sample d random points before the actual join</p>
    <p>Intuitive observation:  The more points sampled, the better the graph is</p>
    <p>balanced, but what are the actual bounds?</p>
  </div>
  <div class="page">
    <p>Multi-Point Center-Split 2  The extreme case is to sample every peer</p>
    <p>The resulting fmax is always optimal and concentrates on the ideal value 2</p>
    <p>However, this method will suffer from huge traffic overhead</p>
    <p>Thus, the tradeoff is between:  The balancing performance of the algorithm, and</p>
    <p>The amount of sampling traffic</p>
    <p>Next we study two multi-point schemes and present our analysis of this problem</p>
  </div>
  <div class="page">
    <p>A Big Map</p>
    <p>Motivation</p>
    <p>P2P Simulations</p>
    <p>Single-point Multi-point</p>
    <p>Conclusion</p>
    <p>Random Split</p>
    <p>Center Split</p>
    <p>Random d-sampling</p>
    <p>Deterministic d-sampling</p>
  </div>
  <div class="page">
    <p>Purely Random d-sampling  The method samples d independent uniformly</p>
    <p>random points X1, X2,, Xd  Splits the largest zone among the d choices</p>
    <p>How does the performance improve as a function of d?</p>
    <p>Based on the balls-into-bins model, we derive an asymptotic bound on fmax  The analysis is intractable when applying this model to fmin</p>
    <p>We leave this direction for future work</p>
  </div>
  <div class="page">
    <p>Purely Random d-sampling 2  Theorem 1: Under d-point sampling and center</p>
    <p>splits, the following bound holds with probability at least 1  n</p>
    <p>For d = 1, it reduces to the single-point model</p>
    <p>For d  2, the term (1 + ) log n is scaled down by a factor of d</p>
    <p>The power of two choices bound log log n / log d is not achieved here</p>
  </div>
  <div class="page">
    <p>Simulating Random d-sampling  Each of the following simulations is run for 1,000</p>
    <p>graphs with 30,000 nodes each</p>
    <p>fm ax</p>
    <p>model simulation</p>
  </div>
  <div class="page">
    <p>Further Discussion</p>
    <p>For d = c log n,</p>
    <p>For c, the second term goes to zero  And fmax is bounded by 2 with high probability</p>
    <p>Recall from the single-point method,  fmax  28 for n = 106 with probability 1  1/n</p>
    <p>The improvement is significant  But results in additional traffic overhead</p>
  </div>
  <div class="page">
    <p>Reducing Traffic Overhead</p>
    <p>How to reduce the join overhead?  While keeping the graph balanced</p>
    <p>Idea:  Randomly sample a peer</p>
    <p>Then deterministically sample its neighbors</p>
    <p>Subsequently walk along the edges of the graph to find additional peers to sample</p>
    <p>Two walking strategies:  Random walk selects arbitrary (random) neighbors</p>
    <p>Biased walk selects the largest neighbors</p>
  </div>
  <div class="page">
    <p>Reducing Traffic Overhead 2  Intuition: larger nodes are more likely to know</p>
    <p>additional large nodes</p>
    <p>This reduces the join overhead by a factor of (kDav)</p>
    <p>k is graph degree and Dav is the average distance</p>
    <p>The exact analysis is nontrivial since the walk process depends on the state of peers  We leave the exact model for future work</p>
    <p>Instead, we study a similar deterministic model  According to our analysis, it provides a lower bound</p>
    <p>on the performance of the other d-walk models</p>
  </div>
  <div class="page">
    <p>A Big Map</p>
    <p>Motivation</p>
    <p>P2P Simulations</p>
    <p>Single-point Multi-point</p>
    <p>Conclusion</p>
    <p>Random Split</p>
    <p>Center Split</p>
    <p>Random d-sampling</p>
    <p>Deterministic d-sampling</p>
  </div>
  <div class="page">
    <p>Deterministic d-sampling  The model samples a random point X1</p>
    <p>Then checks d  1 additional points according to a simple deterministic rule</p>
    <p>Points X2,,Xi, Xd are obtained by adding i/d of the total size of the DHT space to X1</p>
    <p>An example of d = 4  X1 is the first random sample</p>
    <p>The points X2, X3, X4 are found by adding , , and  of the circles circumference to X1</p>
    <p>X1</p>
    <p>X2</p>
    <p>X4</p>
    <p>X3</p>
  </div>
  <div class="page">
    <p>Deterministic d-sampling 2  Theorem 2: In deterministic sampling, the</p>
    <p>following bound holds with probability at least 1  n</p>
    <p>This result differs from that of random d-sampling by a constant</p>
    <p>Notice that  is positive  Thus, the deterministic model is worse than the</p>
    <p>random model  But how much is the difference?</p>
    <p>where</p>
  </div>
  <div class="page">
    <p>Simulating Deterministic Sampling</p>
    <p>The model is conservative on some points  Round-off errors at d not powers of 2</p>
    <p>fm ax</p>
    <p>model simulation</p>
  </div>
  <div class="page">
    <p>Purely Random vs Deterministic</p>
    <p>With the previous results on fmax, we compare the two multi-point models ( = 0.22)</p>
    <p>fm ax</p>
    <p>random deterministic</p>
    <p>fm ax</p>
    <p>random deterministic</p>
    <p>n=106 n=107</p>
  </div>
  <div class="page">
    <p>Purely Random vs Deterministic</p>
    <p>Further question:  How many samples does the deterministic model need</p>
    <p>to approximate the random model?</p>
    <p>Theorem 3: Assuming that the random method samples c1 logn points and the deterministic method samples c2 logn points, the corresponding upper bounds on fmax are equal if</p>
  </div>
  <div class="page">
    <p>Pure Random vs Deterministic 3</p>
    <p>For c1 = 1 (fmax  4) and  = 1 (probability 11/n), the two methods are equivalent if  The deterministic model samples 2.2 times more</p>
    <p>points than the random model</p>
    <p>For c1 = 2 (fmax  3.5) and  = 2 (probability 11/n2), the difference is by a factor of 5.1</p>
    <p>In summary:  Each model has its benefits (low overhead vs.</p>
    <p>performance)</p>
    <p>What about graph properties?</p>
  </div>
  <div class="page">
    <p>A Big Map</p>
    <p>Motivation</p>
    <p>P2P Simulations</p>
    <p>Single-point Multi-point</p>
    <p>Conclusion</p>
    <p>Random Split</p>
    <p>Center Split</p>
    <p>Random d-sampling</p>
    <p>Deterministic d-sampling</p>
  </div>
  <div class="page">
    <p>P2P Simulations</p>
    <p>We next compare the performance of multi-point methods in P2P simulations  Our main metric of interest is the degree distribution</p>
    <p>Three models  Purely random d-sampling</p>
    <p>Random walk</p>
    <p>Biased walk</p>
    <p>De Bruijn DHT (based on ODRI, SIGCOMM 2003) with n = 30,000 nodes and degree k = 8</p>
  </div>
  <div class="page">
    <p>Degree Distribution - CDF</p>
    <p>Single-point, center-split scheme sets the basis for comparison</p>
    <p>C D</p>
    <p>F</p>
    <p>100 iterations</p>
    <p>Largest degree 81</p>
    <p>5.7% of all nodes have degree 1</p>
    <p>13% with degree 1 or 2</p>
  </div>
  <div class="page">
    <p>Degree Distribution - CDF</p>
    <p>Multi-point schemes perform much better</p>
    <p>Purely random</p>
    <p>d1 = 11</p>
    <p>Deterministic  d2 = 24 = 2.2d1</p>
    <p>40% of the nodes have the ideal degree 8</p>
    <p>C D</p>
    <p>F</p>
    <p>purely random random w alk biased w alk</p>
  </div>
  <div class="page">
    <p>Degree Distribution - PDF</p>
    <p>Overhead: random 55 messages per join and deterministic 7 per join, but performance is similar</p>
    <p>P D</p>
    <p>F</p>
    <p>purely random random w alk biased w alk</p>
  </div>
  <div class="page">
    <p>A Big Map</p>
    <p>Motivation</p>
    <p>P2P Simulations</p>
    <p>Single-point Multi-point</p>
    <p>Conclusion</p>
    <p>Random Split</p>
    <p>Center Split</p>
    <p>Random d-sampling</p>
    <p>Deterministic d-sampling</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>P er</p>
    <p>fo rm</p>
    <p>an ce</p>
    <p>Overhead</p>
    <p>Legend: Single-point center split</p>
    <p>Purely random</p>
    <p>Deterministic</p>
    <p>Chord</p>
    <p>CAN</p>
    <p>ODRI SIGCOMM 2003</p>
    <p>Adler et al. STOC 2003</p>
    <p>Naor et al. SPAA 2003</p>
    <p>D2B PODC 2003</p>
  </div>
</Presentation>
