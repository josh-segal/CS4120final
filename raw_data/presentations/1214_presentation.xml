<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Optimized Query Execution in Large Search Engines with Global Page Ordering</p>
    <p>Xiaohui Long Torsten Suel</p>
    <p>CIS Department Polytechnic University</p>
    <p>Brooklyn, NY 11201</p>
  </div>
  <div class="page">
    <p>intro: query processing in search engines  related work: query execution and pruning techniques  algorithmic techniques  experimental evaluation: single and multiple nodes  concluding remarks</p>
    <p>Talk Outline:</p>
    <p>how to optimize query throughput in large search engines, when the ranking function is a combination of term-based ranking and a global ordering such as Pagerank</p>
    <p>The Problem:</p>
  </div>
  <div class="page">
    <p>inverted index - a data structure for supporting text queries - like index in a book</p>
    <p>Query processing in search engines (single node case)</p>
    <p>inverted index</p>
    <p>aalborg 3452, 11437, .. .. . .. arm 4, 19, 29, 98, 143, ... armada 145, 457, 789, ... armadillo 678, 2134, 3970, ... armani 90, 256, 372, 511, ... . . . . . zz 602, 1189, 3209, ...</p>
    <p>disks with documents</p>
    <p>indexing</p>
    <p>Boolean queries: (zebra AND armadillo) OR alligator</p>
    <p>unions/intersections of lists</p>
  </div>
  <div class="page">
    <p>scoring function: assigns score to each document with respect to a given query</p>
    <p>top-k queries: return k documents with highest scores  example cosine measure for query with terms t to t</p>
    <p>Ranking in search engines:</p>
    <p>can be implemented by computing score for all documents that contain any of the query words (union of inverted lists)</p>
    <p>in case of search engines: often intersection instead of union  in large collections, lists are many MB for average queries</p>
  </div>
  <div class="page">
    <p>Basic Idea:</p>
    <p>significance of a page is determined by the significance of the pages linking to it</p>
    <p>Pagerank Algorithm: (Brin/Page 1998)</p>
    <p>More precisely:</p>
    <p>prune graph until no nodes with out-degree 0  initialize every node with value (N number of nodes)  iterate, where in each iteration we update each node as follows:</p>
    <p>where d(q) is the out-degree of q and = 0.15  corresponds to random walk with random jump with prob.</p>
    <p>Nqd</p>
    <p>qs ps</p>
    <p>pq</p>
    <p>)(</p>
    <p>)( )1()(</p>
    <p>N s(p) 1</p>
  </div>
  <div class="page">
    <p>recall the cosine measure:</p>
    <p>Combining Term-Based Methods and Pagerank</p>
    <p>Pagerank assigns a fixed score to each page (independent of query)  nave way of integrating Pagerank value:</p>
    <p>works for any global ordering of page scores (e.g., based on traffic)  but some more details remain</p>
  </div>
  <div class="page">
    <p>how to combine/add pagerank score and cosine? (addition)  use PR or log(PR) ?  normalize using mean of top-100 in list (Richardson/Domingo)</p>
    <p>Using Pagerank in ranking:</p>
  </div>
  <div class="page">
    <p>pages</p>
    <p>index</p>
    <p>pages</p>
    <p>index</p>
    <p>pages</p>
    <p>index</p>
    <p>pages</p>
    <p>index</p>
    <p>pages</p>
    <p>index</p>
    <p>broadcasts each query and combines the results</p>
    <p>LAN</p>
    <p>Cluster with global index organization</p>
    <p>Query Processing in Parallel Search Engines</p>
    <p>query integrator</p>
    <p>local index: every node stores and indexes subset of pages  every query broadcast to all nodes by query integrator (QI)  every node supplies top-10, and QI computes global top-10  note: we dont really need top-10 from all, maybe only top-2</p>
    <p>low-cost cluster architecture (usually with additional replication)</p>
  </div>
  <div class="page">
    <p>IR: optimized evaluation of cosine measures (since 1980s)  DB: top-k queries for multimedia databases (Fagin 1996)  does not consider combinations of term-based and global scores  Brin/Page 1998: fancy lists in Google</p>
    <p>Related Work on top-k Queries</p>
    <p>basic idea: presort entries in each inverted list by contribution to cosine</p>
    <p>also process inverted lists from shortest to longest list  various schemes, either reliable or probabilistic  most closely related: - Persin/Zobel/Sacks-Davis 1993/96</p>
    <p>- Anh/Moffat 1998, Anh/deKretzer/Moffat 2001</p>
    <p>typical assumptions: many keywords/query, OR semantics</p>
    <p>Related Work (IR)</p>
  </div>
  <div class="page">
    <p>motivation: searching multimedia objects by several criteria  typical assumptions: few attributes, OR semantics, random access</p>
    <p>FA (Fagins algorithm), TA (Threshold algorithm), others</p>
    <p>formal bounds: for k lists if lists independent</p>
    <p>term-based ranking: presort each list by contribution to cosine</p>
    <p>Related Work (DB) (Fagin 1996 and others)</p>
    <p>kN mm m 11</p>
  </div>
  <div class="page">
    <p>fancy lists optimization in Google  create extra shorter inverted list for fancy matches (matches that occur in URL, anchor text, title, bold face, etc.)</p>
    <p>note: fancy matches can be modeled by higher weights in the term-based vector space model</p>
    <p>no details given or numbers published</p>
    <p>Related Work (Google) (Brin/Page 1998)</p>
    <p>chair</p>
    <p>table</p>
    <p>fancy list</p>
    <p>fancy list</p>
    <p>rest of list with other matches</p>
    <p>rest of list with other matches</p>
  </div>
  <div class="page">
    <p>pruning techniques for query execution in large search engines</p>
    <p>focus on a combination of a term-based and a global score (such as Pagerank)</p>
    <p>techniques combine previous approaches such as fancy lists and presorting of lists by term scores</p>
    <p>experimental evaluation on 120 million pages</p>
    <p>very significant savings with almost no impact on results</p>
    <p>its good to have a global ordering!</p>
    <p>Results of our Paper</p>
  </div>
  <div class="page">
    <p>exhaustive algorithm: no pruning, traverse entire list  first-m: a nave algorithm with lists sorted by Pagerank; stop after m elements in intersection found  fancy first-m: use fancy and non-fancy lists, each sorted by Pagerank, and stop after m elements found</p>
    <p>reliable pruning: stop when top-k results found  fancy last-m: stop when at most m elements unresolved  single-node and parallel case with optimization</p>
    <p>Algorithms:</p>
  </div>
  <div class="page">
    <p>120 million pages on 16 machines (1.8TB uncompressed)  P-4 1.7Ghz with 2x80GB Seagate Barracuda IDE  compressed index based on Berkeley DB (using the mg compression macros)</p>
    <p>queries from Excite query trace from December 1999  queries with 2 terms in the following  local index organization with query integrator  first results for one node (7.5 million pages), then 16  note: do not need top-10 from every node  motivates top-1, top-4 schemes and precision at 1, 4  ranking by cosine + log(PR) with normalization</p>
    <p>Experimental setup:</p>
  </div>
  <div class="page">
    <p>sort inverted lists by Pagerank (docID = rank due to Pagerank)  exhaustive: top-10  first-m: return 10 highest scoring among first 10/100/1000 pages in intersection</p>
    <p>A nave approach: first-m</p>
  </div>
  <div class="page">
    <p>for first-10, about 45% of top-10 results belong in top-10</p>
    <p>for first-1000, about 85% of top</p>
    <p>first-m (ctd.)</p>
    <p>loose/strict precision, relative to correct cosine + log(PR)</p>
    <p>for first-100, about 80% of queries return correct top-1 result  for first-1000, about 70% of queries return all correct top-10 results</p>
    <p>average cost per query in terms of disk blocks</p>
  </div>
  <div class="page">
    <p>(1) Use better stopping criteria?  reliable pruning: stop when we are sure  probabilistic pruning: stop when almost sure  do not work well for Pagerank-sorted index</p>
    <p>(2) Reorganize index structure?  sort lists by term score (cosine) instead of Pagerank - does not do any better than sorting by Pagerank only</p>
    <p>sort lists by term + 0.5 log(PR) (or some combination of these) - some problems in normalization and dependence on # of keywords</p>
    <p>generalized fancy lists - for each list, put entries with highest term value in fancy list - sort both lists by pagerank docID - note: anything that does well in 2 out of 3 scores is found soon - deterministic or probabilistic pruning, or first-k</p>
    <p>How can we do better?</p>
    <p>chair</p>
    <p>table</p>
    <p>fancy list</p>
    <p>fancy list</p>
    <p>rest of list, cosine &lt; x</p>
    <p>rest of list, cosine &lt; y</p>
  </div>
  <div class="page">
    <p>loose vs. strict precision for various sizes of the fancy lists</p>
    <p>Results for generalized fancy lists</p>
    <p>MUCH better precision than without fancy lists!  for first-1000, we always get correct top-1 in these runs</p>
  </div>
  <div class="page">
    <p>cost similar to first-m without fancy lists plus the additional cost of reading fancy lists  cost increases slightly with size of fancy list  slight inefficiency: fancy list items not removed from other list  note: we do not consider savings due to caching</p>
    <p>Costs of Fancy Lists</p>
  </div>
  <div class="page">
    <p>always gives correct result  top-4 can be computed reliably with ~20% of original cost  with 16 nodes, top-4 from each node suffice with 99% prob. to get top-10</p>
    <p>Reliable Pruning</p>
  </div>
  <div class="page">
    <p>comparison of first-m, last-m, and reliable pruning schemes for top-4 queries with loose precision</p>
    <p>Summary for all Approaches (single node)</p>
  </div>
  <div class="page">
    <p>first-30 returns correct top-10 for almost 98% of all queries</p>
    <p>Results for 16 Nodes</p>
  </div>
  <div class="page">
    <p>top-10 queries on 16 machines with 120 million pages  up to 10 queries/sec with reliable pruning  up to 20 queries per second with first-30 scheme</p>
    <p>Throughput and Latency for 16 Nodes</p>
    <p>Note: reliable pruning not implemented in purely incremental manner</p>
  </div>
  <div class="page">
    <p>results for 3+ terms and incremental query integrator  need to do precision/recall study  need to engineer ranking function and reevaluate  how to include term distance in documents  impact of caching at lower level  working on publicly available engine prototype  tons of loose ends and open questions</p>
    <p>Current and Future Work</p>
  </div>
</Presentation>
