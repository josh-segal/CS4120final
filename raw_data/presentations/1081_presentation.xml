<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Carnegie Mellon University</p>
    <p>Carnegie Mellon Parallel Data Laboratory</p>
    <p>* UC Berkeley</p>
    <p>Tributary: spot-dancing for elastic services with latency</p>
    <p>SLOs Aaron Harlap, Andrew Chung,</p>
    <p>Alexey Tumanov*, Greg Ganger, Phil Gibbons</p>
  </div>
  <div class="page">
    <p>(a) Berkeley Periodic[12] (b) ClarkNet Periodic[12] (c) WITS Large Variation[18] (d) WCup98 Slow Spike[12] Figure 4: Traces used in system evaluation.</p>
    <p>AutoScale Smart AutoScale Tributary</p>
    <p>(a) Reactive AutoScale Smart AutoScale Tributary</p>
    <p>(b) Predictive-LR AutoScale Smart AutoScale Tributary</p>
    <p>(c) Predictive-MWA Figure 5: Cost savings (red) and percentage of slow requests (blue) for the ClarkNet trace.</p>
    <p>We implement three popular scaling policies: Reactive, Predictive Moving Window Average (MWA), and Predictive Linear Regression (LR) to evaluate our system. In all three policies, the utility function implemented is linear with respect to the amount recommended by the scaling policy. We are able to make this assumption since our workload characteristic is embarrassingly-parallel  if a workload exhibits different scaling characteristics, a different utility function generator can be implemented.</p>
    <p>The Reactive Scaling Policy scales out immediately when demand reported by the MM is greater than what the available resources are able to handle. It scales in slowly (only after three minutes of low demand), as recommended by Gandhi et al. [15], to prevent premature scale-in in case the demand fluctuates widely in a short period of time. Tributarys smart termination mechanism helps with the Reactive Scaling Policys strategy of scaling in slowly. With smart termination, Tributary keeps a resource available if the resource has not yet been revoked or met the end of its billing period even if the scaling policy recommends a scale in.</p>
    <p>The Predictive-MWA Scaling Policy maintains a sliding window of a fixed size, with each window entry consisting of the number of requests received in each monitoring period. The policy takes the average of the window entries to predict the number of requests on the next monitoring period. The policy then adjusts the utility and scaling functions according to the predicted number of requests, and reports the updated functions to the ResMgr to scale in expectation of future requests. The Predictive-LR Scaling Policy also maintains a sliding window of a fixed size, but rather than using the average in the window for prediction, the policy performs linear regression on data points in the window to estimate the expected number of requests in the next monitoring period.</p>
    <p>Our experiments show that regardless of the scaling policy used, Tributary beats its competitors in both meeting the service latency target and the cost of operation.</p>
    <p>This section evaluates Tributarys ability to reduce cost and latency target misses. We compare Tributary to three alternate resource acquisition approaches: using on-demand resources, using AWS AutoScale with spot instances, and using Smart AutoScale.</p>
    <p>AWS Autoscale. The default AWS AutoScale only supports the simplest reactive scaling policies. To provide better comparison between approaches, we implement the AWS AutoScale resource acquisition algorithm as closely as possible according to its documentation [2] and integrate it with Tributary to work with</p>
    <p>Services with SLOs  Time varying client</p>
    <p>workloads - handled with elastically</p>
    <p>sized resources</p>
    <p>How are they sized? - decide how many</p>
    <p>resources are needed</p>
    <p>- add/release resources</p>
    <p>!2</p>
  </div>
  <div class="page">
    <p>Elastic Service Architecture</p>
    <p>!3</p>
    <p>Load Balancer</p>
    <p>Scaling Policy Resource Manager</p>
    <p>Resources</p>
  </div>
  <div class="page">
    <p>Elastic Service Architecture</p>
    <p>!3</p>
    <p>Load Balancer</p>
    <p>Scaling Policy Resource Manager</p>
    <p>Resources</p>
    <p>User Requests</p>
  </div>
  <div class="page">
    <p>Elastic Service Architecture</p>
    <p>!3</p>
    <p>Load Balancer</p>
    <p>Scaling Policy Resource Manager</p>
    <p>Resources</p>
    <p>User Requests Fwd Requests</p>
  </div>
  <div class="page">
    <p>Elastic Service Architecture</p>
    <p>!3</p>
    <p>Load Balancer</p>
    <p>Scaling Policy Resource Manager</p>
    <p>Resources</p>
    <p>User Requests Fwd Requests</p>
    <p>Stats</p>
  </div>
  <div class="page">
    <p>Elastic Service Architecture</p>
    <p>!3</p>
    <p>Load Balancer</p>
    <p>Scaling Policy Resource Manager</p>
    <p>Resources</p>
    <p>User Requests Fwd Requests</p>
    <p>Stats</p>
    <p>How many resources currently needed</p>
  </div>
  <div class="page">
    <p>Elastic Service Architecture</p>
    <p>!3</p>
    <p>Load Balancer</p>
    <p>Scaling Policy Resource Manager</p>
    <p>Resources</p>
    <p>User Requests Fwd Requests</p>
    <p>Stats</p>
    <p>How many resources currently needed</p>
    <p>Add Remove</p>
  </div>
  <div class="page">
    <p>Why Tributary?  CSPs offer cheaper resources that come with</p>
    <p>potential of being taken away - GCE preemptible instances</p>
    <p>- AWS EC2 spot instances</p>
    <p>Preemptions are bad for services w/ SLOs</p>
    <p>!4</p>
  </div>
  <div class="page">
    <p>Transient resources much cheaper  Often 75-85% cheaper to use Spot Instances</p>
    <p>!5</p>
    <p>Jan 19 Jan 20 Jan 21 Jan 22 Jan 23 Jan 24 0</p>
    <p>Date</p>
    <p>P ric</p>
    <p>e pe</p>
    <p>r H ou</p>
    <p>r ( $)</p>
    <p>OnDemand</p>
  </div>
  <div class="page">
    <p>Transient resources much cheaper  Often 75-85% cheaper to use Spot Instances</p>
    <p>!5</p>
    <p>Jan 19 Jan 20 Jan 21 Jan 22 Jan 23 Jan 24 0</p>
    <p>Date</p>
    <p>P ric</p>
    <p>e pe</p>
    <p>r H ou</p>
    <p>r ( $)</p>
    <p>c4.xlarge OnDemand</p>
  </div>
  <div class="page">
    <p>Transient resources much cheaper  Often 75-85% cheaper to use Spot Instances</p>
    <p>!5</p>
    <p>Jan 19 Jan 20 Jan 21 Jan 22 Jan 23 Jan 24 0</p>
    <p>Date</p>
    <p>P ric</p>
    <p>e pe</p>
    <p>r H ou</p>
    <p>r ( $)</p>
    <p>c4.xlarge OnDemand</p>
    <p>Low Cost</p>
  </div>
  <div class="page">
    <p>Spot Market Details  Many different spot markets</p>
    <p>- each instance type, in each availability zone, in each datacenter</p>
    <p>- empirically, markets are uncorrelated</p>
    <p>If pre-empted, Amazon issues refund - during first hour only</p>
    <p>Aquire resource(machines) by specifying: - &lt;spot market, bid price, number of machines&gt;</p>
    <p>!6</p>
  </div>
  <div class="page">
    <p>Tributary Changes how we Aquire Resources</p>
    <p>Uses transient instead of reliable resources - while addressing bulk preemptions</p>
    <p>Uses resource from multiple spot markets - predicts allocation P[preemption]</p>
    <p>- tracks inter-market correlations</p>
    <p>- maintains diverse resource buffer</p>
    <p>!7</p>
  </div>
  <div class="page">
    <p>Tributary Components  Predicting resource reliability</p>
    <p>Constructing resource footprint</p>
    <p>!8</p>
  </div>
  <div class="page">
    <p>Influencing P[preemption]  Users bids influence P[preemption] of spot instances</p>
    <p>- bid delta = user bid price - spot market price</p>
    <p>Bigger Delta</p>
    <p>- lower P[preemption] and higher cost</p>
    <p>Smaller Delta</p>
    <p>- higher P[preemption] and lower cost</p>
    <p>!9</p>
  </div>
  <div class="page">
    <p>Predicting P[preemption]  Predict P[preemption] as a function of bid deltas  Extract features</p>
    <p>- calendrical</p>
    <p>- temporal</p>
    <p>Plug features into LSTM Model - models EC2 as a sequence of events</p>
    <p>!10</p>
  </div>
  <div class="page">
    <p>Constructing the Resource Footprint</p>
    <p>Need to achieve capacity to satisfy SLO of client workload</p>
    <p>Need sufficient diversity across markets</p>
    <p>While expected request capacity &lt; SLO: Add resource that increases expected cost the least and increases request capacity the most.</p>
    <p>!11</p>
  </div>
  <div class="page">
    <p>Computing Expected Request Capacity  Compute probability of exactly 0 - N resources not</p>
    <p>pre-empted</p>
    <p>Accounts for spot market dependencies  Encourages diversity</p>
    <p>!12</p>
  </div>
  <div class="page">
    <p>Computing Expected Request Capacity  Compute probability of exactly 0 - N resources not</p>
    <p>pre-empted</p>
    <p>Accounts for spot market dependencies  Encourages diversity</p>
    <p>!12</p>
  </div>
  <div class="page">
    <p>Computing Expected Request Capacity  Compute probability of exactly 0 - N resources not</p>
    <p>pre-empted</p>
    <p>Accounts for spot market dependencies  Encourages diversity</p>
    <p>!12</p>
  </div>
  <div class="page">
    <p>Computing Expected Request Capacity  Compute probability of exactly 0 - N resources not</p>
    <p>pre-empted</p>
    <p>Accounts for spot market dependencies  Encourages diversity</p>
    <p>!12</p>
  </div>
  <div class="page">
    <p>So Why Does this Work?  Creates a diversified, oversized footprint</p>
    <p>- able to tolerate preemptions</p>
    <p>- little or no extra cost</p>
    <p>Handles unexpected workload spikes - handled via oversized natural resource buffers</p>
    <p>!13</p>
  </div>
  <div class="page">
    <p>Time for an Example</p>
    <p>!14</p>
    <p>R at</p>
    <p>e of</p>
    <p>R eq</p>
    <p>ue st</p>
    <p>s</p>
    <p>Time (min) 6030</p>
    <p>R at</p>
    <p>e of</p>
    <p>R eq</p>
    <p>ue st</p>
    <p>s</p>
    <p>Time (min)</p>
    <p>AutoScale Tributary</p>
  </div>
  <div class="page">
    <p>Time for an Example</p>
    <p>!15</p>
    <p>Alloc B</p>
    <p>Alloc C</p>
    <p>R at</p>
    <p>e of</p>
    <p>R eq</p>
    <p>ue st</p>
    <p>s</p>
    <p>Alloc A</p>
    <p>Time (min) 6030</p>
    <p>Alloc 2</p>
    <p>R at</p>
    <p>e of</p>
    <p>R eq</p>
    <p>ue st</p>
    <p>s</p>
    <p>Alloc 1</p>
    <p>Time (min) 6030</p>
    <p>AutoScale Tributary</p>
  </div>
  <div class="page">
    <p>Tributary Serves More Requests</p>
    <p>!16</p>
    <p>Alloc B</p>
    <p>Alloc C</p>
    <p>R at</p>
    <p>e of</p>
    <p>R eq</p>
    <p>ue st</p>
    <p>s</p>
    <p>Alloc A</p>
    <p>Alloc D</p>
    <p>Time (min) 6030</p>
    <p>Alloc 2</p>
    <p>Alloc 3</p>
    <p>R at</p>
    <p>e of</p>
    <p>R eq</p>
    <p>ue st</p>
    <p>s</p>
    <p>Alloc 1</p>
    <p>Time (min)</p>
    <p>Alloc 3</p>
    <p>AutoScale Tributary</p>
  </div>
  <div class="page">
    <p>Request Rate Decreases</p>
    <p>!17</p>
    <p>Alloc B</p>
    <p>Alloc C</p>
    <p>R at</p>
    <p>e of</p>
    <p>R eq</p>
    <p>ue st</p>
    <p>s</p>
    <p>Alloc A</p>
    <p>Alloc D</p>
    <p>Time (min)</p>
    <p>Alloc C</p>
    <p>Alloc D</p>
    <p>Alloc 2</p>
    <p>Alloc 3</p>
    <p>R at</p>
    <p>e of</p>
    <p>R eq</p>
    <p>ue st</p>
    <p>s</p>
    <p>Alloc 1</p>
    <p>Time (min)</p>
    <p>Alloc 3</p>
    <p>AutoScale Tributary</p>
  </div>
  <div class="page">
    <p>Tributarys Resources are Pre-empted</p>
    <p>!18</p>
    <p>Alloc B</p>
    <p>Alloc C</p>
    <p>R at</p>
    <p>e of</p>
    <p>R eq</p>
    <p>ue st</p>
    <p>s</p>
    <p>Alloc A</p>
    <p>Alloc D</p>
    <p>Time (min)</p>
    <p>Alloc C</p>
    <p>Alloc E</p>
    <p>Alloc D</p>
    <p>Alloc 2</p>
    <p>Alloc 3</p>
    <p>R at</p>
    <p>e of</p>
    <p>R eq</p>
    <p>ue st</p>
    <p>s</p>
    <p>Alloc 1</p>
    <p>Time (min)</p>
    <p>Alloc 3</p>
    <p>AutoScale Tributary</p>
  </div>
  <div class="page">
    <p>Experimental Setup  4 Traces Evaluated</p>
    <p>- show Clarknet</p>
    <p>3 Scaling Policies - show reactive</p>
    <p>Comparisons</p>
    <p>- Autoscale on spot</p>
    <p>- Autoscale+Buffer on spot</p>
    <p>- Tributary</p>
    <p>!19</p>
    <p>(a) Berkeley Periodic[12] (b) ClarkNet Periodic[12] (c) WITS Large Variation[18] (d) WCup98 Slow Spike[12] Figure 4: Traces used in system evaluation.</p>
    <p>AutoScale Smart AutoScale Tributary</p>
    <p>(a) Reactive AutoScale Smart AutoScale Tributary</p>
    <p>(b) Predictive-LR AutoScale Smart AutoScale Tributary</p>
    <p>(c) Predictive-MWA Figure 5: Cost savings (red) and percentage of slow requests (blue) for the ClarkNet trace.</p>
    <p>We implement three popular scaling policies: Reactive, Predictive Moving Window Average (MWA), and Predictive Linear Regression (LR) to evaluate our system. In all three policies, the utility function implemented is linear with respect to the amount recommended by the scaling policy. We are able to make this assumption since our workload characteristic is embarrassingly-parallel  if a workload exhibits different scaling characteristics, a different utility function generator can be implemented.</p>
    <p>The Reactive Scaling Policy scales out immediately when demand reported by the MM is greater than what the available resources are able to handle. It scales in slowly (only after three minutes of low demand), as recommended by Gandhi et al. [15], to prevent premature scale-in in case the demand fluctuates widely in a short period of time. Tributarys smart termination mechanism helps with the Reactive Scaling Policys strategy of scaling in slowly. With smart termination, Tributary keeps a resource available if the resource has not yet been revoked or met the end of its billing period even if the scaling policy recommends a scale in.</p>
    <p>The Predictive-MWA Scaling Policy maintains a sliding window of a fixed size, with each window entry consisting of the number of requests received in each monitoring period. The policy takes the average of the window entries to predict the number of requests on the next monitoring period. The policy then adjusts the utility and scaling functions according to the predicted number of requests, and reports the updated functions to the ResMgr to scale in expectation of future requests. The Predictive-LR Scaling Policy also maintains a sliding window of a fixed size, but rather than using the average in the window for prediction, the policy performs linear regression on data points in the window to estimate the expected number of requests in the next monitoring period.</p>
    <p>Our experiments show that regardless of the scaling policy used, Tributary beats its competitors in both meeting the service latency target and the cost of operation.</p>
    <p>This section evaluates Tributarys ability to reduce cost and latency target misses. We compare Tributary to three alternate resource acquisition approaches: using on-demand resources, using AWS AutoScale with spot instances, and using Smart AutoScale.</p>
    <p>AWS Autoscale. The default AWS AutoScale only supports the simplest reactive scaling policies. To provide better comparison between approaches, we implement the AWS AutoScale resource acquisition algorithm as closely as possible according to its documentation [2] and integrate it with Tributary to work with</p>
  </div>
  <div class="page">
    <p>Comparing to AutoScale  AWS AutoScale</p>
    <p>- AWS service that acquires cheapest spot instances</p>
    <p>!20</p>
    <p>AutoScale AutoScale+Buffer Tributary</p>
    <p>C o</p>
    <p>s t(</p>
    <p>% )</p>
    <p>N o</p>
    <p>r m</p>
    <p>a li</p>
    <p>z e</p>
    <p>d t</p>
    <p>o O</p>
    <p>n D</p>
    <p>e m</p>
    <p>a n</p>
    <p>a d</p>
    <p>Cost Compared to On-Demand</p>
    <p>AutoScale AutoScale+Buffer Tributary</p>
    <p>S lo</p>
    <p>w R</p>
    <p>eq ue</p>
    <p>st P</p>
    <p>er ce</p>
    <p>nt ag</p>
    <p>e</p>
    <p>Percentage of Slow Requests</p>
  </div>
  <div class="page">
    <p>Other Interesting Results  Across 4 traces Tributary reduces cost by 47-62%  Outperformed recent research systems</p>
    <p>- ExoSphere [Sharma 2017]</p>
    <p>- Proteus [Harlap 2017]</p>
    <p>Only ~50% of cost saving come from preemptions</p>
    <p>!21</p>
  </div>
  <div class="page">
    <p>Conclusion  Provides reliable service using transient</p>
    <p>resources</p>
    <p>Uses diversified buffers of resources  Reduces cost by ~85% over on-demand</p>
    <p>!22</p>
  </div>
</Presentation>
