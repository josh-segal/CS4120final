<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Improving Flash Storage Performance by Caching Address Mapping Table in</p>
    <p>Host Memory</p>
    <p>Presented at USENIX Hotstorage by</p>
    <p>Joo-Young Hwang ( jooyoung.hwang@samsung.com)</p>
    <p>Wookhan Jeong, Yongmyung Lee, Hyunsoo Cho, Jaegyu Lee, Songho Yoon, Jooyoung Hwang, and Donggi Lee</p>
  </div>
  <div class="page">
    <p>Problem Definition  Mobile apps are random read performance</p>
    <p>hungry.</p>
    <p>Bottlenecks of random read in mobile storage  Limited parallelism (due to smaller density than</p>
    <p>desktop SSD)</p>
    <p>L2P metadata (due to constraints on form factor/power consumption/cost)</p>
  </div>
  <div class="page">
    <p>What is FTLs L2P Metadata?</p>
    <p>L2P: Logical to physical address translation</p>
    <p>.</p>
    <p>.</p>
    <p>.</p>
    <p>Flash erase block #0</p>
    <p>Page #0</p>
    <p>Page #1</p>
    <p>Page #2</p>
    <p>LBA EB Page Offset</p>
    <p>L2P table</p>
  </div>
  <div class="page">
    <p>L2P Metadata Size Issue</p>
    <p>1 L2P entry: 4Bytes (for 4KB logical block)</p>
    <p>For 128GB storage, total L2P size is</p>
    <p>controller memory.</p>
  </div>
  <div class="page">
    <p>On-Demand L2P Loading  Loads a proper L2P page on</p>
    <p>demand.</p>
    <p>Performs well for reads with good locality.</p>
    <p>For random reads, L2P loading occurs more.  1 L2P page (16KB) may</p>
    <p>contain 4K entries, and covers 16MB logical block address range.</p>
    <p>Storage</p>
    <p>controller Controller</p>
    <p>memory</p>
    <p>NAND</p>
    <p>Host</p>
    <p>memory</p>
    <p>HCI</p>
    <p>CPU</p>
    <p>Read request</p>
    <p>Load L2P (if hit)</p>
    <p>Load L2P (if miss)</p>
    <p>Load data</p>
    <p>Data</p>
  </div>
  <div class="page">
    <p>Mobile workload pattern</p>
    <p>QD1 random reads</p>
    <p>Prediction and L2P prefetching?</p>
  </div>
  <div class="page">
    <p>Our Approach</p>
    <p>HPB (Host-aware Performance Booster):</p>
    <p>Collaboration between host and device</p>
    <p>In essence,</p>
    <p>Cache L2P in host memory,</p>
    <p>Host driver includes L2P in I/O request to avoid L2P</p>
    <p>loading from flash.</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>Storage</p>
    <p>controller Controller</p>
    <p>memory</p>
    <p>NAND</p>
    <p>Host</p>
    <p>memory</p>
    <p>HCI</p>
    <p>CPU</p>
    <p>Verify Host-provided L2P - authorized information? (detect tampering) - up-to-date? (detect old information)</p>
    <p>Dirty L2P</p>
    <p>groups</p>
    <p>L2P cache Host-side L2P Cache - device-provided L2P bookkeeping - include L2P per read request</p>
    <p>Device-side L2P Manager - maintains dirty groups - provide L2P</p>
    <p>L2P cache update protocol</p>
  </div>
  <div class="page">
    <p>Read Request Processing in HPB Host Memory</p>
    <p>Host Controller Interface</p>
    <p>Host I/F</p>
    <p>CPU + Logic</p>
    <p>NAND I/F</p>
    <p>NAND Flash memory D</p>
    <p>e v</p>
    <p>ic e m</p>
    <p>e m</p>
    <p>o r y</p>
    <p>Host System (+HPB)</p>
    <p>Storage Device (+HPB)</p>
    <p>(1)</p>
    <p>(2)</p>
    <p>(3)</p>
    <p>(4)</p>
    <p>(5)</p>
    <p>(6)</p>
    <p>(1) Read L2P entry</p>
    <p>(2) Fetch read command</p>
    <p>(3) Request L2P entry</p>
    <p>(4) Read L2P entry</p>
    <p>(5) Request user data</p>
    <p>(6) Transfer user data</p>
    <p>(1) (2) (3) tR (L2P map) (4) (5) tR (data) (6)</p>
    <p>(1) (2) (5) tR (data) (6)</p>
    <p>t</p>
    <p>t</p>
    <p>Case1: Host-side L2P Cache miss</p>
    <p>Case2: Host-side L2P Cache hit</p>
    <p>tR : NAND page read latency</p>
  </div>
  <div class="page">
    <p>L2P Cache Updates</p>
    <p>L2P group 0</p>
    <p>LBA PPN</p>
    <p>L2P group 1</p>
    <p>LBA PPN</p>
    <p>L2P Group 0</p>
    <p>LBA PPN</p>
    <p>L2P Group 1</p>
    <p>LBA PPN</p>
    <p>Group # Validity</p>
    <p>... ...</p>
    <p>L2P dirty bitmap</p>
    <p>(controller memory)</p>
    <p>L2P Map</p>
    <p>(NAND)</p>
    <p>Host-side L2P Cache (Host memory)</p>
    <p>Device</p>
    <p>Notify need to update</p>
    <p>Request L2P for Group 0</p>
    <p>Returns L2P for Group 0 900</p>
    <p>L2P changes due to host writes, garbage collection, and wear leveling.</p>
  </div>
  <div class="page">
    <p>L2P Cache Updates (contd)  Two ways to update the cache</p>
    <p>Host initiated: host issues commands to fetch L2P of a group.</p>
    <p>Device notifies host of dirty group in response packet.</p>
    <p>Device initiated: device piggybacks L2P in response packets.</p>
  </div>
  <div class="page">
    <p>Implementation in UFS  UFS (Universal Flash Storage)</p>
    <p>Successor of eMMC, shipped in smartphones since 2015.</p>
    <p>Layered architecture, uses SCSI command sets</p>
    <p>UFS 2.0 600MB/s per lane, max 2 lanes</p>
  </div>
  <div class="page">
    <p>Delivering L2P Hints</p>
    <p>READ16 CDB for HPB</p>
    <p>B \ b 7 6 5 4 3 2 1 0</p>
    <p>...</p>
    <p>...</p>
    <p>...</p>
    <p>L2P entry</p>
    <p>Logical block address</p>
    <p>Transfer Length</p>
    <p>Modify READ(16) commands to include L2P.</p>
    <p>READ(16): 8Bytes LBA, 4Bytes Transfer Length</p>
    <p>Modified READ(16): 4Bytes L2P, 4Bytes LBA, 4 Bytes Transfer Length</p>
  </div>
  <div class="page">
    <p>Experimental Results</p>
    <p>tiobench 4KB RR (Random Read) performance tiobench SR(Sequential Read), SW(Sequential Write), RW(Random Write) performance.</p>
    <p>59~67% random read performance improvements</p>
    <p>Little or no effect on sequential R/W and random write performances</p>
  </div>
  <div class="page">
    <p>Experimental Results (contd)</p>
    <p>Mixed pattern performance (4KB record size, 1GB I/O issue, 16 threads).</p>
    <p>In RW(x:y), x is read portion and y is write portion.</p>
    <p>HPB shows better performance in overall R:W mix ratio</p>
    <p>and chunk sizes (4 ~ 512KB).</p>
  </div>
  <div class="page">
    <p>Further Works  Standardization</p>
    <p>EHS(Extra Header Segment) in UFS 3.0</p>
    <p>Host can deliver L2P for a chunk that is physically fragmented.</p>
    <p>Host-side memory management</p>
    <p>Deal with host memory pressure</p>
    <p>More performance benchmark</p>
    <p>Benefits in phone user scenarios</p>
    <p>L2P verification implementation</p>
  </div>
  <div class="page">
    <p>L2P Verification  Check if a host-provided L2P has not been tampered.</p>
    <p>Requires encrypt/decrypt hardware support to avoid overhead.</p>
    <p>Random Seed LBA PPN Signature</p>
    <p>Encryption Key Encryption Data</p>
    <p>Encrypted data</p>
  </div>
  <div class="page">
    <p>Related Works</p>
    <p>NVMe SSD SSD CPU</p>
    <p>NAND</p>
    <p>P C</p>
    <p>Ie I</p>
    <p>/F</p>
    <p>NAND</p>
    <p>NAND I/F</p>
    <p>CPU</p>
    <p>Host system</p>
    <p>Memory</p>
    <p>HMB</p>
    <p>P C</p>
    <p>I E</p>
    <p>x p</p>
    <p>r e ss</p>
    <p>Other approaches</p>
    <p>Interconnects that allows device to access host memory directly.</p>
    <p>: PCIe/NVMe provides HMB (Host Memory Buffer)</p>
    <p>: UFS UME (Unified Memory Extension)</p>
    <p>Static allocation of host memory</p>
    <p>Latency of accessing host memory from device</p>
    <p>is in critical path.</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>HPB (Host Performance Booster)</p>
    <p>Improve random read performance by caching L2P</p>
    <p>map in host memory and delivering L2P hint when</p>
    <p>sending I/O request.</p>
    <p>HPB implementation in UFS</p>
    <p>Modified READ(16) to piggyback L2P hints.</p>
    <p>Improved random read performance by 59~67%</p>
  </div>
  <div class="page"/>
</Presentation>
