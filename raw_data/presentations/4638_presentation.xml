<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Improving Instruction Delivery with a Block-Aware ISA</p>
    <p>Ahmad Zmily, Earl Killian, Christos Kozyrakis</p>
    <p>Computer Systems Laboratory</p>
    <p>Stanford University</p>
    <p>http://csl.stanford.edu</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Processor front-end engine</p>
    <p>Performs control flow prediction &amp; instruction fetch</p>
    <p>Sets upper limit for performance</p>
    <p>Cannot execute instructions faster than you can fetch them!</p>
    <p>Front-end detractors</p>
    <p>Control-flow mispredictions that lead to pipeline flushing</p>
    <p>Instruction cache misses</p>
    <p>Multi-cycle instruction cache accesses</p>
    <p>M o ti v a ti o n</p>
    <p>Imperfect Predictor Imperfect I-Cache Imperfect Predictor +</p>
    <p>Imperfect I-Cache</p>
    <p>% L o s s</p>
    <p>Performance Energy</p>
  </div>
  <div class="page">
    <p>BLISS</p>
    <p>A block-aware instruction set architecture</p>
    <p>Allows software to help with hardware challenges</p>
    <p>Decouples control-flow prediction from instruction fetching</p>
    <p>Allows fast &amp; accurate instruction delivery with simple hardware</p>
    <p>Talk outline</p>
    <p>BLISS overview</p>
    <p>Instruction set and front-end microarchitecture</p>
    <p>Performance optimizations</p>
    <p>Energy optimizations</p>
    <p>Experimental results</p>
    <p>20% performance and 14% energy improvements</p>
    <p>Outperforms hardware-only block-based front-ends</p>
    <p>Conclusions</p>
    <p>O u tl in e</p>
  </div>
  <div class="page">
    <p>BLISS Instruction Set</p>
    <p>Explicit basic block descriptors (BBDs)</p>
    <p>Stored separately from instructions in the text segment</p>
    <p>Describe control flow and identify associated instructions</p>
    <p>Execution model</p>
    <p>PC always points to a BBD, not to instructions</p>
    <p>Atomic execution of basic blocks</p>
    <p>O v e rv ie w</p>
    <p>Instructions Instructions</p>
    <p>Block Descriptors</p>
    <p>Conventional ISA BLISS ISA</p>
    <p>Text Segment</p>
  </div>
  <div class="page">
    <p>Type: type of terminating control-flow instruction</p>
    <p>Fall-through, jump, jump register, forward/backward branch, call, return</p>
    <p>Offset: displacement for PC-relative branches and jumps</p>
    <p>Offset to target basic block descriptor</p>
    <p>Length: number of instruction in the basic block</p>
    <p>0 to 15 instructions</p>
    <p>Longer basic blocks use multiple descriptors</p>
    <p>Instruction pointer: address of the first instruction in the block</p>
    <p>Remaining bits from TLB</p>
    <p>Hints: optional compiler-generated hints</p>
    <p>This study: branch hints (biased taken/non-taken branches)</p>
    <p>Other uses: code density, power savings, VLIW techniques,</p>
    <p>O v e rv ie w</p>
  </div>
  <div class="page">
    <p>BLISS Code Example</p>
    <p>Example program in C-source code</p>
    <p>Counts the number of zeros in array A</p>
    <p>Calls foo() for each non-zero element</p>
    <p>O v e rv ie w</p>
    <p>numeqz=0;</p>
    <p>for (i=0; i&lt;N; i++)</p>
    <p>if (A[i]==0) numeqz++;</p>
    <p>else foo();</p>
  </div>
  <div class="page">
    <p>BLISS Code Example O v e rv ie w</p>
    <p>addu r4,r0,r0</p>
    <p>lw r6,0(r1)</p>
    <p>bneqz r6,L2</p>
    <p>j L3</p>
    <p>jal FOO</p>
    <p>addui r1,r1,4</p>
    <p>bneq r1,r2,L1</p>
    <p>L1:</p>
    <p>L2:</p>
    <p>L3:</p>
    <p>addui r4,r4,1</p>
    <p>BBD1: FT , --- , 1</p>
    <p>BBD2: B_F , BBD4, 2</p>
    <p>BBD3: J, BBD5, 1</p>
    <p>BBD4: JAL, FOO, 0</p>
    <p>BBD5: B_B, BBD2, 2</p>
    <p>All jump instructions are redundant</p>
    <p>Several branches can be folded in arithmetic instructions</p>
    <p>Branch offset is encoded in descriptors</p>
  </div>
  <div class="page">
    <p>BLISS Decoupled Front-End O v e rv ie w Basic Block</p>
    <p>Descriptor cache</p>
    <p>replaces BTB</p>
    <p>Basic-Block queue</p>
    <p>decouples prediction</p>
    <p>from instruction cache</p>
    <p>Extra pipe stage to access</p>
    <p>BB-cache</p>
    <p>D e c o d e</p>
    <p>P C</p>
    <p>ic a c h e m</p>
    <p>is s</p>
    <p>Ic a c h e p re fe tc h</p>
  </div>
  <div class="page">
    <p>Front-End Operation: BB-cache Hit O v e rv ie w</p>
    <p>Push descriptor &amp; predicted target in BBQ</p>
    <p>Instructions fetched and executed later (decoupling)</p>
    <p>Continue fetching from predicted BBD address</p>
    <p>Hybrid predictor accessed in following cycle to verify speculation</p>
  </div>
  <div class="page">
    <p>Front-End Operation: BB-cache Miss O v e rv ie w</p>
    <p>Wait for refill from L2 cache</p>
    <p>Calculate 32-bit instruction pointer &amp; target on refill</p>
    <p>Back-end only stalls when BBQ and IQ are drained</p>
    <p>Can hide significant portion of L2 cache latency</p>
  </div>
  <div class="page">
    <p>Front-End Operation: Misprediction O v e rv ie w</p>
    <p>Flush pipeline including BBQ and IQ</p>
    <p>Restart from correct BBD address</p>
    <p>Start fetching BBDs while recovering back-end state</p>
  </div>
  <div class="page">
    <p>Performance Optimizations (1)</p>
    <p>I-cache misses can be tolerated</p>
    <p>BBQ provides early view into instruction stream</p>
    <p>Guided instruction prefetch</p>
    <p>I-cache is not in the critical path for speculation</p>
    <p>BBDs provide branch type and offsets for speculation</p>
    <p>Multi-cycle I-cache does not affect prediction accuracy</p>
    <p>Latency only visible on mispredictions</p>
    <p>Similar to previous decoupled front-end work</p>
    <p>[Calder et.al. 94], [Stark et.al. 97], [Reinman et.al. 01] ,</p>
    <p>O p ti m iz a ti o n s</p>
  </div>
  <div class="page">
    <p>Performance Optimizations (2)</p>
    <p>Better target prediction</p>
    <p>L2 backs up target buffer on capacity misses</p>
    <p>No cold misses for PC-relative branch targets</p>
    <p>Compiler hints for branches (optional)</p>
    <p>Better direction prediction</p>
    <p>All PCs refer to basic block boundaries</p>
    <p>Denser representation leads to less interference</p>
    <p>Judicious use and training of predictor</p>
    <p>No predictor access for fall-through or jump blocks</p>
    <p>Selective use of hybrid predictor if branch hints are available</p>
    <p>Overall up to 41% less pipeline flushes with BLISS</p>
    <p>Without complicated hardware control</p>
    <p>O p ti m iz a ti o n s</p>
  </div>
  <div class="page">
    <p>Energy Optimizations</p>
    <p>Energy saved on mispredicted instructions</p>
    <p>Due to better target and direction prediction</p>
    <p>The saving is across the whole processor pipeline</p>
    <p>15% of energy wasted on mispredicted instructions</p>
    <p>Instruction cache optimizations</p>
    <p>Access only the necessary words in I-cache</p>
    <p>Serial access of tags and data in I-cache</p>
    <p>Merged I-cache accesses waiting in the BBQ</p>
    <p>Judicious use and training of predictor</p>
    <p>No predictor access for fall-through or jump blocks</p>
    <p>Selective use of hybrid predictor if branch hints are available</p>
    <p>O p ti m iz a ti o n s</p>
  </div>
  <div class="page">
    <p>Evaluation Methodology</p>
    <p>8-way superscalar processor</p>
    <p>Out-of-order execution, two-level cache hierarchy</p>
    <p>Simulated with Simplescalar &amp; Wattch toolsets</p>
    <p>SpecCPU2K benchmarks with reference datasets</p>
    <p>BLISS code generation</p>
    <p>Binary translation from MIPS executables</p>
    <p>16% reduction in static code size by eliminating redundancy</p>
    <p>Comparison: fetch-target-block (FTB) [Reinman et. al. 2001]</p>
    <p>Similar to BLISS but pure hardware implementation</p>
    <p>Hardware creates and caches block and extended blocks</p>
    <p>Optimistic approach on FTB misses to help block detection</p>
    <p>Similar performance and energy optimizations applied</p>
    <p>M e th o d o lo g y</p>
  </div>
  <div class="page">
    <p>Front-end Parameters</p>
    <p>BTB, FTB, and BB-cache have exactly the same capacity</p>
    <p>Same number of SRAM bits needed for implementation</p>
    <p>Nearly identical access latency</p>
    <p>M e th o d o lo g y</p>
    <p>I-cache Latency</p>
    <p>BLISSFTBBase</p>
    <p>BB-cache: 2K entries</p>
    <p>FTB: 2K entries</p>
    <p>BTB: 2K entries</p>
    <p>Target</p>
    <p>Predictor</p>
  </div>
  <div class="page">
    <p>Performance</p>
    <p>Consistent performance advantage for BLISS</p>
    <p>20% average improvement over base</p>
    <p>13% average improvement over FTB</p>
    <p>Sources of performance improvement</p>
    <p>41% reduction pipeline flushes compared to base</p>
    <p>24% reduction in I-cache misses due to prefetching</p>
    <p>E x p e ri m e n ts</p>
    <p>-10%</p>
    <p>gcc crafty vortex mesa equake AVG% I P C I m p ro v e m e n t o v e r B a s e FTB BLISS BLISS-Hints</p>
  </div>
  <div class="page">
    <p>FTB vs. BLISS E x p e ri m e n ts</p>
    <p>FTB</p>
    <p>Aggressive extended block formation  higher fetch IPC</p>
    <p>Over-speculation on misses  lower commit IPC</p>
    <p>BLISS</p>
    <p>Stall on misses, get accurate block descriptor from L2 cache</p>
    <p>Balance between under-speculation and over-speculation</p>
    <p>FTB BLISS FTB BLISS FTB BLISS FTB BLISS FTB BLISS FTB BLISS</p>
    <p>gcc vortex crafty mesa equake average</p>
    <p>IP C</p>
    <p>Fetch IPC Commit IPC</p>
  </div>
  <div class="page">
    <p>Prediction Accuracy</p>
    <p>BLISS lead to 41% reduction in mispredictions</p>
    <p>Avoids over-speculation on BB-cache misses</p>
    <p>Accurate indexing and training of the hybrid predictor</p>
    <p>Dense PCs lead to 1% better prediction</p>
    <p>1.2% better prediction when hints are used</p>
    <p>E x p e ri m e n ts</p>
    <p>gcc crafty vortex mesa equake AVG</p>
    <p>N o rm</p>
    <p>a liz e d n u m b e r o f p ip e lin e f lu s h e s Base FTB BLISS BLISS-Hints1.24</p>
  </div>
  <div class="page">
    <p>Instruction Cache E x p e ri m e n ts</p>
    <p>BLISS reduces instruction cache misses</p>
    <p>Dense static code</p>
    <p>Prefetching using BBQ contents</p>
    <p>Fewer mispeculated instructions requested</p>
    <p>gcc crafty vortex mesa equake AVG</p>
    <p>N o rm</p>
    <p>a li z e d n u m b e r o f Ic a c h e m</p>
    <p>is s e s</p>
    <p>Base FTB BLISS BLISS-Hints</p>
  </div>
  <div class="page">
    <p>Total Chip Energy</p>
    <p>Total energy = front-end + back-end + all caches</p>
    <p>BLISS leads to 14% total energy savings over base</p>
    <p>Front-end savings + savings from fewer mispredictions</p>
    <p>FTB is limited to 7% savings</p>
    <p>Optimistic, large blocks needed to facilitate block creation</p>
    <p>Over-speculation is bad for energy too</p>
    <p>E x p e ri m e n ts</p>
    <p>gcc crafty vortex mesa equake AVG</p>
    <p>% E</p>
    <p>n e rg y I m p ro v e m e n t o v e r</p>
    <p>B a s e</p>
    <p>FTB BLISS BLISS-Hints</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>BLISS: a block-aware instruction set</p>
    <p>Defines basic block descriptors separate from instructions</p>
    <p>Expressive ISA to communicate software info and hints</p>
    <p>Enabled optimizations</p>
    <p>Better target and direction prediction accuracy</p>
    <p>Tolerate I-cache misses</p>
    <p>Less time and energy spent on overspeculation</p>
    <p>Results: improved performance and energy consumption</p>
    <p>20% performance and 14% energy over conventional</p>
    <p>13% performance and 7% energy over hardware-only scheme</p>
    <p>Additional benefits from software hints</p>
    <p>C o n c lu s io n s</p>
  </div>
</Presentation>
