<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>HydraVM:HydraVM:</p>
    <p>Mohamed M. Saad Mohamed Mohamedin, and</p>
    <p>Binoy RavindranBinoy Ravindran</p>
    <p>Hot Topics in Parallelism (HotPar '12), Berkeley, CA</p>
  </div>
  <div class="page">
    <p>Motivation &amp; ObjectivesMotivation &amp; Objectives</p>
    <p>Background</p>
    <p>Architecture</p>
    <p>Program Reconstruction  Implementation</p>
  </div>
  <div class="page">
    <p>Multicore Era More cores, not faster CPUs More cores, not faster CPUs</p>
    <p>Are we ready?</p>
    <p>Legacy Software Refactoring  Designed to use few threads</p>
    <p>Multi-threading programming  Multi-threading programming headache</p>
    <p>General Purpose Parallelization</p>
  </div>
  <div class="page">
    <p>General Purpose Parallelization</p>
    <p>Automated refactoring at Virtual Machine level (no</p>
    <p>source code required)</p>
    <p>HydraVM: Java Virtual Machine Prototype based on Jikes RVM and targets utilizing large number of on Jikes RVM and targets utilizing large number of</p>
    <p>cores by automatically detecting possible parallel</p>
    <p>portions of code</p>
  </div>
  <div class="page">
    <p>Non-speculative Parallelization [4, 16, 27, 13]</p>
    <p>Compiler-based Compiler-based</p>
    <p>Exploit loop-level parallelism</p>
    <p>Limited data dependency support</p>
    <p>Speculative Parallelization [26, 33, 15, 20, 32, 10, 11, 24, 34, 18, 27, 13, 12, 9]</p>
    <p>Program constructs</p>
    <p>HW, SW or both HW, SW or both</p>
    <p>Requires source code</p>
    <p>Online, offline or both</p>
    <p>Coarse-grain parallelism vs. fine-grain parallelism</p>
  </div>
  <div class="page">
    <p>Concurrency Control AbstractionConcurrency Control Abstraction</p>
    <p>Like database transactions</p>
    <p>ACID properties</p>
    <p>Easier to program</p>
    <p>Fine-grained performance</p>
    <p>Composable</p>
    <p>HTM (e.g., TCC, UTM),</p>
    <p>public boolean add(int item) { Node pred, curr; atomic { pred = head; curr = pred.next; while (curr.val &lt; item) { pred = curr; curr = curr.next;</p>
    <p>} if (item == curr.val) {</p>
    <p>HTM (e.g., TCC, UTM),</p>
    <p>STM (e.g., RSTM, Deuce),</p>
    <p>and HyTM (e.g., SpHT, VTM)</p>
    <p>Limitations</p>
    <p>if (item == curr.val) { return false;</p>
    <p>} else { Node node = new Node(item); node.next = curr; pred.next = node; return true;</p>
    <p>} }</p>
  </div>
  <div class="page">
    <p>Optimistic concurrency Optimistic concurrency</p>
    <p>Example: Adding 9 &amp; 15 concurrently</p>
  </div>
  <div class="page">
    <p>Thread A adds 9 &amp; Thread B adds 15</p>
    <p>Thread A Read-set: 8 Write-set:</p>
    <p>Thread B Read-set: 8 Write-set:</p>
  </div>
  <div class="page">
    <p>Thread A adds 9 &amp; Thread B adds 15</p>
    <p>Thread A Read-set: 8, 10 Write-set:</p>
    <p>Thread B Read-set: 8, 10 Write-set:</p>
  </div>
  <div class="page">
    <p>Thread A adds 9 &amp; Thread B adds 15</p>
    <p>Thread A Read-set: 8, 10 Write-set: 10 (left child pointer)</p>
    <p>Thread B Read-set: 8, 10, 14 Write-set:</p>
  </div>
  <div class="page">
    <p>Thread A adds 9 &amp; Thread B adds 15</p>
    <p>Thread A Read-set: 8, 10 Write-set: 10 (left child pointer) Committed successfully</p>
    <p>Thread B Read-set: 8, 10, 14 Write-set: 14 (right child pointer)</p>
  </div>
  <div class="page">
    <p>Thread A adds 9 &amp; Thread B adds 15</p>
    <p>Thread A Read-set: 8, 10 Write-set: 10 (left child pointer) Committed successfully</p>
    <p>Thread B Read-set: 8, 10, 14 Write-set: 14 (right child pointer) Committed successfully</p>
  </div>
  <div class="page">
    <p>Object-based granularity</p>
    <p>Thread A Read-set: 8, 10 Write-set: 10 Committed successfully</p>
    <p>Thread B Read-set: 8, 10, 14 Write-set: 14 Conflict  Abort</p>
    <p>WAR</p>
  </div>
  <div class="page">
    <p>STM versus locking on Hashtable Comparison of STM and locking on B-Tree</p>
    <p>* B. Saha, A. Adl-Tabatabai, et al. McRT-STM: a high performance software transactional memory system for a multi-core runtime. In ACM PPoPP, pages 187197, 2006.</p>
  </div>
  <div class="page">
    <p>How it can help?</p>
    <p>Course-grain parallelism Course-grain parallelism</p>
    <p>Simpler data dependency analysis</p>
    <p>Overhead</p>
    <p>Past efforts</p>
    <p>Loop-based [22, 30] Loop-based [22, 30]</p>
    <p>Recursive programs [6]</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Program Analysis</p>
    <p>Online/Offline</p>
    <p>Instrumentation</p>
    <p>Profiling based</p>
    <p>Slow</p>
    <p>Program Reconstruction</p>
    <p>Basic Blocks Analysis</p>
    <p>Job Based execution</p>
    <p>Tuning</p>
    <p>Re-layout Basic Blocks</p>
    <p>Minimize conflicts</p>
  </div>
  <div class="page">
    <p>Basic blocks int C = 0;</p>
    <p>for(int J=0; J&lt;3; J++)</p>
    <p>if(Math.random()&gt;0.3)  Basic blocks</p>
    <p>Execution graph</p>
    <p>Profiling code injection</p>
    <p>Execution frequency</p>
    <p>Data dependency</p>
    <p>I/O</p>
    <p>if(Math.random()&gt;0.3)</p>
    <p>C++;</p>
    <p>else</p>
    <p>C--;</p>
    <p>I/O 20: goto 2623: iinc 1, -1 26: iinc 2, 1 29: iload_2 30: bipush 3 32: if_icmplt 7 35: return</p>
    <p>AFBDEFBDEFBCEFG</p>
  </div>
  <div class="page">
    <p>Execute the profiled bytecode Execute the profiled bytecode</p>
    <p>Hot spot detection</p>
    <p>Data dependency</p>
    <p>Parallel execution patterns detection</p>
    <p>(Superblocks)</p>
  </div>
  <div class="page">
    <p>abjbhcfefghcfefghijbhcfefghcfefghijk</p>
    <p>String factorization  Mains algorithm [21, 28]</p>
    <p>ab(jb(hcfefg)2 hi)2 jkab(jb(hcfefg) hi) jk</p>
    <p>Problems?  Data dependency</p>
    <p>I/O</p>
  </div>
  <div class="page">
    <p>Job-based execution  Job-based execution</p>
    <p>Producer-Consumer pattern</p>
    <p>Jobs run as transactions</p>
  </div>
  <div class="page">
    <p>Collector</p>
    <p>Provides Executor with suitable blocks as Tasks to execute</p>
    <p>according to flow up-to time</p>
    <p>Executor</p>
    <p>Allocates core threads</p>
    <p>Assign tasks to threads</p>
    <p>Requests Collector for</p>
    <p>more blocks based on</p>
    <p>program flow, after all</p>
    <p>threads complete</p>
  </div>
  <div class="page">
    <p>Maintain program consistency &amp; correctness Maintain program consistency &amp; correctness</p>
    <p>Each transaction has a chronological order</p>
    <p>A transaction commits iff</p>
    <p>It is reachable</p>
    <p>The program reached</p>
    <p>its chronological orderits chronological order</p>
    <p>No conflict with</p>
    <p>older concurrent</p>
    <p>transactions</p>
  </div>
  <div class="page">
    <p>Store conflicting jobs (knowledge repository) Store conflicting jobs (knowledge repository)</p>
    <p>Monitor conflict rate</p>
    <p>Tune through combining conflicting</p>
    <p>superblockssuperblocks</p>
  </div>
  <div class="page">
    <p>Detecting Real Memory Dependencies Detecting Real Memory Dependencies</p>
    <p>Static Single Assignment (SSA)</p>
    <p>Misprofiling</p>
    <p>Superblock has multiple entries &amp; multiple exits</p>
  </div>
  <div class="page">
    <p>Method Inlining  Automatic Automatic</p>
    <p>Partial recursion unrolling</p>
    <p>ByteSTM  VM-level STM</p>
    <p>Based on RingSTM algorithm [31]  The Ring The Ring</p>
    <p>Bloom filter [3]</p>
    <p>Ordering (conflict resolution &amp; commit postponing)</p>
    <p>ByteSTM implementation is publicly available at [www.hydravm.org/bytestm]</p>
  </div>
  <div class="page">
    <p>Parallelizing Nested Loops</p>
    <p>Implemented as parallel closed nesting transactionsImplemented as parallel closed nesting transactions</p>
    <p>Figure from: A. Turcu and B. Ravindran. On open nesting in distributed transactional memory. In Systor, 2012.</p>
  </div>
  <div class="page">
    <p>Example: Matrix Multiplication</p>
    <p>ab(jb(hcfefg)2 hi)2 jkab(jb(hcfefg)2 hi)2 jk</p>
  </div>
  <div class="page">
    <p>TestbedTestbed  8-core machine (2 Intel Xeon (E5520), each with 4 cores</p>
    <p>@ 2.27GHz)</p>
    <p>Ubuntu Linux Server 10.04 LTS 64-bit</p>
    <p>JikesRVM version 3.1.0</p>
    <p>Benchmarks Benchmarks  Matrix multiplication</p>
    <p>JOlden benchmark suite [7] (MST, TreeAdd, TSP, BiSort)</p>
  </div>
  <div class="page">
    <p>Speedup Speedup</p>
  </div>
  <div class="page">
    <p>HydraVM HydraVM</p>
    <p>JVM with automatic parallelization (refactoring)</p>
    <p>At the bytecode-level</p>
    <p>Exploits data-level &amp; execution-flow parallelism</p>
    <p>STM is used for program consistency</p>
    <p>Promising speedup (2x-5x) Promising speedup (2x-5x)</p>
  </div>
  <div class="page">
    <p>Thank YouThank You</p>
    <p>Please visit us at</p>
    <p>www.hydravm.org</p>
    <p>Questions?</p>
  </div>
</Presentation>
