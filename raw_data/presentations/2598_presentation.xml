<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Libra: Divide and Conquer to Verify Forwarding Tables in Huge Networks</p>
    <p>James Hongyi Zeng with Shidong Zhang, Fei Ye, Vimalkumar Jeyakumar, Mickey Ju</p>
    <p>Junda Liu, Nick McKeown, Amin Vahdat NSDI, April 2nd, 2014</p>
  </div>
  <div class="page">
    <p>My dear friend Copperfield, said Mr. Micawber, accidents will occur in the best-regulated families.</p>
    <p>-- Charles Dickens</p>
  </div>
  <div class="page">
    <p>Best Regulated Families: Data Centers</p>
    <p>- Homogeneous machines/switches - Pure IP forwarding - Few security concerns - No silly human users - Full control to all devices</p>
  </div>
  <div class="page">
    <p>Data Plane Tickets in a Google Data Center</p>
  </div>
  <div class="page">
    <p>Why ge7ng networks right is hard? Complex interacZon  Between mulZple protocols on a switch.  Between state on different switches.</p>
    <p>MulZple uncoordinated writers of state. Operators cannot</p>
    <p>Observe all state.  Control all state.</p>
    <p>One soluZon: StaZc Data Plane VerificaZon</p>
  </div>
  <div class="page">
    <p>Sta&lt;c Data Plane Verifica&lt;on Goal: Verifying data planes logical correctness  Example failures: loops, blackholes, parZZons  Inputs: desZnaZons, rules, topology  Independent of control plane</p>
    <p>A</p>
    <p>LOOP!</p>
  </div>
  <div class="page">
    <p>Two Challenges of Data Plane Verifica&lt;on in Data Centers  Constant Rule Changes  Link up/down, route recalculaZon, new policy, etc.  Careless snapshot of forwarding tables may result in false posiZves</p>
    <p>Large Scale  10,000s of switches, 1,000,000s of rules  How to finish the verificaZon within a reasonable Zme?</p>
  </div>
  <div class="page">
    <p>Forwarding Graph</p>
    <p>C D</p>
    <p>B A</p>
    <p>Forwarding Graph for IP2</p>
  </div>
  <div class="page">
    <p>The Snapshot Problem</p>
    <p>C D</p>
    <p>B A</p>
    <p>e1) A deletes rule AD e2) D deletes rule DB</p>
    <p>e1 e2</p>
    <p>Real Zmeline</p>
    <p>BA</p>
    <p>DC</p>
    <p>BA</p>
    <p>DC</p>
    <p>BA</p>
    <p>DC</p>
  </div>
  <div class="page">
    <p>The Snapshot Problem</p>
    <p>e1) A deletes rule AD e2) D deletes rule DB</p>
    <p>e1</p>
    <p>e2 D</p>
    <p>A</p>
    <p>e1 e2 OK OK OK</p>
    <p>BA</p>
    <p>DC</p>
    <p>IniZal</p>
    <p>BA</p>
    <p>DC</p>
    <p>IniZal + e1</p>
    <p>BA</p>
    <p>DC</p>
    <p>IniZal + e1 + e2</p>
  </div>
  <div class="page">
    <p>The Snapshot Problem</p>
    <p>e1) A deletes rule AD e2) D deletes rule DB</p>
    <p>e1</p>
    <p>e2 D</p>
    <p>A</p>
    <p>e2 e1 OK Blackhole! OK</p>
    <p>BA</p>
    <p>DC</p>
    <p>IniZal</p>
    <p>BA</p>
    <p>DC</p>
    <p>IniZal + e2</p>
    <p>BA</p>
    <p>DC</p>
    <p>IniZal + e1 + e2</p>
  </div>
  <div class="page">
    <p>The Stable Snapshot</p>
    <p>Problem: Cannot take a global snapshot simultaneously  Otherwise, we will know either (iniZal), (iniZal+e1), or (iniZal +e1+e2) but never (iniZal+e2)</p>
    <p>But this is a physical limitaZon..  SoluZon: Record events (rule updates), not states (forwarding tables)</p>
    <p>e1</p>
    <p>e2 D</p>
    <p>A</p>
    <p>e1 e2</p>
  </div>
  <div class="page">
    <p>The Stable Snapshot</p>
    <p>Problem: Lack of true Global Clock for Zmestamps  SoluZon: Leverage imperfect global clock  NTP  NTP has precision of  = 1-100ms: Every event is bounded by 2  Only consider a snapshot when its stable</p>
    <p>e1 e2</p>
  </div>
  <div class="page">
    <p>Will networks ever be stable?</p>
    <p>Example: Bursty rule updates in a producZon Google DC - 28,445 events in 24 hours - 95% of events happen within 400ms of each other - 99.9% of Zme the network is stable (silent)</p>
    <p>- Assuming  = 100ms</p>
    <p>How about transient states? - We can report potenZal problems - Network operators may not care anyway</p>
  </div>
  <div class="page">
    <p>Two Challenges of Data Plane Verifica&lt;on in Data Centers Constant Data Plane Changes  Link up/down, route recalculaZon, new policy, etc.  Bad snapshot may result in false posiZves  SoluZon: Stable Snapshots</p>
    <p>Large Scale  10,000s of switches, 1,000,000s of rules  How to finish the verificaZon within a reasonable Zme?</p>
  </div>
  <div class="page">
    <p>Scalable Verifica&lt;on</p>
    <p>Nave StaZc Checker:  Load all rules in memory  Pick one desZnaZon, pick one ingress port, simulate  Try the next one</p>
    <p>Data Center Networks are immense  10,000 switches x 1,000 rules = 10M rules  Thousands of desZnaZons</p>
    <p>VerificaZon Complexity grows as O(N2)  N Zmes switches/rules  N Zmes desZnaZons</p>
    <p>Parallelism!  But, how to parZZon? 16</p>
  </div>
  <div class="page">
    <p>Forwarding Graph</p>
    <p>Each desZnaZon has a forwarding graph  All data plane abnormaliZes are graph problems  loops, blackholes, parZZons</p>
    <p>Forwarding graph size == Physical network size  Each physical node is a vertex</p>
    <p>For each graph, only a subset of rules are needed</p>
    <p>C D</p>
    <p>B A</p>
    <p>Forwarding Graph for IP2</p>
  </div>
  <div class="page">
    <p>Divide and Conquer</p>
    <p>LOOP!</p>
    <p>OK</p>
    <p>(1) Map (2) Reduce</p>
    <p>Process 1</p>
    <p>Process 2</p>
    <p>Process 3</p>
  </div>
  <div class="page">
    <p>Libra: Distributed Data Plane Verifica&lt;on</p>
    <p>Graph assembly &amp; computaZon</p>
    <p>Shuffle by desZnaZon</p>
    <p>Find all &lt;dest, rule&gt;</p>
    <p>match</p>
    <p>Stable Snapshots</p>
  </div>
  <div class="page">
    <p>Evalua&lt;on: Loop detec&lt;on</p>
    <p>DCN: Googles emulated data center network DCN-G: 100 DCNs connected in a star topo INET: 300 Internet routers with full BGP table</p>
    <p>DCN DCN-G INET</p>
    <p>Switches 11,260 1,126,001 316</p>
    <p>Rules 2,657,422 265,742,626 151,649,486</p>
    <p>DesZnaZons 11,136 1,113,600 482,966</p>
    <p>Machines 50 20,000* 50</p>
    <p>Time/s 57 906 93</p>
    <p>*extrapolated</p>
  </div>
  <div class="page">
    <p>Even Faster: Incremental Updates</p>
    <p>DCN DCN-G INET</p>
    <p>Map (us) 0.133 0.156 0.158</p>
    <p>Reduce (ms) 0.62 1.76 &lt;0.01</p>
  </div>
  <div class="page">
    <p>Libra: Data Plane Verifica&lt;on at Data Center Scale</p>
    <p>Stable Snapshots  Only consider stable states of the data plane  Avoid false posiZves in bad snapshots</p>
    <p>Divide and Conquer  Implemented in MapReduce  Handles massive scale with parallelism</p>
  </div>
  <div class="page">
    <p>Thank you! hMp://eastzone.github.io/libra/</p>
    <p>Acknowledgement: Thanks to our shepherd T.V. Lakshman and anonymous NSDI reviewers for construcZve feedbacks.</p>
  </div>
  <div class="page">
    <p>Distributed Longest Prefix Matching Problem: Relevant rules may be in different shards  Mappers cannot see each other!</p>
    <p>Solu=on: Defer length comparison to Reduce phase  Reducer can see everything related to a desZnaZon</p>
    <p>Example:</p>
    <p>M1</p>
    <p>M2</p>
    <p>desZnaZon: 192.168.1.1/32</p>
    <p>R1</p>
  </div>
  <div class="page">
    <p>Challenge: All-prefix Matching</p>
    <p>Problem: In mappers, given a rule, find out all matching desZnaZons  ConvenZonal matching: Given a desZnaZon, find out one matching rule  Nave approach: Linear search, O(TR) where T = # of desZnaZons, R = # of rules</p>
    <p>Solu=on: Use a Trie (prefix Tree)  Put all desZnaZons in a Trie (once per mapper)  O(LR) where L=32 for IPv4</p>
    <p>Assuming a small number of matching desZnaZons</p>
  </div>
  <div class="page">
    <p>Challenge: All-prefix Matching</p>
    <p>Algorithm:  Step 1: Find the smallest matching trie node (X) that is bigger or equal to the rule (A) (lexical order)</p>
    <p>Step 2: Enumerate all Xs descendants including X.</p>
    <p>Proof:  Assume there is another node Y that isnt Xs descendant</p>
    <p>X and Y have common ancestor Z, Z!=X and Z!=Y  Z matches A because both X and Y match A, and  Z is smaller than X. ContradicZon! QED</p>
    <p>X Y</p>
    <p>Z</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Who benefits</p>
    <p>Network Engineers  Ensure policy compliance  Reduce service downZme  Report specific errors to vendors/Fix bugs</p>
    <p>Network Users  Visibility in networks  Reduce applicaZon diagnosis Zme</p>
    <p>VerificaZon OK  Debug applicaZon  VerificaZon Failed  Engage network engineers</p>
  </div>
</Presentation>
