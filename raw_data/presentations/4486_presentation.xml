<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Question Answering Passage Retrieval Using Dependency Parsing</p>
    <p>Hang Cui Renxu Sun</p>
    <p>Keya Li Min-Yen Kan Tat-Seng Chua</p>
    <p>Department of Computer Science National University of Singapore</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Passage Retrieval in Question Answering</p>
    <p>Document Retrieval</p>
    <p>Answer Extraction</p>
    <p>Passage Retrieval</p>
    <p>QA System</p>
    <p>To narrow down the search scope  Can answer questions with more context</p>
    <p>Lexical density based  Distance between question words</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Density Based Passage Retrieval Method  However, density based can err when</p>
    <p>&lt;Question&gt; What percent of the nation's cheese does Wisconsin produce?</p>
    <p>Incorrect:  the number of consumers who mention California when asked about cheese has risen by 14 percent, while the number specifying Wisconsin has dropped 16 percent. Incorrect: The wry It's the Cheese ads, which attribute California's allure to its cheese _ and indulge in an occasional dig at the Wisconsin stuff''  sales of cheese in California grew three times as fast as sales in the nation as a whole 3.7 percent compared to 1.2 percent,  Incorrect: Awareness of the Real California Cheese logo, which appears on about 95 percent of California cheeses, has also made strides.</p>
    <p>Correct: In Wisconsin, where farmers produce roughly 28 percent of the nation's cheese, the outrage is palpable.</p>
    <p>Relationships between matched words differ</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Our Solution</p>
    <p>Examine the relationship between words  Dependency relations</p>
    <p>Exact match of relations for answer extraction</p>
    <p>Has low recall because same relations are often phrased differently</p>
    <p>Fuzzy match of dependency relationship  Statistical similarity of relations</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Measuring Sentence Similarity</p>
    <p>Sentence 1 Sentence 2</p>
    <p>Sim (Sent1, Sent2) = ?</p>
    <p>Matched words</p>
    <p>Lexical matching Similarity of relations</p>
    <p>between matched words+</p>
    <p>Similarity of individual relations</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Outline</p>
    <p>Extracting and Paring Relation Paths</p>
    <p>Measuring Path Match Scores</p>
    <p>Learning Relation Mapping Scores</p>
    <p>Evaluations</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Outline</p>
    <p>Extracting and Paring Relation Paths</p>
    <p>Measuring Path Match Scores</p>
    <p>Learning Relation Mapping Scores</p>
    <p>Evaluations</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>What Dependency Parsing is Like</p>
    <p>Minipar (Lin, 1998) for dependency parsing</p>
    <p>Dependency tree  Nodes: words/chunks in the sentence  Edges (ignoring the direction): labeled by</p>
    <p>relation types</p>
    <p>What percent of the nation's cheese does Wisconsin produce?</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Extracting Relation Paths</p>
    <p>Relation path  Vector of relations between two nodes in the tree</p>
    <p>produce &lt; P1: subj &gt; Wisconsin percent &lt; P2: prep pcomp-n &gt; cheese</p>
    <p>Two constraints for relation paths: 1. Path length (less than 7 relations) 2. Ignore those between two words that are within a chunk, e.g. New York.</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Paired Paths from Question and Answer</p>
    <p>What percent of the nation's cheese does Wisconsin produce?</p>
    <p>In Wisconsin, where farmers produce roughly 28 percent of the nation's cheese, the outrage is palpable.</p>
    <p>&lt; P1 (Q) : subj &gt;</p>
    <p>&lt; P1 (Sent) : pcomp-n mod i &gt;</p>
    <p>Paired Relation Paths</p>
    <p>SimRel (Q, Sent) = i,j Sim (Pi (Q), Pj</p>
    <p>(Sent))</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Outline</p>
    <p>Extracting and Paring Relation Paths</p>
    <p>Measuring Path Match Scores</p>
    <p>Learning Relation Mapping Scores</p>
    <p>Evaluations</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Measuring Path Match Degree</p>
    <p>Employ a variation of IBM Translation Model 1  Path match degree (similarity) as translation</p>
    <p>probability  MatchScore (PQ, PS)  Prob (PS | PQ )  Relations as words</p>
    <p>Why IBM Model 1?  No word order  bag of undirected relations  No need to estimate target sentence length</p>
    <p>Relation paths are determined by the parsing tree</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Calculating Translation Probability (Similarity) of Paths</p>
    <p>m</p>
    <p>n</p>
    <p>n</p>
    <p>i</p>
    <p>Q</p>
    <p>i</p>
    <p>S it</p>
    <p>m</p>
    <p>nQS lRelReP</p>
    <p>m PPProb</p>
    <p>)()(</p>
    <p>)|()|(</p>
    <p>Considering the most probable alignment (finding the most probable mapped relations)</p>
    <p>Take logarithm and ignore the constants (for all sentences, question path length is a constant)</p>
    <p>n</p>
    <p>i</p>
    <p>Q</p>
    <p>iA S</p>
    <p>itnQS lRelReP</p>
    <p>m PPProb</p>
    <p>)()( )|()|(</p>
    <p>MatchScores of paths are combined to give the sentences relevance to the question.</p>
    <p>n</p>
    <p>i</p>
    <p>Q</p>
    <p>iA S</p>
    <p>it</p>
    <p>QSS</p>
    <p>lRelReP n</p>
    <p>PPProbPMatchScore</p>
    <p>)()( )|(log '</p>
    <p>)|()(</p>
    <p>?</p>
    <p>Given two relation paths from the question and a candidate sentence</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Outline</p>
    <p>Extracting and Paring Relation Paths</p>
    <p>Measuring Path Match Scores</p>
    <p>Learning Relation Mapping Scores</p>
    <p>Evaluations</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Training and Testing</p>
    <p>Testing Training</p>
    <p>Sim ( Q, Sent ) = ?</p>
    <p>Relation Mapping Scores</p>
    <p>Prob ( PSent | PQ ) = ?</p>
    <p>P ( Rel (Sent) | Rel (Q) ) = ?</p>
    <p>Q - A pairs</p>
    <p>Paired Relation Paths</p>
    <p>Relation Mapping Model</p>
    <p>Similarity between relation vectors</p>
    <p>Similarity between individual relations</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Approach 1: MI Based</p>
    <p>Measures bipartite co-occurrences in training path pairs</p>
    <p>Accounts for path length (penalize those long paths)</p>
    <p>Uses frequencies to approximate mutual information</p>
    <p>||||</p>
    <p>),( log)|(</p>
    <p>)()(</p>
    <p>)()( )()()(</p>
    <p>S i</p>
    <p>Q j</p>
    <p>S i</p>
    <p>Q jQ</p>
    <p>j S</p>
    <p>i MI</p>
    <p>t lRelRe</p>
    <p>lRelRe lRelReP</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Approach  2: EM Based</p>
    <p>Employ the training method from IBM Model 1  Relation mapping scores = word translation</p>
    <p>probability</p>
    <p>Utilize GIZA to accomplish training</p>
    <p>Iteratively boosting the precision of relation translation probability</p>
    <p>Initialization  assign 1 to identical relations and a small constant otherwise</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Outline</p>
    <p>Extracting and Paring Relation Paths</p>
    <p>Measuring Path Match Scores  Learning Relation Mapping Scores</p>
    <p>Evaluations  Can relation matching help?</p>
    <p>Can fuzzy match perform better than exact match?</p>
    <p>Can long questions benefit more?</p>
    <p>Can relation matching work on top of query expansion?</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Evaluation Setup</p>
    <p>Training data  3k corresponding path pairs from 10k QA</p>
    <p>pairs (TREC-8, 9)</p>
    <p>Test data  324 factoid questions from TREC-12 QA task</p>
    <p>Passage retrieval on top 200 relevant documents by TREC</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Comparison Systems</p>
    <p>MITRE baseline  Stemmed word overlapping  Baseline in previous work on passage retrieval evaluation</p>
    <p>SiteQ  top performing density based method  using 3 sentence window</p>
    <p>NUS  Similar to SiteQ, but using sentences as passages</p>
    <p>Strict Matching of Relations  Simulate strict matching in previous work for answer selection  Counting the number of exactly matched paths</p>
    <p>Relation matching are applied on top of MITRE and NUS</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Evaluation Metrics</p>
    <p>Mean reciprocal rank (MRR)  On the top 20 returned passages  Measure the mean rank position of the correct</p>
    <p>answer in the returned rank list</p>
    <p>Percentage of questions with incorrect answers</p>
    <p>Precision at the top one passage</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Performance Evaluation</p>
    <p>All improvements are statistically significant (p&lt;0.001)  MI and EM do not make much difference given our training data</p>
    <p>EM needs more training data  MI is more susceptible to noise, so may not scale well</p>
    <p>Passage retrieval systems</p>
    <p>MITRE SiteQ NUS Rel_Strict (MITRE)</p>
    <p>Rel_Strict (NUS)</p>
    <p>Rel_MI (MITRE)</p>
    <p>Rel_EM (MITRE)</p>
    <p>Rel_MI (NUS)</p>
    <p>Rel_EM (NUS)</p>
    <p>MRR 0.2000 0.2765 0.2677 0.2990 0.3625 0.4161 0.4218 0.4756 0.4761</p>
    <p>% MRR improvement over MITRE SiteQ NUS</p>
    <p>N/A N/A N/A</p>
    <p>% Incorrect 45.68% 37.65% 33.02% 41.96% 32.41% 29.63% 29.32% 24.69% 24.07%</p>
    <p>Precision at top one passage</p>
    <p>Fuzzy matching outperforms strict</p>
    <p>matching significantly.</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Performance Variation to Question Length  Long questions, with more paired paths,</p>
    <p>tend to improve more  Using the number of non-trivial question terms</p>
    <p>to approximate question length</p>
    <p># Question Term s</p>
    <p>M R</p>
    <p>R Rel_NUS_EM Rel_MITRE_EM</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Error Analysis</p>
    <p>Mismatch of question terms  e.g. In which city is the River Seine</p>
    <p>Introduce question analysis</p>
    <p>Paraphrasing between the question and the answer sentence</p>
    <p>e.g. write the book  be the author of the book</p>
    <p>Most of current techniques fail to handle it</p>
    <p>Finding paraphrasing via dependency parsing (Lin and Pantel)</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Performance on Top of Query Expansion  On top of query expansion, fuzzy relation matching brings a</p>
    <p>further 50% improvement  However</p>
    <p>query expansion doesnt help much on a fuzzy relation matching system</p>
    <p>Expansion terms do not help in paring relation paths</p>
    <p>Passage Retrieval Systems</p>
    <p>NUS (baseline)</p>
    <p>NUS+QE Rel_MI (NUS+QE)</p>
    <p>Rel_EM (NUS+QE)</p>
    <p>MRR (% improvement over baseline)</p>
    <p>% MRR improvement over NUS+QE</p>
    <p>N/A N/A +49.54% +49.86%</p>
    <p>% Incorrect 33.02% 28.40% 22.22% 22.22%</p>
    <p>Precision at top one passage</p>
    <p>Rel_EM (NUS) 0.4761</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Outline</p>
    <p>Extracting and Paring Relation Paths</p>
    <p>Measuring Path Match Scores</p>
    <p>Learning Relation Mapping Scores</p>
    <p>Evaluations</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Conclusions</p>
    <p>Proposed a novel fuzzy relation matching method for factoid QA passage retrieval  Brings dramatic 70%+ improvement over the state-of</p>
    <p>the-art systems</p>
    <p>Brings further 50% improvement over query expansion</p>
    <p>Future QA systems should bring in relations between words for better performance</p>
    <p>Query expansion should be integrated to relation matching seamlessly</p>
  </div>
  <div class="page">
    <p>August 17, 200 5</p>
    <p>Q &amp; A</p>
    <p>Thanks!</p>
  </div>
</Presentation>
