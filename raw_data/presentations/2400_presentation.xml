<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Andrew W Leung  Ethan L Miller University of California, Santa Cruz</p>
    <p>Spyglass: Fast, Scalable Metadata Search for Large-Scale Storage Systems</p>
    <p>Minglong Shao  Timothy Bisson  Shankar Pasupathy NetApp</p>
  </div>
  <div class="page">
    <p>The data management problem</p>
    <p>Large-scale storage systems are difficult to manage  Management questions become difficult or impossible to ask  Must sift through billions of files</p>
    <p>Impacts users and administrators  User - Where are my recently modified presentation files?  Admin - Which apps and users are consuming the most space?</p>
    <p>Challenge: need fast answers to difficult questions  Example -- smart data restore</p>
    <p>A buggy script deletes a number of users files  Which files should be restored from backup?</p>
    <p>Search current and previous versions  Locate the affected files to restore  Find the files to restore first</p>
  </div>
  <div class="page">
    <p>What can be done?</p>
    <p>Need to quickly gather and search info from the storage system  Ad hoc queries over file properties  I.e., metadata search capabilities</p>
    <p>Metadata includes file inode and extended attributes  Formatted as &lt;attribute, value&gt; pairs</p>
    <p>Metadata search becoming more common  Desktop - Spotlight, Beagle, Windows search  Small-scale enterprise - IndexEngines, Google Enterprise, FAST</p>
    <p>How can this be done at very large-scales?</p>
  </div>
  <div class="page">
    <p>Large-scale search challenges</p>
    <p>Challenge Existing Solutions Why Is This Difficult?</p>
    <p>Cost &amp; resources Require dedicated hardware.</p>
    <p>Cant afford dedicated hardware. Must share resources.</p>
    <p>Metadata Collection</p>
    <p>Slow to collect changes. Impacts the storage system. Collect millions of changes.</p>
    <p>Scale &amp; performance</p>
    <p>Use general-purpose DBMSs. Few storage optimizations. Searching 10</p>
    <p>Large-scale search challenges are not currently addressed  Requires a specialized solution</p>
  </div>
  <div class="page">
    <p>Spyglass overview</p>
    <p>How should a solution address these challenges?  Leverage metadata search properties</p>
    <p>Metadata query properties  Conducted user survey</p>
    <p>File metadata properties  Analyzed 3 storage systems</p>
    <p>Spyglass uses new index designs:  Hierarchical partitioning  Signature files  Partition versioning - in the paper  Snapshot-based metadata crawling</p>
    <p>Storage system</p>
    <p>Spyglass</p>
    <p>Cache Crawler</p>
    <p>Internal File System</p>
    <p>Partitions</p>
    <p>Version 1</p>
    <p>Version n</p>
    <p>Index</p>
    <p>Query</p>
    <p>Results</p>
  </div>
  <div class="page">
    <p>Metadata query properties</p>
    <p>Surveyed over 30 users and administrators  Asked how would you use metadata search?</p>
    <p>Property Description Example Solution</p>
    <p>Multiple attributes</p>
    <p>Includes multiple metadata attributes.</p>
    <p>Where are my recently modified presentations?</p>
    <p>Use all attributes in query execution.</p>
    <p>Localized Includes a directory pathname. Which files in my home directory can be deleted?</p>
    <p>Include namespace knowledge.</p>
    <p>Back-in-time Searches multiple metadata versions. Which files have grown the most in the last week?</p>
    <p>Version index changes.</p>
  </div>
  <div class="page">
    <p>File metadata properties</p>
    <p>Analyzed 3 storage systems at NetApp  Web server -- 15 million files  Engineering server -- 60 million files  Home directory servers -- 300 million files</p>
    <p>Property Description Example Solution</p>
    <p>Spatial locality</p>
    <p>Values clustered in namespace.</p>
    <p>Andrews files mostly in /home/andrew</p>
    <p>Allow index control using the namespace.</p>
    <p>Skewed frequencies</p>
    <p>A few values occur frequently.</p>
    <p>Intersections are more uniform.</p>
    <p>Many PDFs or Andrews files.</p>
    <p>Fewer Andrews PDF files.</p>
    <p>Query execution using intersections.</p>
  </div>
  <div class="page">
    <p>Hierarchical partitioning</p>
    <p>Partition the index using the namespace  Parts of the namespace are indexed in separate partitions</p>
    <p>Exploits spatial locality  Allows index control at the granularity of sub-trees  Uses a simple greedy algorithm</p>
    <p>Partitions are stored sequentially on disk  Fast access to each partition</p>
    <p>/</p>
    <p>home proj usr</p>
    <p>andrew jim distmeta reliability include</p>
    <p>thesis scidac src experiments</p>
  </div>
  <div class="page">
    <p>Query execution</p>
    <p>Performance is tied to the number of partitions searched  How do we determine which partitions to search?</p>
    <p>Users can localize their queries  Users control the size of the search space</p>
    <p>Signature files  Automatically determines which partitions to search  Exploits attribute value intersections</p>
    <p>Searches only partitions containing all query values</p>
  </div>
  <div class="page">
    <p>Signature files</p>
    <p>Compactly summarizes a partitions contents  A signature file for each attribute in the partition  Small enough to fit in memory  Created as files are inserted</p>
    <p>Only search a partition if all tested bits are 1</p>
    <p>False positives can be reduced by  Increasing signature size  Changing the hashing function</p>
    <p>hash() mod</p>
    <p>doc xls c ppt</p>
    <p>py pl h mpg jpg</p>
    <p>mov</p>
    <p>&lt;1 1-4 5-31 32127</p>
    <p>&gt;500MBpy 32127</p>
    <p>plpy</p>
  </div>
  <div class="page">
    <p>Partition design</p>
    <p>Each partition stores metadata in a KD-tree  Not explicitly tied to a particular index structure</p>
    <p>KD-trees  A multi-dimensional binary tree  Provides fast, multi-dimensional search  Allows a single index structure to be used</p>
    <p>Performance is bound by reading partitions from disk  Partitions are managed by a caching sub-system</p>
    <p>Uses LRU  Captures the likely Zipf-like query distributions  Ensures popular partitions are in-memory</p>
  </div>
  <div class="page">
    <p>Metadata collection</p>
    <p>Metadata collection must  Scale to millions of changes  Not degrade storage system performance</p>
    <p>Calculates the difference between to two snapshots  Leverages the inode file in WAFL snapshots  Only re-crawls metadata for changed files</p>
    <p>Block 1</p>
    <p>Snapshot 1</p>
    <p>Block 2 Block 3</p>
    <p>Block 4 Block 5 Block 6</p>
    <p>Block 1</p>
    <p>Block 2 Block 3</p>
    <p>Block 4 Block 5 Block 6</p>
    <p>Snapshot 2</p>
    <p>Inode Change</p>
    <p>Block 7</p>
    <p>Block 8</p>
    <p>Block 9</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Evaluate performance, scalability, and efficiency  Using our real-world traces from NetApp</p>
    <p>In the talk we evaluate  Metadata collection</p>
    <p>Compare performance to a simple straw-man  Search performance</p>
    <p>Compare performance to PostgreSQL and MySQL</p>
    <p>In the paper we also evaluate  Update performance  Space requirements  Index locality  Versioning overhead</p>
  </div>
  <div class="page">
    <p>Collection performance</p>
    <p>Compare snapshot-based collection (SB)  To a parallel file system crawl (SM)</p>
    <p>Ti m</p>
    <p>e( M</p>
    <p>in )</p>
    <p>Files (Millions) SM SB</p>
    <p>Baseline crawl</p>
    <p>Reads entire inode file</p>
    <p>10x faster that SM</p>
    <p>m e</p>
    <p>(M in</p>
    <p>)</p>
    <p>Files (Millions) SM-10% SM-5% SM-2%</p>
    <p>SB-10% SB-5% SB-2%</p>
    <p>Incremental crawl</p>
    <p>2%, 5%, and 10% change</p>
    <p>Finishes in less than 45 min</p>
  </div>
  <div class="page">
    <p>Search performance</p>
    <p>Set 1: 75% queries finish in less than 1 second  Many partitions are eliminated from search</p>
    <p>Set 2: Localization significantly improves performance</p>
    <p>Query Selectivity</p>
    <p>Q u</p>
    <p>e ry</p>
    <p>E x e</p>
    <p>c u</p>
    <p>ti o</p>
    <p>n T</p>
    <p>im e</p>
    <p>Spyglass System X System Y</p>
    <p>Figure4.10: ComparisonofSelectivity Impact. Theselectivity ofqueries inmyquery set isplotted against</p>
    <p>the execution time for that query. I find that query performance in Spyglass is much less correlated to the</p>
    <p>selectivity of the query predicates than the DBMSs, which are closely correlated with selectivity.</p>
    <p>Set Search Metadata Attributes</p>
    <p>Set 1 Which user and application files consume the most space? Sum sizes for files using owner and ext</p>
    <p>Set 2 How much space in this part do files from query 1 consume? Use query 1 with an additional directory path.</p>
    <p>Table 4.5: Query Sets. A summary of the searches used to generate my evaluation query sets.</p>
    <p>to store the base table and index structures. Figure 4.9 shows that this approach can incur over a 100%</p>
    <p>overhead.</p>
    <p>Selectivity Impact. In this experiment, I evaluated the effect of metadata selectivity on the performance of</p>
    <p>Spyglass and the DBMSs. I again generated query sets ofext and owner from the Web trace with varying</p>
    <p>selectivitythe ratio of the number of results to all records. Figure 4.10 plots query selectivity against query</p>
    <p>execution time. I found that the performance of PostgreSQL and MySQL is highly correlated with query</p>
    <p>selectivity. However, this correlation is much weaker in Spyglass, which exhibits much more variance.</p>
    <p>For example, a Spyglass query with selectivity 7 ! 10!6 runs in 161ms while another with selectivity 8 ! 10!6 requires 3ms. This variance is caused by the higher sensitivity of Spyglass to hierarchical locality and query locality, as opposed to simple query selectivity. This behavior is unlike that of a DBMS, which</p>
    <p>accesses records from disk based on the predicate it thinks is the most selective. The weak correlation with</p>
    <p>selectivity in Spyglass means it is less affected by the highly skewed distribution of storage metadata which</p>
    <p>makes determining selectivity difficult.</p>
    <p>Search Performance. Toevaluate Spyglass search performance I generated sets ofquery derived from real</p>
    <p>world queries in my user study; there are, unfortunately, nostandard benchmarks for file system search. My</p>
    <p>first set is based ona storage administrator searching for theuser and application files that are consuming the</p>
    <p>most spacean example of a simple two attribute search. The second set is an administrator localizing the</p>
    <p>same search to only part of the namespace, which shows how localizing the search changes performance.</p>
    <p>Evaluate 100 queries generated from 300 million file trace</p>
    <p>Query Execution Time</p>
    <p>Fr ac</p>
    <p>tio n</p>
    <p>of Q</p>
    <p>ue rie</p>
    <p>s</p>
    <p>Spyglass Postgres MySQL Query Execution Time</p>
    <p>Fr ac</p>
    <p>tio n</p>
    <p>of Q</p>
    <p>ue rie</p>
    <p>s</p>
    <p>Spyglass Postgres MySQL</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Metadata search can greatly improve how we manage data  Large-scale storage systems present unique challenges</p>
    <p>Cost &amp; resources, metadata collection, performance &amp; scalability</p>
    <p>There are opportunities to leverage query and file properties  Conducted a survey of real users and administrators  Analyzed real-world large-scale storage systems</p>
    <p>Spyglass is a new metadata search design  Hierarchical partitioning  Partition versioning  Snapshot-based metadata collection</p>
  </div>
  <div class="page">
    <p>Thank you! Questions?</p>
    <p>Thanks to our sponsors:</p>
  </div>
  <div class="page">
    <p>Partition versioning</p>
    <p>Index versioning provides  Back-in-time search capabilities  Fast, out-of-place index updates</p>
    <p>Each partition manages its own versions with a version vector  Exploits file update locality</p>
    <p>Each version is a batch of index updates  Represents the state of metadata at a given time  Absorbs frequent file re-modifications  However, creates a stale index</p>
  </div>
  <div class="page">
    <p>Versioning design</p>
    <p>Versions contain incremental metadata changes  Changes roll results forward</p>
    <p>Stored sequentially with the partition  Updates are fast - small sequential writes  Search overhead is low - Longer sequential reads</p>
    <p>T0 T1 T2 T3</p>
    <p>Baseline index</p>
    <p>T0 T2T0 T0 T2 T3</p>
    <p>Incremental indexes</p>
    <p>/</p>
    <p>home proj usr</p>
    <p>john jim distmeta reliability include</p>
    <p>thesis scidac src experiments</p>
  </div>
  <div class="page">
    <p>Update performance</p>
    <p>Between 8x and 44x faster than DBMSs  DBMS load table and build indexes</p>
    <p>Scales linearly</p>
    <p>Web Eng Home</p>
    <p>U pd</p>
    <p>at e</p>
    <p>Ti m</p>
    <p>e (s</p>
    <p>)</p>
    <p>Spyglass PostgreSQL Table PostgreSQL Index</p>
    <p>MySQL Table MySQL Index</p>
    <p>Build baseline for each full snapshot</p>
  </div>
  <div class="page">
    <p>Index locality</p>
    <p>Attribute intersections reduce the search space  50% of queries access less than 2% of partitions</p>
    <p>Selective attributes improve cache hit ratio  95% of queries have 95% cache hits</p>
    <p>Evaluate how partitions are queried and cached</p>
    <p>Generate queries based on attribute distributions</p>
    <p>Percent of Queries</p>
    <p>P er</p>
    <p>ce nt</p>
    <p>o f S</p>
    <p>ub t</p>
    <p>re e</p>
    <p>P ar</p>
    <p>tit io</p>
    <p>ns Q</p>
    <p>ue rie</p>
    <p>d</p>
    <p>ext owner ext/owner Percent of Queries</p>
    <p>P er</p>
    <p>ce nt</p>
    <p>o f C</p>
    <p>ac he</p>
    <p>H its</p>
    <p>ext owner ext/owner</p>
  </div>
  <div class="page">
    <p>Versioning overhead</p>
    <p>Each versions adds 10% runtime overhead  Overhead is not evenly distributed</p>
    <p>50% of queries have less than a 5 ms overhead  A few queries contribute most to overhead</p>
    <p>Evaluate overhead of 1 to 3 days of changes</p>
    <p>Number of Versions 0 1 2 3</p>
    <p>To ta</p>
    <p>l R un</p>
    <p>T im</p>
    <p>e (s</p>
    <p>)</p>
    <p>Query Overhead</p>
    <p>Fr ac</p>
    <p>tio n</p>
    <p>of Q</p>
    <p>ue rie</p>
    <p>s</p>
  </div>
</Presentation>
