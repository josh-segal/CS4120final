<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Design and ImplementationDesign and Implementation of the CCC of the CCC</p>
    <p>Parallel Programming LanguageParallel Programming Language</p>
    <p>Nai-Wei Lin</p>
    <p>Department of Computer Science and Information Engineering</p>
    <p>National Chung Cheng University</p>
  </div>
  <div class="page">
    <p>ICS2004 2</p>
    <p>OutlineOutline</p>
    <p>Introduction</p>
    <p>The CCC programming language</p>
    <p>The CCC compiler</p>
    <p>Performance evaluation</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>ICS2004 3</p>
    <p>MotivationsMotivations</p>
    <p>Parallelism is the future trend</p>
    <p>Programming in parallel is much more difficult than programming in serial</p>
    <p>Parallel architectures are very diverse</p>
    <p>Parallel programming models are very diverse</p>
  </div>
  <div class="page">
    <p>ICS2004 4</p>
    <p>MotivationsMotivations</p>
    <p>Design a parallel programming language that uniformly integrates various parallel program ming models</p>
    <p>Implement a retargetable compiler for this par allel programming language on various paralle l architectures</p>
  </div>
  <div class="page">
    <p>ICS2004 5</p>
    <p>Approaches to ParallelismApproaches to Parallelism</p>
    <p>Library approach  MPI (Message Passing Interface), pthread</p>
    <p>Compiler approach  HPF (High Performance Fortran), HPC++</p>
    <p>Language approach  Occam, Linda, CCC (Chung Cheng C)</p>
  </div>
  <div class="page">
    <p>ICS2004 6</p>
    <p>Models of Parallel ArchitecturesModels of Parallel Architectures</p>
    <p>Control Model  SIMD: Single Instruction Multiple Data</p>
    <p>MIMD: Multiple Instruction Multiple Data</p>
    <p>Data Model  Shared-memory</p>
    <p>Distributed-memory</p>
  </div>
  <div class="page">
    <p>ICS2004 7</p>
    <p>Models of Parallel ProgrammingModels of Parallel Programming</p>
    <p>Concurrency  Control parallelism: simultaneously execute</p>
    <p>multiple threads of control</p>
    <p>Data parallelism: simultaneously execute the same operations on multiple data</p>
    <p>Synchronization and communication  Shared variables</p>
    <p>Message passing</p>
  </div>
  <div class="page">
    <p>ICS2004 8</p>
    <p>Granularity of ParallelismGranularity of Parallelism</p>
    <p>Procedure-level parallelism  Concurrent execution of procedures on multiple</p>
    <p>processors</p>
    <p>Loop-level parallelism  Concurrent execution of iterations of loops on</p>
    <p>multiple processors</p>
    <p>Instruction-level parallelism  Concurrent execution of instructions on a single</p>
    <p>processor with multiple functional units</p>
  </div>
  <div class="page">
    <p>ICS2004 9</p>
    <p>The CCC Programming LanguageThe CCC Programming Language</p>
    <p>CCC is a simple extension of C and supports both control and data parallelism</p>
    <p>A CCC program consists of a set of concurrent and cooperative tasks</p>
    <p>Control parallelism runs in MIMD mode and communicates via shared variables and/or message passing</p>
    <p>Data parallelism runs in SIMD mode and communicates via shared variables</p>
  </div>
  <div class="page">
    <p>ICS2004 10</p>
    <p>Tasks in CCC ProgramsTasks in CCC Programs</p>
    <p>Control Parallel</p>
    <p>Data Parallel</p>
  </div>
  <div class="page">
    <p>ICS2004 11</p>
    <p>Control ParallelismControl Parallelism</p>
    <p>Concurrency  task</p>
    <p>par and parfor</p>
    <p>Synchronization and communication  shared variables  monitors</p>
    <p>message passing  channels</p>
  </div>
  <div class="page">
    <p>ICS2004 12</p>
    <p>MonitorsMonitors</p>
    <p>The monitor construct is a modular and efficient construct for synchronizing shared variables among concurrent tasks</p>
    <p>It provides data abstraction, mutual exclusion, and conditional synchronization</p>
  </div>
  <div class="page">
    <p>ICS2004 13</p>
    <p>An Example - Barber Shop An Example - Barber Shop</p>
    <p>Barber</p>
    <p>Chair</p>
    <p>Customer Customer Customer</p>
  </div>
  <div class="page">
    <p>ICS2004 14</p>
    <p>An Example - Barber Shop An Example - Barber Shop</p>
    <p>task::main( ) { monitor Barber_Shop bs; int i;</p>
    <p>par { barber( bs ); parfor (i = 0; i &lt; 10; i++) customer( bs ); } }</p>
  </div>
  <div class="page">
    <p>ICS2004 15</p>
    <p>An Example - Barber Shop An Example - Barber Shop</p>
    <p>task::barber(monitor Barber_Shop in bs) { while ( 1 ) { bs.get_next_customer( ); bs.finished_cut( ); } }</p>
    <p>task::customer(monitor Barber_Shop in bs) { bs.get_haircut( ); }</p>
  </div>
  <div class="page">
    <p>ICS2004 16</p>
    <p>An Example - Barber Shop An Example - Barber Shop</p>
    <p>monitor Barber_Shop { int barber, chair, open; cond barber_available, chair_occupied; cond door_open, customer_left;</p>
    <p>Barber_Shop( ); void get_haircut( ); void get_next_customer( ); void finished_cut( ); };</p>
  </div>
  <div class="page">
    <p>ICS2004 17</p>
    <p>An Example - Barber Shop An Example - Barber Shop</p>
    <p>Barber_Shop( ) { barber = 0; chair = 0; open = 0; }</p>
    <p>void get_haircut( ) { while (barber == 0) wait(barber_available); barber = 1; chair += 1; signal(chair_occupied); while (open == 0) wait(door_open); open = 1; signal(customer_left); }</p>
  </div>
  <div class="page">
    <p>ICS2004 18</p>
    <p>An Example - Barber Shop An Example - Barber Shop</p>
    <p>void get_next_customer( ) { barber += 1; signal(barber_available); while (chair == 0) wait(chair_occupied); chair = 1; }</p>
    <p>void get_haircut( ) { open += 1; signal(door_open); while (open &gt; 0) wait(customer_left); }</p>
  </div>
  <div class="page">
    <p>ICS2004 19</p>
    <p>ChannelsChannels</p>
    <p>The channel construct is a modular and effi cient construct for message passing among concurrent tasks</p>
    <p>Pipe: one to one</p>
    <p>Merger: many to one</p>
    <p>Spliter: one to many</p>
    <p>Multiplexer: many to many</p>
  </div>
  <div class="page">
    <p>ICS2004 20</p>
    <p>ChannelsChannels</p>
    <p>Communication structures among parallel task s are more comprehensive</p>
    <p>The specification of communication structures is easier</p>
    <p>The implementation of communication structu res is more efficient</p>
    <p>The static analysis of communication structur es is more effective</p>
  </div>
  <div class="page">
    <p>ICS2004 21</p>
    <p>An Example - Consumer-Producer An Example - Consumer-Producer</p>
    <p>producer consumer</p>
    <p>consumer</p>
    <p>consumer</p>
    <p>spliter</p>
  </div>
  <div class="page">
    <p>ICS2004 22</p>
    <p>An Example - Consumer-Producer An Example - Consumer-Producer</p>
    <p>task::main( ) { spliter int chan; int i;</p>
    <p>par { producer( chan ); parfor (i = 0; i &lt; 10; i++) consumer( chan ); } }</p>
  </div>
  <div class="page">
    <p>ICS2004 23</p>
    <p>An Example - Consumer-Producer An Example - Consumer-Producer</p>
    <p>task::producer(spliter in int chan) { int i;</p>
    <p>for (i = 0; i &lt; 100; i++) put(chan, i); for (i = 0; i &lt; 10; i++) put(chan, END); }</p>
  </div>
  <div class="page">
    <p>ICS2004 24</p>
    <p>An Example - Consumer-Producer An Example - Consumer-Producer</p>
    <p>task::consumer(spliter in int chan) { int data;</p>
    <p>while ((data = get(chan)) != END) process(data); }</p>
  </div>
  <div class="page">
    <p>ICS2004 25</p>
    <p>Data ParallelismData Parallelism</p>
    <p>Concurrency  domain  an aggregate of synchronous tasks</p>
    <p>Synchronization and communication  domain  variables in global name space</p>
  </div>
  <div class="page">
    <p>ICS2004 26</p>
    <p>An Example  Matrix MultiplicationAn Example  Matrix Multiplication</p>
    <p>=</p>
  </div>
  <div class="page">
    <p>ICS2004 27</p>
    <p>An Example Matrix MultiplicationAn Example Matrix Multiplication</p>
    <p>domain matrix_op[16] { int a[16], b[16], c[16]; multiply(distribute in int [16:block][16], distribute in int [16][16:block], distribute out int [16:block][16]); };</p>
  </div>
  <div class="page">
    <p>ICS2004 28</p>
    <p>task::main( ) { int A[16][16], B[16][16], C[16][16]; domain matrix_op m;</p>
    <p>read_array(A); read_array(B); m.multiply(A, B, C); print_array(C); }</p>
    <p>An Example Matrix MultiplicationAn Example Matrix Multiplication</p>
  </div>
  <div class="page">
    <p>ICS2004 29</p>
    <p>matrix_op::multiply(A, B, C) distribute in int [16:block][16] A; distribute in int [16][16:block] B; distribute out int [16:block][16] C; { int i, j; a := A; b := B; for (i = 0; i &lt; 16; i++) for (c[i] = 0, j = 0; j &lt; 16; j++) c[i] += a[j] * matrix_op[i].b[j]; C := c; }</p>
    <p>An Example Matrix MultiplicationAn Example Matrix Multiplication</p>
  </div>
  <div class="page">
    <p>ICS2004 30</p>
    <p>Platforms for the CCC CompilerPlatforms for the CCC Compiler</p>
    <p>PCs and SMPs  Pthread: shared memory + dynamic thread creat</p>
    <p>ion</p>
    <p>PC clusters and SMP clusters  Millipede: distributed shared memory + dynami</p>
    <p>c remote thread creation</p>
    <p>The similarities between these two classes o f machines enable a retargetable compiler i mplementation for CCC</p>
  </div>
  <div class="page">
    <p>ICS2004 31</p>
    <p>Organization of the CCC Organization of the CCC Programming System Programming System</p>
    <p>CCC compiler</p>
    <p>CCC runtime library</p>
    <p>Virtual shared memory machine interface</p>
    <p>CCC applications</p>
    <p>Pthread Millipede</p>
    <p>SMP SMP cluster</p>
  </div>
  <div class="page">
    <p>ICS2004 32</p>
    <p>The CCC CompilerThe CCC Compiler</p>
    <p>Tasks  threads</p>
    <p>Monitors  mutex locks, read-write locks, an d condition variables</p>
    <p>Channels  mutex locks and condition variab les</p>
    <p>Domains  set of synchronous threads</p>
    <p>Synchronous execution  barriers</p>
  </div>
  <div class="page">
    <p>ICS2004 33</p>
    <p>Virtual Shared Memory Machine Virtual Shared Memory Machine InterfaceInterface</p>
    <p>Processor management</p>
    <p>Thread management</p>
    <p>Shared memory allocation</p>
    <p>Mutex locks</p>
    <p>Read-write locks</p>
    <p>Condition variables</p>
    <p>Barriers</p>
  </div>
  <div class="page">
    <p>ICS2004 34</p>
    <p>The CCC Runtime LibraryThe CCC Runtime Library</p>
    <p>The CCC runtime library contains a collection of functions that implements the salient abstra ctions of CCC on top of the virtual shared me mory machine interface</p>
  </div>
  <div class="page">
    <p>ICS2004 35</p>
    <p>Performance EvaluationPerformance Evaluation</p>
    <p>SMPs</p>
    <p>Hardware  an SMP machine with four CPUs, each CPU is an Intel PentiumII Xeon 450MHz, and cache is 512K</p>
    <p>Software  OS is Solaris 5.7 and library is pthread 1.26</p>
    <p>SMP clusters</p>
    <p>Hardware  four SMP machines, each of which has two CP Us, each CPU is Intel PentiumIII 500MHz, and cache is 512K</p>
    <p>Software  OS is windows 2000 and library is millipede 4.0</p>
    <p>Network  Fast ethernet network 100Mbps</p>
  </div>
  <div class="page">
    <p>ICS2004 36</p>
    <p>BenchmarksBenchmarks</p>
    <p>Matrix multiplication (1024 x 1024)</p>
    <p>arshalls transitive closure (1024 x 1024)</p>
    <p>Airshed simulation (5)</p>
  </div>
  <div class="page">
    <p>ICS2004 37</p>
    <p>Matrix Multiplication (SMPs)</p>
    <p>Sequential 1thread/1cpu 2threads/1cpu 4threads/1cpu 8threads/1cpu</p>
    <p>CCC (1 cpu) 287.5</p>
    <p>Pthread (1 cpu)</p>
    <p>(0.98, 0.98) 257.45</p>
    <p>(1.12, 1.12) 244.24</p>
    <p>(1.17, 1.17) 266.20</p>
    <p>(1.08, 1.08)</p>
    <p>CCC (2 cpu)</p>
    <p>Pthread (2 cpu)</p>
    <p>(1.91, 0.96) 105.45</p>
    <p>(2.72, 1.36) 93.56</p>
    <p>(3.07, 1.53) 119.42</p>
    <p>(2.41, 1.20)</p>
    <p>CCC (4 cpu)</p>
    <p>Pthread (4 cpu)</p>
    <p>(3.85, 0.96) 65.42</p>
    <p>(4.39, 1.09) 69.88</p>
    <p>(4.11, 1.02)</p>
    <p>(unit  sec )</p>
  </div>
  <div class="page">
    <p>ICS2004 38</p>
    <p>Matrix Multiplication (SMP clusters)</p>
    <p>Sequential 1thread/1cpu 2threads/1cpu 4threads/1cpu 8threads/1cpu</p>
    <p>CCC (1mach x 2cpu) 470.44</p>
    <p>Millipede (1mach x 2cpu)</p>
    <p>CCC (2mach x 2cpu)</p>
    <p>Millipede (2mach x 2cpu)</p>
    <p>CCC (4mach x 2cpu)</p>
    <p>Millipede (4mach x 2cpu)</p>
    <p>(unit  sec )</p>
  </div>
  <div class="page">
    <p>ICS2004 39</p>
    <p>Warshalls Transitive Closure (SMPs)</p>
    <p>Sequtial 1thread/1cpu 2threads/1cpu 4threads/1cpu 8threads/1cpu</p>
    <p>CCC (1 cpu) 150.32 152.88</p>
    <p>(0.98, 0.98) 138.44</p>
    <p>(1.08, 1.08) 143.54</p>
    <p>(1.05, 1.05) 154.33</p>
    <p>(0.97, 0.97)</p>
    <p>Pthread (1 cpu)</p>
    <p>CCC (2 cpu)</p>
    <p>Pthread (2 cpu)</p>
    <p>CCC (4 cpu)</p>
    <p>Pthread (4 cpu)</p>
    <p>(unit  sec )</p>
  </div>
  <div class="page">
    <p>ICS2004 40</p>
    <p>Warshalls Transitive Closure (SMP cluste rs)</p>
    <p>Sequential 1thread/1cpu 2threads/1cpu 4threads/1cpu 8threads/1cpu</p>
    <p>CCC (1mach x 2cpu) 305.35</p>
    <p>Millipade (1mach x 2cpu)</p>
    <p>CCC (2mach x 2cpu)</p>
    <p>Millipede (2mach x 2cpu)</p>
    <p>CCC (4mach x 2cpu)</p>
    <p>Millipede (4mach x 2cpu)</p>
    <p>(unit  sec )</p>
  </div>
  <div class="page">
    <p>ICS2004 41</p>
    <p>Seq 5\5\5 1\5\5 5\1\5 5\5\1 1\1\5 1\5\1 5\1\1</p>
    <p>CCC(2cpu )</p>
    <p>(1.6,0.8) 8.84</p>
    <p>(1.6,0.8) 10.52</p>
    <p>(1.3,0.6) 12.87</p>
    <p>(1.1,0.5) 10.75</p>
    <p>(1.3,0.6) 13.2</p>
    <p>(1.1,0.5) 14.85</p>
    <p>(0.9,0.4)</p>
    <p>Pthread (2cpu)</p>
    <p>(1.6,0.8) 8.82</p>
    <p>(1.6,0.8) 10.42</p>
    <p>(1.3,0.6) 12.84</p>
    <p>(1.1,0.5) 10.72</p>
    <p>(1.3,0.6) 13.19</p>
    <p>(1.1,0.5) 14.82</p>
    <p>(0.9,0.4)</p>
    <p>CCC(4cpu )</p>
    <p>(2.1,0.5) 6.84</p>
    <p>(2.1,0.5) 9.03</p>
    <p>(1.5,0.3) 12.08</p>
    <p>(1.1,0.2) 9.41</p>
    <p>(1.5,0.3) 12.46</p>
    <p>(1.1,0.2) 14.66</p>
    <p>(0.9,0.2)</p>
    <p>Pthread (4cpu)</p>
    <p>(2.2,0.5) 6.81</p>
    <p>(2.1,0.5) 9.02</p>
    <p>(1.5,0.3) 12.07</p>
    <p>(1.1,0.2) 9.38</p>
    <p>(1.5,0.3) 12.44</p>
    <p>(1.1,0.2) 14.62</p>
    <p>(0.9,0.2)</p>
    <p>Airshed simulation (SMPs)</p>
    <p>thread s</p>
    <p>(unit  sec )</p>
  </div>
  <div class="page">
    <p>ICS2004 42</p>
    <p>Seq 5\5\5 1\5\5 5\1\5 5\5\1 1\1\5 1\5\1 5\1\1</p>
    <p>CCC (1m x 2p)</p>
    <p>(1.9,0.9) 26.75</p>
    <p>(1.8,0.9) 30.37</p>
    <p>(1.6,0.8) 44.25</p>
    <p>(1.1,0.5) 31.97</p>
    <p>(1.5,0.7) 45.25</p>
    <p>(1.1,0.5) 48.51</p>
    <p>(1.1,0.5)</p>
    <p>Millipe de</p>
    <p>(1m x 2p)</p>
    <p>(2.4,1.2) 20.87</p>
    <p>(2.3,1.1) 26.05</p>
    <p>(1.9,0.9) 30.41</p>
    <p>(1.6,0.8) 26.42</p>
    <p>(1.8,0.9) 31.13</p>
    <p>(1.5,0.7) 35.89</p>
    <p>(1.3,0.6)</p>
    <p>CCC (2m x 2p)</p>
    <p>(1.8,0.4) 27.51</p>
    <p>(1.8,0.4) 50.42</p>
    <p>(0.9,0.2) 56.68</p>
    <p>(0.8,0.2) 54.76</p>
    <p>(0.9,0.2) 58.25</p>
    <p>(0.8,0.2) 91.17</p>
    <p>(0.5,0.1)</p>
    <p>Millipede (2m x 2</p>
    <p>p) 49.9</p>
    <p>CCC (4m x 2p)</p>
    <p>(2.1,0.2) 25.59</p>
    <p>(1.9,0.2) 48.97</p>
    <p>(1.0,0.1) 58.31</p>
    <p>(0.8,0.1) 53.33</p>
    <p>(0.9,0.1) 61.96</p>
    <p>(0.8,0.1) 89.61</p>
    <p>(0.5,0.1)</p>
    <p>Millipede (4m x 2</p>
    <p>p) 49.9</p>
    <p>Airshed simulation (SMP clusters)</p>
    <p>thread s</p>
    <p>(unit  sec )</p>
  </div>
  <div class="page">
    <p>ICS2004 43</p>
    <p>ConclusionsConclusions</p>
    <p>A high-level parallel programming language that uniformly integrates  Both control and data parallelism</p>
    <p>Both shared variables and message passing</p>
    <p>A modular parallel programming language</p>
    <p>A retargetable compiler</p>
  </div>
</Presentation>
