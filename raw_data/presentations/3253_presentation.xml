<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Cloudy with a Chance of Breach: Forecasting Cyber Security Incidents</p>
    <p>Yang Liu, Armin Sarabi, Jing Zhang, Parinaz Naghizadeh</p>
    <p>Manish Karir], Michael Bailey, Mingyan Liu,]</p>
    <p>EECS Department, University of Michigan, Ann Arbor ] QuadMetrics, Inc.</p>
    <p>ECE Department, University of Illinois, Urbana-Champaign</p>
    <p>http://grs.eecs.umich.edu</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 1 / 28</p>
  </div>
  <div class="page">
    <p>Intro Introduction</p>
    <p>Motivation</p>
    <p>Increasingly frequent and high-impact data breaches</p>
    <p>I Target, JP Morgan Chase, Home Depot, to name a few</p>
    <p>I Increasing social and economic impact of such cyber incidents</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 2 / 28</p>
  </div>
  <div class="page">
    <p>Intro Introduction</p>
    <p>Limitation of current approaches</p>
    <p>I Heavily detection based</p>
    <p>I Fail to detect, or too late by the time a breach is detected</p>
    <p>I Not suited for cost/damage control</p>
    <p>I Urgent need for more proactive measures</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 3 / 28</p>
  </div>
  <div class="page">
    <p>Intro Introduction</p>
    <p>Detection</p>
    <p>I analogous to diagnosing a patient who may already be ill (e.g., by using biopsy).</p>
    <p>I [Qian et al. NDSS14, Wang et al. USENIX Sec14]</p>
    <p>Prediction</p>
    <p>I predicting whether a presently healthy person may become ill based on a variety of relevant factors.</p>
    <p>I [Soska &amp; Christin, USENIX Sec14]</p>
    <p>Our goal:</p>
    <p>I Understand the extent to which one can forecast incidents on an organizational level.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 4 / 28</p>
  </div>
  <div class="page">
    <p>Intro Introduction</p>
    <p>Detection</p>
    <p>I analogous to diagnosing a patient who may already be ill (e.g., by using biopsy).</p>
    <p>I [Qian et al. NDSS14, Wang et al. USENIX Sec14]</p>
    <p>Prediction</p>
    <p>I predicting whether a presently healthy person may become ill based on a variety of relevant factors.</p>
    <p>I [Soska &amp; Christin, USENIX Sec14]</p>
    <p>Our goal:</p>
    <p>I Understand the extent to which one can forecast incidents on an organizational level.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 4 / 28</p>
  </div>
  <div class="page">
    <p>Intro Introduction</p>
    <p>Objective</p>
    <p>To develop the ability to forecast security incidences</p>
    <p>I Applicability: we rely solely on externally observed data; do not require information on the internal workings of a network or its hosts.</p>
    <p>I Robustness: we do not have control over or direct knowledge of the error embedded in the data.</p>
    <p>Key idea:</p>
    <p>I tap into a diverse set of data that captures different aspects of a networks security posture, ranging from the explicit to latent.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 5 / 28</p>
  </div>
  <div class="page">
    <p>Intro Introduction</p>
    <p>Objective</p>
    <p>To develop the ability to forecast security incidences</p>
    <p>I Applicability: we rely solely on externally observed data; do not require information on the internal workings of a network or its hosts.</p>
    <p>I Robustness: we do not have control over or direct knowledge of the error embedded in the data.</p>
    <p>Key idea:</p>
    <p>I tap into a diverse set of data that captures different aspects of a networks security posture, ranging from the explicit to latent.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 5 / 28</p>
  </div>
  <div class="page">
    <p>Intro Introduction</p>
    <p>Objective</p>
    <p>To develop the ability to forecast security incidences</p>
    <p>I Applicability: we rely solely on externally observed data; do not require information on the internal workings of a network or its hosts.</p>
    <p>I Robustness: we do not have control over or direct knowledge of the error embedded in the data.</p>
    <p>Key idea:</p>
    <p>I tap into a diverse set of data that captures different aspects of a networks security posture, ranging from the explicit to latent.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 5 / 28</p>
  </div>
  <div class="page">
    <p>Intro Introduction</p>
    <p>Why prediction?</p>
    <p>Forecast enables entirely new classes of applications which are otherwise not feasible.</p>
    <p>I Prediction allows proactive policies and measures to be adopted rather than reactive measures following the detection.</p>
    <p>Forecast enables effective risk management schemes</p>
    <p>I Internal to an org.: more informed decisions on resource allocation.</p>
    <p>I External to an org.: incentive mechanisms such as cyber insurance.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 6 / 28</p>
  </div>
  <div class="page">
    <p>Intro Introduction</p>
    <p>Why prediction?</p>
    <p>Forecast enables entirely new classes of applications which are otherwise not feasible.</p>
    <p>I Prediction allows proactive policies and measures to be adopted rather than reactive measures following the detection.</p>
    <p>Forecast enables effective risk management schemes</p>
    <p>I Internal to an org.: more informed decisions on resource allocation.</p>
    <p>I External to an org.: incentive mechanisms such as cyber insurance.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 6 / 28</p>
  </div>
  <div class="page">
    <p>Intro Introduction</p>
    <p>Why prediction?</p>
    <p>Forecast enables entirely new classes of applications which are otherwise not feasible.</p>
    <p>I Prediction allows proactive policies and measures to be adopted rather than reactive measures following the detection.</p>
    <p>Forecast enables effective risk management schemes</p>
    <p>I Internal to an org.: more informed decisions on resource allocation.</p>
    <p>I External to an org.: incentive mechanisms such as cyber insurance.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 6 / 28</p>
  </div>
  <div class="page">
    <p>Intro Introduction</p>
    <p>Why prediction?</p>
    <p>Forecast enables entirely new classes of applications which are otherwise not feasible.</p>
    <p>I Prediction allows proactive policies and measures to be adopted rather than reactive measures following the detection.</p>
    <p>Forecast enables effective risk management schemes</p>
    <p>I Internal to an org.: more informed decisions on resource allocation.</p>
    <p>I External to an org.: incentive mechanisms such as cyber insurance.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 6 / 28</p>
  </div>
  <div class="page">
    <p>Intro Introduction</p>
    <p>Why prediction?</p>
    <p>Forecast enables entirely new classes of applications which are otherwise not feasible.</p>
    <p>I Prediction allows proactive policies and measures to be adopted rather than reactive measures following the detection.</p>
    <p>Forecast enables effective risk management schemes</p>
    <p>I Internal to an org.: more informed decisions on resource allocation.</p>
    <p>I External to an org.: incentive mechanisms such as cyber insurance.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 6 / 28</p>
  </div>
  <div class="page">
    <p>Intro Introduction</p>
    <p>Outline of the talk</p>
    <p>I Data and Preliminaries</p>
    <p>- Description of the data - Data pre-processing</p>
    <p>I Forecasting methods</p>
    <p>- Construction of the predictor</p>
    <p>I Forecasting results</p>
    <p>- Main prediction results &amp; analysis</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 7 / 28</p>
  </div>
  <div class="page">
    <p>Data Methodology</p>
    <p>Datasets at a glance</p>
    <p>Category Collection period Datasets</p>
    <p>Mismanagement Feb13 - Jul13 Open Recursive Resolvers, DNS Source Port, symptoms BGP misconfiguration, Untrusted HTTPS,</p>
    <p>Open SMTP Mail Relays Malicious May13 - Dec14 CBL, SBL, SpamCop, UCEPROTECT, activities WPBL, SURBL, PhishTank, hpHosts,</p>
    <p>Darknet scanners list, Dshield, OpenBL Incident Aug13 - Dec14 VERIS Community Database, reports Hackmageddon, Web Hacking Incidents</p>
    <p>I Mismanagement and malicious activities used to extract features.</p>
    <p>I Incident reports used to generate labels for training and testing.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 8 / 28</p>
  </div>
  <div class="page">
    <p>Data Methodology</p>
    <p>Security posture data</p>
    <p>Mismanagement symptoms</p>
    <p>I Deviation from known best practices; indicators of lack of policy or expertise:</p>
    <p>- Misconfigured- HTTPS cert, DNS (resolver+source port), mail server, BGP.</p>
    <p>I Collected around mid-2013 (pre-incidnts).</p>
    <p>Malicious Activity Data: a set of 11 reputation blacklists (RBLs)</p>
    <p>I Daily collections of IPs seen engaged in some malicious activity.</p>
    <p>I Three malicious activity types: spam, phishing, scan.</p>
    <p>I Use data between May 2013 and December 2014.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 9 / 28</p>
  </div>
  <div class="page">
    <p>Data Methodology</p>
    <p>Security posture data</p>
    <p>Mismanagement symptoms</p>
    <p>I Deviation from known best practices; indicators of lack of policy or expertise:</p>
    <p>- Misconfigured- HTTPS cert, DNS (resolver+source port), mail server, BGP.</p>
    <p>I Collected around mid-2013 (pre-incidnts).</p>
    <p>Malicious Activity Data: a set of 11 reputation blacklists (RBLs)</p>
    <p>I Daily collections of IPs seen engaged in some malicious activity.</p>
    <p>I Three malicious activity types: spam, phishing, scan.</p>
    <p>I Use data between May 2013 and December 2014.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 9 / 28</p>
  </div>
  <div class="page">
    <p>Data Methodology</p>
    <p>Security incident Data</p>
    <p>Three incident datasets</p>
    <p>I Hackmageddon</p>
    <p>I Web Hacking Incidents Database (WHID)</p>
    <p>I VERIS Community Database (VCDB)</p>
    <p>Incident type SQLi Hijacking Defacement DDoS</p>
    <p>Hackmageddon 38 9 97 59 WHID 12 5 16 45</p>
    <p>Incident type Crimeware Cyber Esp. Web app. Else VCDB 59 16 368 213</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 10 / 28</p>
  </div>
  <div class="page">
    <p>Data Data Pre-processing</p>
    <p>Data Pre-processing</p>
    <p>Incident cleaning.</p>
    <p>I Remove irrelevant cases, e.g., robbery at liquor store, something happened etc.</p>
    <p>Data diversity presents challenge in alignment in time and space.</p>
    <p>I Security posture records information at the host IP-address level.</p>
    <p>I Cyber incident reports associated with an organization.</p>
    <p>I Such alignment is not travial: reallocation makes boundary unclear.</p>
    <p>A mapping process:</p>
    <p>I Summarizing owner IDs from RIR databases.</p>
    <p>I 4.4 million prefixes listed under 2.6 million owner IDs: finer degree compared to routing table.</p>
    <p>I Sample IP from organization + search in above table.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 11 / 28</p>
  </div>
  <div class="page">
    <p>Data Data Pre-processing</p>
    <p>Data Pre-processing</p>
    <p>Incident cleaning.</p>
    <p>I Remove irrelevant cases, e.g., robbery at liquor store, something happened etc.</p>
    <p>Data diversity presents challenge in alignment in time and space.</p>
    <p>I Security posture records information at the host IP-address level.</p>
    <p>I Cyber incident reports associated with an organization.</p>
    <p>I Such alignment is not travial: reallocation makes boundary unclear.</p>
    <p>A mapping process:</p>
    <p>I Summarizing owner IDs from RIR databases.</p>
    <p>I 4.4 million prefixes listed under 2.6 million owner IDs: finer degree compared to routing table.</p>
    <p>I Sample IP from organization + search in above table.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 11 / 28</p>
  </div>
  <div class="page">
    <p>Data Data Pre-processing</p>
    <p>Data Pre-processing</p>
    <p>Incident cleaning.</p>
    <p>I Remove irrelevant cases, e.g., robbery at liquor store, something happened etc.</p>
    <p>Data diversity presents challenge in alignment in time and space.</p>
    <p>I Security posture records information at the host IP-address level.</p>
    <p>I Cyber incident reports associated with an organization.</p>
    <p>I Such alignment is not travial: reallocation makes boundary unclear.</p>
    <p>A mapping process:</p>
    <p>I Summarizing owner IDs from RIR databases.</p>
    <p>I 4.4 million prefixes listed under 2.6 million owner IDs: finer degree compared to routing table.</p>
    <p>I Sample IP from organization + search in above table.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 11 / 28</p>
  </div>
  <div class="page">
    <p>Forecast</p>
    <p>Outline of the talk</p>
    <p>I Data and Preliminaries</p>
    <p>- Description of the data - Data pre-processing</p>
    <p>I Forecasting methods</p>
    <p>- Construction of the predictor</p>
    <p>I Forecasting results</p>
    <p>- Main prediction results &amp; analysis</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 12 / 28</p>
  </div>
  <div class="page">
    <p>Forecast Methodology</p>
    <p>Approach at a glance</p>
    <p>Feature extraction</p>
    <p>I 258 features extracted from the datasets: Primary + Secondary features.</p>
    <p>Label generation</p>
    <p>I 1,000+ incident reports from the three incident sets</p>
    <p>Classifier training and testing</p>
    <p>I Random Forest (RF) classifier trained with features and labels.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 13 / 28</p>
  </div>
  <div class="page">
    <p>Forecast Methodology</p>
    <p>Approach at a glance</p>
    <p>Feature extraction</p>
    <p>I 258 features extracted from the datasets: Primary + Secondary features.</p>
    <p>Label generation</p>
    <p>I 1,000+ incident reports from the three incident sets</p>
    <p>Classifier training and testing</p>
    <p>I Random Forest (RF) classifier trained with features and labels.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 13 / 28</p>
  </div>
  <div class="page">
    <p>Forecast Methodology</p>
    <p>Approach at a glance</p>
    <p>Feature extraction</p>
    <p>I 258 features extracted from the datasets: Primary + Secondary features.</p>
    <p>Label generation</p>
    <p>I 1,000+ incident reports from the three incident sets</p>
    <p>Classifier training and testing</p>
    <p>I Random Forest (RF) classifier trained with features and labels.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 13 / 28</p>
  </div>
  <div class="page">
    <p>Forecast Methodology</p>
    <p>Primary features: raw data</p>
    <p>Mismanagement symptoms (5).</p>
    <p>I Five symptoms; each measures a fraction</p>
    <p>I Predictive power of these symptoms.</p>
    <p>% Untrusted HTTPS</p>
    <p>C D</p>
    <p>F</p>
    <p>Victim org. Nonvictim org.</p>
    <p>% openresolver C</p>
    <p>D F</p>
    <p>Victim org. Nonvictim org.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 14 / 28</p>
  </div>
  <div class="page">
    <p>Forecast Methodology</p>
    <p>Malicious activity time series (60  3). I Three time series over a period: spam, phishing, scan.</p>
    <p>I Recent 60 v.s. Recent 14.</p>
    <p>Days 10 20 30 40 50 60</p>
    <p>Days 10 20 30 40 50 60</p>
    <p>Days</p>
    <p>Size: number of IPs in an aggregation unit (1)</p>
    <p>I To some extent capture the likelihood of an organization becoming a target of/reproting intentional attacks.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 15 / 28</p>
  </div>
  <div class="page">
    <p>Forecast Methodology</p>
    <p>Malicious activity time series (60  3). I Three time series over a period: spam, phishing, scan.</p>
    <p>I Recent 60 v.s. Recent 14.</p>
    <p>Days 10 20 30 40 50 60</p>
    <p>Days 10 20 30 40 50 60</p>
    <p>Days</p>
    <p>Size: number of IPs in an aggregation unit (1)</p>
    <p>I To some extent capture the likelihood of an organization becoming a target of/reproting intentional attacks.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 15 / 28</p>
  </div>
  <div class="page">
    <p>Forecast Methodology</p>
    <p>Secondary features</p>
    <p>Quantization and feature extraction</p>
    <p>Days</p>
    <p># o</p>
    <p>f IP</p>
    <p>s lis</p>
    <p>te d</p>
    <p>Persistency</p>
    <p>I Measure security efforts and responsiveness.</p>
    <p>I In each quantized region, measure average magnitude, average duration, and frequency.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 16 / 28</p>
  </div>
  <div class="page">
    <p>Forecast Methodology</p>
    <p>A look at their predictive power (using data from Nov-Dec13):</p>
    <p>Unnormalized &quot;bad&quot; magnitude</p>
    <p>C D</p>
    <p>F</p>
    <p>Victim org. Nonvictim org.</p>
    <p>Normalized &quot;good&quot; magnitude</p>
    <p>C D</p>
    <p>F</p>
    <p>Victim org. Nonvictim org.</p>
    <p>&quot;Bad&quot; duration</p>
    <p>C D</p>
    <p>F</p>
    <p>Victim org. Nonvictim org.</p>
    <p>&quot;Bad&quot; frequency</p>
    <p>C D</p>
    <p>F</p>
    <p>Victim org. Nonvictim org.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 17 / 28</p>
  </div>
  <div class="page">
    <p>Forecast Overview of method</p>
    <p>Training subjects</p>
    <p>A subset victim organizations, Group(1) or incident group.</p>
    <p>I Training-testing ratio, e.g., 70-30 or 50-50 split .</p>
    <p>I Split strictly according to time: use past to predict future.</p>
    <p>Hackmageddon VCDB WHID</p>
    <p>Training Oct 13  Dec 13 Aug 13  Dec 13 Jan 14  Mar 14 Testing Jan 14  Feb 14 Jan 14  Dec 14 Apr 14  Nov 14</p>
    <p>A random subset of non-victims, Group (0) or non-incident group.</p>
    <p>I Random sub-sampling necessary to avoid imbalance; procedure is repeated over different random subsets.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 18 / 28</p>
  </div>
  <div class="page">
    <p>Forecast Overview of method</p>
    <p>Training subjects</p>
    <p>A subset victim organizations, Group(1) or incident group.</p>
    <p>I Training-testing ratio, e.g., 70-30 or 50-50 split .</p>
    <p>I Split strictly according to time: use past to predict future.</p>
    <p>Hackmageddon VCDB WHID</p>
    <p>Training Oct 13  Dec 13 Aug 13  Dec 13 Jan 14  Mar 14 Testing Jan 14  Feb 14 Jan 14  Dec 14 Apr 14  Nov 14</p>
    <p>A random subset of non-victims, Group (0) or non-incident group.</p>
    <p>I Random sub-sampling necessary to avoid imbalance; procedure is repeated over different random subsets.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 18 / 28</p>
  </div>
  <div class="page">
    <p>Results</p>
    <p>Outline of the talk</p>
    <p>I Data and Preliminaries</p>
    <p>- Description of the data - Data pre-processing</p>
    <p>I Forecasting methods</p>
    <p>- Construction of the predictor</p>
    <p>I Forecasting results</p>
    <p>- Main prediction results &amp; analysis</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 19 / 28</p>
  </div>
  <div class="page">
    <p>Results Main results</p>
    <p>Prediction procedure</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 20 / 28</p>
  </div>
  <div class="page">
    <p>Results Main results</p>
    <p>Prediction procedure</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 20 / 28</p>
  </div>
  <div class="page">
    <p>Results Main results</p>
    <p>Prediction procedure</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 20 / 28</p>
  </div>
  <div class="page">
    <p>Results Main results</p>
    <p>Prediction performance</p>
    <p>False positive</p>
    <p>T ru</p>
    <p>e p</p>
    <p>o si</p>
    <p>tiv e</p>
    <p>VCDB Hackmageddon WHID ALL</p>
    <p>Example of desirable operating points of the classifier:</p>
    <p>Accuracy Hackmageddon VCDB WHID All</p>
    <p>True Positive (TP) 96% 88% 80% 88% False Positive (FP) 10% 10% 5% 4% Overall Accuracy 90% 90% 95% 96%</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 21 / 28</p>
  </div>
  <div class="page">
    <p>Results Other observations</p>
    <p>Split ratio</p>
    <p>False positive</p>
    <p>T ru</p>
    <p>e p</p>
    <p>o s it iv</p>
    <p>e</p>
    <p>VCDB: 5050 &amp; Short</p>
    <p>VCDB: 7030 &amp; Short</p>
    <p>More training data better performance.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 22 / 28</p>
  </div>
  <div class="page">
    <p>Results Other observations</p>
    <p>Long term prediction</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 23 / 28</p>
  </div>
  <div class="page">
    <p>Results Other observations</p>
    <p>Short term v.s. long term prediction</p>
    <p>False positive</p>
    <p>T ru</p>
    <p>e p</p>
    <p>o s it iv</p>
    <p>e</p>
    <p>VCDB: 5050 &amp; Short</p>
    <p>VCDB: 5050 &amp; Long</p>
    <p>Temporal features become outdated.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 24 / 28</p>
  </div>
  <div class="page">
    <p>Results Other observations</p>
    <p>Importance of the Features</p>
    <p>Top feature descriptor Value</p>
    <p>Untrusted HTTPS Certificates 0.1531 Frequency 0.1089 Organization size 0.0976 Open recursive resolver 0.0928</p>
    <p>I Two mismgmt features rank in top 4.</p>
    <p>Feature category Normalized importance</p>
    <p>Mismanagement 0.3229 Time series data 0.2994 Recent-60 secondary features 0.2602</p>
    <p>I Secondary features almost as important as time series data.</p>
    <p>I Dynamic features &gt; static features.</p>
    <p>I Separate data does NOT achieve comparable results.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 25 / 28</p>
  </div>
  <div class="page">
    <p>Results Other observations</p>
    <p>Importance of the Features</p>
    <p>Top feature descriptor Value</p>
    <p>Untrusted HTTPS Certificates 0.1531 Frequency 0.1089 Organization size 0.0976 Open recursive resolver 0.0928</p>
    <p>I Two mismgmt features rank in top 4.</p>
    <p>Feature category Normalized importance</p>
    <p>Mismanagement 0.3229 Time series data 0.2994 Recent-60 secondary features 0.2602</p>
    <p>I Secondary features almost as important as time series data.</p>
    <p>I Dynamic features &gt; static features.</p>
    <p>I Separate data does NOT achieve comparable results.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 25 / 28</p>
  </div>
  <div class="page">
    <p>Results Other observations</p>
    <p>Importance of the Features</p>
    <p>Top feature descriptor Value</p>
    <p>Untrusted HTTPS Certificates 0.1531 Frequency 0.1089 Organization size 0.0976 Open recursive resolver 0.0928</p>
    <p>I Two mismgmt features rank in top 4.</p>
    <p>Feature category Normalized importance</p>
    <p>Mismanagement 0.3229 Time series data 0.2994 Recent-60 secondary features 0.2602</p>
    <p>I Secondary features almost as important as time series data.</p>
    <p>I Dynamic features &gt; static features.</p>
    <p>I Separate data does NOT achieve comparable results.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 25 / 28</p>
  </div>
  <div class="page">
    <p>Results Other observations</p>
    <p>Importance of the Features</p>
    <p>Top feature descriptor Value</p>
    <p>Untrusted HTTPS Certificates 0.1531 Frequency 0.1089 Organization size 0.0976 Open recursive resolver 0.0928</p>
    <p>I Two mismgmt features rank in top 4.</p>
    <p>Feature category Normalized importance</p>
    <p>Mismanagement 0.3229 Time series data 0.2994 Recent-60 secondary features 0.2602</p>
    <p>I Secondary features almost as important as time series data.</p>
    <p>I Dynamic features &gt; static features.</p>
    <p>I Separate data does NOT achieve comparable results.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 25 / 28</p>
  </div>
  <div class="page">
    <p>Results Other observations</p>
    <p>Case study: Data Breaches of 2014</p>
    <p>Predictor output</p>
    <p>C D</p>
    <p>F</p>
    <p>Randomly selected nonvictim set VCDB victim set</p>
    <p>AXTEL 0.87</p>
    <p>Homedepot 0.85BJP Junagadh 0.77</p>
    <p>Threshold 0.85</p>
    <p>Threshold 0.85</p>
    <p>Target 0.84</p>
    <p>ACME 0.85 Sony picture 0.90 OnlineTech 0.92Ebay 0.88</p>
    <p>I High profile data breaches from 2014: Sony (0.9), Ebay (0.88), Homedepot (0.85), Target (0.84), OnlineTech/JP Morgan Chase (0.92)</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 26 / 28</p>
  </div>
  <div class="page">
    <p>Discussion Discussions</p>
    <p>Discussions</p>
    <p>Errors in the data.</p>
    <p>Robustness against advasarial data.</p>
    <p>Prediction by incident type. I O. Thonnard, L. Bilge, A. Kashyap, and M.Lee, Are You At Risk? Profiling</p>
    <p>Organizations and Individuals Subject to Targeted Attacks. Financial Cryptography and Data Security 2015.</p>
    <p>I A. Sarabi, P. Naghizadeh, Y. Liu and M. Liu, Prioritizing Security Spending: A Quantitative Analysis of Risk Distributions for Different Business Profiles, WEIS 2015.</p>
    <p>Quality of reported data. I Part of our data can be downladed here: http://grs.eecs.umich.edu.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 27 / 28</p>
  </div>
  <div class="page">
    <p>Discussion Discussions</p>
    <p>Discussions</p>
    <p>Errors in the data.</p>
    <p>Robustness against advasarial data.</p>
    <p>Prediction by incident type. I O. Thonnard, L. Bilge, A. Kashyap, and M.Lee, Are You At Risk? Profiling</p>
    <p>Organizations and Individuals Subject to Targeted Attacks. Financial Cryptography and Data Security 2015.</p>
    <p>I A. Sarabi, P. Naghizadeh, Y. Liu and M. Liu, Prioritizing Security Spending: A Quantitative Analysis of Risk Distributions for Different Business Profiles, WEIS 2015.</p>
    <p>Quality of reported data. I Part of our data can be downladed here: http://grs.eecs.umich.edu.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 27 / 28</p>
  </div>
  <div class="page">
    <p>Discussion Discussions</p>
    <p>Discussions</p>
    <p>Errors in the data.</p>
    <p>Robustness against advasarial data.</p>
    <p>Prediction by incident type. I O. Thonnard, L. Bilge, A. Kashyap, and M.Lee, Are You At Risk? Profiling</p>
    <p>Organizations and Individuals Subject to Targeted Attacks. Financial Cryptography and Data Security 2015.</p>
    <p>I A. Sarabi, P. Naghizadeh, Y. Liu and M. Liu, Prioritizing Security Spending: A Quantitative Analysis of Risk Distributions for Different Business Profiles, WEIS 2015.</p>
    <p>Quality of reported data. I Part of our data can be downladed here: http://grs.eecs.umich.edu.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 27 / 28</p>
  </div>
  <div class="page">
    <p>Discussion Discussions</p>
    <p>Discussions</p>
    <p>Errors in the data.</p>
    <p>Robustness against advasarial data.</p>
    <p>Prediction by incident type. I O. Thonnard, L. Bilge, A. Kashyap, and M.Lee, Are You At Risk? Profiling</p>
    <p>Organizations and Individuals Subject to Targeted Attacks. Financial Cryptography and Data Security 2015.</p>
    <p>I A. Sarabi, P. Naghizadeh, Y. Liu and M. Liu, Prioritizing Security Spending: A Quantitative Analysis of Risk Distributions for Different Business Profiles, WEIS 2015.</p>
    <p>Quality of reported data. I Part of our data can be downladed here: http://grs.eecs.umich.edu.</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 27 / 28</p>
  </div>
  <div class="page">
    <p>Discussion Discussions</p>
    <p>Q &amp; A</p>
    <p>Acknowledgement</p>
    <p>I We thank NSF and DHS for fundings.</p>
    <p>Project webpage (part of data being available)</p>
    <p>I http://grs.eecs.umich.edu</p>
    <p>I http://www.umich.edu/~youngliu</p>
    <p>Y.Liu (U. Michigan) Forecasting Cyber Security Incidents 28 / 28</p>
  </div>
</Presentation>
