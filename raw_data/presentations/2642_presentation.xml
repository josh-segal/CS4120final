<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>A C B i M A : A d v a n c e d C h i n e s e B i - C h a ra c t e r Wo r d M o r p h o l o g i c a l A n a l y ze r</p>
    <p>T i n g - H a o ( K e n n e t h ) H u a n g Yu n - N u n g ( V i v i a n ) C h e n</p>
    <p>L i n g p e n g K o n g</p>
    <p>H T T P : / / A C B I M A . O R G</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction</p>
    <p>Related Work</p>
    <p>Morphological Type Scheme</p>
    <p>Morphological Type Classification</p>
    <p>o Drived Word: Rule-Based Approach</p>
    <p>o Compond Word: ML Approach</p>
    <p>Experiments</p>
    <p>o ACBiMA Corpus 1.0</p>
    <p>o Experimental Results</p>
    <p>Conclusion &amp; Future Work</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction</p>
    <p>Related Work</p>
    <p>Morphological Type Scheme</p>
    <p>Morphological Type Classification</p>
    <p>o Drived Word: Rule-Based Approach</p>
    <p>o Compond Word: ML Approach</p>
    <p>Experiments</p>
    <p>o ACBiMA Corpus 1.0</p>
    <p>o Experimental Results</p>
    <p>Conclusion &amp; Future Work</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>NLP tasks usually focus on segmented words</p>
    <p>Morphology is how words are composed with morphemes</p>
    <p>Usages of Chinese morphological structures</p>
    <p>o Sentiment Analysis (Ku, 2009; Huang, 2009)</p>
    <p>o POS Tagging (Qiu, 2008)</p>
    <p>o Word Segmentation (Gao, 2005)</p>
    <p>o Parsing (Li, 2011; Li, 2012; Zhang, 2013)</p>
    <p>Challenge for Chinese morphology</p>
    <p>o Lack of complete theories</p>
    <p>o Lack of category schema</p>
    <p>o Lack of toolkits</p>
    <p>anti bacteria verb object</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction</p>
    <p>Related Work</p>
    <p>Morphological Type Scheme</p>
    <p>Morphological Type Classification</p>
    <p>o Drived Word: Rule-Based Approach</p>
    <p>o Compond Word: ML Approach</p>
    <p>Experiments</p>
    <p>o ACBiMA Corpus 1.0</p>
    <p>o Experimental Results</p>
    <p>Conclusion &amp; Future Work</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>Focus on longer unknown words</p>
    <p>o Tseng, 2002; Tseng, 2005; Lu, 2008; Qiu, 2008</p>
    <p>Focus on the functionality of morphemic characters</p>
    <p>o Bruno, 2010</p>
    <p>Focus on Chinese bi-character words</p>
    <p>o Huang, et al., 2010 (LREC)</p>
    <p>o 52% multi-character Chinese tokens are bi-character</p>
    <p>o analyze Chinese morphological types</p>
    <p>o developed a suite of classifiers for type prediction</p>
    <p>Issue: covers only a subset of Chinese content words and has limited scalability</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction</p>
    <p>Related Work</p>
    <p>Morphological Type Scheme</p>
    <p>Morphological Type Classification</p>
    <p>o Drived Word: Rule-Based Approach</p>
    <p>o Compond Word: ML Approach</p>
    <p>Experiments</p>
    <p>o ACBiMA Corpus 1.0</p>
    <p>o Experimental Results</p>
    <p>Conclusion &amp; Future Work</p>
  </div>
  <div class="page">
    <p>Morphological Type Scheme</p>
    <p>Chinese Bi-Char Content Word</p>
    <p>Single-Morpheme Word</p>
    <p>Synthetic Word</p>
    <p>Derived Word</p>
    <p>Compound Word</p>
    <p>dup, pfx, sfx, neg, ec</p>
    <p>a-head, conj, n-head, nsubj,</p>
    <p>v-head, vobj, vprt, els</p>
    <p>els</p>
  </div>
  <div class="page">
    <p>Derived Word</p>
  </div>
  <div class="page">
    <p>Compond Word</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction</p>
    <p>Related Work</p>
    <p>Morphological Type Scheme</p>
    <p>Morphological Type Classification</p>
    <p>o Drived Word: Rule-Based Approach</p>
    <p>o Compond Word: ML Approach</p>
    <p>Experiments</p>
    <p>o ACBiMA Corpus 1.0</p>
    <p>o Experimental Results</p>
    <p>Conclusion &amp; Future Work</p>
  </div>
  <div class="page">
    <p>Morphological Type Classification</p>
    <p>Assumption: Chinese morphological structures are independent</p>
    <p>from word-level contexts (Tseng, 2002; Li, 2011)</p>
    <p>Derived words</p>
    <p>o Rule-based approach</p>
    <p>Compound words</p>
    <p>o ML-based approach</p>
  </div>
  <div class="page">
    <p>Derived Word: Rule-Based</p>
    <p>Idea</p>
    <p>o a morphologically derived word can be recognized based on its formation</p>
    <p>Approach</p>
    <p>o pattern matching rules</p>
    <p>Evaluation</p>
    <p>o Data: Chinese Treebank 7.0</p>
    <p>o Result:</p>
    <p>o 2.9% of bi-char content words are annotated as derived words</p>
    <p>o Precision = 0.97</p>
    <p>Rule-based methods are able to effectively recognizing derived words.</p>
  </div>
  <div class="page">
    <p>Compond Word: ML-Based</p>
    <p>Idea</p>
    <p>o The characteristics of individual characters can help decide the type of compond words</p>
    <p>ML classification models</p>
    <p>o Nave Bayes o Random Forest o SVM</p>
  </div>
  <div class="page">
    <p>Classification Feature</p>
    <p>o Dict: Revised Mandarin Chinese Dictionary (MoE, 1994)</p>
    <p>o CTB: Chinese Treebank 5.1 (Xue et al., 2005)</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction</p>
    <p>Related Work</p>
    <p>Morphological Type Scheme</p>
    <p>Morphological Type Classification</p>
    <p>o Drived Word: Rule-Based Approach</p>
    <p>o Compond Word: ML Approach</p>
    <p>Experiments</p>
    <p>o ACBiMA Corpus 1.0</p>
    <p>o Experimental Results</p>
    <p>Conclusion &amp; Future Work</p>
  </div>
  <div class="page">
    <p>ACBiMA Corpus 1.0</p>
    <p>Initial Set</p>
    <p>o 3,052 words</p>
    <p>o Extracted from CTB5</p>
    <p>o Annotated with difficulty level</p>
    <p>Whole Set</p>
    <p>o 11,366 words</p>
    <p>o Initial Set +</p>
  </div>
  <div class="page">
    <p>Baseline Models</p>
    <p>o Step 1: assign the POS tags to each known character based</p>
    <p>on different heuristics</p>
    <p>o Step 2: assign the most frequent morphological type</p>
    <p>obtained from training data to each POS combination, e.g.,</p>
    <p>(VV, NN) = vobj</p>
  </div>
  <div class="page">
    <p>Experimental Result</p>
    <p>o Setting: 10-fold cross-validation</p>
    <p>o Metrics: Macro F-measure (MF), Accuracy (ACC)</p>
    <p>Approach nsubj v</p>
    <p>head a</p>
    <p>head n</p>
    <p>head vprt vobj conj els MF ACC</p>
    <p>Majority 0 0 0 .507 0 0 0 0 .172 .340</p>
    <p>Stanford Dep. Map 0 0 0 .525 .351 .438 .213 .010 .332 .388</p>
    <p>Tabular</p>
    <p>Stanford 0 .296 0 .524 .389 .434 .162 .064 .349 .395</p>
    <p>CTB .021 .337 .009 .645 .397 .529 .421 .095 .479 .508</p>
    <p>Dict 0 .292 .060 .670 .253 .572 .484 .035 .495 .526</p>
    <p>Tablular approaches perform better among all baselines.</p>
  </div>
  <div class="page">
    <p>Experimental Result</p>
    <p>o Setting: 10-fold cross-validation</p>
    <p>o Metrics: Macro F-measure (MF), Accuracy (ACC)</p>
    <p>Approach nsubj v</p>
    <p>head a</p>
    <p>head n</p>
    <p>head vprt vobj conj els MF ACC</p>
    <p>Majority 0 0 0 .507 0 0 0 0 .172 .340</p>
    <p>Stanford Dep. Map 0 0 0 .525 .351 .438 .213 .010 .332 .388</p>
    <p>Tabular</p>
    <p>Stanford 0 .296 0 .524 .389 .434 .162 .064 .349 .395</p>
    <p>CTB .021 .337 .009 .645 .397 .529 .421 .095 .479 .508</p>
    <p>Dict 0 .292 .060 .670 .253 .572 .484 .035 .495 .526</p>
    <p>Nave Base .273 .406 .195 .523 .679 .566 .547 .188 .519 .518</p>
    <p>Random Forest .250 .421 .063 .760 .803 .643 .656 .076 .647 .674</p>
    <p>SVM .413 .541 .288 .748 .791 .657 .636 .271 .662 .665</p>
    <p>ML-based methods outperform all baselines, where SVM &amp; RF perform best.</p>
  </div>
  <div class="page">
    <p>Experimental Result</p>
    <p>o Setting: 10-fold cross-validation</p>
    <p>o Metrics: Macro F-measure (MF), Accuracy (ACC)</p>
    <p>Approach nsubj v</p>
    <p>head a</p>
    <p>head n</p>
    <p>head vprt vobj conj els MF ACC</p>
    <p>Majority 0 0 0 .507 0 0 0 0 .172 .340</p>
    <p>Stanford Dep. Map 0 0 0 .525 .351 .438 .213 .010 .332 .388</p>
    <p>Tabular</p>
    <p>Stanford 0 .296 0 .524 .389 .434 .162 .064 .349 .395</p>
    <p>CTB .021 .337 .009 .645 .397 .529 .421 .095 .479 .508</p>
    <p>Dict 0 .292 .060 .670 .253 .572 .484 .035 .495 .526</p>
    <p>Nave Base .273 .406 .195 .523 .679 .566 .547 .188 .519 .518</p>
    <p>Random Forest .250 .421 .063 .760 .803 .643 .656 .076 .647 .674</p>
    <p>SVM .413 .541 .288 .748 .791 .657 .636 .271 .662 .665</p>
    <p>Avg Difficulty 1.74 1.55 1.64 1.36 1.38 1.38 1.47 1.95 -</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction</p>
    <p>Related Work</p>
    <p>Morphological Type Scheme</p>
    <p>Morphological Type Classification</p>
    <p>o Drived Word: Rule-Based Approach</p>
    <p>o Compond Word: ML Approach</p>
    <p>Experiments</p>
    <p>o ACBiMA Corpus 1.0</p>
    <p>o Experimental Results</p>
    <p>Conclusion &amp; Future Work</p>
  </div>
  <div class="page">
    <p>Conclusion &amp; Future Work</p>
    <p>Contribution</p>
    <p>o Linguistic</p>
    <p>Propose a morphological type scheme</p>
    <p>Develop a corpus containing about 11K words</p>
    <p>o Technical</p>
    <p>Develop an effective morphological classifier</p>
    <p>o Practical</p>
    <p>Data and tool available</p>
    <p>Additional features for any Chinese task</p>
    <p>Future</p>
    <p>o Improve other NLP tasks by using ACBiMA</p>
  </div>
  <div class="page">
    <p>Q &amp; A</p>
    <p>Thanks for your attentions!!</p>
    <p>HTTP://ACBIMA.ORG</p>
  </div>
</Presentation>
