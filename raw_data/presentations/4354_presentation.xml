<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Babble Labble: Training Classifiers with Natural</p>
    <p>Language Explanations</p>
    <p>Braden Hancock, Paroma Varma, Stephanie Wang, Martin Bringmann, Percy Liang, Chris R</p>
    <p>ACL 17 July 2018</p>
    <p>Melbourne, Australia</p>
  </div>
  <div class="page">
    <p>Machine learning can help you!***</p>
    <p>***If you have enough training data</p>
  </div>
  <div class="page">
    <p>Traditional Labeling</p>
    <p>Tom Brady was spotted in New York City on Monday with his wife Gisele Bndchen amid rumors of Bradys alleged role in Deflategate.</p>
    <p>Example</p>
    <p>Label Is person 1 married to person 2?</p>
    <p>Reading/Understanding</p>
    <p>Time Spent</p>
    <p>Y N</p>
    <p>Clicking Y/N</p>
  </div>
  <div class="page">
    <p>Explanation</p>
    <p>Because the words his wife are right before person 2.</p>
    <p>Why do you think so?</p>
    <p>Tom Brady was spotted in New York City on Monday with his wife Gisele Bndchen amid rumors of Bradys alleged role in Deflategate.</p>
    <p>Example</p>
    <p>Label Is person 1 married to person 2?</p>
    <p>Higher Bandwidth Supervision</p>
    <p>Y N</p>
  </div>
  <div class="page">
    <p>Explanations Encode Labeling Heuristics</p>
    <p>Explanation</p>
    <p>Because the words his wife are right before person 2.</p>
    <p>Why did you label True?</p>
    <p>Barack batted back tears as he thanked his wife, Michelle, for all her help. Both Bill and his wife Hillary smiled and waved at reporters as they rode by. George attended the event with his wife, Laura, and their two daughters.</p>
    <p>True</p>
    <p>True</p>
    <p>True</p>
    <p>Label Example</p>
    <p>Big Idea: Instead of collecting labels, collect labeling heuristics (in the form of explanations) that can be used to label more examples for free.</p>
  </div>
  <div class="page">
    <p>A framework for generating large training sets from natural language explanations and</p>
    <p>unlabeled data</p>
    <p>Result: classifiers trained with Babble Labble and explanations achieved the same F1 score as ones trained with traditional labels while requiring 5100x fewer user inputs</p>
  </div>
  <div class="page">
    <p>Babble Labble Framework</p>
    <p>SEMANTIC PARSER</p>
    <p>False,because</p>
    <p>e1</p>
    <p>e2 e3</p>
    <p>UNLABELED EXAMPLES</p>
    <p>EXPLANATIONS</p>
    <p>x1 x2 x3</p>
    <p>True,because</p>
    <p>True,because</p>
  </div>
  <div class="page">
    <p>Explanations Encode Heuristics</p>
    <p>Explanation</p>
    <p>Because the words his wife are right before person 2.</p>
    <p>Why did you label True?</p>
    <p>Labeling Function def f(x):</p>
    <p>return 1 if (his wife in left(x.person2, dist==1)) else 0 #abstain</p>
  </div>
  <div class="page">
    <p>Semantic Parser</p>
    <p>&lt;START&gt; label false because X and Y are the same person &lt;STOP&gt;</p>
    <p>START LABEL FALSE BECAUSE ARG AND ARG IS EQUAL STOP</p>
    <p>BOOL ARGLIST ISEQUAL</p>
    <p>CONDITION</p>
    <p>LF</p>
    <p>def LF(x): return [label] if [condition] else [abstain]</p>
    <p>Labeling Function Template:</p>
    <p>Lexical Rules Unary Rules Compositional Rules</p>
    <p>&lt;START&gt; label false</p>
    <p>START  LABEL  FALSE</p>
    <p>FALSE TRUE INT</p>
    <p>BOOL  BOOL  NUM</p>
    <p>LF  CONDITION  ARGLIST</p>
    <p>START LABEL BOOL BECAUSE CONDITION STOP ARGLIST ISEQUAL ARG AND ARG</p>
    <p>Ignored token</p>
  </div>
  <div class="page">
    <p>Predicates</p>
    <p>Logic &amp; Comparison</p>
    <p>String Matching</p>
    <p>NER Tags</p>
    <p>Sets &amp; Mapping</p>
    <p>Relative Positioning</p>
  </div>
  <div class="page">
    <p>Semantic Parser I/O</p>
    <p>True, because Typical</p>
    <p>Semantic Parser</p>
    <p>Our Semantic</p>
    <p>Parser</p>
    <p>def f(x): return 1 if</p>
    <p>True, because def f(x): return 1 if</p>
    <p>def f(x): return 1 if</p>
    <p>def f(x): return 1 if</p>
    <p>Goal: produce the correct parse</p>
    <p>Goal: produce useful parses (whether theyre correct or not)</p>
  </div>
  <div class="page">
    <p>Babble Labble Framework</p>
    <p>SEMANTIC PARSER FILTER BANK</p>
    <p>False,because</p>
    <p>e1</p>
    <p>e2 e3</p>
    <p>UNLABELED EXAMPLES</p>
    <p>EXPLANATIONS</p>
    <p>SEMANTIC</p>
    <p>PRAGMATIC</p>
    <p>x1 x2 x3</p>
    <p>True,because</p>
    <p>True,because</p>
  </div>
  <div class="page">
    <p>Filter Bank</p>
    <p>False, because</p>
    <p>True, because</p>
    <p>True, because</p>
    <p>Explanations Labeling Functions (Filtered)</p>
    <p>Labeling Functions</p>
    <p>Semantic Parser</p>
    <p>def f(x): return 1 if</p>
    <p>def f(x): return 1 if</p>
    <p>def f(x): return 1 if</p>
    <p>def f(x): return 1 if</p>
    <p>def f(x): return 1 if</p>
    <p>def f(x): return 1 if</p>
    <p>Filter Bank</p>
    <p>def f(x): return 1 if</p>
    <p>def f(x): return 1 if</p>
    <p>def f(x): return 1 if</p>
    <p>Semantic Filter</p>
    <p>Pragmatic Filter</p>
  </div>
  <div class="page">
    <p>Semantic Filter</p>
    <p>Tom Brady was spotted in New York City on Monday with his wife Gisele Bndchen amid rumors of Bradys alleged role in Deflategate.</p>
    <p>True, because the words his wife are right before person 2.</p>
    <p>def LF_1a(x): return (1 if his wife in left(x.person2, dist==1) else 0)</p>
    <p>def LF_1b(x): return (1 if his wife in right(x.person2) else 0</p>
    <p>Explanation</p>
    <p>LF_1a(x1) == 1</p>
    <p>(his wife is, in fact, 1 word to the left of person 2)</p>
    <p>LF_1b(x1) == 0</p>
    <p>(his wife is not to the right of person 2)</p>
    <p>right before = immediately beforeright before = to the right of</p>
    <p>x1: Example</p>
    <p>Candidate Labeling Functions</p>
  </div>
  <div class="page">
    <p>Pragmatic Filters</p>
    <p>LF1:</p>
    <p>LF2A: LF2B:</p>
    <p>x1 xNUniform labeling signature</p>
    <p>How does the LF label our unlabeled data?</p>
    <p>Duplicate labeling signature</p>
  </div>
  <div class="page">
    <p>Babble Labble Framework</p>
    <p>SEMANTIC PARSER FILTER BANK LABEL AGGREGATOR</p>
    <p>False,because</p>
    <p>e1</p>
    <p>e2 e3</p>
    <p>UNLABELED EXAMPLES</p>
    <p>EXPLANATIONS</p>
    <p>SEMANTIC</p>
    <p>PRAGMATIC</p>
    <p>x1 x2 x3</p>
    <p>True,because</p>
    <p>True,because y</p>
  </div>
  <div class="page">
    <p>Label Aggregator</p>
    <p>LF 1: LF 2: LF 3: LF 4: LF 5:</p>
    <p>y: ? ? ? ? ? ? ? ? ?</p>
    <p>x1 x9x2 x3 x4 x5 x6 x7 x8</p>
    <p>Input:</p>
    <p>Output:</p>
    <p>(x1,1) (x2,2) (x3,3) (x4,4)</p>
    <p>Training Data</p>
    <p>Positive</p>
    <p>Negative</p>
    <p>Abstain</p>
  </div>
  <div class="page">
    <p>Label Aggregator</p>
    <p>LF 1: LF 2: LF 3: LF 4: LF 5:</p>
    <p>y: ? ? ? ? ? ? ? ? ?</p>
    <p>x1 x9x2 x3 x4 x5 x6 x7 x8</p>
    <p>Input:</p>
    <p>Output:</p>
    <p>High correlation; not independent?</p>
    <p>High conflict; low accuracy?</p>
    <p>Low coverage, high accuracy?</p>
    <p>How should I break this tie?</p>
    <p>Data Programming: (Ratner, et al. NIPS 2016)</p>
    <p>As implemented in: snorkel.stanford.edu</p>
  </div>
  <div class="page">
    <p>Babble Labble Framework</p>
    <p>SEMANTIC PARSER FILTER BANK LABEL AGGREGATOR DISC. MODEL</p>
    <p>False,because</p>
    <p>e1</p>
    <p>e2 e3</p>
    <p>UNLABELED EXAMPLES</p>
    <p>EXPLANATIONS</p>
    <p>SEMANTIC</p>
    <p>PRAGMATIC</p>
    <p>x1 x2 x3</p>
    <p>True,because</p>
    <p>True,because x yy</p>
  </div>
  <div class="page">
    <p>Discriminative Classifier</p>
    <p>Input: Labeling Functions, Unlabeled data</p>
    <p>Labeling functions generate noisy,</p>
    <p>conflicting votes</p>
    <p>Label Aggregator</p>
    <p>Resolve conflicts, re-weight &amp;</p>
    <p>combine</p>
    <p>Discriminative Model</p>
    <p>Generalize beyond the labeling</p>
    <p>functions</p>
  </div>
  <div class="page">
    <p>Generalization</p>
    <p>Task: identify disease-causing chemicals</p>
    <p>Keywords mentioned in LFs:</p>
    <p>treats, causes, induces, prevents,</p>
    <p>Highly relevant features learned by discriminative model:</p>
    <p>could produce a, support diagnosis of,</p>
    <p>Training a discriminative model that can take advantage of additional useful features not</p>
    <p>specified in labeling functions boosted performance by 4.3 F1 points on average (10%).</p>
  </div>
  <div class="page">
    <p>Datasets</p>
    <p>Name # Unlabeled Sample Explanations</p>
    <p>Spouse 22k Label true because &quot;and&quot; occurs between X and Y and &quot;marriage&quot; occurs one word after person1.</p>
    <p>Disease 6.7k Label true because the disease is immediately after the chemical and &quot;induc&quot; or &quot;assoc&quot; is in the chemical name.</p>
    <p>Protein 5.5k Label true because &quot;Ser&quot; or &quot;Tyr&quot; are within 10 characters of the protein.</p>
  </div>
  <div class="page">
    <p>Results</p>
    <p>Task F1 Score</p>
    <p>Babble Labble # Explanations</p>
    <p>Traditional Labels # Labels</p>
    <p>Reduction in User Inputs</p>
    <p>Spouse 50.1 30 3000+ 100x Disease 42.3 30 1000+ 33x Protein 47.3 30 150+ 5x</p>
    <p>Classifiers trained with Babble Labble and explanations achieved the same F1 score as ones trained with traditional labels while requiring 5100x fewer user inputs</p>
  </div>
  <div class="page">
    <p>Utilizing Unlabeled Data</p>
    <p>With labeling functions, training set size (and often performance) scales with the amount of unlabeled data we have.</p>
  </div>
  <div class="page">
    <p>Filter Bank Effectiveness</p>
    <p>Task Babble Labble (No Filters)</p>
    <p>Babble Labble % Incorrected Parses Filtered</p>
    <p>Spouse 15.7 50.1 97.8% Disease 39.8 42.3 96.0% Protein 38.2 47.3 97.0% AVERAGE 31.2 46.6 96.9%</p>
    <p>The filters removed almost 97% of incorrect parses. Without the filters removing bad parses, F1 drops by 15 F1 points on average.</p>
  </div>
  <div class="page">
    <p>Perfect Parsers Need Not Apply</p>
    <p>Task Babble Labble Babble Labble (Perfect Parses)</p>
    <p>Spouse 50.1 49.8 Disease 42.3 43.2 Protein 47.3 46.8 AVERAGE 46.6 46.8</p>
    <p>Using perfect parses yielded negligible improvements. In this framework, for this task, a nave semantic parser is good enough!</p>
  </div>
  <div class="page">
    <p>Limitations</p>
    <p>Do you think person 1 is the spouse of person 2? Why?</p>
    <p>No, because it sounds like theyre just co-workers.</p>
    <p>Whats a co-worker?</p>
    <p>Alice beat Bob in the annual office pool tournament.</p>
    <p>Prefers High-level</p>
    <p>(e.g., it says so)</p>
    <p>Prefers Low-level</p>
    <p>(e.g., keywords, word distance,</p>
    <p>capitalization, etc.)</p>
    <p>Users reasons for labeling are sometimes high-level concepts that are hard to parse.</p>
  </div>
  <div class="page">
    <p>Related Work: Data Programming</p>
    <p>Snorkel (Ratner et al., VLDB 2018)  Flagship platform for dataset creation from weak supervision</p>
    <p>Structure Learning (Bach et al., ICML 2017)  Learning dependencies between correlated labeling functions</p>
    <p>Reef (Varma and R, In Submission)  Auto-generating labeling functions from a small labeled set</p>
    <p>snorkel.stanford.edu</p>
    <p>Common theme: Use weak supervision (e.g., labeling functions) to generate training sets</p>
  </div>
  <div class="page">
    <p>Related Work: Explanations as Features (Srivastava et al., 2017) What if we use our explanations to make features instead of training labels?</p>
    <p>Exp 1:</p>
    <p>Exp 2:</p>
    <p>Exp 3:</p>
    <p>Exp 4:</p>
    <p>Exp 5:</p>
    <p>x1 x9x2 x3 x4 x5 x6 x7 x8</p>
    <p>LABEL AGGREGATOR DISC. MODEL</p>
    <p>x yy</p>
    <p>DISC. MODEL</p>
    <p>x y</p>
    <p>Use as features for</p>
    <p>classifier</p>
    <p>Use as labels for training set</p>
    <p>Using the parses to label training data instead of as features boosts 4.5 F1 points.</p>
  </div>
  <div class="page">
    <p>Related Work: Highlighting</p>
    <p>Highlight key phrases in text: (Zaidan and Eisner, 2008), (Arora and Nyberg, 2009)</p>
    <p>Mark key regions in images: (Ahn et al., 2006)</p>
    <p>Label key features directly: (Druck et al., 2009), (Raghavan et al., 2005), (Liang et al., 2009)</p>
    <p>Tom Brady was spotted in New York City on Monday with his wife Gisele Bndchen amid rumors of Bradys alleged role in Deflategate.</p>
    <p>Benefits of natural language approach:  more options: e.g., X is not in the sentence, X or Y is in the sentence  more direct credit assignment (compared to highlighting)  no feature set required a priori</p>
  </div>
  <div class="page">
    <p>Summary We need more efficient ways to collect supervision</p>
    <p>We can collect labeling heuristics instead of labels</p>
    <p>https://github.com/HazyResearch/babble</p>
    <p>Using this approach, training set size grows with the amount of unlabeled data we have</p>
  </div>
  <div class="page">
    <p>EXTRA SLIDES</p>
  </div>
  <div class="page">
    <p>Dataset Statistics</p>
  </div>
  <div class="page">
    <p>Babble Labble Framework</p>
    <p>Tom Brady and his wife Gisele Bndchen were</p>
    <p>spotted in New York City on Monday amid rumors</p>
    <p>of Bradys alleged role in Deflategate.</p>
    <p>True, because the words his wife are right before person 2.</p>
    <p>def LF_1a(x): return (1 if his wife in left(x.person2, dist==1) else 0)</p>
    <p>def LF_1b(x): return (1 if his wife in right(x.person2) else 0</p>
    <p>Correct</p>
    <p>Semantic Filter</p>
    <p>(inconsistent)</p>
    <p>Unlabeled Examples + Explanations Label whether person 1 is married to person 2</p>
    <p>Labeling Functions Filters Label Matrix</p>
    <p>None of us knows what happened at Kanes</p>
    <p>home Aug. 2, but it is telling that the NHL has not</p>
    <p>suspended Kane.</p>
    <p>False, because person 1 and person 2 in the sentence are identical.</p>
    <p>Dr. Michael Richards and real estate and</p>
    <p>insurance businessman Gary Kirke did not attend</p>
    <p>the event.</p>
    <p>False, because the last word of person 1 is different than the last word of person 2.</p>
    <p>x1</p>
    <p>x2</p>
    <p>x3 def LF_3a(x): return (-1 if x.person1.tokens[-1] != x.person2.tokens[-1] else 0)</p>
    <p>Correct</p>
    <p>Pragmatic Filter</p>
    <p>(duplicate of LF_3a)</p>
    <p>def LF_2b(x): return (-1 if x.person1 == x.person2) else 0)</p>
    <p>Correct</p>
    <p>def LF_3b(x): return (-1 if not ( x.person1.tokens[-1] == x.person2.tokens[-1]) else 0)</p>
    <p>def LF_2a(x): return (-1 if x.person1 in x.sentence and x.person2 in x.sentence else 0)</p>
    <p>Pragmatic Filter</p>
    <p>(always true)</p>
    <p>x1 x2 x3</p>
    <p>LF1a LF2b</p>
    <p>LF3a</p>
    <p>-1</p>
    <p>-1-1</p>
    <p>x4</p>
    <p>LF4c</p>
    <p>+</p>
    <p>-+</p>
    <p>Noisy Labels</p>
    <p>(x1,1) (x2,2) (x3,3) (x4,4)</p>
    <p>Classifier</p>
    <p>x</p>
  </div>
  <div class="page">
    <p>Babble Labble Framework</p>
    <p>INPUT SEMANTIC PARSER FILTER BANK LABEL AGGREGATOR DISC. MODEL</p>
    <p>False,because</p>
    <p>e1</p>
    <p>e2 e3</p>
    <p>UNLABELED EXAMPLES</p>
    <p>EXPLANATIONS</p>
    <p>SEMANTIC</p>
    <p>PRAGMATIC</p>
    <p>LF1A</p>
    <p>LF1B</p>
    <p>LF3A</p>
    <p>LABELING FUNCTIONS PROBABILISTIC LABELS</p>
    <p>LF1B</p>
    <p>LF3A</p>
    <p>x1 x2 x3</p>
    <p>LABEL MATRIX</p>
    <p>x1 x2</p>
    <p>x3</p>
    <p>True,because</p>
    <p>True,because</p>
    <p>+ - +y</p>
    <p>TRAINED MODEL</p>
    <p>x yy</p>
    <p>x1 x2 x3</p>
    <p>IMPORTANT: No Babble Labble components require no labeled training data!</p>
  </div>
  <div class="page">
    <p>Babble Labble</p>
    <p>Explanation</p>
    <p>Because the words his wife are right before person 2.</p>
    <p>Why do you think so?</p>
    <p>Labeling Function def LF1(x): return (1 if his wife in left(x.person2, dist==1)</p>
    <p>else 0)</p>
    <p>Tom Brady was spotted in New York City on Monday with his wife Gisele Bndchen amid rumors of Bradys alleged role in Deflategate.</p>
    <p>Example</p>
    <p>Label Is person 1 married to person 2?</p>
    <p>Y N</p>
    <p>Label Matrix x1 x2 x3</p>
    <p>LF1 LF2 LF3</p>
    <p>-1</p>
    <p>-1-1</p>
    <p>x4</p>
    <p>LF4</p>
    <p>+</p>
    <p>-+ Aggregated Labels</p>
    <p>(x1,1) (x2,2) (x3,3) (x4,4)</p>
    <p>Classifier</p>
    <p>x</p>
  </div>
</Presentation>
