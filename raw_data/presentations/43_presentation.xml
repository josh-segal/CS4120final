<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Payment Rules for Combinatorial Auctions via Structural Support Vector Machines</p>
    <p>Felix Fischer Harvard University</p>
    <p>joint work with Paul Dtting (EPFL), Petch Jirapinyo (Harvard), John Lai (Harvard), Ben Lubin (BU), and David C. Parkes (Harvard)</p>
    <p>September 7, 2011</p>
  </div>
  <div class="page">
    <p>Combinatorial Auctions</p>
    <p>I n agents I m items I Bundles Y = {0, 1}m</p>
    <p>I Valuation profiles X = R2 mn</p>
    <p>I Allocation rule gi : X  Y I Payment rule ti : X  Y R</p>
    <p>I Optimal allocation: maximize</p>
    <p>i xi [yi ] such that yi  yj =  I Strategyproofness:</p>
    <p>xi [gi (x)]  ti (x, gi (x))  xi [gi (x  i , xi )]  ti (x</p>
    <p>i , xi, gi (x</p>
    <p>i , x1))</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 2</p>
  </div>
  <div class="page">
    <p>Combinatorial Auctions</p>
    <p>I n agents I m items I Bundles Y = {0, 1}m</p>
    <p>I Valuation profiles X = R2 mn</p>
    <p>I Allocation rule gi : X  Y I Payment rule ti : X  Y R</p>
    <p>I Optimal allocation: maximize</p>
    <p>i xi [yi ] such that yi  yj =  I Strategyproofness:</p>
    <p>xi [gi (x)]  ti (x, gi (x))  xi [gi (x  i , xi )]  ti (x</p>
    <p>i , xi, gi (x</p>
    <p>i , x1))</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 2</p>
  </div>
  <div class="page">
    <p>Problem Statement</p>
    <p>I Elicitation of valuations and computation of optimal allocation are costly, often prohibitively so</p>
    <p>I Canonical strategyproof mechanism: VCG I depends on ability to find efficient allocation I other problems: collusion, small or non-monotonic revenue</p>
    <p>I Alternative solutions hard to come by</p>
    <p>I Our approach: take allocation rule g as given, use to generate input for a learning algorithm</p>
    <p>I Implicitly learns payment rule t that makes g maximally incentive compatible (we will see in what sense)</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 3</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Combinatorial Auctions and Margin-Based Learning</p>
    <p>Learning a Payment Rule</p>
    <p>Summary and Open Problems</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 4</p>
  </div>
  <div class="page">
    <p>CAs and Margin-Based Learning Learning a Payment Rule Conclusion</p>
    <p>Learning What We Already Know</p>
    <p>I By symmetry concentrate on agent 1, consider g = g1 and t = t1 I Assume g is given, as well as a distribution P(X ) on X I Together they induce a distribution P(X, Y ) on X  Y</p>
    <p>I Sample set of training examples from P(X, Y ) and learn an allocation function h : X  Y</p>
    <p>I We know g, so we are not actually interested in h I Rather: employ a margin-based learning method, infer t from</p>
    <p>the margin</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 5</p>
  </div>
  <div class="page">
    <p>CAs and Margin-Based Learning Learning a Payment Rule Conclusion</p>
    <p>Learning What We Already Know</p>
    <p>I By symmetry concentrate on agent 1, consider g = g1 and t = t1 I Assume g is given, as well as a distribution P(X ) on X I Together they induce a distribution P(X, Y ) on X  Y</p>
    <p>I Sample set of training examples from P(X, Y ) and learn an allocation function h : X  Y</p>
    <p>I We know g, so we are not actually interested in h I Rather: employ a margin-based learning method, infer t from</p>
    <p>the margin</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 5</p>
  </div>
  <div class="page">
    <p>CAs and Margin-Based Learning Learning a Payment Rule Conclusion</p>
    <p>Learning How to Allocate</p>
    <p>I Single-item case corresponds to an ordinary binary classifier: allocate the item or not</p>
    <p>+ ++</p>
    <p>+</p>
    <p>I In general: one class for each bundle that could be allocated I Learn a discriminant function f : X  Y R that rates bundles I Define h to choose the most appropriate bundle:</p>
    <p>h(x) = arg max yY(x1)</p>
    <p>f (x, y)</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 6</p>
  </div>
  <div class="page">
    <p>CAs and Margin-Based Learning Learning a Payment Rule Conclusion</p>
    <p>Learning How to Allocate</p>
    <p>I Single-item case corresponds to an ordinary binary classifier: allocate the item or not</p>
    <p>+ ++</p>
    <p>+</p>
    <p>allocate dont allocate</p>
    <p>I In general: one class for each bundle that could be allocated I Learn a discriminant function f : X  Y R that rates bundles I Define h to choose the most appropriate bundle:</p>
    <p>h(x) = arg max yY(x1)</p>
    <p>f (x, y)</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 6</p>
  </div>
  <div class="page">
    <p>CAs and Margin-Based Learning Learning a Payment Rule Conclusion</p>
    <p>Learning How to Allocate</p>
    <p>I Single-item case corresponds to an ordinary binary classifier: allocate the item or not</p>
    <p>+ ++</p>
    <p>+</p>
    <p>allocate dont allocate</p>
    <p>I In general: one class for each bundle that could be allocated I Learn a discriminant function f : X  Y R that rates bundles I Define h to choose the most appropriate bundle:</p>
    <p>h(x) = arg max yY(x1)</p>
    <p>f (x, y)</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 6</p>
  </div>
  <div class="page">
    <p>CAs and Margin-Based Learning Learning a Payment Rule Conclusion</p>
    <p>Learning How to Allocate</p>
    <p>I Single-item case corresponds to an ordinary binary classifier: allocate the item or not</p>
    <p>+ ++</p>
    <p>+</p>
    <p>allocate dont allocate</p>
    <p>I In general: one class for each bundle that could be allocated I Learn a discriminant function f : X  Y R that rates bundles I Define h to choose the most appropriate bundle:</p>
    <p>h(x) = arg max yY(x1)</p>
    <p>f (x, y)</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 6</p>
  </div>
  <div class="page">
    <p>CAs and Margin-Based Learning Learning a Payment Rule Conclusion</p>
    <p>The Discriminant Function</p>
    <p>I Impose additional structure on f :</p>
    <p>fw(x, y) = w1x1[y] + w T 1(x1, y)</p>
    <p>I w = (w1, w1) RM+1 is a parameter vector to be learned I (x1, y) RM is a feature vector derived from x1 and y</p>
    <p>I Linear in RM , but can be very expressive in X</p>
    <p>+  +</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 7</p>
  </div>
  <div class="page">
    <p>CAs and Margin-Based Learning Learning a Payment Rule Conclusion</p>
    <p>The Discriminant Function</p>
    <p>I Impose additional structure on f :</p>
    <p>fw(x, y) = w1x1[y] + w T 1(x1, y)</p>
    <p>I w = (w1, w1) RM+1 is a parameter vector to be learned I (x1, y) RM is a feature vector derived from x1 and y</p>
    <p>I Linear in RM , but can be very expressive in X</p>
    <p>+  +</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 7</p>
  </div>
  <div class="page">
    <p>CAs and Margin-Based Learning Learning a Payment Rule Conclusion</p>
    <p>The Discriminant Function</p>
    <p>I Impose additional structure on f :</p>
    <p>fw(x, y) = w1x1[y] + w T 1(x1, y)</p>
    <p>I w = (w1, w1) RM+1 is a parameter vector to be learned I (x1, y) RM is a feature vector derived from x1 and y</p>
    <p>I Linear in RM , but can be very expressive in X</p>
    <p>+  +</p>
    <p>+</p>
    <p>+</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 7</p>
  </div>
  <div class="page">
    <p>CAs and Margin-Based Learning Learning a Payment Rule Conclusion</p>
    <p>The Discriminant Function</p>
    <p>I Impose additional structure on f :</p>
    <p>fw(x, y) = w1x1[y] + w T 1(x1, y)</p>
    <p>I w = (w1, w1) RM+1 is a parameter vector to be learned I (x1, y) RM is a feature vector derived from x1 and y</p>
    <p>I Linear in RM , but can be very expressive in X</p>
    <p>+  +</p>
    <p>+</p>
    <p>+</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 7</p>
  </div>
  <div class="page">
    <p>CAs and Margin-Based Learning Learning a Payment Rule Conclusion</p>
    <p>The Discriminant Function</p>
    <p>I Impose additional structure on f :</p>
    <p>fw(x, y) = w1x1[y] + w T 1(x1, y)</p>
    <p>I w = (w1, w1) RM+1 is a parameter vector to be learned I (x1, y) RM is a feature vector derived from x1 and y</p>
    <p>I Linear in RM , but can be very expressive in X</p>
    <p>+  +</p>
    <p>+</p>
    <p>+</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 7</p>
  </div>
  <div class="page">
    <p>CAs and Margin-Based Learning Learning a Payment Rule Conclusion</p>
    <p>The Payment Rule</p>
    <p>I Ensure w1 &gt; 0 and let</p>
    <p>tw(x, y) =  ( w1 w1</p>
    <p>)T (x1, y)</p>
    <p>I agent-independent I hw predicts the utility-maximizing bundle:</p>
    <p>hw(x) = arg max yY(x1)</p>
    <p>fw(x, y) = arg max yY(x1)</p>
    <p>w1x1[y] + w T 1(x1, y)</p>
    <p>= arg max yY(x1)</p>
    <p>w1x1[y] + w T 1</p>
    <p>(</p>
    <p>w1 w1</p>
    <p>tw(x, y) )</p>
    <p>= arg max yY(x1)</p>
    <p>(x1[y]  tw(x, y))</p>
    <p>I Can ensure by translation that wT 1(x1, 0) = 0, i.e., that</p>
    <p>payment for empty bundle is zero</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 8</p>
  </div>
  <div class="page">
    <p>CAs and Margin-Based Learning Learning a Payment Rule Conclusion</p>
    <p>Truthfulness and Regret</p>
    <p>I Looks like the characterization of a strategyproof mechanism, but hw might not be feasible</p>
    <p>I Also recall that we want to allocate according to g, not hw</p>
    <p>I Ex-post regret (for bidding truthfully): maximum gain in utility by bidding differently</p>
    <p>Lemma: The ex-post regret for bidding truthfully in (g, tw) is 1</p>
    <p>w1</p>
    <p>( maxyY(x1)fw(x, y</p>
    <p>)  fw(x, g(x)) ) .</p>
    <p>Theorem: If hw is exact, then (g, tw) is strategyproof.</p>
    <p>I But: hw will not always be exact, we know it cannot be if g is not monotonic</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 9</p>
  </div>
  <div class="page">
    <p>CAs and Margin-Based Learning Learning a Payment Rule Conclusion</p>
    <p>Truthfulness and Regret</p>
    <p>I Looks like the characterization of a strategyproof mechanism, but hw might not be feasible</p>
    <p>I Also recall that we want to allocate according to g, not hw</p>
    <p>I Ex-post regret (for bidding truthfully): maximum gain in utility by bidding differently</p>
    <p>Lemma: The ex-post regret for bidding truthfully in (g, tw) is 1</p>
    <p>w1</p>
    <p>( maxyY(x1)fw(x, y</p>
    <p>)  fw(x, g(x)) ) .</p>
    <p>Theorem: If hw is exact, then (g, tw) is strategyproof.</p>
    <p>I But: hw will not always be exact, we know it cannot be if g is not monotonic</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 9</p>
  </div>
  <div class="page">
    <p>CAs and Margin-Based Learning Learning a Payment Rule Conclusion</p>
    <p>Truthfulness and Regret</p>
    <p>I Looks like the characterization of a strategyproof mechanism, but hw might not be feasible</p>
    <p>I Also recall that we want to allocate according to g, not hw</p>
    <p>I Ex-post regret (for bidding truthfully): maximum gain in utility by bidding differently</p>
    <p>Lemma: The ex-post regret for bidding truthfully in (g, tw) is 1</p>
    <p>w1</p>
    <p>( maxyY(x1)fw(x, y</p>
    <p>)  fw(x, g(x)) ) .</p>
    <p>Theorem: If hw is exact, then (g, tw) is strategyproof.</p>
    <p>I But: hw will not always be exact, we know it cannot be if g is not monotonic</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 9</p>
  </div>
  <div class="page">
    <p>CAs and Margin-Based Learning Learning a Payment Rule Conclusion</p>
    <p>Regret and Generalization Error</p>
    <p>I Generalization error of a classifier hw H:</p>
    <p>RP (hw) =</p>
    <p>XY</p>
    <p>x(y, hw(x)) dP(x, y)</p>
    <p>where x(y, y) = 1</p>
    <p>w1 (fw(x, y)  fw(x, y))</p>
    <p>Theorem: If hw minimizes generalization error then tw minimizes expected ex-post regret for truthful bidding.</p>
    <p>I Amount a random agent can gain by lying when all others tell the truth, for valuations drawn from P(X )</p>
    <p>I Different from (approximate) ex-ante and ex-interim equilibrium, rather provides an upper bound on the expected ex-interim gain</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 10</p>
  </div>
  <div class="page">
    <p>CAs and Margin-Based Learning Learning a Payment Rule Conclusion</p>
    <p>Support Vector Machines?</p>
    <p>I Learn a discriminant function that maximizes the margin I Binary setting: minimize generalization error in the limit</p>
    <p>I Version with structured/multi-class output due to Joachims et al. I Training by solving a quadratic optimization problem with linear</p>
    <p>constraints, can be done efficiently under certain conditions</p>
    <p>I Training requires computation of inner products in the (high- or infinite-dimensional) feature space RM</p>
    <p>I Kernel trick: choose  carefully to ensure they can be computed efficiently from vectors in the original space</p>
    <p>I Linear classification in RM without any explicit calculations in RM</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 11</p>
  </div>
  <div class="page">
    <p>CAs and Margin-Based Learning Learning a Payment Rule Conclusion</p>
    <p>Summary</p>
    <p>I Design of payment rules using margin-based classifier, given oracle access to valuation distribution and allocation rule</p>
    <p>I Exact classifier yields strategyproof payment rule, minimization of error implies minimization of expected ex-post regret</p>
    <p>I Experiments for 5 items, 2 to 6 agents, 200 training examples I 5 items, 2 to 6 agents, 200 training examples I (x1, y) = ([x2 \ y, . . . , xn \ y]) I  corresponding to RBF kernel K (z, z) = exp(||z  z||/22)</p>
    <p>accuracy average regret IR violation single item 96% 0.2% 2% single-minded 90% 1% 6% multi-minded, complements 94% 0.1% 3% multi-minded, substitutes 75% 2% 15%</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 12</p>
  </div>
  <div class="page">
    <p>CAs and Margin-Based Learning Learning a Payment Rule Conclusion</p>
    <p>Open Problems</p>
    <p>I Possibly wT 1(x1, y)  x1[y], failure of individual rationality</p>
    <p>I tradeoff between individual rationality and strategyproofness I both at the same time (only?) by deviation from g, e.g., by</p>
    <p>discarding y and allocating  I Training problem has (|Y (x1)|) constraints, exponential in m in</p>
    <p>general I only polynomially many constraints matter, a separation</p>
    <p>oracle would suffice I when valuations can be represented succinctly, payment</p>
    <p>monotonicity would also suffice I more highly structured payment rules for restricted valuations</p>
    <p>I More clever feature maps, e.g., to allow for generalization across different numbers of agents</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 13</p>
  </div>
  <div class="page">
    <p>Thank you!</p>
    <p>Dtting, Fischer, Jirapinyo, Lai, Lubin, Parkes Payment Rules for Combinatorial Auctions via Structural Support Vector Machines 14</p>
  </div>
</Presentation>
