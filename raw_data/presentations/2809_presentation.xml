<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Qifan Pu Shivaram Venkataraman Ion Stoica</p>
    <p>Locus Shuffling Fast and Slow</p>
    <p>on Serverless Architecture</p>
  </div>
  <div class="page">
    <p>Serverless Computing</p>
  </div>
  <div class="page">
    <p>Serverless Analytics</p>
    <p>User function</p>
    <p>+</p>
    <p>Data</p>
    <p>i.e., Map()</p>
    <p>F()</p>
    <p>Results</p>
    <p>Launch short-lived cloud workers with transparent elasticity and fine-grain usage billing</p>
  </div>
  <div class="page">
    <p>Serverless Analytics So far, a great fit for embarrassingly parallel analytics</p>
    <p>ExCamera (NSDI17): video encoding</p>
    <p>PyWren (SoCC17): scaling python functions</p>
    <p>NumPyWren: large-block matrix computation</p>
    <p>Stanford gg compiler: distributed compiling</p>
    <p>AWS Redshift Spectrum: ETL</p>
  </div>
  <div class="page">
    <p>General Serverless Analtyics</p>
    <p>To enable general analytics, one needs to implement shuffle.</p>
    <p>- Key operation for join() and groupby()</p>
    <p>- 70+% of TPC-DS queries use shuffle</p>
    <p>- Most expensive operation in production clusters</p>
    <p>Query Results</p>
    <p>Shuffle Shuffle</p>
    <p>How to perform cost-efficient shuffle on a serverless architecture?</p>
  </div>
  <div class="page">
    <p>An Shuffle Example: Cloud Sort</p>
    <p>Lowest cost to sort 100TB of data  Record: Apache Spark, 50min / $144</p>
    <p>Partition Task</p>
    <p>Partition Task</p>
    <p>Partition Task</p>
    <p>merge task</p>
    <p>merge task</p>
    <p>merge task</p>
  </div>
  <div class="page">
    <p>Traditional Analytics Data communicated directly between servers that execute tasks.</p>
    <p>mapper task</p>
    <p>mapper task</p>
    <p>mapper task</p>
    <p>reducer task</p>
    <p>reducer task</p>
    <p>Server</p>
    <p>Server</p>
    <p>Server</p>
  </div>
  <div class="page">
    <p>Traditional Analytics Data communicated directly between servers that execute tasks.</p>
    <p>reducer task</p>
    <p>reducer task</p>
    <p>Server</p>
    <p>Server</p>
    <p>Server</p>
  </div>
  <div class="page">
    <p>How to shuffle in serverless?</p>
    <p>Tasks are short-lived</p>
    <p>mapper task</p>
    <p>mapper task</p>
    <p>mapper task</p>
    <p>reducer task</p>
    <p>reducer task</p>
    <p>Server</p>
    <p>Server</p>
    <p>Server</p>
  </div>
  <div class="page">
    <p>Tasks are short-lived</p>
    <p>reducer task</p>
    <p>reducer task</p>
    <p>Server</p>
    <p>Server</p>
    <p>Server</p>
    <p>How to shuffle in serverless?</p>
    <p>Shuffling directly between tasks is difficult in serverless.</p>
  </div>
  <div class="page">
    <p>How about using S3? - Many frameworks already use it for input/results. - Cheap capacity and elastic bandwidth</p>
    <p>How to shuffle in serverless?</p>
    <p>A gg</p>
    <p>re ga</p>
    <p>te B</p>
    <p>W (G</p>
    <p>B /s</p>
    <p>)</p>
    <p>Number of Lambda Workers</p>
    <p>write</p>
    <p>read</p>
  </div>
  <div class="page">
    <p>Shuffle with S3</p>
    <p>mapper task</p>
    <p>mapper task</p>
    <p>mapper task</p>
    <p>reducer task</p>
    <p>reducer task</p>
    <p>Server</p>
    <p>Server</p>
    <p>Server</p>
    <p>Compute</p>
    <p>S3</p>
    <p>How to shuffle in serverless?</p>
  </div>
  <div class="page">
    <p>Shuffle with S3</p>
    <p>reducer task</p>
    <p>reducer task</p>
    <p>Server</p>
    <p>Server</p>
    <p>Server</p>
    <p>Compute 13</p>
    <p>How to shuffle in serverless?</p>
    <p>S3 How much does it cost for CloudSort?</p>
  </div>
  <div class="page">
    <p>Shuffle with S3</p>
    <p>mapper task</p>
    <p>mapper task</p>
    <p>mapper task</p>
    <p>reducer task</p>
    <p>reducer task</p>
    <p>Server</p>
    <p>Server</p>
    <p>Server</p>
    <p>Compute</p>
    <p>S3</p>
    <p>How to shuffle in serverless?</p>
    <p>$ $ $</p>
    <p>How many requests does it take?</p>
  </div>
  <div class="page">
    <p>An Shuffle Example: Cloud Sort</p>
    <p>Partition Task</p>
    <p>Partition Task</p>
    <p>Partition Task</p>
    <p>merge task</p>
    <p>merge task</p>
    <p>merge task</p>
    <p>Total number of transfers: - Assuming 1GB serverless containers - Num partition/merge tasks = 100TB/1GB = 10# - Number of files: 10$% = 10 billion files</p>
  </div>
  <div class="page">
    <p>An Shuffle Example: Cloud Sort</p>
    <p>Partition Task</p>
    <p>Partition Task</p>
    <p>Partition Task</p>
    <p>merge task</p>
    <p>merge task</p>
    <p>merge task</p>
    <p>Total number of transfers: - Assuming 1GB serverless containers - Num partition/merge tasks = 100TB/1GB = 10# - Number of files: 10$% = 10 billion files - $0.000005/op -&gt; $50k</p>
  </div>
  <div class="page">
    <p>An Shuffle Example: Cloud Sort</p>
    <p>Partition Task</p>
    <p>Partition Task</p>
    <p>Partition Task</p>
    <p>merge task</p>
    <p>merge task</p>
    <p>merge task</p>
    <p>IO P</p>
    <p>S</p>
    <p>Number of Lambda Workers</p>
    <p>Bottlenecked at 4400 ops/sec!</p>
    <p>Takes !&quot;#$ %%&quot;&quot; seconds = 26 days</p>
  </div>
  <div class="page">
    <p>An Shuffle Example: Cloud Sort</p>
    <p>Partition Task</p>
    <p>Partition Task</p>
    <p>Partition Task</p>
    <p>merge task</p>
    <p>merge task</p>
    <p>merge task</p>
    <p>IO P</p>
    <p>S</p>
    <p>Number of Lambda Workers</p>
    <p>Bottlenecked at 4400 ops/sec!</p>
    <p>Takes !&quot;#$ %%&quot;&quot; seconds = 26 days</p>
    <p>S3 lacks cheap and elastic IOPS.</p>
    <p>AWS s3 ElastiCache (Redis) Azure Blob Azure Cache Google Cloud Storage Google MemoryStore</p>
  </div>
  <div class="page">
    <p>An Shuffle Example: Cloud Sort</p>
    <p>Partition Task</p>
    <p>Partition Task</p>
    <p>Partition Task</p>
    <p>merge task</p>
    <p>merge task</p>
    <p>merge task</p>
    <p>Require 158 large (r5.24xlarge) instances! Costs $1.6K/hour.</p>
    <p>Capacity alone is 10x more expansive than record.</p>
  </div>
  <div class="page">
    <p>An Shuffle Example: Cloud Sort</p>
    <p>Partition Task</p>
    <p>Partition Task</p>
    <p>Partition Task</p>
    <p>merge task</p>
    <p>merge task</p>
    <p>merge task</p>
    <p>Require 158 large (r5.24xlarge) instances! Costs $1.6K/hour.</p>
    <p>Capacity alone is 10x more expansive than record.</p>
    <p>Redis capacity is too expensive for large intermediate data.</p>
  </div>
  <div class="page">
    <p>Cloud Storage</p>
    <p>Service $/Mo/GB $/million writes</p>
    <p>AWS S3 0.023 5</p>
    <p>GCS 0.026 5</p>
    <p>Azure Blob 0.023 6.25</p>
    <p>ElastiCache 7.9 0</p>
    <p>MemoryStore 16.5 0</p>
    <p>Azure Cache 11.6 0</p>
    <p>Capacity IOPS</p>
    <p>Slow Storage</p>
    <p>Fast Storage</p>
    <p>High Low</p>
    <p>Low High</p>
    <p>Can we leverage the strengths of two storages types?</p>
  </div>
  <div class="page">
    <p>Locus</p>
    <p>Hybrid slow and fast cloud storage to achieve costefficient shuffle performance  Intuition: use fast storage to absorb IOPS and create bigger</p>
    <p>chunks for slow storage.</p>
  </div>
  <div class="page">
    <p>Hybrid sort (100TB)</p>
    <p>Round1:</p>
    <p>Round2:</p>
    <p>Round20:</p>
    <p>Clean cache after each round</p>
    <p>final merge</p>
    <p>num reqs = num mergers = 10# partition merge</p>
    <p>Total number of S3 reqs: 2010# ('(.10*+)  Total memory cache needed: 5TB (vs. 100TB)</p>
  </div>
  <div class="page">
    <p>Hybrid sort (100TB)</p>
    <p>Round1:</p>
    <p>Round2:</p>
    <p>Round20:</p>
    <p>Clean cache after each round</p>
    <p>num reqs = num mergers = 10# partition merge</p>
    <p>Spark record: 50min + $144  Locus: 50min + $163</p>
    <p>final merge</p>
  </div>
  <div class="page">
    <p>Hybrid sort (100TB)</p>
    <p>Round1:</p>
    <p>Round2:</p>
    <p>Round20:</p>
    <p>Clean cache after each round</p>
    <p>num reqs = num mergers = 10# partition merge</p>
    <p>Spark record: 50min + $144  Locus: 50min + $163</p>
    <p>Locus achieves same performance with 5X less resource.</p>
    <p>final merge</p>
  </div>
  <div class="page">
    <p>Locus</p>
    <p>Hybrid slow and fast cloud storage to achieve costefficient shuffle performance  Intuition: use fast storage to absorb IOPS and create bigger</p>
    <p>chunks for slow storage.</p>
    <p>When to use hybrid shuffle?  Alongside, many other configurations</p>
    <p>Amount of fast cache  Level of parallelism  Worker size</p>
  </div>
  <div class="page">
    <p>Locus Performance Model</p>
    <p>Navigating cost-performance with different compute and storage configurations is difficult.</p>
  </div>
  <div class="page">
    <p>Navigating cost-performance with different compute and storage configurations is difficult.  How many serverless workers? Which size?</p>
    <p>S hu</p>
    <p>ff le</p>
    <p>T im</p>
    <p>e (s</p>
    <p>)</p>
    <p>Worker Memory Size (GB)</p>
    <p>Locus Performance Model</p>
  </div>
  <div class="page">
    <p>Navigating cost-performance with different compute and storage configurations is difficult.  How many serverless workers? Which size?</p>
    <p>S hu</p>
    <p>ff le</p>
    <p>T im</p>
    <p>e (s</p>
    <p>)</p>
    <p>Worker Memory Size (GB)</p>
    <p>Locus Performance Model</p>
  </div>
  <div class="page">
    <p>Navigating cost-performance with different compute and storage configurations is difficult.  How many serverless workers? Which size?</p>
    <p>S hu</p>
    <p>ff le</p>
    <p>T im</p>
    <p>e (s</p>
    <p>)</p>
    <p>Worker Memory Size (GB)</p>
    <p>Locus Performance Model</p>
  </div>
  <div class="page">
    <p>Performance model example: slow-storage only shuffle</p>
    <p>!  IOPS S  shuffle size W  worker size</p>
    <p>&quot;2 = $ %</p>
    <p>&amp;%(</p>
    <p>&quot; = max &quot;1,&quot;2</p>
    <p>mapper task</p>
    <p>mapper task</p>
    <p>mapper task</p>
    <p>Server</p>
    <p>Server</p>
    <p>Server</p>
    <p>S  shuffle size B  worker BW P  parallelism</p>
    <p>&quot;1 = /0  1</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Implement Locus on top of PyWren  AWS Lambda  S3 (slow)  Redis (fast)</p>
    <p>Workloads:  CloudSort  TPC-DS  Big data benchmark</p>
    <p>Baseline:  PyWren  Apache Spark on VMs  Redshift</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Reduce resource usage by up to 59% while achieving comparable performance!</p>
    <p>Q1 Q16 Q94 Q95</p>
    <p>cl us</p>
    <p>te rt</p>
    <p>im e</p>
    <p>(c or</p>
    <p>e se</p>
    <p>c)</p>
    <p>Locus</p>
    <p>Spark-58%</p>
    <p>-59%</p>
    <p>Q1 Q16 Q94 Q95 av</p>
    <p>er ag</p>
    <p>e qu</p>
    <p>er y</p>
    <p>ti m</p>
    <p>e (s</p>
    <p>)</p>
    <p>Locus</p>
    <p>Spark</p>
    <p>TPC-DS</p>
  </div>
  <div class="page">
    <p>Related Works</p>
    <p>Pocket (OSDI18)  New elastic store that scales to application demand</p>
  </div>
  <div class="page">
    <p>Locus</p>
    <p>By judiciously combining slow and fast cloud storage, one can achieve cost-efficient shuffle for serverless analytics.</p>
    <p>Locus achieves this by:  Design algorithms that leverage storage characteristics  A performance model that captures the performance and cost</p>
    <p>metrics of shuffle operations.</p>
    <p>4-500 performance improvements over baseline and reduce resource usage by up to 59% while achieving comparable performance with traditional analytics</p>
  </div>
</Presentation>
