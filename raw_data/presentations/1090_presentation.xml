<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>On Smart Query Routing: For Distributed Graph Querying with Decoupled Storage</p>
    <p>Arijit Khan</p>
    <p>Nanyang Technological</p>
    <p>University (NTU), Singapore</p>
    <p>Gustavo Segovia</p>
    <p>ETH Zurich, Switzerland</p>
    <p>Donald Kossmann</p>
    <p>Microsoft Research, Redmond, USA</p>
  </div>
  <div class="page">
    <p>Big Graphs</p>
    <p>Google: &gt; 1 trillion indexed pages</p>
    <p>Web Graph Social Network</p>
    <p>Facebook: &gt; 800 million active users</p>
    <p>Information Network Biological Network</p>
    <p>De Bruijn: 4k nodes</p>
    <p>(k = 20,  , 40)</p>
    <p>Graphs in Machine Learning</p>
  </div>
  <div class="page">
    <p>Background: Distributed Graph Querying Systems</p>
    <p>State-of-the-art distributed graph querying systems (e.g., SEDGE [SIGMOD12], Trinity [SIGMOD13], Horton [PVLDB13])</p>
    <p>First, partition the graph, and then place each partition on a separate server, where query answering over that partition takes place.</p>
  </div>
  <div class="page">
    <p>Background: Distributed Graph Querying Systems</p>
    <p>State-of-the-art distributed graph querying systems</p>
    <p>Disadvantages</p>
    <p>Fixed Routing (less flexible)</p>
    <p>Balanced Graph Partitioning and Re-Partitioning</p>
  </div>
  <div class="page">
    <p>Background: Distributed Graph Querying Systems</p>
    <p>State-of-the-art distributed graph querying systems</p>
    <p>Disadvantages</p>
    <p>Fixed Routing (less flexible)</p>
    <p>The server which contains the query node can only handle that request  the router maintains a fixed routing table (or, a fixed routing strategy, e.g., modulo hashing).</p>
    <p>Less flexible with respect to query routing and fault tolerance, e.g., adding more machines will require updating the data partition and/or the routing table.</p>
    <p>Balanced Graph Partitioning and Re-Partitioning</p>
  </div>
  <div class="page">
    <p>Background: Distributed Graph Querying Systems</p>
    <p>State-of-the-art distributed graph querying systems</p>
    <p>Disadvantages</p>
    <p>Fixed Routing (less flexible)</p>
    <p>Balanced Graph Partitioning and RePartitioning</p>
    <p>(1) workload balancing to maximize parallelism, (2) locality of data access to minimize network communication  NP-hard, difficult in power-law graphs.</p>
    <p>later updates to graph structure or variations in query workloads  graph re-partitioning/ replication  online monitoring of workload changes, repartitioning of the graph topology, and migration of graph data across servers are expensive.</p>
  </div>
  <div class="page">
    <p>Roadmap</p>
    <p>Distributed graph querying and graph partitioning</p>
    <p>Decoupled graph querying system</p>
    <p>Related work</p>
    <p>Smart graph query routing</p>
    <p>Experimental results</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Decoupled Graph Querying System</p>
    <p>we decouple query processing and graph storage into two separate tiers.</p>
    <p>This decoupling happens at a logical level.</p>
    <p>Decoupled architecture for graph querying</p>
  </div>
  <div class="page">
    <p>Decoupled Graph Querying System</p>
    <p>Flexible routing</p>
    <p>Less reliant on good partitioning across storage servers [Due to our smart query routing strategy  will be discussed soon!]</p>
    <p>Decoupled architecture for graph querying</p>
    <p>Benefits</p>
  </div>
  <div class="page">
    <p>Decoupled Graph Querying System</p>
    <p>Flexible routing</p>
    <p>A query processor no longer assigned a fixed part of the graph  equally capable of handling any request  facilitating load balancing and fault tolerance.</p>
    <p>The query router can send a request to any of the query processors  more flexible query routing, e.g., more query processors can be added (or, a query processor that is down can be replaced) without affecting the routing strategy.</p>
    <p>Decoupled architecture for graph querying</p>
    <p>Benefits</p>
  </div>
  <div class="page">
    <p>Decoupled Graph Querying System</p>
    <p>Flexible routing</p>
    <p>Each tier can be scaled-up independently.</p>
    <p>A certain workload is processing intensive  allocate more servers to the processing tier.</p>
    <p>Graph size increases over time  add more servers in the storage tier.</p>
    <p>Decoupled architecture, being generic, can be employed in many existing graph querying systems. Decoupled architecture for</p>
    <p>graph querying</p>
    <p>Benefits</p>
  </div>
  <div class="page">
    <p>Roadmap</p>
    <p>Distributed graph querying and graph partitioning</p>
    <p>Decoupled graph querying system</p>
    <p>Related work</p>
    <p>Smart graph query routing</p>
    <p>Experimental results</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Related Work: Decoupling Storage and Query Processors</p>
    <p>Googles F1 [PVLDB13]</p>
    <p>ScaleDB [http://scaledb.com/pdfs/TechnicalOverview.pdf]</p>
    <p>Loesing et. al. (On the Design and Scalability of Distributed SharedData Databases) [SIGMOD15]</p>
    <p>Binnig et. al. (The End of Slow Networks: Its Time for a Redesign) [PVLDB16]</p>
    <p>Shalita et. al. (Social Hash: An Assignment Framework for Optimizing Distributed Systems Operations on Social Networks) [NSDI16]</p>
    <p>Facebooks Memcached [NSDI13]</p>
  </div>
  <div class="page">
    <p>Decoupled Graph Querying System</p>
    <p>Disadvantages</p>
    <p>Query processors may need to communicate with the storage tier via the network  additional penalty to the response time for answering a query.</p>
    <p>May cause high contention rates on either the network, storage tier, or both.</p>
    <p>Decoupled architecture for graph querying</p>
  </div>
  <div class="page">
    <p>Our Contribution: Smart Query Routing</p>
    <p>Decoupled architecture for graph querying</p>
    <p>We design a smart query routing logic to utilize the cache of query processors over such decoupled architecture.</p>
    <p>More cache hits  reduce communication among query processors and storage servers.</p>
    <p>More cache hits  less reliant on good partitioning across storage servers.</p>
  </div>
  <div class="page">
    <p>Roadmap</p>
    <p>Distributed graph querying and graph partitioning</p>
    <p>Decoupled graph querying system</p>
    <p>Related work</p>
    <p>Smart graph query routing</p>
    <p>Experimental results</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>h-Hop Traversal Queries</p>
    <p>Online, h-hop queries: explore a small region of the entire graph, and require fast response time.</p>
    <p>Start with a query node, and traverse its neighboring nodes up to a certain number of hops (i.e., h = 2, 3).</p>
    <p>h-hop neighbor aggregation</p>
    <p>h-step random walk with restart</p>
    <p>h-hop reachability</p>
    <p>Examples</p>
    <p>More complex queries, e.g., node labeling and classification, expert finding, ranking, discovering functional modules, complexes, and pathways</p>
  </div>
  <div class="page">
    <p>Objectives for Smart Query Routing</p>
    <p>Leverage each processors cached data</p>
    <p>Balance workload even if skewed or contains hotspot</p>
    <p>Make fast routing decisions [a small constant time, or &lt;&lt; O(n) ]</p>
    <p>Have low storage overhead in the router [a small fraction of the input graph size]</p>
    <p>Decoupled architecture for graph querying</p>
  </div>
  <div class="page">
    <p>Challenges in Smart Query Routing</p>
    <p>Leverage each processors cached data Balance workload even if skewed or contains hotspot Make fast routing decisions Have low storage overhead in the router</p>
    <p>Objectives are conflicting</p>
    <p>For maximum cache locality, router can send all queries to the same processor (assuming no cache eviction)  imbalanced workload in processors  lower throughput.</p>
    <p>router could inspect the cache of each processor before making a good routing decision  network delay. Hence, router must infer what is likely to be in each processors cache.</p>
    <p>Smart Routing Objectives</p>
  </div>
  <div class="page">
    <p>Challenges in Smart Query Routing</p>
    <p>Topology-Aware Locality</p>
    <p>successive queries on nearby nodes must be sent to the same processor. It is likely that h-hop neighborhoods of these nodes significantly overlap.</p>
    <p>How the router knows about nearby nodes without storing the entire graph topology?</p>
    <p>- use landmark, graph embedding</p>
    <p>Smart Routing Objectives are conflicting!</p>
  </div>
  <div class="page">
    <p>Challenges in Smart Query Routing</p>
    <p>Query Stealing</p>
    <p>Always Routing queries to processors that have the most useful cache data  workload imbalance if skew/ query hotspot  lower throughput.</p>
    <p>We perform query stealing at router  Whenever a processor is idle and is ready to handle a new query, if it does not have any other requests assigned to it, the router may steal a request and send to it which was intended for another processor.</p>
    <p>Query stilling by maintaining topology-aware locality (as much as possible).</p>
    <p>Smart Routing Objectives are conflicting!</p>
  </div>
  <div class="page">
    <p>Smart Routing-1: Landmark</p>
    <p>If two nodes are close to a given landmark, they are likely to be close themselves.</p>
  </div>
  <div class="page">
    <p>Smart Routing-1: Landmark</p>
    <p>Select a small set of L nodes as landmarks.</p>
    <p>Compute distance of every node to landmarks.</p>
    <p>Assign landmarks to query processors: Every processor is assigned a pivot landmark with the intent that pivot landmarks are as far from each other as possible. Each remaining landmark is assigned to the processor which contains its closest pivot landmark.</p>
    <p>Pre-processing</p>
    <p>The distance of a node u to a processor p is defined as the minimum distance of u to any landmark that is assigned to processor p.</p>
    <p>This distance information is stored in the router, which requires O(nP) space and O(nL) time to compute.</p>
    <p>If two nodes are close to a given landmark, they are likely to be close themselves.</p>
  </div>
  <div class="page">
    <p>Smart Routing-1: Landmark</p>
    <p>a query on node u  the router verifies the pre-computed distance d(u, p) for every processor p  selects the one with the smallest d(u, p) value.</p>
    <p>Routing decision time: O(p)</p>
    <p>Online Routing</p>
    <p>If two nodes are close to a given landmark, they are likely to be close themselves.</p>
    <p>Load-balancing via Query-stealing</p>
    <p>Route to smallest load-balanced distance.</p>
    <p>Nearby nodes are routed in similar way, maintaining topology-aware locality.</p>
  </div>
  <div class="page">
    <p>Smart Routing-2: Embed</p>
    <p>Embed a graph in a lower D-dimensional Euclidean plane.</p>
    <p>The hop-count distance between graph nodes are approximately preserved via their Euclidean distance.</p>
    <p>Storage = O(nD), time = O(|L|2D + n|L|D)</p>
    <p>Pre-processing</p>
    <p>Graph embedding in 2D Euclidean plane</p>
    <p>A benefit of embed routing is that the pre-processing is independent of the system topology, allowing more processors to be easily added at a later time.</p>
  </div>
  <div class="page">
    <p>Smart Routing-2: Embed</p>
    <p>Exponential moving average to compute the mean of the processors cache contents.</p>
    <p>Router finds the distance between a query node u and a processor p, denoted as d(u, p), and defined as the distance of the query nodes co-ordinates to the historical mean of the processors cache contents.</p>
    <p>Route query on u to processor p with minimum d(u, p).</p>
    <p>Routing decision time: O(PD)</p>
    <p>Online Routing</p>
    <p>Graph embedding in 2D Euclidean plane</p>
  </div>
  <div class="page">
    <p>Smart Routing-2: Embed</p>
    <p>Exponential moving average to compute the mean of the processors cache contents.</p>
    <p>Router finds the distance between a query node u and a processor p, denoted as d(u, p), and defined as the distance of the query nodes co-ordinates to the historical mean of the processors cache contents.</p>
    <p>Route query on u to processor p with minimum d(u, p).</p>
    <p>Routing decision time: O(PD)</p>
    <p>Online Routing</p>
    <p>Graph embedding in 2D Euclidean plane</p>
    <p>Load-balancing via Query-stealing</p>
  </div>
  <div class="page">
    <p>Roadmap</p>
    <p>Distributed graph querying and graph partitioning</p>
    <p>Decoupled graph querying system</p>
    <p>Related work</p>
    <p>Smart graph query routing</p>
    <p>Experimental results</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Experimental Setup</p>
    <p>Graph Datasets</p>
    <p>Cluster Configuration</p>
    <p>12 servers each having 2.4 GHz Intel Xeon processors, 0  4GB cache.</p>
    <p>interconnected by 40 Gbps Infiniband, and also by 10 Gbps Ethernet.</p>
    <p>Use a single core of each server with the following configuration: 1 server as router, 7 servers in the processing tier, 4 servers in the storage tier; and communication over Infiniband with remote direct memory access (RDMA).</p>
    <p>RAMCloud as storage tier.</p>
    <p>Graph is stored as adjacency list  every node-id is key, and the corresponding value is an array of its 1-hop neighbors.</p>
    <p>The graph is partitioned across storage servers via RAMClouds default and inexpensive hash partitioning scheme, MurmurHash3 over graph nodes.</p>
  </div>
  <div class="page">
    <p>List of Experiments</p>
    <p>Comparison with distributed graph systems (SEDGE [SIGMOD12] with Giraph [SIGMOD10], GraphLab [VLDB12]) that use smart graph partitioning and reportioning - Our method achieves up to an order of magnitude higher throughput even with inexpensive hash partitioning of the graph!</p>
    <p>Scalability with number of processors and storage servers</p>
    <p>Impact of cache size</p>
    <p>Impact of graph updates</p>
    <p>Sensitivity w.r.t. different parameters: query locality and hotspot, h-hop queries, load factor, smoothing parameter, embedding dimensionality, landmark numbers, minimum distance between a pair of landmarks</p>
    <p>Performance Metrics</p>
    <p>Baseline Routing Methods</p>
    <p>Query efficiency, Query throughput, Cache hit rates</p>
    <p>Next ready, No cache, Modular hash with query stealing</p>
  </div>
  <div class="page">
    <p>Performance with Varying Number of Query Processors</p>
    <p>Embed routing is able to sustain almost same cache hit rate with many query processors. Hence, its throughput scales linearly with query processors.</p>
  </div>
  <div class="page">
    <p>On Smart Query Routing: For Distributed Graph Querying with Decoupled Storage: Arijit Khan (NTU Singapore), G. Segovia, and D. Kossmann</p>
    <p>Impact of Cache Sizes</p>
    <p>Both smart routings  Embed and Landmark  utilize the cache well; and for the same amount of cache, they achieve lower response time compared to baseline routings.</p>
  </div>
  <div class="page">
    <p>Roadmap</p>
    <p>Distributed graph querying and graph partitioning</p>
    <p>Decoupled graph querying system</p>
    <p>Related work</p>
    <p>Smart graph query routing</p>
    <p>Experimental results</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>On Smart Query Routing: For Distributed Graph Querying with Decoupled Storage: Arijit Khan (NTU Singapore), G. Segovia, and D. Kossmann 32/ 32</p>
    <p>Decoupled graph querying system</p>
    <p>Smart query routing to achieve higher cache hits for h-hop traversal queries</p>
    <p>Decoupled architecture for graph querying</p>
    <p>emphasize less on expensive graph partitioning and re-partitioning across storage tiers</p>
    <p>provide linear scalability in throughput with more number of query processors</p>
    <p>works well in the presence of query hotspots</p>
    <p>adaptive to workload changes and graph updates.</p>
  </div>
</Presentation>
