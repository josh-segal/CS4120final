<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Zhenyu GUO , Dong ZHOU, Haoxiang LIN, Mao YANG, Fan LONG, Chaoqiang DENG, Changshu LIU, Lidong ZHOU</p>
    <p>System Research Group, MSR Asia</p>
    <p>G2: A Graph Processing System for Diagnosing Distributed Systems</p>
  </div>
  <div class="page">
    <p>Cost of Debugging</p>
    <p>The huge prinMng presses for a major Chicago newspaper began malfuncMoning</p>
    <p>Most bugs can be fixed quickly,</p>
    <p>$10,000 = $1 + $9,999</p>
    <p>however iden@fying the root causes is hard.</p>
  </div>
  <div class="page">
    <p>MoMvaMon</p>
    <p>Diagnosing distributed systems is frustraMng  ExecuMon is too complex to comprehend  Tons of logs, but correlaMons are missing  Lost in the informaMon sea</p>
    <p>We need a tool that  Finds correlated informaMon.  Facilitates beUer summarizaMon and reasoning  Is fast and easy to use</p>
  </div>
  <div class="page">
    <p>ContribuMon</p>
    <p>Graph based diagnosis for distributed systems  ExecuMon graph to capture correlaMons  Graph based diagnosis operators</p>
    <p>Slicing for finding &amp; filtering  HierarchicalAggrega@on for summarizaMon</p>
    <p>DeclaraMve diagnosis queries  Integrated with MicrosoZ LINQ</p>
    <p>Distributed engine  Integrated relaMonal computaMon and graph traversal  OpMmizaMons based on the characterisMcs of the execuMon graph and diagnosis operators</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Model  Engine  Programming  EvaluaMon</p>
  </div>
  <div class="page">
    <p>Capture CorrelaMons</p>
    <p>req</p>
    <p>req</p>
    <p>req req</p>
    <p>Disk</p>
    <p>req req</p>
    <p>req req</p>
    <p>Master</p>
    <p>Replica 1</p>
    <p>Replica 2</p>
  </div>
  <div class="page">
    <p>ExecuMon is Graph</p>
    <p>printf req issue</p>
    <p>reqs forward</p>
    <p>reqs use</p>
    <p>reqs forward . . . ...</p>
    <p>Client 1</p>
    <p>Client 2</p>
    <p>Master</p>
    <p>printf req issue</p>
    <p>Time</p>
  </div>
  <div class="page">
    <p>Slicing: Find the correlated subgraph and filter others by traversing the execuMon graph</p>
    <p>printf req issue</p>
    <p>reqs forward</p>
    <p>reqs use</p>
    <p>reqs forward . . . ...</p>
    <p>Client 1</p>
    <p>Client 2</p>
    <p>Master</p>
    <p>printf req issue</p>
    <p>Time</p>
    <p>//Error log analysis Events .Where(e =&gt; (e.Val.Type == EventType.LOG_ERROR) &amp;&amp; e.Val.Payload.Contains(&quot;Write request failed&quot;)) .Slicing(Slice.Backward) .Select(e =&gt; Console.WriteLine(e.Val.Payload));</p>
  </div>
  <div class="page">
    <p>Slicing: Find the correlated subgraph and filter others by traversing the execuMon graph</p>
    <p>printf req issue</p>
    <p>reqs forward</p>
    <p>reqs use</p>
    <p>reqs forward . . . ...</p>
    <p>Client 1</p>
    <p>Client 2</p>
    <p>Master</p>
    <p>printf req issue</p>
    <p>Time</p>
    <p>Events .Where(e =&gt; (e.Val.Type == EventType.LOG_INFORMATION) &amp;&amp; e.Val.Payload.Contains(Start ClientRequest()&quot;)) .Slicing(Slice.Forward) .Select(e =&gt; Console.WriteLine(e.Val.Payload));</p>
  </div>
  <div class="page">
    <p>HierarchicalAggrega-on: Summarize details by traversing the execuMon graph</p>
    <p>Primary (440)</p>
    <p>Machine 2</p>
    <p>Machine 1</p>
    <p>Machine 0</p>
    <p>Time</p>
    <p>Secondary 1 (144)</p>
    <p>Secondary 2 (202)</p>
    <p>ReplicateWrite</p>
    <p>ReplicateWrite Message::DoExecution (12)</p>
    <p>I/O</p>
    <p>Replication</p>
    <p>Network</p>
    <p>Time</p>
    <p>ReplicateWrite (149)</p>
    <p>SerializedIOWrite (17)</p>
    <p>WriteRequestFailed (24)</p>
    <p>Slicing</p>
    <p>AggregaMon</p>
    <p>Zoom In</p>
    <p>//HierarchicalAggregation Events .Where(e =&gt; e.Val.Location.Name == &quot;SubmitWriteReq&quot;) .Slicing(Slice.Forward) .HierarchicalAggregate(e =&gt; e.Val.Process.Machine.Signature, evts =&gt; evts.First().Val.Process.Machine.Name);</p>
  </div>
  <div class="page">
    <p>Understand ExecuMon Graph</p>
    <p>ExecuMon graph is rather huge  A 2-hour SCOPE/Dryad graph has over 1.2 billion verMces, 0.54 billion edges, and lots of user payload(logs)</p>
    <p>Connected subgraph is also huge  However, intra-machine interacMons are much more than inter-machine ones(91% vs 9% in SCOPE/Dryad graph)</p>
    <p>Graph structure data is relaMvely small  User payload is over 64% in storage</p>
    <p>IteraMve access to graph structure data  Concurrent traversals  AggregaMon follows slicing</p>
  </div>
  <div class="page">
    <p>OpMmize Graph Access</p>
    <p>Diagnosing tool as a distributed system  OpMmal parMMon on graph data</p>
    <p>At machine boundary iniMally. Dynamic parMMoning.  Local data is stored in database</p>
    <p>Caching  Graph structure data in memory  Retrieve payload only when necessary</p>
    <p>Prefetching  Get vertex properMes during slicing, instead of during aggregaMon</p>
  </div>
  <div class="page">
    <p>Understand Slicing &amp; HierarchicalAggregaMon</p>
    <p>Latency is an issue  More than 200 hops someMmes, due to deep paths</p>
    <p>Rigorous synchronizaMon is not efficient  Different from Page Rank/Belief PropagaMon</p>
    <p>AggregaMon repeatedly colors local verMces with the same aggregaMon idenMty  Lots of local messages</p>
  </div>
  <div class="page">
    <p>OpMmize Fast ExecuMon Graph Traversal</p>
    <p>Batched Asynchronous Graph Traversal  Explore local verMces unMl reaching cross-parMMon edges without</p>
    <p>synchronizaMon</p>
    <p>ParMMon-level interface  One traversal worker on each parMMon  Direct access to the whole local graph data  Local verMces could be condensed into super nodes in advance</p>
    <p>OneHop Batched Batched + ParMMon</p>
    <p>Sp ee d u p</p>
    <p>Slicing</p>
    <p>OneHop Batched Batched + ParMMon</p>
    <p>OneHop Batched Batched + ParMMon</p>
    <p>Sp ee d u p</p>
    <p>Aggrega@on At Component Level</p>
    <p>OneHop Batched Batched + ParMMon</p>
  </div>
  <div class="page">
    <p>Play with G2</p>
    <p>Capture the graph  Manual annotaMon, Binary rewriter and dynamic instrumentaMon</p>
    <p>Write simple C# queries  Reuse exisMng relaMonal operators in LINQ  Slicing(Chopping) / HierarchicalAggregaMon  Local Extensions: Diff, CriMcalPath,</p>
    <p>Provide diagnosis wizards in Visual Studio</p>
  </div>
  <div class="page">
    <p>EvaluaMon Systems LOC(K) Func# Edge# Event# Raw(MB) DB(MB) Time(min) Node#</p>
    <p>Berkeley DB 172 46164 92502 186597 14 29 2 3</p>
    <p>G2 27 267,728 634,704 1,212,778 85 231 17 60</p>
    <p>SCOPE/Dryad 1,577 3,128,105 8,964,168 20,106,457 1,226 3,269 120 60</p>
    <p>60 machines  2 GHZ dual core  8 GB memory  Two 1 TB disk  1 Gb Ethernet</p>
    <p>Systems Annotated Edge#</p>
    <p>Annotated CS#</p>
    <p>Instrumented Func#</p>
    <p>Rules</p>
    <p>Berkeley DB 2 2 1,542 23</p>
    <p>G2 9 11 197 10</p>
    <p>SCOPE/Dryad 17 13 730 5</p>
    <p>Table 1: Per node graph sta@s@cs</p>
    <p>Table 2: Instrumenta@on sta@s@cs</p>
  </div>
  <div class="page">
    <p>End to End Query Performance</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>ExecuMon Model  Path based analysis  Pure log analysis  StaMc analysis</p>
    <p>Distributed ExecuMon Engine and Storage  Graph systems  Map-reduce alike systems</p>
    <p>Diagnosis Plarorm  Cloud9: TesMng as a service  Dapper: path analysis atop of BigTable</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Graph based diagnosis for distributed systems  Slicing for filtering the logs  HierarchicalAggregaMon for summarizaMon</p>
    <p>Graph engine with specific requirements  Integrated relaMonal computaMon and graph traversal support</p>
    <p>Batched asynchronous graph traversal and parMMon-level interface for beUer performance</p>
  </div>
  <div class="page">
    <p>Thanks!</p>
  </div>
  <div class="page">
    <p>GeneraMons for log structure and related tools:</p>
    <p>Text  Unstructured text</p>
    <p>Format: [AUTO: #me, component, log level, pid, #d, loca#on], `prinr message</p>
    <p>AggregaMon: by the meta informaMon or keywords in the unstructured message</p>
    <p>Pros  Free style format  Easy to process: grep</p>
    <p>Cons  May miss many implicit dependencies among log entries without shared tag (e.g., request id)</p>
  </div>
  <div class="page">
    <p>GeneraMons for log structure and related tools:</p>
    <p>Paths  Path-based aggregaMon</p>
    <p>Format:  [ANNOTATION: path id] + unstructured text  OpMonal: [ANNOTATION] dependencies among log entries belonging to the</p>
    <p>same path are captured  AggregaMon: by the user request id (path id)</p>
    <p>Pros  EffecMve for request-centric analysis and modeling  The logs are parMMoned by request id, and each parMMon can usually</p>
    <p>be handled by single machine  A nice balance between usability and the overhead</p>
    <p>Cons  Cut off interacMons between requests, which is common in distributed</p>
    <p>systems, such as batching  Path is staMcally defined by the pre-defined `requests only</p>
  </div>
  <div class="page">
    <p>printf req issue</p>
    <p>reqs forward</p>
    <p>reqs use</p>
    <p>reqs forward . . . ...</p>
    <p>Client 1</p>
    <p>Client 2</p>
    <p>Master</p>
    <p>printf req issue</p>
    <p>Time</p>
  </div>
  <div class="page">
    <p>Scaling Performance</p>
  </div>
  <div class="page">
    <p>Graph Traversal Interface</p>
    <p>IQueryable&lt;T&gt; GraphTraversal&lt;TWorker&gt;( this Graph&lt;TV, TE&gt; g, IQueryable&lt;Vertex&lt;TV, TE&gt;&gt; startVertices ) where TWorker : GPartitionWorker&lt;TV, TE, _, T&gt;;</p>
    <p>class GPartitionWorker&lt;TV, TE, TMsg, T&gt; { public Vertex&lt;TV, TE&gt; GetLocalVertex(ID VertexID); public void SendMessage(ID VertexID, TMsg msg); public void WriteOutput(T val); public virtual void Initialize(VertexIterator&lt;TV, TE&gt;); public virtual void OnMessage(Vertex&lt;TV, TE&gt;, TMsg msg); public virtual void Finalize(); }</p>
  </div>
  <div class="page">
    <p>class GPartitionSlicingWorker&lt;TV, TE&gt; : GPartitionWorker&lt;TV, TE, bool, Vertex&lt;TV, TE&gt;&gt; { private HashSet&lt;ID&gt; VisitedVertices;</p>
    <p>public override void Initialize(VertexIterator&lt;TV,TE&gt; inits) { foreach (var v in inits) { SendMessage(v.ID, true); } }</p>
    <p>public override void OnMessage(Vertex&lt;TV,TE&gt; v, bool msg) { if (VisitedVertices.Contains(v.ID)) return; VisitedVertices.Add(v.ID); WriteOutput(v); foreach (var e in v.OutEdges) { if (e.IsCausal()) SendMessage(e.DstVertexID, true); } } }</p>
  </div>
  <div class="page">
    <p>Experience using G2</p>
  </div>
  <div class="page">
    <p>Deployment Issues</p>
    <p>Capture the correlaMons  Instrument the network and thread pool libraries to capture the asynchronous transiMons among threads and machines</p>
    <p>Store and process the logs  OpMon 1: dedicated graph engine (G2)</p>
    <p>Pros: complete support of G2 diagnosis queries  Cons: interference to host systems</p>
    <p>OpMon 2: in-app graph engine with latest logs  Pros: lightweight, easy to deploy  Cons: limited memory cache capacity (latest logs only)</p>
  </div>
</Presentation>
