<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>VANTAGE: SCALABLE AND EFFICIENT FINE-GRAIN CACHE PARTITIONING</p>
    <p>Daniel Sanchez and Christos Kozyrakis Stanford University</p>
    <p>ISCA-38, June 6th 2011</p>
  </div>
  <div class="page">
    <p>Executive Summary</p>
    <p>! Problem: Interference in shared caches ! Lack of isolation &quot; no QoS ! Poor cache utilization &quot; degraded performance</p>
    <p>! Cache partitioning addresses interference, but current partitioning techniques (e.g. way-partitioning) have serious drawbacks ! Support few coarse-grain partitions &quot; do not scale to many-cores ! Hurt associativity &quot; degraded performance</p>
    <p>! Vantage solves deficiencies of previous partitioning techniques ! Supports hundreds of fine-grain partitions ! Maintains high associativity ! Strict isolation among partitions ! Enables cache partitioning in many-cores</p>
  </div>
  <div class="page">
    <p>Outline 3</p>
    <p>! Introduction ! Vantage Cache Partitioning ! Evaluation</p>
  </div>
  <div class="page">
    <p>Motivation 4</p>
    <p>! Fully shared last-level caches are the norm in multi-cores # Better cache utilization, faster communication, cheaper coherence $ Interference &quot; performance degradation, no QoS</p>
    <p>! Increasingly important problem due to more cores/chip and virtualization, consolidation (datacenter/cloud) ! Major performance and energy losses due to cache contention (~2x) ! Consolidation opportunities lost to maintain SLAs</p>
    <p>LLC</p>
    <p>L2</p>
    <p>Core</p>
    <p>L2</p>
    <p>Core</p>
    <p>L2</p>
    <p>Core</p>
    <p>L2</p>
    <p>Core</p>
    <p>L2</p>
    <p>Core</p>
    <p>L2</p>
    <p>Core</p>
    <p>L2</p>
    <p>Core</p>
    <p>L2</p>
    <p>Core</p>
    <p>VM1 VM2 VM3 VM4 VM5 VM6</p>
    <p>L2 L2 L2 L2 L2 L2 L2 L2</p>
    <p>LLC</p>
  </div>
  <div class="page">
    <p>Cache Partitioning 5</p>
    <p>! Cache partitioning: Divide cache space among competing workloads (threads, processes, VMs) # Eliminates interference, enabling QoS guarantees # Adjust partition sizes to maximize performance, fairness, satisfy SLA... $ Previously proposed partitioning schemes have major drawbacks</p>
    <p>LLC</p>
    <p>L2</p>
    <p>Core</p>
    <p>L2</p>
    <p>Core</p>
    <p>L2</p>
    <p>Core</p>
    <p>L2</p>
    <p>Core</p>
    <p>L2</p>
    <p>Core</p>
    <p>L2</p>
    <p>Core</p>
    <p>L2</p>
    <p>Core</p>
    <p>L2</p>
    <p>Core</p>
    <p>VM1 VM2 VM3 VM4 VM5 VM6</p>
    <p>L2 L2 L2 L2 L2 L2 L2 L2</p>
    <p>LLC</p>
  </div>
  <div class="page">
    <p>Cache Partitioning = Policy + Scheme 6</p>
    <p>! Cache partitioning consists of a policy (decide partition sizes to achieve a goal, e.g. fairness) and a scheme (enforce sizes)</p>
    <p>! Focus on the scheme ! For policy to be effective, scheme should be:</p>
    <p>partitions 4. Dynamic: can create, remove, resize partitions efficiently 5. Maintains associativity 6. Independent of replacement policy 7. Simple to implement</p>
    <p>Maintain high cache performance</p>
  </div>
  <div class="page">
    <p>Existing Schemes with Strict Guarantees</p>
    <p>! Based on restricting line placement ! Way partitioning: Restrict insertions to specific ways</p>
    <p>-15 -10 -5 0 5</p>
    <p>mix1 mix2 IP</p>
    <p>C i m</p>
    <p>p ro</p>
    <p>v em</p>
    <p>en t</p>
    <p>v s</p>
    <p>a y (</p>
    <p>% )</p>
    <p>WayPart Way 0 Way 1 Way 2 Way 3 Way 4 Way 5 Way 6 Way 7</p>
    <p># Strict isolation # Dynamic # Indep of repl policy # Simple $ Few coarse-grain partitions $ Hurts associativity</p>
  </div>
  <div class="page">
    <p>Existing Schemes with Soft Guarantees 8</p>
    <p>! Based on tweaking the replacement policy ! PIPP [ISCA 2009]: Lines inserted and promoted in LRU</p>
    <p>chain depending on the partition they belong to</p>
    <p>-20</p>
    <p>-10</p>
    <p>mix1 mix2</p>
    <p>IP C</p>
    <p>i m</p>
    <p>p ro</p>
    <p>v em</p>
    <p>en t</p>
    <p>v s</p>
    <p>a y (</p>
    <p>% )</p>
    <p>WayPart PIPP Way 0 Way 1 Way 2 Way 3 Way 4 Way 5 Way 6 Way 7</p>
    <p># Dynamic # Maintains associativity # Simple $ Few coarse-grain partitions $ Weak isolation $ Sacrifices replacement policy</p>
  </div>
  <div class="page">
    <p>Comparison of Schemes 9</p>
    <p>Scalable &amp; fine-grain</p>
    <p>Strict isolation</p>
    <p>Dynamic</p>
    <p>Maintains assoc.</p>
    <p>Indep. of repl. policy</p>
    <p>Simple</p>
    <p>$</p>
    <p>#</p>
    <p>#</p>
    <p>$</p>
    <p>#</p>
    <p>#</p>
    <p>Way partitioning</p>
    <p>$</p>
    <p>$</p>
    <p>#</p>
    <p>#</p>
    <p>$</p>
    <p>#</p>
    <p>$</p>
    <p>#</p>
    <p>$</p>
    <p>#</p>
    <p>#</p>
    <p>$</p>
    <p>PIPP</p>
    <p>$</p>
    <p>#</p>
    <p>$</p>
    <p>#</p>
    <p>#</p>
    <p>#</p>
    <p>#</p>
    <p>#</p>
    <p>#</p>
    <p>#</p>
    <p>#</p>
    <p>#</p>
    <p>Reconfig. caches</p>
    <p>Page coloring</p>
    <p>Vantage</p>
    <p>Partitions whole cache # # # # $ (most)</p>
  </div>
  <div class="page">
    <p>Outline 10</p>
    <p>! Introduction ! Vantage Cache Partitioning ! Evaluation</p>
  </div>
  <div class="page">
    <p>Vantage Design Overview 11</p>
    <p>minimal interference</p>
  </div>
  <div class="page">
    <p>Analytical Guarantees 12</p>
    <p>! Vantage can be completely characterized using analytical models</p>
    <p># We can prove that strict guarantees are kept on partition</p>
    <p>sizes and interference independently of workload $ The paper has too much math to describe it here ! We now focus on the intuition behind the math</p>
    <p>mRS S</p>
    <p>C C</p>
    <p>A i</p>
    <p>P</p>
    <p>k k P</p>
    <p>k k</p>
    <p>i i</p>
    <p>! =</p>
    <p>&quot; &quot;</p>
    <p>=</p>
    <p>=</p>
    <p>RA S</p>
    <p>P</p>
    <p>i i</p>
    <p>max0</p>
    <p>!&quot;# =mR</p>
    <p>Amgd !</p>
    <p>= 1</p>
    <p>]1,0[,)()(</p>
    <p>},...,max{ ]1,0[...~,...,</p>
    <p>!=&quot;=</p>
    <p>=</p>
    <p>xxxAPxF</p>
    <p>EEA UdiiEE</p>
    <p>R A</p>
    <p>R</p>
    <p>R</p>
    <p>???</p>
  </div>
  <div class="page">
    <p>ZCache [MICRO 2010] 13</p>
    <p>! A highly-associative cache with a low number of ways ! Hits take a single lookup ! In a miss, replacement process</p>
    <p>provides many replacement candidates</p>
    <p>! Provides cheap high associativity (e.g. associativity equivalent to 64 ways with a 4-way cache)</p>
    <p>! Achieves analytical guarantees on associativity</p>
    <p>Indexes</p>
    <p>H0</p>
    <p>H1</p>
    <p>H2</p>
    <p>Line address</p>
    <p>Way0 Way1 Way2</p>
  </div>
  <div class="page">
    <p>Analytical Associativity Guarantees 14</p>
    <p>! Eviction priority: Rank of a line given by the replacement policy (e.g. LRU), normalized to [0,1] ! Higher is better to evict (e.g. LRU line has 1.0 priority, MRU has 0.0)</p>
    <p>! Associativity distribution: Probability distribution of the eviction priorities of evicted lines</p>
    <p>! In a zcache, associativity distribution depends only on the number of replacement candidates (R) ! Independent of ways, workload and replacement policy</p>
    <p>With R=8, 17% of evictions happen to the 80% least evictable lines</p>
    <p>With R=64, 10-6 of evictions happen to the 80% least evictable lines</p>
  </div>
  <div class="page">
    <p>Managed-Unmanaged Region Division 15</p>
    <p>! Logical division (tag each block as managed/unmanaged) ! Unmanaged region large enough to absorb most evictions ! Unmanaged region still used, acts as victim cache (demotion &quot; eviction) ! Single partition with guaranteed size</p>
    <p>Evictions Insertions Demotions</p>
    <p>Managed region</p>
    <p>Unmanaged region</p>
  </div>
  <div class="page">
    <p>Multiple Partitions in Managed Region</p>
    <p>! P partitions + unmanaged region ! Each line is tagged with its partition ID (0 to P-1) ! On each miss:</p>
    <p>! Insert new line into corresponding partition ! Demote one of the candidates to unmanaged region ! Evict from the unmanaged region</p>
    <p>Insertions</p>
    <p>Partition 0 Unmanaged</p>
    <p>region Partition 1</p>
    <p>Partition 2</p>
    <p>Partition 3</p>
    <p>Evictions</p>
    <p>Demotions</p>
  </div>
  <div class="page">
    <p>Churn-Based Management 17</p>
    <p>! Problem: always demoting from inserting partition does not scale ! Could demote from partition 0, but only 3 candidates ! With many partitions, might not even see a candidate from inserting partition!</p>
    <p>! Instead, demote to match insertion rate (churn) and demotion rate</p>
    <p>Get replacement candidates (16)</p>
    <p>Evict from unmanaged region</p>
    <p>Insert new line (in partition 0)</p>
  </div>
  <div class="page">
    <p>Churn-Based Management 18</p>
    <p>! Aperture: Portion of candidates to demote from each partition</p>
    <p>Replacement candidates</p>
    <p>Eviction priorities Evict</p>
    <p>Demote (in top 11% of P3)</p>
    <p>Partition 0 Partition 1 Partition 2 Partition 3</p>
    <p>Eviction priorities</p>
    <p>Evict Nothing is demoted (all candidates above apertures!)</p>
    <p>Eviction priorities Evict</p>
    <p>Demote (in top 23% of P0) Demote (in top 15% of P1)</p>
  </div>
  <div class="page">
    <p>Managing Apertures 19</p>
    <p>! Set each aperture so that partition churn = demotion rate ! Instantaneous partition sizes vary a bit, but sizes are maintained ! Unmanaged region prevents interference</p>
    <p>! Each partition requires aperture proportional to its churn/ size ratio ! Higher churn More frequent insertions (and demotions!) ! Larger size We see lines from that partition more often</p>
    <p>! Partition aperture determines partition associativity ! Higher aperture less selective lower associativity</p>
  </div>
  <div class="page">
    <p>Stability 20</p>
    <p>! In partitions with high churn/size, controlling aperture is sometimes not enough to keep size ! e.g. 1-line partition that misses all the time ! To keep high associativity, set a maximum aperture Amax (e.g. 40%) ! If a partition needs Ai &gt; Amax, we just let it grow</p>
    <p>! Key result: Regardless of the number of partitions that need to grow beyond their target, the worst-case total growth over their target sizes is bounded and small!</p>
    <p>! 5% of the cache with R=52, Amax=0.4 ! Simply size the unmanaged region with that much extra slack ! Stability and scalability are guaranteed</p>
    <p>RA 11</p>
    <p>max</p>
  </div>
  <div class="page">
    <p>A Simple Vantage Controller 21</p>
    <p>! Directly implementing these techniques is impractical ! Must constantly compute apertures, estimate churns ! Need to know eviction priorities of every block</p>
    <p>! Solution: Use negative feedback loops to derive apertures and the lines below aperture ! Practical implementation ! Maintains analytical guarantees</p>
  </div>
  <div class="page">
    <p>Feedback-Based Aperture Control 22</p>
    <p>! Adjust aperture by letting partition size (Si) grow over its target (Ti):</p>
    <p>! Need small extra space in unmanaged region</p>
    <p>! e.g. 0.5% of the cache with R=52, Amax=0.4, slack=10%</p>
    <p>Amax</p>
    <p>Ai</p>
    <p>Ti (1+slack)Ti Si</p>
    <p>Ai</p>
  </div>
  <div class="page">
    <p>Implementation Costs</p>
    <p>! See paper for detailed implementation</p>
    <p>Cache Controller Partition 0</p>
    <p>state (256b) Partition P-1 state (256b)</p>
    <p>Data Array</p>
    <p>Tag Array 256 bits of state per partition</p>
    <p>Line Address Coherence/ Valid Bits</p>
    <p>Timestamp (8b)</p>
    <p>Tags: Extra partition ID field Partition</p>
    <p>(6b)</p>
    <p>Vantage Replacement Logic</p>
    <p>Simple logic, ~10 adders and comparators Logic not on critical path</p>
  </div>
  <div class="page">
    <p>Vantage Summary 24</p>
    <p>! Use a cache with associativity guarantees</p>
    <p>! Maintain an unmanaged region</p>
    <p>! Match insertion and demotion rates in each partition ! Partitions help each other evict lines &quot; maintain associativity ! Unmanaged region guarantees isolation and stability</p>
    <p>! Use negative feedback to simplify implementation</p>
  </div>
  <div class="page">
    <p>Outline 25</p>
    <p>! Introduction ! Vantage Cache Partitioning ! Evaluation</p>
  </div>
  <div class="page">
    <p>Methodology 26</p>
    <p>! Simulations of small (4-core) and large (32-core) systems ! Private L1s, shared non-inclusive L2, 1 partition/core</p>
    <p>! Partitioning policy: Utility-based partitioning [ISCA06] ! Assign more space to threads that can use it better</p>
    <p>! Partitioning schemes: Way-partitioning, PIPP, Vantage</p>
    <p>! Workloads: 350 multiprogrammed mixes from SPECCPU2006 (full suite)</p>
  </div>
  <div class="page">
    <p>Small-Scale: 4 cores, 4 partitions 27</p>
    <p>! Each line shows throughput improvement versus an unpartitioned 16-way set-associative cache</p>
    <p>! Way-partitioning and PIPP degrade throughput for 45% of workloads</p>
  </div>
  <div class="page">
    <p>Small-Scale: 4 cores, 4 partitions 28</p>
    <p>! Vantage works on best on zcaches ! We use Vantage on a 4-way zcache with R=52 replacement</p>
    <p>candidates</p>
  </div>
  <div class="page">
    <p>Small-Scale: 4 cores, 4 partitions 29</p>
    <p>! Vantage improves throughput for most workloads ! 6.2% throughput improvement (gmean), 26% for the 50 most</p>
    <p>memory-intensive workloads</p>
  </div>
  <div class="page">
    <p>Large-Scale: 32 cores, 32 partitions 30</p>
    <p>! Way-partitioning and PIPP use a 64-way set-associative cache ! Both degrade throughput for most workloads</p>
  </div>
  <div class="page">
    <p>Large-Scale: 32 cores, 32 partitions 31</p>
    <p>! Vantage uses the same Z4/52 cache as the 4-core system ! Vantage improves throughput for most workloads &quot; scalable</p>
  </div>
  <div class="page">
    <p>A Closer Look: Sizes &amp; Associativity 32</p>
    <p>Vantage Way-partitioning</p>
    <p>! Vantage maintains strict partition sizes ! Vantage maintains high associativity even in the worst case</p>
  </div>
  <div class="page">
    <p>Additional Results (see paper) 33</p>
    <p>! Vantage maintains strict control of partition sizes ! Vantage maintains high associativity ! Unmanaged region size vs isolation tradeoff</p>
    <p>! ~5% unmanaged region and moderate isolation ! ~20% unmanaged region and strict isolation</p>
    <p>! Validation of analytical models ! Vantage on set-associative caches</p>
    <p>! Loses analytical guarantees, but outperforms other schemes</p>
    <p>! Vantage with other replacement policies (RRIP)</p>
  </div>
  <div class="page">
    <p>Conclusions 34</p>
    <p>! Vantage enables cache partitioning for many-cores ! Tens to hundreds of fine-grain partitions ! High associativity per partition ! Strict isolation among partitions ! Derived from analytical models, bounds independent of</p>
    <p>number of partitions and cache ways ! Simple to implement</p>
  </div>
  <div class="page">
    <p>THANK YOU FOR YOUR ATTENTION</p>
    <p>QUESTIONS?</p>
  </div>
  <div class="page">
    <p>Backup: Associativity Guarantees 36</p>
    <p>! Why does zcache produce uniform random replacement candidates, independently of access pattern?</p>
    <p>! ZCache hashing and replacement scheme eliminates spatial locality</p>
    <p>! Evictions have negligible temporal locality w.r.t. cache ! Evictions to the same block are widely separated in time ! NOTE: Invalidations (e.g. coherence) are not evictions</p>
    <p>! No locality &quot; uniform random</p>
  </div>
  <div class="page">
    <p>Backup: Setpoint-Based Demotions 37</p>
    <p>! Derive portion of lines below aperture without tracking eviction priorities ! Coarse-grain timestamp LRU replacement</p>
    <p>! Tag each block with an 8-bit LRU per-partition timestamp ! Increment timestamp every Si/16 accesses</p>
    <p>! Demote every candidate below the setpoint timestamp ! Adjust setpoint using negative feedback</p>
    <p>Pa rt</p>
    <p>iti on</p>
    <p>li ne</p>
    <p>s d is</p>
    <p>tr ib</p>
    <p>Timestamp 255 0</p>
    <p>Setpoint TS Current TS</p>
    <p>Demote Demote Keep</p>
  </div>
  <div class="page">
    <p>A Closer Look: Partition Sizes 38</p>
    <p>Way-partitioning Vantage PIPP</p>
    <p>$ Coarse-grain partitions</p>
    <p># Strict size</p>
    <p>$ Slow convergence</p>
    <p>$ Coarse-grain partitions</p>
    <p>$ Approximate size</p>
    <p>$ No convergence</p>
    <p># Fine-grain partitions</p>
    <p># Strict size</p>
    <p># Fast convergence</p>
  </div>
  <div class="page">
    <p>Unmanaged Size vs Isolation Trade-off 40</p>
    <p>! A larger unmanaged region reduces UCP perfomance slightly, but gives excellent isolation ! Simulations match analytical models ! See paper for additional results (Vantage on set-associative caches, other replacement</p>
    <p>policies, etc.)</p>
  </div>
</Presentation>
