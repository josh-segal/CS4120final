<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 1</p>
    <p>Ella Rabinovich1,2, Shachar Mirkin1, Raj Nath Patel3, Lucia Specia4, Shuly Wintner2</p>
    <p>Personalized Machine Translation: Preserving Original Author Traits</p>
    <p>EACL 2017, Valencia</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 2</p>
    <p>Background  Personalized Machine Translation</p>
    <p>The language we produce reflects our personality</p>
    <p>Demographics: gender, age, geography etc.</p>
    <p>Personality: extraversion, agreeableness, openness, conscientiousness, neuroticism (the Big Five)</p>
    <p>Authorial traits affect our perception of the content we face</p>
    <p>We may have a preference to a specific authorial style</p>
    <p>Personalized Machine Translation (PMT)</p>
    <p>Preserving authorial traits in manual and machine translation (Mirkin et al., 2015)</p>
    <p>Predicting users translation preference (Mirkin and Meunier, 2015)</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 3</p>
    <p>Background  Authorial Gender</p>
    <p>Male and female speech differs, to an extent distinguishable by automatic classification (Koppel et al., 2002; Schler et al., 2006; Burger et al., 2011)</p>
    <p>Male speakers use nouns and numerals more frequently</p>
    <p>associated with the alleged information emphasis</p>
    <p>Female prominent signals include verbs and pronouns</p>
    <p>e.g., we as a marker of group identity</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 4</p>
    <p>Research Questions</p>
    <p>We focus on SMT adaptation to better preserve authorial gender markers through automatic translation</p>
    <p>Are the prominent authorial signals preserved through translation?</p>
    <p>Human (a translator involved) and machine translation</p>
    <p>Can machine-translation models be adapted to better preserve authorial traits?</p>
    <p>Are authorial traits in translated text retained from the source?</p>
    <p>Do they differ from those of the target language?</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 5</p>
    <p>Datasets</p>
    <p>Europarl - proceedings of the European Parliament</p>
    <p>Automatically annotated1 for speaker gender and age using:</p>
    <p>Wikidata (manually curated dataset)</p>
    <p>Genderize.io (based on persons first name and country)</p>
    <p>Alchemy vision (image classification for gender)</p>
    <p>Estimated accuracy of gender annotation in the dataset is 99.8%</p>
    <p>Based on an evaluation against the Wikidata ground truth</p>
    <p>Michael Cramer (Germany)</p>
    <p>instance of: human sex or gender: male position held: member of the European parliament</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 6</p>
    <p>Datasets (cont.)</p>
    <p>TED talks transcripts</p>
    <p>English-French corpus of IWSLT 2014 Evaluation Campaigns MT track</p>
    <p>Annotated for speaker gender (Mirkin et al., 2015)</p>
    <p>gender / language pair en-fr fr-en en-de de-en</p>
    <p>Europarl</p>
    <p># of sentences by M speakers 100K 67K 101K 88K</p>
    <p># of sentences by F speakers 44K 40K 61K 43K</p>
    <p>additional (not annotated) data 1.7M 1.5M</p>
    <p>TED</p>
    <p># of sentences by M speakers 140K</p>
    <p># of sentences by F speakers 43K</p>
    <p>* the numbers refer to sentences originally uttered in the source language</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 7</p>
    <p>Personalized MT - Approach</p>
    <p>Gender-aware SMT models</p>
    <p>Personalization as a domain-adaptation task</p>
    <p>Gender-specific model components (TM and LM)</p>
    <p>Gender-specific tuning sets</p>
    <p>Baseline model disregarding the gender information</p>
    <p>A single TM and LM is built using male, female and unlabeled data</p>
    <p>Tuning is done using a random sample of sentences</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 8</p>
    <p>Personalized MT Models</p>
    <p>MT-PERS1: a single system with 3 TMs and 3 LMs trained on male (M), female (F) and additional unlabeled data</p>
    <p>Male LM</p>
    <p>Female LM</p>
    <p>Unlabeled LM</p>
    <p>Male TM</p>
    <p>Female TM</p>
    <p>Unlabeled TM</p>
    <p>The model was tuned using the gender-specific tuning set</p>
    <p>Resulting in 2 sub-models that differ in their tuning</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 9</p>
    <p>Personalized MT Models (cont.)</p>
    <p>MT-PERS2: two separate systems, each one comprising gender-specific (M or F), as well as unlabeled TM and LM</p>
    <p>Male LM</p>
    <p>Unlabeled LM</p>
    <p>Male TM</p>
    <p>Unlabeled TM</p>
    <p>Both models were tuned using the gender-specific tuning set</p>
    <p>Female LM</p>
    <p>Unlabeled LM</p>
    <p>Female TM</p>
    <p>Unlabeled TM</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 10</p>
    <p>MT Evaluation Results (BLEU)</p>
    <p>model / language-pair en-fr fr-en en-de de-en</p>
    <p>MT-baseline 38.65 37.65 21.95 26.37</p>
    <p>MT-PERS1 38.42 37.16 21.65 26.35</p>
    <p>MT-PERS2 38.34 37.16 21.80 26.21</p>
    <p>MT-baseline 33.25</p>
    <p>MT-PERS1 33.19</p>
    <p>MT-PERS2 33.16</p>
    <p>Personalized models do not harm MT quality</p>
    <p>Phrase-based SMT  Moses (Koehn et al., 2007)</p>
    <p>Language modeling done using KenLM (Heafield, 2011)</p>
    <p>5-gram LMs with Kneser-Ney smoothing</p>
    <p>Tuning with MERT</p>
    <p>E u</p>
    <p>ro p</p>
    <p>a rl</p>
    <p>T E</p>
    <p>D</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 11</p>
    <p>Preserving Gender Traits  Evaluation</p>
    <p>Binary (M vs F) classification of each model output</p>
    <p>Human- and machine-translation</p>
    <p>Features: frequencies of function words and POS-trigrams</p>
    <p>Stylistic, content-independent features</p>
    <p>Classification units: random chunks of 1K tokens</p>
    <p>Inline with Schler et al., 2006 (classified blog posts)</p>
    <p>Gender classification at small units, e.g., sentence, is practically impossible</p>
    <p>Linear SVM classifier, 10-fold cross-validation evaluation</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 12</p>
    <p>Preserving Gender Traits  Results</p>
    <p>language (-pair) accuracy (%)</p>
    <p>en O 77.3</p>
    <p>fr O 81.4</p>
    <p>fr-en HT 75.0</p>
    <p>fr-en MT-baseline 77.6</p>
    <p>fr-en MT-PERS1 81.4</p>
    <p>fr-en MT-PERS2 80.0</p>
    <p>en-fr HT 56.5</p>
    <p>en-fr MT-baseline 60.1</p>
    <p>en-fr MT-PERS1 62.8</p>
    <p>en-fr MT-PERS2 65.3</p>
    <p>language (-pair) accuracy (%)</p>
    <p>en O 80.4</p>
    <p>en-fr HT 73.8</p>
    <p>en-fr MT-baseline 70.7</p>
    <p>en-fr MT-PERS1 77.2</p>
    <p>en-fr MT-PERS2 77.7</p>
    <p>Binary classification using function words and top-1000 POS-trigrams</p>
    <p>E u</p>
    <p>ro p</p>
    <p>a rl</p>
    <p>T E</p>
    <p>D</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 13</p>
    <p>Preserving Gender Traits  Results</p>
    <p>language (-pair) accuracy (%)</p>
    <p>en O 77.3</p>
    <p>fr O 81.4</p>
    <p>fr-en HT 75.0</p>
    <p>fr-en MT-baseline 77.6</p>
    <p>fr-en MT-PERS1 81.4</p>
    <p>fr-en MT-PERS2 80.0</p>
    <p>en-fr HT 56.5</p>
    <p>en-fr MT-baseline 60.1</p>
    <p>en-fr MT-PERS1 62.8</p>
    <p>en-fr MT-PERS2 65.3</p>
    <p>language (-pair) accuracy (%)</p>
    <p>en O 80.4</p>
    <p>en-fr HT 73.8</p>
    <p>en-fr MT-baseline 70.7</p>
    <p>en-fr MT-PERS1 77.2</p>
    <p>en-fr MT-PERS2 77.7</p>
    <p>Binary classification using function words and top-1000 POS-trigrams</p>
    <p>E u</p>
    <p>ro p</p>
    <p>a rl</p>
    <p>T E</p>
    <p>D</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 14</p>
    <p>Preserving Gender Traits  Results</p>
    <p>language (-pair) accuracy (%)</p>
    <p>en O 77.3</p>
    <p>fr O 81.4</p>
    <p>fr-en HT 75.0</p>
    <p>fr-en MT-baseline 77.6</p>
    <p>fr-en MT-PERS1 81.4</p>
    <p>fr-en MT-PERS2 80.0</p>
    <p>en-fr HT 56.5</p>
    <p>en-fr MT-baseline 60.1</p>
    <p>en-fr MT-PERS1 62.8</p>
    <p>en-fr MT-PERS2 65.3</p>
    <p>language (-pair) accuracy (%)</p>
    <p>en O 80.4</p>
    <p>en-fr HT 73.8</p>
    <p>en-fr MT-baseline 70.7</p>
    <p>en-fr MT-PERS1 77.2</p>
    <p>en-fr MT-PERS2 77.7</p>
    <p>Binary classification using function words and top-1000 POS-trigrams</p>
    <p>E u</p>
    <p>ro p</p>
    <p>a rl</p>
    <p>T E</p>
    <p>D</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 15</p>
    <p>Preserving Gender Traits  Results</p>
    <p>language (-pair) accuracy (%)</p>
    <p>en O 77.3</p>
    <p>fr O 81.4</p>
    <p>fr-en HT 75.0</p>
    <p>fr-en MT-baseline 77.6</p>
    <p>fr-en MT-PERS1 81.4</p>
    <p>fr-en MT-PERS2 80.0</p>
    <p>en-fr HT 56.5</p>
    <p>en-fr MT-baseline 60.1</p>
    <p>en-fr MT-PERS1 62.8</p>
    <p>en-fr MT-PERS2 65.3</p>
    <p>language (-pair) accuracy (%)</p>
    <p>en O 80.4</p>
    <p>en-fr HT 73.8</p>
    <p>en-fr MT-baseline 70.7</p>
    <p>en-fr MT-PERS1 77.2</p>
    <p>en-fr MT-PERS2 77.7</p>
    <p>Binary classification using function words and top-1000 POS-trigrams</p>
    <p>E u</p>
    <p>ro p</p>
    <p>a rl</p>
    <p>T E</p>
    <p>D</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 16</p>
    <p>Preserving Gender Traits  Results</p>
    <p>language (-pair) accuracy (%)</p>
    <p>en O 77.3</p>
    <p>fr O 81.4</p>
    <p>fr-en HT 75.0</p>
    <p>fr-en MT-baseline 77.6</p>
    <p>fr-en MT-PERS1 81.4</p>
    <p>fr-en MT-PERS2 80.0</p>
    <p>en-fr HT 56.5</p>
    <p>en-fr MT-baseline 60.1</p>
    <p>en-fr MT-PERS1 62.8</p>
    <p>en-fr MT-PERS2 65.3</p>
    <p>language (-pair) accuracy (%)</p>
    <p>en O 80.4</p>
    <p>en-fr HT 73.8</p>
    <p>en-fr MT-baseline 70.7</p>
    <p>en-fr MT-PERS1 77.2</p>
    <p>en-fr MT-PERS2 77.7</p>
    <p>Binary classification using function words and top-1000 POS-trigrams</p>
    <p>E u</p>
    <p>ro p</p>
    <p>a rl</p>
    <p>T E</p>
    <p>D</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 17</p>
    <p>Preserving Gender Traits  Results</p>
    <p>language (-pair) accuracy (%)</p>
    <p>en O 77.3</p>
    <p>fr O 81.4</p>
    <p>fr-en HT 75.0</p>
    <p>fr-en MT-baseline 77.6</p>
    <p>fr-en MT-PERS1 81.4</p>
    <p>fr-en MT-PERS2 80.0</p>
    <p>en-fr HT 56.5</p>
    <p>en-fr MT-baseline 60.1</p>
    <p>en-fr MT-PERS1 62.8</p>
    <p>en-fr MT-PERS2 65.3</p>
    <p>language (-pair) accuracy (%)</p>
    <p>en O 80.4</p>
    <p>en-fr HT 73.8</p>
    <p>en-fr MT-baseline 70.7</p>
    <p>en-fr MT-PERS1 77.2</p>
    <p>en-fr MT-PERS2 77.7</p>
    <p>Binary classification using function words and top-1000 POS-trigrams</p>
    <p>E u</p>
    <p>ro p</p>
    <p>a rl</p>
    <p>T E</p>
    <p>D</p>
    <p>* similar results obtained for en-de and de-en translations</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 18</p>
    <p>Analysis  Gender Markers</p>
    <p>Are gender markers of the original language preserved in translation?</p>
    <p>Distribution of individual gender markers varies between languages</p>
    <p>English: must is a male marker</p>
    <p>French: doit and doivent are more frequent in female speech</p>
    <p>English: we exhibits nearly equal frequencies in male and female texts</p>
    <p>German: wir is a prominent female marker</p>
    <p>Translations tend to embrace gender tendencies of the original language</p>
    <p>Resulting in a hybrid outcome where M and F traits are affected both by markers of the source and (to a much lesser extent) the target language</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 19</p>
    <p>Analysis (cont.)</p>
    <p>Weights assigned to various gender marker by InfoGain attribute evaluator</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 20</p>
    <p>Summary</p>
    <p>State-of-the-art NMT models for personalization in translation</p>
    <p>Additional domains, datasets and language-pairs</p>
    <p>Additional authorial traits, e.g., age</p>
    <p>Future work</p>
    <p>Author gender is strongly marked in original texts</p>
    <p>This signal is obfuscated in human and machine translation</p>
    <p>Simple personalized SMT models using standard domain adaptation techniques offer a good approach for preserving gender traits in automatic translation</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 21</p>
    <p>Backup</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 22</p>
    <p>Preserving Gender Traits - Evaluation</p>
    <p>Translations and original texts constitute distinct language variants</p>
    <p>Distinguishable by text classification techniques</p>
    <p>We found that the signal of translation overshadows that of gender</p>
    <p>Multivariate data color-separated by two dimensions (using function words as features)</p>
    <p>We therefore evaluate the signal of gender by classification of M vs F texts separately in original, human- and machine-translated texts</p>
    <p>A gender classifier trained on originals fails to predict gender in translations</p>
    <p>original (M+F) and</p>
    <p>translated (M+F) texts</p>
    <p>are easily separable gender signal is inferior to the</p>
    <p>signal of translation in the</p>
    <p>two-dimensional data</p>
    <p>male vs female manually-translated vs original</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 23</p>
    <p>Analysis (en-de)</p>
  </div>
  <div class="page">
    <p>PERSONALIZED MACHINE TRANSLATION: PRESERVING ORIGINAL AUTHOR TRAITS APR 2017 24</p>
    <p>Capturing the personalization effect</p>
    <p>The French vraiment in male utterance is translated as really by the gender-agnostic (and</p>
    <p>human) models, and as exactly by the personalized version; in German example, a female utterance</p>
    <p>is translated as English female marker think, compared to the more neutral believe and consider</p>
  </div>
</Presentation>
