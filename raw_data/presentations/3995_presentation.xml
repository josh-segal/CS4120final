<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>PriBots</p>
    <p>Hamza Harkous1, Kassem Fawaz2, Kang. G. Shin2, Karl Aberer1 1EPFL; 2University of Michigan</p>
    <p>Conversational Privacy with Chatbots</p>
    <p>Workshop on the Future of Privacy Notices and Indicators, SOUPS 2016</p>
  </div>
  <div class="page">
    <p>Privacy Notice: Current State</p>
  </div>
  <div class="page">
    <p>legally binding</p>
    <p>human understandable</p>
    <p>Dual Role:</p>
    <p>Privacy Notice: Current State</p>
  </div>
  <div class="page">
    <p>Can we split these roles?</p>
    <p>legally binding</p>
    <p>human understandable</p>
    <p>Dual Role:</p>
    <p>Privacy Notice: Current State</p>
  </div>
  <div class="page">
    <p>Figure 1. An example of a standardized table is shown on the left, and a standardized short table on the right. The comparison highlights the rows</p>
    <p>deleted to shorten this version. These deleted rows are listed directly below the table. While both formats contain the legend (bottom right), it is</p>
    <p>displayed only on the right here due to space constraints.</p>
    <p>have already been deployed by major corporations, making them a viable, real world summary format for privacy policies. These policies were stripped of brand information, but the formatting and styles were retained.</p>
    <p>METHODOLOGY We conducted an online user study in summer 2009 using Amazons Mechanical Turk and a tool we developed called Surveyors Point. Mechanical Turk offers workers the ability to perform short tasks and get compensated. People can place jobs through Mechanical Turk, specifying the number of workers they are looking for, necessary qualifications, the amount they are willing to pay, and details about the task. Mechanical Turk payments are generally calibrated for the length of the task. For our approximately 15-minute study, we paid $0.75 on successful completion.</p>
    <p>We developed a custom survey-management tool called Surveyors Point to facilitate our data collection. Our implementation allows us to show respondents a single question on the screen along with links for switching back and forth between two policies within a single browser window. This allowed us to track the number of users who looked at each policy and the number of times they switched between them. Additionally, Surveyors Point allowed us to collect the amount of time that users spent reading the policies, as well as information about whether they clicked through to opt-out forms, to additional policy information links, or from a layered notice through to the full text policy.</p>
    <p>In preparation for this study we first performed three smaller pilot tests of our survey framework. We ran our pilot studies with approximately thirty users each, across 2-3 conditions. Our pilot studies helped us to finalize remaining design decisions surrounding the standardized short table, refine our questionnaire, and test the integration of Surveyors Point with Mechanical Turk.2</p>
    <p>We then conducted our large-scale study and completed the analysis with 764 participants (409 female, 355 male), randomly assigned to five conditions (see Table 1): full policy text, standardized table, standardized short table, standardized short text, and layered text. We dropped 25 additional participants from the study prior to analysis due to incomplete data or for completing the study in an amount of time that indicated inadequate attention to the task (defined as time on task that was two standard deviations lower than the mean). We chose a between-subjects design to remove learning effects and ensure the study could be completed within about 15 minutes. Participants in each condition followed the same protocol; only the policy format differed.</p>
    <p>Policies We selected policies for the study from companies that consumers would conceivably interact with. We narrowed our</p>
    <p>Standardization</p>
  </div>
  <div class="page">
    <p>Figure 1. An example of a standardized table is shown on the left, and a standardized short table on the right. The comparison highlights the rows</p>
    <p>deleted to shorten this version. These deleted rows are listed directly below the table. While both formats contain the legend (bottom right), it is</p>
    <p>displayed only on the right here due to space constraints.</p>
    <p>have already been deployed by major corporations, making them a viable, real world summary format for privacy policies. These policies were stripped of brand information, but the formatting and styles were retained.</p>
    <p>METHODOLOGY We conducted an online user study in summer 2009 using Amazons Mechanical Turk and a tool we developed called Surveyors Point. Mechanical Turk offers workers the ability to perform short tasks and get compensated. People can place jobs through Mechanical Turk, specifying the number of workers they are looking for, necessary qualifications, the amount they are willing to pay, and details about the task. Mechanical Turk payments are generally calibrated for the length of the task. For our approximately 15-minute study, we paid $0.75 on successful completion.</p>
    <p>We developed a custom survey-management tool called Surveyors Point to facilitate our data collection. Our implementation allows us to show respondents a single question on the screen along with links for switching back and forth between two policies within a single browser window. This allowed us to track the number of users who looked at each policy and the number of times they switched between them. Additionally, Surveyors Point allowed us to collect the amount of time that users spent reading the policies, as well as information about whether they clicked through to opt-out forms, to additional policy information links, or from a layered notice through to the full text policy.</p>
    <p>In preparation for this study we first performed three smaller pilot tests of our survey framework. We ran our pilot studies with approximately thirty users each, across 2-3 conditions. Our pilot studies helped us to finalize remaining design decisions surrounding the standardized short table, refine our questionnaire, and test the integration of Surveyors Point with Mechanical Turk.2</p>
    <p>We then conducted our large-scale study and completed the analysis with 764 participants (409 female, 355 male), randomly assigned to five conditions (see Table 1): full policy text, standardized table, standardized short table, standardized short text, and layered text. We dropped 25 additional participants from the study prior to analysis due to incomplete data or for completing the study in an amount of time that indicated inadequate attention to the task (defined as time on task that was two standard deviations lower than the mean). We chose a between-subjects design to remove learning effects and ensure the study could be completed within about 15 minutes. Participants in each condition followed the same protocol; only the policy format differed.</p>
    <p>Policies We selected policies for the study from companies that consumers would conceivably interact with. We narrowed our</p>
    <p>Standardization</p>
    <p>Summarization</p>
  </div>
  <div class="page">
    <p>Figure 1. An example of a standardized table is shown on the left, and a standardized short table on the right. The comparison highlights the rows</p>
    <p>deleted to shorten this version. These deleted rows are listed directly below the table. While both formats contain the legend (bottom right), it is</p>
    <p>displayed only on the right here due to space constraints.</p>
    <p>have already been deployed by major corporations, making them a viable, real world summary format for privacy policies. These policies were stripped of brand information, but the formatting and styles were retained.</p>
    <p>METHODOLOGY We conducted an online user study in summer 2009 using Amazons Mechanical Turk and a tool we developed called Surveyors Point. Mechanical Turk offers workers the ability to perform short tasks and get compensated. People can place jobs through Mechanical Turk, specifying the number of workers they are looking for, necessary qualifications, the amount they are willing to pay, and details about the task. Mechanical Turk payments are generally calibrated for the length of the task. For our approximately 15-minute study, we paid $0.75 on successful completion.</p>
    <p>We developed a custom survey-management tool called Surveyors Point to facilitate our data collection. Our implementation allows us to show respondents a single question on the screen along with links for switching back and forth between two policies within a single browser window. This allowed us to track the number of users who looked at each policy and the number of times they switched between them. Additionally, Surveyors Point allowed us to collect the amount of time that users spent reading the policies, as well as information about whether they clicked through to opt-out forms, to additional policy information links, or from a layered notice through to the full text policy.</p>
    <p>In preparation for this study we first performed three smaller pilot tests of our survey framework. We ran our pilot studies with approximately thirty users each, across 2-3 conditions. Our pilot studies helped us to finalize remaining design decisions surrounding the standardized short table, refine our questionnaire, and test the integration of Surveyors Point with Mechanical Turk.2</p>
    <p>We then conducted our large-scale study and completed the analysis with 764 participants (409 female, 355 male), randomly assigned to five conditions (see Table 1): full policy text, standardized table, standardized short table, standardized short text, and layered text. We dropped 25 additional participants from the study prior to analysis due to incomplete data or for completing the study in an amount of time that indicated inadequate attention to the task (defined as time on task that was two standard deviations lower than the mean). We chose a between-subjects design to remove learning effects and ensure the study could be completed within about 15 minutes. Participants in each condition followed the same protocol; only the policy format differed.</p>
    <p>Policies We selected policies for the study from companies that consumers would conceivably interact with. We narrowed our</p>
    <p>Standardization</p>
    <p>Summarization</p>
    <p>Challeng es</p>
    <p>one size fits all</p>
    <p>user edu cation</p>
  </div>
  <div class="page">
    <p>Privacy Choice: Current State</p>
  </div>
  <div class="page">
    <p>fragmented ecosystem</p>
    <p>difficult to find</p>
    <p>Privacy Choice: Current State</p>
  </div>
  <div class="page">
    <p>Conversation-first Interfaces</p>
  </div>
  <div class="page">
    <p>The Rise of Conversational UI</p>
  </div>
  <div class="page">
    <p>PriBots: Conversational Privacy Bots</p>
    <p>Message|</p>
  </div>
  <div class="page">
    <p>PriBots: Conversational Privacy Bots</p>
    <p>Message|</p>
  </div>
  <div class="page">
    <p>PriBots: Conversational Privacy Bots</p>
    <p>Message|</p>
    <p>Appeal to new tech adopters</p>
  </div>
  <div class="page">
    <p>PriBots: Conversational Privacy Bots</p>
    <p>Message|</p>
    <p>Appeal to new tech adopters</p>
    <p>Appeal to existing users</p>
  </div>
  <div class="page">
    <p>PriBots: Conversational Privacy Bots</p>
    <p>Message|</p>
    <p>Appeal to new tech adopters</p>
    <p>Appeal to existing users</p>
    <p>An intuitive way to 1. communicate privacy policies 2. adjust privacy preferences</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Ch ann</p>
    <p>el</p>
  </div>
  <div class="page">
    <p>Ch ann</p>
    <p>el</p>
    <p>Primary 9</p>
  </div>
  <div class="page">
    <p>Ch ann</p>
    <p>el</p>
    <p>Primary Secondary 9</p>
  </div>
  <div class="page">
    <p>Tim ing</p>
  </div>
  <div class="page">
    <p>Tim ing</p>
    <p>At-setup</p>
  </div>
  <div class="page">
    <p>Tim ing</p>
    <p>At-setup On-demand</p>
  </div>
  <div class="page">
    <p>Fee dba</p>
    <p>ck</p>
    <p>implicit: sentiment analysis</p>
    <p>explicit: structured messages</p>
    <p>gathering users concerns</p>
  </div>
  <div class="page">
    <p>Voicing User Concerns</p>
    <p>Providers traditionally</p>
    <p>say what they want</p>
  </div>
  <div class="page">
    <p>Voicing User Concerns</p>
    <p>Providers traditionally</p>
    <p>say what they want</p>
    <p>Users concerns might not</p>
    <p>be covered</p>
  </div>
  <div class="page">
    <p>Voicing User Concerns</p>
    <p>Providers traditionally</p>
    <p>say what they want</p>
    <p>Users concerns might not</p>
    <p>be covered</p>
    <p>PriBots activate the</p>
    <p>two-way channel</p>
  </div>
  <div class="page"/>
  <div class="page"/>
  <div class="page">
    <p>Service and platform-dependent interface</p>
  </div>
  <div class="page">
    <p>Service and platform-dependent interface Tradeoffs for simplicity: try finding this setting on Mobile Web version</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Unique interface with all functionalities Ability to suggest adjustments to the user (combining notice and choice/preferences )</p>
  </div>
  <div class="page">
    <p>User Input</p>
    <p>Analysis &amp; Classification</p>
    <p>System Architecture</p>
  </div>
  <div class="page">
    <p>User Input</p>
    <p>Analysis &amp; Classification</p>
    <p>Query Structured Query</p>
    <p>Statement</p>
    <p>Yes</p>
    <p>No</p>
    <p>System Architecture</p>
  </div>
  <div class="page">
    <p>User Input</p>
    <p>Analysis &amp; Classification</p>
    <p>Query Structured Query</p>
    <p>Statement</p>
    <p>Yes</p>
    <p>No</p>
    <p>Retrieval Module</p>
    <p>Result</p>
    <p>Knowledge Base</p>
    <p>System Architecture</p>
  </div>
  <div class="page">
    <p>User Input</p>
    <p>Analysis &amp; Classification</p>
    <p>Query Structured Query</p>
    <p>Statement</p>
    <p>Yes</p>
    <p>No</p>
    <p>Confident? Answer</p>
    <p>Formulation in NL</p>
    <p>Fallback Answer</p>
    <p>Generation</p>
    <p>Yes</p>
    <p>No</p>
    <p>Retrieval Module</p>
    <p>Result</p>
    <p>Knowledge Base</p>
    <p>System Architecture</p>
  </div>
  <div class="page">
    <p>PriBot Reply</p>
    <p>User Input</p>
    <p>Analysis &amp; Classification</p>
    <p>Query Structured Query</p>
    <p>Statement</p>
    <p>Yes</p>
    <p>No</p>
    <p>Confident? Answer</p>
    <p>Formulation in NL</p>
    <p>Fallback Answer</p>
    <p>Generation</p>
    <p>Yes</p>
    <p>No</p>
    <p>Retrieval Module</p>
    <p>Result</p>
    <p>Knowledge Base</p>
    <p>System Architecture</p>
  </div>
  <div class="page">
    <p>PriBot Reply</p>
    <p>User Input</p>
    <p>Analysis &amp; Classification</p>
    <p>Query Structured Query</p>
    <p>Statement</p>
    <p>Yes</p>
    <p>No</p>
    <p>Confident? Answer</p>
    <p>Formulation in NL</p>
    <p>Fallback Answer</p>
    <p>Generation</p>
    <p>Yes</p>
    <p>No</p>
    <p>Retrieval Module</p>
    <p>Result</p>
    <p>Knowledge Base</p>
    <p>System Architecture</p>
    <p>Feedback DB</p>
    <p>Analytics Amendments/ Improvements</p>
    <p>Augment the Knowledge Base</p>
    <p>unanswered queries  frequent questions  user sentiments</p>
    <p>Feedback DB</p>
  </div>
  <div class="page">
    <p>Challenges</p>
  </div>
  <div class="page">
    <p>Mature User Understanding Text processing</p>
    <p>Question answering</p>
    <p>Domain-specific datasets and ontologies</p>
    <p>Graceful fallback</p>
  </div>
  <div class="page">
    <p>Legal Challenges</p>
    <p>Inherently error prone: are they legally binding?</p>
    <p>Accounting for false-positives and false-negatives</p>
    <p>The case of 3rd party PriBots: defamation possibilities?</p>
  </div>
  <div class="page">
    <p>Trusting the Machine rule-based vs. AI-based</p>
    <p>user backlash?</p>
    <p>regulate the confidence level</p>
  </div>
  <div class="page">
    <p>PriBots Personality</p>
    <p>positive tone  higher trust</p>
    <p>diversified content  reduced habituation</p>
  </div>
  <div class="page">
    <p>De plo</p>
    <p>ym ent</p>
  </div>
  <div class="page">
    <p>provider</p>
    <p>De plo</p>
    <p>ym ent</p>
  </div>
  <div class="page">
    <p>provider</p>
    <p>De plo</p>
    <p>ym ent</p>
    <p>Suitable for Voice Assistants</p>
  </div>
  <div class="page">
    <p>Rule-based Prototype</p>
    <p>System Implementation</p>
    <p>User studies</p>
    <p>Whats Next?</p>
    <p>Privacy as a Dialogue</p>
  </div>
  <div class="page">
    <p>Questions/Feedback?</p>
    <p>hamza.harkous@gmail.com hamzaharkous.com</p>
  </div>
  <div class="page">
    <p>Image/Media Credits Zara Picken: slide 12 Egor Kosten: slide 24 Alex Prokhoda: slide 6 Freepik: slide 23 Geoff Keough: slide 14 Victor: slide 12</p>
  </div>
</Presentation>
