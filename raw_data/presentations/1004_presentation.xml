<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Preemptive, Low Latency Datacenter Scheduling via Lightweight Virtualization</p>
    <p>Wei Chen, Jia Rao*, and Xiaobo Zhou University of Colorado, Colorado Springs</p>
    <p>* University of Texas at Arlington</p>
  </div>
  <div class="page">
    <p>Data Center Computing</p>
    <p>Challenges - Increase hardware utilization and efficiency - Meet SLOs</p>
    <p>Heterogeneous workloads - Diverse resource demands</p>
    <p>Short jobs v.s. long jobs</p>
    <p>- Different QoS requirements  Latency v.s. throughput</p>
  </div>
  <div class="page">
    <p>Data Center Computing</p>
    <p>Challenges - Increase hardware utilization and efficiency - Meet SLOs</p>
    <p>Heterogeneous workloads - Diverse resource demands</p>
    <p>Short jobs v.s. long jobs</p>
    <p>- Different QoS requirements  Latency v.s. throughput</p>
    <p>Long jobs help improve hardware utilization while short jobs are</p>
    <p>important to QoS</p>
  </div>
  <div class="page">
    <p>Data Center Trace Analysis</p>
    <p>Google traces (https://github.com/google/cluster-data)</p>
    <p>Tasks are evicted if encountering resource shortage</p>
  </div>
  <div class="page">
    <p>Data Center Trace Analysis</p>
    <p>Google traces (https://github.com/google/cluster-data)</p>
    <p>Short jobs have higher priority and most preempted (evicted) tasks belong to long jobs</p>
    <p>Tasks are evicted if encountering resource shortage</p>
  </div>
  <div class="page">
    <p>Overhead of Kill-based Preemption</p>
    <p>Spark</p>
    <p>Pagerank Kmeans Bayes Wordcount Terasort</p>
    <p>MapReduce</p>
    <p>Wordcount Grep RandWrite Terasort SelfJoin</p>
    <p>synchronization and the re-computation of failed RDDs</p>
    <p>N or</p>
    <p>m al</p>
    <p>iz ed</p>
    <p>s lo</p>
    <p>w do</p>
    <p>w n</p>
    <p>N or</p>
    <p>m al</p>
    <p>iz ed</p>
    <p>s lo</p>
    <p>w do</p>
    <p>w n</p>
    <p>Map-heavy Reduce-heavy</p>
  </div>
  <div class="page">
    <p>Our Approach</p>
    <p>Container-based task preemption - Containerize tasks using docker and control resource via cgroup - Task preemption without losing the execution progress</p>
    <p>Suspension: reclaim resources from a preempted task</p>
    <p>Resumption: re-activate a task by restoring its resource</p>
    <p>Preemptive fair share scheduler - Augment the capacity scheduler in YARN with preemptive task scheduling and</p>
    <p>fine-grained resource reclamation</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>Optimizations for heterogeneous workloads - YARN [SoCC13]: kill long jobs if needed - Sparrow [SOSP13]: decentralized scheduler for short jobs - Hawk [ATC15]: hybrid scheduler based on reservation</p>
    <p>Task preemption - Natjam [SoCC13], Amoeba [SoCC12]: proactive checkpointing - CRIU [Middleware15]: on-demand checkpointing</p>
    <p>Task containerization - Google Borg [EuroSys15]: mainly for task isolation</p>
    <p>Long job slowdown and resource waste</p>
    <p>No mechanism for preemption</p>
    <p>Hard to determine optimal reservation</p>
    <p>Hard to decide frequency</p>
    <p>Application changes required</p>
    <p>Still kill-based preemption</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>Optimizations for heterogeneous workloads - YARN [SoCC13]: kill long jobs if needed - Sparrow [SOSP13]: decentralized scheduler for short jobs - Hawk [ATC15]: hybrid scheduler based on reservation</p>
    <p>Task preemption - Natjam [SoCC13], Amoeba [SoCC12]: proactive checkpointing - CRIU [Middleware15]: on-demand checkpointing</p>
    <p>Task containerization - Google Borg [EuroSys15]: mainly for task isolation</p>
    <p>Long job slowdown and resource waste</p>
    <p>No mechanism for preemption</p>
    <p>Hard to determine optimal reservation</p>
    <p>Hard to decide frequency</p>
    <p>Application changes required</p>
    <p>Still kill-based preemption</p>
    <p>If short jobs can timely preempt long jobs  No need for cluster reservation  Preserving long jobs progress  Application agnostic  Fine-grained resource management</p>
  </div>
  <div class="page">
    <p>Container-based Task Preemption</p>
    <p>Task containerization - Launch tasks in Docker containers</p>
    <p>- Use cgroup to control resource allocation, i.e., CPU and memory</p>
    <p>Task suspension - Stop task execution: deprive task of CPU - Save task context: reclaim container memory and write dirty memory pages onto disk</p>
    <p>Task resumption - Restore task resources</p>
  </div>
  <div class="page">
    <p>Task Suspension and Resumption</p>
    <p>Keep a minimum footprint for a preempted task: 64MB memory and 1% CPU</p>
    <p>Reclaim memory</p>
    <p>Restore memory</p>
    <p>Deprive CPU</p>
    <p>Restore CPU &amp; memory</p>
  </div>
  <div class="page">
    <p>Task Suspension and Resumption</p>
    <p>Keep a minimum footprint for a preempted task: 64MB memory and 1% CPU</p>
    <p>Reclaim memory</p>
    <p>Restore memory</p>
    <p>Deprive CPU</p>
    <p>Restore CPU &amp; memory</p>
    <p>Suspended task is alive, but does not make progress or affect other tasks</p>
  </div>
  <div class="page">
    <p>Two Types of Preemption</p>
  </div>
  <div class="page">
    <p>BIG-C: Preemptive Cluster Scheduling</p>
    <p>NodeNode</p>
    <p>Resource Manager</p>
    <p>Resource Monitor Scheduler</p>
    <p>Preemption Decision</p>
    <p>Request</p>
    <p>La un</p>
    <p>ch Re</p>
    <p>lea se</p>
    <p>Heartbeat</p>
    <p>Node</p>
    <p>Node Manager</p>
    <p>Task Container Allocator</p>
    <p>Launch</p>
    <p>Container Monitor</p>
    <p>S/R</p>
    <p>Application Master</p>
    <p>Container allocator - Replaces YARNs nominal</p>
    <p>container with docker</p>
    <p>Container monitor - Performs container suspend and</p>
    <p>resume (S/R) operations</p>
    <p>Resource monitor &amp; Scheduler - Determine how much resource</p>
    <p>and which container to preempt</p>
    <p>Source code available at https://github.com/yncxcw/big-c</p>
  </div>
  <div class="page">
    <p>YARNs Capacity Scheduler</p>
    <p>Capacity scheduler</p>
    <p>Cluster resource</p>
    <p>task</p>
    <p>task</p>
    <p>task</p>
    <p>task</p>
    <p>DRF</p>
    <p>Work conserving, use more than fair share if rsc is available</p>
  </div>
  <div class="page">
    <p>YARNs Capacity Scheduler</p>
    <p>Capacity scheduler</p>
    <p>Cluster resource</p>
    <p>task</p>
    <p>task</p>
    <p>task</p>
    <p>task</p>
    <p>DRF</p>
    <p>Work conserving, use more than fair share if rsc is available</p>
  </div>
  <div class="page">
    <p>YARNs Capacity Scheduler</p>
    <p>Capacity scheduler</p>
    <p>Cluster resource</p>
    <p>task</p>
    <p>task</p>
    <p>task</p>
    <p>task</p>
    <p>DRF</p>
    <p>Work conserving, use more than fair share if rsc is available</p>
  </div>
  <div class="page">
    <p>YARNs Capacity Scheduler</p>
    <p>Capacity scheduler</p>
    <p>Cluster resource</p>
    <p>task</p>
    <p>task</p>
    <p>task</p>
    <p>task</p>
    <p>DRF</p>
    <p>Work conserving, use more than fair share if rsc is available</p>
    <p>At least kill one long task</p>
    <p>Rsc reclamation does not enforce DRF</p>
  </div>
  <div class="page">
    <p>Preemptive Fair Share Scheduler</p>
    <p>Preemptive fair sharing</p>
    <p>Cluster resource</p>
    <p>task</p>
    <p>task</p>
    <p>task</p>
    <p>task</p>
    <p>DRF</p>
    <p>Work conserving, use more than fair share if rsc is available</p>
    <p>Cap acit</p>
    <p>y sc hed</p>
    <p>uler</p>
    <p>VO ID</p>
  </div>
  <div class="page">
    <p>Preemptive Fair Share Scheduler</p>
    <p>Preemptive fair sharing</p>
    <p>Cluster resource</p>
    <p>task</p>
    <p>task</p>
    <p>task</p>
    <p>task</p>
    <p>DRF</p>
    <p>Work conserving, use more than fair share if rsc is available</p>
    <p>Cap acit</p>
    <p>y sc hed</p>
    <p>uler</p>
    <p>VO ID</p>
  </div>
  <div class="page">
    <p>Preemptive Fair Share Scheduler</p>
    <p>Preemptive fair sharing</p>
    <p>Cluster resource</p>
    <p>task</p>
    <p>task</p>
    <p>task</p>
    <p>task</p>
    <p>DRF</p>
    <p>Work conserving, use more than fair share if rsc is available</p>
    <p>Cap acit</p>
    <p>y sc hed</p>
    <p>uler</p>
    <p>VO ID</p>
  </div>
  <div class="page">
    <p>Preemptive Fair Share Scheduler</p>
    <p>Preemptive fair sharing</p>
    <p>Cluster resource</p>
    <p>task</p>
    <p>task</p>
    <p>task</p>
    <p>task</p>
    <p>DRF</p>
    <p>Work conserving, use more than fair share if rsc is available</p>
    <p>Preempt part of task rsc</p>
    <p>Cap acit</p>
    <p>y sc hed</p>
    <p>uler</p>
    <p>VO ID</p>
    <p>Enforce DRF, avoid unnecessary reclamation</p>
  </div>
  <div class="page">
    <p>Compute DR at Task Preemption</p>
    <p>CPU</p>
    <p>MEM</p>
    <p>CPU</p>
    <p>MEM</p>
    <p>CPU</p>
    <p>MEM</p>
    <p>CPU</p>
    <p>MEM</p>
    <p>CPU</p>
    <p>MEM</p>
    <p>CPU</p>
    <p>MEM</p>
  </div>
  <div class="page">
    <p>Compute DR at Task Preemption</p>
    <p>CPU</p>
    <p>MEM</p>
    <p>CPU</p>
    <p>MEM</p>
    <p>CPU</p>
    <p>MEM</p>
    <p>CPU</p>
    <p>MEM</p>
    <p>CPU</p>
    <p>MEM</p>
    <p>CPU</p>
    <p>MEM</p>
  </div>
  <div class="page">
    <p>Container Preemption Algorithm</p>
    <p>Choose a container c from the preempted job</p>
    <p>Choose a job with the longest remaining time</p>
    <p>Yes</p>
    <p>No</p>
    <p>No</p>
    <p>END</p>
    <p>Yes</p>
  </div>
  <div class="page">
    <p>Container Preemption Algorithm</p>
    <p>Choose a container c from the preempted job</p>
    <p>Choose a job with the longest remaining time</p>
    <p>Yes</p>
    <p>No</p>
    <p>No</p>
    <p>END</p>
    <p>Yes</p>
  </div>
  <div class="page">
    <p>Optimizations</p>
    <p>Disable speculative execution of preempted tasks - Suspended tasks appear to be slow to the cluster manager and will likely trigger</p>
    <p>futile speculative execution</p>
    <p>Delayed task resubmission - Tasks may be resubmitted immediately after preemption, causing them to be</p>
    <p>suspended again. A suspended task is required to perform D attempts before it is re-admitted</p>
  </div>
  <div class="page">
    <p>Experimental Settings</p>
    <p>Hardware - 26-node cluster; 32 cores, 128GB on each node; 10Gbps Ethernet, RAID-5 HDDs</p>
    <p>Software - Hadoop-2.7.1, Docker-1.12.1</p>
    <p>Cluster configuration - Two queues: 95% and 5% shares for short and long jobs queues, respectively - Schedulers: FIFO (no preemption), Reserve (60% capacity for short jobs), Kill, IP and GP - Workloads: Spark-SQL as short jobs and HiBench benchmarks as long jobs</p>
  </div>
  <div class="page">
    <p>Synthetic Workloads</p>
    <p>High, low, and multiple bursts of short jobs. Long jobs persistently utilize 80% of cluster capacity</p>
    <p>Time (S)</p>
    <p>Cl us</p>
    <p>te r u</p>
    <p>til iz</p>
    <p>at io</p>
    <p>n (%</p>
    <p>)</p>
  </div>
  <div class="page">
    <p>Short Job Latency with Spark</p>
    <p>FIFO is the worst due to the inability to preempt long jobs</p>
    <p>Reserve underperforms due to lack of reserved capacity under high-load</p>
    <p>GP is better than IP due to less resource reclamation time or swapping</p>
    <p>JCT (S) JCT (S) JCT (S)</p>
    <p>CD F</p>
    <p>Low-load High-load Multi-load</p>
  </div>
  <div class="page">
    <p>Performance of Long Spark Jobs</p>
    <p>FIFO is the reference performance for long jobs  GP achieves on average 60% improvement over Kill.  IP incurs significant overhead to Spark jobs:</p>
    <p>- aggressive resource reclamation causes system-wide swapping - completely suspended tasks impede overall job progress</p>
    <p>FIFO Reserve Kill IP GP FIFO Reserve Kill IP GP FIFO Reserve Kill IP GP</p>
    <p>JC T</p>
    <p>(s )</p>
    <p>Low-load High-load Multi-load</p>
  </div>
  <div class="page">
    <p>Short Job Latency with MapReduce</p>
    <p>FIFO (not shown) incurs 15-20 mins slowdown to short jobs</p>
    <p>Re-submissions of killed MapReduce jobs block short jobs</p>
    <p>IP and GP achieve similar performance</p>
    <p>Low-load High-load Multi-load</p>
    <p>CD F</p>
    <p>JCT (S) JCT (S) JCT (S)</p>
  </div>
  <div class="page">
    <p>Performance of Long MapReduce Jobs</p>
    <p>Kill performs well for map-heavy workloads  IP and GP show similar performance for MapReduce workloads</p>
    <p>- MapReduce tasks are loosely coupled - A suspended task does not stop the entire job</p>
    <p>Map-heavy Reduce-heavy N</p>
    <p>or m</p>
    <p>al iz</p>
    <p>ed J</p>
    <p>CT (s</p>
    <p>)</p>
    <p>Wordcount Terasosrt</p>
    <p>Low-load High-load Multi-load Low-load High-load Multi-load</p>
  </div>
  <div class="page">
    <p>Google Trace Contains 2202 jobs, of which 2020 are classified as short jobs and 182 as long jobs.</p>
    <p>Time (S)</p>
    <p>Cl us</p>
    <p>te r u</p>
    <p>til iz</p>
    <p>at io</p>
    <p>n (%</p>
    <p>)</p>
  </div>
  <div class="page">
    <p>Google Trace Contains 2202 jobs, of which 2020 are classified as short jobs and 182 as long jobs.</p>
    <p>Time (S)</p>
    <p>Cl us</p>
    <p>te r u</p>
    <p>til iz</p>
    <p>at io</p>
    <p>n (%</p>
    <p>)</p>
    <p>IP and GP guarantee short job latency  GP improved the 90th percentile long job runtime by 67%,</p>
    <p>cause NO job failures.</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Data-intensive cluster computing lacks an efficient mechanism for task preemption - Task killing incurs significant slowdowns or failures to preempted jobs</p>
    <p>BIG-C is a simple yet effective approach to enable preemptive cluster scheduling - lightweight virtualization helps to containerize tasks</p>
    <p>- Task preemption is achieved through precise resource management</p>
    <p>Results: - BIG-C maintains short job latency close to reservation-based scheduling while achieving similar</p>
    <p>long job performance compared to FIFO scheduling</p>
  </div>
</Presentation>
