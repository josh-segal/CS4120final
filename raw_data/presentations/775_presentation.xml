<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>2002 IBM Corporation</p>
    <p>IBM Research</p>
    <p>Analytics in the cloud</p>
    <p>Dow we really need to reinvent the storage stack?</p>
    <p>Image courtesy NASA / ESA</p>
    <p>R. Ananthanarayanan, Karan Gupta, Prashant Pandey,</p>
    <p>Himabindu Pucha, Prasenjit Sarkar, Mansi Shah, Renu</p>
    <p>Tewari</p>
  </div>
  <div class="page">
    <p>IBM Research</p>
    <p>Data-Intensive Internet Scale Applications</p>
    <p>Typical Applications</p>
    <p>Web-scale search, indexing, mining</p>
    <p>Genomic sequencing</p>
    <p>brain-scale network simulations</p>
  </div>
  <div class="page">
    <p>IBM Research</p>
    <p>Data-Intensive Internet Scale Applications</p>
    <p>Key Requirements</p>
    <p>Scale to very large data sets</p>
    <p>Platform needs to scale to 1000s of nodes</p>
    <p>Built of commodity hardware for cost efficiency</p>
    <p>Tolerate failures during every job execution</p>
    <p>Support data shipping to reduce network requirements</p>
  </div>
  <div class="page">
    <p>IBM Research</p>
    <p>MapReduce for analytics</p>
    <p>MapReduce is emerging as a model for large-scale analytics application</p>
    <p>Important design goals are extreme-scalability and fault-tolerance</p>
    <p>Storage layer is separated and has well-defined requirements</p>
    <p>QuickTime and a decompressor</p>
    <p>are needed to see this picture.</p>
    <p>Image source: http://developer.yahoo.com/hadoop/tutorial/module1.html</p>
  </div>
  <div class="page">
    <p>IBM Research</p>
    <p>MapReduce Data-store requirements</p>
    <p>Provide a hierarchical namespace with directories and files</p>
    <p>Allow applications to read/write data to files</p>
    <p>Protect data availability and reliability in the face of node and</p>
    <p>disk failures</p>
    <p>Provide high bandwidth access to reasonably-sized chunks of</p>
    <p>data to all compute nodes (not necessarily all-to-all)</p>
    <p>Provide chunk access-affinity information to allow proper</p>
    <p>scheduling of tasks</p>
  </div>
  <div class="page">
    <p>IBM Research</p>
    <p>Data store options: Cluster FS Vs Specialized FS</p>
    <p>YesYesCommodity hardware compliant</p>
    <p>Yes</p>
    <p>Specialized FS</p>
    <p>YesScaling</p>
    <p>Cluster FS</p>
  </div>
  <div class="page">
    <p>IBM Research</p>
    <p>YesNo Mature management tools</p>
    <p>YesYesCommodity hardware compliant</p>
    <p>YesNoTraditional application support</p>
    <p>Yes</p>
    <p>Specialized FS</p>
    <p>YesScaling</p>
    <p>Cluster FS</p>
    <p>Data store options: Cluster FS Vs Specialized FS</p>
  </div>
  <div class="page">
    <p>IBM Research</p>
    <p>YesNo Mature management tools</p>
    <p>YesYesCommodity hardware compliant</p>
    <p>YesNoTraditional application support</p>
    <p>Yes</p>
    <p>Yes</p>
    <p>Specialized FS</p>
    <p>NoTuned for Hadoop</p>
    <p>YesScaling</p>
    <p>Cluster FS</p>
    <p>Data store options: Cluster FS Vs Specialized FS</p>
  </div>
  <div class="page">
    <p>IBM Research</p>
    <p>Modifying a Cluster Filesystem for MapReduce</p>
    <p>GPFS</p>
    <p>Mature filesystem - many large production installations</p>
    <p>High performance, Highly scalable</p>
    <p>Reliability features focused on SAN environments</p>
    <p>Supports rack-aware 2-way replication</p>
    <p>POSIX interface</p>
    <p>Supports shared disk (SAN) and shared-nothing setups</p>
    <p>Not optimized for MapReduce workloads</p>
    <p>Does not expose data location information</p>
    <p>largest block size = 16 MB</p>
    <p>Changes for Hadoop:</p>
    <p>Make blocks bigger</p>
    <p>Let the platform know where the big blocks are</p>
    <p>Optimize replication and placement to reduce network usage</p>
  </div>
  <div class="page">
    <p>IBM Research</p>
    <p>Key change: Metablocks</p>
    <p>Works for many workloads</p>
    <p>Small FS blocks (eg: 512K)</p>
    <p>Large Application blks (eg: 64M)</p>
    <p>New allocation scheme</p>
    <p>Metablock size granularity for</p>
    <p>wide striping</p>
    <p>Block map operates on large</p>
    <p>Metablock size</p>
    <p>All FS operations operate on small</p>
    <p>regular block size</p>
    <p>Additional changes to provide</p>
    <p>block location information and</p>
    <p>write affinity</p>
    <p>Application meta-blockFS block</p>
    <p>New allocation policy</p>
  </div>
  <div class="page">
    <p>IBM Research</p>
    <p>MapReduce performance</p>
    <p>Test bed</p>
    <p>iDataPlex: 42 nodes</p>
    <p>(replication factor = 2)</p>
    <p>Hadoop : version 0.18.1</p>
    <p>GPFS: version pre3.3</p>
    <p>Grep TeraGen Terasort</p>
    <p>T im e ( s e c )</p>
    <p>GPFS rack=1</p>
    <p>HDFS rack=1</p>
    <p>GPFS rack=2</p>
    <p>HDFS rack=2</p>
  </div>
  <div class="page">
    <p>IBM Research</p>
    <p>Impact on traditional workloads</p>
    <p>N o r m a li z e d p e r f</p>
    <p>Normalized Random perf Normalized Seq read perf</p>
    <p>iDataPlex: 42 nodes</p>
    <p>GPFS: version pre3.3</p>
    <p>Bonnie filesystem benchmark</p>
  </div>
  <div class="page">
    <p>IBM Research</p>
    <p>Things that didnt work</p>
    <p>Large filesystem block-size</p>
    <p>Turn-off Prefetching</p>
    <p>Create alignment of records</p>
    <p>to block boundaries 0</p>
    <p>H D F S</p>
    <p>G P FS</p>
    <p>G P F S 16</p>
    <p>M L</p>
    <p>G P FS</p>
    <p>G P F S 16</p>
    <p>M LA</p>
    <p>N P</p>
    <p>File System</p>
    <p>T im e ( s e c )</p>
    <p>Normalized Random perf Normalized Seq read perf</p>
  </div>
  <div class="page">
    <p>IBM Research</p>
    <p>Advantages of traditional filesystems</p>
    <p>Traditional filesystems have solved many hard problems like</p>
    <p>access control, quotas, snapshots</p>
    <p>Allow traditional and MapReduce applications to share the</p>
    <p>same input data.</p>
    <p>Exploit Filesystem tools &amp; scripts based on regular</p>
    <p>filesystems.</p>
    <p>Re-use of Backup/Archive solutions built around particular</p>
    <p>filesystems.</p>
    <p>Mixed analytics pipelines.</p>
    <p>Load AnalyzeCrawl Output Serve</p>
    <p>Crawl Analyze Serve</p>
    <p>Using a MapReduce-specific filesystem (e.g. HDFS):</p>
    <p>Using a general-purpose filesystem (e.g. GPFS):</p>
    <p>Crawler writes to a traditional filesystem Into mapreduce filesystem Back to traditional fielsystem</p>
  </div>
  <div class="page">
    <p>IBM Research</p>
    <p>Conclusion</p>
    <p>MapReduce platforms can use traditional filesystems without</p>
    <p>loss of performance.</p>
    <p>There are important reasons why traditional filesystems are</p>
    <p>attractive to users of MapReduce.</p>
  </div>
</Presentation>
