<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Deep Investigation of Cross-Language Plagiarism Detection Methods</p>
    <p>Authors</p>
    <p>Jrmy Ferrero Laurent Besacier Didier Schwab Frdric Agns</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 1</p>
  </div>
  <div class="page">
    <p>What is Cross-Language Plagiarism Detection?</p>
    <p>Cross-Language Plagiarism is a plagiarism by translation, i.e. a text has been plagiarized while being translated (manually or automatically).</p>
    <p>From a text in a language L, we must find similar passage(s) in other text(s) from a set of candidate texts in language L (cross-language textual similarity).</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 2</p>
  </div>
  <div class="page">
    <p>Why is it so important?</p>
    <p>Sources: - McCabe, D. (2010). Students cheating takes a high-tech turn. In Rutgers Business School. - Josephson Institute. (2011). What would honest Abe Lincoln say?</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 3</p>
  </div>
  <div class="page">
    <p>Research Questions</p>
    <p>How do the state-of-the-art methods behave according to the characteristics of the compared texts?</p>
    <p>Are the methods depend on the characteristics of the compared texts? And if so, which characteristics?</p>
    <p>Are the state-of-the-art methods complementary?</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 4</p>
  </div>
  <div class="page">
    <p>State-of-the-Art Methods</p>
    <p>MT-Based Models Translation + Monolingual Analysis [Muhr et al., 2010]</p>
    <p>Comparable Corpora-Based Models CL-KGA, CL-ESA [Potthast et al., 2008]</p>
    <p>Parallel Corpora-Based Models CL-ASA [Pinto et al., 2009], CL-LSI, CL-KCCA</p>
    <p>Dictionary-Based Models CL-VSM, CL-CTS [Pataki, 2012]</p>
    <p>Syntax-Based Models Length Model, CL-CnG [Potthast et al., 2011], Cognateness</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 5</p>
  </div>
  <div class="page">
    <p>CL-C3G [Potthast et al., 2011]</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 6</p>
  </div>
  <div class="page">
    <p>CL-CTS [Pataki, 2012]</p>
    <p>We use DBNary [Srasset, 2015] as linked lexical resource. Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 7</p>
  </div>
  <div class="page">
    <p>CL-ASA [Pinto et al., 2009]</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 8</p>
  </div>
  <div class="page">
    <p>CL-ESA [Potthast et al., 2008]</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 9</p>
  </div>
  <div class="page">
    <p>T+MA [Muhr et al., 2010]</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 10</p>
  </div>
  <div class="page">
    <p>Evaluation Dataset [Ferrero et al., 2016]1</p>
    <p>French, English and Spanish;  Parallel and comparable (mix of Wikipedia, conference papers, product reviews,</p>
    <p>Europarl and JRC);  Different granularities: document level, sentence level and chunk level;  Human and machine translated texts;  Obfuscated (to make the similarity detection more complicated) and without</p>
    <p>added noise;  Written and translated by multiple types of authors;  Cover various fields.</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 11</p>
  </div>
  <div class="page">
    <p>Fist experiment: Evaluation Protocol</p>
    <p>We compared each textual unit to its corresponding unit in another language and to 999 other units randomly selected;</p>
    <p>We threshold the obtained distance matrix to find the threshold giving the best F1 score;</p>
    <p>We repeat these two steps 10 times, leading to a 10 folds validation;</p>
    <p>The final value are the average of the 10 F1 score.</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 12</p>
  </div>
  <div class="page">
    <p>Results: Across Language Pairs</p>
    <p>Chunk level Methods ENFR FREN ENES ESEN ESFR FRES CL-C3G 0.5071 0.5071 0.4375 0.4375 0.4795 0.4795 CL-CTS 0.4250 04116 0.3780 0.3881 0.4203 0.4169 CL-ASA 0.4738 0.4252 0.4083 0.3941 0.3736 0.3540 CL-ESA 0.1499 0.1499 0.1476 0.1476 0.1520 0.1520 T+MA 0.3730 0.3634 0.3177 0.3279 0.3158 0.3140</p>
    <p>Sentence level Methods ENFR FREN ENES ESEN ESFR FRES CL-C3G 0.4931 0.4931 0.3819 0.3819 0.4577 0.4577 CL-CTS 0.4734 0.4633 0.3171 0.3204 0.4645 0.4575 CL-ASA 0.3576 0.3523 0.2694 0.2531 0.3098 0.2843 CL-ESA 0.1430 0.1430 0.1337 0.1337 0.1383 0.1383 T+MA 0.3760 0.3692 0.3505 0.3526 0.3673 0.3525</p>
    <p>Table 1: Overall F1 score over all sub-corpora of the state-of-the-art methods for each language pair (EN: English; FR: French; ES: Spanish).</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 13</p>
  </div>
  <div class="page">
    <p>Results: Across Language Pairs</p>
    <p>ENFR ESFR ENES CL-C3G CL-C3G CL-ASA CL-CTS CL-CTS CL-ASA (a) Chunk granularity</p>
    <p>ENFR ENES ESFR FRES CL-C3G CL-C3G CL-CTS CL-CTS T+MA CL-C3G T+MA CL-CTS T+MA</p>
    <p>(b) Sentence granularity</p>
    <p>Table 2: Top 3 methods by source and target language.</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 14</p>
  </div>
  <div class="page">
    <p>Results: Across Language Pairs</p>
    <p>Strong correlation between languages! Chunk level</p>
    <p>ENFR FREN ENES ESEN ESFR FRES Overall Lang. Pair 1.000 0.991 0.998 0.995 0.957 0.940 0.980 ENFR</p>
    <p>Sentence level ENFR FREN ENES ESEN ESFR FRES Overall Lang. Pair 1.000 1.000 0.929 0.922 0.991 0.982 0.971 ENFR</p>
    <p>Table 3: Pearson correlations of the overall F1 score over all sub-corpora of all methods between the different language pairs (EN: English; FR: French; ES: Spanish).</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 15</p>
  </div>
  <div class="page">
    <p>Results: Across Language Pairs</p>
    <p>Strong correlation between granularities!</p>
    <p>Lang. Pair Correlation ENFR 0.907 FREN 0.946 ENES 0.833 ESEN 0.838 ESFR 0.932 FRES 0.939</p>
    <p>Table 4: Pearson correlations of the results of all methods on all sub-corpora, between the chunk and the sentence granularity, by language pair (EN: English; FR: French; ES: Spanish) (calculated from Table 1).</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 16</p>
  </div>
  <div class="page">
    <p>Results: Across Language Pairs</p>
    <p>Strong correlation between granularities!</p>
    <p>Methods Correlation CL-C3G 0.996 CL-CTS 0.970 CL-ASA 0.649 CL-ESA 0.515 T+MA 0.780</p>
    <p>Table 5: Pearson correlations of the results on all sub-corpora on all language pairs, between the chunk and the sentence granularity, by methods (calculated from Table 1).</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 17</p>
  </div>
  <div class="page">
    <p>Results: Detailed Analysis for English-French</p>
    <p>Chunk level Methods Wikipedia (%) TALN (%) JRC (%) APR (%) Europarl (%) Overall (%) CL-C3G 62.91 0.815 40.90 0.500 36.63 0.826 80.30 0.703 53.29 0.583 50.71 0.655 CL-CTS 58.00 0.519 33.71 0.382 29.87 0.815 67.51 1.050 44.95 1.157 42.50 1.053 CL-ASA 23.33 0.724 23.39 0.432 33.14 0.936 26.49 1.205 55.50 0.681 47.38 0.781 CL-ESA 64.89 0.664 23.78 0.613 14.03 0.997 23.14 0.777 14.19 0.590 14.99 0.709 T+MA 58.22 0.756 39.13 0.551 28.61 0.597 73.14 0.666 36.95 1.502 37.30 1.200</p>
    <p>Sentence level Methods Wikipedia (%) TALN (%) JRC (%) APR (%) Europarl (%) Overall (%) CL-C3G 48.25 0.349 48.08 0.538 36.68 0.693 61.10 0.581 52.72 0.866 49.31 0.798 CL-CTS 46.68 0.437 38.67 0.552 28.21 0.612 50.82 1.034 53.21 0.601 47.34 0.632 CL-ASA 27.63 0.330 27.25 0.341 35.17 0.644 25.53 0.795 36.55 1.139 35.76 0.978 CL-ESA 51.14 0.875 14.25 0.334 14.44 0.341 13.93 0.714 13.91 0.618 14.30 0.551 T+MA 50.57 0.888 37.79 0.364 32.36 0.369 61.94 0.756 37.92 0.552 37.60 0.518</p>
    <p>Table 6: Average F1 scores and confidence intervals of methods applied on ENFR sub-corpora at chunk and sentence level  10 folds validation.</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 18</p>
  </div>
  <div class="page">
    <p>Second Experiment: Evaluation Protocol</p>
    <p>We compare 1000 English textual units to their corresponding unit in French, and to one other (not relevant) French unit;</p>
    <p>Each unit must strictly leads to one match and one mismatch (= 1000 matches and 1000 mismatches);</p>
    <p>We repeat these two steps 10 times, leading to a 10 folds validation.</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 19</p>
  </div>
  <div class="page">
    <p>Complementarity?</p>
    <p>Figure 1: Distribution histograms of Random Baseline (left) and CL-C3G (right) for 1000 positives (lightgreen) and 1000 negatives (darkred) (mis)matches.</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 20</p>
  </div>
  <div class="page">
    <p>Complementarity?</p>
    <p>Figure 2: Distribution histograms of CL-ASA (left) and CL-C3G (right) for 1000 positives (lightgreen) and 1000 negatives (darkred) (mis)matches.</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 21</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Results show a common behavior of methods across different language pairs;  Strong correlations across languages, sizes and types of texts;  Methods behave differently in clustering, even if they seem similar in</p>
    <p>performance  combination or fusion? I invit you to come see my poster this afternoon at SemEval workshop to verify that ;)</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 22</p>
  </div>
  <div class="page">
    <p>Thank you for your attention. Do you have any questions?</p>
    <p>jeremy.ferrero@compilatio.net  @FerreroJeremy  github.com/FerreroJeremy  fr.linkedin.com/in/FerreroJeremy  researchgate.net/profile/Jeremy_Ferrero</p>
  </div>
  <div class="page">
    <p>References I</p>
    <p>Ferrero, J., Agns, F., Besacier, L., and Schwab, D. (2016). A Multilingual, Multi-style and Multi-granularity Dataset for Cross-language Textual Similarity Detection. In Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC16), pages 41624169, Portoroz, Slovenia. European Language Resources Association (ELRA).</p>
    <p>Muhr, M., Kern, R., Zechner, M., and Granitzer, M. (2010). External and Intrinsic Plagiarism Detection Using a Cross-Lingual Retrieval and Segmentation System - Lab Report for PAN at CLEF 2010. In Braschler, M., Harman, D., and Pianta, E., editors, CLEF Notebook, Padua, Italy.</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 23</p>
  </div>
  <div class="page">
    <p>References II</p>
    <p>Pataki, M. (2012). A New Approach for Searching Translated Plagiarism. In Proceedings of the 5th International Plagiarism Conference, pages 4964, Newcastle, UK. Pinto, D., Civera, J., Juan, A., Rosso, P., and Barrn-Cedeo, A. (2009). A Statistical Approach to Crosslingual Natural Language Tasks. In CEUR Workshop Proceedings, volume 64 of Journal of Algorithms, pages 5160.</p>
    <p>Potthast, M., Barrn-Cedeo, A., Stein, B., and Rosso, P. (2011). Cross-Language Plagiarism Detection. In Language Resources and Evaluation, volume 45, pages 4562.</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 24</p>
  </div>
  <div class="page">
    <p>References III</p>
    <p>Potthast, M., Stein, B., and Anderka, M. (2008). A Wikipedia-Based Multilingual Retrieval Model. In 30th European Conference on IR Research (ECIR08), volume 4956 of LNCS of Lecture Notes in Computer Science, pages 522530, Glasgow, Scotland. Springer.</p>
    <p>Srasset, G. (2015). DBnary: Wiktionary as a Lemon-Based Multilingual Lexical Resource in RDF. In Semantic Web Journal (special issue on Multilingual Linked Open Data), volume 6, pages 355361.</p>
    <p>Jrmy Ferrero, Laurent Besacier, Didier Schwab and Frdric Agns BUCC - August 2017 Deep Investigation of Cross-Language Plagiarism Detection Methods 25</p>
  </div>
</Presentation>
