<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>LAMA: Op(mized Locality- aware Memory Alloca(on</p>
    <p>for Key-value Cache Xiameng Hu, Xiaolin Wang, Yechen Li, Lan Zhou, Yingwei Luo</p>
    <p>Peking University Chen Ding</p>
    <p>University of Rochester Song Jiang</p>
    <p>Wayne State University Zhenlin Wang</p>
    <p>Michigan Technological University 15/7/7 Usenix ATC'15 1</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Background  ExisOng SoluOons  LAMA design  EvaluaOon  Conclusion</p>
  </div>
  <div class="page">
    <p>Background</p>
    <p>The in-memory caches are vital components in todays web server architecture.  Memcached  Redis</p>
  </div>
  <div class="page">
    <p>Memcached</p>
    <p>A high-performance, distributed memory object caching system.  Slab-based allocaOon.  PlaXorm independent.  LRU evicOon.</p>
  </div>
  <div class="page">
    <p>Memcached  Split the space into different classes to store variable-size objects.  Each class obtains its own memory space by requesOng free slabs (1MB per slab).  Each allocated slab is divided into slots of equal size.  The slot size increases exponenOally.</p>
  </div>
  <div class="page">
    <p>Memcached</p>
    <p>Default Memcached fills the cache at the cold start based on the demand.  Demand-driven slab allocaOon may not deliver best performance.  Default allocaOon results in slab calcificaOon.</p>
  </div>
  <div class="page">
    <p>Example For Demand-driven Slab Alloca(on</p>
    <p>There are two classes of data references:  Class 1: abcabcabc.  Class 2: 123456789.  Combined reference pagern: a1b2c3a4b5c6a7b8c9.  There are four slabs and each slab contains one slot.</p>
  </div>
  <div class="page">
    <p>Default Alloca(on</p>
    <p>Trace: a 1 b 2 c 3 a 4 b 5 c 6 a 7 b 8 c 9 Class 1 slabs : Class 2 slabs : hits :</p>
    <p>Total hits: 0</p>
  </div>
  <div class="page">
    <p>Op(mal Alloca(on</p>
    <p>Trace: a 1 b 2 c 3 a 4 b 5 c 6 a 7 b 8 c 9 Class 1 slabs : Class 2 slabs : hits :</p>
    <p>Total hits: 6</p>
  </div>
  <div class="page">
    <p>Slab Calcifica(on</p>
    <p>The slab allocaOon is decided by the reference pagern in cold start period.  When the workload behavior changes, slab allocaOon cannot adapt to the change in reference pagern.  The cache performance will drop.</p>
    <p>class 1 class 2 class 3 class 4 class 5 class 6</p>
    <p>requsets/sec</p>
    <p>class 1 class 2 class 3 class 4 class 5 class 6</p>
    <p>requsets/sec</p>
  </div>
  <div class="page">
    <p>Exis(ng Solu(ons</p>
    <p>Automove  Move a slab from a class with no evicOons to one with the highest number of evicOons in three consecuOve monitoring windows(30 seconds).</p>
    <p>Twemcache (By Twiger)  Random slab evicOon aims to balance the evicOon rates among all classes.</p>
    <p>Periodic Slab AllocaOon (PSA) (ICC14)  Move a slab from the class with the lowest risk to the class with the largest number of misses.</p>
    <p>Facebook Policy (NSDI13)  Balance the age of the least recently used items among all classes, effecOvely approximaOng global LRU.</p>
  </div>
  <div class="page">
    <p>Locality-aware Memory Alloca(on (LAMA)</p>
    <p>MoOvaOon  Miss RaOo Curve  Footprint Theory  Minimal Miss RaOo  Minimal Average Request Time</p>
  </div>
  <div class="page">
    <p>Mo(va(on  Why demand-driven allocaOon may not deliver best performance?  Different classes of data objects show different reference locality.</p>
    <p>Some classes of data may be frequently requested but others not.  AllocaOng more slabs to cache frequently used data will increase cache performance.</p>
    <p>ExisOng soluOons have been moOvated by the same observaOon, but their performances are far from opOmal.</p>
  </div>
  <div class="page">
    <p>Miss Ra(o Curve</p>
    <p>What metric can be used to accurately describe data reference pagern?  Miss raOo curve (MRC) or Hit raOo curve (HRC).</p>
    <p>How to profile MRC online for each classes with low overhead?  Use footprint theory [PACT11, ASPLOS13]</p>
  </div>
  <div class="page">
    <p>Footprint Theory</p>
  </div>
  <div class="page">
    <p>LAMA Design</p>
    <p>Trace tracking</p>
    <p>Get sub-trace for each class</p>
    <p>MRCs profiling</p>
    <p>Use footprint theory</p>
    <p>Slabs reparOOon</p>
    <p>Use dynamic programing</p>
  </div>
  <div class="page">
    <p>Minimal Miss Ra(o</p>
  </div>
  <div class="page">
    <p>Minimal Average Request Time</p>
  </div>
  <div class="page">
    <p>Slabs Repar((on</p>
  </div>
  <div class="page">
    <p>Evalua(on</p>
    <p>We have implemented LAMA in Memcached-1.4.20.  Experimental Setup:  Intel(R) Core(TM) I7-3770 with 4 cores, 3.4GHz, 8MB shared LLC.  16GB memory.  Fedora 18 with Linux-3.8.2.  4 server threads, one Memcached server.</p>
  </div>
  <div class="page">
    <p>Workloads  The Facebook ETC workload to test the steady-state performance.  A general-purpose workload with the highest miss raOo in all Facebooks Memcached pools.  Generated by MuOlate.  50 million requests to 7 million data objects.</p>
    <p>A 3-phase workload to test dynamic allocaOon.  Used to evaluate PSA.  200 million requests to data items in two working sets, each of which has 7 million items.  Each phase has a different access pagern.</p>
    <p>A stress-test workload to measure the overhead.  Use the Memaslap generator of libmemcached.  To test the throughput of a given number of server threads.</p>
  </div>
  <div class="page">
    <p>Facebook ETC Miss Ra(o</p>
    <p>Miss raOo from cold-start to steady state(512MB).</p>
    <p>ObservaOon: LAMA_OPT_MR is  47.20% lower than Memcached.  18.08% lower than PSA.  5.40% lower than Facebook.</p>
  </div>
  <div class="page">
    <p>Facebook ETC Average Response Time</p>
    <p>Average request Ome from cold-start to steady state (512MB).</p>
    <p>ObservaOon: LAMA_OPT_ART is  33.45% lower than Memcached.  13.17% lower than PSA.  6.70% lower than Facebook.</p>
  </div>
  <div class="page">
    <p>Facebook ETC Upper Bound Performance</p>
    <p>Steady-state miss raOo using different amounts of memory  TheoreOcal Upper Bound (TUB): Using real MRCs measured by the full-trace reuse distance tracking.</p>
  </div>
  <div class="page">
    <p>Facebook ETC Upper Bound Performance</p>
    <p>Conclusion (compared with Default Memcached):</p>
    <p>TUB LAMA FACEBOOK PSA Automove Twemcache</p>
    <p>Miss RaOo reducOon</p>
    <p>Average request Ome reducOon</p>
  </div>
  <div class="page">
    <p>Slab Calcifica(on</p>
    <p>Miss raOo over Ome by different policies (3-phased workload, 1024M).</p>
    <p>ObservaOon: LAMA outperforms other techniques in each phase.</p>
    <p>Dynamic allocaOon based on the previous access pagern.</p>
  </div>
  <div class="page">
    <p>LAMA Overhead</p>
    <p>Overall throughput as different number of threads are used (stress test workload)</p>
    <p>ObservaOon: Average degradaOon of LAMA is only 3.14%.</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Compared with the default Memcached:  LAMA reduces the miss raOo by 42% using the same amount of memory.  LAMA achieves the same memory uOlizaOon (miss raOo) with 41% less memory.  LAMA outperforms four previous techniques in steady-state performance, convergence speed, and the ability to adapt to phase changes.  LAMA is close to opOmal, achieving over 98% of the theoreOcal potenOal (TUB).</p>
  </div>
  <div class="page">
    <p>Thank you for your aQen(on!</p>
    <p>Q&amp;A Email: hxm@pku.edu.cn</p>
  </div>
</Presentation>
