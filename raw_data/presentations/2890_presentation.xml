<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Transfer Learning for Performance Modeling of Deep Neural Network</p>
    <p>Systems</p>
    <p>Md Shahriar Iqbal Lars Kotthoff Pooyan Jamshidi</p>
  </div>
  <div class="page">
    <p>Performance can change across systems</p>
    <p>Can we expect similar performance in new environment? 2</p>
    <p>Environment 1.0 Dev/Staging</p>
    <p>Environment 2.0 Production</p>
    <p>Push Performance - Inference time - Energy consumption</p>
  </div>
  <div class="page">
    <p>Case study: Performance behavior changes across environments and so does optimal configuration</p>
    <p>Default is 2.8 times bad</p>
    <p>Default is 2.1 times bad</p>
    <p>Default is 2.6 times bad</p>
    <p>Default is 5.1 times bad</p>
    <p>optimal</p>
    <p>Optimal in Environment 1.0 is 1.9 times bad</p>
    <p>Optimal in Environment 1.0 is 4.9 times bad</p>
    <p>optimal 3</p>
    <p>How can the developer tune parameters for energy consumption during source code development?</p>
  </div>
  <div class="page">
    <p>DNN system stack allows developers to tune parameters for energy consumption</p>
    <p>core status, core frequency, gpu status, gpu frequency, memory controller frequency etc</p>
    <p>Network Level</p>
    <p>Model Compiler Level</p>
    <p>Deployment Level</p>
    <p>Hardware/OS Level</p>
    <p>&gt;100</p>
    <p>DNN Systems are highly configurable</p>
  </div>
  <div class="page">
    <p>Building configuration space of DNN systems</p>
    <p>Hardware/OS Level</p>
    <p>Core frequency</p>
    <p>Core status</p>
    <p>gpu status</p>
    <p>gpu frequency</p>
    <p>Core status</p>
    <p>Inference time</p>
    <p>Energy consumption</p>
  </div>
  <div class="page">
    <p>A typical approach to understand system behavior is sensitivity analysis C O1xO2xO3xO4....xO20</p>
    <p>c1 0x0x0x0....x1 y1=f(c1)</p>
    <p>c2 0x0x1x0....x1 y2=f(c2)</p>
    <p>c3 1x0x0x0....x0 y3=f(c3)</p>
    <p>. . . . . . . f*-&gt;f</p>
    <p>cn 1x1x1x0....x1 yn=f(cn)</p>
    <p>Training Set</p>
    <p>learn</p>
  </div>
  <div class="page">
    <p>Performance models could be in any form of black box models C O1xO2xO3xO4....xO20</p>
    <p>c1 0x0x0x0....x1 y1=f(c1)</p>
    <p>c2 0x0x1x0....x1 y2=f(c2)</p>
    <p>c3 1x0x0x0....x0 y3=f(c3)</p>
    <p>. . . . . . . f*-&gt;f</p>
    <p>cn 1x1x1x0....x1 yn=f(cn)</p>
    <p>Training Set</p>
  </div>
  <div class="page">
    <p>Evaluating a performance model</p>
    <p>C O1xO2xO3xO4....xO20</p>
    <p>c1 0x0x0x0....x1 y1=f(c1)</p>
    <p>c2 0x0x1x0....x1 y2=f(c2)</p>
    <p>c3 1x0x0x0....x0 y3=f(c3) MAPE(f *,f)=</p>
    <p>. . . . . . . f*-&gt;f</p>
    <p>cn 1x1x1x0....x1 yn=f(cn)</p>
    <p>Training Set</p>
  </div>
  <div class="page">
    <p>A Performance Model contains useful information about option interactions f:C-&gt;R</p>
    <p>f(.)=1.2+3O1+5O2+7O7+8O1O2-3.4O1O7+5O3O7+11.2O1O2O7</p>
  </div>
  <div class="page">
    <p>What are the roadblocks for performance modeling of DNN systems?  Configuration space grows exponentially with addition of new options.  Performance measurements are costly.</p>
    <p>Transfer learning can help to reuse the cheap measurements from old environments to new environments to quickly learn</p>
    <p>system behavior using performance modeling. 10</p>
  </div>
  <div class="page">
    <p>Direct Model Transfer Learning</p>
    <p>Model learned in source environment is used directly</p>
    <p>in target environment</p>
    <p>s fs(s)</p>
    <p>t fs(t)</p>
    <p>Experimentation Cost: 0</p>
  </div>
  <div class="page">
    <p>Linear/Non-Linear Model Shift</p>
    <p>Transfer Learning Linear and non-linear model shift are learned using</p>
    <p>source model (all samples) and target model (random</p>
    <p>sub-samples).</p>
    <p>Experimentation Cost: 0 s fs(s)</p>
    <p>t* ft(t *)</p>
    <p>f*</p>
    <p>Experimentation Cost: m(t*)</p>
  </div>
  <div class="page">
    <p>Guided Sampling Transfer Learning</p>
    <p>Influential configurations are sampled in target environment by studying options interactions from source environment to build</p>
    <p>performance model.</p>
    <p>s fs(s)</p>
    <p>t* ft(t *)</p>
    <p>Experimentation Cost: m(t*)</p>
  </div>
  <div class="page">
    <p>Experimental Setup</p>
    <p>Measurement</p>
    <p>Analysis</p>
    <p>Select Environment Generate</p>
    <p>Configuration</p>
    <p>Inference</p>
    <p>Compute Inference Time</p>
    <p>Compute Energy Consumption</p>
    <p>Extract knowledge to sample configuration space from Source Measurements</p>
    <p>Transfer Knowledge</p>
    <p>Build Performance Model in Target</p>
    <p>Compute Prediction Error</p>
    <p>f s ( s ) = a 1 O 1 + a 2 O 3 + a 3 O 7 + a 4 O 1 O 3 + a 5 O 1 O 7 + . . + a 7 O 1 O 3 O</p>
  </div>
  <div class="page">
    <p>Results: Inference Time</p>
    <p>Cost Reduction of Error</p>
    <p>Direct Model Transfer 0 1</p>
    <p>Linear Model Shift 2.48 hours (0.15%) 3.48</p>
    <p>Non-Linear Model Shift 2.48 hours (0.15%) 5.76</p>
    <p>Guided Sampling 2.48 hours (0.15%) 22.93 15</p>
  </div>
  <div class="page">
    <p>Results: Energy Consumption</p>
    <p>Cost Reduction of Error</p>
    <p>Direct Model Transfer 0 1</p>
    <p>Linear Model Shift 2.48 hours (0.15%) 7.19</p>
    <p>Non-Linear Model Shift 2.48 hours (0.15%) 16.31</p>
    <p>Guided sampling 2.48 hours (0.15%) 42.85 16</p>
  </div>
  <div class="page">
    <p>Useful tool for practitioners</p>
    <p>To build performance models in new environments using only 2.44% of the configuration space.</p>
    <p>To avoid invalid configurations to quickly find optimal configurations.</p>
    <p>To learn the performance landscape of a system for performance debugging e.g., performance regression etc.</p>
  </div>
  <div class="page">
    <p>Summary</p>
  </div>
</Presentation>
