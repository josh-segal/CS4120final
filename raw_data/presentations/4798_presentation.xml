<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>User Browsing Graph: User Browsing Graph: Structure, Evolution and Application Structure, Evolution and Application</p>
    <p>Yiqun Liu, Yijiang Jin, Min Zhang, Shaoping Yiqun Liu, Yijiang Jin, Min Zhang, Shaoping Ma, Liyun Ru Ma, Liyun Ru</p>
    <p>State Key Lab of Intelligent Technology and SystState Key Lab of Intelligent Technology and Syst ems ems</p>
    <p>Tsinghua University, Beijing, ChinaTsinghua University, Beijing, China 2009/02/102009/02/10</p>
  </div>
  <div class="page">
    <p>Search Engine vs. UsersSearch Engine vs. Users</p>
    <p>How many pages can search engine provide  1 trillion pages in the index (official Google blog 2008</p>
    <p>/07)</p>
    <p>How many pages can user consume?  235 M searches per day for Google (comScore 2008/</p>
    <p>is millions, not billions pages (Mei et al, WSDM 2008) Page quality estimation is important for all search engines</p>
  </div>
  <div class="page">
    <p>Web Page Quality EstimationWeb Page Quality Estimation</p>
    <p>Previous Research  Hyperlink analysis algorithms</p>
    <p>PageRank, Topic-sensitive Pagerank, TrustRank</p>
    <p>Two assumptions  proposed by Craswell et al 2001</p>
    <p>A B A B</p>
    <p>Recommendation Topic locality</p>
  </div>
  <div class="page">
    <p>Web Page Quality EstimationWeb Page Quality Estimation</p>
    <p>Web graph may be mis-leading</p>
  </div>
  <div class="page">
    <p>Web Page Quality EstimationWeb Page Quality Estimation</p>
    <p>Improve with the help of user behavior analysi s  Implicit feedback information from Web users  Objective and reliable, without interrupting users  Information source: Web access log</p>
    <p>Record of users Web browsing history  Mining the search trails of surfing crowds: identifying rel</p>
    <p>evant websites from user activity. (Bilenko et al, WWW 2008)</p>
    <p>BrowseRank: letting web users vote for page importance. (Liu et al, SIGIR 2008)</p>
  </div>
  <div class="page">
    <p>Web Page Quality EstimationWeb Page Quality Estimation</p>
    <p>Construct user browsing graph with Web access log  Hyperlink graph filtering</p>
    <p>User accessed part is more reliable</p>
  </div>
  <div class="page">
    <p>Web access logWeb access log</p>
    <p>Data preparation  With the help of a commercial search</p>
    <p>engine in China using browser toolbar software</p>
    <p>Collected from Aug.3rd, 2008 to Oct 6th, 2008</p>
    <p>Over 2.8 billion click-through events Name Description</p>
    <p>Session ID A random assigned ID for each user session</p>
    <p>Source URL URL of the page which the user is visiting</p>
    <p>Destination URL URL of the page which the user navigates to</p>
    <p>Time Stamp Date/Time of the click event</p>
  </div>
  <div class="page">
    <p>Construction of User Browsing GraphConstruction of User Browsing Graph</p>
    <p>Construction Process</p>
    <p>;),(</p>
    <p>;1),()},,{(</p>
    <p>),(</p>
    <p>};{,</p>
    <p>};{,</p>
    <p>BAWeight</p>
    <p>else</p>
    <p>BAWeightBAEE</p>
    <p>EBAif</p>
    <p>BVVVBif</p>
    <p>AVVVAif</p>
    <p>{}{},  EV</p>
    <p>For each record in the Web access log, if the source URL is A and the destination URL is B, then</p>
  </div>
  <div class="page">
    <p>Structure of User Browsing GraphStructure of User Browsing Graph</p>
    <p>User Browsing Graph UG(V,E)  Constructed with Web access log collected by</p>
    <p>a search engine from Aug.3rd to Sept. 2nd</p>
    <p>Vertex set: 4,252,495 Web sites  Edge set: 10,564,205 edges  Much smaller than whole hyperlink graph  Possible to perform PageRank/TrustRank withi</p>
    <p>n a few hours (very efficient!)</p>
  </div>
  <div class="page">
    <p>Structure of User Browsing GraphStructure of User Browsing Graph</p>
    <p>Comparison: Hyperlink Graph HG(V,E)  Same vertex set as UG(V,E)  Edge set: extracted from a hyperlink graph co</p>
    <p>mposed of over 3 billion Web pages</p>
  </div>
  <div class="page">
    <p>Structure of User Browsing GraphStructure of User Browsing Graph</p>
    <p>Links not clicked by</p>
    <p>users Search engine result page links Links in protected sessions Links which are not crawled</p>
    <p>Part of the user browsing graph is</p>
    <p>user accessed part of hyperlink graph</p>
    <p>User browsing graph contains some other important information</p>
    <p>Hyperlink Graph</p>
    <p>User Browsing Graph</p>
    <p>User Browsing</p>
    <p>Graph</p>
  </div>
  <div class="page">
    <p>Evolution of User Browsing GraphEvolution of User Browsing Graph</p>
    <p>Why should we look into the evolution over time?  Whether information collected from the</p>
    <p>first N days can cover most of user requests on (N+1)th day</p>
    <p>Time Browsing info on the 1st day</p>
    <p>New info on the 2nd day</p>
    <p>New info on the 3rd day</p>
    <p>New info on the Nth day</p>
    <p>User Browsing Graph constructed with information from the first N days</p>
    <p>User request on (N+1)th day</p>
    <p>Pages without previous browsing</p>
    <p>information</p>
  </div>
  <div class="page">
    <p>Evolution of User Browsing GraphEvolution of User Browsing Graph</p>
    <p>How many percentage of vertexes are newly-appeared on each day?</p>
    <p>Most of these pages are low quality and few</p>
    <p>users visit them (&gt;80% of them are visited only</p>
    <p>once per day)</p>
  </div>
  <div class="page">
    <p>Evolution of User Browsing GraphEvolution of User Browsing Graph</p>
    <p>Evolution of the graph  It takes tens of days to construct a</p>
    <p>stable graph</p>
    <p>After that, small part of the graph changes each day and newly-appeared pages are mostly not important ones.</p>
    <p>User browsing graph constructed with data collected from the first N days can be adopted for the (N+1)th day</p>
  </div>
  <div class="page">
    <p>Page Quality EstimationPage Quality Estimation</p>
    <p>Experiment settings  Performance of page quality estimation  How does traditional algorithms (PageRank / T</p>
    <p>rustRank) perform on user browsing graph?  Is it possible to use user browsing graph to re</p>
    <p>place hyperlink graph?</p>
  </div>
  <div class="page">
    <p>Page Quality EstimationPage Quality Estimation</p>
    <p>Graph construction  How PageRank/TrustRank perform on these gr</p>
    <p>aphs Graph Description</p>
    <p>User Graph UG(V,E)</p>
    <p>Constructed with web access data from Aug.3rd, 2008 to Sept.2nd, 2008.</p>
    <p>Hyperlink Graph extracted-HG(V,E)</p>
    <p>Vertexes are from UG(V,E). Edges among them are extracted from hyperlink relations in whole-HG(V,E).</p>
    <p>Combined Graph CG(V,E)</p>
    <p>Vertexes are from UG(V,E). Edges among them are from UG(V,E) combined with those from extracted-HG(V,E).</p>
    <p>Hyperlink Graph whole-HG(V,E)</p>
    <p>Constructed with over 3 billion pages (all pages in a certain search engines index) and all hyperlinks among them</p>
    <p>SameSame Vertex set Vertex set</p>
    <p>(User (User accessed accessed</p>
    <p>part)part)</p>
    <p>Each Each represents represents a kind of a kind of</p>
    <p>User User Browsing Browsing</p>
    <p>GraphGraph</p>
  </div>
  <div class="page">
    <p>Page Quality EstimationPage Quality Estimation</p>
    <p>Performance Evaluation  Metrics: ROC/AUC, pair wise orderedness acc</p>
    <p>uracy  Test set: Page Type Amount Percentage</p>
    <p>High Quality 247 39.21%</p>
    <p>Low Quality 91 14.44%</p>
    <p>N/A pages 57 9.05%</p>
    <p>Spam 22 3.49%</p>
    <p>NON-GB2312 Pages 115 18.25%</p>
    <p>Illegel Pages 98 15.56%</p>
    <p>Total 630</p>
  </div>
  <div class="page">
    <p>Experimental ResultsExperimental Results</p>
    <p>High quality page identification</p>
    <p>Spam/illegal page identification</p>
    <p>Graph PageRank TrustRank</p>
    <p>UG(V,E) 0.84868 0.92032</p>
    <p>extracted-HG(V,E) 0.86960 0.91626</p>
    <p>CG(V,E) 0.86756 0.91846</p>
    <p>whole-HG(V,E) 0.84113 0.85737</p>
    <p>Graph PageRank TrustRank</p>
    <p>UG(V,E) 0.87666 0.84627</p>
    <p>extracted-HG(V,E) 0.84686 0.84554</p>
    <p>CG(V,E) 0.88014 0.88198</p>
    <p>whole-HG(V,E) 0.73659 0.80612</p>
    <p>User User browsing browsing</p>
    <p>graphgraph</p>
    <p>User User browsing browsing</p>
    <p>graphgraph</p>
    <p>TrustRank performs bTrustRank performs b etteretter</p>
    <p>Change in edge set Change in edge set doesnt affect muchdoesnt affect much</p>
    <p>Change in edge set Change in edge set doesnt affect muchdoesnt affect much Combination of edge Combination of edge set sometimes helpsset sometimes helps</p>
  </div>
  <div class="page">
    <p>Experimental ResultsExperimental Results</p>
    <p>Pair wise orderedness accuracy test  Firstly proposed by Gyngyi et al. 2004  700 pairs of Web sites: [A, B] ,Q(A)&gt;Q(B)  Annotated by product managers from a survey</p>
    <p>company  Performance of PageRank algorithm on these</p>
    <p>graphs Graph Pairwise Orderedness Accuracy</p>
    <p>UG(V,E) 0.9686</p>
    <p>extracted-HG(V,E) 0.9586</p>
    <p>CG(V,E) 0.9600</p>
    <p>whole-HG(V,E) 0.8754</p>
  </div>
  <div class="page">
    <p>ConclusionsConclusions</p>
    <p>Important Findings  User browsing graph can be regarded as user</p>
    <p>accessed part of Web, but it also contains information usually not collected by search engines.</p>
    <p>The size of user browsing graph is significantly smaller than whole hyperlink graph</p>
    <p>User browsing graph constructed with logs collected from first N days can be adopted for the (N+1)th day</p>
    <p>Traditional link analysis algorithms perform better on user browsing graph than on hyperlink graph</p>
  </div>
  <div class="page">
    <p>Future worksFuture works</p>
    <p>How will query-dependent link analysis algorithms (e.g. HITS) perform on the user browsing graph?</p>
    <p>What happens if we extract anchor text information from the user browsing graph and adopt this into retrieval?</p>
  </div>
  <div class="page">
    <p>Thank you!</p>
    <p>yiqunliu@tsinghua.edu.cn</p>
  </div>
  <div class="page">
    <p>Evolution of User Browsing GraphEvolution of User Browsing Graph</p>
    <p>Why should we look into the evolution over time?  It takes time to</p>
    <p>Construct a user browsing graph</p>
    <p>Calculate page importance scores</p>
    <p>During this time period,  New pages may appear</p>
    <p>People may visit new pages</p>
    <p>These pages are not included in the browsing graph</p>
  </div>
  <div class="page">
    <p>Structure of User Browsing GraphStructure of User Browsing Graph</p>
    <p>Sites with most out-degrees in HG(V,E)Rank URL Out-degree</p>
    <p>HG(V,E) UG(V,E)</p>
  </div>
  <div class="page">
    <p>Structure of User Browsing GraphStructure of User Browsing Graph</p>
    <p>Sites with most out-degrees in UG(V,E)</p>
    <p>Rank URL Out-degree</p>
    <p>HG(V,E) UG(V,E)</p>
  </div>
  <div class="page">
    <p>Structure of User Browsing GraphStructure of User Browsing Graph</p>
    <p>Search engine oriented edges Search Engine Number of Edges in UG(V,E)</p>
    <p>Baidu 1,518,109</p>
    <p>Google 1,169,647</p>
    <p>Sogou 291,829</p>
    <p>Soso 147,034</p>
    <p>Yahoo 143,860</p>
    <p>Gougou 47,099</p>
    <p>Yodao 24,171</p>
    <p>Total 3,341,749 (41.92%)</p>
  </div>
</Presentation>
