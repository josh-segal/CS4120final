<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Unsupervised Learning of Soft Patterns for Generating Definitions from Online News</p>
    <p>Hang Cui Min-Yen Kan Tat-Seng Chua</p>
    <p>{cuihang, kanmy, chuats} @ comp.nus.edu.sg</p>
    <p>School of Computing, NUS, Singapore</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Problem</p>
    <p>To answer Who is Bob Woodward and What is SARS questions.  A large portion of queries in search logs (Voorhees</p>
    <p>Where to get definitions  Dictionaries, encyclopedias, online glossaries   Online news  new terms (e.g. Sasser)</p>
    <p>In this paper, we  deal with recently popular terms and people.  identify definition sentences from online news.  distill search engine results to definitions.</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>In the News from Google (Apr 23, 2004)</p>
    <p>In the News</p>
    <p>Bob Woodward SARS Vietnam War Yasser Arafat George W. Bush Marine Corps Gaza Strip Kofi Annan Mitsubishi Motors Alan Greenspan First Quarter Maurice Clarett</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>In the News from Google (Apr 23, 2004)</p>
    <p>A list of relevant documents rather</p>
    <p>than a direct answer</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Our Solution  DefSearch</p>
    <p>Bob Woodward</p>
    <p>Woodward, an Office of Naval Intelligence (ONI) asset, interviewed over 75 Bush Cabal insiders. (CNN)</p>
    <p>Woodward, who had previously endeared himself to the Bush Administration with his pandering portrait of the President in &quot;Bush at War&quot;, has launched a blistering assault on White House credibility with his new book, &quot;Plan of Attack&quot;. (NY Times)</p>
    <p>People close to Mr. Powell said Sunday that they had no doubt he would weather any criticism from within over his apparent cooperation with Mr. Woodward, an assistant managing editor at The Washington Post. (CNN)</p>
    <p>The book, called Plan of Attack, is written by Bob Woodward, the respected journalist who helped break open the Watergate scandal.The book is based on interviews with 75 people, including Bush, and is due for release Tuesday. (REUTERS)</p>
    <p>Bob Woodward, the famous Watergate reporter has interviewed President Bush and other Whitehouse &quot;insiders&quot;. As a result of the interview, Woodward might have done more damage to the Presidents re-election cause than anyone since Richard Clarkes interview on the same program and the recent events in Spain might be an indication as to how the world is beginning to view President Bush. (ABC News)</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Behind DefSearch</p>
    <p>User</p>
    <p>Query</p>
    <p>Def Search</p>
    <p>I R Engi ne Pat t ern Mat chi ng</p>
    <p>Best Sentences</p>
    <p>Defi ni ti on Sentences</p>
    <p>Sent ence Sel ecti on</p>
    <p>Resul t</p>
    <p>Defi ni ti on Patterns</p>
    <p>Trai ni ng Pat t ern</p>
    <p>I nst ances</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Outline</p>
    <p>How Do Current Systems Identify Definitions?</p>
    <p>What are Soft Patterns?</p>
    <p>Matching Soft Patterns</p>
    <p>Unsupervised Learning of Soft Patterns</p>
    <p>Evaluations</p>
    <p>Conclusion and Future Work</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>How Do Current Systems Identify Definitions?</p>
    <p>Most of current systems use hand-crafted patterns  Appositive</p>
    <p>e.g. Gunter Blobel , a cellular and molecular biologist,  Copulas</p>
    <p>e.g. Battery is a kind of electronic device   Predicates (relations)</p>
    <p>e.g. TB is usually caused by   Current work on definition sentence identification</p>
    <p>Domain-specific definition generation systems  e.g. topic-specific definitions on the Web and</p>
    <p>biographies.  Definitional QA Task at TREC 2003</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Lack of Flexibility  Hard Matching  Pattern: &lt;SCH_TERM&gt; , also known as</p>
    <p>TB , also known as Tuberculosis ,  TB ( also known as Tuberculosis )</p>
    <p>Variations make hard matching fail  Introduce Soft Patterns with greater flexibility</p>
    <p>Manual labor  Introduce unsupervised learning by Group Pseudo</p>
    <p>Relevance Feedback (GPRF).</p>
    <p>Weaknesses of Current Pattern Matching Methods</p>
    <p>mismatch</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Outline</p>
    <p>How Do Current Systems Identify Definitions?</p>
    <p>What are Soft Patterns?</p>
    <p>Matching Soft Patterns</p>
    <p>Unsupervised Learning of Soft Patterns</p>
    <p>Evaluations</p>
    <p>Conclusion and Future Work</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>What are Soft Patterns?</p>
    <p>Soft patterns allow partial matching TB ( also known as Tuberculosis )</p>
    <p>P( ( |Slot1) = 0.001, P(also|Slot2) = 0.21, P(known|Slot3) = 0.33, P(as| Slot4) = 0.13</p>
    <p>P(Matching) = 0.23 : still better than non-definition sentences.</p>
    <p>How does it work?  Training  accumulating pattern instances in a vector.</p>
    <p>Derive pattern instances from labeled definition sentences.</p>
    <p>Matching with a probabilistic model, not regular expressions.  Using statistical information from all pattern instances,</p>
    <p>not generalized rules.  Instance-based learning.</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Preparing Pattern Instances</p>
    <p>The channel Iqra is owned by the Arab Radio and Television company and is the brainchild of the Saudi millionaire, Saleh Kamel.</p>
    <p>The_DT channel_NN Iqra_NNP is_VBZ owned_VBN by_IN NNP company_NN and_CC is_VBZ the_DT brainchild_NN of_IN NNP.</p>
    <p>Step 1 POS tagging and noun</p>
    <p>phrase chunking.</p>
    <p>Step 2 Selective substitution  replace those specific words with more general tags. Other tokens remain unchanged.</p>
    <p>DT$ NN &lt;SEARCH_TERM&gt; BE$ owned by DT$ NNP and BE$ DT$ NN of NNP.</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Preparing Pattern Instances  Contd</p>
    <p>DT$ NN &lt;SCH_TERM&gt; BE$ owned by</p>
    <p>Step 3 Crop a text window around the tag &lt;SCH_TERM&gt; (window size = 3 for each side)</p>
    <p>Pattern Instance</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Illustration of Soft Pattern Generation</p>
    <p>The channel Iqra is owned by the   severance packages, known as golden parachutes, included</p>
    <p>A battery is a cell which can provide electricity.</p>
    <p>DT$ NN &lt;Search_Term&gt; BE$ owned by known as &lt;Search_Term&gt; , VB</p>
    <p>&lt;Search_Term&gt; BE$ DT$</p>
    <p>&lt;Slot-2&gt; &lt;Slot-1&gt; &lt;Search_Term&gt; &lt;Slot1&gt; &lt;Slot2&gt;  NN 0.12 NN 0.11 , 0.40 DT$ 0.2 known 0.09 as 0.20 BE$ 0.2 VB 0.1 DT$ 0.04 owned 0.09</p>
    <p>&lt;Slot-w, , Slot-2, Slot-1, SEARCH_TERM , Slot1, Slot2,  Slotw : Pa&gt;</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Outline</p>
    <p>How Do Current Systems Identify Definitions?</p>
    <p>What are Soft Patterns?</p>
    <p>Matching Soft Patterns  Addressing Flexibility</p>
    <p>Unsupervised Learning of Soft Patterns</p>
    <p>Evaluations</p>
    <p>Conclusion and Future Work</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Matching Soft Patterns</p>
    <p>Test sentences are reduced to a vector S using the same strategy. &lt;token-w, , token-1, SEARCH_TERM, token1, , tokenw : S&gt;</p>
    <p>Matching Soft Patterns  similarity between the pattern vector Pa and the test vector S.  Independent slot content similarity.</p>
    <p>Slot sequence fidelity.</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Probabilistic Matching Degree</p>
    <p>Individual slot similarity  independent assumption</p>
    <p>Sequence fidelity  bigram model</p>
    <p>Combined to get the matching degree</p>
    <p>w</p>
    <p>wi iiSlots SlottokenPaSweightPa )|Pr()|Pr(_</p>
    <p>)|()|()(</p>
    <p>)|,Pr()_Pr(</p>
    <p>ww</p>
    <p>w</p>
    <p>tokentokenPtokentokenPtokenP</p>
    <p>Patokentokentokenseqright</p>
    <p>)|_Pr(</p>
    <p>)|_Pr()1(_</p>
    <p>Paseqright</p>
    <p>PaseqleftweightPa Seq</p>
    <p>lengthfragment</p>
    <p>weightPaweightPa weightPattern</p>
    <p>SeqSlots</p>
    <p>_</p>
    <p>__ _</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Outline</p>
    <p>How Do Current Systems Identify Definitions?</p>
    <p>What are Soft Patterns?</p>
    <p>Matching Soft Patterns  Flexibility</p>
    <p>Unsupervised Learning of Soft Patterns  Addressing Manual Labor</p>
    <p>Evaluations</p>
    <p>Conclusion and Future Work</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Unsupervised Labeling of Definition Sentences using GPRF  Pattern instances obtained from labeled definition</p>
    <p>sentences.  Manual labeling is too expensive.</p>
    <p>Pseudo-relevance Feedback in document retrieval  Take the top n ranked documents as relevant.</p>
    <p>We employ Group pseudo-relevance feedback (GPRF)  Statistical ranking  centroid based method.</p>
    <p>Perform PRF over a group of questions (top 10 sentences for each question).</p>
    <p>Generate soft patterns from all auto-labeled sentences for all questions.</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Analysis of GPRF</p>
    <p>Assumption 1  some definition sentences can be ranked high using statistical method.  Word co-occurrence metrics can well model</p>
    <p>descriptive sentences.  Over 33% of top ranked sentences are definitional.</p>
    <p>Noise introduced in each questions top list can be mitigated by the group strategy.</p>
    <p>Assumption 2  definition patterns are general and can be used across questions.</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Outline</p>
    <p>How Do Current Systems Identify Definitions?</p>
    <p>What are Soft Patterns?</p>
    <p>Matching Soft Patterns  Flexibility</p>
    <p>Unsupervised Learning of Soft Patterns</p>
    <p>Evaluations</p>
    <p>Conclusion and Future Work</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Evaluation Setup</p>
    <p>Two experiments  To evaluate the effectiveness of our method on a community</p>
    <p>standard corpus.  TREC QA corpus - About 1M news articles.  50 definitional questions with answer nuggets.</p>
    <p>To assess the adaptability of the system to actual online news and recent questions.</p>
    <p>26 questions from Lycos.  Up to 200 news articles from each of eight news sites (e.g. CNN and</p>
    <p>BBC) for each question.</p>
    <p>Comparison Systems  Baseline system  centroid based ranking (IR).  A top ranked definitional question answering system at</p>
    <p>TREC2003  HCR  Hand-crafted definition patterns (a man-month of time to construct).</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Evaluation Metrics</p>
    <p>Based on given answer nuggets.  The most essential information about the target.</p>
    <p>Judged by human assessors.</p>
    <p>Nugget Precision (NP)  Penalty to longer answers.</p>
    <p>Nugget Recall (NR)  Proportion of returned nuggets to vital nuggets.</p>
    <p>F5-measure (weighting NR 5 times as NP)</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Evaluations on TREC Corpus</p>
    <p>Pattern matching has significant impact on definition sentence identification.</p>
    <p>Soft patterns are more effective for news text.</p>
    <p>F5 measure</p>
    <p>% improvement</p>
    <p>(over baseline)</p>
    <p>% improvement (over HCR)</p>
    <p>Centroid (Baseline)</p>
    <p>HCR 0.472 11.52%</p>
    <p>SP+GPRF (w = 1)</p>
    <p>SP+GPRF (w = 2)</p>
    <p>SP+GPRF (w = 3)</p>
    <p>SP+GPRF (w = 4)</p>
    <p>SP+GPRF (w = 5)</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Evaluations on the Web Corpus  Using two sets of soft</p>
    <p>patterns.  More pattern instances</p>
    <p>lead to better performance (683 from TREC vs. 375 from Lycos).</p>
    <p>Soft patterns are general enough to be applied to other corpora.  Makes offline training</p>
    <p>possible.</p>
    <p>F5 Measure %</p>
    <p>improvement (over baseline)</p>
    <p>Centroid (baseline) 0.492</p>
    <p>HCR 0.555 12.82%</p>
    <p>SP+GPRF (Lycos patterns)</p>
    <p>SP+GPRF (TREC patterns)</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Outline</p>
    <p>How Do Current Systems Identify Definitions?</p>
    <p>What are Soft Patterns?</p>
    <p>Matching Soft Patterns  Flexibility</p>
    <p>Unsupervised Learning of Soft Patterns</p>
    <p>Evaluations</p>
    <p>Conclusion and Future Work</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Conclusions and Future Work</p>
    <p>Current definition pattern matching has weaknesses  Lack of flexibility</p>
    <p>Manual labor</p>
    <p>We address them by  Soft patterns</p>
    <p>Unsupervised learning by Group PRF</p>
    <p>Soft patterns prove to be effective in Web-based definition generation systems.</p>
    <p>Future work  Soft patterns in information extraction and factoid question</p>
    <p>answering.</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Q &amp; A</p>
    <p>Thanks!</p>
    <p>Try our online demo at http://www-appn.comp.nus.edu.sg/~cuihang/ DefSearch/DefSearch.htm</p>
    <p>!</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Statistical Ranking  Centroid Word Weighting  Weighting the words by their co-occurrences with the</p>
    <p>search target.</p>
    <p>Words with the centrality weights beyond a predefined threshold form a centroid vector.</p>
    <p>Cosine similarity with the centroid vector used to rank the sentences.</p>
    <p>Top Ranked sentences by the centroid vector are deemed as definition sentence candidates.</p>
    <p>)( )1)_(log()1)(log(</p>
    <p>)1)_,(log( )(_ widf</p>
    <p>termschsfwsf</p>
    <p>termschwCo wCentrality termsch</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Sentence Selection</p>
    <p>We adopt a variation of Maximal Marginal Relevance (MMR) to summarize the definition sentences.</p>
    <p>To ensure relevance and to avoid redundancy.  Examine only the top ranked sentences and stop</p>
    <p>when the length of the definition is reached.  Different from MMR, which examines all sentences.</p>
    <p>Due to the noisy input sentences.</p>
  </div>
  <div class="page">
    <p>Hang Cui, MinYen Kan and Ta t-Seng Chua</p>
    <p>Compared to HMM</p>
    <p>Both address individual slot content and sequence fidelity.</p>
    <p>Soft patterns perform instance-based learning  can deal with  Small training set</p>
    <p>Noisy data from group pseudo-relevance feedback</p>
    <p>Online training</p>
    <p>HMM needs  More training data and time</p>
    <p>Explicit transition paths between states</p>
  </div>
</Presentation>
