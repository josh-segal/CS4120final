<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Shih-Fu Chang, Winston Hsu, Lyndon Kennedy, Akira Yanagawa, Eric Zavesky, Dong-Qing Zhang</p>
    <p>Digital Video and Multimedia Lab Columbia University</p>
    <p>Nov. 14 2005 http://www.ee.columbia.edu/dvmm</p>
    <p>Columbia University TRECVID 2005 Search Task</p>
    <p>TRECVID 2005 Workshop</p>
  </div>
  <div class="page">
    <p>Multi-modal Search Tools  combined text-concept search  story-based browsing  near-duplicate browsing</p>
    <p>Content Exploitation  multi-modal feature extraction  story segmentation  semantic concept detection</p>
    <p>User Level Search Objects  Query topic class mining  Cue-X reranking  Interactive activity log</p>
    <p>Columbia Video Search System Overview</p>
    <p>http://www.ee.columbia.edu/cuvidsearch</p>
    <p>automatic story</p>
    <p>segmentation</p>
    <p>video speech</p>
    <p>text</p>
    <p>near-duplicate detection</p>
    <p>concept detectionfeature</p>
    <p>extraction (text, video, prosody)</p>
    <p>concept search</p>
    <p>text search</p>
    <p>Image matching</p>
    <p>story browsing</p>
    <p>Near-duplicate search</p>
    <p>Interactive search</p>
    <p>automatic/manual search</p>
    <p>cue-X re-ranking</p>
    <p>mining query topic classes</p>
    <p>user search pattern mining</p>
  </div>
  <div class="page">
    <p>Information Bottleneck principle</p>
    <p>Cue-X Information-theoretic Framework</p>
    <p>low-level features</p>
    <p>cue-X clusters automatically discovered via Information Bottleneck principle &amp; Kernel Density Estimation (KDE)</p>
    <p>semantic label</p>
    <p>semantic clustering</p>
    <p>cluster cond. prob. (relevance to semantic label)</p>
    <p>= topic Arafat</p>
    <p>Y= story boundary</p>
    <p>Y=demonstration</p>
    <p>Y= search relevance</p>
  </div>
  <div class="page">
    <p>News Story Segmentation in TRECVID 2005  Cue-X framework effectively applied to discover salient features and</p>
    <p>achieve accurate story segmentation  Focus on visual and audio (prosody) features only  Without a priori manual selection of features  High accuracy across multi-lingual data sources</p>
    <p>TRECVID 2005  Dataset</p>
    <p>277 videos, 3 languages (ARB, CHN, and ENG),  7 channels, 10+ different programs  Poor or missing ASR/MT transcripts</p>
    <p>Accuracy on the validation set  Cue-X features + prosody features (no text features!)  ARB-0.87, CHN-0.84, and ENG-0.52 (F1 measure)</p>
    <p>Results donated to whole TRECIVD 2005 community  Story boundary results available for download at</p>
    <p>http://www.ee.columbia.edu/dvmm/downloads/cuex_story.htm</p>
  </div>
  <div class="page">
    <p>Enhancing Interactive Search Using Story Boundaries</p>
    <p>in other news pope john paul the second will get his first look at the shroud of turin today that's the piece of linen many believe was the burial cloth of jesus the round is on public display for the first time in twenty years it has already drawn up million visitors the pope's visit to northwest italy has also included beatification services for three people the vatican says john paul is now the longest serving pope this century he has surpassed pope pious the twelfth who served for nineteen years seven months and seven days</p>
    <p>Story Shot ShotShotShotShot</p>
    <p>Query</p>
    <p>Find shots of Pope John Paul second</p>
    <p>Stories define an intuitive unit with coherent semantics</p>
    <p>Story boundaries are effectively detected by Cue-X using audiovisual features</p>
    <p>Improves text search by more than 100% in TRECVID 2005 automatic search</p>
    <p>Major contributor to good performance of interactive video search</p>
    <p>Relative contributions from different search tools</p>
  </div>
  <div class="page">
    <p>Enhancing Semantic Concept Detection Performance Using Local Features and Spatial Context</p>
    <p>Color Moment</p>
    <p>Color Moment</p>
    <p>Global or block-based features: Difficult to achieve robustness against background clutter Difficult to model object appearance variations</p>
    <p>Part</p>
    <p>Part relation</p>
    <p>Part-based model: Eliminate background clutter Model part appearance more accurately Model part relation more accurately</p>
    <p>traditional</p>
    <p>enhanced</p>
  </div>
  <div class="page">
    <p>Extracting Graphical Representations of Visual Content and Learning Statistical Models of Content Classes</p>
    <p>Individual images Salient points, high entropy regions</p>
    <p>Attributed Relational Graph (ARG)</p>
    <p>Graph Representation of Visual Content</p>
    <p>size; color; texture</p>
    <p>Collection of training images</p>
    <p>Random Attributed Relational Graph (R-ARG)</p>
    <p>Statistical Graph Representation of Model</p>
    <p>Statistics of attributes and relations</p>
    <p>machine learning</p>
    <p>spatial relation</p>
  </div>
  <div class="page">
    <p>Parts-based detector performance in TRECVID 2005</p>
    <p>Parts-based detector consistently improves by more than 10% for all concepts</p>
    <p>It performs best for spatio-dominant concepts such as US flag.</p>
    <p>It complements nicely with the discriminant classifiers using fixed features.</p>
    <p>fixed feature Baseline</p>
    <p>Adding Parts-based</p>
    <p>Avg. performance over all concepts</p>
    <p>SVM fixed feature Baseline</p>
    <p>Adding Parts-based</p>
    <p>Spatio-dominant concepts: US Flag</p>
  </div>
  <div class="page">
    <p>Search Components: Detecting Image Near Duplicates (IND)</p>
    <p>Scene Change</p>
    <p>Camera Change</p>
    <p>Digitization Digitization</p>
    <p>Parts-based Stochastic Attribute Relational Graph Learning</p>
    <p>Stochastic graph models the physics of scene transformation</p>
    <p>Measure IND likelihood ratio</p>
    <p>Learning PoolLearning</p>
    <p>Near duplicates occur frequently in multi-channel broadcast</p>
    <p>But difficult to detect due to diverse variations</p>
    <p>Problem Complexity Similarity matching &lt; IND detection &lt;</p>
    <p>object recognition</p>
    <p>Duplicate detection is the single most effective tool in our Interactive Search</p>
  </div>
  <div class="page">
    <p>Subshots</p>
    <p>Concept Search Query</p>
    <p>Documents</p>
    <p>Query Text Find shots of a road with one or more cars</p>
    <p>Part-of-Speech Tags - keywords road car</p>
    <p>Map to concepts WordNet Resnik semantic similarity</p>
    <p>Concept Metadata Names and Definitions</p>
    <p>Concept Space 39 dimensions</p>
    <p>(1.0) road (0.1) fire (0.2) sports (1.0) car . (0.6) boat (0.0) person</p>
    <p>Confidence for each concept</p>
    <p>Concept Models</p>
    <p>Simple SVM, Grid Color Moments,</p>
    <p>Gabor Texture</p>
    <p>Concept Reliability</p>
    <p>Expected AP for each concept.</p>
    <p>Concept Space 39 dimensions</p>
    <p>(0.9) road (0.1) fire (0.3) sports (0.9) car . (0.2) boat (0.1) person</p>
    <p>(0.9) road (0.1) fire (0.3) sports (0.9) car . (0.2) boat (0.1) person</p>
    <p>(0.9) road (0.1) fire (0.3) sports (0.9) car . (0.2) boat (0.1) person</p>
    <p>(0.9) road (0.1) fire (0.3) sports (0.9) car . (0.2) boat (0.1) person</p>
    <p>(0.9) road (0.1) fire (0.3) sports (0.9) car . (0.2) boat (0.1) person</p>
    <p>E uclidean D</p>
    <p>istance</p>
    <p>Map text queries to high-level feature detection</p>
    <p>Use humandefined keywords from concept definitions</p>
    <p>Measure semantic distance between query and concept</p>
    <p>Use detection and reliability for subshot documents</p>
  </div>
  <div class="page">
    <p>Concept Search</p>
    <p>APMethod</p>
    <p>Automatic - Can help for queries with related concepts Find shots of boats.</p>
    <p>APMethod Find shots of a road with one or more cars.</p>
    <p>Manual / Interactive Manual keyword selection allows more relationships to be found.</p>
    <p>Query Text Find shots of an office setting, i.e., one or more desks/tables and one or more computers and one or more people</p>
    <p>Concepts Office</p>
    <p>Query Text Find shots of a graphic map of Iraq, location of Bagdhad marked - not a weather map</p>
    <p>Concepts Map</p>
    <p>Query Text Find shots of one or more people entering or leaving a building</p>
    <p>Concepts Person, Building, Urban</p>
    <p>Query Text Find shots of people with banners or signs</p>
    <p>Concepts March or protest</p>
  </div>
  <div class="page">
    <p>Cue-X Reranking by Pseudo-Labeling</p>
    <p>cue-x clustering &amp; ranking clusters by</p>
    <p>Learn the recurrent relevant and irrelevant low-level patterns from the estimated pseudo-labels</p>
    <p>Reorder shots by the smoothed cluster relevance</p>
    <p>pseudo-label, random variable: Y</p>
    <p>+ + + + +</p>
    <p>Text Search</p>
    <p>- OKAPI text query - Yahoo - Google</p>
    <p>rank withincluster features by density prob.</p>
    <p>use only</p>
    <p>estimated from rough search results (e.g., text search scores), user feedbacks, etc.</p>
    <p>low-level feature: X</p>
    <p>Query: AL clinic bombing rough shot list (1) (2)</p>
    <p>(4)</p>
    <p>(3)</p>
    <p>feature &amp; pseudo-label smoothing w/ kernels</p>
    <p>soft pseudo-labeling</p>
    <p>(5)</p>
    <p>(6)</p>
  </div>
  <div class="page">
    <p>Effect of Cue-X Reranking in Video Search  Improvement over story-based text search (in automatic search</p>
    <p>TRECVID 2005)  17% in MAP, 46% in soccer (171), 36% in helicopter (158), 32% in Blair (153),</p>
    <p>topic: soccer (171) reranked resultstext search (goal soccer match )</p>
    <p>topic: Blair (153) reranked resultstext search (tony blair )</p>
  </div>
  <div class="page">
    <p>Automatic Discovery of Multimodal Query Classes</p>
    <p>Distinct query classes use customized fusion strategies</p>
    <p>How to automatically discover query classes?</p>
    <p>When and how does each modality help for each query?</p>
    <p>Existing methods: define query classes using human knowledge.</p>
    <p>New method: discover queries according to performance and semantics of searches.</p>
    <p>Find Person A</p>
    <p>Find Person B</p>
    <p>Find Person C</p>
    <p>Find Event D</p>
    <p>Find Event E</p>
    <p>Find Object F</p>
    <p>Find Object G</p>
    <p>Query Semantics Search Performance</p>
    <p>Video Text Audio</p>
    <p>Key:</p>
    <p>Automatic Joint semanticsperformance grouping</p>
    <p>Manually defined query classes</p>
  </div>
  <div class="page">
    <p>Auto. Discovered Query Clusters</p>
    <p>Learned over a large query topic pool</p>
    <p>Text search and person-X  named persons</p>
    <p>Image search  named objects,  sports, and  generic scene classes</p>
    <p>Automated term expansion  Google class for cats, birds and airport terminals.</p>
    <p>Named persons</p>
    <p>Named objects</p>
    <p>sports</p>
    <p>Google expansion</p>
    <p>Generic scenes</p>
  </div>
  <div class="page">
    <p>Post-Mortem Analysis  Analyze inter-labeler disparity  Find difficult search topics by high</p>
    <p>common error rate  Discover where certain tools failed  In the future, use actions as passive</p>
    <p>relevance feedback rounds</p>
    <p>Example Log Detail</p>
    <p>Interactive Activity Logging Detailed</p>
    <p>search and topic criterion</p>
    <p>Aggregate tool actions by</p>
    <p>search time</p>
    <p>Monitor labeling to understand interface</p>
    <p>usage</p>
    <p>Ground truth included in</p>
    <p>label actions</p>
    <p>Label Disparity</p>
    <p>topic 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 Topic Id</p>
    <p>A bs</p>
    <p>E rr</p>
    <p>or D</p>
    <p>iff er</p>
    <p>en ce</p>
    <p>user1_true</p>
    <p>user2_true</p>
    <p>user3_true</p>
    <p>user4_true</p>
    <p>user1_diff</p>
    <p>user2_diff</p>
    <p>user3_diff</p>
    <p>user4_diff</p>
  </div>
  <div class="page">
    <p>Automatic Search (Performance Breakdown)</p>
    <p>Largest improvement from story segmentation Noticeable improvements from other components</p>
    <p>especially cue-x rerank and concept search</p>
    <p>Text+Story+Anchor Removal +CueX Re-rank +CBIR+Concept Search</p>
    <p>Text+Story+Anchor Removal +CueX Re-rank +CBIR0.111</p>
    <p>Text+Story+Anchor Removal +CueX Re-rank0.107</p>
    <p>Text+Story+Anchor Removal0.095</p>
    <p>Text+Story0.087</p>
    <p>Text0.039</p>
    <p>ComponentsMAP</p>
    <p>text baseline</p>
    <p>+ story boundary</p>
    <p>+ Cue-X re-rank (visual features)</p>
    <p>+ concept search</p>
    <p>MAP</p>
    <p>Run</p>
  </div>
  <div class="page">
    <p>Automatic Search</p>
    <p>Ri ce</p>
    <p>Al la</p>
    <p>w i</p>
    <p>Ka ra</p>
    <p>m i</p>
    <p>Jin ta</p>
    <p>o Bl</p>
    <p>ai r</p>
    <p>Ab ba</p>
    <p>s</p>
    <p>Ba gh</p>
    <p>da d</p>
    <p>m ap</p>
    <p>te nn</p>
    <p>is</p>
    <p>sh ak</p>
    <p>in g</p>
    <p>ha nd</p>
    <p>s he</p>
    <p>lic op</p>
    <p>te r</p>
    <p>Bu sh fir</p>
    <p>e ba</p>
    <p>nn er</p>
    <p>s</p>
    <p>en te</p>
    <p>r bu</p>
    <p>ild in</p>
    <p>g m</p>
    <p>ee tin</p>
    <p>g bo</p>
    <p>at ba</p>
    <p>sk et</p>
    <p>ba ll</p>
    <p>pa lm</p>
    <p>tr ee</p>
    <p>s ai</p>
    <p>rp la</p>
    <p>ne ro</p>
    <p>ad c</p>
    <p>ar s</p>
    <p>m ili</p>
    <p>ta ry</p>
    <p>v eh</p>
    <p>ic le</p>
    <p>s bu</p>
    <p>ild in</p>
    <p>g so</p>
    <p>cc er</p>
    <p>of fic</p>
    <p>e</p>
    <p>Topic</p>
    <p>Multimodal Automatic Search Max Official Median Official</p>
  </div>
  <div class="page">
    <p>Interactive Tool Contribution Varied search strategies  User 1: prefers story browsing,</p>
    <p>duplicate and traditional search  User 2: no story discovery, use</p>
    <p>lots of duplicate browsing</p>
    <p>Strategy dynamic for each topic  Common visual concepts good</p>
    <p>candidates for duplicates  Temporal events best suited for</p>
    <p>discovery by story browsing  Named entities or specific</p>
    <p>actions usually best in traditional search methods</p>
    <p>Top-ranking interactive searches</p>
    <p>User 1</p>
    <p>User 2</p>
  </div>
  <div class="page">
    <p>Formula for Success: 1. Find positives through any</p>
    <p>search method 2. Iteratively browse through the</p>
    <p>near-duplicates or story browsing</p>
    <p>Close to Best 149 (Rice), 151 (Karami), 153 (Blair), 154 (Abbas), 157 (shaking hands), 161 (banners), 166 (palm trees), 168 (roads/cars), 169 (military vehicles), and 171 (soccer)</p>
    <p>Best Overall Performance 160 (fire), 164 (boat), and 162 (entering building)</p>
    <p>Interactive Search</p>
  </div>
</Presentation>
