<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Peeking Behind the Curtains of Serverless Platforms</p>
    <p>Liang Wang1 , Mengyuan Li2, Yinqian Zhang2 , Thomas Ristenpart3, Michael Swift1</p>
  </div>
  <div class="page">
    <p>Providers do more, tenant do less</p>
    <p>Physical Machine</p>
    <p>VM</p>
    <p>Server Scaling Uptime</p>
    <p>APP</p>
    <p>Serverless (FaaS)</p>
    <p>Non-controllable Controllable</p>
    <p>Physical Machine</p>
    <p>VM</p>
    <p>PaaS</p>
    <p>Server Scaling Uptime</p>
    <p>APP</p>
    <p>Physical Machine</p>
    <p>APP</p>
    <p>VM</p>
    <p>IaaS</p>
    <p>Server Scaling Uptime</p>
    <p>APP</p>
  </div>
  <div class="page">
    <p>Benefits of serverless</p>
    <p>Function Tenant</p>
    <p>Serverless provider</p>
    <p>Function: Standalone, small application dedicated to specific tasks</p>
    <p>Function Deploy</p>
    <p>Minimal configuration  No efforts on server management  Low cost</p>
  </div>
  <div class="page">
    <p>Serverless ecosystem</p>
    <p>Source: https://venturebeat.com/2017/10/22/the-big-opportunities-in-serverless-computing/</p>
  </div>
  <div class="page">
    <p>Lots of questions about serverless</p>
    <p>Are applications resistant to DDos attacks in serverless?</p>
    <p>Are functions secure in serverless?</p>
    <p>Can serverless providers deliver guaranteed performance?</p>
    <p>We need better methodology and more systematic measurement to answer these questions</p>
  </div>
  <div class="page">
    <p>Contributions  In-depth study of resource management and performance isolation in</p>
    <p>Identify opportunities to improve serverless platforms o AWS: Bad performance isolation, function consistency issue,  o Azure: Unpredictable performance, tenant isolation issues,  o Google: Resource accounting bug,</p>
    <p>Open-source measurement tool (https://github.com/liangw89/faas_measure)</p>
    <p>Azure Functions Google Cloud FunctionsAWS Lambda</p>
  </div>
  <div class="page">
    <p>Overview  Background</p>
    <p>Methodology</p>
    <p>Highlighted results o Serverless architectures o Resource scheduling o Performance isolation o Bugs</p>
  </div>
  <div class="page">
    <p>How serverless works</p>
    <p>Serverless provider</p>
    <p>Function User Request</p>
    <p>VM</p>
    <p>Function Container</p>
    <p>Response</p>
    <p>A function runs in a container (function instance) launched by the providerwith limited CPU/memory/execution time</p>
    <p>Launch</p>
  </div>
  <div class="page">
    <p>VM</p>
    <p>How serverless works</p>
    <p>Serverless provider</p>
    <p>Function User</p>
    <p>Function Container</p>
    <p>The function instance will be frozen after returning from invocation</p>
    <p>Pause New requests: Reactivated</p>
    <p>Tenants dont need to pay while instances are paused</p>
  </div>
  <div class="page">
    <p>VM</p>
    <p>How serverless works</p>
    <p>Serverless provider</p>
    <p>Function</p>
    <p>User Concurrent requests</p>
    <p>VM</p>
    <p>Responses</p>
    <p>Providers manage backend infrastructures and resource for tenants</p>
    <p>Scale up</p>
  </div>
  <div class="page">
    <p>Methodology</p>
    <p>Azure Functions</p>
    <p>Google Cloud Functions</p>
    <p>AWS Lambda</p>
    <p>Measurement function  Collect information via procfs/cmd/env  Execute performance tests</p>
    <p>Setting variables:  Function memory  Function language  Request frequency  Concurrent request</p>
    <p>Invoke measurement functions many times (50K+) under various settings from vantage points in the same cloud region</p>
    <p>Time: JulyDec 2017, May 2018</p>
  </div>
  <div class="page">
    <p>Tool 1: Map requests to instances</p>
    <p>Inst1 Request 1</p>
    <p>Instance identification: Write a unique file on /tmp  persistent during instance lifetime</p>
    <p>Result + inst1.txt (new inst!)</p>
    <p>inst1.txt</p>
    <p>Inst2</p>
    <p>inst2.txt Request 2</p>
    <p>Result + inst1.txt (inst1 ran again!)</p>
    <p>Request 3</p>
    <p>Result + inst2.txt (new inst!)</p>
    <p>Which instance handled the request?</p>
  </div>
  <div class="page">
    <p>VM2</p>
    <p>Tool 2: Map instances to VMs</p>
    <p>Requests</p>
    <p>VM identification:  AWS: An entry in the /proc/self/cgroup  Azure: The WEBSITE_INSTANCE_ID environment variable  Google: Unknown</p>
    <p>Results + Inst ID + VM ID</p>
    <p>VM1 VM ID = abc</p>
    <p>VM ID = abc</p>
    <p>VM ID = xyz</p>
    <p>Verified via I/O-based and Flush-Reload coresidency tests</p>
    <p>Are instances on the same VM?</p>
  </div>
  <div class="page">
    <p>Highlighted results</p>
    <p>Serverless architectures</p>
    <p>Resource scheduling</p>
    <p>Performance isolation</p>
    <p>Bugs</p>
  </div>
  <div class="page">
    <p>Do multiple tenants instances run on the same VM?</p>
    <p>AWS: No  VM only hosts functions from single tenant</p>
    <p>AWS</p>
    <p>VM1 VM2 Tenant A func1</p>
    <p>Tenant A func2</p>
    <p>Tenant B func3</p>
    <p>Azure</p>
    <p>VM1</p>
    <p>Tenant A</p>
    <p>func1 func2</p>
    <p>Tenant B</p>
    <p>Azure:  2017: Yes  VM hosts functions from multiple tenants  2018: No. But other platforms still do this: Spotinst, stdlib, webtask.io</p>
    <p>Google: Unknown</p>
    <p>Cross-tenant VM sharing make applications vulnerable to side-channel attacks</p>
  </div>
  <div class="page">
    <p>Do VMs have the same configurations? Methodology: Examine procfs and env variables of the host VMs of 50 K function instances</p>
    <p>AWS: 5 CPU configurations (1 or 2 vCPUs, 4 CPU models) Azure: 9 configurations ( 1 or 2 or 4 vCPUs, 4 CPU models) Google: 4 configurations (4 CPU models)</p>
    <p>AWS</p>
    <p>Google model version</p>
    <p>Azure</p>
    <p>Different types of VMs could result in different instance performance</p>
  </div>
  <div class="page">
    <p>Highlighted results</p>
    <p>Serverless architectures</p>
    <p>Resource scheduling</p>
    <p>Performance isolation</p>
    <p>Bugs</p>
  </div>
  <div class="page">
    <p>Can the platforms effectively handle concurrent requests?</p>
    <p>Azure/Google: Dont deliver promised scalability</p>
    <p>Methodology: send N concurrent requests and examine the number of instances running concurrently</p>
    <p>N # Requests</p>
    <p># In st an ce</p>
    <p>AWS: N</p>
    <p>Google: N / 2</p>
    <p>Azure: 10</p>
  </div>
  <div class="page">
    <p>How long does it take to launch an instance?</p>
    <p>AWS</p>
    <p>b</p>
    <p>Google</p>
    <p>Azure</p>
    <p>AWS: 160 ms</p>
    <p>Google: 500 ms (2017)  2000 ms (2018)</p>
    <p>Azure: 3600 ms (2017)  300 ms (2018)</p>
    <p>Coldstart might affect tail latencies</p>
    <p>Median coldstart latency per hour over 7 days (2017)</p>
    <p>m s</p>
    <p>m s</p>
    <p>m s</p>
    <p>Median coldstart latency of 1000 instances</p>
  </div>
  <div class="page">
    <p>Highlighted results</p>
    <p>Serverless architectures</p>
    <p>Resource scheduling</p>
    <p>Performance isolation</p>
    <p>Bugs</p>
  </div>
  <div class="page">
    <p>What can affect performance?  CPU share: fraction of 1000-ms time period for which the instance can use CPU</p>
    <p>IO throughput: Write 512 KB of data to the local disk 1,000 times (via dd or scripts)</p>
    <p>Network throughput: Use iperf3 to run the throughput test for 10 seconds</p>
    <p>AWS Azure Google</p>
    <p>Coresidency Yes Yes Unknown VM configuration No Yes No</p>
    <p>Factors affecting performance:</p>
  </div>
  <div class="page">
    <p>How instances are placed on VMs AWS: Bin-packing; use at most 3328 MB VM memory</p>
    <p>Azure: Random</p>
    <p>Google: Unknown</p>
    <p>AWS Lambda VM memory utilization: 85-100%</p>
    <p>AWS: Easy for instances from the same tenant to be coresident</p>
    <p>N o. o f V</p>
    <p>M s</p>
    <p>No. of instances</p>
    <p>AWS: No. of VMs being used for a given number of instances (128 MB)</p>
  </div>
  <div class="page">
    <p>(Estimated based on the median performance across coresident instances, over 50 rounds)</p>
    <p>CPU IO Network</p>
    <p>AWS</p>
    <p>CPU IO Netowrk</p>
    <p>Azure</p>
    <p>same</p>
    <p>Coresident instances contend for VM resources</p>
    <p>Resources are allocated per VM More co-residency decreases resources per function</p>
  </div>
  <div class="page">
    <p>(Estimated based on the median performance across coresident instances, over 50 rounds)</p>
    <p>CPU IO Network</p>
    <p>AWS</p>
    <p>CPU IO Netowrk</p>
    <p>Azure</p>
    <p>same</p>
    <p>Coresident instances contend for VM resources</p>
    <p>Resources are allocated per VM More co-residency decreases resources per function</p>
  </div>
  <div class="page">
    <p>AWS/Google: CPU share is proportional to memory</p>
    <p>AWS Google</p>
    <p>More memory --&gt; More CPU --&gt; Better performance</p>
    <p>Function memory (MB)</p>
    <p>F ra</p>
    <p>c ti o n</p>
    <p>CPU share Mem*2/3328</p>
    <p>Function memory (MB)</p>
    <p>F ra</p>
    <p>c ti o n</p>
    <p>CPU share</p>
    <p>AWS: Functions of 128 MB memory can use CPU for 80 ms in 1000 ms Functions of 1.5 GB memory can use CPU for 900 ms in 1000 ms</p>
  </div>
  <div class="page">
    <p>AWS Azure Google</p>
    <p>Coresidency Yes Yes Unknown VM configuration No Yes No</p>
    <p>What can affect performance?  CPU share: fraction of 1000-ms time period for which the instance can use CPU</p>
    <p>IO throughput: Write 512 KB of data to the local disk 1,000 times (via dd or scripts)</p>
    <p>Network throughput: Use iperf3 to run the throughput test for 10 seconds</p>
    <p>Factors affecting performance:</p>
  </div>
  <div class="page">
    <p>Azure: VM configurations affect performance</p>
    <p>% o f i ns ta nc es</p>
    <p>Azure:</p>
    <p>Same function + fewer resources = longer running time = more money</p>
    <p>CPU share</p>
  </div>
  <div class="page">
    <p>Highlighted results</p>
    <p>Serverless architectures</p>
    <p>Resource scheduling</p>
    <p>Performance isolation</p>
    <p>Bugs</p>
  </div>
  <div class="page">
    <p>Can AWS propagate function updates correctly?</p>
    <p>Instance set A</p>
    <p>Memory IAM roles Environment variable Function code</p>
    <p>Update 1 of:</p>
    <p>Did any instances in set B run func instead of func?</p>
    <p>func</p>
    <p>func func</p>
    <p>func</p>
    <p>Instance set B</p>
    <p>Methodology:</p>
  </div>
  <div class="page">
    <p>AWS: Inconsistent function usage</p>
  </div>
  <div class="page">
    <p>AWS: Inconsistent function usage</p>
    <p>Case 1: New instances ran outdated functions (0.1%)</p>
  </div>
  <div class="page">
    <p>AWS: Inconsistent function usage</p>
    <p>Case 1: New instances ran outdated functions (0.1%)</p>
    <p>Case 2: Requests handled by the instances for outdated functions (3.7%)</p>
  </div>
  <div class="page">
    <p>AWS: Inconsistent function usage</p>
    <p>Case 1: New instances ran outdated functions (0.1%)</p>
    <p>Case 2: Requests handled by the instances for outdated functions (3.7%)</p>
    <p>Inconsistent responses to users</p>
  </div>
  <div class="page">
    <p>Google: Stealthy background process Processes can run after function invocation concluded</p>
    <p>exports.handler = function handler(req, res) { // run asynchronous task here.</p>
    <p>line A: user_task(); // send back results.</p>
    <p>line B: res.status(http_code).send(user_data); }</p>
    <p>Nodejs will execute line B without waiting for user_task returns</p>
    <p>Processes can stay alive for to 21 hours  No billing  Use extra resources for free!</p>
    <p>Method:</p>
  </div>
  <div class="page">
    <p>Google: Stealthy background process Processes can run after function invocation concluded</p>
    <p>exports.handler = function handler(req, res) { // run asynchronous task here.</p>
    <p>line A: user_task(); // send back results.</p>
    <p>line B: res.status(http_code).send(user_data); }</p>
    <p>Nodejs will execute line B without waiting for user_task returns</p>
    <p>Method:</p>
    <p>Google should monitor the resource usage of the entire function instance rather than the Nodejs processes</p>
  </div>
  <div class="page">
    <p>Summary  In-depth measurement study that discover various issues in three serverless computing platforms o Unpredictable performance o Bad performance isolation o Consistency issues</p>
    <p>Performance baselines and design considerations for future design of serverless platforms</p>
    <p>Responsible disclosure</p>
  </div>
</Presentation>
