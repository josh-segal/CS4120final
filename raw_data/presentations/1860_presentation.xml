<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Low-Profile Source-side Deduplication</p>
    <p>for Virtual Machine Backup</p>
    <p>Daniel Agun, Tao Yang</p>
    <p>University of California at Santa Barbara</p>
    <p>Wei Zhang</p>
    <p>Pure Storage</p>
  </div>
  <div class="page">
    <p>Cloud Platform and VM Snapshot Backup</p>
    <p>Public and private IaaS cloud systems have become</p>
    <p>industry standard</p>
    <p>Frequent virtual machine snapshot backups improves</p>
    <p>system reliability</p>
    <p>Backup traffic of VM snapshots with limited source</p>
    <p>side deduplication is huge.</p>
    <p>100,000VMs with 76% dirty bit detection still requires ~1</p>
    <p>petabyte of networking with 40GB per VM snapshot</p>
  </div>
  <div class="page">
    <p>Objective: Aggressive Source-Side Deduplication</p>
    <p>With low-profile computing</p>
    <p>Backup data daily for tens of thousand VMs within a few hours</p>
    <p>each day.</p>
    <p>Minimize network traffic via aggressive source-side</p>
    <p>deduplication</p>
    <p>State-of-art deduplication algorithms are memory/compute</p>
    <p>intensive</p>
    <p>Resource friendly  small memory footprint and CPU usage,</p>
    <p>minimum impact to primaryservices</p>
    <p>Backup</p>
    <p>Cloud service</p>
  </div>
  <div class="page">
    <p>Strategies for Scalable/Low-cost Aggressive</p>
    <p>Source-Side Deduplication</p>
    <p>Focus on popular data chunks shared among snapshots</p>
    <p>Zipf distribution. Top 2-4% of most popular items</p>
    <p>(plus inner-VM dedup) accomplishes ~98%</p>
    <p>deduplication efficiency.</p>
    <p>Cluster-based deduplication</p>
    <p>Distribute VM chunk signatures to cluster machines</p>
    <p>Minimize job completion time instead of individual</p>
    <p>chunk backup time.</p>
    <p>Approximated snapshot deletion</p>
    <p>VM snapshot chunk index</p>
  </div>
  <div class="page">
    <p>Example datasets</p>
    <p>from Alibaba.</p>
    <p>Left: 4200 VMs with</p>
    <p>max/average VM size= 20.</p>
    <p>Right 8000 VMs with max/avg=45</p>
    <p>Low-cost source-side cluster-based deduplication</p>
    <p>Given a set of VMs to be backed up, find if their block</p>
    <p>signatures are duplicates of the existing snapshot blocks.</p>
    <p>Challenge in control buffer size during data shuffling</p>
    <p>Complicated by uneven VM size distribution.</p>
    <p>buffer</p>
    <p>buffer</p>
  </div>
  <div class="page">
    <p>Multi-round Collaborative Deduplication</p>
    <p>Major stages of each duplicate detection round</p>
    <p>k rounds</p>
    <p>Stage 1: Collect fingerprints in parallel</p>
    <p>Stage 2: Detect duplicates in parallel</p>
    <p>Stage 3: Perform actual VM backup in parallel</p>
    <p>k too small  more</p>
    <p>buffering needed</p>
    <p>k too large  more</p>
    <p>dedup overhead</p>
    <p>Choose k so that</p>
    <p>buffer memory  100MB</p>
  </div>
  <div class="page">
    <p>How many rounds of backup batches?</p>
    <p>Estimate # of rounds k based on memory usage per node</p>
    <p>p is the number of physical machines.</p>
    <p>V is number of VMs hosted per machine</p>
    <p>q is the number of fingerprint partitions per machine</p>
    <p>D is size of modified data per VM</p>
    <p>is percentage of unique chunks among dirty data</p>
    <p>accumulated</p>
    <p>b is the average number of snapshot versions per VM.</p>
    <p>r is the ratio of chunk size over index entry size</p>
    <p>p=100, V=25, D=8.8GB,  =22.8%, b=10, r=136, q=400</p>
    <p>k=12. 9% of VMs is handled per batch</p>
    <p>100MB</p>
  </div>
  <div class="page">
    <p>Low-cost Design for Snapshot Deletion</p>
    <p>Snapshot deletion is as frequent as creation</p>
    <p>Identifying unused chunks with reference counting is</p>
    <p>costly</p>
    <p>Grouped Mark-and-sweep [Guo et. al , ATC11]: A block</p>
    <p>can be deleted if its reference count is zero</p>
    <p>Our approximate approach</p>
    <p>Separate strategies for popular chunks (2-4%) and non</p>
    <p>popular inner VM chunks.</p>
    <p>Approximate deletion for VM-specific chunks with</p>
    <p>bloom filter</p>
    <p>Snapshots Snapshots Snapshots</p>
  </div>
  <div class="page">
    <p>Summary vector to detect the usage of a chunk within a VM.</p>
    <p>Use bloom filter to summarize snapshots of VM</p>
    <p>Summary vectors of live snapshots represent the chunks in use</p>
    <p>Checking the existence of a chunk reference is fast</p>
    <p>Tolerate small percentage of storage leak to allow fast deletion with</p>
    <p>approximation</p>
    <p>Approximate Deletion for VM-specific chunks</p>
    <p>Snapshots</p>
    <p>How often to repair leakage?</p>
  </div>
  <div class="page">
    <p>Leakage Analysis: How Often to Repair?</p>
    <p>Periodically repair with mark-and-sweep to remove false</p>
    <p>negatives (those with 0 reference, but not removed)</p>
    <p>u : the initial size of a snapshot</p>
    <p>u: average VM change between consecutive snapshots.</p>
    <p>Total chunks stored after h snapshots per VM:</p>
    <p>U=u+(h-1) u</p>
    <p>Total leakage after R rounds: L=R u</p>
    <p>is the misjudgement rate of bloom-filter summary vector</p>
    <p>How often to repair?</p>
    <p>With daily backup, u/u=2.5%, h=10, t=0.1,  R=19.6 days</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Prototype implementation in C. Evaluated on a Linux cluster of</p>
    <p>Test data from Alibaba Aliyuan cloud</p>
    <p>41TB. 10 snapshots per VM for 2500 VMs</p>
    <p>Segment size: 2MB. Avg. chunk size: 4KB.</p>
    <p>SHA-1 fingerprint hash.</p>
    <p>Evaluation objectives</p>
    <p>Compare resource usage of three source-side</p>
    <p>deduplication methods: 1) dirty bit. 2) Synchronous</p>
    <p>method. 2) Collaborative multi-round with k=12.</p>
    <p>Impact of multi-round scheduling on backup job span</p>
    <p>Compare exact deletion with approximate deletion on</p>
    <p>resource usage, time, and space leakage.</p>
  </div>
  <div class="page">
    <p>Data Characteristics</p>
    <p>Each VM uses 40GB storage space on average</p>
    <p>OS and user data disks: each takes ~50% of space</p>
    <p>OS data : Debian, Ubuntu, Redhat, CentOS, Win2003</p>
    <p>Zipf-like distribution of VM OS/user data:</p>
    <p>frequency of any chunk is inversely proportional to its</p>
    <p>rank in the frequency table</p>
  </div>
  <div class="page">
    <p>Resource Comparison</p>
    <p>Resource usage comparison per snapshot.</p>
    <p>Local disk IO and memory costs are per machine.</p>
    <p>Storage and network cost are for 100 physical machines after</p>
    <p>deduplication.</p>
    <p>Aggressive source-side deduplication incurs 4.55x less space and</p>
  </div>
  <div class="page">
    <p>Job time comparison</p>
    <p>Job span in hours (total time for backup of all VM snapshots)</p>
    <p>Average per-VM backup time</p>
    <p>Even VM size distribution vs skewed distribution with</p>
    <p>max/average size=20.</p>
    <p>Multiround collaborative processing with k=12</p>
    <p>is 21x faster than synchronous method for job span.</p>
  </div>
  <div class="page">
    <p>Effectiveness of Approximate Deletion</p>
    <p>Processing time and per-machine memory usage of four</p>
    <p>deletion methods.</p>
    <p># of machines: p= 50 and 100 while # of VMs per machine=25</p>
    <p>Approximate deletion is 3114x faster than the grouped</p>
    <p>mark&amp;sweep method.</p>
    <p>Leakage repair is 53x faster with 35% to 96% less memory usage</p>
  </div>
  <div class="page">
    <p>Contributions &amp; Conclusions</p>
    <p>Scalable low-profile multi-round source-side deduplication for</p>
    <p>frequent VM snapshot backup.</p>
    <p>For the tested dataset,</p>
    <p>Network cost: 4x and storage cost is reduced by 4.55x</p>
    <p>compared to a dirty-bit based method.</p>
    <p>Multi-round deduplication is an order of magnitude faster</p>
    <p>than a synchronous scheme in dealing a skewed load.</p>
    <p>Approximate snapshot deletion only requires 15MB per</p>
    <p>machine</p>
    <p>3114x faster than the grouped mark&amp;sweep method.</p>
    <p>Leakage repair is 53x faster with 35% to 96% less memory</p>
    <p>usage.</p>
  </div>
  <div class="page">
    <p>Thank You!</p>
    <p>Questions?</p>
  </div>
</Presentation>
