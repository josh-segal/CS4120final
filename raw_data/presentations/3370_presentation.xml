<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Crowdscreen: Algorithms for Filtering Data using Humans</p>
    <p>Aditya Parameswaran</p>
    <p>Stanford University</p>
    <p>(Joint work with Hector Garcia-Molina, Hyunjung Park, Neoklis Polyzotis, Aditya Ramesh, and Jennifer</p>
    <p>Widom)</p>
  </div>
  <div class="page">
    <p>Why? Many tasks done better by humans</p>
    <p>Crowdsourcing: A Quick Primer</p>
    <p>Pick the cuter cat Pick the cuter cat Is this a photo of a car?</p>
    <p>Is this a photo of a car?</p>
    <p>How? We use an internet marketplace</p>
    <p>Requester: Aditya Reward: 1$ Time: 1 day</p>
    <p>Requester: Aditya Reward: 1$ Time: 1 day</p>
    <p>Asking the crowd for help to solve problems</p>
  </div>
  <div class="page">
    <p>Crowd Algorithms</p>
    <p>Working on fundamental data processing algorithms that use humans: Max [SIGMOD12] Filter [SIGMOD12] Categorize [VLDB11] Cluster [KDD12] Search Sort</p>
    <p>Using human unit operations: Predicate Eval., Comparisons, Ranking, Rating</p>
    <p>Goal: Design efficient crowd algorithmsGoal: Design efficient crowd algorithms</p>
  </div>
  <div class="page">
    <p>Efficiency: Fundamental Tradeoffs</p>
    <p>LatencyLatency</p>
    <p>CostCost</p>
    <p>Uncertaint y</p>
    <p>Uncertaint y</p>
    <p>How much $$ can I spend?</p>
    <p>How much $$ can I spend?</p>
    <p>How long can I wait?</p>
    <p>How long can I wait?</p>
    <p>What is the desired quality?</p>
    <p>What is the desired quality?</p>
    <p>Which questions do I ask humans?  Do I ask in sequence or in parallel?  How much redundancy in questions?  How do I combine the answers?  When do I stop?</p>
    <p>Which questions do I ask humans?  Do I ask in sequence or in parallel?  How much redundancy in questions?  How do I combine the answers?  When do I stop?</p>
  </div>
  <div class="page">
    <p>Filter</p>
    <p>Dataset of Items</p>
    <p>Dataset of Items</p>
    <p>PredicatePredicate</p>
    <p>Y Y N Item X satisfies</p>
    <p>predicate? Item X satisfies</p>
    <p>predicate?</p>
    <p>Predicate 1</p>
    <p>Predicate 1</p>
    <p>Predicate 2</p>
    <p>Predicate 2  Predicate</p>
    <p>k Predicate</p>
    <p>k</p>
    <p>Single</p>
    <p>Is this an image of Paris? Is this an image of Paris?</p>
    <p>Is the image blurry? Is the image blurry?</p>
    <p>Does it show peoples faces? Does it show peoples faces?</p>
    <p>Filtered Dataset Filtered Dataset</p>
    <p>Applications: Content Moderation, Spam Identification, Determining Relevance, Image/Video Selection, Curation, and</p>
    <p>Management,</p>
    <p>Applications: Content Moderation, Spam Identification, Determining Relevance, Image/Video Selection, Curation, and</p>
    <p>Management,</p>
  </div>
  <div class="page">
    <p>Parameters</p>
    <p>LatencyLatency</p>
    <p>CostCost</p>
    <p>Uncertaint y</p>
    <p>Uncertaint y</p>
    <p>Given: Per-question human error probability (FP/FN)</p>
    <p>Selectivity</p>
    <p>Goal: Compose filtering strategies, minimizing across all items Overall expected cost (# of questions)</p>
    <p>Overall expected error</p>
  </div>
  <div class="page">
    <p>Our Visualization of Strategies</p>
    <p>NOs</p>
    <p>YESs</p>
    <p>continue</p>
    <p>decide PASS</p>
    <p>decide FAIL</p>
  </div>
  <div class="page">
    <p>Common Strategies</p>
    <p>Always ask X questions, return most likely answer Triangular strategy</p>
    <p>If X YES return Pass, Y NO return Fail, else keep asking. Rectangular strategy</p>
    <p>Ask until |#YES - #NO| &gt; X, or at most Y questions Chopped off triangle</p>
  </div>
  <div class="page">
    <p>Filtering: Outline</p>
    <p>How do we evaluate strategies?  Hasnt this been done before?  What is the best strategy? (Formulation 1)</p>
    <p>Formal statement Brute force approach Pruning strategies Probabilistic strategies Experiments</p>
    <p>Extensions</p>
  </div>
  <div class="page">
    <p>Evaluating Strategies</p>
    <p>NOs</p>
    <p>YESs Cost = (x+y) Pr. of reaching (x,y)</p>
    <p>Error = Pr. of reaching (x,y) and incorrectly filtered</p>
    <p>Cost = (x+y) Pr. of reaching (x,y)</p>
    <p>Error = Pr. of reaching (x,y) and incorrectly filtered</p>
    <p>Pr. of reaching (x, y) = Pr. of reaching (x, y-1) and getting Yes + Pr. of reaching (x-1, y) and getting No</p>
    <p>Pr. of reaching (x, y) = Pr. of reaching (x, y-1) and getting Yes + Pr. of reaching (x-1, y) and getting No</p>
  </div>
  <div class="page">
    <p>Hasnt this been done before?</p>
    <p>Solutions from elementary statistics guarantee the same error per item Important in contexts like:</p>
    <p>Automobile testing  Medical diagnosis</p>
    <p>Were worried about aggregate error over all items: a uniquely data-oriented problem We dont care if every item is perfect as long as</p>
    <p>the overall error is met. As we will see, results in $$$ savings</p>
  </div>
  <div class="page">
    <p>Find strategy with minimum overall expected cost, such that</p>
    <p>m</p>
    <p>Find strategy with minimum overall expected cost, such that</p>
    <p>m</p>
    <p>What is the best strategy?</p>
    <p>NOs</p>
    <p>YESs</p>
  </div>
  <div class="page">
    <p>Brute Force Approaches</p>
    <p>Try all O(3p) strategies, p = O(m2)</p>
    <p>Try all hollow strategies</p>
    <p>Too Long! Too</p>
    <p>Long!</p>
    <p>Too Long! Too</p>
    <p>Long!</p>
    <p>NOs</p>
    <p>YESs</p>
    <p>NOs</p>
    <p>YESs</p>
  </div>
  <div class="page">
    <p>Pruning Hollow Strategies</p>
    <p>NOs</p>
    <p>YESs For every hollow strategy, there is a ladder strategy that is as good or better.</p>
    <p>For every hollow strategy, there is a ladder strategy that is as good or better.</p>
  </div>
  <div class="page">
    <p>Other Pruning Examples</p>
    <p>NOs</p>
    <p>YESs</p>
    <p>NOs</p>
    <p>YESs</p>
    <p>Ladder</p>
    <p>Hollow</p>
  </div>
  <div class="page">
    <p>Probabilistic Strategies</p>
    <p>Probabilities: continue(x, y), pass(x, y), fail(x, y)</p>
    <p>YESs</p>
    <p>NOs</p>
    <p>(0,1,0) (0,1,0)</p>
    <p>(0,0,1 )</p>
    <p>(0,0,1)</p>
    <p>(0,0,1)</p>
    <p>(1,0,0)</p>
    <p>(1,0,0)</p>
    <p>(0.5,0,0.5 )</p>
    <p>(0.5,0.5,0 )</p>
    <p>(1,0,0)</p>
    <p>(1,0,0)</p>
    <p>(1,0,0 )</p>
    <p>(0.5,0.5,0 )</p>
    <p>(0,1,0)</p>
    <p>(1,0,0)</p>
  </div>
  <div class="page">
    <p>Best probabilistic strategy</p>
    <p>Finding best strategy can be posed as a Linear Program!</p>
    <p>Insight 1:  Pr of reaching (x, y) = Paths into (x, y) * Pr. of one path</p>
    <p>Insight 2:  Probability of filtering incorrectly at a point is independent</p>
    <p>of number of paths</p>
    <p>Insight 3:  At least one of pass(x, y) or fail(x, y) must be 0</p>
  </div>
  <div class="page">
    <p>Experimental Setup</p>
    <p>Goal: Study cost savings of probabilistic relative to others</p>
    <p>Parameters  Generate Strategies  Compute Cost</p>
    <p>Two sample plots  Varying false positive error</p>
    <p>(other parameters fixed)  Varying selectivity</p>
    <p>(other parameters varying) 18</p>
    <p>Ladder</p>
    <p>Hollow</p>
    <p>Probabilisiti c</p>
    <p>Rect</p>
    <p>Deterministi c</p>
    <p>Growth Shrink</p>
  </div>
  <div class="page">
    <p>Varying false positive error</p>
  </div>
  <div class="page">
    <p>Varying selectivity</p>
  </div>
  <div class="page">
    <p>Other Issues and Factors</p>
    <p>Other formulations  Multiple filters  Categorize (output &gt;2 types)</p>
    <p>Ref: Crowdscreen: Algorithms for filtering with humans [SIGMOD 2012]</p>
  </div>
  <div class="page">
    <p>Natural Next Steps</p>
    <p>Expertise  Spam Workers  Task Difficulty  Latency  Error Models  Pricing</p>
    <p>Algorithm s</p>
    <p>Skyline of cost, latency, error</p>
  </div>
  <div class="page">
    <p>Related Work on Crowdsourcing</p>
    <p>Workflows, Platforms and Libraries: Turkit [Little et al. 2009], HProc [Heymann 2010], CrowdForge [Kittur et al. 2011], Turkomatic [Kulkarni and Can 2011], TurKontrol/Clowder [Dai, Mausam and Weld 2010-11]</p>
    <p>Games: GWAP, Matchin, Verbosity, Input Agreement, Tagatune, Peekaboom [Von Ahn &amp; group 2006-10], Kisskissban [Ho et al. 2009], Foldit [Cooper et. al. 2010-11], Trivia Masster [Deutch et al. 2012]</p>
    <p>Marketplace Analysis: [Kittur et al. 2008], [Chilton et al. 2010], [Horton and Chilton 2010], [Ipeirotis 2010]</p>
    <p>Apps: VizWiz [Bigham et al. 2010], Soylent [Bernstein et al. 2010], ChaCha, CollabMap [Stranders et al. 2011], Shepherd [Dow et al. 2011]</p>
    <p>Active Learning: Survey [Settles 2010], [Raykar et al. 2009-10], [Sheng et al. 2008], [Welinder et al. 2010], [Dekel 2010], [Snow et al. 2008], [Shahaf 2010], [Dasgupta, Langford et al. 2007-10]</p>
    <p>Databases: CrowdDB [Franklin et al. 2011], Qurk [Marcus et al. 2011], Deco [Parameswaran et. al. 2011], Hlog [Chai et al., 2009]</p>
    <p>Algorithms: [Marcus et al. 2011], [Gomes et al. 2011], [Ailon et al. 2008], [Karger et al. 2011],</p>
  </div>
  <div class="page">
    <p>Thanks for listening! Questions?</p>
    <p>SCHRDING ERS CAT</p>
  </div>
</Presentation>
