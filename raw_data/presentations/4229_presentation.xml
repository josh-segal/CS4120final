<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>The Strength of the Weakest Supervision: Topic Classification Using Class Labels</p>
    <p>Jiatong Li, Kai Zheng, Hua Xu, Qiaozhu Mei, Yue Wang</p>
  </div>
  <div class="page">
    <p>How humans learn</p>
    <p>Definition of a circle  Properties</p>
  </div>
  <div class="page">
    <p>How machines learn</p>
    <p>Black Box</p>
    <p>Patterns</p>
  </div>
  <div class="page">
    <p>Document classification tasks start with class definitions</p>
  </div>
  <div class="page">
    <p>Supervised machine learning  class labels are ignored, becoming 0,1,2  Difficult to transfer knowledge between tasks</p>
    <p>Labeling data for every new task is labor intensive  Medicine &amp; law</p>
    <p>Humans can already know what data will look like given a topic (class labels)  E.g. sports, politics, science &amp; technology.</p>
  </div>
  <div class="page">
    <p>Goal</p>
    <p>Build a classifier:  learn to interpret class labels before the training starts  warm start</p>
  </div>
  <div class="page">
    <p>Word Embedding Nave Bayes (WENB)</p>
    <p>Document x=(w1,w2,,wj,)</p>
    <p>Label=wy (single word definition, e.g. sports)</p>
    <p>Nave Bayes</p>
    <p>Word Embedding</p>
    <p>=</p>
    <p>Label dy=(w1,,wy) (multiple words, e.g. science &amp; technology)  (noisy-OR)</p>
  </div>
  <div class="page">
    <p>Pseudo Labels</p>
    <p>Pseudo labels: (y|x)  p(x|y)p(y)  comes for free</p>
  </div>
  <div class="page">
    <p>Continued training  Fine tuning with labeled documents  Unlabeled documents: , pseudo labels  True labels  Train a new classifier</p>
    <p>True labels</p>
    <p>RegularizationPseudo labels 9</p>
    <p>+|||| 2</p>
  </div>
  <div class="page">
    <p>Compared Methods</p>
    <p>Retrieval Based Methods  IR (Dirichlet smoothing language model)  IR+Rocchio, IR+Nave Bayes, IR+Logistic Regression</p>
    <p>Semi-supervised Methods  Class labels as labeled documents: self-training  Class labels as labeled features:  generalized expectation (Druck et al., 2008)  Seeded LDA (Jagarlamudi et al.,2012)</p>
    <p>Word Embedding-based Methods  Cosine, WENB, WENB+LR</p>
  </div>
  <div class="page">
    <p>Warm start performance</p>
    <p>Performance achieved using class labels only</p>
  </div>
  <div class="page">
    <p>Short documents: Semi-supervised learning: does not help WENB: robust performance</p>
    <p>Long documents: leveraging unlabeled data helps WENB: not as effective</p>
    <p>Short documents Long documents</p>
    <p>Macro-F1</p>
  </div>
  <div class="page">
    <p>Label Savings</p>
    <p>Number of true labels needed for a logistic regression classifier to achieve the same performance as WENB+LR</p>
    <p>Label Savings 13</p>
  </div>
  <div class="page">
    <p>Label Savings</p>
    <p>Label Savings</p>
    <p>Number of labels needed to achieve the same performance as WENB+LR</p>
  </div>
  <div class="page">
    <p>Continued Training Results</p>
  </div>
  <div class="page">
    <p>Analysis</p>
    <p>Short documents:  Semi-supervised learning: does not help  Vocabulary mismatch</p>
    <p>WENB: robust performance  word vectors can capture semantic similarity</p>
    <p>Long documents:  leveraging unlabeled data helps  topic-specific words can be learned through</p>
    <p>exploiting intra-document word co-occurrences 16</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Class labels can save a significant amount of labeled examples in the beginning  Long documents: retrieval-based and semi</p>
    <p>supervised methods tend to perform better  Short documents: Word embedding based</p>
    <p>method perform better</p>
  </div>
  <div class="page">
    <p>Thanks! Q &amp; A</p>
  </div>
  <div class="page">
    <p>Continued Training Results</p>
  </div>
  <div class="page"/>
  <div class="page"/>
</Presentation>
