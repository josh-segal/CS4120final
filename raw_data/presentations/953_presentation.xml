<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>StackMap: Low-Latency Networking with the OS Stack and Dedicated NICs Kenichi Yasukata (Keio University*), MichioHonda, Douglas Santry, Lars Eggert (NetApp)</p>
    <p>June 22nd @ USENIX ATC 2016</p>
    <p>2016 NetApp, Inc. All rights reserved. 1</p>
    <p>*Work while an intern at NetApp</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>Message-oriented communication over TCP is common  e.g., HTTP, memcached, CDNs</p>
    <p>Linux network stack can serve 1KB messages only at 3.5 Gbps w/ a single core</p>
    <p>Improve socket API?  Limited Improvements</p>
    <p>User-space TCP/IP stack?  Maintaining and updating todays complex TCP is hard</p>
    <p>2016 NetApp, Inc. All rights reserved. 2</p>
    <p>T hr</p>
    <p>ou gh</p>
    <p>pu t [</p>
    <p>G b/</p>
    <p>s]</p>
    <p>Concurrent TCP Connections</p>
    <p>Linux Seastar StackMap</p>
    <p>StackMap achieves high performance with the OS TCP/IP</p>
  </div>
  <div class="page">
    <p>Background</p>
    <p>Message-oriented communication over TCP (e.g., HTTP, memcached)  Many concurrent connections  Small messages  High packet rates</p>
    <p>2016 NetApp, Inc. All rights reserved. 3</p>
    <p>NIC Device drivers</p>
    <p>Linux packet I/O</p>
    <p>Socket API</p>
    <p>StackMap appRegular app 1.</p>
    <p>us er</p>
    <p>ke rn el</p>
    <p>NIC</p>
    <p>TCP/IP/Eth</p>
    <p>netmap</p>
    <p>Packet buffers</p>
    <p>Request (e.g., HTTP GET) Response (e.g., HTTP OK)</p>
  </div>
  <div class="page">
    <p>Message Latency Problem</p>
    <p>Many requests are processed in each epoll_wait() cycle  New requests are queued in the kernel</p>
    <p>2016 NetApp, Inc. All rights reserved. 4</p>
    <p>while (1) { n = epoll_wait(fds); for (i= 0; i &lt; n; i++) { read(fds[i], buf) http_ok(buf); write(fds[i], buf); } }</p>
    <p>D es</p>
    <p>cr ip</p>
    <p>to rs</p>
    <p>[# ]</p>
    <p>Concurrent TCP Connections</p>
    <p># of descriptors returned by epoll_wait()</p>
    <p>L at</p>
    <p>en cy</p>
    <p>[ s]</p>
    <p>Concurrent TCP Connections</p>
  </div>
  <div class="page">
    <p>Processing cost of TCP/IPprotocol is not high</p>
    <p>TCP/IP takes 1.48 us, out of 3.75 us server processing</p>
    <p>RTT reported by the client app is 9.75 us  The rest of 6 us come from minimum hard/soft indirection  netmap-based ping-pong (network stack bypass) reports 5.77 us</p>
    <p>Where Could We Improve?</p>
    <p>2016 NetApp, Inc. All rights reserved. 5</p>
    <p>HTTP GET (96B)</p>
    <p>HTTP OK (127B)</p>
    <p>Pkt. I/O TCP/IP Socket/VFS App</p>
  </div>
  <div class="page">
    <p>Processing cost of TCP/IPprotocol is not high</p>
    <p>TCP/IP takes 1.48 us, out of 3.75 us server processing</p>
    <p>RTT reported by the client app is 9.75 us  The rest of 6 us come from minimum hard/soft indirection (5.77 us)  netmap-based ping-pong (network stack bypass) reports 5.77 us</p>
    <p>Where Could We Improve?</p>
    <p>2016 NetApp, Inc. All rights reserved. 6</p>
    <p>HTTP GET (96B)</p>
    <p>HTTP OK (127B)</p>
    <p>Pkt. I/O TCP/IP Socket/VFS App</p>
    <p>epoll_wait() processing delay</p>
  </div>
  <div class="page">
    <p>Takeaway</p>
    <p>Conventional system introduces end-to-end latency of 10s to 100s of us  Results of processing delays</p>
    <p>Socket API comes at a significant cost  read()/write()/epoll_wait() processing delay</p>
    <p>Packet I/O is expensive</p>
    <p>TCP/IP protocol processing is relatively cheap</p>
    <p>We can use the feature-rich kernel TCP/IP implementation, but need to improve API and packet I/O</p>
    <p>2016 NetApp, Inc. All rights reserved. 7</p>
    <p>NIC Device drivers</p>
    <p>Linux packet I/O</p>
    <p>Socket API</p>
    <p>StackMap appRegular app 1.</p>
    <p>us er</p>
    <p>ke rn el</p>
    <p>NIC</p>
    <p>TCP/IP/Eth</p>
    <p>netmap</p>
    <p>Packet buffers</p>
  </div>
  <div class="page">
    <p>StackMapApproach</p>
    <p>Dedicating a NIC to an application  Common for todays high-performance systems</p>
    <p>Similar to OS-bypass TCP/IPs</p>
    <p>2016 NetApp, Inc. All rights reserved. 8</p>
    <p>NIC Device drivers</p>
    <p>Linux packet I/O</p>
    <p>Socket API</p>
    <p>StackMap appRegular app 1.</p>
    <p>us er</p>
    <p>ke rn el</p>
    <p>NIC</p>
    <p>TCP/IP/Eth</p>
    <p>netmap</p>
    <p>Packet buffers</p>
    <p>NIC Device drivers</p>
    <p>Linux packet I/O</p>
    <p>Socket API</p>
    <p>StackMap appRegular app</p>
    <p>us er</p>
    <p>ke rn el</p>
    <p>NIC</p>
    <p>TCP/IP/Eth</p>
  </div>
  <div class="page">
    <p>StackMapApproach</p>
    <p>Dedicating a NIC to an application  Common for todays high-performance systems</p>
    <p>Similar to OS-bypass TCP/IPs</p>
    <p>TCP/IP stack in the kernel  State-of-the-art features  Active updates and maintenance</p>
    <p>2016 NetApp, Inc. All rights reserved. 9</p>
    <p>NIC Device drivers</p>
    <p>Linux packet I/O</p>
    <p>Socket API</p>
    <p>StackMap appRegular app 1.</p>
    <p>us er</p>
    <p>ke rn el</p>
    <p>NIC</p>
    <p>TCP/IP/Eth</p>
    <p>netmap</p>
    <p>Packet buffers</p>
    <p>NIC Device drivers</p>
    <p>Linux packet I/O</p>
    <p>Socket API</p>
    <p>StackMap appRegular app</p>
    <p>us er</p>
    <p>ke rn el</p>
    <p>NIC</p>
    <p>TCP/IP/Eth</p>
  </div>
  <div class="page">
    <p>StackMapArchitecture</p>
    <p>2016 NetApp, Inc. All rights reserved. 10</p>
    <p>NIC Device drivers</p>
    <p>Linux packet I/O</p>
    <p>Socket API</p>
    <p>StackMap appRegular app 1.</p>
    <p>us er</p>
    <p>ke rn el</p>
    <p>NIC</p>
    <p>TCP/IP/Eth</p>
    <p>netmap framework</p>
    <p>Packet buffers</p>
    <p>Syscall and packet I/O batching, zero copy, run-to- completion</p>
    <p>Efficiently call into kernel TCP/IP</p>
  </div>
  <div class="page">
    <p>StackMapData Path API</p>
    <p>2016 NetApp, Inc. All rights reserved. 11</p>
    <p>TX  Put data and fd in each slot  Advance the head pointer  Syscall to start network stack processing and transmission headtail</p>
    <p>data, fd</p>
  </div>
  <div class="page">
    <p>StackMapData Path API</p>
    <p>2016 NetApp, Inc. All rights reserved. 12</p>
    <p>TX  Put data and fd in each slot  Advance the head pointer  Syscall to start network stack processing and transmission</p>
    <p>RX  Kernel puts fd on each buffer</p>
    <p>App can traverse a ring by descriptors</p>
    <p>headtail</p>
    <p>data, fd</p>
    <p>fd4 fd3 fd4 fd4 fd5 fd3</p>
    <p>head tail data, fd</p>
    <p>fd4 fd3 fd5</p>
    <p>[0]</p>
    <p>[2] [1]</p>
    <p>FD Array nxt 2 5 3 5idx 0 1 2 3 4</p>
    <p>[3]</p>
    <p>[5] [4]</p>
    <p>Scratchpad</p>
  </div>
  <div class="page">
    <p>Implementation  Linux 4.2 with 228 LoC changes  netmapwith 56 LoC changes  A new kernel module with 2269 LoC</p>
    <p>Experimental Results</p>
    <p>Setup  Two machines with Xeon E5-2680 v2 (2.8 -3.6 Ghz) Intel 82599 10 GbENIC</p>
    <p>Server: Linux or StackMap  Client: Linux with WRK http benchmark tool or memaslapmemcachedbenchmark tool</p>
    <p>2016 NetApp, Inc. All rights reserved. 13</p>
  </div>
  <div class="page">
    <p>Basic Performance</p>
    <p>Simple HTTP server  Serving 1KB messages (single core)</p>
    <p>2016 NetApp, Inc. All rights reserved. 14</p>
    <p>hr ou</p>
    <p>gh pu</p>
    <p>t [ G</p>
    <p>b/ s]</p>
    <p>Concurrent TCP Connections</p>
    <p>Linux StackMap</p>
    <p>L at</p>
    <p>en cy</p>
    <p>[ s]</p>
    <p>Concurrent TCP Connections</p>
    <p>Linux (99th %ile) Linux (mean) StackMap (99th %ile) StackMap (mean)</p>
  </div>
  <div class="page">
    <p>MemcachedPerformance</p>
    <p>Serving 1KB messages  single core  Seastar is a fast user-space TCP/IP on on top of DPDK*</p>
    <p>Serving 64B messages  1-8 CPU cores</p>
    <p>2016 NetApp, Inc. All rights reserved. 15</p>
    <p>hr ou</p>
    <p>gh pu</p>
    <p>t [ G</p>
    <p>b/ s]</p>
    <p>Concurrent TCP Connections</p>
    <p>Linux Seastar StackMap</p>
    <p>ou gh</p>
    <p>pu t [</p>
    <p>G b/</p>
    <p>s]</p>
    <p>CPU cores [#]</p>
    <p>Linux Seastar StackMap</p>
    <p>L at</p>
    <p>en cy</p>
    <p>[ s]</p>
    <p>Concurrent TCP Connections</p>
    <p>Linux Seastar StackMap</p>
    <p>*http://www.seastar-project.org/</p>
  </div>
  <div class="page">
    <p>Discussion</p>
    <p>What makes StackMap fast?  Techniques used by OS-bypass TCP/IPs  Run-to-completion, static packet buffers, zero copy, syscall and I/O batching and new API</p>
    <p>Limitations and Future Work  Safely sharing packet buffers  If kernel-owned buffers are modified by a misbehaving app, TCP might fall into inconsistent state</p>
    <p>2016 NetApp, Inc. All rights reserved. 16</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>Kernel-bypass TCP/IPs  IX [OSDI14], Arrakis [OSDI14], UTCP [CCR14], Sandstorm [SIGCOMM14], mTCP [NSDI14], Seastar</p>
    <p>Socket API enhancements  MegaPipe [OSDI12], FlexSC [OSDI10], KCM [Linux]</p>
    <p>Improving OS stack with fast packet I/O  mSwitch [SOSR15]</p>
    <p>In-stack improvement  FastSocket [ASPLOS16]</p>
    <p>Running kernel stack in user-space  Rump [AsiaBSDCon09], NUSE [netdev15]</p>
    <p>2016 NetApp, Inc. All rights reserved. 17</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Message-oriented communication over TCP</p>
    <p>Kernel TCP/IP is fast  But socket API and packet I/O are slow</p>
    <p>We can bring the most of techniques used by kernel-bypass stacks into the OS stack</p>
    <p>Latency reduction by 4-80% (average) or 2-70% (99th%tile)</p>
    <p>Throughput improvement by 4-391%</p>
    <p>2016 NetApp, Inc. All rights reserved. 18</p>
  </div>
</Presentation>
