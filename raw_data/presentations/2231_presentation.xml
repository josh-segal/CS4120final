<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Caching in the multiverse</p>
    <p>Mania Abdi, Amin Mosayyebzadeh, Mohammad Hossein Hajkazemi, Ata Turk, Orran Krieger, Peter Desnoyers</p>
    <p>Northeastern University, State Street, Boston University</p>
  </div>
  <div class="page">
    <p>Execution Framework e.g. Hadoop, Spark, Tez</p>
    <p>Typical Data analytic Cluster</p>
    <p>Analytic Frameworks</p>
    <p>Datacenter Network</p>
    <p>Cluster Network Cluster Network</p>
    <p>TOR TOR TOR</p>
    <p>C o</p>
    <p>m p</p>
    <p>u te</p>
    <p>S to</p>
    <p>ra g</p>
    <p>e</p>
  </div>
  <div class="page">
    <p>Execution Framework</p>
    <p>Typical Data analytic Cluster</p>
    <p>Storage disaggregation enables:  Scalability  Flexibility</p>
    <p>Execution frameworks perform better when data is local to cluster</p>
    <p>A distributed cache can help, e.g. Alluxio Storage</p>
    <p>Distributed Cache</p>
    <p>Datacenter Network</p>
    <p>Cluster Network Cluster Network</p>
    <p>TOR TOR TOR TOR</p>
    <p>Analytic Frameworks</p>
  </div>
  <div class="page">
    <p>Data analytic executions</p>
    <p>User queries -&gt; Query optimizer -&gt; Job DAG e.g. PIG</p>
    <p>DAGs have complex and deep structure, e.g. 200 or more nodes for complex jobs. In DAGs:  vertices represent analytic jobs  Edges represent dependencies between jobs.</p>
    <p>Dependency within a DAG + run time</p>
    <p>estimated critical path.Query #8 from TPC-H benchmark</p>
  </div>
  <div class="page">
    <p>Taxonomy of caching</p>
    <p>Frequent Management Approaches</p>
    <p>History based Informed hint based</p>
    <p>LRU Most practice today</p>
    <p>e.g. Alluxio</p>
    <p>All-or-nothing e.g. Pacman (NSDI12)</p>
    <p>Deadline aware</p>
    <p>DAG aware</p>
    <p>e.g. NetCo (SOCC18)</p>
    <p>MRD (ICPP18), LRC (InfoComm 17)</p>
    <p>Application hints e.g. TIP (SOSP95), MC2 (TOCS11)</p>
  </div>
  <div class="page">
    <p>Optimizing Data Analytic caches</p>
    <p>Cache performance metric:</p>
    <p>Query completion time = Tjob finish  Tjob submission</p>
    <p>Goal: minimize query completion time</p>
  </div>
  <div class="page">
    <p>Our approach Adapt with</p>
    <p>time Adapt with schedule</p>
    <p>The first system that solve the joint problem of DAGs scheduling and caching</p>
    <p>Goal: Calculate optimize cache plan  Prefetch control  Admission control  Eviction control</p>
    <p>Execution Framework</p>
    <p>DAGs of Jobs Cache Status</p>
    <p>Execution History</p>
    <p>Storage bandwidth</p>
  </div>
  <div class="page">
    <p>How to find cache/prefetch plan?</p>
  </div>
  <div class="page">
    <p>How to find cache/prefetch plan?</p>
    <p>Predict job run time with and without prefetching.</p>
    <p>Find critical path based on dependencies and history of execution.</p>
    <p>Incorporate dependencies, bandwidth to storage, current cache status to choose:  Dataset to be cached</p>
    <p>Dataset to be prefetched</p>
    <p>Dataset to be evicted</p>
    <p>DAGs of Jobs Cache Status</p>
    <p>Execution History</p>
    <p>Storage bandwidth</p>
  </div>
  <div class="page">
    <p>PIG</p>
    <p>Experimental environment</p>
    <p>Analytic framework: Pig</p>
    <p>Execution framework: MapReduce</p>
    <p>4 bare metal nodes:</p>
    <p>60GB RAM</p>
    <p>16 CPU</p>
    <p>10 Gbps Ethernet</p>
    <p>Distributed cache: Alluxio</p>
    <p>4 bare metal nodes:</p>
    <p>Collocate with Hadoop nodes.</p>
    <p>6BG per cache = 24GB cache</p>
    <p>Remote storage: Ceph</p>
    <p>Benchmark: TPC-H queries</p>
    <p>30 GB dataset size</p>
    <p>MapReduce</p>
    <p>Alluxio</p>
    <p>Ceph</p>
    <p>TPC-H</p>
    <p>Prefetch/Evict Script</p>
  </div>
  <div class="page">
    <p>Results</p>
    <p>2X improvement over LRU.</p>
    <p>Up to 22% improvement over MRD</p>
  </div>
  <div class="page">
    <p>Current work: implementation</p>
    <p>Workflow DAG</p>
    <p>Job runtime estimator</p>
    <p>Critical path estimator</p>
    <p>Job improvement estimator</p>
    <p>D istrib</p>
    <p>u te</p>
    <p>d C</p>
    <p>a ch</p>
    <p>e</p>
    <p>I/O planner</p>
    <p>Remote Storage</p>
    <p>History of execution</p>
  </div>
  <div class="page">
    <p>Discussion / Challenges</p>
    <p>Benchmark:  New benchmark to evaluate our approach.</p>
    <p>Multi-query execution:  Approaches: two step cache management</p>
    <p>Create plan for a single query  Create plan for multiple queries.</p>
    <p>Competition queries with contradicting requests  Initial approaches: prioritize nearest future access.</p>
    <p>Bandwidth allocation for multiple queries  Initial approaches: prioritize shortest job first.</p>
    <p>Where to prefetch?</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Goal: minimize end-to-end latency of query execution</p>
    <p>Approach: scheduling aware cache management policy</p>
    <p>Key insight: incorporate execution history and current cache status to optimize the critical path through caching and prefetching.</p>
    <p>Results: 2X improvement over LRU</p>
  </div>
</Presentation>
