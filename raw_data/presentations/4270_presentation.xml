<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Unifying Text, Metadata, and User Network Representa8ons with a Neural Network</p>
    <p>for Geoloca8on Predic8on Yasuhide Miura,, Motoki Taniguchi,</p>
    <p>Tomoki Taniguchi, and Tomoko Ohkuma  Fuji Xerox Co., Ltd.</p>
    <p>Tokyo Ins8tute of Technology</p>
  </div>
  <div class="page">
    <p>Geoloca8on Predic8on</p>
    <p>Goal  Predict a loca8on of a person</p>
    <p>My house is at Vancouver.</p>
    <p>Example</p>
    <p>geoloca8on predic8on</p>
    <p>Vancouver</p>
    <p>an SNS message city name</p>
  </div>
  <div class="page">
    <p>Our Approach</p>
    <p>Geoloca8on predic8on with neural networks</p>
    <p>messages (timeline)</p>
    <p>RNNL</p>
    <p>AttentionL</p>
    <p>FCU</p>
    <p>label</p>
    <p>location description timezone</p>
    <p>Timezone Embedding</p>
    <p>AttentionTL</p>
    <p>RNND</p>
    <p>AttentionD</p>
    <p>RNNM</p>
    <p>AttentionM</p>
    <p>AttentionU</p>
    <p>Word Embedding</p>
    <p>linked cities</p>
    <p>linked users</p>
    <p>+</p>
    <p>AttentionN</p>
    <p>City Embedding</p>
    <p>User Embedding</p>
    <p>AttentionUN</p>
    <p>FCUN</p>
    <p>TEXT</p>
    <p>TEXT&amp;META</p>
    <p>USERNET</p>
    <p>Inputs messages, metadata, and user network</p>
    <p>Overview</p>
  </div>
  <div class="page">
    <p>Our Approach</p>
    <p>Geoloca8on predic8on with neural networks</p>
    <p>messages (timeline)</p>
    <p>RNNL</p>
    <p>AttentionL</p>
    <p>FCU</p>
    <p>label</p>
    <p>location description timezone</p>
    <p>Timezone Embedding</p>
    <p>AttentionTL</p>
    <p>RNND</p>
    <p>AttentionD</p>
    <p>RNNM</p>
    <p>AttentionM</p>
    <p>AttentionU</p>
    <p>Word Embedding</p>
    <p>linked cities</p>
    <p>linked users</p>
    <p>+</p>
    <p>AttentionN</p>
    <p>City Embedding</p>
    <p>User Embedding</p>
    <p>AttentionUN</p>
    <p>FCUN</p>
    <p>TEXT</p>
    <p>TEXT&amp;META</p>
    <p>USERNET</p>
    <p>Inputs messages, metadata, and user network</p>
    <p>Overview</p>
    <p>Text processes with RNN+APen8on</p>
  </div>
  <div class="page">
    <p>Our Approach</p>
    <p>Geoloca8on predic8on with neural networks</p>
    <p>messages (timeline)</p>
    <p>RNNL</p>
    <p>AttentionL</p>
    <p>FCU</p>
    <p>label</p>
    <p>location description timezone</p>
    <p>Timezone Embedding</p>
    <p>AttentionTL</p>
    <p>RNND</p>
    <p>AttentionD</p>
    <p>RNNM</p>
    <p>AttentionM</p>
    <p>AttentionU</p>
    <p>Word Embedding</p>
    <p>linked cities</p>
    <p>linked users</p>
    <p>+</p>
    <p>AttentionN</p>
    <p>City Embedding</p>
    <p>User Embedding</p>
    <p>AttentionUN</p>
    <p>FCUN</p>
    <p>TEXT</p>
    <p>TEXT&amp;META</p>
    <p>USERNET</p>
    <p>Inputs messages, metadata, and user network</p>
    <p>Merge representa8ons with APen8on</p>
    <p>Overview</p>
    <p>Text processes with RNN+APen8on</p>
  </div>
  <div class="page">
    <p>Our Approach</p>
    <p>Geoloca8on predic8on with neural networks</p>
    <p>messages (timeline)</p>
    <p>RNNL</p>
    <p>AttentionL</p>
    <p>FCU</p>
    <p>label</p>
    <p>location description timezone</p>
    <p>Timezone Embedding</p>
    <p>AttentionTL</p>
    <p>RNND</p>
    <p>AttentionD</p>
    <p>RNNM</p>
    <p>AttentionM</p>
    <p>AttentionU</p>
    <p>Word Embedding</p>
    <p>linked cities</p>
    <p>linked users</p>
    <p>+</p>
    <p>AttentionN</p>
    <p>City Embedding</p>
    <p>User Embedding</p>
    <p>AttentionUN</p>
    <p>FCUN</p>
    <p>TEXT</p>
    <p>TEXT&amp;META</p>
    <p>USERNET</p>
    <p>Inputs messages, metadata, and user network</p>
    <p>Merge representa8ons with APen8on</p>
    <p>Overview</p>
    <p>Text processes with RNN+APen8on</p>
    <p>Output city name</p>
  </div>
  <div class="page">
    <p>Our Approach</p>
    <p>Geoloca8on predic8on with neural networks</p>
    <p>messages (timeline)</p>
    <p>RNNL</p>
    <p>AttentionL</p>
    <p>FCU</p>
    <p>label</p>
    <p>location description timezone</p>
    <p>Timezone Embedding</p>
    <p>AttentionTL</p>
    <p>RNND</p>
    <p>AttentionD</p>
    <p>RNNM</p>
    <p>AttentionM</p>
    <p>AttentionU</p>
    <p>Word Embedding</p>
    <p>linked cities</p>
    <p>linked users</p>
    <p>+</p>
    <p>AttentionN</p>
    <p>City Embedding</p>
    <p>User Embedding</p>
    <p>AttentionUN</p>
    <p>FCUN</p>
    <p>TEXT</p>
    <p>TEXT&amp;META</p>
    <p>USERNET</p>
    <p>Overview</p>
    <p>Quite a complex model, why?</p>
  </div>
  <div class="page">
    <p>Geoloca8on Predic8on Target</p>
    <p>TwiPer users  A popular target in previous works (Cheng et al., 2010; Eisenstein et al., 2010)</p>
  </div>
  <div class="page">
    <p>Geoloca8on Predic8on Target</p>
    <p>TwiPer users  A popular target in previous works (Cheng et al., 2010; Eisenstein et al., 2010)</p>
    <p>Characteris8cs  Mul8ple geoloca8on clues</p>
    <p>Message (tweet)  Metadata  User network</p>
    <p>Large-scale data  Ground-truth loca8ons with geotags</p>
  </div>
  <div class="page">
    <p>Metadata</p>
    <p>Descrip8on, loca8on, 8mezone, etc.  State-of-the-art performances combined with texts (Han et al., 2013, 2014; Jayasinghe et al., 2016; Miura et al., 2016)</p>
    <p>I work as a researcher at XXX</p>
    <p>I live in Canada.</p>
    <p>America/Vancouver</p>
    <p>Descrip0on</p>
    <p>Loca0on</p>
    <p>Timezone TwiPer user</p>
    <p>Example</p>
  </div>
  <div class="page">
    <p>User Network</p>
    <p>Men8on network, friend network, etc.  Predic8on with label propaga8on  State-of-the-art performances combined with texts (Rahimi et al., 2015a; Jayasinghe et al., 2016)</p>
    <p>Target user</p>
    <p>Vancouver</p>
    <p>Vancouver</p>
    <p>(null)</p>
    <p>Tokyo Example</p>
    <p>Men8on user 1 Men8on user 2</p>
    <p>Men8on user 3</p>
    <p>Men8on user 4</p>
  </div>
  <div class="page">
    <p>User Network</p>
    <p>Men8on network, friend network, etc.  Predic8on with label propaga8on  State-of-the-art performances combined with texts (Rahimi et al., 2015a; Jayasinghe et al., 2016)</p>
    <p>Target user</p>
    <p>Vancouver</p>
    <p>Vancouver</p>
    <p>(null)</p>
    <p>Tokyo Example</p>
    <p>Perhaps, Vancouver</p>
    <p>Men8on user 1 Men8on user 2</p>
    <p>Men8on user 3</p>
    <p>Men8on user 4</p>
  </div>
  <div class="page">
    <p>Model</p>
    <p>messages (timeline)</p>
    <p>RNNL</p>
    <p>AttentionL</p>
    <p>FCU</p>
    <p>label</p>
    <p>location description timezone</p>
    <p>Timezone Embedding</p>
    <p>AttentionTL</p>
    <p>RNND</p>
    <p>AttentionD</p>
    <p>RNNM</p>
    <p>AttentionM</p>
    <p>AttentionU</p>
    <p>Word Embedding</p>
    <p>linked cities</p>
    <p>linked users</p>
    <p>+</p>
    <p>AttentionN</p>
    <p>City Embedding</p>
    <p>User Embedding</p>
    <p>AttentionUN</p>
    <p>FCUN</p>
    <p>TEXT</p>
    <p>TEXT&amp;META</p>
    <p>USERNET</p>
    <p>Messages Metadata User network</p>
  </div>
  <div class="page">
    <p>TEXT Component (1)</p>
    <p>messages (timeline)</p>
    <p>RNNL</p>
    <p>AttentionL</p>
    <p>FCU</p>
    <p>label</p>
    <p>location description timezone</p>
    <p>Timezone Embedding</p>
    <p>AttentionTL</p>
    <p>RNND</p>
    <p>AttentionD</p>
    <p>RNNM</p>
    <p>AttentionM</p>
    <p>AttentionU</p>
    <p>Word Embedding</p>
    <p>linked cities</p>
    <p>linked users</p>
    <p>+</p>
    <p>AttentionN</p>
    <p>City Embedding</p>
    <p>User Embedding</p>
    <p>AttentionUN</p>
    <p>FCUN</p>
    <p>TEXT</p>
    <p>TEXT&amp;META</p>
    <p>USERNET</p>
    <p>Messages</p>
  </div>
  <div class="page">
    <p>TEXT Component (2)</p>
    <p>Hierarchical Neural Networks  Layers  Word Embedding  Recurrent Neural Network</p>
    <p>Specifically, GRU (Cho et al., 2014)  (Self) APen8on</p>
    <p>messages (timeline)</p>
    <p>timeline representation</p>
    <p>AttentionTL</p>
    <p>RNNM</p>
    <p>AttentionM</p>
    <p>Word Embedding</p>
    <p>messages (timeline)</p>
    <p>timeline representation</p>
    <p>AttentionTL</p>
    <p>RNNM</p>
    <p>AttentionM</p>
    <p>Word Embedding</p>
    <p>x1 xT</p>
    <p>input</p>
    <p>h1</p>
    <p>bi-directional recurrent</p>
    <p>states</p>
    <p>g1 g2 gT</p>
    <p>RNN features</p>
    <p>x2</p>
    <p>u1</p>
    <p>context vectors</p>
    <p>+ 1g1</p>
    <p>2g2 TgT</p>
    <p>Attention features m</p>
    <p>u2 uT</p>
    <p>Attention Layer</p>
    <p>RNN Layer h1</p>
    <p>h2</p>
    <p>h2</p>
    <p>hT</p>
    <p>hT</p>
    <p>Figure 2: Overview of the text component with detailed description of RNNM and AttentionM.</p>
    <p>and  h are concatenated to form g where gt =</p>
    <p>ht  ht and are passed to the first attention layer</p>
    <p>AttentionM. AttentionM computes a message representa</p>
    <p>tion m as a weighted sum of gt with weight t:</p>
    <p>m = !</p>
    <p>t</p>
    <p>tgt (5)</p>
    <p>t = exp</p>
    <p>&quot; vTut</p>
    <p># $</p>
    <p>t exp (v T ut)</p>
    <p>(6)</p>
    <p>ut = tanh (W gt + b) (7)</p>
    <p>where v is a weight vector, W  is a weight matrix, and b a bias vector. ut is an attention context vector calculated from gt with a single fullyconnected layer (Eq. 7). ut is normalized with softmax to obtain t as a probability (Eq. 6). The message representation m is passed to the second attention layer AttentionTL to obtain a timeline representation from message representations.</p>
    <p>linked cities</p>
    <p>+ AttentionN</p>
    <p>City Embedding</p>
    <p>User Embedding</p>
    <p>user network representation</p>
    <p>linked users</p>
    <p>linked user 1</p>
    <p>linked user N</p>
    <p>current user</p>
    <p>User Network</p>
    <p>c1 cN</p>
    <p>inputs</p>
    <p>p1 p2 pN</p>
    <p>c2</p>
    <p>u1</p>
    <p>context vectors</p>
    <p>+ 1p1</p>
    <p>2p2 NpN</p>
    <p>Attention features m</p>
    <p>u2 uN</p>
    <p>Attention Layer</p>
    <p>a1 aN</p>
    <p>a2</p>
    <p>+ ++</p>
    <p>Figure 3: Overview of the user network component with a detailed description of the elementwise addition and AttentionN.</p>
    <p>We process location fields and description fields similarly to messages using an RNN layer and an attention layer. Because there is only one location and one description per user, a second attention layer is not required, as it is in the text component. We also chose to share word embeddings among the messages, the location, and the description processes because these inputs are all textual information. For the timezone, an embedding is assigned for each timezone value. A processed timeline representation, a location representation, and a description representation are then passed to the attention layer AttentionU with a timezone representation. AttentionU combines these four representations and outputs a user representation. This combination is done as in AttentionTL with four representations as g1 . . . g4 in Eq. 5.</p>
    <p>RNNM output</p>
    <p>Mul8-layer Perceptron Sofmax</p>
    <p>APen8onM</p>
  </div>
  <div class="page">
    <p>TEXT&amp;META Component</p>
    <p>messages (timeline)</p>
    <p>RNNL</p>
    <p>AttentionL</p>
    <p>FCU</p>
    <p>label</p>
    <p>location description timezone</p>
    <p>Timezone Embedding</p>
    <p>AttentionTL</p>
    <p>RNND</p>
    <p>AttentionD</p>
    <p>RNNM</p>
    <p>AttentionM</p>
    <p>AttentionU</p>
    <p>Word Embedding</p>
    <p>linked cities</p>
    <p>linked users</p>
    <p>+</p>
    <p>AttentionN</p>
    <p>City Embedding</p>
    <p>User Embedding</p>
    <p>AttentionUN</p>
    <p>FCUN</p>
    <p>TEXT</p>
    <p>TEXT&amp;META</p>
    <p>USERNET</p>
    <p>Messages Metadata (loca8on, descrip8on, 8mezone)</p>
    <p>Text processes (single text)</p>
    <p>Merge four representa8ons</p>
    <p>Embedding</p>
  </div>
  <div class="page">
    <p>USERNET Component (1)</p>
    <p>messages (timeline)</p>
    <p>RNNL</p>
    <p>AttentionL</p>
    <p>FCU</p>
    <p>label</p>
    <p>location description timezone</p>
    <p>Timezone Embedding</p>
    <p>AttentionTL</p>
    <p>RNND</p>
    <p>AttentionD</p>
    <p>RNNM</p>
    <p>AttentionM</p>
    <p>AttentionU</p>
    <p>Word Embedding</p>
    <p>linked cities</p>
    <p>linked users</p>
    <p>+</p>
    <p>AttentionN</p>
    <p>City Embedding</p>
    <p>User Embedding</p>
    <p>AttentionUN</p>
    <p>FCUN</p>
    <p>TEXT</p>
    <p>TEXT&amp;META</p>
    <p>USERNET</p>
    <p>User network</p>
  </div>
  <div class="page">
    <p>USERNET Component (2)</p>
    <p>Linked users  Embedding for each user</p>
    <p>Regional celebri8es  Linked ci8es  Embedding for each ground-truth city of a user  unknown for unavailable cases</p>
    <p>Merge  Element-wise addi8on  APen8on over N users</p>
    <p>linked cities</p>
    <p>+ AttentionN</p>
    <p>City Embedding</p>
    <p>User Embedding</p>
    <p>user network representation</p>
    <p>linked users</p>
    <p>linked user 1</p>
    <p>linked user N</p>
    <p>current user</p>
    <p>User Network</p>
  </div>
  <div class="page">
    <p>Unified Processes</p>
    <p>messages (timeline)</p>
    <p>RNNL</p>
    <p>AttentionL</p>
    <p>FCU</p>
    <p>label</p>
    <p>location description timezone</p>
    <p>Timezone Embedding</p>
    <p>AttentionTL</p>
    <p>RNND</p>
    <p>AttentionD</p>
    <p>RNNM</p>
    <p>AttentionM</p>
    <p>AttentionU</p>
    <p>Word Embedding</p>
    <p>linked cities</p>
    <p>linked users</p>
    <p>+</p>
    <p>AttentionN</p>
    <p>City Embedding</p>
    <p>User Embedding</p>
    <p>AttentionUN</p>
    <p>FCUN</p>
    <p>TEXT</p>
    <p>TEXT&amp;META</p>
    <p>USERNET</p>
    <p>Merge two representa8ons</p>
    <p>Predict City</p>
    <p>User representa8on</p>
    <p>User network representa8on</p>
  </div>
  <div class="page">
    <p>Data (1)  Two open datasets  TwiPerUS (Roller et al., 2012)  W-NUT (Han et al., 2016)</p>
    <p>User Network  Uni-direc8onal men8on network (Rahimi et al., 2015a, 2015b)  Dataset users + one-hop users  Set undirected edges for men8ons</p>
    <p>@Alice Hello!</p>
    <p>Bob</p>
    <p>Example</p>
    <p>set edge Bob</p>
    <p>Alice</p>
  </div>
  <div class="page">
    <p>Data (2) TwitterUS</p>
    <p>(train) W-NUT (train)</p>
    <p>#user 279K 782K #tweet 23.8M 9.03M tweet/user 85.6 11.6 #reduced-edge* 2.11M 1.01M reduced-edge/user 7.04 1.29 #city 339 3028</p>
    <p>* Restricted edges to sa8sfy one of the following condi8ons: 1. Both users have ground truth loca8ons. 2. One user has a ground truth loca8on and another user is</p>
    <p>men8oned 5 8mes or more.</p>
  </div>
  <div class="page">
    <p>Baselines and Sub-models Name Text Metadata</p>
    <p>User Network Key Components</p>
    <p>LR X logistic regression, k-d tree (Rahimi et al. 2015a)</p>
    <p>MADCEL-B-LR X X logistic regression, k-d tree, Modified Adsorption (Rahimi et al. 2015a)</p>
    <p>LR-STACK X X logistic regression, k-d tree, stacking (Han et al. 2013, 2014)</p>
    <p>MADCEL-BLR-STACK X X X</p>
    <p>logistic regression, k-d tree, stacking, Modified Adsorption</p>
    <p>SUB-NN-TEXT X TEXT SUB-NN-UNET X X TEXT, USERNET SUB-NN-META X X TEXT&amp;META Proposed Model X X X Full model</p>
  </div>
  <div class="page">
    <p>Metrics Metric Definition Accuracy The percentage of correctly predicted cities.</p>
    <p>Accuracy@161 A relaxed accuracy that takes prediction errors within 161 km as correct predictions.</p>
    <p>Median Error Distance* Median value of error distances in predictions. Mean Error Distance* Mean value of error distances in predictions.</p>
    <p>Example Predic8on: Vancouver Ground-truth: Victoria Accuracy = 0.0 Accuracy@161 = 1.0 Error Distance = 94km</p>
    <p>* Error distance evalua8ons are excluded from this presenta8on for simplifica8on.</p>
  </div>
  <div class="page">
    <p>Results (TwiPerUS)</p>
    <p>Model Accuracy Accuracy @161</p>
    <p>Baselines (implemented)</p>
    <p>LR MADCEL-B-LR LR-STACK MADCEL-B-LR-STACK</p>
    <p>Our Models</p>
    <p>SUB-NN-TEXT SUB-NN-UNET SUB-NN-META Proposed Model</p>
    <p>* significant improvement with 5% significance level ** significant improvement with 1% significance level</p>
  </div>
  <div class="page">
    <p>Results (W-NUT)</p>
    <p>Model Accuracy Accuracy @161</p>
    <p>Baselines (reported) Jayasinghe et al. (2016) 52.6 -</p>
    <p>Baselines (implemented)</p>
    <p>LR MADCEL-B-LR LR-STACK MADCEL-B-LR-STACK</p>
    <p>Our Models</p>
    <p>SUB-NN-TEXT SUB-NN-UNET SUB-NN-META Proposed Model</p>
    <p>** significant improvement with 1% significance level</p>
  </div>
  <div class="page">
    <p>Analysis of APen8on layers (1)</p>
    <p>description</p>
    <p>locationtimeline</p>
    <p>timezone</p>
    <p>messages (timeline)</p>
    <p>RNNL</p>
    <p>AttentionL</p>
    <p>FCU</p>
    <p>label</p>
    <p>location description timezone</p>
    <p>Timezone Embedding</p>
    <p>AttentionTL</p>
    <p>RNND</p>
    <p>AttentionD</p>
    <p>RNNM</p>
    <p>AttentionM</p>
    <p>AttentionU</p>
    <p>Word Embedding</p>
    <p>linked cities</p>
    <p>linked users</p>
    <p>+</p>
    <p>AttentionN</p>
    <p>City Embedding</p>
    <p>User Embedding</p>
    <p>AttentionUN</p>
    <p>FCUN</p>
    <p>TEXT</p>
    <p>TEXT&amp;META</p>
    <p>USERNETTimeline &amp; Metadata</p>
    <p>Stronger in TwiPerUS</p>
    <p>probability density func8ons</p>
  </div>
  <div class="page">
    <p>Analysis of APen8on layers (1)</p>
    <p>description</p>
    <p>locationtimeline</p>
    <p>timezone</p>
    <p>Stronger in TwiPerUS</p>
    <p>TwitterUS (train)</p>
    <p>W-NUT (train)</p>
    <p>#user 279K 782K</p>
    <p>#tweet 23.8M 9.03M</p>
    <p>tweet/user 85.6 11.6</p>
  </div>
  <div class="page">
    <p>Analysis of APen8on layers (2)</p>
    <p>messages (timeline)</p>
    <p>RNNL</p>
    <p>AttentionL</p>
    <p>FCU</p>
    <p>label</p>
    <p>location description timezone</p>
    <p>Timezone Embedding</p>
    <p>AttentionTL</p>
    <p>RNND</p>
    <p>AttentionD</p>
    <p>RNNM</p>
    <p>AttentionM</p>
    <p>AttentionU</p>
    <p>Word Embedding</p>
    <p>linked cities</p>
    <p>linked users</p>
    <p>+</p>
    <p>AttentionN</p>
    <p>City Embedding</p>
    <p>User Embedding</p>
    <p>AttentionUN</p>
    <p>FCUN</p>
    <p>TEXT</p>
    <p>TEXT&amp;META</p>
    <p>USERNETUser &amp; User Network</p>
    <p>user network</p>
    <p>Stronger in TwiPerUS</p>
    <p>probability density func8on</p>
  </div>
  <div class="page">
    <p>Analysis of APen8on layers (2)</p>
    <p>user network</p>
    <p>Stronger in TwiPerUS</p>
    <p>TwitterUS (train)</p>
    <p>W-NUT (train)</p>
    <p>#reduced-edge 2.11M 1.01M</p>
    <p>reduced-edge/user 7.04 1.29</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Proposed a neural network model for geoloca8on predic8on  Unifies:</p>
    <p>text  metadata  user network</p>
    <p>Improvement over previous state-of-the art models  +2.83.8% in accuracy  +2.46.6% in accuracy@161</p>
    <p>Analysis of aPen8on probabili8es:  Capturing sta8s8cal characteris8cs of the datasets</p>
  </div>
  <div class="page">
    <p>Future Works</p>
    <p>An extension of the proposed model  Introduc8on of temporal state</p>
    <p>Capture loca8on changes like travel</p>
    <p>Applica8on to different tasks  For example, gender analysis or age analysis</p>
    <p>Some metadata may not be effec8ve</p>
  </div>
  <div class="page">
    <p>Thank You!</p>
  </div>
  <div class="page">
    <p>References (1) Zhiyuan Cheng, James Caverlee, and Kyumin Lee. 2010. You are where you tweet: A content-based approach to geo-loca8ng TwiPer users. In Proc. of CIKM 2010. pp. 759 768. Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase representa8ons using RNN encoderdecoder for sta8s8cal machine transla8on. In Proc. of EMNLP 2014. pp. 17241734. Jacob Eisenstein, Brendan OConnor, Noah A. Smith, and Eric P. Xing. 2010. A latent variable model for geographic lexical varia8on. In Proc. of EMNLP 2010. pp.1277 1287. Bo Han, Paul Cook, and Timothy Baldwin. 2013. A stacking-based approach to TwiPer user geoloca8on predic8on. In Proc. of ACL 2013: System Demonstra8ons. pp.712. Bo Han, Paul Cook, and Timothy Baldwin. 2014. Text-based TwiPer user geoloca8on predic8on. Journal of Ar8ficial Intelligence Research 49(1):451500. Bo Han, Afshin Rahimi, Leon Derczynski, and Timothy Baldwin. 2016. TwiPer geoloca8on predic8on shared task of the 2016 workshop on noisy user-generated text. In Proc. of W-NUT 2016. pp.213217.</p>
  </div>
  <div class="page">
    <p>References (2) Gaya Jayasinghe, Brian Jin, James Mchugh, Bella Robinson, and Stephen Wan. 2016. CSIRO Data61 at the WNUT geo shared task. In Proc. of W-NUT 2016. pp.218226. Yasuhide Miura, Motoki Taniguchi, Tomoki Taniguchi, and Tomoko Ohkuma. 2016. A simple scalable neural networks based model for geoloca8on predic8on in TwiPer. In Proc. of W-NUT 2016. pp.235239. Afshin Rahimi, Trevor Cohn, and Timothy Baldwin. 2015a. TwiPer user geoloca8on using a unified text and network predic8on model. In Proc. of ACL 2015. pp.630636. Afshin Rahimi, Duy Vu, Trevor Cohn, and Timothy Baldwin. 2015b. Exploi8ng text and network context for geoloca8on of social media users. In Proc. of NAACL-HLT 2015. pp.13621367. Stephen Roller, Michael Speriosu, Sarat Rallapalli, Benjamin Wing, and Jason Baldridge. 2012. Supervised text-based geoloca8on using language models on an adap8ve grid. In Proc. of EMNLP 2012. pp.15001510.</p>
  </div>
  <div class="page">
    <p>Any Ques8ons?</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Mo8va8on</p>
    <p>Crucial for tasks like:  Disaster Analysis  Disease Analysis  Poli8cal Analysis</p>
    <p>Enables a region specific analysis in:  Sen8ment Analysis  User APribute Analysis</p>
  </div>
  <div class="page">
    <p>Other Geoloca8on Targets</p>
    <p>In previous works:  Wikipedia ar8cles (Overell, 2009)  Flicker photos (Serdyukov et al., 2009; Crandall et al., 2009)</p>
    <p>Facebook users (Backstrom et al., 2010)  TwiPer users (Cheng et al., 2010; Eisenstein et al., 2010)</p>
  </div>
  <div class="page">
    <p>Comparison with Previous Approaches</p>
    <p>In previous works:  Ensemble approaches</p>
    <p>Stacking (Han et al., 2013, 2014)  Dongle nodes (Rahimi et al., 2015a, 2015b)  Cascades ensemble (Jayasinghe et al., 2016)</p>
    <p>This work:  Neural network</p>
    <p>Mul8ple inputs  APen8on mechanism to merge inputs</p>
  </div>
  <div class="page">
    <p>Text and Metadata Component (2)</p>
    <p>Loca8on, Descrip8on  RNN+APen8on  Single text</p>
    <p>Timezone  Embedding for each 8mezone</p>
    <p>Merge  APen8on over four representa8ons</p>
    <p>messages (hierarchical)</p>
    <p>RNNL</p>
    <p>AttentionL</p>
    <p>location description timezone</p>
    <p>Timezone Embedding</p>
    <p>AttentionTL</p>
    <p>RNND</p>
    <p>AttentionD</p>
    <p>RNNM</p>
    <p>AttentionM</p>
    <p>AttentionU</p>
    <p>Word Embedding</p>
    <p>user representation</p>
  </div>
  <div class="page">
    <p>Data (1)(detailed)</p>
    <p>Two open datasets  TwiPerUS  The dataset of Roller et al. (2012)  449K TwiPer users  North America region</p>
    <p>W-NUT  The dataset of W-NUT 2016 geoloca8on predic8on shared task (Han et al., 2016)</p>
    <p>1.02M TwiPer users  World-wide</p>
  </div>
  <div class="page">
    <p>Data (2)(detailed) TwitterUS</p>
    <p>(train) W-NUT (train)</p>
    <p>#user 279K 782K #tweet 23.8M 9.03M tweet/user 85.6 11.6 #edge 3.69M 3.21M #reduced-edge* 2.11M 1.01M reduced-edge/user 7.04 1.29 #city 339 3028</p>
    <p>* Restricted edges to sa8sfy one of the following condi8ons: 1. Both users have ground truth loca8ons. 2. One user has a ground truth loca8on and another user is men8oned 5 8mes or more.</p>
  </div>
  <div class="page">
    <p>Baselines  LR</p>
    <p>l1-regularized logis8c regression with k-d tree regions (Roller et al., 2012; Rahimi et al. 2015a)</p>
    <p>MADCEL-B-LR  LR with Modified Adsorp8on (Rahimi et al. 2015a)</p>
    <p>Modified Adsorp8on is a graph-based label propaga8on algorithm  LR-STACK</p>
    <p>Stacking of logis8c regression classifiers  Four LR classifier for messages and metadata  l2-regularized logis8c regression meta-classifier</p>
    <p>Similar to previous stacking approaches (Han et al., 2013, 2014)  MADCEL-B-LR-STACK</p>
    <p>LR-STACK with Modified Adsorp8on</p>
  </div>
  <div class="page">
    <p>Results (TwiPerUS)(2)</p>
    <p>Model Sign. Test</p>
    <p>ID Accuracy</p>
    <p>Accuracy @161</p>
    <p>Error Distance</p>
    <p>Median Mean</p>
    <p>Baselines (reported)</p>
    <p>Han et al. (2012) Wing and Baldridge (2014) LR (Rahimi et al. 2015b) LR-NA (Rahimi et al. 2016) MADCEL-B-LR (Rahimi et al. 2015a) MADCEL-W-LR (Rahimi et al. 2015a)</p>
    <p>Baselines (implemented)</p>
    <p>LR MADCEL-B-LR LR-STACK MADCEL-B-LR-STACK</p>
    <p>i ii iii iv</p>
    <p>Our Models</p>
    <p>SUB-NN-TEXT SUB-NN-UNET SUB-NN-META Proposed Model</p>
    <p>i ii iii iv</p>
  </div>
  <div class="page">
    <p>Results (W-NUT)(2)</p>
    <p>Model Sign. Test</p>
    <p>ID Accuracy</p>
    <p>Accuracy @161</p>
    <p>Error Distance</p>
    <p>Median Mean</p>
    <p>Baselines (reported)</p>
    <p>Miura et al. (2016) Jayasinghe et al. (2016)</p>
    <p>-</p>
    <p>Baselines (implemented)</p>
    <p>LR MADCEL-B-LR LR-STACK MADCEL-B-LR-STACK</p>
    <p>i ii iii iv</p>
    <p>Our Models</p>
    <p>SUB-NN-TEXT SUB-NN-UNET SUB-NN-META Proposed Model</p>
    <p>i ii iii iv</p>
  </div>
  <div class="page">
    <p>APen8on PaPerns</p>
    <p>Clustering of APen8onU and APen8onUN  k-means with 9 clusters  Some typical paPerns</p>
    <p>Cluster 2 and Cluster 3 balancing Timeline and Loca8on</p>
    <p>TwitterUS W-NUT</p>
    <p>Cluster ID</p>
    <p>Dataset Timeline</p>
    <p>Location</p>
    <p>Description</p>
    <p>Timezone</p>
    <p>User User Net</p>
  </div>
  <div class="page">
    <p>Errors with High Confidences</p>
    <p>Incorrect Loca8on Field  Ex.</p>
    <p>Loca8on Field: Hong Kong  Ground-truth: Tronto</p>
    <p>Perhaps, a house move  Travel  Ex.</p>
    <p>Twee8ng about San Francisco  Ground-truth: Boston</p>
  </div>
  <div class="page">
    <p>Model Configura8on (1)</p>
    <p>TwitterUS W-NUT RNN unit size 100 200</p>
    <p>Attention context vector size 200 400</p>
    <p>FC unit size 200 400</p>
    <p>Word embedding dimension 100 200</p>
    <p>Timezone embedding dimension 200 400</p>
    <p>City embedding dimension 200 400</p>
    <p>User embedding dimension 200 400</p>
    <p>Max tweet number per user 200 -</p>
  </div>
  <div class="page">
    <p>Model Configura8on (2)  Pre-training  Word Embeddings</p>
    <p>skip-gram  learning rate=0.025, window size=5, nega8ve sample size=5, epoch=5</p>
    <p>Network Embeddings  LINE</p>
    <p>ini8al learning rate=0.025, order=2, nega8ve sample size=5, training sample size=100M</p>
    <p>Op8miza8on  Adam  l2 regulariza8on</p>
  </div>
  <div class="page">
    <p>Training Time</p>
    <p>GPU  GeForce GTX Titan X  Titan X</p>
    <p>Time  1520 hours</p>
    <p>Full model  Longer for TwiPerUS</p>
  </div>
</Presentation>
