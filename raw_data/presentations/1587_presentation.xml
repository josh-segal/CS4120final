<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Improving Docker Registry Design based on Production Workload Analysis</p>
    <p>Ali Anwar, Mohamed Mohamed, Vasily Tarasov, Michael Littley, Lukas Rupprecht, Yue Cheng,</p>
    <p>Nannan Zhao, Dimitrios Skourtis, Amit S. Warke, Heiko Ludwig, Dean Hildebrand, and Ali R. Butt</p>
  </div>
  <div class="page">
    <p>The average company QUINTUPLES its Docker usage within</p>
    <p>Source: Datadog</p>
    <p>Containers will be a $2.7B market by 2020*</p>
    <p>Containers accelerate software development and distribution.</p>
    <p>In 2017 alone, Docker adoption went up by 40%.</p>
    <p>Containers use in enterprise and cloud infrastructure is expected to grow much faster.</p>
    <p>*http://bit.ly/2uryjDI</p>
  </div>
  <div class="page">
    <p>Docker usage patterns remain a mystery</p>
    <p>How are Docker containers used and managed?  How can we streamline Docker workflows?  How do we facilitate Docker performance analysis?</p>
  </div>
  <div class="page">
    <p>Our contribution: Characterization and optimization of Docker workflow</p>
    <p>Conduct a large-scale analysis of a real-world Docker workload from geo-distributed IBM container service</p>
    <p>Provide insights and develop heuristics to increase Docker performance</p>
    <p>Develop an open source Docker workflow analysis tool* * https://dssl.cs.vt.edu/drtp/</p>
  </div>
  <div class="page">
    <p>Background: Docker container image</p>
    <p>Container images are divided into layers.  The metadata file is called manifest.  Users create repositories to store images.  Images in a repository can have</p>
    <p>different tags (versions). JSON Layer</p>
    <p>Layer</p>
    <p>Layer</p>
    <p>Manifest</p>
    <p>Container image</p>
    <p>}</p>
    <p>Redis CentOS</p>
    <p>v2.6</p>
    <p>latest myOS</p>
  </div>
  <div class="page">
    <p>Background: Docker container image</p>
    <p>Container images are divided into layers.  The metadata file is called manifest.  Users create repositories to store images.  Images in a repository can have</p>
    <p>different tags (versions). JSON Layer</p>
    <p>Layer</p>
    <p>Layer</p>
    <p>Manifest</p>
    <p>Container image</p>
    <p>}</p>
    <p>Redis CentOS</p>
    <p>v2.6</p>
    <p>latest myOS &lt;user, repository, tag&gt;</p>
  </div>
  <div class="page">
    <p>Background: Docker container registry</p>
    <p>Docker container images are stored online in Docker registry.</p>
    <p>docker push docker pull</p>
    <p>Push image: 1. HEAD layers 2. POST/PUT layer 3. PUT manifest</p>
    <p>Pull image: 1. GET manifest 2. GET layers</p>
  </div>
  <div class="page">
    <p>Background: Docker container registry</p>
    <p>Docker container images are stored online in Docker registry.</p>
    <p>docker push docker pull</p>
    <p>Push image: 1. HEAD layers 2. POST/PUT layer 3. PUT manifest</p>
    <p>Pull image: 1. GET manifest 2. GET layers</p>
    <p>Significant amount of a container startup time is spent in pulling the image</p>
  </div>
  <div class="page">
    <p>The IBM Cloud Docker registry traces</p>
    <p>Capture a diverse set of customers: individuals, small &amp; medium businesses, government institutions</p>
    <p>Cover five geographical locations and seven availability zones</p>
    <p>Span 75 days and 38M requests that account for more than ~181TB of data transferred</p>
  </div>
  <div class="page">
    <p>IBM Docker registry service</p>
    <p>Five geographical locations constitute seven Availability Zones (AZ):</p>
    <p>IBM Cloud Registry architecture</p>
    <p>*The registry setup is identical, except prs and dev are only half the size of the other Azs.</p>
    <p>IBM Internal 5. Staging (stg)</p>
    <p>Testing*</p>
    <p>Production 1. Dallas (dal) 2. London (lon) 3. Frankfurt (fra) 4. Sydney (syd) Nginx</p>
    <p>Object store Registry</p>
    <p>Broadcaster</p>
    <p>Registry</p>
    <p>Registry</p>
    <p>Stats counter</p>
  </div>
  <div class="page">
    <p>Tracing methodology</p>
    <p>Combined traces by matching the incoming HTTP request identifier across the components</p>
    <p>Removed redundant fields and anonymized the traces</p>
    <p>Collected data from Registry, Nginx, and Broadcaster</p>
    <p>Studied requests: GET, PUT, HEAD, PATCH, POST</p>
    <p>Registry</p>
    <p>Broadcaster</p>
    <p>Registry</p>
    <p>Registry</p>
    <p>Nginx</p>
  </div>
  <div class="page">
    <p>{ &quot;host&quot;: &quot; &quot;, &quot;http.request.duration&quot;: 0.879271282, &quot;http.request.method&quot;: &quot;GET&quot;, &quot;http.request.remoteaddr&quot;: &quot; &quot;, &quot;http.request.uri&quot;: &quot;v2/ / /blobs/ &quot;, &quot;http.request.useragent&quot;: &quot;docker/17.04.0-ce go/go1.7.5..)&quot;, &quot;http.response.status&quot;: 200, &quot;http.response.written&quot;: 1518, &quot;id&quot;: &quot; &quot;, &quot;timestamp&quot;: &quot;2017-07-01T01:39:37.098Z&quot; }</p>
    <p>Anonymized log sample</p>
  </div>
  <div class="page">
    <p>Q1: What is the distribution of request types?</p>
    <p>da l</p>
    <p>lo n</p>
    <p>fr a</p>
    <p>sy d</p>
    <p>st g</p>
    <p>pr s</p>
    <p>de v</p>
    <p>Re qu</p>
    <p>es ts</p>
    <p>pull push 80%95% of requests are reads (pulls)</p>
    <p>Production: dal, lon, fra, syd IBM internal: stg Testing: prs, dev</p>
  </div>
  <div class="page">
    <p>dal lon fra syd stg prs dev</p>
    <p>Re qu</p>
    <p>es ts</p>
    <p>GET POST HEAD PUT PATCH</p>
    <p>Q1: What is the distribution of request types?</p>
    <p>Production: dal, lon, fra, syd IBM internal: stg Testing: prs, dev</p>
  </div>
  <div class="page">
    <p>Q2: What is the manifest size distribution?</p>
    <p>Typical manifest size is around 1 KB</p>
    <p>Production: dal, lon, fra, syd IBM internal: stg Testing: prs, dev</p>
  </div>
  <div class="page">
    <p>Q3: What is the layer size distribution? 65% of the layers are smaller than 1 MB and</p>
    <p>around 80% are smaller than 10 MB</p>
    <p>Production: dal, lon, fra, syd IBM internal: stg Testing: prs, dev</p>
  </div>
  <div class="page">
    <p>Q3: What is the layer size distribution? 65% of the layers are smaller than 1 MB and</p>
    <p>around 80% are smaller than 10 MB</p>
    <p>There is a significant opportunity for caching the layers</p>
    <p>Production: dal, lon, fra, syd IBM internal: stg Testing: prs, dev</p>
  </div>
  <div class="page">
    <p>Q4: Is there spatial locality? 1% of most accessed layers account for 42% and 59% of</p>
    <p>all requests in dal and syd, respectively</p>
    <p>Production: dal, lon, fra, syd IBM internal: stg Testing: prs, dev</p>
  </div>
  <div class="page">
    <p>Q4: Is there spatial locality?</p>
    <p>% o f r eq</p>
    <p>ue st s</p>
    <p>Popularity rank</p>
    <p>dal lon fra syd stg prs dev</p>
    <p>Production: dal, lon, fra, syd IBM internal: stg Testing: prs, dev</p>
    <p>The popularity rate drops rapidly as we move from most popular to tenth most popular layer</p>
  </div>
  <div class="page">
    <p>Q5: Can future requests be predicted?</p>
    <p>GET manifest requests are not followed by any subsequent GET layer request Production: dal, lon, fra, syd</p>
    <p>IBM internal: stg Testing: prs, dev</p>
  </div>
  <div class="page">
    <p>Q5: Can future requests be predicted? Significant increase in subsequent GET</p>
    <p>layer requests within a session Production: dal, lon, fra, syd IBM internal: stg Testing: prs, dev</p>
  </div>
  <div class="page">
    <p>Q5: Can future requests be predicted? Significant increase in subsequent GET</p>
    <p>layer requests within a session</p>
    <p>Strong correlation between requests  GET layers requests can be predicted  opportunity for layer prefetching</p>
    <p>Production: dal, lon, fra, syd IBM internal: stg Testing: prs, dev</p>
  </div>
  <div class="page">
    <p>Enabling further analysis: Trace re-player</p>
    <p>Client 1</p>
    <p>Master Client 2</p>
    <p>Client 3</p>
    <p>Registry</p>
    <p>Trace Round Robin/ Hashing (client remote address)</p>
    <p>Performance analysis mode</p>
    <p>Offline analysis mode</p>
    <p>Study throughput and latency  Understand effect of CPU,</p>
    <p>Memory, Storage, Network</p>
    <p>Simulate prefetching and caching policies  Explore cache efficacy</p>
    <p>Additional analysis  Analyze request arrival rate at user define granularity  Study effect of deduplication on registry size</p>
  </div>
  <div class="page">
    <p>Effect of backend storage technologies</p>
    <p>Experimental setup:</p>
    <p>Registry on 32 core machine with 64 GB RAM and 512 GB SSD</p>
    <p>Swift object store on 10 similar nodes</p>
    <p>Trace re-player on 6 additional nodes</p>
  </div>
  <div class="page">
    <p>Effect of backend storage technologies</p>
    <p>Experimental setup:</p>
    <p>Registry on 32 core machine with 64 GB RAM and 512 GB SSD</p>
    <p>Swift object store on 10 similar nodes</p>
    <p>Trace re-player on 6 additional nodes Fast backend storage/cache for the registry can significantly improve the overall performance</p>
  </div>
  <div class="page">
    <p>Effect of a two-level Main Memory+SSD cache</p>
    <p>Experimental setup:  Small layers (&lt;100 MB) are stored in the main memory  Replacement policy for both cache level is LRU  Studied cache sizes:</p>
    <p>RAM: 2%, 4%, 6%, 8%, and 10% of the data ingress SSD: 10x, 15x, 20x the size of RAM cache</p>
    <p>Layers are content addressable  cache invalidation is not a problem</p>
  </div>
  <div class="page">
    <p>Two-level cache: Main memory+SSD</p>
    <p>hi t r at io</p>
    <p>data ingress</p>
    <p>LRU:mem LRU:mem+SSD(10x)</p>
    <p>LRU:mem+SSD(15x) LRU:mem+SSD(20x)</p>
    <p>Dallas</p>
  </div>
  <div class="page">
    <p>Benefit of layer prefetching</p>
    <p>PUT layer GET manifest GET layer LMthresh MLthresh</p>
    <p>hi ts /p re fe tc h</p>
    <p>LM thresh</p>
    <p>ML-thresh:1 hour ML-thresh:12 hours ML-thresh:1 day</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>We perform a quantitative characterization of a production Docker registry deployment  Registry workload is read intensive  Layers sizes are small  Strong correlation exists between layer requests</p>
    <p>We propose effective caching and prefetching strategies for container layers</p>
    <p>We enable further Docker investigation and optimization by making our traces and the trace re-player tool open source*</p>
    <p>* https://dssl.cs.vt.edu/drtp/</p>
  </div>
  <div class="page">
    <p>Thank You!</p>
    <p>Questions &amp; contact: Ali Anwar, ali@vt.edu https://dssl.cs.vt.edu/</p>
  </div>
</Presentation>
