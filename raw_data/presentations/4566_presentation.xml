<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>An Integrated Knowledge-based and Machine Learning Approach for Chinese Question Classification</p>
    <p>Min-Yuh Day1,2, Cheng-Wei Lee1, Shih-Hung Wu3,</p>
    <p>Chorng-Shyong Ong2, Wen-Lian Hsu1</p>
    <p>myday@iis.sinica.edu.tw IEEE NLPKE 2005</p>
  </div>
  <div class="page">
    <p>Outline  Introduction</p>
    <p>Chinese Question Classification (CQC)  Proposed Approach</p>
    <p>Knowledge-based Approach: INFOMAP  Machine Learning Approach: SVM  Integration of SVM and INFOMAP</p>
    <p>Hybrid Approach</p>
    <p>Experimental Results and Discussion  Related Works  Conclusions</p>
  </div>
  <div class="page">
    <p>Introduction  Question Answering</p>
    <p>TREC QA  QA@CLEF  NTCIR CLQA</p>
    <p>Chinese Question Classification  Goal: accurately classify a Chinese question into a question</p>
    <p>type and then map it to an expected answer type  Chinese Question:</p>
    <p>Where is the originating place of the Olympics?  Question Type: Q_LOCATION|</p>
    <p>Question Types  Answer extraction and answer filtering  Improve the accuracy of the overall question answering</p>
    <p>system</p>
  </div>
  <div class="page">
    <p>Introduction  Problem of Question Classification</p>
    <p>36.4% of the errors occur in the question classification module (Moldovan et al., 2003)</p>
    <p>Approaches to Question Classification (QC)  Rule-based approaches  Statistical approaches</p>
  </div>
  <div class="page">
    <p>Proposed Approach  Chinese Question Taxonomy  Question Type Filter for</p>
    <p>Expected Answer Type (EAT)  Knowledge-based Approach:</p>
    <p>INFOMAP  Machine Learning Approach: SVM  Hybrid Approach: Integration of SVM</p>
    <p>and INFOMAP</p>
  </div>
  <div class="page">
    <p>Chinese Question Taxonomy for NTCIR CLQA Factoid Question Answering</p>
  </div>
  <div class="page">
    <p>Question Type (QType) Filter for Expected Answer Type (EAT)</p>
  </div>
  <div class="page">
    <p>INFOMAP (Knowledge-based Approach)</p>
    <p>INFOMAP: Knowledge Representation Framework  Extracts important concepts from a natural language</p>
    <p>text  Feature of INFOMAP</p>
    <p>represent and match complicated template structures  hierarchical matching  regular expressions  semantic template matching  frame (non-linear relations) matching  graph matching</p>
    <p>We adopt INFOMAP as the knowledge-based approach for CQC</p>
    <p>Using INFOMAP, we can identify the question category from a Chinese question</p>
  </div>
  <div class="page">
    <p>Knowledge Representation of Chinese Question</p>
    <p>Chinese Question: 2004  ? (In which city were the Olympics held in</p>
    <p>[5 Time]:[3 Organization]:[7 Q_Location]:([9 LocaitonRelatedEvent])</p>
  </div>
  <div class="page">
    <p>Knowledge representation for CQC in INFOMAP</p>
  </div>
  <div class="page">
    <p>Knowledge representation for CQC in INFOMAP</p>
  </div>
  <div class="page">
    <p>Knowledge representation for CQC in INFOMAP</p>
  </div>
  <div class="page">
    <p>Knowledge representation for CQC in INFOMAP</p>
    <p>[5 Time]: [3 Organization] :[7 Q_Location]: ([9 LocaitonRelatedEvent])</p>
  </div>
  <div class="page">
    <p>SVM (Machine Learning Approach)</p>
    <p>Two types of feature used for CQC  Syntactic features</p>
    <p>Bag-of-Words  character-based bigram (CB)  word-based bigram (WB)</p>
    <p>Part-of-Speech (POS)  AUTOTAG</p>
    <p>POS tagger developed by CKIP, Academia Sinica</p>
    <p>Semantic Features  HowNet Senses</p>
    <p>HowNet Main Definition (HNMD)  HowNet Definition (HND)</p>
  </div>
  <div class="page">
    <p>Integration of SVM and INFOMAP (Hybrid Approach)</p>
    <p>The integrated module selects the question type with the highest confidence score from the INFOMAP or the SVM model</p>
    <p>If the question matches the templates or rules represented in INFOMAP and obtains the question type, we use the question type obtain from INFOMAP first.</p>
    <p>If no question type can be obtained from INFOMAP, we use the result from the SVM model.</p>
    <p>If multiple question types are obtained from INFOMAP, we choose the one obtained from SVM first.</p>
    <p>If one question type with a high positive score is obtained from SVM and one question type obtained from INFOMAP, which is not the same as the one from SVM, we choose the one from SVM with a high positive score.</p>
    <p>SVM</p>
    <p>INFOMAP</p>
    <p>HP</p>
  </div>
  <div class="page">
    <p>Experimental Results and Discussion  Datasets</p>
    <p>Training: 1350 questions  500 questions from CLQAs development dataset</p>
    <p>300 questions for Japanese news  200 questions for Traditional Chinese news</p>
    <p>850 questions manually build for our proposed question taxonomy</p>
    <p>518 questions in SVM  332 questions in INFOMAP</p>
    <p>Testing: 200 questions  200 Questions from CLQAs formal run dataset</p>
    <p>We use different features to train the SVM model based on a total of 1350 questions and their labeled question type</p>
  </div>
  <div class="page">
    <p>Experimental Results of CLQAs development dataset</p>
    <p>SVM Training data: CLQAS300 (300 questions for Japanese news) SVM Testing data: CLQAS200 (200 questions for Chinese news)</p>
  </div>
  <div class="page">
    <p>Experimental Results of CLQAs Formal Run dataset  Training dataset: 1350 questions</p>
    <p>300 (Development dataset for Japanese News) + 200 (Development dataset for Chinese News) + 518 (SVM) + 332 (INFOMAP)</p>
    <p>Features: CB+HNMD  Testing dataset: 200 questions</p>
    <p>CLQAs formal run</p>
  </div>
  <div class="page">
    <p>Experimental Results of CLQAs Formal Run dataset</p>
  </div>
  <div class="page">
    <p>Discussion  Integrated approach performs better than the</p>
    <p>individual knowledge-based or machine learning approach</p>
    <p>knowledge-based approach performs well with easy questions using the templates and rules</p>
    <p>Easy questions are defined as follows:  Clear words that show the question type and indicate the</p>
    <p>words that are not question types  Ex:   (Who),   (Which person),   (the first</p>
    <p>person)  Explicit words that identify the question type. If words are</p>
    <p>easy to identify, it means they overlap with a question type  Ex:  (team) and   (sports team)</p>
    <p>Interrogative words that connect with question type words in question</p>
    <p>Ex:   (Which Person)</p>
  </div>
  <div class="page">
    <p>Related Works  Li and Roth (2002)</p>
    <p>6 coarse classes and 50 fine classes for TREC factoid question answering  Sparse Network of Windows (SNoW)  Over 90% accuracy</p>
    <p>Zhang and Lee (2003)  Support Vector Machines (SVMs)  Surface text features (bag-of-words and bag-of-ngrams)</p>
    <p>coarse-grained: 86% accuracy  fine-grained: approximately 80% accuracy.</p>
    <p>Adding syntactic information  coarse-grained: accuracy of 90%</p>
    <p>Suzuki et al. (2003)  Hierarchical SVM  Four feature sets</p>
    <p>(1) words only (2) words and named entities (3) words and semantic information (4) words and NEs and semantic information</p>
    <p>Coarse-grained: 95% (depth 1)  Fine-grained: 75% (depth 4)</p>
  </div>
  <div class="page">
    <p>Comparison with related works  Question classification in Chinese  The accuracy of CQC</p>
    <p>SVM: 73.5%  INFOMAP: 88%  Hybrid Approach (SVM+INFOMAP):</p>
  </div>
  <div class="page">
    <p>Conclusions  We have proposed a Hybrid approach to</p>
    <p>Chinese question classification (CQC) for NTCIR CLQA factoid question-answering  Hierarchical coarse-grained and fine-grained</p>
    <p>question taxonomies  6 coarse-grained categories and 62 fine-grained</p>
    <p>categories for Chinese questions  Mapping method for question type filtering</p>
    <p>to obtain expected answer types (EAT)  The integrated knowledge-based and</p>
    <p>machine learning approach achieves significantly better accuracy rate than individual approaches</p>
  </div>
  <div class="page">
    <p>Applications: ASQA (Academia Sinica Question Answering system)  ASQA (IASL-IIS-SINICA-TAIWAN)</p>
    <p>First place in the Chinese-Chinese (CC) subtask of the NTCIR5 CrossLanguage Question Answering (CLQA 2005) task</p>
  </div>
  <div class="page">
    <p>http://asqa.iis.sinica.edu.tw/clqa/</p>
  </div>
  <div class="page">
    <p>Q &amp; A An Integrated Knowledge-based and Machine Learning Approach</p>
    <p>for Chinese Question Classification</p>
    <p>Min-Yuh Day1,2, Cheng-Wei Lee1, Shih-Hung Wu3, Chorng-Shyong Ong2, Wen-Lian Hsu1</p>
    <p>( 1,2,  1,  3,  2,  1)</p>
    <p>myday@iis.sinica.edu.tw</p>
    <p>IEEE NLPKE 2005</p>
  </div>
</Presentation>
