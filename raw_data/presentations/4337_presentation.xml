<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Sameen Maruf, Gholamreza Haffari</p>
    <p>Faculty of Information Technology</p>
    <p>Monash University</p>
    <p>July 17, 2017</p>
  </div>
  <div class="page">
    <p>Overview</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>Overview</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>Why document-level machine translation?</p>
    <p>Most MT models translate sentences independently</p>
    <p>Discourse phenomena are ignored, e.g. pronominal anaphora and lexical consistency which may have long range dependency</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>Why document-level machine translation?</p>
    <p>Most MT models translate sentences independently</p>
    <p>Discourse phenomena are ignored, e.g. pronominal anaphora and lexical consistency which may have long range dependency</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>Why document-level machine translation?</p>
    <p>Most MT models translate sentences independently</p>
    <p>Discourse phenomena are ignored, e.g. pronominal anaphora and lexical consistency which may have long range dependency</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>Why document-level machine translation?</p>
    <p>Most MT models translate sentences independently</p>
    <p>Discourse phenomena are ignored, e.g. pronominal anaphora and lexical consistency which may have long range dependency</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>Why document-level machine translation?</p>
    <p>Most MT models translate sentences independently</p>
    <p>Discourse phenomena are ignored, e.g. pronominal anaphora and lexical consistency which may have long range dependency</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>Why document-level machine translation?</p>
    <p>Statistical MT attempts to document MT do not yield significant empirical improvements [Hardmeier and Federico, 2010, Gong et al., 2011, Garcia et al., 2014]</p>
    <p>Previous context-NMT models only use local context and report deteriorated performance when using the target-side context [Jean et al., 2017, Wang et al., 2017, Bawden et al., 2018]</p>
    <p>We incorporate global source and target document contexts</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>Why document-level machine translation?</p>
    <p>Statistical MT attempts to document MT do not yield significant empirical improvements [Hardmeier and Federico, 2010, Gong et al., 2011, Garcia et al., 2014]</p>
    <p>Previous context-NMT models only use local context and report deteriorated performance when using the target-side context [Jean et al., 2017, Wang et al., 2017, Bawden et al., 2018]</p>
    <p>We incorporate global source and target document contexts</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>Why document-level machine translation?</p>
    <p>Statistical MT attempts to document MT do not yield significant empirical improvements [Hardmeier and Federico, 2010, Gong et al., 2011, Garcia et al., 2014]</p>
    <p>Previous context-NMT models only use local context and report deteriorated performance when using the target-side context [Jean et al., 2017, Wang et al., 2017, Bawden et al., 2018]</p>
    <p>We incorporate global source and target document contexts</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>Why document-level machine translation?</p>
    <p>Statistical MT attempts to document MT do not yield significant empirical improvements [Hardmeier and Federico, 2010, Gong et al., 2011, Garcia et al., 2014]</p>
    <p>Previous context-NMT models only use local context and report deteriorated performance when using the target-side context [Jean et al., 2017, Wang et al., 2017, Bawden et al., 2018]</p>
    <p>We incorporate global source and target document contexts</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Overview</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
    <p>Two types of factors: f(yt ; xt, xt ), g(yt ; yt )</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
    <p>Training objective: Maximise P(y1, . . . , y|d||x1, . . . , x|d|)</p>
    <p>= Maximise the pseudo-likelihood</p>
    <p>arg max</p>
    <p>|d| t=1</p>
    <p>P(yt|xt, yt, xt ) (1)</p>
    <p>where f and g are subsumed in the P(yt|xt, yt, xt )</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
    <p>Training objective:</p>
    <p>Maximise P(y1, . . . , y|d||x1, . . . , x|d|)</p>
    <p>= Maximise the pseudo-likelihood</p>
    <p>arg max</p>
    <p>|d| t=1</p>
    <p>P(yt|xt, yt, xt ) (1)</p>
    <p>where f and g are subsumed in the P(yt|xt, yt, xt )</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
    <p>Training objective: Maximise P(y1, . . . , y|d||x1, . . . , x|d|)</p>
    <p>= Maximise the pseudo-likelihood</p>
    <p>arg max</p>
    <p>|d| t=1</p>
    <p>P(yt|xt, yt, xt ) (1)</p>
    <p>where f and g are subsumed in the P(yt|xt, yt, xt )</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
    <p>Training objective: Maximise P(y1, . . . , y|d||x1, . . . , x|d|)</p>
    <p>= Maximise the pseudo-likelihood</p>
    <p>arg max</p>
    <p>|d| t=1</p>
    <p>P(yt|xt, yt, xt ) (1)</p>
    <p>where f and g are subsumed in the P(yt|xt, yt, xt )</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
    <p>Challenge: During test time, the target document is not given</p>
    <p>Coordinate Ascent (i.e., Iterative Decoding)</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
    <p>Challenge: During test time, the target document is not given</p>
    <p>Coordinate Ascent (i.e., Iterative Decoding)</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
    <p>Challenge: During test time, the target document is not given</p>
    <p>Coordinate Ascent (i.e., Iterative Decoding)</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
    <p>Challenge: During test time, the target document is not given</p>
    <p>Coordinate Ascent (i.e., Iterative Decoding)</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
    <p>Challenge: During test time, the target document is not given</p>
    <p>Coordinate Ascent (i.e., Iterative Decoding)</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
    <p>Challenge: During test time, the target document is not given</p>
    <p>Coordinate Ascent (i.e., Iterative Decoding)</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
    <p>Iterative Decoding</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
    <p>Iterative Decoding</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
    <p>Iterative Decoding</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
    <p>Iterative Decoding</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
    <p>Iterative Decoding</p>
  </div>
  <div class="page">
    <p>Document MT as Structured Prediction</p>
    <p>Document MT as Structured Prediction</p>
    <p>Iterative Decoding</p>
  </div>
  <div class="page">
    <p>Document NMT with MemNets</p>
    <p>Overview</p>
  </div>
  <div class="page">
    <p>Document NMT with MemNets</p>
    <p>Document NMT with MemNets</p>
    <p>= P(yt|xt, yt, xt )</p>
  </div>
  <div class="page">
    <p>Document NMT with MemNets</p>
    <p>Document NMT with MemNets</p>
    <p>=</p>
  </div>
  <div class="page">
    <p>Document NMT with MemNets</p>
    <p>Document NMT with MemNets</p>
    <p>=</p>
  </div>
  <div class="page">
    <p>Document NMT with MemNets</p>
    <p>Document NMT with MemNets</p>
    <p>=</p>
  </div>
  <div class="page">
    <p>Document NMT with MemNets</p>
    <p>Document NMT with MemNets</p>
    <p>=</p>
    <p>Memory-to-Context:</p>
    <p>st,j = GRU(st,j1, ET [yt,j1], ct,j, csrct , c trg t )</p>
  </div>
  <div class="page">
    <p>Document NMT with MemNets</p>
    <p>Document NMT with MemNets</p>
    <p>=</p>
    <p>Memory-to-Output:</p>
    <p>yt,j  softmax(Wy  rt,j + Wym  csrct + Wyt  c trg t + by )</p>
  </div>
  <div class="page">
    <p>Document NMT with MemNets</p>
    <p>Document NMT with MemNets</p>
    <p>Use only source, target, or both external memories</p>
    <p>Use Memory-to-Context/Memory-to-Output architectures for incorporating the different contexts</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Overview</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Experimental Setup</p>
    <p>Training/dev/test corpora statistics:</p>
    <p>corpus #docs (H) #sents (K) avg doc len</p>
    <p>FrEn Ted-Talks 10/1.2/1.5 123/15/19 123/128/124 EtEn Europarl v7 150/10/18 209/14/25 14/14/14 DeEn News-Commentary 49/.9/1.6 191/2/3 39/23/19</p>
    <p>Evaluation Metrics: BLEU, METEOR</p>
    <p>Baselines:</p>
    <p>Context-free baseline (S-NMT)</p>
    <p>Local source context baselines:  [Jean et al., 2017] &amp; [Wang et al., 2017]</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Experimental Setup</p>
    <p>Training/dev/test corpora statistics:</p>
    <p>corpus #docs (H) #sents (K) avg doc len</p>
    <p>FrEn Ted-Talks 10/1.2/1.5 123/15/19 123/128/124 EtEn Europarl v7 150/10/18 209/14/25 14/14/14 DeEn News-Commentary 49/.9/1.6 191/2/3 39/23/19</p>
    <p>Evaluation Metrics: BLEU, METEOR</p>
    <p>Baselines:</p>
    <p>Context-free baseline (S-NMT)</p>
    <p>Local source context baselines:  [Jean et al., 2017] &amp; [Wang et al., 2017]</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Experimental Setup</p>
    <p>Training/dev/test corpora statistics:</p>
    <p>corpus #docs (H) #sents (K) avg doc len</p>
    <p>FrEn Ted-Talks 10/1.2/1.5 123/15/19 123/128/124 EtEn Europarl v7 150/10/18 209/14/25 14/14/14 DeEn News-Commentary 49/.9/1.6 191/2/3 39/23/19</p>
    <p>Evaluation Metrics: BLEU, METEOR</p>
    <p>Baselines:</p>
    <p>Context-free baseline (S-NMT)</p>
    <p>Local source context baselines:  [Jean et al., 2017] &amp; [Wang et al., 2017]</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Experimental Setup</p>
    <p>Training/dev/test corpora statistics:</p>
    <p>corpus #docs (H) #sents (K) avg doc len</p>
    <p>FrEn Ted-Talks 10/1.2/1.5 123/15/19 123/128/124 EtEn Europarl v7 150/10/18 209/14/25 14/14/14 DeEn News-Commentary 49/.9/1.6 191/2/3 39/23/19</p>
    <p>Evaluation Metrics: BLEU, METEOR</p>
    <p>Baselines:</p>
    <p>Context-free baseline (S-NMT)</p>
    <p>Local source context baselines:  [Jean et al., 2017] &amp; [Wang et al., 2017]</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Memory-to-Context Results</p>
    <p>FrEnFrEnFrEn 0</p>
    <p>B L</p>
    <p>E U</p>
    <p>DeEnDeEnDeEn 0</p>
    <p>EtEnEtEnEtEn 0</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Memory-to-Context Results</p>
    <p>FrEn 20</p>
    <p>B L</p>
    <p>E U</p>
    <p>DeEn 9</p>
    <p>S-NMT</p>
    <p>EtEn 20</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Memory-to-Context Results</p>
    <p>FrEn 20</p>
    <p>B L</p>
    <p>E U</p>
    <p>DeEn 9</p>
    <p>S-NMT S-NMT+src</p>
    <p>EtEn 20</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Memory-to-Context Results</p>
    <p>FrEn 20</p>
    <p>B L</p>
    <p>E U</p>
    <p>DeEn 9</p>
    <p>S-NMT S-NMT+src S-NMT+trg</p>
    <p>EtEn 20</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Memory-to-Context Results</p>
    <p>FrEn 20</p>
    <p>B L</p>
    <p>E U</p>
    <p>DeEn 9</p>
    <p>S-NMT S-NMT+src S-NMT+trg S-NMT+both</p>
    <p>EtEn 20</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Memory-to-Output Results</p>
    <p>FrEnFrEnFrEn 0</p>
    <p>B L</p>
    <p>E U</p>
    <p>DeEnDeEnDeEn 0</p>
    <p>EtEnEtEnEtEn 0</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Memory-to-Output Results</p>
    <p>FrEn 20</p>
    <p>B L</p>
    <p>E U</p>
    <p>DeEn 9</p>
    <p>S-NMT</p>
    <p>EtEn 20</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Memory-to-Output Results</p>
    <p>FrEn 20</p>
    <p>B L</p>
    <p>E U</p>
    <p>DeEn 9</p>
    <p>S-NMT S-NMT+src</p>
    <p>EtEn 20</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Memory-to-Output Results</p>
    <p>FrEn 20</p>
    <p>B L</p>
    <p>E U</p>
    <p>DeEn 9</p>
    <p>S-NMT S-NMT+src S-NMT+trg</p>
    <p>EtEn 20</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Memory-to-Output Results</p>
    <p>FrEn 20</p>
    <p>B L</p>
    <p>E U</p>
    <p>DeEn 9</p>
    <p>S-NMT S-NMT+src S-NMT+trg S-NMT+both</p>
    <p>EtEn 20</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Main Results</p>
    <p>FrEnFrEnFrEn 0</p>
    <p>B L</p>
    <p>E U</p>
    <p>DeEnDeEnDeEn 0</p>
    <p>EtEnEtEnEtEn 0</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Main Results</p>
    <p>FrEn 21</p>
    <p>B L</p>
    <p>E U</p>
    <p>DeEn 10</p>
    <p>[Jean et al., 2017] [Wang et al., 2017]</p>
    <p>EtEn 21</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Main Results</p>
    <p>FrEn 21</p>
    <p>B L</p>
    <p>E U</p>
    <p>DeEn 10</p>
    <p>[Jean et al., 2017] [Wang et al., 2017] S-NMT+src</p>
    <p>EtEn 21</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Main Results</p>
    <p>FrEn 21</p>
    <p>B L</p>
    <p>E U</p>
    <p>DeEn 10</p>
    <p>[Jean et al., 2017] [Wang et al., 2017] S-NMT+src S-NMT+both</p>
    <p>EtEn 21</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Example translation</p>
    <p>Source qimonda taidab lissaboni strateegia eesmarke. Target qimonda meets the objectives of the lisbon strategy.</p>
    <p>S-NMT &lt;UNK&gt; is the objectives of the lisbon strategy. +Src Mem the millennium development goals are fulfilling the</p>
    <p>millennium goals of the lisbon strategy. +Trg Mem in writing. - (ro) the lisbon strategy is fulfilling the</p>
    <p>objectives of the lisbon strategy. +Both Mems qimonda fulfils the aims of the lisbon strategy.</p>
    <p>[Wang et al., 2017] &lt;UNK&gt; fulfils the objectives of the lisbon strategy.</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Example translation</p>
    <p>Source qimonda taidab lissaboni strateegia eesmarke. Target qimonda meets the objectives of the lisbon strategy.</p>
    <p>S-NMT &lt;UNK&gt; is the objectives of the lisbon strategy. +Src Mem the millennium development goals are fulfilling the</p>
    <p>millennium goals of the lisbon strategy. +Trg Mem in writing. - (ro) the lisbon strategy is fulfilling the</p>
    <p>objectives of the lisbon strategy. +Both Mems qimonda fulfils the aims of the lisbon strategy.</p>
    <p>[Wang et al., 2017] &lt;UNK&gt; fulfils the objectives of the lisbon strategy.</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Example translation</p>
    <p>Source qimonda taidab lissaboni strateegia eesmarke. Target qimonda meets the objectives of the lisbon strategy.</p>
    <p>S-NMT &lt;UNK&gt; is the objectives of the lisbon strategy. +Src Mem the millennium development goals are fulfilling the</p>
    <p>millennium goals of the lisbon strategy. +Trg Mem in writing. - (ro) the lisbon strategy is fulfilling the</p>
    <p>objectives of the lisbon strategy. +Both Mems qimonda fulfils the aims of the lisbon strategy.</p>
    <p>[Wang et al., 2017] &lt;UNK&gt; fulfils the objectives of the lisbon strategy.</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Example translation</p>
    <p>Source qimonda taidab lissaboni strateegia eesmarke. Target qimonda meets the objectives of the lisbon strategy.</p>
    <p>S-NMT &lt;UNK&gt; is the objectives of the lisbon strategy. +Src Mem the millennium development goals are fulfilling the</p>
    <p>millennium goals of the lisbon strategy. +Trg Mem in writing. - (ro) the lisbon strategy is fulfilling the</p>
    <p>objectives of the lisbon strategy. +Both Mems qimonda fulfils the aims of the lisbon strategy.</p>
    <p>[Wang et al., 2017] &lt;UNK&gt; fulfils the objectives of the lisbon strategy.</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Example translation (contd.)</p>
    <p>Source ... et riigis kehtib endiselt lukasenka diktatuur, mis rikub inim- ning etnilise vahemuse oigusi.</p>
    <p>Target ... this country is still under the dictatorship of lukashenko, breaching human rights and the rights of ethnic minorities.</p>
    <p>S-NMT ... the country still remains in a position of lukashenko to violate human rights and ethnic minorities.</p>
    <p>+Src Mem ... the country still applies to the brutal dictatorship of human and ethnic minority rights.</p>
    <p>+Trg Mem ... the country still keeps the &lt;UNK&gt; dictatorship that violates human rights and ethnic rights.</p>
    <p>+Both Mems ... the country still persists in lukashenkos dictatorship that violate human rights and ethnic minority rights.</p>
    <p>[Wang et al., 2017] ... there is still a regime in the country that is violating the rights of human and ethnic minority in the country.</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Example translation (contd.)</p>
    <p>Source ... et riigis kehtib endiselt lukasenka diktatuur, mis rikub inim- ning etnilise vahemuse oigusi.</p>
    <p>Target ... this country is still under the dictatorship of lukashenko, breaching human rights and the rights of ethnic minorities.</p>
    <p>S-NMT ... the country still remains in a position of lukashenko to violate human rights and ethnic minorities.</p>
    <p>+Src Mem ... the country still applies to the brutal dictatorship of human and ethnic minority rights.</p>
    <p>+Trg Mem ... the country still keeps the &lt;UNK&gt; dictatorship that violates human rights and ethnic rights.</p>
    <p>+Both Mems ... the country still persists in lukashenkos dictatorship that violate human rights and ethnic minority rights.</p>
    <p>[Wang et al., 2017] ... there is still a regime in the country that is violating the rights of human and ethnic minority in the country.</p>
  </div>
  <div class="page">
    <p>Experiments and Analysis</p>
    <p>Example translation (contd.)</p>
    <p>Source ... et riigis kehtib endiselt lukasenka diktatuur, mis rikub inim- ning etnilise vahemuse oigusi.</p>
    <p>Target ... this country is still under the dictatorship of lukashenko, breaching human rights and the rights of ethnic minorities.</p>
    <p>S-NMT ... the country still remains in a position of lukashenko to violate human rights and ethnic minorities.</p>
    <p>+Src Mem ... the country still applies to the brutal dictatorship of human and ethnic minority rights.</p>
    <p>+Trg Mem ... the country still keeps the &lt;UNK&gt; dictatorship that violates human rights and ethnic rights.</p>
    <p>+Both Mems ... the country still persists in lukashenkos dictatorship that violate human rights and ethnic minority rights.</p>
    <p>[Wang et al., 2017] ... there is still a regime in the country that is violating the rights of human and ethnic minority in the country.</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Overview</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Conclusion</p>
    <p>Proposed a model which incorporates the global source and target document contexts</p>
    <p>Proposed effective training and decoding methodologies for our model</p>
    <p>Future Work: Investigate document-context NMT models which incorporate specific discourse-level phenomena</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Conclusion</p>
    <p>Proposed a model which incorporates the global source and target document contexts</p>
    <p>Proposed effective training and decoding methodologies for our model</p>
    <p>Future Work: Investigate document-context NMT models which incorporate specific discourse-level phenomena</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Conclusion</p>
    <p>Proposed a model which incorporates the global source and target document contexts</p>
    <p>Proposed effective training and decoding methodologies for our model</p>
    <p>Future Work: Investigate document-context NMT models which incorporate specific discourse-level phenomena</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Conclusion</p>
    <p>Proposed a model which incorporates the global source and target document contexts</p>
    <p>Proposed effective training and decoding methodologies for our model</p>
    <p>Future Work: Investigate document-context NMT models which incorporate specific discourse-level phenomena</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Conclusion</p>
    <p>Proposed a model which incorporates the global source and target document contexts</p>
    <p>Proposed effective training and decoding methodologies for our model</p>
    <p>Future Work: Investigate document-context NMT models which incorporate specific discourse-level phenomena</p>
  </div>
  <div class="page">
    <p>References</p>
    <p>Overview</p>
  </div>
  <div class="page">
    <p>References</p>
    <p>References I</p>
    <p>Hardmeier C. and Federico, M. (2010).</p>
    <p>Modelling pronominal anaphora in statistical machine translation. International Workshop on Spoken Language Translation.</p>
    <p>Gong Z. and Zhang M. and Zhou G. (2011).</p>
    <p>Cache-based document-level statistical machine translation. Proceedings of the Conference on Empirical Methods in Natural Language Processing.</p>
    <p>Garcia E. M. and Espana-Bonet C. and Marquez L. (2014).</p>
    <p>Document-level machine translation as a re-translation process. Procesamiento del Lenguaje Natural, 53:103110..</p>
    <p>Jean, S. and Lauly, L. and Firat, O. and Cho, K. (2017).</p>
    <p>Does Neural Machine Translation Benefit from Larger Context? arXiv:1704.05135.</p>
    <p>Wang, L. and Tu, Z. and Way, A. and Liu, Q. (2017).</p>
    <p>Exploiting Cross-Sentence Context for Neural Machine Translation. Proceedings of the Conference on Empirical Methods in Natural Language Processing.</p>
    <p>Bawden, R. and Sennrich, R. and Birch, A. and Haddow, B. (2018).</p>
    <p>Evaluating Discourse Phenomena in Neural Machine Translation. Proceedings of the NAACL-HLT 2018.</p>
  </div>
</Presentation>
