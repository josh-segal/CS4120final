<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Adaptive Knowledge Sharing in Multi-Task Learning: Improving Low-Resource Neural Machine Translation</p>
    <p>Poorya ZareMoodi, Wray Buntine, Gholamreza (Reza) Haffari</p>
    <p>Monash University</p>
    <p>Slides:</p>
  </div>
  <div class="page">
    <p>Roadmap</p>
    <p>Introduction &amp; background</p>
    <p>Adaptive knowledge sharing in Multi-Task Learning  Experiments &amp; analysis  Conclusion</p>
    <p>!2</p>
  </div>
  <div class="page">
    <p>Improving NMT in low-Resource scenarios</p>
    <p>NMT is notorious!</p>
    <p>Bilingually low-resource scenario: large amounts of bilingual training data is not available</p>
    <p>IDEA: Use existing resources from other tasks and train one model for all tasks using multi-task learning</p>
    <p>This effectively injects inductive biases to help improving the generalisation of NMT</p>
    <p>Auxiliary tasks: Semantic Parsing, Syntactic Parsing, Named Entity Recognition</p>
    <p>!3</p>
  </div>
  <div class="page">
    <p>Encoders-Decoders for Individual Tasks !4</p>
    <p>Encoder Decoder</p>
    <p>Machine Translation</p>
    <p>Encoder Decoder</p>
    <p>Semantic Parsing</p>
    <p>Encoder Decoder</p>
    <p>Syntactic Parsing</p>
    <p>Encoder Decoder</p>
    <p>Named-Entity Recognition</p>
    <p>I went home</p>
    <p>S</p>
    <p>NP</p>
    <p>DT the</p>
    <p>N bur gla r</p>
    <p>VP</p>
    <p>V rob bed</p>
    <p>NP</p>
    <p>DT the</p>
    <p>N</p>
    <p>apa rtm ent</p>
    <p>No un Phr ase s(N</p>
    <p>P): th ebu</p>
    <p>rgla r, th eap</p>
    <p>artm ent</p>
    <p>Ver bP hra ses (VP</p>
    <p>): ro bbe dth eap</p>
    <p>artm ent</p>
    <p>Sen ten ces (S) :</p>
    <p>th ebu</p>
    <p>rgla rro bbe dth eap</p>
    <p>artm ent</p>
    <p>Obama was elected and his voter celebrated</p>
    <p>The burglar robbed the apartment</p>
    <p>Jim bought 300 shares of Acme Corp. in 2006</p>
    <p>B-PER 0 0 0 0 B-ORG I-ORG 0 B-MISC</p>
  </div>
  <div class="page">
    <p>Sharing Scenario !5</p>
    <p>Multitask seq2seq</p>
    <p>translation</p>
    <p>Named-entities</p>
    <p>Parse tree</p>
    <p>Semantic graph</p>
    <p>sentence</p>
    <p>task tag</p>
    <p>Encoder DecoderMachine Translation</p>
    <p>Encoder Decoder</p>
    <p>Encoder DecoderSyntactic Parsing</p>
    <p>Encoder DecoderNamed-Entity Recognition</p>
    <p>Semantic Parsing</p>
  </div>
  <div class="page">
    <p>h5</p>
    <p>Partial Parameter Sharing !6</p>
    <p>h2h1</p>
    <p>I went</p>
    <p>h4h3</p>
    <p>home &lt;EOS&gt;</p>
    <p>h2h1 h4h3</p>
    <p>h2h1 h4h3</p>
    <p>g1 g2 g3</p>
    <p>g1 g2 g3</p>
    <p>g1 g2 g3</p>
    <p>g4</p>
    <p>g4</p>
    <p>g4</p>
    <p>(1) (1) (1) (1)</p>
    <p>(2) (2) (2) (2)</p>
    <p>(3) (3) (3) (3)</p>
    <p>sh a</p>
    <p>re d</p>
    <p>g5</p>
    <p>g5</p>
    <p>g5</p>
    <p>&lt;EOS&gt;</p>
    <p>(1) (1) (1) (1) (1)</p>
    <p>(2) (2) (2) (2) (2)</p>
    <p>(3) (3) (3) (3) (3)</p>
    <p>C o</p>
    <p>nt e</p>
    <p>xt</p>
    <p>sh a</p>
    <p>re d</p>
    <p>Encoder Decoder &lt;translation&gt; I went home</p>
    <p>Zaremoodi &amp; Haffari, NAACL, 2018</p>
    <p>h5</p>
    <p>h5</p>
    <p>(1)</p>
    <p>(2)</p>
    <p>(3)</p>
    <p>&lt;translation&gt;</p>
    <p>Ta sk</p>
    <p>int erf</p>
    <p>ere nc</p>
    <p>e</p>
  </div>
  <div class="page">
    <p>Roadmap</p>
    <p>Introduction &amp; Background  Adaptive knowledge sharing in Multi-Task Learning</p>
    <p>Experiments &amp; analysis  Conclusion</p>
    <p>!7</p>
  </div>
  <div class="page">
    <p>Adaptive Knowledge Sharing in MTL</p>
    <p>!Sharing the parameters of the recurrent units among all tasks ! Task interference</p>
    <p>! Inability to leverage commonalities among subsets of tasks</p>
    <p>!IDEA ! Multiple experts in handling different kinds of information ! Adaptively share experts among the tasks</p>
    <p>!8</p>
    <p>sharing the knowledge for controlling the information flow in the hidden states</p>
  </div>
  <div class="page">
    <p>Adaptive Knowledge Sharing in MTL</p>
    <p>!IDEA ! Multiple experts in handling different kinds of information ! Adaptively share experts among the tasks ! Extend the recurrent units with multiple blocks</p>
    <p>! each block has its own information flow through the time ! Routing mechanism: to softly direct the input to these blocks</p>
    <p>!9</p>
    <p>Task Block</p>
  </div>
  <div class="page">
    <p>Adaptive Knowledge Sharing !10</p>
    <p>Routing:</p>
    <p>Blocks:</p>
    <p>Task Block</p>
    <p>!!</p>
  </div>
  <div class="page">
    <p>Adaptive Knowledge Sharing !11</p>
    <p>h3h2</p>
    <p>I went</p>
    <p>h5h4</p>
    <p>home &lt;EOS&gt;</p>
    <p>g1 g2 g3 g4</p>
    <p>(1) (1) (1) (1) g5</p>
    <p>&lt;EOS&gt;</p>
    <p>(1) (1) (1) (1) (1)</p>
    <p>C o</p>
    <p>nt e</p>
    <p>xt</p>
    <p>h1 (1)</p>
    <p>&lt;translation&gt;</p>
    <p>We use the proposed recurrent unit inside encoder and decoder.</p>
    <p>Task Block</p>
    <p>!!</p>
    <p>Task Block</p>
    <p>!!</p>
  </div>
  <div class="page">
    <p>Roadmap</p>
    <p>Introduction &amp; background  Adaptive knowledge sharing in Multi-Task Learning  Experiments &amp; analysis</p>
    <p>Conclusion</p>
    <p>!12</p>
  </div>
  <div class="page">
    <p>Experiments</p>
    <p>Language Pairs: English to Farsi/Vietnamese</p>
    <p>Datasets:  English to Farsi: TED corpus &amp; LDC2016E93  English to Vietnamese: IWSLT 2015 (TED and TEDX talks)  Semantic parsing: AMR corpus(newswire, weblogs, web discussion forums and broadcast</p>
    <p>conversations)  Syntactic parsing: Penn Treebank  NER: CONLL NER Corpus (newswire articles from the Reuters Corpus)</p>
    <p>NMT Architecture: GRU for blocks, 400 RNN hidden states and word embedding</p>
    <p>NMT best practice:  Optimisation: Adam  Byte Pair Encoding (BPE) on both source/target  Evaluation metrics: PPL, TER and BLEU</p>
    <p>!13</p>
  </div>
  <div class="page">
    <p>Experiments !14</p>
    <p>English  Farsi English  Vietnamese</p>
    <p>BL EU</p>
  </div>
  <div class="page">
    <p>Experiments (English to Farsi)</p>
    <p>! Average block usage. ! Blocks specialisation: Block 1: MT, Semantic Parsing, Block 2: Syntactic/Semantic</p>
    <p>Parsing, Block 3: NER</p>
    <p>!15</p>
    <p>Block 1 Block 2 Block 3</p>
    <p>MT Semantic Syntactic NER</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>! Address the task interference issue in MTL ! extending the recurrent units with multiple blocks ! with a trainable routing network</p>
    <p>!16</p>
  </div>
  <div class="page">
    <p>!17</p>
    <p>Questions?</p>
    <p>Paper:</p>
  </div>
</Presentation>
