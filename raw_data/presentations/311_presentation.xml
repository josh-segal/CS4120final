<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Isolated virtualised clusters:</p>
    <p>Testbeds for high-risk security experimentation and training</p>
    <p>Jos M. Fernandez (*) cole Polytechnique de Montral</p>
    <p>Information Systems Security Research Lab (Laboratoire SecSI)</p>
    <p>CSET Workshop - Washington, DC, August 2010 1</p>
    <p>(*) Joint work with: - Carlton Davis, Pier-Luc St-Onge  Lab SecSI, Montral, Canada - Joan Calvet, Wadie Guizani, Mathieu Kaczmarek, Jean-Yves Marion  LORIA, Nancy, France</p>
  </div>
  <div class="page">
    <p>ISSNet 2010 Workshop 2</p>
    <p>Agenda</p>
    <p>The Problem and the Objective  The History  The Design Criteria  Architecture Description  The Accomplishments  Lessons Learned  Future Work</p>
  </div>
  <div class="page">
    <p>Definition(s)</p>
    <p>CSET =</p>
    <p>Computer Security Experimentation Testbed</p>
  </div>
  <div class="page">
    <p>Summary of Contributions</p>
    <p>Isolated virtualised clusters</p>
    <p>experiments  In-lab Botnet re-creation (3000 bots)  In-lab training of security grad students</p>
  </div>
  <div class="page">
    <p>Why a CSET ?</p>
    <p>Trying to bring some of the benefits of the scientific method to Computer Security R&amp;D</p>
    <p>In particular 1. Experimental Control 2. Repeatability 3. Realism</p>
    <p>In contrast with  Mathematical modelling and simulation  Field experimentation</p>
  </div>
  <div class="page">
    <p>Desiderata and challenges of a CSET</p>
    <p>From CSET Workshop CFP  Scale  Multi-party Nature  Risk  Realism  Rigor  Setup/Scenario Complexity</p>
  </div>
  <div class="page">
    <p>Risks of CS R&amp;D and CSET  Confidentiality</p>
    <p>Privacy of data (e.g. network traces)  Details of real system configurations  Security product design features  High-impact vulnerability information  Dual-use tools and technology (e.g. malware)</p>
    <p>Integrity and Availability  Effect on outside systems</p>
    <p>University computing facilities  Internet</p>
  </div>
  <div class="page">
    <p>The SecSI/LORIA Story Lab SecSI</p>
    <p>cole Polytechnique, Montral  2005</p>
    <p>Initial design and grant proposal to Canadian Foundation for Innovation (CFI)</p>
    <p>2006</p>
    <p>CFI Grant approved: 1.2 M$</p>
    <p>2007-2008</p>
    <p>Construction and eqpt acquisition</p>
    <p>2009</p>
    <p>Tool comparative analysis &amp; configuration</p>
    <p>Initial experiments</p>
    <p>First student projects</p>
    <p>2010</p>
    <p>First large scale experiments</p>
    <p>Graduate course taught on testbed</p>
    <p>Laboratoire Haute Scurit</p>
    <p>INPL/LORIA, Nancy, France</p>
    <p>2007</p>
    <p>LORIA and regional government support for LHS</p>
    <p>2008</p>
    <p>Collaboration starts with Lab SecSI</p>
    <p>2009</p>
    <p>Eqpt acquisition &amp; config</p>
    <p>2010</p>
    <p>Official launch 1 July</p>
  </div>
  <div class="page">
    <p>Risk Management Measures</p>
    <p>Onion model  Separate access control &amp; video surveillance</p>
    <p>Strong logical security  Air gap whenever possible</p>
    <p>Personnel security</p>
  </div>
  <div class="page">
    <p>Risk Management Measures</p>
    <p>related risks  Tasks</p>
    <p>Evaluates risk  Examines benefits of research against risks.  Examines and vets counter-measures and project</p>
    <p>Includes external members and experts  Not imposed by research granting-agencies</p>
  </div>
  <div class="page">
    <p>CSET design criteria In order to achieve</p>
    <p>overarching goals of  Realism  Scale  Flexibility</p>
    <p>We defined the following criteria</p>
  </div>
  <div class="page">
    <p>Isolated Virtualised Clusters</p>
    <p>Isolated  Research programme required high-risk experiments</p>
    <p>Lack of control on typical network-layer isolation measures</p>
    <p>Tried to follow model of Government of Canada security policy and IS security policy</p>
    <p>Virtualisation  Scale, scale, scale !!</p>
    <p>Emulated machine typically does not require much CPU  Test conducted showed typical machine could support 50-100 VM</p>
    <p>Built-in manageability and portability</p>
    <p>Challenges/questions  VM/host isolation  Versatility  Cost</p>
  </div>
  <div class="page">
    <p>Network Architecture</p>
  </div>
  <div class="page">
    <p>Baby &amp; Mumma Cluster</p>
    <p>Baby  14 machines  Used for</p>
    <p>Student training  Experiment development  Low-risk experiments  Experiments requiring network connectivity  Very high-risk experiments (before and after sanitisation)</p>
    <p>Increasing Mummas firepower</p>
    <p>Mumma  98 machines  Used for at-scale experiments  Always isolated  Can be partitioned (air gap) for conducting simultaneous experiments</p>
    <p>Supporting infrastructure  Adjacent console room  12 Tb file server</p>
  </div>
  <div class="page">
    <p>Management tools</p>
    <p>Considered two options: DETER and xCAT  xCAT</p>
    <p>eXtreme Cluster Administration Tool  Open-source, initially developed/supported by IBM  VMWare ESX support initially custom-developed,</p>
    <p>now mainstream  Allows deployment and management of VM as if</p>
    <p>they were real nodes  Allows high-level design with VM as design element</p>
    <p>(higher granularity)</p>
  </div>
  <div class="page">
    <p>Design methodology  Higher level design</p>
    <p>Deployment  Run xCat scripts  deploys and configures all VMs in a few hours</p>
    <p>Network configuration  No ability to generate switch configuration (yet)  Manual network configuration (patch panel/switch)</p>
    <p>Measurement &amp; Monitoring  Custom monitoring/measurement application run on VM  Network traffic sniffing  VM management tools</p>
  </div>
  <div class="page">
    <p>Achievements - SecSI 1. DDoS experiment</p>
    <p>Study of DoS resilience of various SMTP servers  50 machines, run on-the-metal</p>
    <p>(IDS &amp; concept botnet)</p>
  </div>
  <div class="page">
    <p>Lessons Learned  There is a lot to learn from high-scale, high-risk</p>
    <p>experiments in isolated testbeds . (Wow!)  It cannot be learnt by other methods</p>
    <p>(e.g. in-the-wild experiments)  It is less risky</p>
    <p>Disadvantages  Access by researchers complicated  Experiment design and testing more arduous  baby cluster not a luxury</p>
  </div>
  <div class="page">
    <p>Lessons Learned</p>
    <p>Virtualisation  Larger scale, more flexibility  Deployment and monitoring not supported by all</p>
    <p>toolkits (e.g. DETER)  Some experiments still need to be run on-the-metal</p>
    <p>(synchronisation)</p>
  </div>
  <div class="page">
    <p>Achieving CSET design criteria 1. Versatility 2. Synchronisation ??? 3. Soundness 4. Transparency ??? 5. Environment 6. Background 7. High-level Exp. Design 8. Deployability 9. Manageability 10. Portability 11. Sterilisability ???</p>
  </div>
  <div class="page">
    <p>Future Work 1. Investigate/manage risk of VM containment failure 2. High-level design</p>
    <p>More intuitive tools (vs. Perl scripts)  Granularity to the process/programme</p>
    <p>(a la DETER)</p>
  </div>
</Presentation>
