<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>A Low Power Front-End for Embedded Processors Using a Block-Aware Instruction Set</p>
    <p>Ahmad ZmilyAhmad Zmily</p>
    <p>Computer System Lab Stanford University</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Processor front-end engine</p>
    <p>Performs control flow prediction &amp; instruction fetch</p>
    <p>Sets upper limit for performance</p>
    <p>Cannot execute faster than you can fetch</p>
    <p>Energy and Power efficiency</p>
    <p>Determines battery life-time</p>
    <p>Cost of cooling and packaging</p>
    <p>Cost of cooling and packaging</p>
    <p>Front-end consumes significant budget of total power</p>
    <p>Large memory arrays accessed nearly every cycle</p>
    <p>Instruction cache, predictors, BTB</p>
    <p>Arrays are sized to achieve good overall performance</p>
    <p>Reduce the size of the front-end structures?</p>
  </div>
  <div class="page">
    <p>The Problem</p>
    <p>Xscale with small front-end structures  16% decrease in total processor power</p>
    <p>The cost for MediaBench programs  12% performance loss</p>
    <p>Base with regular I-Cache and BTB Base with small I-Cache and BTB</p>
    <p>Execution Time Total Power Total Energy</p>
  </div>
  <div class="page">
    <p>BLISS</p>
    <p>Focus of this paper  Low-power using small front-end structures</p>
    <p>Eliminate performance degradation through optimizations</p>
    <p>A block-aware instruction set architecture (BLISS)  Decouples control-flow prediction from instruction fetching</p>
    <p>Allows software to help with hardware challenges</p>
    <p>Talk outline  BLISS Overview</p>
    <p>Front-End Optimizations</p>
    <p>Tools and Methodology</p>
    <p>Evaluation for Embedded Processors</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Block-Aware Instruction Set</p>
    <p>BLISS = Block-aware Instruction Set</p>
    <p>Instructions Instructions</p>
    <p>Block Descriptors</p>
    <p>Conventional ISA BLISS ISA</p>
    <p>Text Segment</p>
    <p>Explicit basic block descriptors (BBDs)  Stored separately from instructions in the text segment</p>
    <p>Describe control flow and identify associated instructions</p>
    <p>Execution model  PC always points to a BBD, not to instructions</p>
  </div>
  <div class="page">
    <p>Type: type of terminating control-flow instruction  Fall-through, jump, jump register, branch, call, return</p>
    <p>Offset: displacement for PC-relative branches and jumps  Offset to target basic block descriptor</p>
    <p>Hints</p>
    <p>Length</p>
    <p>Offset</p>
    <p>Type</p>
    <p>Instruction Pointer</p>
    <p>Length: number of instruction in the basic block  0 to 15 instructions</p>
    <p>Instruction pointer: address of the first instruction in the block  Remaining bits from TLB</p>
    <p>Hints: optional compiler-generated hints</p>
  </div>
  <div class="page">
    <p>BLISS Code Example</p>
    <p>numeqz=0;</p>
    <p>for (i=0; i&lt;N; i++)</p>
    <p>if (a[i]==0) numeqz++;</p>
    <p>Example program in C-source code:  Counts the number of zeros in array a</p>
    <p>Calls foo() for each non-zero element</p>
    <p>else foo();</p>
  </div>
  <div class="page">
    <p>BLISS Code Example</p>
    <p>addu r4,r0,r0</p>
    <p>lw r6,0(r1)</p>
    <p>bneqz r6,L2</p>
    <p>j L3</p>
    <p>L1:</p>
    <p>addui r4,r4,1</p>
    <p>BBD1: FT , --- , 1</p>
    <p>BBD2: B_F , BBD4, 2</p>
    <p>BBD3: J, BBD5, 1</p>
    <p>BBD4: JAL, FOO, 0</p>
    <p>jal FOO</p>
    <p>addui r1,r1,4</p>
    <p>bneq r1,r2,L1</p>
    <p>L2:</p>
    <p>L3:</p>
    <p>BBD4: JAL, FOO, 0</p>
    <p>BBD5: B_B, BBD2, 2</p>
    <p>All jump instructions are redundant</p>
    <p>Several branches can be folded in arithmetic instructions</p>
    <p>Branch offset is encoded in descriptors</p>
  </div>
  <div class="page">
    <p>BLISS Decoupled Front-End</p>
    <p>Schedule</p>
    <p>&amp;</p>
    <p>Execute</p>
    <p>I-Cache</p>
    <p>Pipelined</p>
    <p>D e c o d e</p>
    <p>BB-Cache</p>
    <p>Hybrid</p>
    <p>Predictor</p>
    <p>P C</p>
    <p>branch type</p>
    <p>&lt;basic block&gt;</p>
    <p>mispredicted branch target</p>
    <p>m is</p>
    <p>s</p>
    <p>BBQ IQ</p>
    <p>p re</p>
    <p>fe tc</p>
    <p>h</p>
    <p>BB-cache misses</p>
    <p>Basic-Block queue</p>
    <p>decouples prediction</p>
    <p>from instruction cache</p>
    <p>Basic Block</p>
    <p>Descriptor cache</p>
    <p>replaces BTB</p>
    <p>RAS</p>
    <p>call return target</p>
    <p>basic block target L2 Cache</p>
    <p>ic a c h e</p>
    <p>m</p>
    <p>D-Cache</p>
    <p>BB-cache Entry Format</p>
    <p>tag length</p>
    <p>(4b)</p>
    <p>type</p>
    <p>(4b)</p>
    <p>target</p>
    <p>(30b)</p>
    <p>hints</p>
    <p>(2b)</p>
    <p>Ic a c h eBB-cache misses</p>
    <p>instr. pointer</p>
    <p>(13b)</p>
    <p>bimod</p>
    <p>(2b)</p>
  </div>
  <div class="page">
    <p>Agenda</p>
    <p>Motivation</p>
    <p>BLISS Overview</p>
    <p>Front-End Optimizations</p>
    <p>Tools and Methodology</p>
    <p>Evaluation for Embedded Processors</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Instruction Reordering  Idea: Reorder blocks to improve hit rate and utilization</p>
    <p>Lay out closely executed blocks in chains using profiling</p>
    <p>Adjust instruction pointer in block descriptor</p>
  </div>
  <div class="page">
    <p>Instruction Reordering</p>
    <p>add r3,r2,r8</p>
    <p>addu r4,0,r6</p>
    <p>lw r6,128(r30)</p>
    <p>BBD1: B_F , BBD4, 2</p>
    <p>BBD2: B_F, BBDy, 3</p>
    <p>BBD3: J, BBDx, 2</p>
    <p>L1:</p>
    <p>bne L2 r3,r12</p>
    <p>beq L6 r4, r9</p>
    <p>Idea: Reorder blocks to improve hit rate and utilization</p>
    <p>Lay out closely executed blocks in chains using profiling</p>
    <p>Adjust instruction pointer in block descriptor</p>
    <p>addiu r17,r0,1L2:</p>
    <p>beq L6 r4, r9</p>
    <p>add r3,r2,r8</p>
    <p>add bne lw addu</p>
    <p>jal addiu add</p>
    <p>Instruction Cache</p>
  </div>
  <div class="page">
    <p>Instruction Prefetching</p>
    <p>branch type</p>
    <p>mispredicted branch target</p>
    <p>BBQ decouples prediction from instruction fetching  Predictor runs ahead even when IQ full or I-cache miss</p>
    <p>Stalls only on BB-cache miss or BBQ</p>
    <p>Schedule</p>
    <p>&amp;</p>
    <p>Execute</p>
    <p>I-Cache</p>
    <p>Pipelined</p>
    <p>D e c o d e</p>
    <p>BB-Cache</p>
    <p>RAS</p>
    <p>Hybrid</p>
    <p>Predictor</p>
    <p>P C</p>
    <p>call return target</p>
    <p>basic block target</p>
    <p>&lt;basic block&gt;</p>
    <p>L2 Cache ic a c h e</p>
    <p>m is</p>
    <p>s</p>
    <p>BBQ IQ</p>
    <p>D-Cache Ic a c h e</p>
    <p>p re</p>
    <p>fe tc</p>
    <p>h BB-cache misses</p>
  </div>
  <div class="page">
    <p>Instruction Prefetching</p>
    <p>branch type</p>
    <p>mispredicted branch target</p>
    <p>BBQ provides early view into instruction stream  Guided instruction prefetch</p>
    <p>I-cache misses can be tolerated</p>
    <p>Schedule</p>
    <p>&amp;</p>
    <p>Execute</p>
    <p>I-Cache</p>
    <p>Pipelined</p>
    <p>D e c o d e</p>
    <p>BB-Cache</p>
    <p>RAS</p>
    <p>Hybrid</p>
    <p>Predictor</p>
    <p>P C</p>
    <p>call return target</p>
    <p>basic block target</p>
    <p>&lt;basic block&gt;</p>
    <p>L2 Cache ic a c h e</p>
    <p>m is</p>
    <p>s</p>
    <p>BBQ IQ</p>
    <p>D-Cache Ic a c h e</p>
    <p>p re</p>
    <p>fe tc</p>
    <p>h BB-cache misses</p>
  </div>
  <div class="page">
    <p>Instruction Prefetching</p>
    <p>branch type</p>
    <p>mispredicted branch target</p>
    <p>Prefetches initiated for potential misses  Prop the cache when read port is idle</p>
    <p>Prefetched data in a buffer to avoid cache pollution  Pushed into the I-cache after first access</p>
    <p>Schedule</p>
    <p>&amp;</p>
    <p>Execute</p>
    <p>I-Cache</p>
    <p>Pipelined</p>
    <p>D e c o d e</p>
    <p>BB-Cache</p>
    <p>RAS</p>
    <p>Hybrid</p>
    <p>Predictor</p>
    <p>P C</p>
    <p>call return target</p>
    <p>basic block target</p>
    <p>&lt;basic block&gt;</p>
    <p>L2 Cache ic a c h e</p>
    <p>m is</p>
    <p>s</p>
    <p>BBQ IQ</p>
    <p>D-Cache Ic a c h e</p>
    <p>p re</p>
    <p>fe tc</p>
    <p>h BB-cache misses</p>
  </div>
  <div class="page">
    <p>Unified Instruction Cache and BTB</p>
    <p>Programs exhibit different behavior  Susceptible to I-cache organization and size (e.g. rasta)</p>
    <p>Susceptible to BTB organization and size (e.g. adpcm)</p>
    <p>A unified I-cache and BB-cache  Cache line has either BBDs or regular instructions</p>
    <p>Single port accessed by BBD fetch or instruction fetch  Instruction fetch returns multiple instructions per cycle</p>
    <p>Instruction fetch returns multiple instructions per cycle</p>
    <p>Difficult with a conventional front-end  Same PC used to access I-cache &amp; BTB</p>
    <p>More conflict misses</p>
    <p>Need to store extra information to differentiate the two types</p>
    <p>Sharing single port is difficult  Basic-Block Boundaries are not known before decoding</p>
  </div>
  <div class="page">
    <p>Tagless Instruction Cache  Idea: exploit tag checks on descriptor accesses</p>
    <p>Improves I-cache access time, energy, and area</p>
  </div>
  <div class="page">
    <p>Tagless Instruction Cache  Idea: exploit tag checks on descriptor accesses</p>
    <p>Improves I-cache access time, energy, and area</p>
  </div>
  <div class="page">
    <p>Cache Hints  General mechanism to attach compiler generated hints</p>
    <p>Basic-Block granularity</p>
    <p>No effect on instruction footprint</p>
    <p>Cache placement hints  At what cache level it is profitable to place data</p>
    <p>Hints</p>
    <p>Length</p>
    <p>Offset</p>
    <p>Type</p>
    <p>Instruction Pointer</p>
    <p>At what cache level it is profitable to place data</p>
    <p>Heuristic: exclude infrequent and/or high mis-rates blocks</p>
    <p>Cache redistribute hints  Hints used as part of the cache index</p>
    <p>PC HintsTag Index Offset</p>
  </div>
  <div class="page">
    <p>Agenda</p>
    <p>Motivation</p>
    <p>BLISS Overview</p>
    <p>Front-End Optimizations</p>
    <p>Tools and Methodology</p>
    <p>Evaluation for Embedded Processors</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Evaluation Methodology</p>
    <p>Intel XScale PXA270 processor  Single issue in-order execution</p>
    <p>Simulated with Simplescalar &amp; Wattch toolsets</p>
    <p>MediaBench benchmark suite</p>
    <p>BLISS code generation  Static binary translation from MIPS executables</p>
    <p>Static binary translation from MIPS executables</p>
    <p>Front-end optimizations performed during translation</p>
    <p>Instruction Reordering  Pettis and Hansen block-level positioning</p>
  </div>
  <div class="page">
    <p>Agenda</p>
    <p>Motivation</p>
    <p>BLISS Overview</p>
    <p>Front-End Optimizations</p>
    <p>Tools and Methodology</p>
    <p>Evaluation for Embedded Processors</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Performance Analysis</p>
    <p>N o r m a li z e d I P C</p>
    <p>Instruction Prefetching &amp; Reordering  consistent performance</p>
    <p>Unified I-cache and BTB  for programs stressing BTB</p>
    <p>Tagless I-cache  for programs with BB size of 4 instructions</p>
    <p>Cache hints  consistent performance</p>
    <p>g721 jpeg pegwit crafty vortex Average</p>
    <p>N o r m a li z e d I P C</p>
  </div>
  <div class="page">
    <p>Total Energy Analysis</p>
    <p>N o r m a li z e d T o ta l E n e r g y</p>
    <p>Tagless I-cache achieves lowest energy  Except for vortex due to its large BBs</p>
    <p>Combination leads to 19% total energy savings over base</p>
    <p>g721 jpeg pegwit crafty vortex Average</p>
  </div>
  <div class="page">
    <p>BLISS Vs. Filter Cache</p>
    <p>Execution Time Total Power Total Energy</p>
    <p>Base with regular I-Cache and BTB Base with Filter Cache and optimizations</p>
    <p>BLISS with small caches and optimizations</p>
    <p>Filter cache (tiny cache) proposed by kin et al.  Using similar optimizations</p>
    <p>BLISS achieves similar power reduction with  9% performance improvement</p>
    <p>19% total energy improvement</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>BLISS: a block-aware instruction set  Block descriptors separate from instructions</p>
    <p>Expressive ISA to communicate software info and hints</p>
    <p>Enabled front-end optimizations  Efficient instruction reordering</p>
    <p>Accurate instruction prefetching</p>
    <p>General mechanism to implement cache hints</p>
    <p>General mechanism to implement cache hints</p>
    <p>Unified instruction cache and BTB</p>
    <p>Tagless instruction cache</p>
    <p>Result: Low-Power + Performance + Energy  9% performance improvement</p>
    <p>16% total power improvement</p>
    <p>19% total energy improvement</p>
  </div>
  <div class="page">
    <p>Questions?</p>
  </div>
  <div class="page">
    <p>Microarchitecture parameters</p>
    <p>XScale PXA270</p>
    <p>Base BLISS</p>
    <p>Fetch Width 1 inst/cycle 1 BB/cycle</p>
    <p>Regular BTB 64-entry, 4-way 64-set, 4-way</p>
    <p>Small BTB 16-entry, 2-way 16-set, 4-way</p>
    <p>Regular I-cache 32 KBytes, 32-way, 32B Blocks, 2-cycle access</p>
    <p>Small I-cache 2 KBytes, 2-way, 32B Blocks, 2-cycle access</p>
    <p>BBQ  4 entries</p>
    <p>Execution single-issue, in-order with 1 INT &amp; 1 FP unit</p>
    <p>Predictor 256-entry bimod with 8 entry RAS</p>
    <p>IQ/RUU/LSQ 16/32/32 entries</p>
    <p>D-cache 32 KBytes, 4-way, 32B blocks, 1 port, 2-cycle access</p>
    <p>L2-cache 128 KBytes, 4-way, 64B blocks, 1 port, 5-cycle access</p>
    <p>Main memory 30-cycle access</p>
  </div>
</Presentation>
