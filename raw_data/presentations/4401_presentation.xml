<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Judicious Selection of Training Data in Assisting Language for Multilingual Neural NER Association for Computational Linguistics (ACL) 2018</p>
    <p>Rudra Murthy V CFILT Lab,</p>
    <p>Indian Institute Of Technology Bombay rudra@cse.iitb.ac.in</p>
    <p>Anoop Kunchukuttan Microsoft AI &amp; Research,</p>
    <p>Hyderabad, India ankunchu@microsoft.com</p>
    <p>Pushpak Bhattacharyya CFILT Lab,</p>
    <p>Indian Institute Of Technology Bombay pb@cse.iitb.ac.in</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Problem Statement</p>
    <p>Motivation</p>
    <p>Related Work</p>
    <p>Proposed Approach</p>
    <p>Experiments and Results</p>
  </div>
  <div class="page">
    <p>Table of Contents</p>
    <p>Problem Statement</p>
    <p>Motivation</p>
    <p>Related Work</p>
    <p>Proposed Approach</p>
    <p>Experiments and Results</p>
  </div>
  <div class="page">
    <p>Problem Statement</p>
    <p>Judiciously select labeled data from assisting language to improve the NER performance in the primary language for multilingual learning</p>
  </div>
  <div class="page">
    <p>Table of Contents</p>
    <p>Problem Statement</p>
    <p>Motivation</p>
    <p>Related Work</p>
    <p>Proposed Approach</p>
    <p>Experiments and Results</p>
  </div>
  <div class="page">
    <p>Why need to judiciously select data from assisting language?</p>
    <p>Many language have less named entity annotated data  Several approaches have explored use of data from one or more languages (assisting languages) [Gillick et al. [2016], Yang et al. [2017]]</p>
    <p>However, annotated data from assisting languages might negatively influence the performance on the primary language</p>
  </div>
  <div class="page">
    <p>What can go wrong in multilingual learning for NER?</p>
    <p>Vocabulary  False Friends  Dataset Characteristics</p>
    <p>Sub-word features  Capitalization feature</p>
    <p>Religions, Languages, Nationalities, etc. uppercase in English but not in Spanish</p>
    <p>Contextual features  Different Word Order</p>
  </div>
  <div class="page">
    <p>What can go wrong in multilingual learning for NER?</p>
    <p>Vocabulary  False Friends  Dataset Characteristics</p>
    <p>Sub-word features  Capitalization feature</p>
    <p>Religions, Languages, Nationalities, etc. uppercase in English but not in Spanish</p>
    <p>Contextual features  Different Word Order</p>
  </div>
  <div class="page">
    <p>Why need to judiciously select data from assisting language?</p>
    <p>Vocabulary  False Friends  Dataset Characteristics</p>
    <p>English</p>
    <p>Word Per Loc Org Misc</p>
    <p>China - 91 7 France - 123 4 1 Reuters - 40 18 ...</p>
    <p>Spanish</p>
    <p>Word Per Loc Org Misc</p>
    <p>China - 20 49 1 France - - 10 Reuters - 3 1 ...</p>
  </div>
  <div class="page">
    <p>Table of Contents</p>
    <p>Problem Statement</p>
    <p>Motivation</p>
    <p>Related Work</p>
    <p>Proposed Approach</p>
    <p>Experiments and Results</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>Axelrod et al. [2011] Moore and Lewis [2010]</p>
    <p>Select sentences from general domain data most similar to in-domain data</p>
    <p>Used language model to measure similarity of general domain data with the in-domain training data</p>
    <p>Ruder and Plank [2017]  Learn to weigh various data selection measures using Bayesian Optimization</p>
    <p>Zhao et al. [2018]  Select assisting data for multi-task domain adaptation  Assisting language sentences with highest log likelihood value were selected</p>
    <p>Ponti et al. [2018]  Measure cross-lingual syntactic variation considering both morphological and structural properties</p>
    <p>Selecting a assisting language with a lower degree of anisomorphism is crucial for knowledge transfer</p>
    <p>Table 1: Literature most relevant to our work</p>
  </div>
  <div class="page">
    <p>Table of Contents</p>
    <p>Problem Statement</p>
    <p>Motivation</p>
    <p>Related Work</p>
    <p>Proposed Approach</p>
    <p>Experiments and Results</p>
  </div>
  <div class="page">
    <p>Proposed Approach</p>
    <p>Select sentences based on the agreement in tag distribution of common entities Goal: Improve Spanish NER performance by adding English NER annotated data</p>
    <p>English</p>
    <p>Word Per Loc Org Misc</p>
    <p>China - 91 7 France - 123 4 1 Reuters - 40 18 ...</p>
    <p>Spanish</p>
    <p>Word Per Loc Org Misc</p>
    <p>China - 20 49 1 France - - 10 Reuters - 3 1 ...</p>
    <p>Select English sentences containing entities with similar tag distribution</p>
    <p>Use Symmetric Kl-Divergence to calculate the tag disagreement for common entities between English and Spanish</p>
    <p>English Spanish Word Per Loc Org Misc Per Loc Org Misc KL(EngEsp) KL(EspEng) SKL</p>
    <p>China - 91 7 - - 20 49 1 0.9314 1.3972 2.3287 France - 123 - 4 1 - - 10 - 10.4332 2.6388 13.0721 Reuters - 40 18 - - 3 1 - 0.1088 0.1531 0.2620</p>
  </div>
  <div class="page">
    <p>Proposed Approach</p>
    <p>Select sentences based on the agreement in tag distribution of common entities Goal: Improve Spanish NER performance by adding English NER annotated data</p>
    <p>English</p>
    <p>Word Per Loc Org Misc</p>
    <p>China - 91 7 France - 123 4 1 Reuters - 40 18 ...</p>
    <p>Spanish</p>
    <p>Word Per Loc Org Misc</p>
    <p>China - 20 49 1 France - - 10 Reuters - 3 1 ...</p>
    <p>Select English sentences containing entities with similar tag distribution</p>
    <p>Use Symmetric Kl-Divergence to calculate the tag disagreement for common entities between English and Spanish</p>
    <p>English Spanish Word Per Loc Org Misc Per Loc Org Misc KL(EngEsp) KL(EspEng) SKL</p>
    <p>China - 91 7 - - 20 49 1 0.9314 1.3972 2.3287 France - 123 - 4 1 - - 10 - 10.4332 2.6388 13.0721 Reuters - 40 18 - - 3 1 - 0.1088 0.1531 0.2620</p>
  </div>
  <div class="page">
    <p>Proposed Approach</p>
    <p>Select sentences based on the agreement in tag distribution of common entities Goal: Improve Spanish NER performance by adding English NER annotated data</p>
    <p>English</p>
    <p>Word Per Loc Org Misc</p>
    <p>China - 91 7 France - 123 4 1 Reuters - 40 18 ...</p>
    <p>Spanish</p>
    <p>Word Per Loc Org Misc</p>
    <p>China - 20 49 1 France - - 10 Reuters - 3 1 ...</p>
    <p>Select English sentences containing entities with similar tag distribution</p>
    <p>Use Symmetric Kl-Divergence to calculate the tag disagreement for common entities between English and Spanish</p>
    <p>English Spanish Word Per Loc Org Misc Per Loc Org Misc KL(EngEsp) KL(EspEng) SKL</p>
    <p>China - 91 7 - - 20 49 1 0.9314 1.3972 2.3287 France - 123 - 4 1 - - 10 - 10.4332 2.6388 13.0721 Reuters - 40 18 - - 3 1 - 0.1088 0.1531 0.2620</p>
  </div>
  <div class="page">
    <p>Proposed Approach</p>
    <p>Select sentences based on the agreement in tag distribution of common entities Goal: Improve Spanish NER performance by adding English NER annotated data</p>
    <p>English</p>
    <p>Word Per Loc Org Misc</p>
    <p>China - 91 7 France - 123 4 1 Reuters - 40 18 ...</p>
    <p>Spanish</p>
    <p>Word Per Loc Org Misc</p>
    <p>China - 20 49 1 France - - 10 Reuters - 3 1 ...</p>
    <p>Select English sentences containing entities with similar tag distribution</p>
    <p>Use Symmetric Kl-Divergence to calculate the tag disagreement for common entities between English and Spanish</p>
    <p>English Spanish Word Per Loc Org Misc Per Loc Org Misc KL(EngEsp) KL(EspEng) SKL</p>
    <p>China - 91 7 - - 20 49 1 0.9314 1.3972 2.3287 France - 123 - 4 1 - - 10 - 10.4332 2.6388 13.0721 Reuters - 40 18 - - 3 1 - 0.1088 0.1531 0.2620</p>
  </div>
  <div class="page">
    <p>Proposed Approach</p>
    <p>Select sentences based on the agreement in tag distribution of common entities Goal: Improve Spanish NER performance by adding English NER annotated data</p>
    <p>English</p>
    <p>Word Per Loc Org Misc</p>
    <p>China - 91 7 France - 123 4 1 Reuters - 40 18 ...</p>
    <p>Spanish</p>
    <p>Word Per Loc Org Misc</p>
    <p>China - 20 49 1 France - - 10 Reuters - 3 1 ...</p>
    <p>Select English sentences containing entities with similar tag distribution</p>
    <p>Use Symmetric Kl-Divergence to calculate the tag disagreement for common entities between English and Spanish</p>
    <p>English Spanish Word Per Loc Org Misc Per Loc Org Misc KL(EngEsp) KL(EspEng) SKL</p>
    <p>China - 91 7 - - 20 49 1 0.9314 1.3972 2.3287 France - 123 - 4 1 - - 10 - 10.4332 2.6388 13.0721 Reuters - 40 18 - - 3 1 - 0.1088 0.1531 0.2620</p>
  </div>
  <div class="page">
    <p>Proposed Approach</p>
    <p>Select sentences based on the agreement in tag distribution of common entities Goal: Improve Spanish NER performance by adding English NER annotated data</p>
    <p>English</p>
    <p>Word Per Loc Org Misc</p>
    <p>China - 91 7 France - 123 4 1 Reuters - 40 18 ...</p>
    <p>Spanish</p>
    <p>Word Per Loc Org Misc</p>
    <p>China - 20 49 1 France - - 10 Reuters - 3 1 ...</p>
    <p>Select English sentences containing entities with similar tag distribution</p>
    <p>Use Symmetric Kl-Divergence to calculate the tag disagreement for common entities between English and Spanish</p>
    <p>English Spanish Word Per Loc Org Misc Per Loc Org Misc KL(EngEsp) KL(EspEng) SKL</p>
    <p>China - 91 7 - - 20 49 1 0.9314 1.3972 2.3287 France - 123 - 4 1 - - 10 - 10.4332 2.6388 13.0721 Reuters - 40 18 - - 3 1 - 0.1088 0.1531 0.2620</p>
  </div>
  <div class="page">
    <p>Proposed Approach</p>
    <p>for every sentence X, in assisting language do Score(X)  0.0 for every word xi, in sentence X do if word xi appears in primary language then SKL(xi)</p>
    <p>[ KL(Pp(xi)||Pa(xi)) + KL(Pa(x)||Pp(x))</p>
    <p>] /2 {Pp(xi) and</p>
    <p>Pa(xi) are tag distributions of xi in primary and assisting languages} Score(X)  Score(X) + SKL(xi)</p>
    <p>end if end for</p>
    <p>end for</p>
    <p>Add assisting language sentences with sentence score Score(X) less than a threshold  to the primary language data</p>
  </div>
  <div class="page">
    <p>Table of Contents</p>
    <p>Problem Statement</p>
    <p>Motivation</p>
    <p>Related Work</p>
    <p>Proposed Approach</p>
    <p>Experiments and Results</p>
  </div>
  <div class="page">
    <p>Dataset Statistics</p>
    <p>Language Source Train Test</p>
    <p>Word Embeddings (#Tokens) (#Tokens)</p>
    <p>English Tjong Kim Sang and De Meulder [2003]</p>
    <p>Dhillon et al. [2015] (Spectral embeddings)Spanish Tjong Kim Sang [2002] 264,715 51,533</p>
    <p>Dutch Tjong Kim Sang [2002] 202,931 68,994 Italian Speranza [2009] 149,651 86,420 German Faruqui and Pad [2010] 74,907 20,696</p>
    <p>Hindi Lalitha Devi et al. [2014] 81,817 23,696</p>
    <p>Bojanowski et al. [2017] (fastText embeddings)</p>
    <p>Marathi In-house 71,299 36,581 Tamil Lalitha Devi et al. [2014] 66,143 18,646 Bengali Lalitha Devi et al. [2014] 34,387 7,614 Malayalam Lalitha Devi et al. [2014] 26,295 8,275</p>
    <p>Table 2: Dataset Statistics</p>
  </div>
  <div class="page">
    <p>Network Details</p>
    <p>Figure 1: Architecture of the Neural Network (Murthy and Bhattacharyya [2016])</p>
    <p>Parameter sharing configurations considered  Sub-word feature extractors shared across languages (Yang et al. [2017])</p>
    <p>Neural network trained in language independent way</p>
  </div>
  <div class="page">
    <p>Results</p>
    <p>Primary Assisting Layers Data Selection Primary Assisting Layers Data Selection</p>
    <p>Language Language Shared All SKL Language Language Shared All SKL</p>
    <p>German</p>
    <p>Monolingual None 87.64</p>
    <p>Italian</p>
    <p>Monolingual None 75.98</p>
    <p>English All 89.08 89.46</p>
    <p>English All 76.22 76.91</p>
    <p>Sub-word 88.76 89.10 Sub-word 79.44 79.44</p>
    <p>Spanish All 89.02 91.61</p>
    <p>Spanish All 74.94 76.92</p>
    <p>Sub-word 88.37 89.10 Sub-word 76.99 77.45</p>
    <p>Dutch All 89.66 90.85</p>
    <p>Dutch All 75.59 77.29</p>
    <p>Sub-word 89.94 90.11 Sub-word 77.38 77.56</p>
    <p>Table 3: F-Score for German and Italian Test data using Monolingual and Multilingual learning strategies.  indicates that the SKL results are statistically significant compared to adding all assisting language data with p-value &lt; 0.05 using two-sided Welch t-test.</p>
  </div>
  <div class="page">
    <p>Analysis</p>
    <p>Histogram of assisting language sentences ranked by their sentence scores</p>
    <p>Figure 2: English-Italian: Histogram of English Sentences</p>
    <p>Figure 3: Spanish-Italian: Histogram of Spanish Sentences</p>
  </div>
  <div class="page">
    <p>Analysis: European Languages</p>
    <p>Adding all Spanish/Dutch sentences to Italian data, leads to drop in Italian NER performance</p>
    <p>Label drift from overlapping entities is one of the reasons for the poor results</p>
    <p>We compare the histograms of English and Spanish sentences ranked by the SKL scores for Italian multilingual learning</p>
    <p>Similar pattern is observed in the case of Dutch sentences</p>
  </div>
  <div class="page">
    <p>Results</p>
    <p>Primary Language Assisting Language</p>
    <p>Hindi Marathi Bengali Malayalam Tamil</p>
    <p>ALL SKL ALL SKL ALL SKL ALL SKL ALL SKL</p>
    <p>Hindi 64.93 - 59.30 66.33 58.51 59.30 58.21 59.13 56.75 58.75 Marathi 54.46 63.30 61.46 - 47.67 61.28 50.13 61.05 59.04 58.62</p>
    <p>Bengali 44.34 51.05 41.28 55.77 40.02 - 48.79 49.84 38.38 44.14 Malayalam 59.74 64.00 65.88 66.42 58.01 63.65 57.94 - 58.25 58.92 Tamil 60.13 61.51 60.54 61.67 53.27 60.32 61.03 61.45 53.13</p>
    <p>Table 4: Test set F-Score from monolingual and multilingual learning on Indian languages. Result from monolingual training on the primary language is underlined.  indicates SKL results statistically significant compared to adding all assisting language data with p-value &lt; 0.05 using two-sided Welch t-test.</p>
  </div>
  <div class="page">
    <p>Analysis: Indian Languages</p>
    <p>Bengali, Malayalam, and Tamil (low-resource languages) benefits from our data selection strategy</p>
    <p>Hindi and Marathi NER performance improves when the other is used as assisting language</p>
    <p>Hindi and Marathi are not benefited from multilingual learning with Bengali, Malayalam and Tamil</p>
  </div>
  <div class="page">
    <p>Analysis</p>
    <p>Influence of SKL Threshold</p>
    <p>Figure 4: Spanish-Italian Multilingual Learning: Influence of Sentence score (SKL) on Italian NER</p>
  </div>
  <div class="page">
    <p>Analysis: Influence of SKL Threshold</p>
    <p>Train for Italian NER by adding Spanish training sentences and sharing all layers except for output layer across languages</p>
    <p>We vary the threshold value from 0.0 to 9.0 in steps of 1  Italian test F-Score increases initially as we add more and more Spanish sentences and then drops due to influence of drift becoming significant</p>
  </div>
  <div class="page">
    <p>Conclusion And Future Work</p>
    <p>We address the problem of divergence in tag distribution between primary and assisting languages for multilingual Neural NER</p>
    <p>We show that filtering out the assisting language sentences exhibiting significant divergence in the tag distribution can improve NER accuracy</p>
    <p>A more principled approach for data selection would be exploring the work of Ponti et al. [2018]</p>
    <p>We plan to study the influence of data selection for multilingual learning on other NLP tasks like sentiment analysis, question answering, neural machine translation</p>
    <p>We also plan to explore more metrics for multilingual learning, specifically for morphologically rich languages</p>
  </div>
  <div class="page">
    <p>Thank You</p>
  </div>
  <div class="page">
    <p>References I</p>
    <p>Amittai Axelrod, Xiaodong He, and Jianfeng Gao. Domain adaptation via pseudo in-domain data selection. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, Edinburgh, United Kingdom, 2011.</p>
    <p>Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. Enriching word vectors with subword information. Transactions of the Association for Computational Linguistics, 2017.</p>
    <p>Paramveer S. Dhillon, Dean P. Foster, and Lyle H. Ungar. Eigenwords: Spectral word embeddings. Journal of Machine Learning Research, 2015.</p>
    <p>Manaal Faruqui and Sebastian Pad. Training and evaluating a German Named Entity Recognizer with semantic generalization. In Proceedings of KONVENS, 2010.</p>
  </div>
  <div class="page">
    <p>References II</p>
    <p>Dan Gillick, Cliff Brunk, Oriol Vinyals, and Amarnag Subramanya. Multilingual language processing from bytes. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics, San Diego, US, 2016.</p>
    <p>Shobha Lalitha Devi, Pattabhi RK Rao, Malarkodi C.S, and R Vijay Sundar Ram. Indian language NER annotated FIRE 2014 corpus (FIRE 2014 NER Corpus). In Named-Entity Recognition Indian Languages FIRE 2014 Evaluation Track, 2014.</p>
    <p>Robert C. Moore and William Lewis. Intelligent selection of language model training data. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, Uppsala, Sweden, 2010.</p>
  </div>
  <div class="page">
    <p>References III</p>
    <p>Rudra V. Murthy and Pushpak Bhattacharyya. A deep learning solution to Named Entity Recognition. In CICLing, Konya, Turkey, 2016.</p>
    <p>Edoardo Maria Ponti, Roi Reichart, Anna Korhonen, and Ivan Vulic. Isomorphic transfer of syntactic structures in cross-lingual nlp. In ACL 2018, 2018.</p>
    <p>Sebastian Ruder and Barbara Plank. Learning to select data for transfer learning with Bayesian Optimization. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, Copenhagen, Denmark, 2017.</p>
    <p>Manuela Speranza. The Named Entity Recognition task at EVALITA 2009. In Proceedings of the Workshop Evalita, 2009.</p>
  </div>
  <div class="page">
    <p>References IV</p>
    <p>Erik F. Tjong Kim Sang. Introduction to the conll-2002 shared task: Language-independent Named Entity Recognition. In Proceedings of the 6th Conference on Natural Language Learning at COLING-02, Taipei, Taiwan, 2002.</p>
    <p>Erik F. Tjong Kim Sang and Fien De Meulder. Introduction to the conll-2003 shared task: Language-independent Named Entity Recognition. In Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, Edmonton, Canada, 2003.</p>
    <p>Zhilin Yang, Ruslan Salakhutdinov, and William Cohen. Multi-task cross-lingual sequence tagging from scratch. In International Conference on Learning Representations, Toulon, France, 2017.</p>
  </div>
  <div class="page">
    <p>References V</p>
    <p>Huasha Zhao, Yi Yang, Qiong Zhang, and Luo Si. Improve neural entity recognition via multi-task data selection and constrained decoding. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers). Association for Computational Linguistics, 2018.</p>
  </div>
  <div class="page">
    <p>Why need to judiciously select data from assisting language?</p>
    <p>Vocabulary  False Friends  Dataset Characteristics</p>
    <p>Sub-word features  Capitalization feature</p>
    <p>Religions, Languages, Nationalities, etc. uppercase in English but not in Spanish</p>
    <p>Contextual features  Different Word Order</p>
    <p>I am going to Washington</p>
    <p>mein washington jaa raha hun me washington going to</p>
  </div>
</Presentation>
