<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>ICAC 2013 - 1</p>
    <p>Preemptive ReduceTask Scheduling for Fair and Fast Job Completion</p>
    <p>Yandong Wang, Jian Tan, Weikuan Yu,</p>
    <p>Li Zhang, Xiaoqiao Meng</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 2</p>
    <p>Background &amp; Motivation</p>
    <p>Issues in Hadoop Scheduler</p>
    <p>Preemptive ReduceTask</p>
    <p>Fair Completion Scheduler</p>
    <p>Performance Evaluation</p>
    <p>Conclusion and Future Work</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 3</p>
    <p>Overview</p>
    <p>MapReduce is a programming model for processing massive-scale data.</p>
    <p>Hadoop: Open-source implementation of MapReduce</p>
    <p>Hadoop has been widely adopted by leading companies.</p>
    <p>Providing high scalability and strong fault tolerance.</p>
    <p>Data consolidation can be highly beneficial.</p>
    <p>Co-location of disparate data sets and avoiding data replication cost.</p>
    <p>Mixed workloads of long batch jobs and small interactive queries.</p>
    <p>Interactive queries are expected to return quickly.</p>
    <p>Hadoop Fair Scheduler was introduced to allow fair sharing among concurrent jobs.</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 4</p>
    <p>Split</p>
    <p>Split</p>
    <p>Split</p>
    <p>MapTask</p>
    <p>MapTask</p>
    <p>MapTask</p>
    <p>Map</p>
    <p>ReduceTask</p>
    <p>ReduceTask</p>
    <p>Output</p>
    <p>Output</p>
    <p>Shuffle Reduce</p>
    <p>Hadoop schedulers strive to overlap the map and shuffle phases to accelerate data processing pipeline.</p>
    <p>High-Level Hadoop Overview</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 5</p>
    <p>A widely used Hadoop scheduler for sharing a Hadoop cluster.</p>
    <p>Providing fairness among concurrently running jobs via max-min fair sharing.  Delay scheduling policy are used to provide data locality awareness.</p>
    <p>Tasks occupy slots until successful completion or failure.</p>
    <p>Hadoop Fair Scheduler</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 6</p>
    <p>Background &amp; Motivation</p>
    <p>Issues in Hadoop Scheduler</p>
    <p>Preemptive ReduceTask</p>
    <p>Fair Completion Scheduler</p>
    <p>Performance Evaluation</p>
    <p>Conclusion and Future Work</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 7</p>
    <p>On average, last 5 small jobs are severely slowed down by 15.</p>
    <p>Unfair Reduce Slots Allocation</p>
    <p>Map slots are fairly shared by 6 jobs</p>
    <p>Job4 is slowed down by 19</p>
    <p>Monopolizing behavior of long ReduceTasks from the large job (Job3).</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 8</p>
    <p>Distinctions MapTask ReduceTask</p>
    <p>Execution Time Short-lived Long-lived</p>
    <p>Execution Phase Single-phase Multi-phase</p>
    <p>Execution Dependency None Map phase</p>
    <p>Distinct Execution Pattern between Map and Reduce Tasks</p>
    <p>Current Hadoop schedulers treat map and reduce tasks similarly.</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 9</p>
    <p>Distinctions MapTask ReduceTask</p>
    <p>Execution Time Short-lived Long-lived</p>
    <p>Execution Phase Single-phase Multi-phase</p>
    <p>Execution Dependency None Map phase</p>
    <p>Distinct Execution Pattern between Map and Reduce Tasks</p>
    <p>Current Hadoop schedulers treat map and reduce tasks similarly.</p>
    <p>It is critical for Hadoop schedulers to be aware of these different patterns.</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 10</p>
    <p>Hadoop introduces slow start [1]</p>
    <p>Mitigating the starvation but at the cost of slowing down the data processing pipeline.</p>
    <p>Impacting the execution time of small jobs.</p>
    <p>Coupling scheduling policy from IBM[2]</p>
    <p>Similar to slow start which let monopolization progressively happen  Copy-Compute Splitting[3]</p>
    <p>Performance is unknown, no results was reported.</p>
    <p>Existing Efforts</p>
    <p>[1]: mapred.reduce.slowstart.completed.maps . [2]: Jian Tan, Xiaoqiao Meng, Li Zhang, Coupling scheduler for MapReduce/Hadoop, HPDC12. [3]: Job Scheduling for Multi-User MapReduce Cluster, Berkeley, Technical Report UCB/EECS-2009-55.</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 11</p>
    <p>How to achieve both high Efficiency and Fairness ?</p>
    <p>How to tackle monopolizing behavior of long running ReduceTasks ?  Existing schedulers ignore long-lasting ReduceTasks, once they are launched, they</p>
    <p>occupy resource until completion or failure.</p>
    <p>Introducing a new mechanism: Preemptive ReduceTask.</p>
    <p>How to coordinate two-phase job scheduling ?  MapReduce adopts two-phase scheme (map and reduce) to schedule tasks. However</p>
    <p>less contemplation has been given to coordinate them.</p>
    <p>A new scheduler: Fair Completion Scheduler.</p>
    <p>Fundamental Solutions</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 12</p>
    <p>Background &amp; Motivation</p>
    <p>Issues in Hadoop Scheduler</p>
    <p>Preemptive ReduceTask</p>
    <p>Fair Completion Scheduler</p>
    <p>Performance Evaluation</p>
    <p>Conclusion and Future Work</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 13</p>
    <p>Lightweight work-conserving preemption mechanism.</p>
    <p>Preserving previous computation and I/O.</p>
    <p>Providing lightweight preemption with no noticeable performance impact.</p>
    <p>Different from Linux process suspend commend (Kill -STOP $PID).  Preemptive ReduceTask releases the reduce slot.</p>
    <p>Superior to current killing preemption mechanism.  Killing can lead to significant waste of computation and I/O.</p>
    <p>Preemptive ReduceTask</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 14</p>
    <p>TaskTracker</p>
    <p>Heap</p>
    <p>S eg</p>
    <p>m en</p>
    <p>t</p>
    <p>Merge</p>
    <p>seg seg seg Heap</p>
    <p>seg</p>
    <p>Retrieve</p>
    <p>R1: Before Preempt R1: After Resume</p>
    <p>Index</p>
    <p>S eg</p>
    <p>m en</p>
    <p>t</p>
    <p>Preemption During Shuffle Phase  Only merging the in-memory intermediate data, while maintaining on-disk</p>
    <p>intermediate data untouched.</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 15</p>
    <p>R1: Before Preempt</p>
    <p>MPQ</p>
    <p>R1: After Resume</p>
    <p>MPQ</p>
    <p>DFS</p>
    <p>Index</p>
    <p>R et</p>
    <p>rie ve</p>
    <p>offset</p>
    <p>Preemption During Reduce Phase  Recording the current offset of each segment and minimum priority queue</p>
    <p>Preemption occurs at the boundary of intermediate &lt;key,value&gt; pairs.</p>
    <p>TaskTracker</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 16</p>
    <p>Evaluation of Preemptive ReduceTask</p>
    <p>Jo b</p>
    <p>E xe</p>
    <p>cu tio</p>
    <p>n Ti</p>
    <p>m e</p>
    <p>(s ec</p>
    <p>)</p>
    <p>Finished Percentage of ReduceTask Workload</p>
    <p>Work-Conserving Preemption Killing Preemption No Preemption (Baseline)</p>
    <p>Terasort benchmark with 512GB input data on a cluster of 20 worker nodes.</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 17</p>
    <p>Background &amp; Motivation</p>
    <p>Issues in Hadoop Scheduler</p>
    <p>Preemptive ReduceTask</p>
    <p>Fair Completion Scheduler</p>
    <p>Performance Evaluation</p>
    <p>Conclusion and Future Work</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 18</p>
    <p>Prioritizing ReduceTasks from jobs with the shortest remaining map phases.  Allowing small jobs to preempt long-running ReduceTasks from large jobs.</p>
    <p>MapTask scheduling follows max-min fair sharing policy.</p>
    <p>When remaining map phases are equal, prioritizing ReduceTasks from jobs with least remaining reduce data.</p>
    <p>Detecting the job execution slowdown caused by preemptions.  Preventing ReduceTasks of large jobs from being preempted for too long and too many</p>
    <p>times.</p>
    <p>Fair Completion Scheduler</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 19</p>
    <p>Slave Node 1</p>
    <p>FCS</p>
    <p>R1 of J1 R2 of J1</p>
    <p>Slave Node 2</p>
    <p>R3 of J1 R1 of J2</p>
    <p>Slave Node 3</p>
    <p>R4 of J1 R5 of J1</p>
    <p>Slave Node 4</p>
    <p>R6 of J1 R2 of J2</p>
    <p>Job J1</p>
    <p>Remaining Map Phase</p>
    <p>Remaining Reduce Data Reduce</p>
    <p>J1 1000 s 100GB 6</p>
    <p>J2 200 s 10GB 2</p>
    <p>Job J2</p>
    <p>Sort Running Jobs: (1): According to remaining map time (2): According to remaining reduce data</p>
    <p>Fair Completion Scheduling Details</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 20</p>
    <p>Slave Node 1</p>
    <p>FCS</p>
    <p>R1 of J1 R2 of J1</p>
    <p>Slave Node 2</p>
    <p>R3 of J1 R1 of J2</p>
    <p>Slave Node 3</p>
    <p>R4 of J1 R5 of J1</p>
    <p>Slave Node 4</p>
    <p>R6 of J1 R2 of J2</p>
    <p>Job J1</p>
    <p>Remaining Map Phase</p>
    <p>Remaining Reduce Data Reduce</p>
    <p>J1 1000 s 100GB 6</p>
    <p>J2 200 s 10GB 2</p>
    <p>Job J2 Job J3</p>
    <p>Sort Running Jobs: (1): According to remaining map time (2): According to remaining reduce data</p>
    <p>J3 80 s 8GB 4</p>
    <p>Fair Completion Scheduling Details</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 21</p>
    <p>Slave Node 1</p>
    <p>FCS</p>
    <p>R1 of J1 R2 of J1</p>
    <p>Slave Node 2</p>
    <p>R3 of J1 R1 of J2</p>
    <p>Slave Node 3</p>
    <p>R4 of J1 R5 of J1</p>
    <p>Slave Node 4</p>
    <p>R6 of J1 R2 of J2</p>
    <p>Job J1</p>
    <p>Remaining Map Phase</p>
    <p>Remaining Reduce Data Reduce</p>
    <p>J1 1000 s 100GB 6</p>
    <p>J2 200 s 10GB 2</p>
    <p>Job J2 Job J3</p>
    <p>Sort Running Jobs: (1): According to remaining map time (2): According to remaining reduce data</p>
    <p>J3 80 s 8GB 4</p>
    <p>Preempt ReduceTask of Job1</p>
    <p>Fair Completion Scheduling Details</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 22</p>
    <p>Slave Node 1</p>
    <p>FCS</p>
    <p>R1 of J1 R2 of J1</p>
    <p>Slave Node 2</p>
    <p>R3 of J1 R1 of J2</p>
    <p>Slave Node 3</p>
    <p>R4 of J1 R5 of J1</p>
    <p>Slave Node 4</p>
    <p>R6 of J1 R2 of J2</p>
    <p>Remaining Map Phase</p>
    <p>Remaining Reduce Data Reduce</p>
    <p>J1 1000 s 100GB 6</p>
    <p>J2 200 s 10GB 2</p>
    <p>Job J2</p>
    <p>Sort Running Jobs: (1): According to remaining map time (2): According to remaining reduce data</p>
    <p>J3 80 s 8GB 4</p>
    <p>R1 of J3 R2 of J3 R3 of J3 R4 of J3</p>
    <p>Fair Completion Scheduling Details</p>
    <p>Job J1 Job J3</p>
    <p>Launch ReduceTasks of Job3</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 23</p>
    <p>Slave Node 1</p>
    <p>FCS</p>
    <p>R1 of J1 R2 of J1</p>
    <p>Slave Node 2</p>
    <p>R3 of J1 R1 of J2</p>
    <p>Slave Node 3</p>
    <p>R4 of J1 R5 of J1</p>
    <p>Slave Node 4</p>
    <p>R6 of J1 R2 of J2</p>
    <p>Job J1</p>
    <p>Remaining Map Phase</p>
    <p>Remaining Reduce Data Reduce</p>
    <p>J1 800 s 100GB 6</p>
    <p>J2 120 s 10GB 2</p>
    <p>Job J2</p>
    <p>Sort Running Jobs: (1): According to remaining map time (2): According to remaining reduce data</p>
    <p>Resume ReduceTasks of Job 1</p>
    <p>Fair Completion Scheduling Details</p>
    <p>Job3 completes</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 24</p>
    <p>Background &amp; Motivation</p>
    <p>Issues in Hadoop Scheduler</p>
    <p>Preemptive ReduceTask</p>
    <p>Fair Completion Scheduler</p>
    <p>Performance Evaluation</p>
    <p>Conclusion and Future Work</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 25</p>
    <p>Hardware configuration  A cluster of 46 nodes. 4 2.67GHz hex-core Intel Xeon CPUs, 24GB memory and two</p>
    <p>hard disks.</p>
    <p>Software configuration:</p>
    <p>Hadoop 1.0.0 and its Fair Scheduler. 8 map slots and 4 reduce slots on each nodes.</p>
    <p>Gridmix2 and Tarazu benchmarks:  Map-heavy workload</p>
    <p>Reduce-heavy workload</p>
    <p>Scalability evaluation</p>
    <p>Testbed and Benchmarks/Metrics</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 26</p>
    <p>FCS HFS</p>
    <p>FCS reduces average execution time by 31% (171 jobs).</p>
    <p>Significantly speeds up small jobs, slightly slow down large jobs.</p>
    <p>A ve</p>
    <p>ra ge</p>
    <p>E xe</p>
    <p>cu tio</p>
    <p>n Ti</p>
    <p>m e</p>
    <p>(s ec</p>
    <p>)</p>
    <p>Results for Map-heavy Workload</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 27</p>
    <p>ra ge</p>
    <p>R ed</p>
    <p>uc eT</p>
    <p>as k</p>
    <p>W ai</p>
    <p>t Ti</p>
    <p>m e</p>
    <p>(s ec</p>
    <p>)</p>
    <p>FCS HFS</p>
    <p>Small jobs are benefited from significantly shortened reduce wait time.</p>
    <p>Waiting time are reduced by 22 for the jobs in the first 6 groups.</p>
    <p>Average ReduceTask Wait Time</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 28</p>
    <p>FCS controls the preemption frequency to avoid excessive preemptions.</p>
    <p>Preemption Frequency</p>
    <p>P re</p>
    <p>em pt</p>
    <p>io n</p>
    <p>F re</p>
    <p>qu en</p>
    <p>cy</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 29</p>
    <p>M ax</p>
    <p>im um</p>
    <p>S lo</p>
    <p>w do</p>
    <p>w n Fair Completion</p>
    <p>Hadoop Fair</p>
    <p>FCS improves the fairness by 66.7% on average.</p>
    <p>Achieving nearly uniform maximum slowdown for all groups of jobs.</p>
    <p>Fairness Evaluation: Maximum Slowdown</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 30</p>
    <p>FCS reduces average execution time by 28% (171 jobs).</p>
    <p>FCS accelerates all types of jobs in the reduce-heavy workload.  Impact of preemption on large job is not heavy due to they are still in map phases.</p>
    <p>A ve</p>
    <p>ra ge</p>
    <p>E xe</p>
    <p>cu tio</p>
    <p>n Ti</p>
    <p>m e</p>
    <p>(s ec</p>
    <p>)</p>
    <p>Results for Reduce-heavy Workload</p>
    <p>FCS HFS</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 31</p>
    <p>FCS improves the fairness by 35.2% on average.</p>
    <p>M ax</p>
    <p>im um</p>
    <p>S lo</p>
    <p>w do</p>
    <p>w n</p>
    <p>Fairness of Reduce-heavy Workload</p>
    <p>Fair Completion</p>
    <p>Hadoop Fair</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 32</p>
    <p>A ve</p>
    <p>ra ge</p>
    <p>E xe</p>
    <p>cu tio</p>
    <p>n T</p>
    <p>im e</p>
    <p>(s ec</p>
    <p>)</p>
    <p>Different Number of Jobs</p>
    <p>Fair Completion Hadoop Fair</p>
    <p>FCS reduces the average execution time by 39.7%.</p>
    <p>Small improvement at 60 due to dominant number of small jobs.</p>
    <p>Scalability Evaluation with GridMix-2</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 33</p>
    <p>Background &amp; Motivation</p>
    <p>Issues in Hadoop Scheduler</p>
    <p>Preemptive ReduceTask</p>
    <p>Fair Completion Scheduler</p>
    <p>System Evaluation</p>
    <p>Conclusion and Future Work</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 34</p>
    <p>Identify the inefficiencies in existing Hadoop schedulers.</p>
    <p>Preemptive ReduceTask provides an efficient preemption approach.  Fair Completion Scheduler is introduced to improve the efficiency and</p>
    <p>fairness of the concurrently running jobs.</p>
    <p>Preemptive ReduceTask provides opportunities to improve the fault tolerance mechanism.</p>
    <p>More preemptive scheduling policy can be implemented based on Preemptive ReduceTask.</p>
    <p>Conclusion and Future Work</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 35</p>
    <p>Sponsors of Our Research</p>
  </div>
  <div class="page">
    <p>ICAC 2013 - 36</p>
    <p>Thank You and Questions ?</p>
  </div>
</Presentation>
