<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Hybrid Transitive Trust Mechanisms</p>
    <p>Jie Tang, Sven Seuken, David C. Parkes UC Berkeley, Harvard University,</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Large multi-agent systems must deal with fraudulent behavior  eBay auctions  P2P file sharing systems  Web surfing</p>
    <p>Pool collective experience  Need mechanisms for aggregating trust</p>
  </div>
  <div class="page">
    <p>Agent Interaction Model Defn. Agent Type: i in [0,1] = prob. of a successful interaction</p>
    <p>1</p>
    <p>2</p>
    <p>3</p>
    <p>4</p>
    <p>5</p>
    <p>s1</p>
    <p>s2</p>
    <p>s3</p>
    <p>s4</p>
    <p>s5</p>
  </div>
  <div class="page">
    <p>Goals</p>
    <p>Informativeness: correlation between scores si produced by the trust mechanism and true agent types i (corr(S, ))</p>
    <p>Strategyproofness: Prevent individual agents from manipulating trust scores si</p>
    <p>Trust mechanisms should be both informative and strategyproof</p>
    <p>Optimize tradeoff between informativeness and strategyproofness</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation  Example Mechanisms  Informativeness vs. Strategyproofness  Hybrid Transitive Trust Mechanisms</p>
    <p>Theoretical Analysis  Experimental Results</p>
    <p>Informativeness  Efficiency</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation  Example Mechanisms  Informativeness vs. Strategyproofness  Hybrid Transitive Trust Mechanisms</p>
    <p>Theoretical Analysis  Experimental Results</p>
    <p>Informativeness  Efficiency</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Example: PageRank</p>
  </div>
  <div class="page">
    <p>Example: Shortest Path</p>
    <p>i</p>
    <p>j</p>
  </div>
  <div class="page">
    <p>Example: Maxflow</p>
    <p>i</p>
    <p>j</p>
  </div>
  <div class="page">
    <p>Example: Hitting Time</p>
    <p>i</p>
    <p>j</p>
  </div>
  <div class="page">
    <p>Example: PageRank</p>
    <p>i</p>
    <p>j</p>
  </div>
  <div class="page">
    <p>Manipulations Misreport Sybil</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation  Example Mechanisms  Informativeness vs. Strategyproofness  Hybrid Transitive Trust Mechanisms</p>
    <p>Theoretical Analysis  Experimental Results</p>
    <p>Informativeness  Efficiency</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Value-strategyproof example</p>
    <p>i</p>
    <p>j</p>
    <p>Value strategyproofness: an agent cannot increase its own trust score</p>
  </div>
  <div class="page">
    <p>Rank-strategyproof example</p>
    <p>i</p>
    <p>j</p>
    <p>Rank strategyproofness: an agent cannot increase its rank</p>
  </div>
  <div class="page">
    <p>-strategyproof</p>
    <p>-value strategyproof: Agents cannot increase their trust score by more than  through manipulation</p>
    <p>-rank strategyproof: Agents cannot improve their rank to be above agents who have  higher trust score</p>
  </div>
  <div class="page">
    <p>Informativeness vs. Strategyproofness</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation  Example Mechanisms  Informativeness vs. Strategyproofness  Hybrid Transitive Trust Mechanisms</p>
    <p>Theoretical Analysis  Experimental Results</p>
    <p>Informativeness  Efficiency</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Hybrid Mechanisms</p>
    <p>Convex weighting of two mechanisms (one with good strategyproofness properties, one with good informativeness)</p>
    <p>Get intermediate strategyproofness and informativeness properties</p>
    <p>( ) + (1-)( )</p>
  </div>
  <div class="page">
    <p>Main Results</p>
    <p>Can combine -value-strategyproof mechanisms naturally</p>
    <p>(1- )Maxflow-  PageRank hybrid is 0.5value strategyproof</p>
    <p>Adjust strategyproofness as we vary</p>
  </div>
  <div class="page">
    <p>Main Results:</p>
    <p>Upwards value preservance and valuestrategyproofness yield -rank strategyproofness</p>
    <p>(1- ) Shortest Path-  Hitting Time hybrid is -rank strategyproof</p>
    <p>(1- ) Shortest Path-  Maxflow hybrid is -rank strategyproof</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation  Example Mechanisms  Informativeness vs. Strategyproofness  Hybrid Transitive Trust Mechanisms</p>
    <p>Theoretical Analysis  Experimental Results</p>
    <p>Informativeness  Efficiency</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Informativeness</p>
    <p>Informativeness is the correlation between the true agent types i and the trust scores given by each trust mechanism si</p>
    <p>Can only be measured experimentally  Setup</p>
    <p>N agents, each with type i (fraction of good)  No strategic agent behavior  Agents randomly interact, report results  Vary number of timesteps</p>
  </div>
  <div class="page">
    <p>Informativeness Properties  Sometimes hybrids have informativeness even</p>
    <p>higher than either of their base mechanisms</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation  Example Mechanisms  Informativeness vs. Strategyproofness  Hybrid Transitive Trust Mechanisms</p>
    <p>Theoretical Analysis  Experimental Results</p>
    <p>Informativeness  Efficiency</p>
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Efficiency Experiments</p>
    <p>In practice: care about trustworthy agents receiving good interactions</p>
    <p>Agents will be strategic  Measure efficiency as fraction of good interactions for</p>
    <p>cooperative agents  Simulated two application domains, a P2P file sharing</p>
    <p>domain and a web surfing domain  Setup</p>
    <p>Agents use hybrid trust mechanism to choose interaction partners</p>
    <p>Report results of interactions to trust mechanism</p>
  </div>
  <div class="page">
    <p>Cooperative, Lazy free-rider, Strategic</p>
    <p>Cooperative agents have high type  Lazy free-rider agents have low type  Strategic agents also have low type, but</p>
    <p>attempt to manipulate the system  Simple agent utility model:</p>
    <p>Assume heterogenous ability to manipulate  Reward proportional to manipulability of algorithm  As  increases, more strategic agents manipulate</p>
  </div>
  <div class="page">
    <p>File Sharing Domain</p>
  </div>
  <div class="page">
    <p>Conclusions  Analyzed informativeness and</p>
    <p>strategyproofness trade-off theoretically and experimentally</p>
    <p>Hybrid mechanisms have intermediate informativeness, strategyproofness properties</p>
    <p>For some domains, hybrid mechanisms produce better efficiency than either base mechanism</p>
    <p>Thank you for your attention</p>
  </div>
  <div class="page">
    <p>Conclusions  Analyzed informativeness and</p>
    <p>strategyproofness trade-off theoretically and experimentally</p>
    <p>Hybrid mechanisms have intermediate informativeness, strategyproofness properties</p>
    <p>For some domains, hybrid mechanisms produce better efficiency than either base mechanism</p>
    <p>Thank you for your attention</p>
  </div>
</Presentation>
