<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Overcoming the Limitations of Conventional Vector Processors</p>
    <p>Christos Kozyrakis David Patterson Stanford University U.C. Berkeley</p>
    <p>http://csl.stanford.edu/~christos</p>
  </div>
  <div class="page">
    <p>Renaissance for Vector Architectures  Declared dead about a decade ago</p>
    <p>Did not fit in a single-chip at the time  Did not match the important workloads of the time</p>
    <p>(desktop)</p>
    <p>Resurfacing for several important workloads  Multimedia processing</p>
    <p>Berkeley VIRAM, Stanford Imagine  Intel SSE-2, Motorola Altivec, AMD 3DNow!,</p>
    <p>Telecommunications &amp; networking  Intel IXS, Philips CVP, Broadcom Calisto</p>
    <p>Scientific computing &amp; bioinformatics  NEC Earth Simulator, Cray X1, Alpha Tarantula</p>
  </div>
  <div class="page">
    <p>Proof of Concept [Micro02]</p>
    <p>VIRAM vector processor  Single-issue, in-order, no vector caches  32 vector registers, 32 64-bit elements per register  2 arithmetic &amp; 1 load/store vector units, 4 parallel lanes</p>
    <p>10x speedup over OOO superscalar and wide VLIW for EEMBC benchmarks  Multimedia &amp; telecommunications workload</p>
    <p>Rgb2cmyk Rgb2yiq Filter Cjpeg Djpeg Autocor Convenc Bital Fft Viterbi Geom. Mean</p>
    <p>P er</p>
    <p>fo rm</p>
    <p>an ce</p>
    <p>/ M</p>
    <p>H z</p>
  </div>
  <div class="page">
    <p>Advantages of Vector Architectures  Most efficient way to exploit data-level parallelism</p>
    <p>High computation throughput at low complexity &amp; power  Many independent operations per vector instruction</p>
    <p>Require high memory bandwidth, not low latency  Regular memory access patterns</p>
    <p>Scale with CMOS technology if long vectors available  Use mature compiler technology</p>
    <p>Orthogonal to architectures for ILP and TLP  Superscalar or VLIW with vector unit</p>
    <p>E.g. Cray X1, Alpha Tarantula  Parallel vector processors (SMP, CMP, )</p>
    <p>E.g. NEC Earth Simulator, Cray X1, Broadcom Calisto</p>
  </div>
  <div class="page">
    <p>Technical Obstacles to Wide Adoption 1. Complexity of vector register file (VRF)</p>
    <p>Large SRAM array with 3N ports for N functional units  Area O(N2), latency O(N), power O(logN)</p>
    <p>Performance issue for short vector lengths  Limits vector processors to N3 functional units (VFUs)</p>
    <p>ROB must support chaining (vector forwarding)  Large, fully associative TLB required</p>
    <p>To translate all addresses for a vector load/store  Guarantee for forward progress between exceptions</p>
  </div>
  <div class="page">
    <p>Technical Obstacles to Wide Adoption  3. Cost of a large, on-chip, multi-bank memory</p>
    <p>Need high bandwidth for vector loads/stores  Large on-chip memories increase chip cost  Small on-chip caches dont work well with vectors</p>
    <p>Off-chip, high bandwidth memory is economical  But introduces significant latency overhead for vector</p>
    <p>loads/stores</p>
  </div>
  <div class="page">
    <p>This Work  CODE: a vector microarchitecture that</p>
    <p>Efficiently scales to many functional units  Implements precise exceptions at negligible cost  Tolerates the latency of off-chip memory systems</p>
    <p>Not presented  see paper for results</p>
    <p>Outline  Motivation  CODE microarchitecture overview  Performance evaluation &amp; comparison  Implementation of precise exceptions  Conclusion and future work</p>
  </div>
  <div class="page">
    <p>Traditional Vector Processor Organization</p>
    <p>Scalar Core</p>
    <p>$D $I</p>
    <p>Vector Unit</p>
    <p>V ec</p>
    <p>to r</p>
    <p>R eg</p>
    <p>is te</p>
    <p>rs Issue Memory Hierarchy</p>
  </div>
  <div class="page">
    <p>CODE Overview Clustered Organization for Decoupled Execution</p>
    <p>Scalar Core</p>
    <p>$D $I</p>
    <p>Vector Unit Vector Cluster</p>
    <p>Vector Cluster</p>
    <p>Vector Cluster</p>
    <p>Vector unit organized as collection of clusters</p>
    <p>Memory Hierarchy</p>
  </div>
  <div class="page">
    <p>CODE Overview Clustered Organization for Decoupled Execution</p>
    <p>Scalar Core</p>
    <p>$D $I</p>
    <p>Vector Unit</p>
    <p>Memory Hierarchy</p>
    <p>Vector Cluster</p>
    <p>Vector Cluster</p>
    <p>Vector Cluster</p>
    <p>Vector Regs</p>
    <p>Vector Regs</p>
    <p>Vector Regs</p>
    <p>Each cluster is a simple vector processor with 1 VFU</p>
  </div>
  <div class="page">
    <p>CODE Overview Clustered Organization for Decoupled Execution</p>
    <p>Scalar Core</p>
    <p>$D $I</p>
    <p>Vector Unit</p>
    <p>In te</p>
    <p>rC</p>
    <p>lu st</p>
    <p>er</p>
    <p>N</p>
    <p>et w</p>
    <p>or k</p>
    <p>Vector Cluster</p>
    <p>Vector Cluster</p>
    <p>Vector Cluster</p>
    <p>Vector Regs</p>
    <p>Vector Regs</p>
    <p>Vector Regs</p>
    <p>Clusters communicate through explicit transfers over network</p>
    <p>Memory Hierarchy</p>
  </div>
  <div class="page">
    <p>CODE Overview Clustered Organization for Decoupled Execution</p>
    <p>Scalar Core</p>
    <p>$D $I</p>
    <p>Vector Unit</p>
    <p>In te</p>
    <p>rC</p>
    <p>lu st</p>
    <p>er</p>
    <p>N</p>
    <p>et w</p>
    <p>or k</p>
    <p>Vector Cluster</p>
    <p>Vector Cluster</p>
    <p>Vector Cluster</p>
    <p>Vector Regs</p>
    <p>Vector Regs</p>
    <p>Vector Regs</p>
    <p>Issue logic steers instructions and indicates need for transfers</p>
    <p>Rename &amp; Issue</p>
    <p>Memory Hierarchy</p>
  </div>
  <div class="page">
    <p>Key Advantages  Separates the two functions of the centralized VRF</p>
    <p>Stage operands for a VFU  local VRF in each cluster  The VRF in each cluster has fixed complexity  Number/area/power for registers O(N), latency O(1)</p>
    <p>Communication between VFUs  inter-cluster network  Does not have to be a full crossbar  Network organization is a separate design trade-off</p>
    <p>Clusters are transparent at the instruction set level  Flexible mapping of architectural to physical registers</p>
    <p>Register values can move to the FUs that use them  Number of physical registers is unrestricted</p>
    <p>Allows for precise exceptions support</p>
  </div>
  <div class="page">
    <p>Potential Disadvantage  Number of inter-cluster transfers</p>
    <p>Worst case is 6 vector transfers per instruction  Can hurt performance significantly</p>
    <p>Clusters are idling while waiting for data  Can hurt complexity significantly</p>
    <p>Complexity of network can cancel simplicity of VRF</p>
    <p>How to reduce effect of inter-cluster transfers  Minimize number of transfers</p>
    <p>Provide a sufficient number of vector registers per cluster  Preferably, send instructions where their operands are</p>
    <p>Hide latency of transfers with extensive decoupling  Use instruction queues within clusters  Allow chaining to and from inter-cluster transfers</p>
  </div>
  <div class="page">
    <p>Experimental Methodology  IRAM vector instruction set</p>
    <p>32 vector registers, 32 64-bit elements/register  CODE equally applicable to Cray X1 or Alpha Tarantula</p>
    <p>Trace-driven, parameterized, performance model  Can vary: # &amp; mix of clusters, # of registers/cluster, # of</p>
    <p>lanes, issue policy, network bandwidth &amp; latency, memory system characteristics</p>
    <p>Default memory system is that of the VIRAM prototype  Limited to single instruction issue and one VFU per cluster</p>
    <p>Applications: EEMBC benchmarks  Highly vectorizable code with short and long vectors  Traces from IRAM vectorizing compiler &amp; ISA simulator</p>
  </div>
  <div class="page">
    <p>Instruction Issue Policy</p>
    <p>How to select a cluster for each vector instruction?  Random, minimize # of transfers, minimum # of</p>
    <p>transfers unless too much work imbalance  This graph:</p>
    <p>Relative performance with 2 clusters per instr. Type  Normalized to results with random selection</p>
    <p>Load approximated with occupancy of instruction queue</p>
    <p>Rgb2cmyk Rgb2yiq Filter Cjpeg Djpeg Autocor Convenc Bital Fft Viterbi Average</p>
    <p>R el</p>
    <p>at iv</p>
    <p>e P</p>
    <p>er fo</p>
    <p>rm an</p>
    <p>ce</p>
    <p>Random MinTrans MinTrans &amp; LoadBalance</p>
  </div>
  <div class="page">
    <p>Comparison to VIRAM</p>
    <p>-50</p>
    <p>Rgb2cmyk Rgb2yiq Filter Cjpeg Djpeg Autocor Convenc Bital Fft Viterbi Average</p>
    <p>% Im</p>
    <p>p ro</p>
    <p>ve m</p>
    <p>en t</p>
    <p>Lanes=1 Lanes=2 Lanes=4 Lanes=8</p>
    <p>Same area, memory system, clock, peak throughput  2 integer VFUs, 1 load/store VFU</p>
    <p>CODE:  Decoupling hides latency of inter-cluster transfers</p>
    <p>But also hides memory latency for strided/indexed accesses  CODE is 20% faster than VIRAM</p>
    <p>Even for multi-lane implementation of both approaches</p>
  </div>
  <div class="page">
    <p>Number of FUs (Clusters)</p>
    <p>A ve</p>
    <p>ra g</p>
    <p>e S</p>
    <p>p ee</p>
    <p>d u</p>
    <p>p</p>
    <p>Lanes=1 Lanes=2 Lanes=4 Lanes=8</p>
    <p>Scalability</p>
  </div>
  <div class="page">
    <p>Number of FUs (Clusters)</p>
    <p>A ve</p>
    <p>ra g</p>
    <p>e S</p>
    <p>p ee</p>
    <p>d u</p>
    <p>p</p>
    <p>Lanes=1 Lanes=2 Lanes=4 Lanes=8</p>
    <p>Scalability</p>
    <p>Lanes exploit data-level parallelism (long vectors) in the application</p>
  </div>
  <div class="page">
    <p>Number of FUs (Clusters)</p>
    <p>A ve</p>
    <p>ra g</p>
    <p>e S</p>
    <p>p ee</p>
    <p>d u</p>
    <p>p</p>
    <p>Lanes=1 Lanes=2 Lanes=4 Lanes=8</p>
    <p>Scalability</p>
    <p>Clusters exploit instruction-level parallelism &amp; long vectors in the application</p>
  </div>
  <div class="page">
    <p>Number of FUs (Clusters)</p>
    <p>A ve</p>
    <p>ra g</p>
    <p>e S</p>
    <p>p ee</p>
    <p>d u</p>
    <p>p</p>
    <p>Lanes=1 Lanes=2 Lanes=4 Lanes=8</p>
    <p>Scalability</p>
    <p>~6.8x improvement over 4 clusters/1 lane</p>
  </div>
  <div class="page">
    <p>Number of FUs (Clusters)</p>
    <p>A ve</p>
    <p>ra g</p>
    <p>e S</p>
    <p>p ee</p>
    <p>d u</p>
    <p>p</p>
    <p>Lanes=1 Lanes=2 Lanes=4 Lanes=8</p>
    <p>Scalability</p>
    <p>Limited by single instruction issue and available instruction-level parallelism</p>
  </div>
  <div class="page">
    <p>Precise Vector Exceptions  Key insight:</p>
    <p>Exploit extra vector registers and renaming  Dont need to modify the vector cluster design</p>
    <p>Changes in issue logic for precise exceptions  Dont deallocate registers with old values until</p>
    <p>instruction known to commit without exceptions  Use history buffer to log changes in renaming table</p>
    <p>Used to restore safe mappings on exceptions</p>
    <p>Remove large TLB requirement with ISA change  Allow faulting instruction to partially commit</p>
    <p>All elements until first one to cause exception  Large TLB is now a performance optimization only</p>
  </div>
  <div class="page">
    <p>Performance Loss due to Precise Exceptions</p>
    <p>-5 0 5</p>
    <p>Rgb2cmyk Rgb2yiq Filter Cjpeg Djpeg Autocor Convenc Bital Fft Viterbi Average</p>
    <p>% S</p>
    <p>lo w</p>
    <p>d o w</p>
    <p>n</p>
    <p>r=4 r=8 r=12 r=16</p>
    <p>Higher pressure for physical registers  Issue logic stalls &amp; more inter-cluster transfers</p>
    <p>Performance loss: ~5% with r=8 registers per cluster  Performance loss can be higher for FP applications</p>
    <p>If arithmetic exceptions are of interest</p>
  </div>
  <div class="page">
    <p>Related Work  Vector &amp; data-parallel processors</p>
    <p>Decoupling of load/stores [Espasa96][Asanovic98]  Hierarchical/distributed register file [Rixner00]</p>
    <p>Clustered ILP processors  Superscalar</p>
    <p>21264 [Kessler99], multi-cluster architecture [Farkas97]  ILDP [Kim02]  Many others</p>
    <p>VLIW  Clustered VLIW [Nicolau92][Fisher98][Gonzalez00]  Many others</p>
  </div>
  <div class="page">
    <p>Clustered Vectors Vs. Clustered SS/VLIW</p>
    <p>Clustering also used with superscalar &amp; VLIW  Same motivation</p>
    <p>More VFUs with simple register file, ROB, instr. window  Difficult to hide latency of inter-cluster transfers</p>
    <p>Always slower than ideal, centralized, architecture</p>
    <p>Why is clustering easier with CODE?  Can tolerate the latency of inter-cluster transfers</p>
    <p>Vectors tolerate latency  Decoupling between clusters helps further with latency</p>
    <p>Lower instruction issue bandwidth requirements  Issuing fewer instructions per cycle simplifies issue logic  Can implement much smarter issue policies</p>
  </div>
  <div class="page">
    <p>Conclusions  CODE: a scalable vector architecture</p>
    <p>Clustered vector register file  Extensive decoupling</p>
    <p>Overcomes the limitations of vector processors  Scales to 8 functional units</p>
    <p>Up to 70% performance improvement over 4-VFU design  Without complicating register file, without wide-issue  Works with applications with short vectors</p>
    <p>Can support precise vector instructions  At a 5% performance loss</p>
    <p>Can tolerate latency of off-chip memory  See paper for details</p>
  </div>
</Presentation>
