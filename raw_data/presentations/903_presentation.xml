<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Fine-Grain Performance Scaling of Soft Vector Processors</p>
    <p>Peter Yiannacouras Jonathan Rose Gregory J. Steffan</p>
    <p>ESWEEK  CASES 2009, Grenoble, France Oct 13, 2009</p>
  </div>
  <div class="page">
    <p>FPGA Systems and Soft Processors</p>
    <p>Soft Processor</p>
    <p>Custom HW</p>
    <p>HDL +</p>
    <p>CAD</p>
    <p>Software +</p>
    <p>Compiler</p>
    <p>Easier  Faster  Smaller  Less Power</p>
    <p>Simplify FPGA design: Customize soft processor architecture</p>
    <p>? Configurable COMPETE</p>
    <p>Weeks Months</p>
    <p>Target: Data level parallelism  vector processors</p>
    <p>Used in 25% of designs [source: Altera, 2009]</p>
    <p>Digital System</p>
    <p>Hard Processor</p>
    <p>Board space, latency, power Specialized device, increased cost</p>
    <p>computation</p>
  </div>
  <div class="page">
    <p>Vector Processing Primer</p>
    <p>// C code for(i=0;i&lt;16; i++) c[i]=a[i]+b[i]</p>
    <p>// Vectorized code set vl,16 vload vr0,a vload vr1,b vadd vr2,vr0,vr1 vstore vr2,c</p>
    <p>Each vector instruction holds many units of independent operations</p>
    <p>vr2[0]= vr0[0]+vr1[0] vr2[1]= vr0[1]+vr1[1] vr2[2]= vr0[2]+vr1[2]</p>
    <p>vr2[4]= vr0[4]+vr1[4] vr2[3]= vr0[3]+vr1[3]</p>
    <p>vr2[5]= vr0[5]+vr1[5] vr2[6]= vr0[6]+vr1[6] vr2[7]= vr0[7]+vr1[7] vr2[8]= vr0[8]+vr1[8] vr2[9]= vr0[9]+vr1[9]</p>
    <p>vr2[10]=vr0[10]+vr1[10] vr2[11]=vr0[11]+vr1[11] vr2[12]=vr0[12]+vr1[12] vr2[13]=vr0[13]+vr1[13] vr2[14]=vr0[14]+vr1[14] vr2[15]=vr0[15]+vr1[15]</p>
    <p>vadd</p>
  </div>
  <div class="page">
    <p>Vector Processing Primer</p>
    <p>// C code for(i=0;i&lt;16; i++) c[i]=a[i]+b[i]</p>
    <p>// Vectorized code set vl,16 vload vr0,a vload vr1,b vadd vr2,vr0,vr1 vstore vr2,c</p>
    <p>Each vector instruction holds many units of independent operations</p>
    <p>vadd 16 Vector Lanes</p>
    <p>vr2[0]= vr0[0]+vr1[0] vr2[1]= vr0[1]+vr1[1] vr2[2]= vr0[2]+vr1[2]</p>
    <p>vr2[4]= vr0[4]+vr1[4] vr2[3]= vr0[3]+vr1[3]</p>
    <p>vr2[5]= vr0[5]+vr1[5] vr2[6]= vr0[6]+vr1[6] vr2[7]= vr0[7]+vr1[7] vr2[8]= vr0[8]+vr1[8] vr2[9]= vr0[9]+vr1[9]</p>
    <p>vr2[10]=vr0[10]+vr1[10] vr2[11]=vr0[11]+vr1[11] vr2[12]=vr0[12]+vr1[12] vr2[13]=vr0[13]+vr1[13] vr2[14]=vr0[14]+vr1[14] vr2[15]=vr0[15]+vr1[15]</p>
    <p>Previous Work (on Soft Vector Processors): 1. Scalability 2. Flexibility 3. Portability</p>
    <p>CASES08</p>
  </div>
  <div class="page">
    <p>VESPA Architecture Design (Vector Extended Soft Processor Architecture)</p>
    <p>Scalar Pipeline 3-stage</p>
    <p>Vector Control Pipeline 3-stage</p>
    <p>Vector Pipeline 6-stage</p>
    <p>Icache Dcache</p>
    <p>Decode RF A L U</p>
    <p>M U X</p>
    <p>WB</p>
    <p>VC RF</p>
    <p>VS RF</p>
    <p>VC WB</p>
    <p>VS WB</p>
    <p>Logic</p>
    <p>Decode Replicate</p>
    <p>Hazard check</p>
    <p>VR RF</p>
    <p>VR WB</p>
    <p>VR RF</p>
    <p>VR WB</p>
    <p>Decode</p>
    <p>Supports integer and fixed-point operations [VIRAM]</p>
    <p>Shared Dcache</p>
    <p>Legend Pipe stage Logic Storage</p>
    <p>Lane 1 ALU,Mem UnitLane 2 ALU, Mem, Mul</p>
  </div>
  <div class="page">
    <p>In This Work</p>
    <p>Augment with parameterized vector chaining support</p>
  </div>
  <div class="page">
    <p>Evaluation Infrastructure</p>
    <p>Binary</p>
    <p>Instruction Set</p>
    <p>Simulation</p>
    <p>EEMBC Benchmarks</p>
    <p>RTL Simulation</p>
    <p>SOFTWARE HARDWARE</p>
    <p>Verilog</p>
    <p>FPGA CAD</p>
    <p>Software</p>
    <p>cycles area, power, clock frequency</p>
    <p>GCC Compiler</p>
    <p>verification verification</p>
    <p>Full hardware design of VESPA soft vector processor</p>
    <p>Evaluate soft vector processors with high accuracy</p>
    <p>Stratix III 340</p>
    <p>DDR2</p>
    <p>Vectorized assembly</p>
    <p>subroutines</p>
    <p>GNU as</p>
    <p>ld</p>
  </div>
  <div class="page">
    <p>VESPA Scalability</p>
    <p>Up to 19x, average of 11x for 32 lanes  good scaling</p>
    <p>(Area=1)</p>
    <p>(Area=1.3)</p>
    <p>(Area=1.9)</p>
    <p>(Area=3.2)</p>
    <p>(Area=6.3)</p>
    <p>(Area=12.3)</p>
    <p>Powerful parameter  but is coarse-grained</p>
  </div>
  <div class="page">
    <p>Vector Lane Design Space</p>
    <p>Too coarse grain! Reprogrammability allows more exact-fit</p>
    <p>(Equivalent ALMs)</p>
  </div>
  <div class="page">
    <p>In This Work</p>
    <p>Augment with parameterized vector chaining support</p>
  </div>
  <div class="page">
    <p>Vector Chaining</p>
    <p>Simultaneous execution of independent element operations within dependent instructions</p>
    <p>vadd vr10, vr1,vr2</p>
    <p>vmul vr20, vr10,vr11</p>
    <p>dependency</p>
    <p>vadd</p>
    <p>vmul</p>
    <p>Dependent Instructions</p>
    <p>Independent Element Operations</p>
  </div>
  <div class="page">
    <p>Vector Chaining in VESPA</p>
    <p>Unified</p>
    <p>A L U</p>
    <p>Vector Register File</p>
    <p>B=1</p>
    <p>B=2</p>
    <p>Bank 0</p>
    <p>Vector Register File</p>
    <p>Bank 1</p>
    <p>M U X</p>
    <p>M U X</p>
    <p>vmul vadd</p>
    <p>vmul vadd</p>
    <p>Single Instruction Execution</p>
    <p>Multiple Instruction Execution</p>
    <p>time</p>
    <p>time</p>
    <p>No Vector Chaining</p>
    <p>With Vector Chaining</p>
    <p>A L U</p>
    <p>A L U</p>
    <p>A L U</p>
    <p>Mem</p>
    <p>A L U</p>
    <p>A L U</p>
    <p>A L U</p>
    <p>MemMem</p>
    <p>A L U</p>
    <p>Mul</p>
    <p>MemMemMemMul</p>
    <p>Lanes=4</p>
    <p>Performance increase if instructions correctly scheduled</p>
  </div>
  <div class="page">
    <p>ALU Replication</p>
    <p>B=2 APB=false</p>
    <p>Bank 0</p>
    <p>Vector Register File</p>
    <p>Bank 1</p>
    <p>M U X</p>
    <p>vsub vadd</p>
    <p>Single Instruction Execution</p>
    <p>time</p>
    <p>With Vector Chaining</p>
    <p>MemMemMem</p>
    <p>ALU</p>
    <p>Mul</p>
    <p>M U X</p>
    <p>ALUALUALU</p>
    <p>B=2 APB=true</p>
    <p>Bank 0</p>
    <p>Vector Register File</p>
    <p>Bank 1</p>
    <p>M U X</p>
    <p>With Vector Chaining</p>
    <p>MemMemMem</p>
    <p>ALU</p>
    <p>Mul</p>
    <p>M U X</p>
    <p>ALUALUALU</p>
    <p>M U X</p>
    <p>ALUALUALUALU</p>
    <p>vsub vadd</p>
    <p>Multiple Instruction Execution</p>
    <p>time</p>
    <p>Lanes=4</p>
  </div>
  <div class="page">
    <p>Vector Chaining Speedup (on an 8-lane VESPA)</p>
    <p>Dont care</p>
    <p>More banks More ALUs</p>
    <p>More banks</p>
    <p>More ALUs</p>
    <p>Chaining can be quite costly in area: 27%-92% Performance is application dependent: 5%-76% Significant speed improvement over no chaining (22-35% avg)</p>
    <p>More fine-grain vs double lanes: 19-89% speed, 86% area</p>
    <p>C y</p>
    <p>c le</p>
    <p>S p</p>
    <p>e e d</p>
    <p>u p</p>
    <p>vs</p>
    <p>N o C</p>
    <p>h a in</p>
    <p>in g</p>
  </div>
  <div class="page">
    <p>In This Work</p>
    <p>Augment with parameterized vector chaining support</p>
  </div>
  <div class="page">
    <p>Heterogeneous Lanes</p>
    <p>Mul</p>
    <p>ALU</p>
    <p>Mul</p>
    <p>ALU</p>
    <p>Mul</p>
    <p>ALU</p>
    <p>Mul</p>
    <p>ALU</p>
    <p>Lane 1</p>
    <p>Lane 2</p>
    <p>Lane 3</p>
    <p>Lane 4</p>
    <p>vmul</p>
  </div>
  <div class="page">
    <p>Heterogeneous Lanes</p>
    <p>Mul</p>
    <p>ALU</p>
    <p>Mul</p>
    <p>ALU</p>
    <p>ALU</p>
    <p>ALU</p>
    <p>Lane 1</p>
    <p>Lane 2</p>
    <p>Lane 3</p>
    <p>Lane 4</p>
    <p>vmul</p>
    <p>STALL!</p>
    <p>Save area, but reduce speed depending on demand on the multiplier</p>
  </div>
  <div class="page">
    <p>Impact of Heterogeneous Lanes (on a 32-lane VESPA)</p>
    <p>Free Expensive Moderate</p>
    <p>Performance penalty is application dependent: 0%-85%</p>
    <p>Modest area savings (6%-13%)  dedicated multipliers</p>
  </div>
  <div class="page">
    <p>In This Work</p>
    <p>Augment with parameterized vector chaining support</p>
  </div>
  <div class="page">
    <p>Design Space Exploration using VESPA Architectural Parameters</p>
    <p>Description Symbol Values</p>
    <p>Number of Lanes L 1,2,4,8,</p>
    <p>Memory Crossbar Lanes M 1,2, , L</p>
    <p>Multiplier Lanes X 1,2, , L</p>
    <p>Banks for Vector Chaining B 1,2,4</p>
    <p>ALU Replicate Per Bank APB on/off</p>
    <p>Maximum Vector Length MVL 2,4,8,</p>
    <p>Width of Lanes (in bits) W 1-32</p>
    <p>Instruction Enable (each) - on/off</p>
    <p>Data Cache Capacity DD any</p>
    <p>Data Cache Line Size DW any</p>
    <p>Data Prefetch Size DPK &lt; DD</p>
    <p>Vector Data Prefetch Size DPV &lt; DD/MVL</p>
    <p>Compute Architecture</p>
    <p>Memory Architecture</p>
    <p>Instruction Set</p>
    <p>Architecture</p>
  </div>
  <div class="page">
    <p>VESPA Design Space (768 architectural configurations)</p>
    <p>Fine-grain design space allows better-fit architecture</p>
    <p>Evidence of efficiency: trade performance and area 1:1</p>
    <p>Normalized Coprocessor Area</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d W</p>
    <p>a ll</p>
    <p>C lo</p>
    <p>c k</p>
    <p>T im</p>
    <p>e</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>22-35% better average performance than without  Chaining configuration impact very application-dependent</p>
    <p>Use software for non-critical data-parallel computation</p>
  </div>
  <div class="page">
    <p>Thank You!</p>
    <p>VESPA release: http://www.eecg.utoronto.ca/VESPA</p>
  </div>
  <div class="page">
    <p>VESPA Parameters</p>
    <p>Description Symbol Values</p>
    <p>Number of Lanes L 1,2,4,8,</p>
    <p>Memory Crossbar Lanes M 1,2, , L</p>
    <p>Multiplier Lanes X 1,2, , L</p>
    <p>Banks for Vector Chaining B 1,2,4</p>
    <p>ALU Replicate Per Bank APB on/off</p>
    <p>Maximum Vector Length MVL 2,4,8,</p>
    <p>Width of Lanes (in bits) W 1-32</p>
    <p>Instruction Enable (each) - on/off</p>
    <p>Data Cache Capacity DD any</p>
    <p>Data Cache Line Size DW any</p>
    <p>Data Prefetch Size DPK &lt; DD</p>
    <p>Vector Data Prefetch Size DPV &lt; DD/MVL</p>
    <p>Compute Architecture</p>
    <p>Memory Architecture</p>
    <p>Instruction Set</p>
    <p>Architecture</p>
  </div>
  <div class="page">
    <p>VESPA Scalability</p>
    <p>Up to 27x, average of 15x for 32 lanes  good scaling</p>
    <p>(Area=1)</p>
    <p>(Area=1.3)</p>
    <p>(Area=1.9)</p>
    <p>(Area=3.2)</p>
    <p>(Area=6.3)</p>
    <p>(Area=12.3)</p>
    <p>Powerful parameter  but too coarse-grained</p>
  </div>
  <div class="page">
    <p>Proposed Soft Vector Processor System Design Flow</p>
    <p>Memory Interface</p>
    <p>Custom HW</p>
    <p>Peripherals</p>
    <p>Soft ProcVector</p>
    <p>Lane 1</p>
    <p>Is the soft processor the bottleneck?</p>
    <p>yes, increase lanes</p>
    <p>www.fpgavendor.com</p>
    <p>We propose adding vector extensions to existing soft processors</p>
    <p>User Code +</p>
    <p>Portable, Flexible, Scalable</p>
    <p>Vectorized Software Routine</p>
    <p>Vectorized Software Routine</p>
    <p>Vectorized Software Routine</p>
    <p>Portable</p>
    <p>Vectorized Software Routine</p>
    <p>Vectorized Software Routine</p>
    <p>Vectorized Software Routine</p>
    <p>Vector Lane 2 Vector Lane 3 Vector Lane 4</p>
    <p>We want to evaluate soft vector processors for real</p>
  </div>
  <div class="page">
    <p>Vector Memory Unit</p>
    <p>Dcache</p>
    <p>base</p>
    <p>stride*0</p>
    <p>index0</p>
    <p>+ M U X</p>
    <p>...</p>
    <p>stride*1</p>
    <p>index1</p>
    <p>+ M U X</p>
    <p>stride*L</p>
    <p>indexL</p>
    <p>+ M U X</p>
    <p>Memory Request Queue</p>
    <p>Read Crossbar</p>
    <p>Memory Lanes=4</p>
    <p>rddata0 rddata1</p>
    <p>rddataL</p>
    <p>wrdata0 wrdata1</p>
    <p>wrdataL ...</p>
    <p>Write Crossbar</p>
    <p>Memory Write</p>
    <p>Queue</p>
    <p>L = # Lanes - 1</p>
  </div>
  <div class="page">
    <p>Overall Memory System Performance</p>
    <p>(4KB) (16KB)</p>
    <p>Wider line + prefetching reduces memory unit stall cycles significantly</p>
    <p>Wider line + prefetching eliminates all but 4% of miss cycles</p>
  </div>
</Presentation>
