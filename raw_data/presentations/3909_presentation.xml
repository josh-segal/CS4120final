<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Provenance for Data Mining</p>
    <p>Boris Glavic1 Javed Siddique2 Periklis Andritsos3</p>
    <p>Renee J. Miller2</p>
    <p>Illinois Institute of Technology1</p>
    <p>DBGroup</p>
    <p>University of Toronto2</p>
    <p>Miller Lab University of Toronto3</p>
    <p>iSchool</p>
    <p>TaPP 2013, April 2, 2013</p>
  </div>
  <div class="page">
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Data Mining / KDD</p>
    <p>Goals</p>
    <p>Extract useful information from data</p>
    <p>Approach</p>
    <p>Cleaning Feature Extraction . . .</p>
    <p>Clustering, Frequent Itemset Mining, Classification, . . . Most approaches: Reduce size/Summarize data</p>
    <p>Slide 1 of 18 Boris Glavic Datamining Provenance: Motivation</p>
  </div>
  <div class="page">
    <p>Provenance for Data Mining?</p>
    <p>Dilemmas</p>
    <p>Purpose of data mining necessitates summarization</p>
    <p>Needle in the haystack Loss of information</p>
    <p>Makes interpreting raw results harder</p>
    <p>User point of view: DM algorithm is black box</p>
    <p>Slide 2 of 18 Boris Glavic Datamining Provenance: Motivation</p>
  </div>
  <div class="page">
    <p>Provenance for Data Mining?</p>
    <p>How to solve Dilemmas?</p>
    <p>Selective access to input data result is based on</p>
    <p>Inputs to mining algorithm Inputs to preprocessing Contextual information</p>
    <p>Understand importance of inputs for results</p>
    <p>Input data Parameter settings</p>
    <p>Understand how data mining algorithm generates result from inputs</p>
    <p>Understand missing results</p>
    <p>Slide 2 of 18 Boris Glavic Datamining Provenance: Motivation</p>
  </div>
  <div class="page">
    <p>Provenance for Data Mining?</p>
    <p>How to solve Dilemmas?</p>
    <p>Selective access to input data result is based on (Data Provenance+)</p>
    <p>Inputs to mining algorithm Inputs to preprocessing Contextual information</p>
    <p>Understand importance of inputs for results (Responsibility)</p>
    <p>Input data Parameter settings</p>
    <p>Understand how data mining algorithm generates result from inputs (Process provenance)</p>
    <p>Understand missing results (Missing answers)</p>
    <p>Slide 2 of 18 Boris Glavic Datamining Provenance: Motivation</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>Provenance</p>
    <p>Database provenance, Workflow provenance, Missing answers, Responsibility, . . .</p>
    <p>Data Mining</p>
    <p>Enriching mining results with additional information</p>
    <p>Contextual information for frequent itemsetsa</p>
    <p>Visualization techniquesb</p>
    <p>Determining effect of parameter settings/inputs on result</p>
    <p>e.g., K-means cluster stability based on parameter settingsc</p>
    <p>aQ. Mei et al. Generating semantic annotations for frequent patterns with context analysis. In: SIGKDD. 2006, pp. 337346.</p>
    <p>bD.A. Keim and H.P. Kriegel. Visualization techniques for mining large databases: A comparison. In: TKDE 8.6 (1996), pp. 923938.</p>
    <p>cL.I. Kuncheva and D.P. Vetrov. Evaluation of stability of k-means cluster ensembles with respect to random initialization. In: TPAMI 28.11 (2006), pp. 17981808.</p>
    <p>Slide 3 of 18 Boris Glavic Datamining Provenance: Motivation</p>
  </div>
  <div class="page">
    <p>Contributions</p>
    <p>Analyze requirements and use cases for data mining provenance (DMProv)</p>
    <p>Discuss applicability of existing approaches</p>
    <p>Outline challenges and sketch research directions</p>
    <p>Exemplify concepts on two concrete mining algorithms</p>
    <p>Frequent Itemset Mining (FIM) Multidimensional Scaling (MDS)</p>
    <p>Slide 4 of 18 Boris Glavic Datamining Provenance: Motivation</p>
  </div>
  <div class="page">
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Fine-Grained Provenance</p>
    <p>Why-Provenance</p>
    <p>Here Why-Provenance means all models based on influence</p>
    <p>Subset of the input that caused output to appear in result</p>
    <p>Caused by modelled as</p>
    <p>Sufficiency Necessity Preservation of Equivalence / Computability Causality</p>
    <p>Useful for Data Mining?</p>
    <p>Provenance concepts seem applicable to data mining</p>
    <p>Have to deal with large provenance size (summarization)</p>
    <p>Can abstract processing of classes of mining algorithms?</p>
    <p>Do not reinvent provenance tracking for each algorithm!</p>
    <p>Slide 5 of 18 Boris Glavic Datamining Provenance: Provenance for Data Mining</p>
  </div>
  <div class="page">
    <p>Fine-Grained Provenance</p>
    <p>Tracing Through Preprocessing Steps</p>
    <p>Track back data mining results to inputs of preprocessing</p>
    <p>ETL tools are used for preprocessing</p>
    <p>can use database or workflow provenance approaches?</p>
    <p>Slide 5 of 18 Boris Glavic Datamining Provenance: Provenance for Data Mining</p>
  </div>
  <div class="page">
    <p>Enriching Provenance with Context</p>
    <p>Contextual Information as Provenance</p>
    <p>Mining algorithms often applied to a subset of available data</p>
    <p>Contextual Data: data related to the mining inputs</p>
    <p>Automatic detection User provided</p>
    <p>Contextual data often more usable and concise than provenance</p>
    <p>Which contextual data is of interest will differ</p>
    <p>per use-case maybe even per query</p>
    <p>Should support contextual data per provenance query/generation Need flexible mechanism to select context (declarative?)</p>
    <p>Slide 6 of 18 Boris Glavic Datamining Provenance: Provenance for Data Mining</p>
  </div>
  <div class="page">
    <p>DMProv and Data Responsibility</p>
    <p>Measuring Amount of Influence</p>
    <p>Single mining result influenced by large subset of input (all)</p>
    <p>e.g., clustering</p>
    <p>Amount of influence differs significantly (Responsibility)</p>
    <p>DB Responsibility Model</p>
    <p>Causalitya</p>
    <p>Counterfactual cause i for output o Removing i removes o from result</p>
    <p>Actual cause i for output o Contingency C : Set of inputs to remove before i becomes CC for o</p>
    <p>Responsibility: 1 size of minimal contingency</p>
    <p>aA. Meliou et al. Causality in databases. In: IEEE Data Engineering Bulletin 33.3 (2010), pp. 5967; James Cheney. Causality and the Semantics of Provenance. In: DCM. 2010, pp. 6374.</p>
    <p>Slide 7 of 18 Boris Glavic Datamining Provenance: Provenance for Data Mining</p>
  </div>
  <div class="page">
    <p>DMProv and Data Responsibility</p>
    <p>Applicability for Data Mining</p>
    <p>Reduce size of provenance</p>
    <p>only return top-k responsible inputs in provenance only return input with responsibility over threshold</p>
    <p>However: Output variables are not boolean</p>
    <p>Solution Sketch</p>
    <p>Consider every input as a cause</p>
    <p>Consider every set of inputs as a contingency</p>
    <p>Measure amount of change</p>
    <p>e.g., distance between cluster means</p>
    <p>Responsibility is sum of 1 size of contingency</p>
    <p>d(o,o) over all contingencies normalized by number of contingencies</p>
    <p>Slide 7 of 18 Boris Glavic Datamining Provenance: Provenance for Data Mining</p>
  </div>
  <div class="page">
    <p>Data vs. Parameter Responsibility</p>
    <p>Effect of Parameter Settings</p>
    <p>Mining results do depend on</p>
    <p>Data Parameter settings</p>
    <p>Define new responsibility type using both data and parameters</p>
    <p>Related Work: Robustness against parameter changes only</p>
    <p>stability of clusteringsa</p>
    <p>aL.I. Kuncheva and D.P. Vetrov. Evaluation of stability of k-means cluster ensembles with respect to random initialization. In: TPAMI 28.11 (2006), pp. 17981808.</p>
    <p>Slide 8 of 18 Boris Glavic Datamining Provenance: Provenance for Data Mining</p>
  </div>
  <div class="page">
    <p>How/Process Provenance</p>
    <p>So far only data provenance</p>
    <p>Understand how mining algorithm combines inputs to produce an output</p>
    <p>Applicability of workflow and program analysis provenance techniques</p>
    <p>Either too detailed or too coarse grained</p>
    <p>Slide 9 of 18 Boris Glavic Datamining Provenance: Provenance for Data Mining</p>
  </div>
  <div class="page">
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Frequent Itemset Mining (FIM)</p>
    <p>One of the most prevalent mining tasks</p>
    <p>Input: set of transactions (sets of items) Fixed domain D</p>
    <p>Output: subsets of D (frequent itemsets) appear in fraction larger  (minimum support) of the transactions</p>
    <p>Slide 10 of 18 Boris Glavic Datamining Provenance: Frequent Itemset Provenance</p>
  </div>
  <div class="page">
    <p>FIM Example</p>
    <p>Transaction TID Items CID</p>
    <p>FIM FID Frequent Items Support</p>
    <p>Slide 11 of 18 Boris Glavic Datamining Provenance: Frequent Itemset Provenance</p>
  </div>
  <div class="page">
    <p>FIM Example with Contextual Data</p>
    <p>Transaction TID Items CID</p>
    <p>FIM FID Frequent Items Support</p>
    <p>Customer CID AgeGroup Sex</p>
    <p>Slide 11 of 18 Boris Glavic Datamining Provenance: Frequent Itemset Provenance</p>
  </div>
  <div class="page">
    <p>Why-Provenance for FIM</p>
    <p>Intuition</p>
    <p>The transactions containing a frequent itemset I caused I to be frequent</p>
    <p>Define the Why-provenance as this set</p>
    <p>Definition (Why-Provenance for FI)</p>
    <p>Given transaction base D, minimum support , itemset I</p>
    <p>W(I ) = {t | I  t  t  D}</p>
    <p>Slide 12 of 18 Boris Glavic Datamining Provenance: Frequent Itemset Provenance</p>
  </div>
  <div class="page">
    <p>FIM Provenance</p>
    <p>Transaction TID Items CID</p>
    <p>FIM FID Frequent Items Support</p>
    <p>Customer CID AgeGroup Sex</p>
    <p>Why-Provenance FID TIDs</p>
    <p>Slide 13 of 18 Boris Glavic Datamining Provenance: Frequent Itemset Provenance</p>
  </div>
  <div class="page">
    <p>FIM Provenance with Context</p>
    <p>Customer CID AgeGroup Sex</p>
    <p>Why-Provenance FID TIDs</p>
    <p>Example (Beer and Diaper)</p>
    <p>Beer and Diaper is frequent</p>
    <p>but why?</p>
    <p>Why-provenance  it appeared in this set of transactions</p>
    <p>Not very useful! Unfeasible if D is large</p>
    <p>Because male customers in age group 20  40 bought it</p>
    <p>More useful and concise Summarization of inputs in provenance using contextual information Will need different context for different use cases</p>
    <p>Slide 13 of 18 Boris Glavic Datamining Provenance: Frequent Itemset Provenance</p>
  </div>
  <div class="page">
    <p>FIM Provenance with Context</p>
    <p>Customer CID AgeGroup Sex</p>
    <p>Why-Provenance FID TIDs</p>
    <p>Example (Beer and Diaper)</p>
    <p>Beer and Diaper is frequent</p>
    <p>but why?</p>
    <p>Why-provenance  it appeared in this set of transactions</p>
    <p>Not very useful! Unfeasible if D is large</p>
    <p>Because male customers in age group 20  40 bought it</p>
    <p>More useful and concise Summarization of inputs in provenance using contextual information Will need different context for different use cases</p>
    <p>Slide 13 of 18 Boris Glavic Datamining Provenance: Frequent Itemset Provenance</p>
  </div>
  <div class="page">
    <p>FIM Provenance with Context</p>
    <p>Customer CID AgeGroup Sex</p>
    <p>Why-Provenance FID TIDs</p>
    <p>Example (Beer and Diaper)</p>
    <p>Beer and Diaper is frequent</p>
    <p>but why?</p>
    <p>Why-provenance  it appeared in this set of transactions Not very useful! Unfeasible if D is large</p>
    <p>Because male customers in age group 20  40 bought it</p>
    <p>More useful and concise Summarization of inputs in provenance using contextual information Will need different context for different use cases</p>
    <p>Slide 13 of 18 Boris Glavic Datamining Provenance: Frequent Itemset Provenance</p>
  </div>
  <div class="page">
    <p>FIM Provenance with Context</p>
    <p>Customer CID AgeGroup Sex</p>
    <p>Why-Provenance FID TIDs</p>
    <p>Example (Beer and Diaper)</p>
    <p>Beer and Diaper is frequent</p>
    <p>but why?</p>
    <p>Why-provenance  it appeared in this set of transactions Not very useful! Unfeasible if D is large</p>
    <p>Because male customers in age group 20  40 bought it</p>
    <p>More useful and concise Summarization of inputs in provenance using contextual information Will need different context for different use cases</p>
    <p>Slide 13 of 18 Boris Glavic Datamining Provenance: Frequent Itemset Provenance</p>
  </div>
  <div class="page">
    <p>FIM Provenance with Context</p>
    <p>Customer CID AgeGroup Sex</p>
    <p>Why-Provenance FID TIDs</p>
    <p>Example (Beer and Diaper)</p>
    <p>Beer and Diaper is frequent</p>
    <p>but why?</p>
    <p>Why-provenance  it appeared in this set of transactions Not very useful! Unfeasible if D is large</p>
    <p>Because male customers in age group 20  40 bought it More useful and concise Summarization of inputs in provenance using contextual information Will need different context for different use cases</p>
    <p>Slide 13 of 18 Boris Glavic Datamining Provenance: Frequent Itemset Provenance</p>
  </div>
  <div class="page">
    <p>Preliminary Results</p>
    <p>FIM Provenance</p>
    <p>Why-Provenance for FIM</p>
    <p>Declarative selection of context</p>
    <p>I-Provenance</p>
    <p>Prefix compressed tree representation of provenance Precise modelling of interdependencies of items in provenance within transactions</p>
    <p>Database-based provenance generation and querying</p>
    <p>Slide 14 of 18 Boris Glavic Datamining Provenance: Frequent Itemset Provenance</p>
  </div>
  <div class="page">
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Multidimensional Scaling (MDS)</p>
    <p>Approach</p>
    <p>Input: Set of observation with pair-wise similarities</p>
    <p>Output: Mapping into n-dim space that tries to preserve similarities Optimization problem</p>
    <p>Use-case Marketing: Customers rate products pairs according to similarity MDS to generate layout (perceptual map) depicting similarity of products</p>
    <p>Example</p>
    <p>A B C D A - - - B 2 - - C 2 4 - D 3 3 3</p>
    <p>A</p>
    <p>C</p>
    <p>D</p>
    <p>B</p>
    <p>Slide 15 of 18 Boris Glavic Datamining Provenance: Multidimensional Scaling Provenance</p>
  </div>
  <div class="page">
    <p>Data vs. Parameter Responsibility</p>
    <p>Problem</p>
    <p>If two items are close in the layout then</p>
    <p>either they are similar or because it minimized the fitness function or some combination of both</p>
    <p>Using Provenance</p>
    <p>Why-provenance</p>
    <p>Show (difference to) original similarities for subset of the data</p>
    <p>Data vs. Parameter Responsibility</p>
    <p>Influence of actual data properties Parameter settings Idiosyncrasies of the algorithm</p>
    <p>Slide 16 of 18 Boris Glavic Datamining Provenance: Multidimensional Scaling Provenance</p>
  </div>
  <div class="page">
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Challenges</p>
    <p>Why-Provenance</p>
    <p>Common model that generalizes processing of large classes of mining algorithms</p>
    <p>Dealing with large (potentially overlapping) provenance</p>
    <p>Context and Preprocessing</p>
    <p>Dynamic handling of contextual data</p>
    <p>Tracing through preprocessing steps</p>
    <p>Responsibility</p>
    <p>Computational complexity</p>
    <p>How to model parameter vs. data responsibility?</p>
    <p>Slide 17 of 18 Boris Glavic Datamining Provenance: Conclusions</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Take Away Messages</p>
    <p>Data Mining is interesting and challenging application domain for provenance</p>
    <p>No previous work</p>
    <p>Future Work</p>
    <p>Extend preliminary results on FIM</p>
    <p>Clustering (responsibility)</p>
    <p>MDS (parameter vs. data responsibility)</p>
    <p>Slide 18 of 18 Boris Glavic Datamining Provenance: Conclusions</p>
  </div>
  <div class="page">
    <p>Questions?</p>
    <p>This is a vision paper</p>
    <p>so lets discuss!</p>
    <p>Provenance for Data Mining</p>
  </div>
</Presentation>
