<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Optimal Schemes for Robust Web Extraction</p>
    <p>Aditya Parameswaran Stanford University</p>
    <p>(Joint work with: Nilesh Dalvi, Hector GarciaMolina, Rajeev Rastogi)</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>htmlhtml</p>
    <p>bodybodyheadhead</p>
    <p>titletitle</p>
    <p>divdiv divdiv</p>
    <p>tabletable</p>
    <p>tdtd</p>
    <p>tabletable</p>
    <p>tdtd tdtd tdtd tdtd tdtd</p>
    <p>class=content</p>
    <p>width=80%Godfather</p>
    <p>Title : Godfather Director : Coppola Runtime 118min</p>
    <p>divdiv</p>
    <p>tdtd</p>
    <p>ad content</p>
    <p>Problem : Wrappers break!</p>
    <p>We can use the following Xpath wrapper to extract directors W1 = /html/body/div[2]/table/td[2]/text()</p>
    <p>class=head</p>
  </div>
  <div class="page">
    <p>But how do we find the most robust wrapper?</p>
    <p>Several alternative wrappers are more robust  W2 = //div[class=content]/table/td[2]/text()  W3 = //table[width=80%]/td[2]/text()  W4 = //td[preceding-sibling/text() = Director]/text()</p>
    <p>htmlhtml</p>
    <p>bodybodyheadhead</p>
    <p>titletitle</p>
    <p>divdiv divdiv</p>
    <p>tabletable</p>
    <p>tdtd</p>
    <p>tabletable</p>
    <p>tdtd tdtd tdtd tdtd tdtd</p>
    <p>class=content</p>
    <p>width=80%Godfather</p>
    <p>Title : Godfather Director : Coppola Runtime 118min</p>
    <p>class=head</p>
  </div>
  <div class="page">
    <p>w1</p>
    <p>w 1</p>
    <p>w 2</p>
    <p>wkt = 0</p>
    <p>t = t1</p>
    <p>Labeled Pages Unlabeled Pages wk+</p>
    <p>w n</p>
    <p>wk+ 2</p>
    <p>Unlabeled Pages</p>
    <p>w2</p>
    <p>wk</p>
    <p>wk+2</p>
    <p>wn</p>
    <p>wk+1</p>
    <p>Focus on Robustness Generalize</p>
    <p>Generalize?? ?</p>
  </div>
  <div class="page">
    <p>Page Level Wrapper Approach</p>
    <p>Compute a wrapper given:  Old version (ordered labeled tree) w  Distinguished node d(w) in w (May be many)</p>
    <p>On being given a new version (ordered labeled tree) w:</p>
    <p>Our wrapper returns:  Distinguished node d(w) in w  Estimate of the confidence</p>
  </div>
  <div class="page">
    <p>Two Core Problems</p>
    <p>Problem 1: Given w find the most robust wrapper on w  Problem 2: Given w, w, estimate the confidence of</p>
    <p>extraction</p>
  </div>
  <div class="page">
    <p>Change Model  Adversarial:</p>
    <p>Each edit: insert, delete, substitute has a known cost</p>
    <p>Sum costs for an edit script  Probabilistic: [Dalvi et. al. , SIGMOD09]</p>
    <p>Each edit has a known probability  Transducer that transforms the tree  Multiply probabilities</p>
  </div>
  <div class="page">
    <p>Summary of Theoretical Results</p>
    <p>Focus on these problems</p>
    <p>Focus on these problems</p>
    <p>Will touch upon this if there is</p>
    <p>time</p>
    <p>Will touch upon this if there is</p>
    <p>time</p>
    <p>PART 1 PART 3 PART 4</p>
    <p>Experiments!Experiments! Adversarial has</p>
    <p>better complexity</p>
    <p>Adversarial has better</p>
    <p>complexity</p>
    <p>Finding the wrapper is EASIER than estimating its</p>
    <p>robustness!</p>
    <p>Finding the wrapper is EASIER than estimating its</p>
    <p>robustness!</p>
    <p>PART 2, 5</p>
  </div>
  <div class="page">
    <p>Part 1: Adversarial Wrapper: Robustness</p>
    <p>Recall: Adversarial has costs for each edit operation</p>
    <p>Given a webpage w, fix a wrapper</p>
    <p>Robustness of a wrapper on a webpage w : Largest c such that for any edit script s with cost &lt; c, wrapper can find the distinguished node in s(w)</p>
    <p>Robustness of a wrapper on a webpage w : Largest c such that for any edit script s with cost &lt; c, wrapper can find the distinguished node in s(w)</p>
    <p>Cost</p>
    <p>Script 1: del(X), ins(Y), subs (Z, W) Script 2: .</p>
    <p>Robustne ss</p>
  </div>
  <div class="page">
    <p>How do we show optimality?</p>
    <p>w1</p>
    <p>w2 w3</p>
    <p>Proof 1: Upperbound on</p>
    <p>Robustness</p>
    <p>Proof 1: Upperbound on</p>
    <p>Robustnessw0</p>
    <p>Robustne ss</p>
    <p>Proof 2: Lowerbound of</p>
    <p>robustness of w0</p>
    <p>Proof 2: Lowerbound of</p>
    <p>robustness of w0 w4</p>
    <p>Thus, w0 is optimal!</p>
    <p>Thus, w0 is optimal!</p>
    <p>c</p>
  </div>
  <div class="page">
    <p>Adversarial Wrapper: Upper Bound</p>
    <p>Let c be the smallest cost such that</p>
    <p>S1&lt;= c, S2&lt;= c, so that this bad case happens</p>
    <p>Then, c is an upperbound on the robustness</p>
    <p>of any wrapper on w! 12</p>
    <p>s1s2w</p>
    <p>BAD CASE:</p>
    <p>Same structure (i.e., S1 (w) = S2</p>
    <p>(w))</p>
    <p>Different locations of distinguished</p>
    <p>nodes.</p>
    <p>BAD CASE:</p>
    <p>Same structure (i.e., S1 (w) = S2</p>
    <p>(w))</p>
    <p>Different locations of distinguished</p>
    <p>nodes.</p>
    <p>w</p>
    <p>s1</p>
    <p>s2</p>
  </div>
  <div class="page">
    <p>Adversarial Optimal Wrapper</p>
    <p>Given w, d(w), w:  Find the smallest cost edit script S such that S(w) =</p>
    <p>w  Return the location of d(w) on applying S to w</p>
    <p>S w w</p>
  </div>
  <div class="page">
    <p>Robustness Lowerbound Proof</p>
    <p>Assume the contrary (robustness of our wrapper is &lt; c)</p>
    <p>Then, there is an actual edit script S1 where it fails</p>
    <p>and cost(S1) &lt; c  Let the min cost script be S2  Then: cost(S2) &lt;= cost(S1) &lt; c  But then this situation cannot happen! 14</p>
    <p>s1</p>
    <p>s2</p>
    <p>w w</p>
  </div>
  <div class="page">
    <p>Detour: Minimum Cost Edit Script</p>
    <p>Classical paper by Zhang-Shasha</p>
    <p>Dynamic programming over subtrees</p>
    <p>Complexity: O(n1 n2 d1 d2)</p>
  </div>
  <div class="page">
    <p>Part 2: Evaluation  Crawls from internet-archive.org</p>
    <p>Domains: IMDB, CNN, Wikipedia  Roughly 10-20 webpages per domain  Roughly 100s of versions per webpage</p>
    <p>Finding distinguished nodes  We looked for unique patterns that appear</p>
    <p>in all webpages, like &lt;Number&gt; votes  Allows us to do automatic evaluation</p>
    <p>How do we set the costs?  Learn from prior data</p>
  </div>
  <div class="page">
    <p>Evaluation (Continued)</p>
    <p>Baseline comparisons  XPATH: Robust XPath Wrapper [SIGMOD09]  FULL: Entire Xpath</p>
    <p>Two kinds of experiments  Variation with difference in archive.org version</p>
    <p>number  A proxy on time  How do wrappers perform as the time gap is</p>
    <p>increased?  Precision/Recall of the confidence estimates provided</p>
    <p>Can I use the confidence values to decide whether to refer the web-page to an editor?</p>
  </div>
  <div class="page"/>
  <div class="page"/>
  <div class="page">
    <p>Part 2: Computation of Robustness</p>
    <p>NP-Hard via a reduction from the partition problem. {x1, x2, , xn}</p>
    <p>Costs: d(a0) = 0 and d(an) = 0</p>
    <p>Costs: s(ai,bi) = 0; s(ai, bi-1) = xi; s(ai, bi+1) = xi; Everything else</p>
    <p>infty.</p>
    <p>a0</p>
    <p>a1 an</p>
    <p>a1 a2 an</p>
    <p>a0 a1 an-1</p>
    <p>b0/1 b1/2 bn/n+1</p>
    <p>c = sum(xi)/2</p>
    <p>iff there is a partition</p>
    <p>c = sum(xi)/2</p>
    <p>iff there is a partition</p>
  </div>
  <div class="page">
    <p>Part 3: Confidence in Extraction</p>
    <p>Let s1 be the min cost edit script  Let s2 be the min cost edit script that has a</p>
    <p>different location of distinguished node  Confidence = cost(s2) - cost(s1)  Also computed in O(n1 n2 d1 d2)</p>
    <p>s1</p>
    <p>s2 w w</p>
  </div>
  <div class="page">
    <p>Probabilistic Wrapper</p>
    <p>No single edit script  All edit scripts have some non-zero</p>
    <p>probability</p>
    <p>Location of node is  Argmaxs Pr(w, w, d(w), s)</p>
    <p>Simple algorithm: For each s, compute above.</p>
    <p>Problem: Too slow!  Solution: Share computation</p>
  </div>
  <div class="page">
    <p>Evaluation (Continued)</p>
    <p>Baseline comparisons  XPATH: Most robust XPath Wrapper [SIGMOD09]  FULL: Entire Xpath</p>
    <p>Two kinds of experiments  Variation with difference in archive.org version</p>
    <p>number  A proxy on time  How do wrappers perform as the time gap is</p>
    <p>increased?  Precision/Recall of the confidence estimates</p>
    <p>provided  Can I use the confidence values to decide</p>
    <p>whether to refer the web-page to an editor?23</p>
  </div>
  <div class="page"/>
  <div class="page"/>
  <div class="page">
    <p>Conclusions</p>
    <p>Our wrappers provide provable guarantees of optimal robustness under Adversarial change model Probabilistic change model</p>
    <p>Experimentally, too: Perform much better in terms of correctness</p>
    <p>considerations Plus, they provide reliable confidence</p>
    <p>estimates</p>
  </div>
  <div class="page">
    <p>Thanks for coming!</p>
    <p>www.stanford.edu/~adityagp</p>
  </div>
</Presentation>
