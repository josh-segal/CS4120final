<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>NetKernel: Making Network Stack Part of the Virtualized Infrastructure</p>
    <p>Zhixiong Niu, Hong Xu, Peng Cheng, Qiang Su, Yongqiang Xiong, Tao Wang, Dongsu Han, Keith Winstein</p>
  </div>
  <div class="page">
    <p>Current architecture in the cloud</p>
    <p>VM</p>
    <p>APP</p>
    <p>Guest OS</p>
    <p>DCN Infrastructure</p>
    <p>Hypervisor infrastructure</p>
    <p>Network Stack</p>
    <p>VM</p>
    <p>APP</p>
    <p>Guest OS Network Stack</p>
  </div>
  <div class="page">
    <p>Whatre the fundamental limitations?</p>
  </div>
  <div class="page">
    <p>Have to deal with the network stack all by myself</p>
    <p>Motivation: Tenants</p>
    <p>TCP parameters</p>
    <p>initcwnd</p>
    <p>initialRTO (ms)</p>
    <p>minRTO (ms)</p>
    <p>DelayedAckTimeout (ms)</p>
    <p>BBR</p>
    <p>CUBIC</p>
    <p>MPTCP</p>
    <p>PCC</p>
    <p>CTCP</p>
    <p>DCTCP</p>
    <p>mTCPStackMap</p>
    <p>FastSocket</p>
    <p>MegaPipe</p>
    <p>FlexSC Kernel</p>
    <p>Buffer</p>
    <p>net.ipv4.tcp_rmem</p>
    <p>net.ipv4.tcp_wmem</p>
    <p>net.core.rmem_max</p>
    <p>net.core.wmem_max</p>
  </div>
  <div class="page">
    <p>Tenants are primarily concerned with performance and functionality, not implementation details.</p>
  </div>
  <div class="page">
    <p>KernelKernel</p>
    <p>NICNICNIC</p>
    <p>Motivation: Operator</p>
    <p>DPDK</p>
    <p>Kernel FPGARDMA</p>
    <p>NIC</p>
    <p>I know everything here. I can really help my tenants (and make some money!)</p>
  </div>
  <div class="page">
    <p>Motivation: Operator</p>
    <p>Stack</p>
    <p>VM</p>
    <p>HypervisorProvider</p>
    <p>Tenant</p>
    <p>Cant deploy new stacks (DCTCP)</p>
    <p>Difficult to perform management tasks</p>
    <p>Difficult to even define performance SLA</p>
    <p>Difficult to troubleshoot</p>
    <p>Zero visibility or control of the network stack</p>
  </div>
  <div class="page">
    <p>Is there a better way?</p>
  </div>
  <div class="page">
    <p>Making Network Stack Part of the Virtualized Infrastructure</p>
    <p>Current architecture</p>
    <p>Interface unchanged (BSD sockets, etc.)</p>
    <p>Packets handled in the NSM</p>
  </div>
  <div class="page">
    <p>Benefits</p>
    <p>Better efficiency in management for the operator  Orchestrate the resource provisioning strategies more flexibly  Implement management functions as a part of users network stack</p>
    <p>Deployment and performance gains for users without efforts  Enforce various kernel stack optimizations  Enforce high-performance userspace stacks  Use advanced hardware</p>
  </div>
  <div class="page">
    <p>Design Challenges</p>
    <p>How to transparently redirect socket API calls without changing applications?  How to transmit the socket semantics between the VM and NSM?  How to ensure high performance with semantics transmission (e.g.,</p>
  </div>
  <div class="page">
    <p>Transparent socket API redirection</p>
    <p>socket(), socket_sendmsg(),</p>
    <p>nk_socket(), nk_socket_sendmsg(),</p>
    <p>A new sock type, SOCK_NETKERNEL  GuestLib: A complete implementation of BSD socket APIs</p>
    <p>Tenant VM</p>
    <p>GuestLib nk_socket(), nk_sendmsg(),</p>
    <p>BSD Socket API socket(), send(),</p>
    <p>GuestLib</p>
  </div>
  <div class="page">
    <p>NQE: NetKernel queue elements for semantics</p>
    <p>NQE queues for semantics transmission and hugepages for data transmission in NetKernel device</p>
    <p>A lightweight semantics channel</p>
    <p>type</p>
    <p>VM ID</p>
    <p>socket ID</p>
    <p>op_data</p>
    <p>data pointer</p>
    <p>size</p>
    <p>rsved</p>
    <p>Tenant VM</p>
    <p>GuestLib nk_bind(), nk_sendmsg(),</p>
    <p>Huge pages</p>
    <p>BSD Socket API socket(), send(),</p>
    <p>NQE</p>
    <p>(2) translate to NQE</p>
    <p>(1) NetKernel socket</p>
    <p>(3) response NQE</p>
    <p>(4) return to app</p>
    <p>NetKernel device</p>
    <p>Queues</p>
  </div>
  <div class="page">
    <p>Scalable lockless queues</p>
    <p>Per-core queue set, lockless queues  NQE switching via CoreEngine</p>
    <p>VM1</p>
    <p>GuestLib</p>
    <p>NK device</p>
    <p>CoreEngine</p>
    <p>connection table</p>
    <p>queue set 1</p>
    <p>ServiceLib</p>
    <p>NSM 1</p>
    <p>&lt;VM ID, queue set ID, socket ID&gt; &lt;NSM ID, queue set ID, socket ID&gt; &lt;01, 01, 2A 3E 97 C3&gt; &lt;01, 01, C8 5D 42 6F&gt; &lt;01, 01, FC 68 4E 02&gt; &lt;01, 02, ?&gt;</p>
    <p>queue set 2queue set 1</p>
  </div>
  <div class="page">
    <p>VM based NSM.</p>
    <p>Supports existing kernel and userspace stacks from various Oses  Provide good isolation to guarantee the performance  Run stacks independent of the hypervisor</p>
  </div>
  <div class="page">
    <p>NetKernel</p>
    <p>Tenant VM</p>
    <p>GuestLib (NetKernel Socket)</p>
    <p>pNICs</p>
    <p>NetKernel device</p>
    <p>Huge pages</p>
    <p>Huge pages</p>
    <p>queues</p>
    <p>stripped area indicates a shared memory region</p>
    <p>mmap</p>
    <p>BSD Socket</p>
    <p>APP2APP1</p>
    <p>NSM</p>
    <p>ServiceLib</p>
    <p>Huge pages</p>
    <p>Network Stack</p>
    <p>NetKernel CoreEngine Virtual Switch or Embedded</p>
    <p>Switch (SR-IOV)</p>
    <p>vNIC</p>
    <p>queues</p>
  </div>
  <div class="page">
    <p>Implementation</p>
    <p>QEMU KVM 2.5.0, Linux Kernel 4.9  Intel(R) Xeon(R) 16-core CPU @ 2.30GHz x 2  256GB DDR4 2133MHz  Mellanox ConnectX-4 100G single port NIC</p>
  </div>
  <div class="page">
    <p>Use Cases #1: Multiplexing</p>
    <p>N or</p>
    <p>m al</p>
    <p>iz ed</p>
    <p>rp s</p>
    <p>pe rfo</p>
    <p>rm an</p>
    <p>ce AG1 AG2 AG3</p>
    <p>Application Gateway (AG): L7 proxy and load balancing services</p>
    <p>AG1 AG2 AG3</p>
    <p>Normalized RPS Performance of a trace from a large cloud</p>
  </div>
  <div class="page">
    <p>Use Cases #1: Multiplexing</p>
    <p>N or</p>
    <p>m al</p>
    <p>iz ed</p>
    <p>rp s</p>
    <p>pe r</p>
    <p>co re</p>
    <p>Baseline Netkernel</p>
    <p>AG1</p>
    <p>AG2</p>
    <p>AG3</p>
    <p>NSM</p>
    <p>CoreEngine</p>
    <p>NetKernel: 9 Cores Baseline: 12 Cores</p>
    <p>Benefit: NetKernel can help operator perform network management more efficiently</p>
  </div>
  <div class="page">
    <p>Use Case #2: Deploying mTCP without API Change  mTCP doesn't support Nginx yet  mTCP ported as an NSM, fixed a bug in DPDK mlx5_core driver  Unmodified Nginx on mTCP without any tenant effort</p>
    <p>Kernel Stack NSM mTCP NSM Krps</p>
    <p>mTCP NSM brings ~1.8x performance gain</p>
  </div>
  <div class="page">
    <p>Use Case #3: Shared Memory Networking</p>
    <p>T K</p>
    <p>ro u</p>
    <p>g K</p>
    <p>S u</p>
    <p>t (G</p>
    <p>b S</p>
    <p>s )</p>
    <p>Baseline</p>
    <p>The operator can easily detect the on-host traffic with NetKernel  For on-host traffic, it can use shared memory NSM to avoid TCP and</p>
    <p>bridge overhead</p>
    <p>Shared memory NSM can achieve &gt;2x performance gain for on-host traffic</p>
    <p>Deployment and performance gains for users</p>
    <p>Benefit: NetKernel can help user achieve deployment and performance gains</p>
  </div>
  <div class="page">
    <p>Microbenchmarks: Throughput</p>
    <p>Uo u</p>
    <p>g K</p>
    <p>p u</p>
    <p>t (G</p>
    <p>b p</p>
    <p>s )</p>
    <p>Baseline</p>
    <p>Baseline (a VM) and NetKernel (a VM with a Linux Kernel) using the same setting  8 TCP connections, 8KB messages</p>
    <p>Send Receive</p>
    <p>Can achieve 100Gbps with 3 cores (send), 8 cores (receive)</p>
    <p>Uo u</p>
    <p>g K</p>
    <p>p u</p>
    <p>t (G</p>
    <p>b p</p>
    <p>s )</p>
    <p>Baseline</p>
  </div>
  <div class="page">
    <p>Microbenchmarks: RPS</p>
    <p>Simple epoll server, short TCP conn.  64B request/response</p>
    <p>mTCP NSM brings 2x performance gain</p>
    <p>s /</p>
    <p>se c (</p>
    <p>x 1 0 3</p>
    <p>)</p>
    <p>Baseline</p>
    <p>P7C3</p>
  </div>
  <div class="page">
    <p>Discussion and future directions</p>
    <p>How can I do Netfilter?  Hard to support for multiple-tenant NSM</p>
    <p>What about troubleshooting performance issues?  Operator can easily monitor their NSMs by deploy additional mechanisms in the</p>
    <p>NSMs  Does NetKernel increase the attack surface?</p>
    <p>Own address spaces for NK device  Isolated channel between NSM and VM</p>
    <p>Future directions  Performance isolation  Charging policies  FPGA/SoC</p>
  </div>
  <div class="page">
    <p>Recap</p>
    <p>Designed and implemented NetKernel  Decouples the network stack from the guest  Making it part of the virtualized infrastructure in the cloud</p>
    <p>Enabled several new usecases  Multiplexing, mTCP NSM, Shared mem. NSM</p>
    <p>Conducted comprehensive testbed evaluation with commodity 100G NICs  Website  https://netkernel.net</p>
  </div>
</Presentation>
