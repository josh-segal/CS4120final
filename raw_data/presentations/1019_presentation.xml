<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>DONT CRY OVER SPILLED RECORDS Memory elasticity of data-parallel applications and its</p>
    <p>application to cluster scheduling</p>
    <p>Clin Iorgulescu (EPFL), Florin Dinu (EPFL), Aunn Raza (NUST Pakistan), Wajih Ul Hassan (UIUC), Willy Zwaenepoel (EPFL)</p>
  </div>
  <div class="page">
    <p>Cluster operators care about resource utilization</p>
    <p>Best bang for your buck!</p>
    <p>Maximize performance of data-parallel applications</p>
    <p>Idea: Efficient resource utilization through under-provisioning</p>
  </div>
  <div class="page">
    <p>Cluster memory is under-utilized!</p>
    <p>Avg. mem. utilization: 78%</p>
  </div>
  <div class="page">
    <p>Cluster memory is under-utilized!</p>
    <p>Avg. mem. utilization: 78%</p>
    <p>Leverage this idle memory!</p>
  </div>
  <div class="page">
    <p>Impact of memory constraining applications</p>
    <p>Conventional wisdom: do not touch memory!</p>
    <p>Risks:  crashes</p>
    <p>severe performance degradation (e.g., thrashing)</p>
    <p>Can we safely, deterministically, and with modest impact constrain memory?</p>
  </div>
  <div class="page">
    <p>Context: batch jobs and their memory usage</p>
  </div>
  <div class="page">
    <p>Context: batch jobs and their memory usage</p>
    <p>Input</p>
  </div>
  <div class="page">
    <p>Context: batch jobs and their memory usage</p>
    <p>Ideal memory</p>
    <p>Input</p>
  </div>
  <div class="page">
    <p>Context: batch jobs and their memory usage</p>
    <p>Ideal memory</p>
    <p>Input</p>
  </div>
  <div class="page">
    <p>Context: batch jobs and their memory usage</p>
    <p>Ideal memory</p>
    <p>Input</p>
  </div>
  <div class="page">
    <p>Context: batch jobs and their memory usage</p>
    <p>Read</p>
    <p>Ideal memory</p>
    <p>Compute Write</p>
    <p>Input</p>
    <p>Disk I/O CPU</p>
  </div>
  <div class="page">
    <p>Context: batch jobs and their memory usage</p>
    <p>Read</p>
    <p>Ideal memory</p>
    <p>Compute Write</p>
    <p>Input</p>
    <p>Ideal duration</p>
    <p>Disk I/O CPU</p>
  </div>
  <div class="page">
    <p>Context: batch jobs and their memory usage</p>
    <p>Read</p>
    <p>Ideal memory</p>
    <p>Non-ideal memory</p>
    <p>Compute Write</p>
    <p>Input</p>
    <p>Ideal duration</p>
    <p>Disk I/O CPU</p>
  </div>
  <div class="page">
    <p>Context: batch jobs and their memory usage</p>
    <p>Read</p>
    <p>Ideal memory</p>
    <p>Non-ideal memory</p>
    <p>Compute Write</p>
    <p>Input</p>
    <p>Ideal duration</p>
    <p>Disk I/O CPU</p>
  </div>
  <div class="page">
    <p>Context: batch jobs and their memory usage</p>
    <p>Read</p>
    <p>Ideal memory</p>
    <p>Non-ideal memory</p>
    <p>Compute Write</p>
    <p>Input</p>
    <p>Ideal duration</p>
    <p>Disk I/O CPU</p>
  </div>
  <div class="page">
    <p>Context: batch jobs and their memory usage</p>
    <p>Read</p>
    <p>Ideal memory</p>
    <p>Non-ideal memory</p>
    <p>Compute Write</p>
    <p>Input</p>
    <p>Ideal duration</p>
    <p>Disk I/O CPU</p>
  </div>
  <div class="page">
    <p>Context: batch jobs and their memory usage</p>
    <p>Read</p>
    <p>Ideal memory</p>
    <p>Non-ideal memory</p>
    <p>Compute Write</p>
    <p>Input</p>
    <p>Ideal duration</p>
    <p>Disk I/O CPU</p>
  </div>
  <div class="page">
    <p>Context: batch jobs and their memory usage</p>
    <p>Read</p>
    <p>Ideal memory</p>
    <p>Non-ideal memory</p>
    <p>ComputeRead</p>
    <p>Compute Write</p>
    <p>Spill Read Read Merge WriteSpill</p>
    <p>Input</p>
    <p>Ideal duration</p>
    <p>Disk I/O CPU</p>
  </div>
  <div class="page">
    <p>Context: batch jobs and their memory usage</p>
    <p>Read</p>
    <p>Ideal memory</p>
    <p>Non-ideal memory</p>
    <p>ComputeRead</p>
    <p>Compute Write</p>
    <p>Spill Read Read Merge WriteSpill</p>
    <p>Input</p>
    <p>Ideal duration</p>
    <p>Disk I/O CPU</p>
    <p>Penalty</p>
  </div>
  <div class="page">
    <p>Context: batch jobs and their memory usage</p>
    <p>Read</p>
    <p>Ideal memory</p>
    <p>Non-ideal memory</p>
    <p>ComputeRead</p>
    <p>Compute Write</p>
    <p>Spill Read Read Merge WriteSpill</p>
    <p>Input</p>
    <p>Ideal duration</p>
    <p>Disk I/O CPU</p>
    <p>Penalty</p>
    <p>Batch jobs handle memory under-provisioning  intermediate results spilled to disk</p>
  </div>
  <div class="page">
    <p>MEMORY ELASTICITY</p>
  </div>
  <div class="page">
    <p>What is Memory Elasticity?</p>
    <p>Task Heap Task Heap</p>
    <p>Non-ideal memory</p>
    <p>Disk I/O CPU</p>
  </div>
  <div class="page">
    <p>What is Memory Elasticity?</p>
    <p>Task Heap Task Heap</p>
    <p>Non-ideal memory</p>
    <p>Disk I/O CPU</p>
    <p>Safely constrain memory</p>
  </div>
  <div class="page">
    <p>What is Memory Elasticity?</p>
    <p>Task Heap Task Heap</p>
    <p>Non-ideal memory</p>
    <p>Disk I/O CPU</p>
    <p>Safely constrain memory  Moderate penalties</p>
  </div>
  <div class="page">
    <p>What is Memory Elasticity?</p>
    <p>Task Heap Task Heap</p>
    <p>Non-ideal memory</p>
    <p>Disk I/O CPU</p>
    <p>Safely constrain memory</p>
    <p>Highly predictable</p>
    <p>Moderate penalties</p>
  </div>
  <div class="page">
    <p>What is Memory Elasticity?</p>
    <p>Task Heap Task Heap</p>
    <p>Non-ideal memory</p>
    <p>Disk I/O CPU</p>
    <p>Safely constrain memory</p>
    <p>Highly predictable  Ubiquitous for most data-parallel apps</p>
    <p>Moderate penalties</p>
  </div>
  <div class="page">
    <p>An empirical study of Memory Elasticity</p>
    <p>Analysis of 18 jobs across 8 different applications</p>
    <p>Constrain tasks memory  measure penalty</p>
    <p>Bypass disk buffer cache (to not mask impact of spilling to disk)</p>
  </div>
  <div class="page">
    <p>Questions about Memory Elasticity</p>
  </div>
  <div class="page">
    <p>Questions about Memory Elasticity</p>
    <p>Are the penalties large?</p>
  </div>
  <div class="page">
    <p>Questions about Memory Elasticity</p>
    <p>Are the penalties large?</p>
    <p>Do penalties vary considerably w.r.t given memory?</p>
  </div>
  <div class="page">
    <p>Questions about Memory Elasticity</p>
    <p>Are the penalties large?</p>
    <p>Do penalties vary considerably w.r.t given memory?</p>
    <p>Does the additional I/O cause disk contention?</p>
  </div>
  <div class="page">
    <p>Questions about Memory Elasticity</p>
    <p>Are the penalties large?</p>
    <p>Do penalties vary considerably w.r.t given memory?</p>
    <p>Does the additional I/O cause disk contention?</p>
    <p>NOT SO</p>
    <p>MUCH!</p>
  </div>
  <div class="page">
    <p>Elasticity of Hadoop workloads: Reducers</p>
    <p>Nutch Indexing</p>
    <p>Pagerank 1</p>
    <p>Pagerank 2</p>
    <p>TPC-DS Q40</p>
    <p>TPC-DS Q7</p>
    <p>Conn. Comp. 1</p>
    <p>Word Count</p>
    <p>Terasort Recomm. 1</p>
    <p>Recomm. 2</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d t</p>
    <p>a sk</p>
    <p>e xe</p>
    <p>cu ti</p>
    <p>o n</p>
    <p>t im</p>
    <p>e</p>
  </div>
  <div class="page">
    <p>Elasticity of Hadoop workloads: Reducers</p>
    <p>Nutch Indexing</p>
    <p>Pagerank 1</p>
    <p>Pagerank 2</p>
    <p>TPC-DS Q40</p>
    <p>TPC-DS Q7</p>
    <p>Conn. Comp. 1</p>
    <p>Word Count</p>
    <p>Terasort Recomm. 1</p>
    <p>Recomm. 2</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d t</p>
    <p>a sk</p>
    <p>e xe</p>
    <p>cu ti</p>
    <p>o n</p>
    <p>t im</p>
    <p>e</p>
    <p>Surprise! The median penalty is &lt;1.6x!</p>
  </div>
  <div class="page">
    <p>Why are the penalties so modest?</p>
    <p>Memory pressure absorbed by data buffer Data buffer  most</p>
    <p>of app. memory</p>
    <p>Spilling records to disk is faster than OS paging Sequential disk</p>
    <p>access</p>
    <p>Merge steps required &lt;&lt; disk spills Logarithmic external</p>
    <p>merge algorithms</p>
  </div>
  <div class="page">
    <p>Elasticity of Hadoop workloads: Reducers</p>
    <p>Nutch Indexing</p>
    <p>Pagerank 1</p>
    <p>Pagerank 2</p>
    <p>TPC-DS Q40</p>
    <p>TPC-DS Q7</p>
    <p>Conn. Comp. 1</p>
    <p>Word Count</p>
    <p>Terasort Recomm. 1</p>
    <p>Recomm. 2</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d t</p>
    <p>a sk</p>
    <p>e xe</p>
    <p>cu ti</p>
    <p>o n</p>
    <p>t im</p>
    <p>e</p>
  </div>
  <div class="page">
    <p>Elasticity of Hadoop workloads: Reducers</p>
    <p>Nutch Indexing</p>
    <p>Pagerank 1</p>
    <p>Pagerank 2</p>
    <p>TPC-DS Q40</p>
    <p>TPC-DS Q7</p>
    <p>Conn. Comp. 1</p>
    <p>Word Count</p>
    <p>Terasort Recomm. 1</p>
    <p>Recomm. 2</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d t</p>
    <p>a sk</p>
    <p>e xe</p>
    <p>cu ti</p>
    <p>o n</p>
    <p>t im</p>
    <p>e</p>
    <p>Surprise! For 10%, 50%, and 90% memory, penalties vary by at most 0.25x!</p>
  </div>
  <div class="page">
    <p>Why do penalties vary so little w/ memory?</p>
    <p>Static spilling threshold  comparable data spilling for 90% and 10% of memory</p>
  </div>
  <div class="page">
    <p>Why do penalties vary so little w/ memory?</p>
    <p>Static spilling threshold  comparable data spilling for 90% and 10% of memory</p>
    <p>Input 2.1 GB Input 2.1 GB</p>
  </div>
  <div class="page">
    <p>Why do penalties vary so little w/ memory?</p>
    <p>Static spilling threshold  comparable data spilling for 90% and 10% of memory</p>
    <p>Input 2.1 GB</p>
    <p>Buffer 2 GB</p>
    <p>Input 2.1 GB</p>
  </div>
  <div class="page">
    <p>Why do penalties vary so little w/ memory?</p>
    <p>Static spilling threshold  comparable data spilling for 90% and 10% of memory</p>
    <p>Input 2.1 GB</p>
    <p>Buffer 2 GB</p>
    <p>Spills 1 x 2 GB</p>
    <p>Input 2.1 GB</p>
  </div>
  <div class="page">
    <p>Why do penalties vary so little w/ memory?</p>
    <p>Static spilling threshold  comparable data spilling for 90% and 10% of memory</p>
    <p>Input 2.1 GB</p>
    <p>Buffer 2 GB</p>
    <p>Spills 1 x 2 GB</p>
    <p>Input 2.1 GB</p>
    <p>Buffer 200 MB</p>
  </div>
  <div class="page">
    <p>Why do penalties vary so little w/ memory?</p>
    <p>Static spilling threshold  comparable data spilling for 90% and 10% of memory</p>
    <p>Input 2.1 GB</p>
    <p>Buffer 2 GB</p>
    <p>Spills 1 x 2 GB</p>
    <p>Input 2.1 GB</p>
    <p>Buffer 200 MB</p>
    <p>Spills 10 x 200 MB</p>
  </div>
  <div class="page">
    <p>Why do penalties vary so little w/ memory?</p>
    <p>Static spilling threshold  comparable data spilling for 90% and 10% of memory</p>
    <p>Input 2.1 GB</p>
    <p>Buffer 2 GB</p>
    <p>Spills 1 x 2 GB</p>
    <p>Input 2.1 GB</p>
    <p>Buffer 200 MB</p>
    <p>Spills 10 x 200 MB</p>
    <p>Total data spilled in both cases: 2GB</p>
  </div>
  <div class="page">
    <p>Elasticity of Hadoop workloads: Mappers</p>
    <p>WordCount w/ combiner</p>
    <p>Conn. Comp. 1</p>
    <p>Pagerank 2 Pagerank 1 WordCount</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d t</p>
    <p>a sk</p>
    <p>e xe</p>
    <p>cu ti</p>
    <p>o n</p>
    <p>t im</p>
    <p>e</p>
  </div>
  <div class="page">
    <p>Elasticity of Hadoop workloads: Mappers</p>
    <p>WordCount w/ combiner</p>
    <p>Conn. Comp. 1</p>
    <p>Pagerank 2 Pagerank 1 WordCount</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d t</p>
    <p>a sk</p>
    <p>e xe</p>
    <p>cu ti</p>
    <p>o n</p>
    <p>t im</p>
    <p>e</p>
    <p>Penalties are even lower! Median penalty is ~1.2x!</p>
  </div>
  <div class="page">
    <p>Elasticity of Hadoop workloads: Mappers</p>
    <p>WordCount w/ combiner</p>
    <p>Conn. Comp. 1</p>
    <p>Pagerank 2 Pagerank 1 WordCount</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d t</p>
    <p>a sk</p>
    <p>e xe</p>
    <p>cu ti</p>
    <p>o n</p>
    <p>t im</p>
    <p>e</p>
    <p>Penalties for 10%, 50%, and 90% memory vary by at most 0.05x!</p>
    <p>Penalties are even lower! Median penalty is ~1.2x!</p>
  </div>
  <div class="page">
    <p>Elasticity of Spark and Tez workloads</p>
    <p>Spark Terasort</p>
    <p>Spark WordCount</p>
    <p>Tez SortMergeJoin</p>
    <p>Tez WordCount</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d t</p>
    <p>a sk</p>
    <p>e xe</p>
    <p>cu ti</p>
    <p>o n</p>
    <p>t im</p>
    <p>e</p>
  </div>
  <div class="page">
    <p>Elasticity of Spark and Tez workloads</p>
    <p>Spark Terasort</p>
    <p>Spark WordCount</p>
    <p>Tez SortMergeJoin</p>
    <p>Tez WordCount</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d t</p>
    <p>a sk</p>
    <p>e xe</p>
    <p>cu ti</p>
    <p>o n</p>
    <p>t im</p>
    <p>e</p>
    <p>Median penalty is ~1.75x!</p>
  </div>
  <div class="page">
    <p>Elasticity of Spark and Tez workloads</p>
    <p>Spark Terasort</p>
    <p>Spark WordCount</p>
    <p>Tez SortMergeJoin</p>
    <p>Tez WordCount</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d t</p>
    <p>a sk</p>
    <p>e xe</p>
    <p>cu ti</p>
    <p>o n</p>
    <p>t im</p>
    <p>e</p>
    <p>Penalties for 10%, 50%, and 90% memory vary by at most 0.3x!</p>
    <p>Median penalty is ~1.75x!</p>
  </div>
  <div class="page">
    <p>Does the additional I/O cause disk contention?</p>
    <p>Measure slowdown of elastic tasks on same machine spilling to the same disk</p>
    <p>Number of concurrent reducers</p>
  </div>
  <div class="page">
    <p>Does the additional I/O cause disk contention?</p>
    <p>Measure slowdown of elastic tasks on same machine spilling to the same disk</p>
    <p>Cluster operators usually provision  1 disk / 2 cores*  &lt;10% slowdown!</p>
    <p>* Facebook (2010) and Nutanix Number of concurrent reducers</p>
  </div>
  <div class="page">
    <p>Does the additional I/O cause disk contention?</p>
    <p>Measure slowdown of elastic tasks on same machine spilling to the same disk</p>
    <p>Cluster operators usually provision  1 disk / 2 cores*  &lt;10% slowdown!</p>
    <p>Degradation &lt;25% for up to 1 disk / 5 cores!</p>
    <p>* Facebook (2010) and Nutanix Number of concurrent reducers</p>
  </div>
  <div class="page">
    <p>Summary: Memory Elasticity of real workloads</p>
    <p>Modest performance penalties (&lt;1.6x median)</p>
    <p>Similar penalties for 10% and 90% of ideal memory</p>
    <p>Disk contention negligible for existing clusters setup (&lt;10%)</p>
  </div>
  <div class="page">
    <p>MODELING MEMORY ELASTICITY</p>
  </div>
  <div class="page">
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d t</p>
    <p>a sk</p>
    <p>e</p>
    <p>xe cu</p>
    <p>ti o</p>
    <p>n t</p>
    <p>im e</p>
    <p>Percentage of ideal memory</p>
    <p>Modeling Memory Elasticity</p>
    <p>How does penalty vary for a task?</p>
  </div>
  <div class="page">
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d t</p>
    <p>a sk</p>
    <p>e</p>
    <p>xe cu</p>
    <p>ti o</p>
    <p>n t</p>
    <p>im e</p>
    <p>Percentage of ideal memory</p>
    <p>Modeling Memory Elasticity</p>
    <p>How does penalty vary for a task?</p>
    <p>Penalty = f ( disk speed, input size, framework configuration )</p>
  </div>
  <div class="page">
    <p>Modeling Memory Elasticity</p>
    <p>Penalties vary little between percentages  step model</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d t</p>
    <p>a sk</p>
    <p>e</p>
    <p>xe cu</p>
    <p>ti o</p>
    <p>n t</p>
    <p>im e</p>
    <p>Percentage of ideal memory</p>
  </div>
  <div class="page">
    <p>Modeling Memory Elasticity</p>
    <p>Penalties vary little between percentages  step model</p>
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d t</p>
    <p>a sk</p>
    <p>e</p>
    <p>xe cu</p>
    <p>ti o</p>
    <p>n t</p>
    <p>im e</p>
    <p>Percentage of ideal memory</p>
    <p>Disk I/ O overhead</p>
  </div>
  <div class="page">
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d t</p>
    <p>a sk</p>
    <p>e</p>
    <p>xe cu</p>
    <p>ti o</p>
    <p>n t</p>
    <p>im e</p>
    <p>Percentage of ideal memory</p>
    <p>Modeling Memory Elasticity</p>
    <p>Requires 2 profiling runs  infers all other points</p>
  </div>
  <div class="page">
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d t</p>
    <p>a sk</p>
    <p>e</p>
    <p>xe cu</p>
    <p>ti o</p>
    <p>n t</p>
    <p>im e</p>
    <p>Percentage of ideal memory</p>
    <p>Modeling Memory Elasticity</p>
    <p>Requires 2 profiling runs  infers all other points</p>
    <p>Ideal memoryNon-ideal memory</p>
  </div>
  <div class="page">
    <p>N o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d t</p>
    <p>a sk</p>
    <p>e</p>
    <p>xe cu</p>
    <p>ti o</p>
    <p>n t</p>
    <p>im e</p>
    <p>Percentage of ideal memory</p>
    <p>Modeling Memory Elasticity</p>
    <p>Requires 2 profiling runs  infers all other points</p>
    <p>Ideal memoryNon-ideal memory</p>
    <p>The step model represents our baseline. More complex models are possible.</p>
  </div>
  <div class="page">
    <p>Accuracy of our reducer model</p>
    <p>Pagerank 1</p>
    <p>Pagerank 2</p>
    <p>TPC-DS Q7</p>
    <p>TPC-DS Q40</p>
    <p>Conn. Comp. 1</p>
    <p>Terasort Recomm. 1</p>
    <p>Recomm. 2</p>
    <p>Word Count</p>
    <p>Nutch Indexing</p>
    <p>Spark Terasort</p>
    <p>Tez SMJ</p>
    <p>Tez Word Count</p>
    <p>R e</p>
    <p>a l</p>
    <p>d u</p>
    <p>ra ti</p>
    <p>o n</p>
    <p>n o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d t</p>
    <p>o m</p>
    <p>o d</p>
    <p>e l</p>
    <p>Avg. offset</p>
  </div>
  <div class="page">
    <p>Accuracy of our reducer model</p>
    <p>Pagerank 1</p>
    <p>Pagerank 2</p>
    <p>TPC-DS Q7</p>
    <p>TPC-DS Q40</p>
    <p>Conn. Comp. 1</p>
    <p>Terasort Recomm. 1</p>
    <p>Recomm. 2</p>
    <p>Word Count</p>
    <p>Nutch Indexing</p>
    <p>Spark Terasort</p>
    <p>Tez SMJ</p>
    <p>Tez Word Count</p>
    <p>R e</p>
    <p>a l</p>
    <p>d u</p>
    <p>ra ti</p>
    <p>o n</p>
    <p>n o</p>
    <p>rm a</p>
    <p>li ze</p>
    <p>d t</p>
    <p>o m</p>
    <p>o d</p>
    <p>e l</p>
    <p>Most reducers are off at most by +/- 5%!</p>
    <p>Avg. offset</p>
  </div>
  <div class="page">
    <p>Summary: Modeling memory elasticity</p>
    <p>Step model is adequate (more complex models available)</p>
    <p>Only 2 profiling points  full model</p>
    <p>Models are very robust (+/- 5% error for most reducers)</p>
  </div>
  <div class="page">
    <p>LEVERAGING MEMORY ELASTICITY IN CLUSTER SCHEDULING</p>
  </div>
  <div class="page">
    <p>How can a scheduler reason about Memory Elasticity?</p>
    <p>Trade-off between</p>
    <p>task queueing time  task execution time</p>
    <p>Elastic allocation</p>
    <p>m e</p>
    <p>m o</p>
    <p>ry</p>
    <p>m e</p>
    <p>m o</p>
    <p>ry</p>
    <p>time time</p>
  </div>
  <div class="page">
    <p>YARN-ME: Decision process</p>
    <p>Make an elastic allocation iff it does not exceed the expected job completion time</p>
    <p>time</p>
    <p>time</p>
    <p>m e</p>
    <p>m o</p>
    <p>ry m</p>
    <p>e m</p>
    <p>o ry</p>
    <p>m e</p>
    <p>m o</p>
    <p>ry</p>
    <p>YARN (no ME)</p>
    <p>YARN-ME</p>
    <p>YARN-ME time</p>
  </div>
  <div class="page">
    <p>YARN-ME: Design and components</p>
    <p>YARN-ME</p>
    <p>Timeline generator</p>
    <p>Resource Manager</p>
    <p>Job ME metadata</p>
    <p>Ideal duration Ideal memory Penalty</p>
    <p>Components</p>
    <p>Timeline generator  computes expected JCTs</p>
    <p>Profiler  generates the model metadata</p>
    <p>Profiler</p>
  </div>
  <div class="page">
    <p>Memory utilization analysis for YARN-ME</p>
    <p>50 node cluster  Homogeneous trace: 5x Pagerank jobs</p>
  </div>
  <div class="page">
    <p>Memory utilization analysis for YARN-ME</p>
    <p>50 node cluster  Homogeneous trace: 5x Pagerank jobs</p>
    <p>Memory utilization increased to 95%</p>
  </div>
  <div class="page">
    <p>Total Pagerank Recommender WordCount</p>
    <p>YA R</p>
    <p>N -M</p>
    <p>E i</p>
    <p>m p</p>
    <p>ro v</p>
    <p>e m</p>
    <p>e n</p>
    <p>t o</p>
    <p>v e</p>
    <p>r YA</p>
    <p>R N</p>
    <p>(%</p>
    <p>) JCT Makespan MAP REDUCE</p>
    <p>What gains can YARN-ME achieve for heterogeneous workloads?</p>
    <p>50 node cluster  Mixed trace  14 jobs</p>
    <p>3x PageRank  3x Recommender  8x Wordcount</p>
  </div>
  <div class="page">
    <p>Total Pagerank Recommender WordCount</p>
    <p>YA R</p>
    <p>N -M</p>
    <p>E i</p>
    <p>m p</p>
    <p>ro v</p>
    <p>e m</p>
    <p>e n</p>
    <p>t o</p>
    <p>v e</p>
    <p>r YA</p>
    <p>R N</p>
    <p>(%</p>
    <p>) JCT Makespan MAP REDUCE</p>
    <p>What gains can YARN-ME achieve for heterogeneous workloads?</p>
    <p>50 node cluster  Mixed trace  14 jobs</p>
    <p>3x PageRank  3x Recommender  8x Wordcount</p>
    <p>Up to 65% improvement for JCT and makespan</p>
  </div>
  <div class="page">
    <p>YA R</p>
    <p>N -M</p>
    <p>E i</p>
    <p>m p</p>
    <p>ro v</p>
    <p>e m</p>
    <p>e n</p>
    <p>t o</p>
    <p>v e</p>
    <p>r YA</p>
    <p>R N</p>
    <p>(%</p>
    <p>) JCT Makespan MAP REDUCE</p>
    <p>What gains can YARN-ME achieve for homogeneous workloads?</p>
    <p>50 node cluster  Pagerank</p>
    <p>concurrent runs</p>
  </div>
  <div class="page">
    <p>YA R</p>
    <p>N -M</p>
    <p>E i</p>
    <p>m p</p>
    <p>ro v</p>
    <p>e m</p>
    <p>e n</p>
    <p>t o</p>
    <p>v e</p>
    <p>r YA</p>
    <p>R N</p>
    <p>(%</p>
    <p>) JCT Makespan MAP REDUCE</p>
    <p>What gains can YARN-ME achieve for homogeneous workloads?</p>
    <p>50 node cluster  Pagerank</p>
    <p>concurrent runs</p>
    <p>Up to 40% improvement for JCT and makespan</p>
  </div>
  <div class="page">
    <p>Trace-driven simulation of YARN-ME</p>
    <p>We built DSS (the Discrete Scheduler Simulator)  and it is open-source!</p>
    <p>Trace parameter sweep</p>
    <p>&gt; 8,000 traces  up to 3,000 nodes  results comparable to</p>
    <p>real workloads</p>
    <p>Robustness analysis</p>
    <p>&gt; 20,000 traces  YARN-ME is robust to</p>
    <p>model mis-estimations</p>
  </div>
  <div class="page">
    <p>Related work</p>
    <p>Efficient packing  better resource utilization  Tetris [SIGCOMM 14], GRAPHENE [OSDI 16]</p>
    <p>Collocate batch-jobs with latency-critical services  Heracles [ISCA 15]</p>
    <p>Resource over-committing  Apollo [OSDI 14], Borg [EuroSys 15]</p>
    <p>Suspend tasks under memory pressure  ITask [SOSP 15]</p>
  </div>
  <div class="page">
    <p>Conclusion: Dont cry over spilled records!</p>
    <p>Memory Elasticity  highly predictable, low penalty</p>
    <p>Memory Elasticity in scheduling  trade task queueing-time for running-time</p>
    <p>YARN-ME  up to 60% improvement in average JCT</p>
    <p>DSS code available: https://github.com/epfl-labos/dss</p>
  </div>
</Presentation>
