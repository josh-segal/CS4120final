<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Probabilistic XML via Markov Chains</p>
    <p>VLDB. Singapore. Sept. 2010</p>
    <p>Evgeny Kharlamov</p>
    <p>Joint work with</p>
    <p>Michael Benedikt Dan Olteanu Pierre Senellart Oxford University Oxford University Tlcom ParisTech</p>
    <p>Free University of Bozen-Bolzano; INRIA Saclay  le-de-France</p>
  </div>
  <div class="page">
    <p>(Web) information extraction  Processing manually entered data (such as census forms)  Data integration, data cleaning  Managing scientific data; sensor data  Risk management / predictions  ...</p>
    <p>Uncertain Data is Commonplace</p>
    <p>Probabilities are a way to deal with uncertain data</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Dealing with Probabilistic Data</p>
    <p>Traditional DBMSs: not meant to deal with probabilistic data  Ad hoc approaches: not very satisfactory  Recent years: advances in developing  representation systems for incomplete/probabilistic data  uncertainty-aware query languages  ...</p>
    <p>Probabilistic relational DBMSs: MayBMS, MystiQ, PrDB, Trio, ...</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Probabilistic XML Today: PrXML Model [Kimelfeld&amp;al:2007] [Abiteboul&amp;al:2009]</p>
    <p>f - event: fresh Pr(f) = 0.4</p>
    <p>MUX - distributional node, mutually exclusive options</p>
    <p>root</p>
    <p>name</p>
    <p>Tones</p>
    <p>grant</p>
    <p>EU</p>
    <p>KRDB</p>
    <p>id project prof</p>
    <p>team team</p>
    <p>name bonus</p>
    <p>id</p>
    <p>prof</p>
    <p>name bonus</p>
    <p>MUX</p>
    <p>Diego 2 Bogdan</p>
    <p>DBWeb</p>
    <p>f f</p>
    <p>dur.</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Probabilistic XML Today: PrXML Model [Kimelfeld&amp;al:2007] [Abiteboul&amp;al:2009]</p>
    <p>f - event: fresh Pr(f) = 0.4</p>
    <p>MUX - distributional node, mutually exclusive options</p>
    <p>Probabilistic XML documents (compactly) represent probability spaces of ordinary XML documents</p>
    <p>root</p>
    <p>name</p>
    <p>Tones</p>
    <p>grant</p>
    <p>EU</p>
    <p>KRDB</p>
    <p>id project prof</p>
    <p>team team</p>
    <p>name bonus</p>
    <p>id</p>
    <p>prof</p>
    <p>name bonus</p>
    <p>MUX</p>
    <p>Diego 2 Bogdan</p>
    <p>DBWeb</p>
    <p>f f</p>
    <p>dur.</p>
    <p>Example world:  f = true (the data is outdated), probability of this choice: 0.4  MUX: 4, probability of this choice: 0.1</p>
    <p>probability of this world is 0.4 x 0.1</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Probabilistic XML Today</p>
    <p>Trees enhanced with distributional nodes and event formulas that define the probabilistic process that generates random trees</p>
    <p>Proposed PrXML representation systems mirror the relational case</p>
    <p>[Kimelfeld&amp;al09]</p>
    <p>[Cohen&amp;al09]</p>
    <p>[Abiteboul&amp;al10]</p>
    <p>[Cohen&amp;al09]</p>
    <p>[Abiteboul&amp;al10]</p>
    <p>[Kharlamov&amp;al10]</p>
    <p>Widely studied in recent years:  Query answering  Aggregating  Constraints  Continuous models  Typing  Updates</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Properties of PrXML Model</p>
    <p>Trees represented by PrXML document T have bounded height &amp; width:  height: at most the height of T  width: at most the width of T</p>
    <p>Number of represented XML documents is bounded:</p>
    <p>at most exp. many in |T|</p>
    <p>root</p>
    <p>name</p>
    <p>Tones</p>
    <p>grant</p>
    <p>EU</p>
    <p>KRDB</p>
    <p>id project prof</p>
    <p>team team</p>
    <p>name bonus</p>
    <p>id</p>
    <p>prof</p>
    <p>name bonus</p>
    <p>MUX</p>
    <p>Diego 2 Bogdan</p>
    <p>DBWeb</p>
    <p>c c</p>
    <p>dur.</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Try to make a probabilistic model of a mailbox with PrXML:  Unbounded # of threads /messages ~ unbounded width / height of docs  The deeper the thread, the lower its probability</p>
    <p>Properties of PrXML Model</p>
    <p>Trees represented by PrXML document T have bounded height &amp; width:  height: at most the height of T  width: at most the width of T</p>
    <p>Number of represented XML documents is bounded:</p>
    <p>at most exp. many in |T|</p>
    <p>root</p>
    <p>name</p>
    <p>Tones</p>
    <p>grant</p>
    <p>EU</p>
    <p>KRDB</p>
    <p>id project prof</p>
    <p>team team</p>
    <p>name bonus</p>
    <p>id</p>
    <p>prof</p>
    <p>name bonus</p>
    <p>MUX</p>
    <p>Diego 2 Bogdan</p>
    <p>DBWeb</p>
    <p>c c</p>
    <p>dur.</p>
    <p>No chance with PrXML  we need models akin to probabilistic DTDs</p>
    <p>D R A</p>
    <p>F T</p>
    <p>Mailbox DTD</p>
    <p>mailbox: (thread)</p>
    <p>thread: (message, id, subject) message: (from, to, content, message)</p>
    <p>from: #PCDATA to: #PCDATA</p>
    <p>content: #PCDATA subject: #PCDATA</p>
    <p>Electricity Consumption DTD</p>
    <p>electr-cons: (room1, room2)</p>
    <p>room1: (measurement)</p>
    <p>room2: (measurement)</p>
    <p>measurement: (date, value)</p>
    <p>date: #PCDATA value: #PCDATA</p>
    <p>Figure 3: On the left: Mailbox DTD; on the right: Electricity Consumption DTD</p>
    <p>In this section, we present more formally the syntax and semantics of the PrXML model. We first focus on a discrete model (to represent discrete probability distributions) and then extend it to</p>
    <p>allow continuous data values.</p>
    <p>We model XML documents as unranked, unordered, labeled trees. Not taking into account the</p>
    <p>order between sibling nodes in an XML document is a common but non-crucial assumption.</p>
    <p>The same modeling can be done for ordered trees, without much change to the theory. A finite probability space over documents, px-space for short, is a pair (D, Pr), where D is a finite set of documents and Pr maps each document to a probability Pr(d) such that</p>
    <p>{Pr(d) | d  D} = 1.</p>
    <p>p-Documents: Syntax. The PrXML model from (Kimelfeld et al., 2009; Abiteboul et al., 2009) uses p-documents to represent px-spaces in a compact way. As already discussed, a pdocument is similar to a document, with the difference that it has two types of nodes: ordinary and</p>
    <p>distributional. Distributional nodes are used for defining the probabilistic process that generates</p>
    <p>random documents but they do not actually occur in these. Ordinary nodes have labels and they</p>
    <p>may appear in random documents. We require the leaves and the root to be ordinary nodes.</p>
    <p>More precisely, we assume given a set X of independent Boolean random variables with some specified probability distribution  over them. A p-document, denoted by P, is an unranked, unordered, labeled tree. Each node has a unique identifier u and a label (u) in L {cie(E)}E {mux(Pr)}Pr {det} where L are labels of ordinary nodes, and the others are labels of distributional nodes. We consider three kinds of the latter labels: cie(E) (for conjunction of independent events), mux(Pr) (for mutually exclusive), and det (for deterministic). If a node u is labeled with cie(E), then E is a function that assigns to each child of u a conjunction e1 ek of literals (x or x, for x  X ). If u is labeled with mux(Pr), then Pr assigns to each child of u a probability with the sum across children equal to 1.</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Goal of This Work</p>
    <p>Identify limitations of existing probabilistic representation systems</p>
    <p>key limitations: expressiveness and succinctness  Develop</p>
    <p>systems that naturally capture other formalisms for representing classes of XML documents</p>
    <p>E.g. DTDs or XML schemas  Understand</p>
    <p>what properties of new systems allow query tractability</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Probabilistic Data and What We Want to Study  Recursive Markov Chains (RMCs)  Probabilistic XML via RMCs  Querying RMCs</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Recursive Markov Chains</p>
    <p>Markov Chains  Graphs whose edges are labeled with</p>
    <p>probabilities</p>
    <p>Define processes evolving via independent choices at nodes</p>
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>[Etessami,Yannakakis09]</p>
    <p>Recursive Markov Chains  Markov Chains with recursive calls  RMC runs have a natural hierarchical</p>
    <p>structure - nested words or trees</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Recursive Markov Chains - Example</p>
    <p>RMC with four components D, P, N, and T  Each component has  a label, e.g., directory is the label of D  nodes: entry, exit, call, return, others  boxes to simulate calls to other components,</p>
    <p>e.g., box P inside D</p>
    <p>transitions (u, pu, v, v) from source u to destination v with probability pu, v; For each source u:</p>
    <p>D is the start component, no calls to D are allowed.</p>
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>{v|(u,pu,v ,v)}</p>
    <p>pu,v = 1</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Recursive Markov Chains - Applications</p>
    <p>Variants of (R)MCs are well-understood and researched in</p>
    <p>Machine learning (e.g., hidden Markov models)</p>
    <p>Computational linguistics (e.g., stochastic CFGs)</p>
    <p>Verification (e.g. probabilistic automata)</p>
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>[Manning,Schuetze99]</p>
    <p>[Bishop06]</p>
    <p>[Kwiatkowska03]</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Probabilistic Data and What We Want to Study  Recursive Markov Chains (RMCs)  Probabilistic XML via RMCs  Querying RMCs</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Entering a component labeled L = generation of an opening tag &lt;L&gt;</p>
    <p>Exiting a component labeled L = generation of a closing tag &lt;/L&gt;</p>
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>Recursive Markov Chains - Tree Generators</p>
    <p>&lt;/directory&gt;</p>
    <p>&lt;/phone&gt; &lt;phone&gt; &lt;/name&gt;</p>
    <p>Pr = 10.8 Pr = 1 Pr = 1 Pr = 10.5 Pr = 1 Pr = 10.5 Pr = 10.2</p>
    <p>Pr(d) = 0.80.50.50.2</p>
    <p>&lt;directory&gt; &lt;person&gt;</p>
    <p>&lt;name&gt;</p>
    <p>&lt;/person&gt;</p>
    <p>Document d</p>
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>A run generates a skeleton of a document  Empty components N and D can model</p>
    <p>the actual data, i.e., names and telephone numbers of people</p>
    <p>&lt;/directory&gt;</p>
    <p>&lt;/phone&gt; &lt;phone&gt; &lt;/name&gt;</p>
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>Pr = 10.8 Pr = 1 Pr = 1 Pr = 10.5 Pr = 1 Pr = 10.5 Pr = 10.2</p>
    <p>Recursive Markov Chains - Tree Generators</p>
    <p>Pr(d) = 0.80.50.50.2</p>
    <p>&lt;directory&gt; &lt;person&gt;</p>
    <p>&lt;name&gt;</p>
    <p>&lt;/person&gt;</p>
    <p>Document d</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Advantages of RMCs over PrXML  More natural, e.g., akin to probabilistic DTDs  We connect questions on prob. XML to</p>
    <p>tools and techniques of Markov models</p>
    <p>&lt;/directory&gt;</p>
    <p>&lt;/phone&gt; &lt;phone&gt; &lt;/name&gt;</p>
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>Pr = 10.8 Pr = 1 Pr = 1 Pr = 10.5 Pr = 1 Pr = 10.5 Pr = 10.2</p>
    <p>Recursive Markov Chains - Tree Generators</p>
    <p>Pr(d) = 0.80.50.50.2</p>
    <p>&lt;directory&gt; &lt;person&gt;</p>
    <p>&lt;name&gt;</p>
    <p>&lt;/person&gt;</p>
    <p>Document d</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>Probabilities of generated documents:  RMC: could be irrational, doubly exponentially small in the size of RMC  PrXML: always rational and at most exponentially small</p>
    <p>Size of generated documents:  RMC: could be</p>
    <p>Unbounded width ~ cycles inside a component  Unbounded depth ~ cycles across components</p>
    <p>PrXML: always linearly bounded by size of probabilistic document</p>
    <p>Probability Spaces of RMCs vs PrXML</p>
    <p>Comes from properties of RMCs</p>
    <p>PrXML models with distributional nodes are subsumed by RMC</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Probabilistic Data and What We Want to Study  Recursive Markov Chains (RMCs)  Probabilistic XML via RMCs  Querying RMCs</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Given: an RMC and a property, e.g., MSO formula, Boolean XPath query Task: verify whether the RMC satisfies the property</p>
    <p>P = 0.3 P = 0.2 P = 0.5</p>
    <p>Yes</p>
    <p>Prob. space of XML docs RMC</p>
    <p>sem antics root</p>
    <p>grant</p>
    <p>FP6</p>
    <p>name</p>
    <p>Tones</p>
    <p>KRDB</p>
    <p>id project prof</p>
    <p>team team</p>
    <p>name bonus</p>
    <p>id</p>
    <p>Diego 2</p>
    <p>DBWeb</p>
    <p>root</p>
    <p>team</p>
    <p>id</p>
    <p>prof</p>
    <p>name bonus</p>
    <p>DBWeb</p>
    <p>root</p>
    <p>KRDB</p>
    <p>id</p>
    <p>team</p>
    <p>No P = 0.7P = 0.3</p>
    <p>distribution for distribution for</p>
    <p>Querying RMC</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>Figure 1: RMC Aex of Examples ??, ??, and ?? Formally, a p-document is an unranked, ordered, labeled</p>
    <p>tree. Each node has a unique identifier v and a label (v) in L{exp(Pr)}{mux(Pr)}{det}. We consider distributional nodes that define discrete probability distributions Pr over the subsets of their children. In the case of mux nodes, we impose that all subsets have cardinality less than or equal</p>
    <p>to 1, that is, we select either no children at all, or a single</p>
    <p>child. A det node deterministically chooses all its children. The semantics of a p-document P, denoted P, is the</p>
    <p>px-space obtained from the following randomized three-step</p>
    <p>process (see [?] for a more detailed presentation): (i) Independently for each exp(Pr) node, we select a subset of its children (according to the corresponding probability dis</p>
    <p>tribution Pr) and delete the other children and the entire subtrees underneath. Independently for each mux(Pr) node, we select either zero or one child (according to Pr) and delete the other children and the entire subtrees underneath. We</p>
    <p>do not delete any children of det nodes. The probability of this run of the process is defined as the product of all</p>
    <p>choices. (ii) We then remove each distributional node, connecting each ordinary node with its closest ordinary ancestor.</p>
    <p>(iii) The resulting px-space is formed of arbitrary representatives of each isomorphism class of the documents obtained</p>
    <p>after step (??). The probability of a document is the sum of probabilities of every run that generated an isomorphic</p>
    <p>image of it. Note that because we consider all possible runs,</p>
    <p>the order of the choice made in step (??) is irrelevant. We denote classes of p-documents by PrXML with the al</p>
    <p>lowed types of distributional nodes as superscripts. We recall</p>
    <p>the following results from [?]: PrXMLmux cannot represent all finite distributions of documents, yet PrXMLmux,det can, and PrXMLmux,det poly PrXMLexp. Also, PrXMLexp is tractable for MSO [?].</p>
    <p>context of document generation, and study their relationship</p>
    <p>with prior probabilistic XML models.</p>
    <p>Definition 1. A recursive Markov chain A, is a tuple A = (A0,    ,Ak,), where  labels each Ai with an element from L {} and every component Ai is a graph Ai = (Ni,Neni ,Nexi ,Bi,Yi,i) that consists of:</p>
    <p>(i) A set Ni of nodes, a subset of entry nodes Neni Ni, and a subset of exit nodes Nexi Ni;</p>
    <p>(ii) A set Bi of boxes, and a mapping Yi : Bi  {1, . . . ,k} that assigns to every box (the index of) one of the com</p>
    <p>ponents, A1, . . . ,Ak. To each box bBi, we associate the sets of call ports, Call(b) = {(b,en) | en NenYi(b)} and return ports, Return(b) = {(b,ex) | ex  NexYi(b)}, that indicate, respectively, the entries and the exits of</p>
    <p>the component corresponding to b; (iii) A transition relation i, where transitions are of the</p>
    <p>form (u,pu,v,v) and</p>
    <p>(a) the source u is either a non-exit node uNi\Nexi , or a return port u = (b,ex) of a box bBi,</p>
    <p>(b) the destination v is either a non-entry node v  Ni\Neni , or a call port u = (b,en) of a box bBi,</p>
    <p>(c) pu,v is the probability of transiting from u to v. For each u that is neither a call port nor exit node we have  {v|(u,pu,v,v)i}</p>
    <p>pu,v = 1.</p>
    <p>We distinguish one component in A, say A0, as the initial component, and within that component an initial node a0  Nen0 and a set of final nodes F0 Nex0 . We also require that no box in the RMC is mapped to A0, and that (A0) = .</p>
    <p>RMCs can be depicted graphically as follows: The compo</p>
    <p>nents are represented as rectangles containing Markov chains</p>
    <p>with inner rectangles corresponding to boxes. The name of</p>
    <p>the component each box is mapped to is given inside the</p>
    <p>box. In the following figures, the initial component is the</p>
    <p>one at the top-left, and it has a single initial node and a</p>
    <p>single final node. The name of a component is given above</p>
    <p>the rectangle, along with its label.</p>
    <p>Example 2. Figure ?? partially shows an RMC Aex with four components D, P , N, and T . For instance, the label of D is (D) = directory. D either calls P with probability 0.8 or exits with probability 0.2, and this choice can occur</p>
    <p>again after returning from the call. The components N: name and T : phone are not depicted; both have a single edge going from the entrance to the exit with probability 1.</p>
    <p>The -transitions for D are: (a0,1,u1), (u1,0.2, t), also (u1,0.8,(P,en)), and ((P,ex),1,u1), where t is the exit node, u1 is the only node pointed to by a0, (P,en) is the call port for box P, and (P,ex) is the return port for box P.</p>
    <p>Intuitively, a run of an RMC generates a document d in a top-down fashion where a call of a box (corresponding to a</p>
    <p>component) labeled l inside another box (corresponding to a component) labeled l generates a node l in d that is a child of l. If a box is labeled , then it generates nothing, though calls within its component may still generate labels. We next</p>
    <p>formalize this via an alternative description of RMCs.</p>
    <p>A vertex of Ai is either a node in Ai, a call port, or a return port. Let Vi denote the set of all vertices of Ai. Thus, the transition relation i is a set of probability-weighted directed edges on Vi. Let V =</p>
    <p>i Vi, and N, B, Y , and  be</p>
    <p>the unions of the corresponding sets. We denote by qu,ex the probability that starting with u one eventually reaches an exit ex in the same component as u.</p>
    <p>Definition 3. An RMC A defines a global (denumerable) Markov chain MA = (St,) as follows:</p>
    <p>The global states St BV (Tag(L){}) of MA are triples of the form (,u,), where  is a (possibly empty) sequence of boxes from B that represents the stack of pending recursive calls, u is the current vertex of A, and  is an optional tag.</p>
    <p>The function  defines probability-weighted directed edges between global states  : (St  St)  [0,1]:</p>
    <p>(i) If (u,pu,v,v)  , then for every sequence of boxes  and   Tag(L) {} there is a -transition from (,u,) to (,v,) with probability pu,v.</p>
    <p>(ii) If (b,en)  Call(b) and (AY (b)) = lL, then for every  and  there is a -transition from (,(b,en),) to (b,en,l) with probability 1.</p>
    <p>(iii) If (b,ex)  Return(b), and (AY (b)) = l L, then for every  and  there is a -transition from (b,ex,) to (,(b,ex),/l) with probability 1.</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>Figure 1: RMC Aex of Examples ??, ??, and ?? Formally, a p-document is an unranked, ordered, labeled</p>
    <p>tree. Each node has a unique identifier v and a label (v) in L{exp(Pr)}{mux(Pr)}{det}. We consider distributional nodes that define discrete probability distributions Pr over the subsets of their children. In the case of mux nodes, we impose that all subsets have cardinality less than or equal</p>
    <p>to 1, that is, we select either no children at all, or a single</p>
    <p>child. A det node deterministically chooses all its children. The semantics of a p-document P, denoted P, is the</p>
    <p>px-space obtained from the following randomized three-step</p>
    <p>process (see [?] for a more detailed presentation): (i) Independently for each exp(Pr) node, we select a subset of its children (according to the corresponding probability dis</p>
    <p>tribution Pr) and delete the other children and the entire subtrees underneath. Independently for each mux(Pr) node, we select either zero or one child (according to Pr) and delete the other children and the entire subtrees underneath. We</p>
    <p>do not delete any children of det nodes. The probability of this run of the process is defined as the product of all</p>
    <p>choices. (ii) We then remove each distributional node, connecting each ordinary node with its closest ordinary ancestor.</p>
    <p>(iii) The resulting px-space is formed of arbitrary representatives of each isomorphism class of the documents obtained</p>
    <p>after step (??). The probability of a document is the sum of probabilities of every run that generated an isomorphic</p>
    <p>image of it. Note that because we consider all possible runs,</p>
    <p>the order of the choice made in step (??) is irrelevant. We denote classes of p-documents by PrXML with the al</p>
    <p>lowed types of distributional nodes as superscripts. We recall</p>
    <p>the following results from [?]: PrXMLmux cannot represent all finite distributions of documents, yet PrXMLmux,det can, and PrXMLmux,det poly PrXMLexp. Also, PrXMLexp is tractable for MSO [?].</p>
    <p>context of document generation, and study their relationship</p>
    <p>with prior probabilistic XML models.</p>
    <p>Definition 1. A recursive Markov chain A, is a tuple A = (A0,    ,Ak,), where  labels each Ai with an element from L {} and every component Ai is a graph Ai = (Ni,Neni ,Nexi ,Bi,Yi,i) that consists of:</p>
    <p>(i) A set Ni of nodes, a subset of entry nodes Neni Ni, and a subset of exit nodes Nexi Ni;</p>
    <p>(ii) A set Bi of boxes, and a mapping Yi : Bi  {1, . . . ,k} that assigns to every box (the index of) one of the com</p>
    <p>ponents, A1, . . . ,Ak. To each box bBi, we associate the sets of call ports, Call(b) = {(b,en) | en NenYi(b)} and return ports, Return(b) = {(b,ex) | ex  NexYi(b)}, that indicate, respectively, the entries and the exits of</p>
    <p>the component corresponding to b; (iii) A transition relation i, where transitions are of the</p>
    <p>form (u,pu,v,v) and</p>
    <p>(a) the source u is either a non-exit node uNi\Nexi , or a return port u = (b,ex) of a box bBi,</p>
    <p>(b) the destination v is either a non-entry node v  Ni\Neni , or a call port u = (b,en) of a box bBi,</p>
    <p>(c) pu,v is the probability of transiting from u to v. For each u that is neither a call port nor exit node we have  {v|(u,pu,v,v)i}</p>
    <p>pu,v = 1.</p>
    <p>We distinguish one component in A, say A0, as the initial component, and within that component an initial node a0  Nen0 and a set of final nodes F0 Nex0 . We also require that no box in the RMC is mapped to A0, and that (A0) = .</p>
    <p>RMCs can be depicted graphically as follows: The compo</p>
    <p>nents are represented as rectangles containing Markov chains</p>
    <p>with inner rectangles corresponding to boxes. The name of</p>
    <p>the component each box is mapped to is given inside the</p>
    <p>box. In the following figures, the initial component is the</p>
    <p>one at the top-left, and it has a single initial node and a</p>
    <p>single final node. The name of a component is given above</p>
    <p>the rectangle, along with its label.</p>
    <p>Example 2. Figure ?? partially shows an RMC Aex with four components D, P , N, and T . For instance, the label of D is (D) = directory. D either calls P with probability 0.8 or exits with probability 0.2, and this choice can occur</p>
    <p>again after returning from the call. The components N: name and T : phone are not depicted; both have a single edge going from the entrance to the exit with probability 1.</p>
    <p>The -transitions for D are: (a0,1,u1), (u1,0.2, t), also (u1,0.8,(P,en)), and ((P,ex),1,u1), where t is the exit node, u1 is the only node pointed to by a0, (P,en) is the call port for box P, and (P,ex) is the return port for box P.</p>
    <p>Intuitively, a run of an RMC generates a document d in a top-down fashion where a call of a box (corresponding to a</p>
    <p>component) labeled l inside another box (corresponding to a component) labeled l generates a node l in d that is a child of l. If a box is labeled , then it generates nothing, though calls within its component may still generate labels. We next</p>
    <p>formalize this via an alternative description of RMCs.</p>
    <p>A vertex of Ai is either a node in Ai, a call port, or a return port. Let Vi denote the set of all vertices of Ai. Thus, the transition relation i is a set of probability-weighted directed edges on Vi. Let V =</p>
    <p>i Vi, and N, B, Y , and  be</p>
    <p>the unions of the corresponding sets. We denote by qu,ex the probability that starting with u one eventually reaches an exit ex in the same component as u.</p>
    <p>Definition 3. An RMC A defines a global (denumerable) Markov chain MA = (St,) as follows:</p>
    <p>The global states St BV (Tag(L){}) of MA are triples of the form (,u,), where  is a (possibly empty) sequence of boxes from B that represents the stack of pending recursive calls, u is the current vertex of A, and  is an optional tag.</p>
    <p>The function  defines probability-weighted directed edges between global states  : (St  St)  [0,1]:</p>
    <p>(i) If (u,pu,v,v)  , then for every sequence of boxes  and   Tag(L) {} there is a -transition from (,u,) to (,v,) with probability pu,v.</p>
    <p>(ii) If (b,en)  Call(b) and (AY (b)) = lL, then for every  and  there is a -transition from (,(b,en),) to (b,en,l) with probability 1.</p>
    <p>(iii) If (b,ex)  Return(b), and (AY (b)) = l L, then for every  and  there is a -transition from (b,ex,) to (,(b,ex),/l) with probability 1.</p>
    <p>/a[c]//b /a[c]//b /a[c]//b /a[c]//b /a[c]//b</p>
    <p>theory practice</p>
    <p>Yes No P = 0.7P = 0.3</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Verifying MSO properties for unrestricted RMCs is  in PSPACE  as hard as SQRT-SUM: in PSPACE</p>
    <p>lower bounds - long standing open problem</p>
    <p>MSO Queries for RMCs</p>
    <p>We focus on RMC fragments to see the tension between  tractability of query evaluation  expressiveness  succinctness</p>
    <p>Monadic Second Order (MSO) query language is very general  Subsumes: Tree-pattern queries, navigational XPath, ...</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>Hierarchical RMCs (HMC):  A component can not (eventually) call itself</p>
    <p>Tree-like RMCs (TLMC):  Every component can be called in one place only</p>
    <p>but possibly many times</p>
    <p>special case of HMC</p>
    <p>RMC Fragments</p>
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>Pr = 10.8 Pr = 1 Pr = 1 Pr = 10.5 Pr = 1 Pr = 10.5 Pr = 10.2</p>
    <p>Recursive Markov Chains - Tree Generators</p>
    <p>Entering a component labeled L = generation of an opening tag &lt;L&gt;</p>
    <p>Exiting a component labeled L = generation of a closing tag &lt;/L&gt;</p>
    <p>&lt;directory&gt;</p>
    <p>&lt;/directory&gt;</p>
    <p>&lt;person&gt; &lt;name&gt; &lt;/name&gt; &lt;phone&gt; &lt;/phone&gt;</p>
    <p>&lt;/person&gt;</p>
    <p>/27</p>
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>Example: prob. DTDs via rec. Markov chains [BKOS09]</p>
    <p>&lt;!ELEMENT directory (person*)&gt; &lt;!ELEMENT person (name,phone*)&gt;</p>
    <p>D: directory</p>
    <p>P</p>
    <p>P: person</p>
    <p>N T1 1 0.5</p>
    <p>N : name</p>
    <p>T : phone</p>
    <p>On such simple RMCs representing trees, MSO queries are tractable!</p>
    <p>P. Senellart (Tlcom ParisTech) Probabilistic XML 2009/01/13 34 / 37</p>
    <p>Pr = 10.8 Pr = 1 Pr = 1 Pr = 10.5 Pr = 1 Pr = 10.5 Pr = 10.2</p>
    <p>Recursive Markov Chains - Tree Generators</p>
    <p>Entering a component labeled L = generation of an opening tag &lt;L&gt;</p>
    <p>Exiting a component labeled L = generation of a closing tag &lt;/L&gt;</p>
    <p>&lt;directory&gt;</p>
    <p>&lt;/directory&gt;</p>
    <p>&lt;person&gt; &lt;name&gt; &lt;/name&gt; &lt;phone&gt; &lt;/phone&gt;</p>
    <p>&lt;/person&gt;</p>
    <p>/27</p>
    <p>The directory RMC is in HMC and in TLMC</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Query evaluation algorithm : Given TLMC A and MSO   Pre-process TLMC:</p>
    <p>A  probabilistic push-down automaton (PPDA) B</p>
    <p>Pre-process MSO:   tree automaton C (det. streaming tree automaton)</p>
    <p>Compute a product PPDA automaton BC  Compute the termination probability for BC</p>
    <p>Theorem: TLMC is tractable for MSO (in data complexity)</p>
    <p>Computable in PTIME</p>
    <p>Tractability of RMC Fragments: TLMC</p>
    <p>Probability that BC terminates = Probability that  holds in A</p>
    <p>Computable in PTIME</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Theorem: HMC is ra-tractable for MSO (in data complexity)</p>
    <p>ra-tractability:  tractability in case of fixed-cost rational arithmetic  all arithmetic operations over rationals take unit time, no</p>
    <p>matter how large the numbers</p>
    <p>Tractability of RMC Fragments: HMC</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Expressiveness of RMC Fragments width</p>
    <p>depth</p>
    <p>sharing wide</p>
    <p>narrow</p>
    <p>deepshallow</p>
    <p>yes</p>
    <p>no</p>
    <p>[none]</p>
    <p>[none]</p>
    <p>TLAMC [none]</p>
    <p>TLMC</p>
    <p>AHMC</p>
    <p>[none]</p>
    <p>HMC</p>
    <p>[none]</p>
    <p>RMC</p>
    <p>Figure 2: Space of models considered in this paper. Considered dimensions (left), 1-exit models (middle),</p>
    <p>multi-exit models (right). Tractability of MSO queries: MODEL: tractable, MODEL: ra-tractable, MODEL: SQRT-SUM is reducible to query evaluation for some fixed MSO query.</p>
    <p>Tree-like Markov chains. How can we move from tractability in a unit-cost arithmetic model to full tractability? For our representation systems, this move corresponds to a transition to exponentially less succinct systems. This is the case of HMC, which is ra-tractable, and a fully tractable yet less succinct subclass of it called TLMC. In short, the latter can be obtained from the former by forbidding call sharing. Recall that the call graphs of hierarchical Markov chains are acyclic. Call sharing means that several boxes can call (i.e., be mapped to) the same component.</p>
    <p>Definition 7. A hierarchical Markov chain A is tree-like if no two boxes are mapped to the same component.</p>
    <p>It follows from the definition that there is no recursion. This defines a shallow and wide probabilistic model, TLMC, that is a restriction of HMC. The RMC depicted in Figure 1 is a tree-like RMC. Note also that the translation of PrXML</p>
    <p>mux,det into RMC used in the proof of Proposition 5 (see the appendix) produces a tree-like Markov chain, whose components are moreover acyclic. An example of RMC that is not tree-like is given in Theorem 3.2, part (4) of [11] (see also Figure 5 in the appendix).</p>
    <p>The global Markov chain defined by a tree-like Markov chain A is finite, and its size is linear in the size of A. A consequence of this is that all reachability probabilities have polynomial size and can be computed in polynomial time as for standard Markov chains. The same automata-based algorithm as in the proof of Theorem 6 reduces calculating the probability of MSO queries over TLMC to calculating reachability probabilities; by combining these two insights, we get an algorithm for efficiently calculating query probabilities:</p>
    <p>Theorem 8. TLMC is tractable for MSO. Unordered models. The existing literature on probabilistic XML models usually assumes unordered documents. We can see RMC, and all other models presented in this paper, as unordered models. Specifically, let A RMC and L(A) be the set of generated strings; the unordered interpretation of A is the set of unordered documents d (with probability Pr(d)) for which there exists L(A) a possible encoding of d under any ordering (Pr(d) is then the sum of probabilities of all such s). We note that the data complexity results obtained in the ordered setting extend to the unordered one:</p>
    <p>Proposition 9. Let S be any ordered probabilistic XML representation system, and q any MSO query that does not make use of the order predicate . The complexity of the quantitative evaluation problem for q and S S is the same as the complexity of the quantitative evaluation problem for</p>
    <p>q and the unordered interpretation of S.</p>
    <p>In the previous section we have shown the existence of tractable restrictions of RMCs. We now explore the space of models in between PrXML and RMC. RMC models extend PrXML in expressiveness in several dimensions. Clearly RMC is wide while PrXML is narrow, it is deep while PrXML is shallow. In addition, it allows state to be passed upward from child to parent, while in PrXML the processing is completely top-down (this is analogous to the distinction in attribute grammars between inherited attributes and synthesized attributes). Finally, in RMCs a component may be called from multiple places, while in PrXML the topology is a tree: a node has a single parent.</p>
    <p>Shallowness corresponds syntactically to being hierarchical. For an RMC to be narrow, it has to be acyclic, i.e., every component is an acyclic graph. An RMC is 1-exit if each of its components has one exit node, and multi-exit otherwise. The ability to pass information up corresponds to being multi-exit. Finally, the restriction on the topology corresponds to being tree-like, as defined in the previous section. We can thus talk about Tree-like Markov Chains (abbreviated TLMC), Tree-like Acyclic Markov Chains (abbreviated TLAMC), etc. These dimensions, as well as models making them up, are shown in Figure 2. We use the following naming convention: If a model is acyclic or hierarchical, its name is preceded by A or H respectively. The abbreviation SCFG stands for Stochastic Context-Free Grammars. All these models are analyzed in more detail later in this section. The empty corners of the cubes, labeled [none], are unavoidable: Deep models without sharing cannot be obtained as RMC restrictions, and because RMC components can be labeled with , deep models can also generate wide documents.</p>
    <p>The arrows in Figure 2 indicate that the pointing model is a restriction of the pointed one. The figure also gives insights into the trade-off between succinctness and tractability:</p>
    <p>(i) Tractability degrades to ra-tractability by adding sharing. As seen further, this amounts to a gain in succinctness by being able to represent worlds with probabilities doubly exponentially small.</p>
    <p>(ii) Neither the width nor the number of exits influences tractability.</p>
    <p>(iii) Going from shallow to deep affects tractability. We now investigate in detail the relationship of these</p>
    <p>classes with each other, and with existing PrXML models.</p>
    <p>width</p>
    <p>depth</p>
    <p>sharing wide</p>
    <p>narrow</p>
    <p>deepshallow</p>
    <p>yes</p>
    <p>no</p>
    <p>[none]</p>
    <p>[none]</p>
    <p>TLAMC [none]</p>
    <p>TLMC</p>
    <p>AHMC</p>
    <p>[none]</p>
    <p>HMC</p>
    <p>[none]</p>
    <p>RMC</p>
    <p>Figure 2: Space of models considered in this paper. Considered dimensions (left), 1-exit models (middle),</p>
    <p>multi-exit models (right). Tractability of MSO queries: MODEL: tractable, MODEL: ra-tractable, MODEL: SQRT-SUM is reducible to query evaluation for some fixed MSO query.</p>
    <p>Tree-like Markov chains. How can we move from tractability in a unit-cost arithmetic model to full tractability? For our representation systems, this move corresponds to a transition to exponentially less succinct systems. This is the case of HMC, which is ra-tractable, and a fully tractable yet less succinct subclass of it called TLMC. In short, the latter can be obtained from the former by forbidding call sharing. Recall that the call graphs of hierarchical Markov chains are acyclic. Call sharing means that several boxes can call (i.e., be mapped to) the same component.</p>
    <p>Definition 7. A hierarchical Markov chain A is tree-like if no two boxes are mapped to the same component.</p>
    <p>It follows from the definition that there is no recursion. This defines a shallow and wide probabilistic model, TLMC, that is a restriction of HMC. The RMC depicted in Figure 1 is a tree-like RMC. Note also that the translation of PrXML</p>
    <p>mux,det into RMC used in the proof of Proposition 5 (see the appendix) produces a tree-like Markov chain, whose components are moreover acyclic. An example of RMC that is not tree-like is given in Theorem 3.2, part (4) of [11] (see also Figure 5 in the appendix).</p>
    <p>The global Markov chain defined by a tree-like Markov chain A is finite, and its size is linear in the size of A. A consequence of this is that all reachability probabilities have polynomial size and can be computed in polynomial time as for standard Markov chains. The same automata-based algorithm as in the proof of Theorem 6 reduces calculating the probability of MSO queries over TLMC to calculating reachability probabilities; by combining these two insights, we get an algorithm for efficiently calculating query probabilities:</p>
    <p>Theorem 8. TLMC is tractable for MSO. Unordered models. The existing literature on probabilistic XML models usually assumes unordered documents. We can see RMC, and all other models presented in this paper, as unordered models. Specifically, let A RMC and L(A) be the set of generated strings; the unordered interpretation of A is the set of unordered documents d (with probability Pr(d)) for which there exists L(A) a possible encoding of d under any ordering (Pr(d) is then the sum of probabilities of all such s). We note that the data complexity results obtained in the ordered setting extend to the unordered one:</p>
    <p>Proposition 9. Let S be any ordered probabilistic XML representation system, and q any MSO query that does not make use of the order predicate . The complexity of the quantitative evaluation problem for q and S S is the same as the complexity of the quantitative evaluation problem for</p>
    <p>q and the unordered interpretation of S.</p>
    <p>In the previous section we have shown the existence of tractable restrictions of RMCs. We now explore the space of models in between PrXML and RMC. RMC models extend PrXML in expressiveness in several dimensions. Clearly RMC is wide while PrXML is narrow, it is deep while PrXML is shallow. In addition, it allows state to be passed upward from child to parent, while in PrXML the processing is completely top-down (this is analogous to the distinction in attribute grammars between inherited attributes and synthesized attributes). Finally, in RMCs a component may be called from multiple places, while in PrXML the topology is a tree: a node has a single parent.</p>
    <p>Shallowness corresponds syntactically to being hierarchical. For an RMC to be narrow, it has to be acyclic, i.e., every component is an acyclic graph. An RMC is 1-exit if each of its components has one exit node, and multi-exit otherwise. The ability to pass information up corresponds to being multi-exit. Finally, the restriction on the topology corresponds to being tree-like, as defined in the previous section. We can thus talk about Tree-like Markov Chains (abbreviated TLMC), Tree-like Acyclic Markov Chains (abbreviated TLAMC), etc. These dimensions, as well as models making them up, are shown in Figure 2. We use the following naming convention: If a model is acyclic or hierarchical, its name is preceded by A or H respectively. The abbreviation SCFG stands for Stochastic Context-Free Grammars. All these models are analyzed in more detail later in this section. The empty corners of the cubes, labeled [none], are unavoidable: Deep models without sharing cannot be obtained as RMC restrictions, and because RMC components can be labeled with , deep models can also generate wide documents.</p>
    <p>The arrows in Figure 2 indicate that the pointing model is a restriction of the pointed one. The figure also gives insights into the trade-off between succinctness and tractability:</p>
    <p>(i) Tractability degrades to ra-tractability by adding sharing. As seen further, this amounts to a gain in succinctness by being able to represent worlds with probabilities doubly exponentially small.</p>
    <p>(ii) Neither the width nor the number of exits influences tractability.</p>
    <p>(iii) Going from shallow to deep affects tractability. We now investigate in detail the relationship of these</p>
    <p>classes with each other, and with existing PrXML models.</p>
    <p>Three dimensions of expressiveness</p>
    <p>Width: wide vs. narrow Wide models: random trees of any width ~ recursion inside components</p>
    <p>Depth: deep vs. shallow Deep models: random trees of any depth ~ recursion across components</p>
    <p>Call sharing: yes vs. no Model with sharing: random trees with doubly exponentially many leaves ~ components can be called from multiple places</p>
    <p>PrXML</p>
    <p>/ DTD</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Expressiveness of RMC Fragments width</p>
    <p>depth</p>
    <p>sharing wide</p>
    <p>narrow</p>
    <p>deepshallow</p>
    <p>yes</p>
    <p>no</p>
    <p>[none]</p>
    <p>[none]</p>
    <p>TLAMC [none]</p>
    <p>TLMC</p>
    <p>AHMC</p>
    <p>[none]</p>
    <p>HMC</p>
    <p>[none]</p>
    <p>RMC</p>
    <p>Figure 2: Space of models considered in this paper. Considered dimensions (left), 1-exit models (middle),</p>
    <p>multi-exit models (right). Tractability of MSO queries: MODEL: tractable, MODEL: ra-tractable, MODEL: SQRT-SUM is reducible to query evaluation for some fixed MSO query.</p>
    <p>Tree-like Markov chains. How can we move from tractability in a unit-cost arithmetic model to full tractability? For our representation systems, this move corresponds to a transition to exponentially less succinct systems. This is the case of HMC, which is ra-tractable, and a fully tractable yet less succinct subclass of it called TLMC. In short, the latter can be obtained from the former by forbidding call sharing. Recall that the call graphs of hierarchical Markov chains are acyclic. Call sharing means that several boxes can call (i.e., be mapped to) the same component.</p>
    <p>Definition 7. A hierarchical Markov chain A is tree-like if no two boxes are mapped to the same component.</p>
    <p>It follows from the definition that there is no recursion. This defines a shallow and wide probabilistic model, TLMC, that is a restriction of HMC. The RMC depicted in Figure 1 is a tree-like RMC. Note also that the translation of PrXML</p>
    <p>mux,det into RMC used in the proof of Proposition 5 (see the appendix) produces a tree-like Markov chain, whose components are moreover acyclic. An example of RMC that is not tree-like is given in Theorem 3.2, part (4) of [11] (see also Figure 5 in the appendix).</p>
    <p>The global Markov chain defined by a tree-like Markov chain A is finite, and its size is linear in the size of A. A consequence of this is that all reachability probabilities have polynomial size and can be computed in polynomial time as for standard Markov chains. The same automata-based algorithm as in the proof of Theorem 6 reduces calculating the probability of MSO queries over TLMC to calculating reachability probabilities; by combining these two insights, we get an algorithm for efficiently calculating query probabilities:</p>
    <p>Theorem 8. TLMC is tractable for MSO. Unordered models. The existing literature on probabilistic XML models usually assumes unordered documents. We can see RMC, and all other models presented in this paper, as unordered models. Specifically, let A RMC and L(A) be the set of generated strings; the unordered interpretation of A is the set of unordered documents d (with probability Pr(d)) for which there exists L(A) a possible encoding of d under any ordering (Pr(d) is then the sum of probabilities of all such s). We note that the data complexity results obtained in the ordered setting extend to the unordered one:</p>
    <p>Proposition 9. Let S be any ordered probabilistic XML representation system, and q any MSO query that does not make use of the order predicate . The complexity of the quantitative evaluation problem for q and S S is the same as the complexity of the quantitative evaluation problem for</p>
    <p>q and the unordered interpretation of S.</p>
    <p>In the previous section we have shown the existence of tractable restrictions of RMCs. We now explore the space of models in between PrXML and RMC. RMC models extend PrXML in expressiveness in several dimensions. Clearly RMC is wide while PrXML is narrow, it is deep while PrXML is shallow. In addition, it allows state to be passed upward from child to parent, while in PrXML the processing is completely top-down (this is analogous to the distinction in attribute grammars between inherited attributes and synthesized attributes). Finally, in RMCs a component may be called from multiple places, while in PrXML the topology is a tree: a node has a single parent.</p>
    <p>Shallowness corresponds syntactically to being hierarchical. For an RMC to be narrow, it has to be acyclic, i.e., every component is an acyclic graph. An RMC is 1-exit if each of its components has one exit node, and multi-exit otherwise. The ability to pass information up corresponds to being multi-exit. Finally, the restriction on the topology corresponds to being tree-like, as defined in the previous section. We can thus talk about Tree-like Markov Chains (abbreviated TLMC), Tree-like Acyclic Markov Chains (abbreviated TLAMC), etc. These dimensions, as well as models making them up, are shown in Figure 2. We use the following naming convention: If a model is acyclic or hierarchical, its name is preceded by A or H respectively. The abbreviation SCFG stands for Stochastic Context-Free Grammars. All these models are analyzed in more detail later in this section. The empty corners of the cubes, labeled [none], are unavoidable: Deep models without sharing cannot be obtained as RMC restrictions, and because RMC components can be labeled with , deep models can also generate wide documents.</p>
    <p>The arrows in Figure 2 indicate that the pointing model is a restriction of the pointed one. The figure also gives insights into the trade-off between succinctness and tractability:</p>
    <p>(i) Tractability degrades to ra-tractability by adding sharing. As seen further, this amounts to a gain in succinctness by being able to represent worlds with probabilities doubly exponentially small.</p>
    <p>(ii) Neither the width nor the number of exits influences tractability.</p>
    <p>(iii) Going from shallow to deep affects tractability. We now investigate in detail the relationship of these</p>
    <p>classes with each other, and with existing PrXML models.</p>
    <p>width</p>
    <p>depth</p>
    <p>sharing wide</p>
    <p>narrow</p>
    <p>deepshallow</p>
    <p>yes</p>
    <p>no</p>
    <p>[none]</p>
    <p>[none]</p>
    <p>TLAMC [none]</p>
    <p>TLMC</p>
    <p>AHMC</p>
    <p>[none]</p>
    <p>HMC</p>
    <p>[none]</p>
    <p>RMC</p>
    <p>Figure 2: Space of models considered in this paper. Considered dimensions (left), 1-exit models (middle),</p>
    <p>multi-exit models (right). Tractability of MSO queries: MODEL: tractable, MODEL: ra-tractable, MODEL: SQRT-SUM is reducible to query evaluation for some fixed MSO query.</p>
    <p>Tree-like Markov chains. How can we move from tractability in a unit-cost arithmetic model to full tractability? For our representation systems, this move corresponds to a transition to exponentially less succinct systems. This is the case of HMC, which is ra-tractable, and a fully tractable yet less succinct subclass of it called TLMC. In short, the latter can be obtained from the former by forbidding call sharing. Recall that the call graphs of hierarchical Markov chains are acyclic. Call sharing means that several boxes can call (i.e., be mapped to) the same component.</p>
    <p>Definition 7. A hierarchical Markov chain A is tree-like if no two boxes are mapped to the same component.</p>
    <p>It follows from the definition that there is no recursion. This defines a shallow and wide probabilistic model, TLMC, that is a restriction of HMC. The RMC depicted in Figure 1 is a tree-like RMC. Note also that the translation of PrXML</p>
    <p>mux,det into RMC used in the proof of Proposition 5 (see the appendix) produces a tree-like Markov chain, whose components are moreover acyclic. An example of RMC that is not tree-like is given in Theorem 3.2, part (4) of [11] (see also Figure 5 in the appendix).</p>
    <p>The global Markov chain defined by a tree-like Markov chain A is finite, and its size is linear in the size of A. A consequence of this is that all reachability probabilities have polynomial size and can be computed in polynomial time as for standard Markov chains. The same automata-based algorithm as in the proof of Theorem 6 reduces calculating the probability of MSO queries over TLMC to calculating reachability probabilities; by combining these two insights, we get an algorithm for efficiently calculating query probabilities:</p>
    <p>Theorem 8. TLMC is tractable for MSO. Unordered models. The existing literature on probabilistic XML models usually assumes unordered documents. We can see RMC, and all other models presented in this paper, as unordered models. Specifically, let A RMC and L(A) be the set of generated strings; the unordered interpretation of A is the set of unordered documents d (with probability Pr(d)) for which there exists L(A) a possible encoding of d under any ordering (Pr(d) is then the sum of probabilities of all such s). We note that the data complexity results obtained in the ordered setting extend to the unordered one:</p>
    <p>Proposition 9. Let S be any ordered probabilistic XML representation system, and q any MSO query that does not make use of the order predicate . The complexity of the quantitative evaluation problem for q and S S is the same as the complexity of the quantitative evaluation problem for</p>
    <p>q and the unordered interpretation of S.</p>
    <p>In the previous section we have shown the existence of tractable restrictions of RMCs. We now explore the space of models in between PrXML and RMC. RMC models extend PrXML in expressiveness in several dimensions. Clearly RMC is wide while PrXML is narrow, it is deep while PrXML is shallow. In addition, it allows state to be passed upward from child to parent, while in PrXML the processing is completely top-down (this is analogous to the distinction in attribute grammars between inherited attributes and synthesized attributes). Finally, in RMCs a component may be called from multiple places, while in PrXML the topology is a tree: a node has a single parent.</p>
    <p>Shallowness corresponds syntactically to being hierarchical. For an RMC to be narrow, it has to be acyclic, i.e., every component is an acyclic graph. An RMC is 1-exit if each of its components has one exit node, and multi-exit otherwise. The ability to pass information up corresponds to being multi-exit. Finally, the restriction on the topology corresponds to being tree-like, as defined in the previous section. We can thus talk about Tree-like Markov Chains (abbreviated TLMC), Tree-like Acyclic Markov Chains (abbreviated TLAMC), etc. These dimensions, as well as models making them up, are shown in Figure 2. We use the following naming convention: If a model is acyclic or hierarchical, its name is preceded by A or H respectively. The abbreviation SCFG stands for Stochastic Context-Free Grammars. All these models are analyzed in more detail later in this section. The empty corners of the cubes, labeled [none], are unavoidable: Deep models without sharing cannot be obtained as RMC restrictions, and because RMC components can be labeled with , deep models can also generate wide documents.</p>
    <p>The arrows in Figure 2 indicate that the pointing model is a restriction of the pointed one. The figure also gives insights into the trade-off between succinctness and tractability:</p>
    <p>(i) Tractability degrades to ra-tractability by adding sharing. As seen further, this amounts to a gain in succinctness by being able to represent worlds with probabilities doubly exponentially small.</p>
    <p>(ii) Neither the width nor the number of exits influences tractability.</p>
    <p>(iii) Going from shallow to deep affects tractability. We now investigate in detail the relationship of these</p>
    <p>classes with each other, and with existing PrXML models.</p>
    <p>[none] - no reasonable syntactic restriction for this class</p>
    <p>A = Acyclic. Each component is an acyclic graph</p>
    <p>PrXML</p>
    <p>/ DTD</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Expressiveness of RMC Fragments width</p>
    <p>depth</p>
    <p>sharing wide</p>
    <p>narrow</p>
    <p>deepshallow</p>
    <p>yes</p>
    <p>no</p>
    <p>[none]</p>
    <p>[none]</p>
    <p>TLAMC [none]</p>
    <p>TLMC</p>
    <p>AHMC</p>
    <p>[none]</p>
    <p>HMC</p>
    <p>[none]</p>
    <p>RMC</p>
    <p>Figure 2: Space of models considered in this paper. Considered dimensions (left), 1-exit models (middle),</p>
    <p>multi-exit models (right). Tractability of MSO queries: MODEL: tractable, MODEL: ra-tractable, MODEL: SQRT-SUM is reducible to query evaluation for some fixed MSO query.</p>
    <p>Tree-like Markov chains. How can we move from tractability in a unit-cost arithmetic model to full tractability? For our representation systems, this move corresponds to a transition to exponentially less succinct systems. This is the case of HMC, which is ra-tractable, and a fully tractable yet less succinct subclass of it called TLMC. In short, the latter can be obtained from the former by forbidding call sharing. Recall that the call graphs of hierarchical Markov chains are acyclic. Call sharing means that several boxes can call (i.e., be mapped to) the same component.</p>
    <p>Definition 7. A hierarchical Markov chain A is tree-like if no two boxes are mapped to the same component.</p>
    <p>It follows from the definition that there is no recursion. This defines a shallow and wide probabilistic model, TLMC, that is a restriction of HMC. The RMC depicted in Figure 1 is a tree-like RMC. Note also that the translation of PrXML</p>
    <p>mux,det into RMC used in the proof of Proposition 5 (see the appendix) produces a tree-like Markov chain, whose components are moreover acyclic. An example of RMC that is not tree-like is given in Theorem 3.2, part (4) of [11] (see also Figure 5 in the appendix).</p>
    <p>The global Markov chain defined by a tree-like Markov chain A is finite, and its size is linear in the size of A. A consequence of this is that all reachability probabilities have polynomial size and can be computed in polynomial time as for standard Markov chains. The same automata-based algorithm as in the proof of Theorem 6 reduces calculating the probability of MSO queries over TLMC to calculating reachability probabilities; by combining these two insights, we get an algorithm for efficiently calculating query probabilities:</p>
    <p>Theorem 8. TLMC is tractable for MSO. Unordered models. The existing literature on probabilistic XML models usually assumes unordered documents. We can see RMC, and all other models presented in this paper, as unordered models. Specifically, let A RMC and L(A) be the set of generated strings; the unordered interpretation of A is the set of unordered documents d (with probability Pr(d)) for which there exists L(A) a possible encoding of d under any ordering (Pr(d) is then the sum of probabilities of all such s). We note that the data complexity results obtained in the ordered setting extend to the unordered one:</p>
    <p>Proposition 9. Let S be any ordered probabilistic XML representation system, and q any MSO query that does not make use of the order predicate . The complexity of the quantitative evaluation problem for q and S S is the same as the complexity of the quantitative evaluation problem for</p>
    <p>q and the unordered interpretation of S.</p>
    <p>In the previous section we have shown the existence of tractable restrictions of RMCs. We now explore the space of models in between PrXML and RMC. RMC models extend PrXML in expressiveness in several dimensions. Clearly RMC is wide while PrXML is narrow, it is deep while PrXML is shallow. In addition, it allows state to be passed upward from child to parent, while in PrXML the processing is completely top-down (this is analogous to the distinction in attribute grammars between inherited attributes and synthesized attributes). Finally, in RMCs a component may be called from multiple places, while in PrXML the topology is a tree: a node has a single parent.</p>
    <p>Shallowness corresponds syntactically to being hierarchical. For an RMC to be narrow, it has to be acyclic, i.e., every component is an acyclic graph. An RMC is 1-exit if each of its components has one exit node, and multi-exit otherwise. The ability to pass information up corresponds to being multi-exit. Finally, the restriction on the topology corresponds to being tree-like, as defined in the previous section. We can thus talk about Tree-like Markov Chains (abbreviated TLMC), Tree-like Acyclic Markov Chains (abbreviated TLAMC), etc. These dimensions, as well as models making them up, are shown in Figure 2. We use the following naming convention: If a model is acyclic or hierarchical, its name is preceded by A or H respectively. The abbreviation SCFG stands for Stochastic Context-Free Grammars. All these models are analyzed in more detail later in this section. The empty corners of the cubes, labeled [none], are unavoidable: Deep models without sharing cannot be obtained as RMC restrictions, and because RMC components can be labeled with , deep models can also generate wide documents.</p>
    <p>The arrows in Figure 2 indicate that the pointing model is a restriction of the pointed one. The figure also gives insights into the trade-off between succinctness and tractability:</p>
    <p>(i) Tractability degrades to ra-tractability by adding sharing. As seen further, this amounts to a gain in succinctness by being able to represent worlds with probabilities doubly exponentially small.</p>
    <p>(ii) Neither the width nor the number of exits influences tractability.</p>
    <p>(iii) Going from shallow to deep affects tractability. We now investigate in detail the relationship of these</p>
    <p>classes with each other, and with existing PrXML models.</p>
    <p>width</p>
    <p>depth</p>
    <p>sharing wide</p>
    <p>narrow</p>
    <p>deepshallow</p>
    <p>yes</p>
    <p>no</p>
    <p>[none]</p>
    <p>[none]</p>
    <p>TLAMC [none]</p>
    <p>TLMC</p>
    <p>AHMC</p>
    <p>[none]</p>
    <p>HMC</p>
    <p>[none]</p>
    <p>RMC</p>
    <p>Figure 2: Space of models considered in this paper. Considered dimensions (left), 1-exit models (middle),</p>
    <p>multi-exit models (right). Tractability of MSO queries: MODEL: tractable, MODEL: ra-tractable, MODEL: SQRT-SUM is reducible to query evaluation for some fixed MSO query.</p>
    <p>Tree-like Markov chains. How can we move from tractability in a unit-cost arithmetic model to full tractability? For our representation systems, this move corresponds to a transition to exponentially less succinct systems. This is the case of HMC, which is ra-tractable, and a fully tractable yet less succinct subclass of it called TLMC. In short, the latter can be obtained from the former by forbidding call sharing. Recall that the call graphs of hierarchical Markov chains are acyclic. Call sharing means that several boxes can call (i.e., be mapped to) the same component.</p>
    <p>Definition 7. A hierarchical Markov chain A is tree-like if no two boxes are mapped to the same component.</p>
    <p>It follows from the definition that there is no recursion. This defines a shallow and wide probabilistic model, TLMC, that is a restriction of HMC. The RMC depicted in Figure 1 is a tree-like RMC. Note also that the translation of PrXML</p>
    <p>mux,det into RMC used in the proof of Proposition 5 (see the appendix) produces a tree-like Markov chain, whose components are moreover acyclic. An example of RMC that is not tree-like is given in Theorem 3.2, part (4) of [11] (see also Figure 5 in the appendix).</p>
    <p>The global Markov chain defined by a tree-like Markov chain A is finite, and its size is linear in the size of A. A consequence of this is that all reachability probabilities have polynomial size and can be computed in polynomial time as for standard Markov chains. The same automata-based algorithm as in the proof of Theorem 6 reduces calculating the probability of MSO queries over TLMC to calculating reachability probabilities; by combining these two insights, we get an algorithm for efficiently calculating query probabilities:</p>
    <p>Theorem 8. TLMC is tractable for MSO. Unordered models. The existing literature on probabilistic XML models usually assumes unordered documents. We can see RMC, and all other models presented in this paper, as unordered models. Specifically, let A RMC and L(A) be the set of generated strings; the unordered interpretation of A is the set of unordered documents d (with probability Pr(d)) for which there exists L(A) a possible encoding of d under any ordering (Pr(d) is then the sum of probabilities of all such s). We note that the data complexity results obtained in the ordered setting extend to the unordered one:</p>
    <p>Proposition 9. Let S be any ordered probabilistic XML representation system, and q any MSO query that does not make use of the order predicate . The complexity of the quantitative evaluation problem for q and S S is the same as the complexity of the quantitative evaluation problem for</p>
    <p>q and the unordered interpretation of S.</p>
    <p>In the previous section we have shown the existence of tractable restrictions of RMCs. We now explore the space of models in between PrXML and RMC. RMC models extend PrXML in expressiveness in several dimensions. Clearly RMC is wide while PrXML is narrow, it is deep while PrXML is shallow. In addition, it allows state to be passed upward from child to parent, while in PrXML the processing is completely top-down (this is analogous to the distinction in attribute grammars between inherited attributes and synthesized attributes). Finally, in RMCs a component may be called from multiple places, while in PrXML the topology is a tree: a node has a single parent.</p>
    <p>Shallowness corresponds syntactically to being hierarchical. For an RMC to be narrow, it has to be acyclic, i.e., every component is an acyclic graph. An RMC is 1-exit if each of its components has one exit node, and multi-exit otherwise. The ability to pass information up corresponds to being multi-exit. Finally, the restriction on the topology corresponds to being tree-like, as defined in the previous section. We can thus talk about Tree-like Markov Chains (abbreviated TLMC), Tree-like Acyclic Markov Chains (abbreviated TLAMC), etc. These dimensions, as well as models making them up, are shown in Figure 2. We use the following naming convention: If a model is acyclic or hierarchical, its name is preceded by A or H respectively. The abbreviation SCFG stands for Stochastic Context-Free Grammars. All these models are analyzed in more detail later in this section. The empty corners of the cubes, labeled [none], are unavoidable: Deep models without sharing cannot be obtained as RMC restrictions, and because RMC components can be labeled with , deep models can also generate wide documents.</p>
    <p>The arrows in Figure 2 indicate that the pointing model is a restriction of the pointed one. The figure also gives insights into the trade-off between succinctness and tractability:</p>
    <p>(i) Tractability degrades to ra-tractability by adding sharing. As seen further, this amounts to a gain in succinctness by being able to represent worlds with probabilities doubly exponentially small.</p>
    <p>(ii) Neither the width nor the number of exits influences tractability.</p>
    <p>(iii) Going from shallow to deep affects tractability. We now investigate in detail the relationship of these</p>
    <p>classes with each other, and with existing PrXML models.</p>
    <p>PrXML</p>
    <p>/ DTD</p>
    <p>Existing PrXML models with distributional nodes:</p>
    <p>shallow, narrow, no sharing  represent finite probability spaces only  subsumed by TLAMC</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Tractability for MSO:</p>
    <p>double underlining ~ MSO evaluation is tractable  single underlining ~ MSO evaluation is</p>
    <p>tractable under unit cost arithmetic</p>
    <p>no underlining ~ MSO evaluation is SQRT-SUM hard</p>
    <p>Expressiveness vs Tractability width</p>
    <p>depth</p>
    <p>sharing wide</p>
    <p>narrow</p>
    <p>deepshallow</p>
    <p>yes</p>
    <p>no</p>
    <p>[none]</p>
    <p>[none]</p>
    <p>TLAMC [none]</p>
    <p>TLMC</p>
    <p>AHMC</p>
    <p>[none]</p>
    <p>HMC</p>
    <p>[none]</p>
    <p>RMC</p>
    <p>Figure 2: Space of models considered in this paper. Considered dimensions (left), 1-exit models (middle),</p>
    <p>multi-exit models (right). Tractability of MSO queries: MODEL: tractable, MODEL: ra-tractable, MODEL: SQRT-SUM is reducible to query evaluation for some fixed MSO query.</p>
    <p>Tree-like Markov chains. How can we move from tractability in a unit-cost arithmetic model to full tractability? For our representation systems, this move corresponds to a transition to exponentially less succinct systems. This is the case of HMC, which is ra-tractable, and a fully tractable yet less succinct subclass of it called TLMC. In short, the latter can be obtained from the former by forbidding call sharing. Recall that the call graphs of hierarchical Markov chains are acyclic. Call sharing means that several boxes can call (i.e., be mapped to) the same component.</p>
    <p>Definition 7. A hierarchical Markov chain A is tree-like if no two boxes are mapped to the same component.</p>
    <p>It follows from the definition that there is no recursion. This defines a shallow and wide probabilistic model, TLMC, that is a restriction of HMC. The RMC depicted in Figure 1 is a tree-like RMC. Note also that the translation of PrXML</p>
    <p>mux,det into RMC used in the proof of Proposition 5 (see the appendix) produces a tree-like Markov chain, whose components are moreover acyclic. An example of RMC that is not tree-like is given in Theorem 3.2, part (4) of [11] (see also Figure 5 in the appendix).</p>
    <p>The global Markov chain defined by a tree-like Markov chain A is finite, and its size is linear in the size of A. A consequence of this is that all reachability probabilities have polynomial size and can be computed in polynomial time as for standard Markov chains. The same automata-based algorithm as in the proof of Theorem 6 reduces calculating the probability of MSO queries over TLMC to calculating reachability probabilities; by combining these two insights, we get an algorithm for efficiently calculating query probabilities:</p>
    <p>Theorem 8. TLMC is tractable for MSO. Unordered models. The existing literature on probabilistic XML models usually assumes unordered documents. We can see RMC, and all other models presented in this paper, as unordered models. Specifically, let A RMC and L(A) be the set of generated strings; the unordered interpretation of A is the set of unordered documents d (with probability Pr(d)) for which there exists L(A) a possible encoding of d under any ordering (Pr(d) is then the sum of probabilities of all such s). We note that the data complexity results obtained in the ordered setting extend to the unordered one:</p>
    <p>Proposition 9. Let S be any ordered probabilistic XML representation system, and q any MSO query that does not make use of the order predicate . The complexity of the quantitative evaluation problem for q and S S is the same as the complexity of the quantitative evaluation problem for</p>
    <p>q and the unordered interpretation of S.</p>
    <p>In the previous section we have shown the existence of tractable restrictions of RMCs. We now explore the space of models in between PrXML and RMC. RMC models extend PrXML in expressiveness in several dimensions. Clearly RMC is wide while PrXML is narrow, it is deep while PrXML is shallow. In addition, it allows state to be passed upward from child to parent, while in PrXML the processing is completely top-down (this is analogous to the distinction in attribute grammars between inherited attributes and synthesized attributes). Finally, in RMCs a component may be called from multiple places, while in PrXML the topology is a tree: a node has a single parent.</p>
    <p>Shallowness corresponds syntactically to being hierarchical. For an RMC to be narrow, it has to be acyclic, i.e., every component is an acyclic graph. An RMC is 1-exit if each of its components has one exit node, and multi-exit otherwise. The ability to pass information up corresponds to being multi-exit. Finally, the restriction on the topology corresponds to being tree-like, as defined in the previous section. We can thus talk about Tree-like Markov Chains (abbreviated TLMC), Tree-like Acyclic Markov Chains (abbreviated TLAMC), etc. These dimensions, as well as models making them up, are shown in Figure 2. We use the following naming convention: If a model is acyclic or hierarchical, its name is preceded by A or H respectively. The abbreviation SCFG stands for Stochastic Context-Free Grammars. All these models are analyzed in more detail later in this section. The empty corners of the cubes, labeled [none], are unavoidable: Deep models without sharing cannot be obtained as RMC restrictions, and because RMC components can be labeled with , deep models can also generate wide documents.</p>
    <p>The arrows in Figure 2 indicate that the pointing model is a restriction of the pointed one. The figure also gives insights into the trade-off between succinctness and tractability:</p>
    <p>(i) Tractability degrades to ra-tractability by adding sharing. As seen further, this amounts to a gain in succinctness by being able to represent worlds with probabilities doubly exponentially small.</p>
    <p>(ii) Neither the width nor the number of exits influences tractability.</p>
    <p>(iii) Going from shallow to deep affects tractability. We now investigate in detail the relationship of these</p>
    <p>classes with each other, and with existing PrXML models.</p>
    <p>width</p>
    <p>depth</p>
    <p>sharing wide</p>
    <p>narrow</p>
    <p>deepshallow</p>
    <p>yes</p>
    <p>no</p>
    <p>[none]</p>
    <p>[none]</p>
    <p>TLAMC [none]</p>
    <p>TLMC</p>
    <p>AHMC</p>
    <p>[none]</p>
    <p>HMC</p>
    <p>[none]</p>
    <p>RMC</p>
    <p>Figure 2: Space of models considered in this paper. Considered dimensions (left), 1-exit models (middle),</p>
    <p>multi-exit models (right). Tractability of MSO queries: MODEL: tractable, MODEL: ra-tractable, MODEL: SQRT-SUM is reducible to query evaluation for some fixed MSO query.</p>
    <p>Tree-like Markov chains. How can we move from tractability in a unit-cost arithmetic model to full tractability? For our representation systems, this move corresponds to a transition to exponentially less succinct systems. This is the case of HMC, which is ra-tractable, and a fully tractable yet less succinct subclass of it called TLMC. In short, the latter can be obtained from the former by forbidding call sharing. Recall that the call graphs of hierarchical Markov chains are acyclic. Call sharing means that several boxes can call (i.e., be mapped to) the same component.</p>
    <p>Definition 7. A hierarchical Markov chain A is tree-like if no two boxes are mapped to the same component.</p>
    <p>It follows from the definition that there is no recursion. This defines a shallow and wide probabilistic model, TLMC, that is a restriction of HMC. The RMC depicted in Figure 1 is a tree-like RMC. Note also that the translation of PrXML</p>
    <p>mux,det into RMC used in the proof of Proposition 5 (see the appendix) produces a tree-like Markov chain, whose components are moreover acyclic. An example of RMC that is not tree-like is given in Theorem 3.2, part (4) of [11] (see also Figure 5 in the appendix).</p>
    <p>The global Markov chain defined by a tree-like Markov chain A is finite, and its size is linear in the size of A. A consequence of this is that all reachability probabilities have polynomial size and can be computed in polynomial time as for standard Markov chains. The same automata-based algorithm as in the proof of Theorem 6 reduces calculating the probability of MSO queries over TLMC to calculating reachability probabilities; by combining these two insights, we get an algorithm for efficiently calculating query probabilities:</p>
    <p>Theorem 8. TLMC is tractable for MSO. Unordered models. The existing literature on probabilistic XML models usually assumes unordered documents. We can see RMC, and all other models presented in this paper, as unordered models. Specifically, let A RMC and L(A) be the set of generated strings; the unordered interpretation of A is the set of unordered documents d (with probability Pr(d)) for which there exists L(A) a possible encoding of d under any ordering (Pr(d) is then the sum of probabilities of all such s). We note that the data complexity results obtained in the ordered setting extend to the unordered one:</p>
    <p>Proposition 9. Let S be any ordered probabilistic XML representation system, and q any MSO query that does not make use of the order predicate . The complexity of the quantitative evaluation problem for q and S S is the same as the complexity of the quantitative evaluation problem for</p>
    <p>q and the unordered interpretation of S.</p>
    <p>In the previous section we have shown the existence of tractable restrictions of RMCs. We now explore the space of models in between PrXML and RMC. RMC models extend PrXML in expressiveness in several dimensions. Clearly RMC is wide while PrXML is narrow, it is deep while PrXML is shallow. In addition, it allows state to be passed upward from child to parent, while in PrXML the processing is completely top-down (this is analogous to the distinction in attribute grammars between inherited attributes and synthesized attributes). Finally, in RMCs a component may be called from multiple places, while in PrXML the topology is a tree: a node has a single parent.</p>
    <p>Shallowness corresponds syntactically to being hierarchical. For an RMC to be narrow, it has to be acyclic, i.e., every component is an acyclic graph. An RMC is 1-exit if each of its components has one exit node, and multi-exit otherwise. The ability to pass information up corresponds to being multi-exit. Finally, the restriction on the topology corresponds to being tree-like, as defined in the previous section. We can thus talk about Tree-like Markov Chains (abbreviated TLMC), Tree-like Acyclic Markov Chains (abbreviated TLAMC), etc. These dimensions, as well as models making them up, are shown in Figure 2. We use the following naming convention: If a model is acyclic or hierarchical, its name is preceded by A or H respectively. The abbreviation SCFG stands for Stochastic Context-Free Grammars. All these models are analyzed in more detail later in this section. The empty corners of the cubes, labeled [none], are unavoidable: Deep models without sharing cannot be obtained as RMC restrictions, and because RMC components can be labeled with , deep models can also generate wide documents.</p>
    <p>The arrows in Figure 2 indicate that the pointing model is a restriction of the pointed one. The figure also gives insights into the trade-off between succinctness and tractability:</p>
    <p>(i) Tractability degrades to ra-tractability by adding sharing. As seen further, this amounts to a gain in succinctness by being able to represent worlds with probabilities doubly exponentially small.</p>
    <p>(ii) Neither the width nor the number of exits influences tractability.</p>
    <p>(iii) Going from shallow to deep affects tractability. We now investigate in detail the relationship of these</p>
    <p>classes with each other, and with existing PrXML models.</p>
    <p>/ DTD</p>
    <p>PrXML</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Gain in width - no influence on tractability  Gain in depth - loss in tractability  Allowing sharing  tractability degrades to unit-cost arithmetics tractability</p>
    <p>Expressiveness vs Tractability width</p>
    <p>depth</p>
    <p>sharing wide</p>
    <p>narrow</p>
    <p>deepshallow</p>
    <p>yes</p>
    <p>no</p>
    <p>[none]</p>
    <p>[none]</p>
    <p>TLAMC [none]</p>
    <p>TLMC</p>
    <p>AHMC</p>
    <p>[none]</p>
    <p>HMC</p>
    <p>[none]</p>
    <p>RMC</p>
    <p>Figure 2: Space of models considered in this paper. Considered dimensions (left), 1-exit models (middle),</p>
    <p>multi-exit models (right). Tractability of MSO queries: MODEL: tractable, MODEL: ra-tractable, MODEL: SQRT-SUM is reducible to query evaluation for some fixed MSO query.</p>
    <p>Tree-like Markov chains. How can we move from tractability in a unit-cost arithmetic model to full tractability? For our representation systems, this move corresponds to a transition to exponentially less succinct systems. This is the case of HMC, which is ra-tractable, and a fully tractable yet less succinct subclass of it called TLMC. In short, the latter can be obtained from the former by forbidding call sharing. Recall that the call graphs of hierarchical Markov chains are acyclic. Call sharing means that several boxes can call (i.e., be mapped to) the same component.</p>
    <p>Definition 7. A hierarchical Markov chain A is tree-like if no two boxes are mapped to the same component.</p>
    <p>It follows from the definition that there is no recursion. This defines a shallow and wide probabilistic model, TLMC, that is a restriction of HMC. The RMC depicted in Figure 1 is a tree-like RMC. Note also that the translation of PrXML</p>
    <p>mux,det into RMC used in the proof of Proposition 5 (see the appendix) produces a tree-like Markov chain, whose components are moreover acyclic. An example of RMC that is not tree-like is given in Theorem 3.2, part (4) of [11] (see also Figure 5 in the appendix).</p>
    <p>The global Markov chain defined by a tree-like Markov chain A is finite, and its size is linear in the size of A. A consequence of this is that all reachability probabilities have polynomial size and can be computed in polynomial time as for standard Markov chains. The same automata-based algorithm as in the proof of Theorem 6 reduces calculating the probability of MSO queries over TLMC to calculating reachability probabilities; by combining these two insights, we get an algorithm for efficiently calculating query probabilities:</p>
    <p>Theorem 8. TLMC is tractable for MSO. Unordered models. The existing literature on probabilistic XML models usually assumes unordered documents. We can see RMC, and all other models presented in this paper, as unordered models. Specifically, let A RMC and L(A) be the set of generated strings; the unordered interpretation of A is the set of unordered documents d (with probability Pr(d)) for which there exists L(A) a possible encoding of d under any ordering (Pr(d) is then the sum of probabilities of all such s). We note that the data complexity results obtained in the ordered setting extend to the unordered one:</p>
    <p>Proposition 9. Let S be any ordered probabilistic XML representation system, and q any MSO query that does not make use of the order predicate . The complexity of the quantitative evaluation problem for q and S S is the same as the complexity of the quantitative evaluation problem for</p>
    <p>q and the unordered interpretation of S.</p>
    <p>In the previous section we have shown the existence of tractable restrictions of RMCs. We now explore the space of models in between PrXML and RMC. RMC models extend PrXML in expressiveness in several dimensions. Clearly RMC is wide while PrXML is narrow, it is deep while PrXML is shallow. In addition, it allows state to be passed upward from child to parent, while in PrXML the processing is completely top-down (this is analogous to the distinction in attribute grammars between inherited attributes and synthesized attributes). Finally, in RMCs a component may be called from multiple places, while in PrXML the topology is a tree: a node has a single parent.</p>
    <p>Shallowness corresponds syntactically to being hierarchical. For an RMC to be narrow, it has to be acyclic, i.e., every component is an acyclic graph. An RMC is 1-exit if each of its components has one exit node, and multi-exit otherwise. The ability to pass information up corresponds to being multi-exit. Finally, the restriction on the topology corresponds to being tree-like, as defined in the previous section. We can thus talk about Tree-like Markov Chains (abbreviated TLMC), Tree-like Acyclic Markov Chains (abbreviated TLAMC), etc. These dimensions, as well as models making them up, are shown in Figure 2. We use the following naming convention: If a model is acyclic or hierarchical, its name is preceded by A or H respectively. The abbreviation SCFG stands for Stochastic Context-Free Grammars. All these models are analyzed in more detail later in this section. The empty corners of the cubes, labeled [none], are unavoidable: Deep models without sharing cannot be obtained as RMC restrictions, and because RMC components can be labeled with , deep models can also generate wide documents.</p>
    <p>The arrows in Figure 2 indicate that the pointing model is a restriction of the pointed one. The figure also gives insights into the trade-off between succinctness and tractability:</p>
    <p>(i) Tractability degrades to ra-tractability by adding sharing. As seen further, this amounts to a gain in succinctness by being able to represent worlds with probabilities doubly exponentially small.</p>
    <p>(ii) Neither the width nor the number of exits influences tractability.</p>
    <p>(iii) Going from shallow to deep affects tractability. We now investigate in detail the relationship of these</p>
    <p>classes with each other, and with existing PrXML models.</p>
    <p>width</p>
    <p>depth</p>
    <p>sharing wide</p>
    <p>narrow</p>
    <p>deepshallow</p>
    <p>yes</p>
    <p>no</p>
    <p>[none]</p>
    <p>[none]</p>
    <p>TLAMC [none]</p>
    <p>TLMC</p>
    <p>AHMC</p>
    <p>[none]</p>
    <p>HMC</p>
    <p>[none]</p>
    <p>RMC</p>
    <p>Figure 2: Space of models considered in this paper. Considered dimensions (left), 1-exit models (middle),</p>
    <p>multi-exit models (right). Tractability of MSO queries: MODEL: tractable, MODEL: ra-tractable, MODEL: SQRT-SUM is reducible to query evaluation for some fixed MSO query.</p>
    <p>Tree-like Markov chains. How can we move from tractability in a unit-cost arithmetic model to full tractability? For our representation systems, this move corresponds to a transition to exponentially less succinct systems. This is the case of HMC, which is ra-tractable, and a fully tractable yet less succinct subclass of it called TLMC. In short, the latter can be obtained from the former by forbidding call sharing. Recall that the call graphs of hierarchical Markov chains are acyclic. Call sharing means that several boxes can call (i.e., be mapped to) the same component.</p>
    <p>Definition 7. A hierarchical Markov chain A is tree-like if no two boxes are mapped to the same component.</p>
    <p>It follows from the definition that there is no recursion. This defines a shallow and wide probabilistic model, TLMC, that is a restriction of HMC. The RMC depicted in Figure 1 is a tree-like RMC. Note also that the translation of PrXML</p>
    <p>mux,det into RMC used in the proof of Proposition 5 (see the appendix) produces a tree-like Markov chain, whose components are moreover acyclic. An example of RMC that is not tree-like is given in Theorem 3.2, part (4) of [11] (see also Figure 5 in the appendix).</p>
    <p>The global Markov chain defined by a tree-like Markov chain A is finite, and its size is linear in the size of A. A consequence of this is that all reachability probabilities have polynomial size and can be computed in polynomial time as for standard Markov chains. The same automata-based algorithm as in the proof of Theorem 6 reduces calculating the probability of MSO queries over TLMC to calculating reachability probabilities; by combining these two insights, we get an algorithm for efficiently calculating query probabilities:</p>
    <p>Theorem 8. TLMC is tractable for MSO. Unordered models. The existing literature on probabilistic XML models usually assumes unordered documents. We can see RMC, and all other models presented in this paper, as unordered models. Specifically, let A RMC and L(A) be the set of generated strings; the unordered interpretation of A is the set of unordered documents d (with probability Pr(d)) for which there exists L(A) a possible encoding of d under any ordering (Pr(d) is then the sum of probabilities of all such s). We note that the data complexity results obtained in the ordered setting extend to the unordered one:</p>
    <p>Proposition 9. Let S be any ordered probabilistic XML representation system, and q any MSO query that does not make use of the order predicate . The complexity of the quantitative evaluation problem for q and S S is the same as the complexity of the quantitative evaluation problem for</p>
    <p>q and the unordered interpretation of S.</p>
    <p>In the previous section we have shown the existence of tractable restrictions of RMCs. We now explore the space of models in between PrXML and RMC. RMC models extend PrXML in expressiveness in several dimensions. Clearly RMC is wide while PrXML is narrow, it is deep while PrXML is shallow. In addition, it allows state to be passed upward from child to parent, while in PrXML the processing is completely top-down (this is analogous to the distinction in attribute grammars between inherited attributes and synthesized attributes). Finally, in RMCs a component may be called from multiple places, while in PrXML the topology is a tree: a node has a single parent.</p>
    <p>Shallowness corresponds syntactically to being hierarchical. For an RMC to be narrow, it has to be acyclic, i.e., every component is an acyclic graph. An RMC is 1-exit if each of its components has one exit node, and multi-exit otherwise. The ability to pass information up corresponds to being multi-exit. Finally, the restriction on the topology corresponds to being tree-like, as defined in the previous section. We can thus talk about Tree-like Markov Chains (abbreviated TLMC), Tree-like Acyclic Markov Chains (abbreviated TLAMC), etc. These dimensions, as well as models making them up, are shown in Figure 2. We use the following naming convention: If a model is acyclic or hierarchical, its name is preceded by A or H respectively. The abbreviation SCFG stands for Stochastic Context-Free Grammars. All these models are analyzed in more detail later in this section. The empty corners of the cubes, labeled [none], are unavoidable: Deep models without sharing cannot be obtained as RMC restrictions, and because RMC components can be labeled with , deep models can also generate wide documents.</p>
    <p>The arrows in Figure 2 indicate that the pointing model is a restriction of the pointed one. The figure also gives insights into the trade-off between succinctness and tractability:</p>
    <p>(i) Tractability degrades to ra-tractability by adding sharing. As seen further, this amounts to a gain in succinctness by being able to represent worlds with probabilities doubly exponentially small.</p>
    <p>(ii) Neither the width nor the number of exits influences tractability.</p>
    <p>(iii) Going from shallow to deep affects tractability. We now investigate in detail the relationship of these</p>
    <p>classes with each other, and with existing PrXML models.</p>
    <p>/ DTD</p>
    <p>PrXML</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>Tree-patterns over PrXML with distributional nodes: FP#P-complete  Navigational XPath over AHMC: in PSACE  MSO over</p>
    <p>PrXML with distributional nodes and TLAMC: PSPACE-complete  AHMC: #EXP-hard and in EXPSPACE  Wide models, e.g. , TLMC:</p>
    <p>even deciding whether an MSO query has a probability &gt; 0 is not elementary</p>
    <p>Combined Complexity of MSO Evaluation</p>
    <p>TP</p>
    <p>MSO</p>
    <p>NavXPath</p>
    <p>/31</p>
  </div>
  <div class="page">
    <p>We adopted a very general RMC model for probabilistic XML. RMC  Mimics DTDs with probabilities  Extends classical PrXML model with distributional nodes</p>
    <p>We studied  space of models between PrXML and RMC  complexity of</p>
    <p>MSO query answering</p>
    <p>width</p>
    <p>depth</p>
    <p>sharing wide</p>
    <p>narrow</p>
    <p>deepshallow</p>
    <p>yes</p>
    <p>no</p>
    <p>[none]</p>
    <p>[none]</p>
    <p>TLAMC [none]</p>
    <p>TLMC</p>
    <p>AHMC</p>
    <p>[none]</p>
    <p>HMC</p>
    <p>[none]</p>
    <p>RMC</p>
    <p>Figure 2: Space of models considered in this paper. Considered dimensions (left), 1-exit models (middle),</p>
    <p>multi-exit models (right). Tractability of MSO queries: MODEL: tractable, MODEL: ra-tractable, MODEL: SQRT-SUM is reducible to query evaluation for some fixed MSO query.</p>
    <p>Tree-like Markov chains. How can we move from tractability in a unit-cost arithmetic model to full tractability? For our representation systems, this move corresponds to a transition to exponentially less succinct systems. This is the case of HMC, which is ra-tractable, and a fully tractable yet less succinct subclass of it called TLMC. In short, the latter can be obtained from the former by forbidding call sharing. Recall that the call graphs of hierarchical Markov chains are acyclic. Call sharing means that several boxes can call (i.e., be mapped to) the same component.</p>
    <p>Definition 7. A hierarchical Markov chain A is tree-like if no two boxes are mapped to the same component.</p>
    <p>It follows from the definition that there is no recursion. This defines a shallow and wide probabilistic model, TLMC, that is a restriction of HMC. The RMC depicted in Figure 1 is a tree-like RMC. Note also that the translation of PrXML</p>
    <p>mux,det into RMC used in the proof of Proposition 5 (see the appendix) produces a tree-like Markov chain, whose components are moreover acyclic. An example of RMC that is not tree-like is given in Theorem 3.2, part (4) of [11] (see also Figure 5 in the appendix).</p>
    <p>The global Markov chain defined by a tree-like Markov chain A is finite, and its size is linear in the size of A. A consequence of this is that all reachability probabilities have polynomial size and can be computed in polynomial time as for standard Markov chains. The same automata-based algorithm as in the proof of Theorem 6 reduces calculating the probability of MSO queries over TLMC to calculating reachability probabilities; by combining these two insights, we get an algorithm for efficiently calculating query probabilities:</p>
    <p>Theorem 8. TLMC is tractable for MSO. Unordered models. The existing literature on probabilistic XML models usually assumes unordered documents. We can see RMC, and all other models presented in this paper, as unordered models. Specifically, let A RMC and L(A) be the set of generated strings; the unordered interpretation of A is the set of unordered documents d (with probability Pr(d)) for which there exists L(A) a possible encoding of d under any ordering (Pr(d) is then the sum of probabilities of all such s). We note that the data complexity results obtained in the ordered setting extend to the unordered one:</p>
    <p>Proposition 9. Let S be any ordered probabilistic XML representation system, and q any MSO query that does not make use of the order predicate . The complexity of the quantitative evaluation problem for q and S S is the same as the complexity of the quantitative evaluation problem for</p>
    <p>q and the unordered interpretation of S.</p>
    <p>In the previous section we have shown the existence of tractable restrictions of RMCs. We now explore the space of models in between PrXML and RMC. RMC models extend PrXML in expressiveness in several dimensions. Clearly RMC is wide while PrXML is narrow, it is deep while PrXML is shallow. In addition, it allows state to be passed upward from child to parent, while in PrXML the processing is completely top-down (this is analogous to the distinction in attribute grammars between inherited attributes and synthesized attributes). Finally, in RMCs a component may be called from multiple places, while in PrXML the topology is a tree: a node has a single parent.</p>
    <p>Shallowness corresponds syntactically to being hierarchical. For an RMC to be narrow, it has to be acyclic, i.e., every component is an acyclic graph. An RMC is 1-exit if each of its components has one exit node, and multi-exit otherwise. The ability to pass information up corresponds to being multi-exit. Finally, the restriction on the topology corresponds to being tree-like, as defined in the previous section. We can thus talk about Tree-like Markov Chains (abbreviated TLMC), Tree-like Acyclic Markov Chains (abbreviated TLAMC), etc. These dimensions, as well as models making them up, are shown in Figure 2. We use the following naming convention: If a model is acyclic or hierarchical, its name is preceded by A or H respectively. The abbreviation SCFG stands for Stochastic Context-Free Grammars. All these models are analyzed in more detail later in this section. The empty corners of the cubes, labeled [none], are unavoidable: Deep models without sharing cannot be obtained as RMC restrictions, and because RMC components can be labeled with , deep models can also generate wide documents.</p>
    <p>The arrows in Figure 2 indicate that the pointing model is a restriction of the pointed one. The figure also gives insights into the trade-off between succinctness and tractability:</p>
    <p>(i) Tractability degrades to ra-tractability by adding sharing. As seen further, this amounts to a gain in succinctness by being able to represent worlds with probabilities doubly exponentially small.</p>
    <p>(ii) Neither the width nor the number of exits influences tractability.</p>
    <p>(iii) Going from shallow to deep affects tractability. We now investigate in detail the relationship of these</p>
    <p>classes with each other, and with existing PrXML models.</p>
    <p>PrXML</p>
    <p>/ DTD</p>
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Thank you</p>
    <p>Webdam Project: Foundations of Data Management ERC-FP7-226513 http://webdam.inria.fr</p>
    <p>ONTORULE: ONTOlogies meet business RULes FP7-ICT-231875 http://ontorule-project.eu/</p>
    <p>Ontologies meet Business Rules</p>
    <p>ON TOR UL E</p>
    <p>DataRing Project: P2P Data Sharing for Online Communities http://www.lina.univ-nantes.fr/projets/DataRing/</p>
    <p>FOX Project: Foundations of XML FP7-ICT-233599 http://fox7.eu/</p>
    <p>British EPSRC grant EP/G004021/1</p>
  </div>
  <div class="page">
    <p>[Abiteboul&amp;al10] -S. Abiteboul, T-H. H. Chan, E. Kharlamov, W. Nutt, and P. Senellart, Aggregate Queries for Discrete and Continuous Probabilistic XML. ICDT 2010</p>
    <p>[Abiteboul&amp;al09] - Serge Abiteboul, Benny Kimelfeld, Yehoshua Sagiv, Pierre Senellart: On the expressiveness of probabilistic XML models. VLDB J. 18(5): 1041-1064 (2009)</p>
    <p>[Antova&amp;al07] - Lyublena Antova, Christoph Koch, Dan Olteanu: 10106 Worlds and Beyond: Efficient Representation and Processing of Incomplete Information. ICDE 2007: 606-615</p>
    <p>[Bishop06] - C. M. Bishop (2006), Pattern Recognition and Machine Learning.  [Cohen&amp;al09] -Sara Cohen, Benny Kimelfeld, Yehoshua Sagiv: Running tree</p>
    <p>automata on probabilistic XML. PODS 2009: 227-236</p>
    <p>[Cohen&amp;al09] - S. Cohen, B, Kimelfeld, Y. Sagiv: Incorporating constraints in probabilistic XML. ACM Trans. Database Syst. 34(3): (2009)</p>
    <p>References</p>
  </div>
  <div class="page">
    <p>[Etessami&amp;Yannakakis05] - K. Etessami, M. Yannakakis: Recursive Markov Chains, Stochastic Grammars, and Monotone Systems of Nonlinear Equations. STACS 2005</p>
    <p>[Etessami06] - Slides of talks at Dagstuhl. Available at http:// homepages.inf.ed.ac.uk/kousha/etessami_wamt_tutorial.pdf</p>
    <p>[Kimelfeld&amp;al09] - Benny Kimelfeld, Yuri Kosharovsky, Yehoshua Sagiv: Query evaluation over probabilistic XML. VLDB J. 18(5): 1117-1140 (2009)</p>
    <p>[Kharlamov&amp;al10] - Evgeny Kharlamov, Werner Nutt, Pierre Senellart: Updating probabilistic XML. EDBT/ICDT Workshops 2010</p>
    <p>[Kwiatkowska03]- M. Z. Kwiatkowska: Model checking for probability and time: from theory to practice. LICS 2003</p>
    <p>[Manning,Schuetze99] - Christopher D. Manning and Hinrich Schtze. Foundations of Statistical Natural Language Processing. MIT Press, 1999.</p>
    <p>[Senellart&amp;al07] - P. Senellart, S. Abiteboul: On the complexity of managing</p>
    <p>References</p>
  </div>
  <div class="page">
    <p>[Senellart&amp;al07] - P. Senellart, S. Abiteboul: On the complexity of managing probabilistic XML data. PODS 2007</p>
    <p>References</p>
  </div>
</Presentation>
