<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>DELPHI: Cryptographic Inference for Neural Networks</p>
    <p>Ryan Lehmkuhl Akshayaram Srinivasan Wenting Zheng Raluca Ada PopaPratyush Mishra</p>
    <p>UC Berkeley</p>
  </div>
  <div class="page">
    <p>Neural Network Inference</p>
    <p>User data is sensitive Servers model is proprietary</p>
    <p>Client</p>
    <p>x</p>
    <p>Server</p>
    <p>M M(x)</p>
    <p>A growing number of applications use neural networks in user interactions</p>
    <p>Home monitoring: detect and recognize visitors  Baby monitor: motion detection to alert parents</p>
  </div>
  <div class="page">
    <p>Client-side inference</p>
    <p>Client Server</p>
    <p>Client sees servers model! This reveals model weights and leaks information about private training data</p>
    <p>M x M(x)</p>
    <p>Client Server</p>
    <p>M x</p>
    <p>M(x)</p>
    <p>Server-side inference</p>
    <p>Server sees client data!</p>
    <p>[SRS17], [CLEKS18], [MSCS18] 3</p>
  </div>
  <div class="page">
    <p>Secure inference goals</p>
    <p>Client (&amp; server) should learn only prediction M(x)</p>
    <p>Server should not learn private client input x Client should not learn private model weights M</p>
    <p>Client</p>
    <p>x</p>
    <p>Server</p>
    <p>MM(x)</p>
  </div>
  <div class="page">
    <p>Prior work on secure inference</p>
    <p>Protocol type FHE based 2PC based Desired</p>
    <p>Examples CryptoNets, CHET, TAPAS SecureML, Gazelle,</p>
    <p>MiniONN Delphi</p>
    <p>Performance</p>
    <p>Functionality/ Accuracy</p>
  </div>
  <div class="page">
    <p>Delphi</p>
    <p>Cryptographic system for secure inference on convolutional neural networks</p>
    <p>improves bandwidth (9x) and inference latency (22x)  can utilize GPU/TPU for linear layers  evaluated on realistic workloads (CIFAR-100, ResNet-32)</p>
    <p>Efficiency:</p>
    <p>supports arbitrary CNNsFunctionality:</p>
    <p>Security: achieves semi-honest simulation-based security</p>
  </div>
  <div class="page">
    <p>Machine LearningCryptography</p>
    <p>Systems</p>
  </div>
  <div class="page">
    <p>Linear Layers</p>
    <p>Non-linear Layers</p>
    <p>Recap: Convolutional Neural Networks</p>
    <p>C on</p>
    <p>vo lu</p>
    <p>tio n</p>
    <p>A ct</p>
    <p>iv at</p>
    <p>io n</p>
    <p>(R eL</p>
    <p>U )</p>
    <p>C on</p>
    <p>vo lu</p>
    <p>tio n</p>
    <p>A ct</p>
    <p>iv at</p>
    <p>io n</p>
    <p>(R eL</p>
    <p>U )</p>
    <p>Fu lly</p>
    <p>-c on</p>
    <p>ne ct</p>
    <p>ed</p>
    <p>Input Prediction</p>
  </div>
  <div class="page">
    <p>Starting point: GAZELLE [JVC18] Key insight: use crypto specialized for each layer.</p>
    <p>Client Server Enc(x)</p>
    <p>c 1. Linear layer c  Enc(Lx + s)</p>
    <p>y  Dec(c)</p>
    <p>GCy s</p>
    <p>Enc(ReLU(Lx))</p>
    <p>y - s  Lx</p>
    <p>ReLU</p>
    <p>Linearly-homomorphic Encryption</p>
    <p>Enc(x) + Enc(y) = Enc(x + y)</p>
    <p>Garbled circuits: 2PC protocol for bitwise operations like ReLU</p>
  </div>
  <div class="page">
    <p>Expensive parts of Gazelle</p>
    <p>Client Server Enc(x)</p>
    <p>c 1. Linear layer c  Enc(Lx + s)</p>
    <p>y  Dec(c)</p>
    <p>GCy s</p>
    <p>Enc(ReLU(Lx))</p>
    <p>y - s  Lx</p>
    <p>ReLU</p>
    <p>For ResNet-32, per inference: ~600MB communication, and ~82 sec latency.</p>
    <p>no GPU!</p>
  </div>
  <div class="page">
    <p>Systems</p>
    <p>Machine LearningCryptography</p>
  </div>
  <div class="page">
    <p>GPU compatible!</p>
    <p>Delphi: Optimizing Linear layers</p>
    <p>Client Server Enc(r)</p>
    <p>c c  Enc(Lr + s)y  Dec(c)</p>
    <p>x + r z := L(x + r) + s = Lx + yGet input x</p>
    <p>Sample r Sample s</p>
    <p>Online phase</p>
    <p>Preprocessing phase</p>
    <p>GCy z ReLU(Lx) + r2</p>
    <p>= x2 + r2 ReLU(z-y)</p>
    <p>Per inference: &gt;600MB communication, ~82 s latency</p>
    <p>~350MB</p>
    <p>~13 sr2 12</p>
  </div>
  <div class="page">
    <p>Delphi: Optimizing Non-linear Activations</p>
    <p>Problem: ReLU is cheap for CPUs, but costly in 2PC.</p>
    <p>Solution Idea: Replace ReLUs with quadratic activations, which are cheap in 2PC [CryptoNets, SecureML]</p>
    <p>Problem: Training accurate quad. networks is difficult: algorithms are optimized for all-ReLU networks</p>
  </div>
  <div class="page">
    <p>Crypto</p>
    <p>Systems</p>
    <p>Machine Learning</p>
  </div>
  <div class="page">
    <p>Delphis Machine Learning Planner</p>
    <p>Delphis Planner all-ReLU CNN</p>
    <p>Accuracy threshold t hybrid CNN</p>
    <p>Contains a mixture of ReLU and quadratic activations,</p>
    <p>and has accuracy &gt; t</p>
    <p>Better techniques for training hybrid networks  Clipping gradients  Blending in quadratic layers slowly</p>
    <p>Specializing Neural Architecture Search to discover hybrid networks  Adapt PBT algorithm  Iterative exploration of search space</p>
  </div>
  <div class="page">
    <p>Delphis end-to-end workflow Client Server</p>
    <p>Server Online</p>
    <p>Client Online</p>
    <p>Server Preprocessing</p>
    <p>Client Preprocessing</p>
    <p>Preprocessing for linear, ReLU, and quadratic layers</p>
    <p>Online phase for linear, ReLU, and quadratic layers</p>
    <p>Planner</p>
    <p>Train all-ReLU CNN</p>
    <p>Accuracy threshold t</p>
    <p>Optimize accuracy and efficiency</p>
    <p>Train initial allReLU network</p>
    <p>x</p>
    <p>All-ReLU CNN</p>
    <p>Hybrid CNN</p>
    <p>M(x)</p>
  </div>
  <div class="page">
    <p>Crypto</p>
    <p>Systems</p>
    <p>Machine Learning</p>
  </div>
  <div class="page">
    <p>Evaluation 1. Does Delphis planner preserve accuracy? 2. Does Delphis protocol reduce latency &amp; bandwidth?</p>
    <p>Benchmark: ResNet-32 network on CIFAR-100</p>
    <p>github.com/mc2-project/delphi</p>
    <p>Implementation</p>
    <p>Rust + C++ library with support for GPU acceleration</p>
  </div>
  <div class="page">
    <p>A cc</p>
    <p>uU ac</p>
    <p>y (%</p>
    <p>)</p>
    <p>all-5eL8 baselLQe 5eL8 + IdeQtLty 5eL8 + 4uadUatLc</p>
    <p>Planner accuracy</p>
    <p>ReLUs are not redundant:</p>
    <p>accuracy loss &gt; 10%</p>
  </div>
  <div class="page">
    <p>A cc</p>
    <p>uU ac</p>
    <p>y (%</p>
    <p>)</p>
    <p>all-5eL8 baselLQe 5eL8 + IdeQtLty 5eL8 + 4uadUatLc</p>
    <p>Planner accuracy</p>
    <p>Most efficient planned network achieves loss of</p>
    <p>&lt; 2%</p>
  </div>
  <div class="page">
    <p>In Ie</p>
    <p>Ue nc</p>
    <p>e tL</p>
    <p>m e</p>
    <p>(s )</p>
    <p>DelphL GDzelle</p>
    <p>D Dt</p>
    <p>D tU</p>
    <p>Dn sf</p>
    <p>eU Ue</p>
    <p>G (G</p>
    <p>B )</p>
    <p>DelphL GDzelle</p>
    <p>Latency and communication</p>
    <p>&gt; 20x ~ 9x</p>
    <p>Comparison with Gazelle</p>
  </div>
  <div class="page">
    <p>Delphi</p>
    <p>Secure inference on convolutional neural networks  9-22x more efficient than prior work  Combines techniques from systems, cryptography, and ML</p>
    <p>ia.cr/2020/050</p>
    <p>github.com/mc2-project/delphi</p>
  </div>
</Presentation>
