<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>BLENDER: Enabling Local Search with a Hybrid Differential Privacy Model</p>
    <p>Brendan Avent1, Aleksandra Korolova1, David Zeber2, Torgeir Hovden2, Benjamin Livshits3</p>
    <p>University of Southern California1 Mozilla2 Imperial College London3</p>
    <p>Full paper available here.</p>
  </div>
  <div class="page">
    <p>Local Search</p>
    <p>Goal</p>
    <p>To make popular queries and their corresponding URLs available locally on users devices</p>
    <p>Why its needed?</p>
    <p>Caching popular search data avoids many round-trips to a server</p>
    <p>Reduces latency in web-browsing  Useful for temporary network</p>
    <p>disruptions  Enables new browser features</p>
    <p>g o</p>
    <p>t o</p>
    <p>t h</p>
    <p>e s</p>
    <p>e rv</p>
    <p>e r</p>
    <p>lo ca</p>
    <p>l se</p>
    <p>a rc</p>
    <p>h</p>
  </div>
  <div class="page">
    <p>Local Search with Privacy</p>
    <p>Why is privacy needed?</p>
    <p>Local search is generated from user data</p>
    <p>Want differential privacy guarantees</p>
  </div>
  <div class="page">
    <p>Local Search with Privacy</p>
    <p>Why is privacy needed?</p>
    <p>Local search is generated from user data</p>
    <p>Want differential privacy guarantees</p>
    <p>Algorithm  is , -differentially private iff for all neighboring databases  and  differing in the value of precisely one users data, the following inequality is satisfied for all possible sets of outputs   ():</p>
    <p>Pr      Pr     +</p>
  </div>
  <div class="page">
    <p>Local Search with Privacy</p>
    <p>Why is privacy needed?</p>
    <p>Local search is generated from user data</p>
    <p>Want differential privacy guarantees</p>
    <p>Why is differentially private local search hard?</p>
  </div>
  <div class="page">
    <p>Differential Privacy Models</p>
    <p>trusted curator model local model</p>
    <p>Each user privatizes their own data, then sends it to a central curator</p>
    <p>Requires less trust from users</p>
    <p>Central curator collects the data from all users, then performs privatization</p>
    <p>Most differentially private algorithms are in this model</p>
    <p>Requires the users to trust the curator with their private data</p>
    <p>Harsh utility trade-offs compared to trusted curator model algorithms [Chan et al 2012; Duchi et al 2013; Kairouz et al 2014, 2016]</p>
  </div>
  <div class="page">
    <p>Hybrid Model</p>
    <p>a more realistic privacy model</p>
  </div>
  <div class="page">
    <p>Users Have Heterogeneous Privacy Preferences</p>
  </div>
  <div class="page">
    <p>Hybrid Model for Differential Privacy</p>
    <p>H y</p>
    <p>b ri</p>
    <p>d m</p>
    <p>o d</p>
    <p>e l</p>
    <p>Allows some users to contribute in the Trusted Curator Model; others in the Local Model</p>
    <p>Tr u</p>
    <p>st e</p>
    <p>d c</p>
    <p>u ra</p>
    <p>to r</p>
    <p>m o</p>
    <p>d e</p>
    <p>l</p>
    <p>Beta users we call Opt-in</p>
    <p>users</p>
    <p>Lo ca</p>
    <p>l m o</p>
    <p>d e</p>
    <p>l</p>
    <p>Regular users we call</p>
    <p>Clients</p>
  </div>
  <div class="page">
    <p>Why a Hybrid Model?</p>
  </div>
  <div class="page">
    <p>Why a Hybrid Model?</p>
  </div>
  <div class="page">
    <p>Why a Hybrid Model?</p>
  </div>
  <div class="page">
    <p>Why a Hybrid Model?</p>
  </div>
  <div class="page">
    <p>BLENDER</p>
    <p>local search in the hybrid model</p>
  </div>
  <div class="page">
    <p>BLENDER Architecture</p>
  </div>
  <div class="page">
    <p>BLENDER Architecture</p>
  </div>
  <div class="page">
    <p>BLENDER Architecture</p>
  </div>
  <div class="page">
    <p>Opt-in Group Algorithm</p>
    <p>Two-phase approach: Discovery and Estimation</p>
    <p>Partition users into two disjoint groups</p>
    <p>Group A  Discovery phase</p>
    <p>Group B  Estimation phase</p>
  </div>
  <div class="page">
    <p>Opt-in Group Data: Discovery of Head List</p>
    <p>For each distinct &lt;query, URL&gt; record from Group As data:  Compute empirical probability</p>
    <p>Add Laplace noise to form noisy empirical probability</p>
    <p>If noisy empirical probability exceeds threshold, add record to the head list</p>
    <p>[Korolova et al, 2009]</p>
  </div>
  <div class="page">
    <p>Opt-in Group Data Usage: Estimation</p>
    <p>For each distinct &lt;query, URL&gt; record from Group Bs data and using the privatized head list:  Compute empirical probability</p>
    <p>Add Laplace noise to form noisy probability estimate</p>
    <p>Compute the sample variance of the probability estimate</p>
    <p>[Dwork et al, 2006]</p>
  </div>
  <div class="page">
    <p>BLENDER: Client Group</p>
  </div>
  <div class="page">
    <p>Client Data Reporting</p>
    <p>otherwise, report a query at random</p>
    <p>probability ,</p>
    <p>otherwise, report a URL at random</p>
  </div>
  <div class="page">
    <p>Server Aggregating Client Data</p>
    <p>Collects privatized reports from all users</p>
    <p>Aggregates the privatized reports into empirical probability estimates for each record</p>
    <p>Performs denoising procedure to generate unbiased probability estimates and variance estimates</p>
  </div>
  <div class="page">
    <p>BLENDER: Blending Stage</p>
    <p>,  -differentially private</p>
    <p>,  -differentially private</p>
    <p>,  -differentially private</p>
  </div>
  <div class="page">
    <p>Evaluation Measuring the utility of BLENDER</p>
  </div>
  <div class="page">
    <p>Experimental Datasets</p>
    <p># Users # Unique Queries # Unique URLs</p>
    <p>AOL (2006) 0.5M 4.8M 1.6M 10-5</p>
    <p>Yandex (2013) 4.9M 13.2M 12.7M 10-7</p>
  </div>
  <div class="page">
    <p>Measuring Utility</p>
    <p>Normalized Discounted Cumulative Gain (NDCG)</p>
    <p>Standard measure of ranking quality</p>
    <p>=  21</p>
    <p>log(+1)</p>
    <p>=</p>
    <p>Ideal</p>
    <p>NDCG of NDCGs</p>
    <p>21</p>
    <p>log(+1)</p>
  </div>
  <div class="page">
    <p>Comparison with Local Model [Qin et al, CCS 2016]</p>
    <p>N D</p>
    <p>C G</p>
    <p>epsilon</p>
    <p>CCS'16</p>
    <p>How does BLENDER compare to having all users use the Local Model?</p>
    <p>AOL dataset Head list size: 10</p>
  </div>
  <div class="page">
    <p>Comparison with Local Model [Qin et al, CCS 2016]</p>
    <p>N D</p>
    <p>C G</p>
    <p>epsilon</p>
    <p>Blender CCS'16</p>
    <p>How does BLENDER compare to having all users use the Local Model?</p>
    <p>AOL dataset Head list size: 10</p>
    <p>BLENDER  5% opt-in users  95% client users</p>
    <p>Caveat: Slightly different versions of NDCG. See paper.</p>
  </div>
  <div class="page">
    <p>Effect of Opt-in User Percentage on NDCG</p>
    <p>N D</p>
    <p>C G</p>
    <p>Percentage of users that opt-in</p>
    <p>How does BLENDERs utility depend on the size of the opt-in user group?</p>
    <p>Yandex dataset  = 4 Head list sizes: 50, 100, 500</p>
  </div>
  <div class="page">
    <p>Effect of Privacy Budget on NDCG</p>
    <p>N D</p>
    <p>C G</p>
    <p>epsilon</p>
    <p>How does BLENDERs utility depend on the privacy budget ?</p>
    <p>Yandex dataset 2.5% opt-in, 97.5% client Head list sizes: 10, 50, 100, 500</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Proposed a hybrid model for differential privacy</p>
    <p>Constructed a blended approach within the hybrid model for local search</p>
    <p>Achieved significant improvement on real world datasets with the blended</p>
    <p>approach</p>
  </div>
  <div class="page">
    <p>Future Work</p>
    <p>Improve on the sub-components of BLENDER to utilize state-of-the-art privatization methods</p>
    <p>Derive theoretical guarantees for the utility of BLENDER</p>
    <p>Reduce BLENDERs reliance on distributional assumptions</p>
    <p>Develop algorithms in the hybrid model for other applications</p>
  </div>
  <div class="page">
    <p>BLENDER: Enabling Local Search with a Hybrid Differential Privacy Model</p>
    <p>Brendan Avent1, Aleksandra Korolova1, David Zeber2, Torgeir Hovden2, Benjamin Livshits3</p>
    <p>Full paper available here.</p>
  </div>
</Presentation>
