<?xml version="1.0" ?>
<Presentation>
  <div class="page"/>
  <div class="page">
    <p>Deep Learning at Microsoft</p>
  </div>
  <div class="page">
    <p>Performance  Single digit millisecond inference</p>
    <p>Scalability  Millions of DNN model inferences per second  Tens of thousands of servers  Forty data centers worldwide</p>
    <p>Agility  New model deployment in minutes</p>
    <p>Flexibility  Variety of deep learning frameworks (ONNX, TF, PyTorch, etc)  Variety of hardware (CPU, GPU, etc)  Support Linux and Windows</p>
  </div>
  <div class="page">
    <p>M od</p>
    <p>el M</p>
    <p>as te</p>
    <p>r</p>
    <p>Model Metadata</p>
    <p>Model Placement</p>
    <p>Hardware Config uration</p>
    <p>O rc</p>
    <p>he st</p>
    <p>ra to</p>
    <p>r</p>
    <p>Model ServerAVX2 AVX512 Nvidia V100 Nvidia T4</p>
    <p>Model Containers</p>
    <p>Windows Model</p>
    <p>Windows Model</p>
    <p>Linux Model</p>
    <p>Linux Model</p>
    <p>Load Model</p>
    <p>Model Loader Model Executer</p>
    <p>Request Dispa tch</p>
    <p>Model Execution Request</p>
    <p>Router Request Routing</p>
    <p>Incoming Request</p>
  </div>
  <div class="page">
    <p>M od</p>
    <p>el M</p>
    <p>as te</p>
    <p>r</p>
    <p>Model Metadata</p>
    <p>Model Placement</p>
    <p>Hardware Configura tion</p>
    <p>O rc</p>
    <p>he st</p>
    <p>ra to</p>
    <p>r</p>
    <p>Model Server</p>
    <p>AVX2 AVX512</p>
    <p>Nvidia V100</p>
    <p>Nvidia T4</p>
  </div>
  <div class="page">
    <p>Model Containers</p>
    <p>Windows Model</p>
    <p>Windows Model</p>
    <p>Linux Model</p>
    <p>Linux Model</p>
    <p>Load Model</p>
    <p>Model Loader Model Executer</p>
    <p>Request Dispatch</p>
    <p>Model Execution Request</p>
  </div>
  <div class="page">
    <p>Router Request Routing</p>
    <p>Incoming Request</p>
  </div>
  <div class="page"/>
  <div class="page"/>
  <div class="page"/>
</Presentation>
