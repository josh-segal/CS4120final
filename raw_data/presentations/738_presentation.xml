<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Profiling Network Performance in Mul5-5er Datacenter Applica5ons</p>
    <p>Minlan Yu Princeton University</p>
    <p>Joint work with Albert Greenberg, Dave Maltz, Jennifer Rexford, Lihua Yuan, Srikanth Kandula, Changhoon Kim</p>
    <p>Scalable Net-App Profiler</p>
  </div>
  <div class="page">
    <p>Applica5ons inside Data Centers</p>
    <p>Front end Server</p>
    <p>Aggregator Workers</p>
    <p>.</p>
    <p>. . .</p>
  </div>
  <div class="page">
    <p>Challenges of Datacenter Diagnosis</p>
    <p>Large complex applica5ons  Hundreds of applica5on components  Tens of thousands of servers</p>
    <p>New performance problems  Update code to add features or fix bugs  Change components while app is s5ll in opera5on</p>
    <p>Old performance problems (Human factors)  Developers may not understand network well  Nagles algorithm, delayed ACK, etc.</p>
  </div>
  <div class="page">
    <p>Diagnosis in Todays Data Center</p>
    <p>Host</p>
    <p>App</p>
    <p>OS Packet sniffer</p>
    <p>App logs: #Reqs/sec Response 5me 1% req. &gt;200ms delay</p>
    <p>Switch logs: #bytes/pkts per minute</p>
    <p>Packet trace: Filter out trace for long delay req.</p>
    <p>SNAP: Diagnose net-app interac5ons</p>
    <p>Applica5on-specific</p>
    <p>Too expensive</p>
    <p>Too coarse-grained Generic, fine-grained, and lightweight</p>
  </div>
  <div class="page">
    <p>SNAP: A Scalable Net-App Profiler</p>
    <p>that runs everywhere, all the 5me</p>
  </div>
  <div class="page">
    <p>SNAP Architecture</p>
    <p>At each host for every connec5on</p>
    <p>Collect data</p>
  </div>
  <div class="page">
    <p>Collect Data in TCP Stack</p>
    <p>TCP understands net-app interac5ons  Flow control: How much data apps want to read/write  Conges5on control: Network delay and conges5on</p>
    <p>Collect TCP-level sta5s5cs  Defined by RFC 4898  Already exists in todays Linux and Windows OSes</p>
  </div>
  <div class="page">
    <p>TCP-level Sta5s5cs</p>
    <p>Cumula5ve counters  Packet loss: #FastRetrans, #Timeout  RTT es5ma5on: #SampleRTT, #SumRTT  Receiver: RwinLimitTime  Calculate the difference between two polls</p>
    <p>Instantaneous snapshots  #Bytes in the send buffer  Conges5on window size, receiver window size  Representa5ve snapshots based on Poisson sampling</p>
  </div>
  <div class="page">
    <p>SNAP Architecture</p>
    <p>At each host for every connec5on</p>
    <p>Collect data</p>
    <p>Performance Classifier</p>
  </div>
  <div class="page">
    <p>Life of Data Transfer</p>
    <p>Applica5on generates the data</p>
    <p>Copy data to send buffer</p>
    <p>TCP sends data to the network</p>
    <p>Receiver receives the data and ACK</p>
    <p>Sender App</p>
    <p>Send Buffer</p>
    <p>Receiver</p>
    <p>Network</p>
  </div>
  <div class="page">
    <p>Taxonomy of Network Performance</p>
    <p>No network problem</p>
    <p>Send buffer not large enough</p>
    <p>Fast retransmission  Timeout</p>
    <p>Not reading fast enough (CPU, disk, etc.)  Not ACKing fast enough (Delayed ACK)</p>
    <p>Sender App</p>
    <p>Send Buffer</p>
    <p>Receiver</p>
    <p>Network</p>
  </div>
  <div class="page">
    <p>Iden5fying Performance Problems</p>
    <p>Not any other problems</p>
    <p>#bytes in send buffer</p>
    <p>#Fast retransmission  #Timeout</p>
    <p>RwinLimitTime  Delayed ACK diff(SumRTT) &gt; diff(SampleRTT)*MaxQueuingDelay</p>
    <p>Sender App</p>
    <p>Send Buffer</p>
    <p>Receiver</p>
    <p>Network Direct measure</p>
    <p>Sampling</p>
    <p>Inference</p>
  </div>
  <div class="page">
    <p>Management System</p>
    <p>SNAP Architecture</p>
    <p>At each host for every connec5on</p>
    <p>Collect data</p>
    <p>Performance Classifier</p>
    <p>Cross- connec5on correla5on</p>
    <p>Topology, rou5ng Conn  proc/app</p>
    <p>Offending app, host, link, or switch</p>
  </div>
  <div class="page">
    <p>Pinpoint Problems via Correla5on</p>
    <p>Correla5on over shared switch/link/host  Packet loss for all the connec5ons going through one switch/host</p>
    <p>Pinpoint the problema5c switch</p>
  </div>
  <div class="page">
    <p>Pinpoint Problems via Correla5on</p>
    <p>Correla5on over applica5on  Same applica5on has problem on all machines  Report aggregated applica5on behavior</p>
  </div>
  <div class="page">
    <p>Management System</p>
    <p>SNAP Architecture</p>
    <p>At each host for every connec5on</p>
    <p>Collect data</p>
    <p>Performance Classifier</p>
    <p>Cross- connec5on correla5on</p>
    <p>Topology, rou5ng Conn  proc/app</p>
    <p>Offending app, host, link, or switch</p>
    <p>Online, lightweight processing &amp; diagnosis</p>
    <p>Offline, cross-conn diagnosis</p>
  </div>
  <div class="page">
    <p>Reducing SNAP Overhead</p>
    <p>SNAP overhead  Data volume: 120 Bytes per connec5on per poll  CPU overhead:  5% for polling 1K connec5ons with 500 ms interval  Increases with #connec5ons and polling freq.</p>
    <p>Solu5on: Adap5ve tuning of polling frequency  Reduce polling frequency to stay within a target CPU  Devote more polling to more problema5c connec5ons</p>
  </div>
  <div class="page">
    <p>SNAP in the Real World</p>
  </div>
  <div class="page">
    <p>Key Diagnosis Steps</p>
    <p>Iden5fy performance problems  Correlate across connec5ons  Iden5fy applica5ons with severe problems</p>
    <p>Expose simple, useful informa5on to developers  Filter important sta5s5cs and classifica5on results</p>
    <p>Iden5fy root cause and propose solu5ons  Work with operators and developers  Tune TCP stack or change applica5on code</p>
  </div>
  <div class="page">
    <p>SNAP Deployment</p>
    <p>Deployed in a produc5on data center  8K machines, 700 applica5ons  Ran SNAP for a week, collected terabytes of data</p>
    <p>Diagnosis results  Iden5fied 15 major performance problems  21% applica5ons have network performance problems</p>
  </div>
  <div class="page">
    <p>Characterizing Perf. Limita5ons</p>
    <p>Send Buffer</p>
    <p>Receiver</p>
    <p>Network</p>
    <p>#Apps that are limited for &gt; 50% of the 5me</p>
    <p>Send buffer not large enough</p>
    <p>Fast retransmission  Timeout</p>
    <p>Not reading fast enough (CPU, disk, etc.)  Not ACKing fast enough (Delayed ACK)</p>
  </div>
  <div class="page">
    <p>Three Example Problems</p>
    <p>Delayed ACK affects delay sensi5ve apps  Conges5on window allows sudden burst</p>
    <p>Significant 5meouts for low-rate flows</p>
  </div>
  <div class="page">
    <p>Problem 1: Delayed ACK  Delayed ACK affected many delay sensi5ve apps  even #pkts per record  1,000 records/sec odd #pkts per record  5 records/sec  Delayed ACK was used to reduce bandwidth usage and server interrupts</p>
    <p>Data</p>
    <p>ACK</p>
    <p>Data</p>
    <p>A B</p>
    <p>ACK</p>
    <p>. Proposed solu5ons: Delayed ACK should be disabled in data centers</p>
    <p>ACK every other packet</p>
  </div>
  <div class="page">
    <p>Receiver</p>
    <p>Socket send buffer</p>
    <p>Send Buffer and Delayed ACK</p>
    <p>Applica5on buffer</p>
    <p>Applica5on</p>
    <p>Network Stack 2. ACK</p>
    <p>With Socket Send Buffer</p>
    <p>Receiver</p>
    <p>Applica5on buffer</p>
    <p>Applica5on</p>
    <p>Zero-copy send</p>
    <p>SNAP diagnosis: Delayed ACK and zero-copy send</p>
  </div>
  <div class="page">
    <p>Problem 2: Conges5on Window Allows Sudden Bursts</p>
    <p>Increase conges5on window to reduce delay  To send 64 KB data with 1 RTT  Developers inten5onally keep conges5on window large  Disable slow start restart in TCP</p>
    <p>t</p>
    <p>Window Drops after an idle time</p>
  </div>
  <div class="page">
    <p>Slow Start Restart</p>
    <p>SNAP diagnosis  Significant packet loss  Conges5on window is too large aler an idle period</p>
    <p>Proposed solu5ons  Change apps to send less data during conges5on  New transport protocols that consider both conges5on and delay</p>
  </div>
  <div class="page">
    <p>Problem 3: Timeouts for Low-rate Flows</p>
    <p>SNAP diagnosis  More fast retrans. for high-rate flows (1-10MB/s)  More 5meouts with low-rate flows (10-100KB/s)</p>
    <p>Proposed solu5ons  Reduce 5meout 5me in TCP stack  New ways to handle packet loss for small flows</p>
  </div>
  <div class="page">
    <p>Conclusion  A simple, efficient way to profile data centers  Passively measure real-5me network stack informa5on  Systema5cally iden5fy problema5c stages  Correlate problems across connec5ons</p>
    <p>Deploying SNAP in produc5on data center  Diagnose net-app interac5ons  A quick way to iden5fy them when problems happen</p>
    <p>Future work  Extend SNAP to diagnose wide-area transfers</p>
  </div>
  <div class="page">
    <p>Thanks!</p>
  </div>
</Presentation>
