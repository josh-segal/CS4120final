<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Exploring Semantic Properties of Sentence Embeddings</p>
    <p>Xunjie Zhu Rutgers University</p>
    <p>Gerard de Melo Rutgers University</p>
    <p>Tingfeng Li * Northwestern Polytechnic</p>
    <p>University</p>
    <p>!1</p>
    <p>*Work conducted while visiting Rutgers University</p>
  </div>
  <div class="page">
    <p>Zhu, Li &amp; de Melo. Exploring Semantic Properties of Sentence Embeddings</p>
    <p>Introduction  Sentence Embeddings:</p>
    <p>Encode a variable-length input sentence into a constant size vector</p>
    <p>Examples:</p>
    <p>Based on Word Embeddings:</p>
    <p>(I) Glove Averaging (Wieting et al., 2015)</p>
    <p>(II) Concatenated P-Mean Embeddings (Ruckle et al. 2018)</p>
    <p>(III) Sent2Vec (Pagliardini et al. 2018)</p>
    <p>Based on RNNs:</p>
    <p>(I) SkipThought Vectors (Kiros et al. 2015)</p>
    <p>(II) InferSent (Conneau et al., 2017)</p>
    <p>!2</p>
  </div>
  <div class="page">
    <p>Zhu, Li &amp; de Melo. Exploring Semantic Properties of Sentence Embeddings</p>
    <p>Goal</p>
    <p>Exploring what specific semantic properties are directly reflected by such embeddings.</p>
    <p>Focusing on a few select aspects of sentence semantics.</p>
    <p>Concurrent related work: Conneau et al. ACL 2018</p>
    <p>(i) Their work studies what you can learn to predict using 100,000 training instances</p>
    <p>(ii) Our goal: Directly study the embeddings (via cosine similarity)</p>
    <p>!3</p>
  </div>
  <div class="page">
    <p>Zhu, Li &amp; de Melo. Exploring Semantic Properties of Sentence Embeddings</p>
    <p>Approach: Contrastive Sentences</p>
    <p>Minor alterations of a sentence may lead to notable shifts in meaning.</p>
    <p>(i) A rabbit is jumping over the fence ( )</p>
    <p>(ii) A rabbit is hopping over the fence ( )</p>
    <p>(iii) A rabbit is not jumping over the fence ( )</p>
    <p>!4</p>
    <p>S</p>
    <p>S*</p>
    <p>S=</p>
  </div>
  <div class="page">
    <p>Zhu, Li &amp; de Melo. Exploring Semantic Properties of Sentence Embeddings</p>
    <p>Sentence Modification Schemes</p>
    <p>Not-Negation</p>
    <p>Quantifier-Negation</p>
    <p>Synonym Substitution</p>
    <p>Embedded Clause Extraction</p>
    <p>Passivization</p>
    <p>Argument Reordering</p>
    <p>Fixed Point Inversion</p>
    <p>!5</p>
  </div>
  <div class="page">
    <p>Zhu, Li &amp; de Melo. Exploring Semantic Properties of Sentence Embeddings</p>
    <p>Negation Detection</p>
    <p>Original Sentence:</p>
    <p>A person is slicing an onion.</p>
    <p>Synonym Substitution:</p>
    <p>A person is cutting an onion.</p>
    <p>Not Negation:</p>
    <p>A person is not slicing an onion.</p>
    <p>!6</p>
  </div>
  <div class="page">
    <p>Zhu, Li &amp; de Melo. Exploring Semantic Properties of Sentence Embeddings</p>
    <p>Negation Variant</p>
    <p>Not Negation:</p>
    <p>A man is not standing on his head under water.</p>
    <p>Quantifier Negation:</p>
    <p>There is no man standing on his head under water.</p>
    <p>Original Sentence:</p>
    <p>A man is standing on his head under water.</p>
    <p>!7</p>
  </div>
  <div class="page">
    <p>Zhu, Li &amp; de Melo. Exploring Semantic Properties of Sentence Embeddings</p>
    <p>Clause Relatedness</p>
    <p>Original Sentence:</p>
    <p>Octel said the purchase was expected.</p>
    <p>Extracted Clause:</p>
    <p>The purchase was expected.</p>
    <p>Not Negation:</p>
    <p>Octel said the purchase was not expected</p>
    <p>!8</p>
  </div>
  <div class="page">
    <p>Zhu, Li &amp; de Melo. Exploring Semantic Properties of Sentence Embeddings</p>
    <p>Argument Sensitivity</p>
    <p>Original Sentence:</p>
    <p>Francesca teaches Adam to adjust the microphone on his stage</p>
    <p>Passivization:</p>
    <p>Adam is taught to adjust the microphone on his stage</p>
    <p>Argument Reordering:</p>
    <p>Adam teaches Francesca to adjust the microphone on his stage</p>
    <p>!9</p>
  </div>
  <div class="page">
    <p>Zhu, Li &amp; de Melo. Exploring Semantic Properties of Sentence Embeddings</p>
    <p>Fixed Point Reordering</p>
    <p>Original Sentence:</p>
    <p>A black dog in the snow is jumping off the ground and catching a stick.</p>
    <p>Synonym Substitution:</p>
    <p>A black dog in the snow is leaping off the ground and catching a stick.</p>
    <p>Fixed Point Inversion(Corrupted Sentence):</p>
    <p>In the snow is jumping off the ground and catching a stick a black dog.</p>
    <p>!10</p>
  </div>
  <div class="page">
    <p>Zhu, Li &amp; de Melo. Exploring Semantic Properties of Sentence Embeddings</p>
    <p>Models and Dataset</p>
    <p>Dataset Embedding Dim</p>
    <p>Glove Avg Common Crawl 300</p>
    <p>P Means Common Crawl 300</p>
    <p>Sent2Vec English Wiki 600</p>
    <p>SkipThought Book Corpus 600</p>
    <p>InferSent SNLI 4096</p>
    <p># of Sentences From</p>
    <p>Negation Detection 674 SICK, SNLI</p>
    <p>Negation Variant 516 SICK, SNLI</p>
    <p>Clause Relatedness 567 Penn Treebank</p>
    <p>MSR Paraphrase</p>
    <p>Argument Sensitivity 445 SICK, MS Paraphrase</p>
    <p>Fixed Point Reordering 623 SICK</p>
    <p>!11</p>
  </div>
  <div class="page">
    <p>Average of Word Embeddings is more easier misled by negation.</p>
    <p>Both InferSent and SkipThought succeed in distinguishing unnegated sentences from negated ones.</p>
    <p>Negation Detection</p>
    <p>A cc</p>
    <p>ur ac</p>
    <p>y</p>
    <p>Glove Avg P Means Sent2Vec SkipThought InferSent</p>
    <p>!12 Zhu, Li &amp; de Melo. Exploring Semantic Properties of Sentence Embeddings</p>
  </div>
  <div class="page">
    <p>Both averaging of word embeddings and SkipThought are dismal in terms of the accuracy.</p>
    <p>InferSent appears to have acquired a better understanding of negation quantifiers, as these are commonplace in many NLI datasets.</p>
    <p>Negation Variant</p>
    <p>Glove Avg P Means Sent2Vec SkipThought InferSent</p>
    <p>!13 Zhu, Li &amp; de Melo. Exploring Semantic Properties of Sentence Embeddings</p>
  </div>
  <div class="page">
    <p>Both SkipThought vectors and InferSent works poorly when sub clause is much shorter than original one.</p>
    <p>Sent2vec best in distinguishing the embedded clause of a sentence from a negation of that sentence.</p>
    <p>Clause Relatedness</p>
    <p>Glove Avg P Means Sent2Vec SkipThought InferSent</p>
    <p>!14 Zhu, Li &amp; de Melo. Exploring Semantic Properties of Sentence Embeddings</p>
  </div>
  <div class="page">
    <p>None of the analyzed approaches prove adept at distinguishing the semantic information from structural information in this case.</p>
    <p>Argument Sensitivity</p>
    <p>Glove Avg P Means Sent2Vec SkipThought InferSent !15</p>
    <p>Zhu, Li &amp; de Melo. Exploring Semantic Properties of Sentence Embeddings</p>
  </div>
  <div class="page">
    <p>Methods based on word embeddings do not encode sufficient word order information into the sentence embeddings.</p>
    <p>SkipThought and InferSent did well when the original sentence and its semantically equivalence share similar structure</p>
    <p>Fixed Point Reordering</p>
    <p>Glove Avg P Means Sent2Vec SkipThought InferSent !16</p>
    <p>Zhu, Li &amp; de Melo. Exploring Semantic Properties of Sentence Embeddings</p>
  </div>
  <div class="page">
    <p>Zhu, Li &amp; de Melo. Exploring Semantic Properties of Sentence Embeddings</p>
    <p>Conclusion</p>
    <p>RNN based sentence embeddings better at identifying negation compared with word embedding based models</p>
    <p>Both SkipThought and InferSent distinguish negation of a sentence from synonymy.</p>
    <p>InferSent better at identifying semantic equivalence regardless of the order of words and copes better with quantifiers.</p>
    <p>SkipThoughts is more suitable for tasks in which the semantics of the sentence corresponds to its structure</p>
    <p>!17</p>
  </div>
  <div class="page">
    <p>Thank you!</p>
    <p>Questions? Contact us at</p>
    <p>xunjie.zhu@rutgers.edu and gdm@demelo.org</p>
  </div>
</Presentation>
