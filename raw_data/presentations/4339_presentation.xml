<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>A MULTI-AXIS ANNOTATION SCHEME FOR</p>
    <p>EVENT TEMPORAL RELATIONS</p>
    <p>Qiang Ning, Hao Wu, and Dan Roth</p>
    <p>University of Illinois, Urbana-Champaign &amp; University of Pennsylvania</p>
  </div>
  <div class="page">
    <p>TOWARDS NATURAL LANGUAGE UNDERSTANDING</p>
  </div>
  <div class="page">
    <p>TIME IS IMPORTANT</p>
    <p>[June, 1989] Chris Robin lives in England and he is the person that you read about in Winnie the Pooh. As a boy, Chris lived in Cotchfield Farm. When he was three, his father wrote a poem about him. His father later wrote Winnie the Pooh in 1925. q Where did Chris Robin live?</p>
  </div>
  <div class="page">
    <p>TIME IS IMPORTANT</p>
    <p>[June, 1989] Chris Robin lives in England and he is the person that you read about in Winnie the Pooh. As a boy, Chris lived in Cotchfield Farm. When he was three, his father wrote a poem about him. His father later wrote Winnie the Pooh in 1925. q Where did Chris Robin live?</p>
    <p>This is time sensitive. q When was Chris Robin born?</p>
  </div>
  <div class="page">
    <p>TIME IS IMPORTANT</p>
    <p>[June, 1989] Chris Robin lives in England and he is the person that you read about in Winnie the Pooh. As a boy, Chris lived in Cotchfield Farm. When he was three, his father wrote a poem about him. His father later wrote Winnie the Pooh in 1925. q Where did Chris Robin live?</p>
    <p>This is time sensitive.</p>
    <p>q When was Chris Robin born?  Based on text: &lt;=1922</p>
    <p>q Requires identifying relations between events, and temporal reasoning.</p>
    <p>q Temporal relation extraction  A happens BEFORE/AFTER B;</p>
    <p>Events are associated with time intervals: !&quot;#$%#&amp; ,!()*&amp; , !&quot;#$%#+ ,!()*+  12 temporal relations in every 100 tokens (in TempEval3 datasets)</p>
    <p>Time could be expressed implicitly</p>
    <p>poem [Chris at age 3] ,-./0</p>
    <p>Winnie the Pooh [1925](Wikipedia: 1920)</p>
  </div>
  <div class="page">
    <p>TEMPORAL RELATIONS: A KEY COMPONENT</p>
    <p>Temporal Relation (TempRel): I turned off the lights and left.  Challenges faced by existing datasets/annotation schemes:</p>
    <p>q Low inter-annotator agreement (IAA)  TB-Dense: Cohens ! 56%~64%  RED: F1&lt;60%  EventTimeCorpus: Krippendorffs &quot;  60%</p>
    <p>q Time consuming: Typically, 2-3 hours for a single document.</p>
    <p>Our goal is to address these challenges, q And, understand the task of temporal relations better.</p>
  </div>
  <div class="page">
    <p>HIGHLIGHTS AND OUTLINE</p>
    <p>What we did:  276 docs: Annotated the 276 documents from TempEval3  1 week: Finished in about one week (using crowdsourcing)  $10: Costs roughly $10/doc  80%: IAA improved from literatures 60% to 80%  Re-thinking identifying temporal relations between events</p>
    <p>q Results in re-defining the temporal relations task, and the corresponding annotation scheme, in order to make it feasible</p>
    <p>Outline of our approach (3 components) q Multi-axis: types of events and their temporal structure q Start &amp; End points: end-points are a source of confusion/ambiguity q Crowdsourcing: collect data more easily while maintaining a good quality</p>
  </div>
  <div class="page">
    <p>Police tried to eliminate the pro-independence army and restore order. At least 51 people were killed in clashes between police and citizens in the troubled region.</p>
    <p>Task: to annotate the TempRels between the bold faced events (according to their start-points).</p>
    <p>Existing Scheme 1: General graph modeling (e.g., TimeBank, ~2007) q Annotators freely add TempRels between those events. q Its inevitable that some TempRels will be missed,</p>
    <p>Pointed out in many works.</p>
    <p>q E.g., only one relation between eliminate and restore is annotated in TimeBank, while other relations such as tried is before eliminate and tried is also before killed are missed.</p>
  </div>
  <div class="page">
    <p>Police tried to eliminate the pro-independence army and restore order. At least 51 people were killed in clashes between police and citizens in the troubled region.</p>
    <p>Existing Scheme 2: Chain modeling (e.g., TimeBank-Dense ~2014) q All event pairs are presented, one-by-one, and an annotator must</p>
    <p>provide a label for each of them.</p>
    <p>q No missing relations anymore. q Rationale: In the physical world, time is one dimensional, so we should</p>
    <p>be able to temporally compare any two events.</p>
    <p>q However, some pairs of events are very confusing, resulting in low agreement.</p>
    <p>q E.g., whats the relation between restore and killed?</p>
  </div>
  <div class="page">
    <p>Police tried to eliminate the pro-independence army and restore order. At least 51 people were killed in clashes between police and citizens in the troubled region.</p>
    <p>Why is restore vs killed confusing? q One possible explanation: the text doesnt provide evidence that the</p>
    <p>restore event actually happened, while killed actually happened q So, non-actual events dont have temporal relations?</p>
    <p>We dont think so: q tried is obviously before restore: actual vs non-actual q eliminate is obviously before restore: non-actual vs non-actual q So relations may exist between non-actual events.</p>
  </div>
  <div class="page">
    <p>Police tried to eliminate the pro-independence army and restore order. At least 51 people were killed in clashes between police and citizens in the troubled region.</p>
    <p>We suggest that while time is 1-dimensional in the physical world, multiple temporal axes may exist in natural language.</p>
    <p>police tried 51 people killed</p>
    <p>to eliminate army</p>
    <p>to restore order</p>
  </div>
  <div class="page">
    <p>Police tried to eliminate the pro-independence army and restore order. At least 51 people were killed in clashes between police and citizens in the troubled region.</p>
    <p>Is it a non-actual event axis?We think no. q First, tried, an actual event, is on both axes. q Second, whether restore is non-actual is questionable. Its very likely that</p>
    <p>order was indeed restored in the end.</p>
    <p>police tried 51 people killed</p>
    <p>to eliminate army</p>
    <p>to restore order</p>
    <p>Real world axis</p>
    <p>?Non-actual axis</p>
  </div>
  <div class="page">
    <p>Police tried to eliminate the pro-independence army and restore order. At least 51 people were killed in clashes between police and citizens in the troubled region.</p>
    <p>Instead, we argue that its an Intention Axis  It contains events that are intentions: restore and eliminate</p>
    <p>q and intersects with the real world axis at the event that invokes these intentions: tried</p>
    <p>police tried 51 people killed</p>
    <p>to eliminate army</p>
    <p>to restore order</p>
    <p>Real world axis</p>
    <p>Intention axis</p>
  </div>
  <div class="page">
    <p>INTENTION VS ACTUALITY</p>
    <p>Identifying intention can be done locally, while identifying actuality often depends on other events.</p>
    <p>Text Intention? Actual?</p>
    <p>I called the police to report the body. Yes Yes</p>
    <p>I called the police to report the body, but the line was busy.</p>
    <p>Yes No</p>
    <p>Police came to restore order. Yes Yes</p>
    <p>Police came to restore order, but 51 people were killed.</p>
    <p>Yes No</p>
  </div>
  <div class="page">
    <p>So far, we introduced the intention axis and distinguished it from (non-) actuality axis.</p>
    <p>The paper extends these ideas to more axes and discusses their difference form (non-)actuality axes q Sec. 2.2 &amp; Appendix A; Sec. 2.3.3 &amp; Appendix B.</p>
    <p>Event Type Time Axis % intention, opinion orthogonal axis ~20</p>
    <p>hypothesis, generic parallel axis</p>
    <p>~10Negation not on any axis</p>
    <p>static, recurrent not considered now</p>
    <p>all others main axis ~70</p>
  </div>
  <div class="page">
    <p>Scheme 1: General graph modeling - E.g., TimeBank - No restrictions on modeling - Relations are inevitably missed</p>
    <p>Scheme 2: Chain modeling - E.g., TimeBank-Dense - A strong restriction on</p>
    <p>modeling - Any pair is comparable - But many are confusing</p>
    <p>Our proposal: Multi-axis modeling  balances the extreme schemes.</p>
    <p>Allows dense modeling, but only within an axis.</p>
  </div>
  <div class="page">
    <p>OVERVIEW: MULTI-AXIS ANNOTATION SCHEME</p>
    <p>Step 0: Given a document in raw text  Step 1: Annotate all the events  Step 2: Assign axis to each event (intention, hypothesis, )  Step 3: On each axis, perform a dense annotation scheme</p>
    <p>In this paper, we use events provided by TempEval3, so we skipped Step 1.</p>
    <p>Our second contribution is successfully using crowdsourcing for Step 2 and Step 3, while maintaining a good quality.</p>
  </div>
  <div class="page">
    <p>Platform: CrowdFlower https://www.crowdflower.com/  Annotation guidelines: Find at</p>
    <p>http://cogcomp.org/page/publication_view/834  Quality control: A gold set is annotated by experts beforehand.</p>
    <p>q Qualification: Before working on this task, one has to pass with 70% accuracy on sample gold questions.</p>
    <p>q Important: with the older task definition, annotators did not pass the qualification test.</p>
    <p>q Survival: During annotation, gold questions will be given to annotators without notice, and one has to maintain 70% accuracy; otherwise, one will be kicked out and all his/her annotations will be discarded.</p>
    <p>q Majority vote: At least 5 different annotators are required for every judgement and by default, the majority vote will be the final decision.</p>
  </div>
  <div class="page">
    <p>Given two time intervals: !&quot;#$%#&amp; ,!()*&amp; , !&quot;#$%#+ ,!()*+</p>
    <p>How durative events are expressed (by authors) and perceived (by readers):</p>
    <p>q Readers usually take longer to perceive durative events than punctual</p>
    <p>events, e.g., restore order vs. try to restore order. q Writers usually assume that readers have a prior knowledge of durations</p>
    <p>(e.g., college takes 4 years and watching an NBA game takes a few hours)</p>
    <p>We only annotate start-points because duration annotation should be a different task and follow special guidelines.</p>
    <p>Metric Pilot Task 1 !&quot;#$%#&amp; ,- !&quot;#$%#+</p>
    <p>Pilot Task 2 !./0&amp; ,- !()*+</p>
    <p>Interpretation</p>
    <p>Qualification pass rate 50% 11% Comparing the end-points is</p>
    <p>significantly harder than comparing</p>
    <p>the start-points. Survival rate 74% 56%</p>
    <p>Accuracy on gold 67% 37%</p>
    <p>Avg. response time 33 sec 52 sec Task 2 is also significantly slower.</p>
  </div>
  <div class="page">
    <p>OVERVIEW: MULTI-AXIS ANNOTATION SCHEME</p>
    <p>Step 0: Given a document in raw text  Step 1: Annotate all the events  Step 2: Assign axis to each event (intention, hypothesis, )  Step 3: On each axis, perform a dense annotation scheme</p>
    <p>according to events start-points</p>
  </div>
  <div class="page">
    <p>QUALITY METRICS OF OUR NEW DATASET</p>
    <p>Remember: Literature expert !/#$ values are around 60%  For interested readers, please refer to our paper for more</p>
    <p>analysis regarding each individual label.  Worker Agreement With Aggregate (WAWA): assumes that the</p>
    <p>aggregated annotations are gold and then compute the accuracy.</p>
    <p>Step 2: Axis Step 3: TempRel Expert (~400 random relations) ! = 85% ! = 84%,#$ = 90%</p>
    <p>Crowdsourcing (same docs in</p>
    <p>TBDense)</p>
    <p>Accuracy 86% 88% Agreement (WAWA) 79% 81%</p>
  </div>
  <div class="page">
    <p>RESULT ON OUR NEW DATASET</p>
    <p>We implemented a baseline system, using conventional features and the sparse averaged perceptron algorithm</p>
    <p>The overall performance on the proposed dataset is much better than those in the literature for TempRel extraction, which used to be in the low 50s (Chambers et al., 2014; Ning et al., 2017). q We do NOT mean that the proposed baseline is better than other</p>
    <p>existing algorithms q Rather, the proposed annotation scheme better defines the machine</p>
    <p>learning task.</p>
    <p>Annotation Training Set Test Set Training Test</p>
    <p>P R F P R F TBDense Same-axis &amp; Cross-axis Same-axis 44 67 53 40 60 48 Proposed Same-axis Same-axis 73 81 77 66 72 69</p>
  </div>
  <div class="page">
    <p>CONCLUSION</p>
    <p>We proposed to re-think the important tasks of identifying temporal relations, resulting in a new annotation scheme it.</p>
    <p>Three components: q Multi-axis modeling: a balance between general graphs and chains</p>
    <p>q Identified that end-point is a major source of confusion</p>
    <p>q Showed that the new scheme is well-defined even for non-experts and crowdsourcing can be used.</p>
    <p>The proposed scheme significantly improves the inter-annotator agreement level, by ~20%.</p>
    <p>The resulting dataset defines an easier machine learning task.</p>
    <p>We hope that this work can be a good start for further investigation in this important area.</p>
    <p>Thank you!</p>
  </div>
</Presentation>
