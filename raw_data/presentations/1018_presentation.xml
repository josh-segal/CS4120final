<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Towards Production-Run Heisenbugs Reproduction on Commercial Hardware</p>
    <p>Shiyou Huang Bowen Cai and Jeff Huang</p>
  </div>
  <div class="page">
    <p>Whats a coders worst nightmare?</p>
    <p>https://www.quora.com/What-is-a-coders-worst-nightmare</p>
  </div>
  <div class="page">
    <p>The bug only occurs in production but cannot be replicated locally.</p>
    <p>https://www.quora.com/What-is-a-coders-worst-nightmare</p>
  </div>
  <div class="page">
    <p>Heisenbug</p>
    <p>When you trace them, they disappear!</p>
  </div>
  <div class="page">
    <p>Heisenbug</p>
    <p>When you trace them, they disappear!</p>
    <p>Localization is hard</p>
  </div>
  <div class="page">
    <p>Heisenbug</p>
    <p>When you trace them, they disappear!</p>
    <p>Localization is hard  reproduction is hard</p>
  </div>
  <div class="page">
    <p>Heisenbug</p>
    <p>When you trace them, they disappear!</p>
    <p>Localization is hard  reproduction is hard  never know if it is fixed</p>
  </div>
  <div class="page">
    <p>A motivating example</p>
    <p>T1 1: T2.start() 2: z=0 3: x++ 4: y++ 5: z=1 6: T2.join()</p>
    <p>T2 7: if (z==1) 8: assert(x+1==y)</p>
    <p>Init: x=1, y=2</p>
    <p>http://stackoverflow.com/questions/16159203/</p>
    <p>z=1</p>
    <p>x=2, y=3</p>
    <p>x+1==y</p>
    <p>contradiction!</p>
  </div>
  <div class="page">
    <p>A motivating example</p>
    <p>T1 1: T2.start() 2: z=0 3: x++ 4: y++ 5: z=1 6: T2.join()</p>
    <p>T2 7: if (z==1) 8: assert(x+1==y)</p>
    <p>Init: x=1, y=2</p>
    <p>http://stackoverflow.com/questions/16159203/</p>
    <p>z=1</p>
    <p>x=2, y=3</p>
    <p>x+1==y</p>
    <p>contradiction!</p>
    <p>PSO</p>
  </div>
  <div class="page">
    <p>A motivating example</p>
    <p>T1 1: T2.start() 2: z=0 3: x++ 4: y++ 5: z=1 6: T2.join()</p>
    <p>T2 7: if (z==1) 8: assert(x+1==y)</p>
    <p>Init: x=1, y=2</p>
    <p>http://stackoverflow.com/questions/16159203/</p>
    <p>z==1</p>
    <p>x=2, y=3</p>
    <p>x+1==y</p>
    <p>contradiction!</p>
    <p>$12 million loss of equipment!</p>
  </div>
  <div class="page">
    <p>Record &amp; Replay (RnR)</p>
    <p>Failure Execution</p>
    <p>RecordReplay</p>
    <p>Goal: record the non-determinism at runtime and reproduce the failure</p>
  </div>
  <div class="page">
    <p>Record &amp; Replay (RnR)</p>
    <p>Failure Execution</p>
    <p>RecordReplay</p>
    <p>Goal: record the non-determinism at runtime and reproduce the failure</p>
    <p>runtime overhead  the ability to reproduce failures</p>
  </div>
  <div class="page">
    <p>Related Work  Software-based approach</p>
    <p>order-based: fully record shared memory dependencies at runtime  LEAP[FSE10], Order[USENIX ATC11], Chimera[PLDI12], Light[PLDI15] RR[USENIX ATC17]</p>
    <p>Chimera: &gt; 2.4x</p>
    <p>search-based: partially record the dependencies at runtime and use offline analysis (e.g. SMT solvers) to reason the dependencies</p>
    <p>ODR[SOSP09], Lee et al. [MICRO09], Weeratunge et al.[ASPLOS10], CLAP[PLDI13]</p>
    <p>CLAP: 0.9x  3x</p>
    <p>Hardware-based approach  Rerun[ISCA08], Delorean[ISCA08], Coreracer[MICRO11], PBI[ASPLOS13]</p>
    <p>rely on special hardware that are not deployed 13</p>
  </div>
  <div class="page">
    <p>Reality of RnR</p>
    <p>high overheads  failing to reproduce failures  lack of commodity hardware</p>
    <p>support</p>
    <p>In production</p>
  </div>
  <div class="page">
    <p>Contributions</p>
    <p>Goal: record the execution at runtime with low overhead and faithfully reproduce it offline</p>
    <p>RnR based on control flow tracing on commercial hardware (Intel PT)</p>
    <p>core-based constraints reduction to reduce the offline computation</p>
    <p>H3, evaluated on popular benchmarks and real-world applications,</p>
    <p>overhead: 1.4%-23.4%</p>
  </div>
  <div class="page">
    <p>Intel Processor Trace (PT)</p>
    <p>PT: Program control flow tracing, supported on 5th and 6th generation Intel core  Low overhead, as low as 5%1</p>
    <p>Highly compacted packets, &lt;1 bit per retired instruction</p>
    <p>One bit (1/0) for branch taken indication</p>
    <p>Compressed branch target address</p>
  </div>
  <div class="page">
    <p>PT Tracing Overhead Intel CPU core 0...n</p>
    <p>Driver</p>
    <p>Packets stream (per logical CPU)</p>
    <p>Binary Image files</p>
    <p>Intel PT Software Decoder</p>
    <p>Reconstructed execution</p>
    <p>Configure &amp; Enable Intel PT</p>
    <p>Runtime data</p>
    <p>Figure 4: Components of Intel Processor Tracing (PT).</p>
    <p>gram control flow by code instrumentation is difficult or impossible. For example, if a failure is caused by a bug in the uninstrumented external code, the constraints generated by CLAP may be incomplete and hence fail to reproduce the bug.</p>
    <p>Next, we first review the basics of PT and then show its performance improvement over software path-recording on PARSEC 3.0 benchmarks [5].</p>
    <p>Intel PT. As depicted in Figure 4, PT consists of two main components: tracing and decoding. For tracing, it only records the instructions that are related to the change of the program control flow and omits everything that can be deduced from the code (e.g., unconditional direct jumps). For each conditional branch executed, PT generates a single bit (1/0) to indicate whether a conditional branch is taken or not taken. As such, PT tracks the control flow information, such as loops, conditional branches and function calls of the program, with minimal perturbation, and outputs a highly compact trace.</p>
    <p>For decoding, PT provides a decoding library [1] to reconstruct the control flow from the recorded raw trace. It first synchronizes the packet streams with the synchronization packets generated during tracing, and then iterates over the instructions from the binary image to identify what instructions have been executed. Only when the</p>
    <p>Table 1: Runtime and space overhead of PT on PARSEC.</p>
    <p>Program Native PT</p>
    <p>time (s) time (s) OH(%) trace bodytrack 0.557 0.573 2.9% 94M</p>
    <p>x264 1.086 1.145 5.4% 88M vips 1.431 1.642 14.7% 98M</p>
    <p>blackscholes 1.51 1.56 9.9% 289M ferret 1.699 1.769 4.1% 145M</p>
    <p>swaptions 2.81 2.98 6.0% 897M raytrace 3.818 4.036 5.7% 102M facesim 5.048 5.145 1.9% 110M</p>
    <p>fluidanimate 14.8 15.1 1.4% 1240M freqmine 15.9 17.1 7.5% 2468M</p>
    <p>Avg. 4.866 5.105 4.9% 553M</p>
    <p>decoder cannot decide the next instruction (e.g., when it encounters a branch), the raw trace is queried to guide the decoding process.</p>
    <p>PT is configurable via a set of model-specific registers by the kernel driver. It provides a privilege-level filtering function for developers to decide what code to trace (i.e. kernel vs. user-space) and a CR3 filtering function to trace only a single application or process. PT on Intel Skylake processors also supports filtering by the instruction pointer (IP) addresses. This feature allows PT to selectively trace code that is only within a certain IP range, which can further reduce the tracing perturbation.</p>
    <p>PT Performance. Table 1 reports the runtime and space overhead of PT on the PARSEC 3.0 benchmarks. We report the execution time of the programs without and with PT tracing (and the trace size), marked as native and PT respectively. Among the 10 benchmarks, PT incurs 1.4% to 14.7% runtime overhead (4.9% on average) and 88MB to 2.4GB space overhead (0.5GB on average).</p>
    <p>In this section, we present the technical details of H3. As we have described in Figure 1, H3 integrates hardware control-flow tracing with offline symbolic constraint analysis to reproduce Heisenbugs. Although the overall flow is easy to understand, there are three technical challenges in the integration:</p>
  </div>
  <div class="page">
    <p>Challenges</p>
    <p>PT trace: low-level representation (assembly instruction)</p>
    <p>Absence of the thread information</p>
    <p>No data values of memory accesses</p>
  </div>
  <div class="page">
    <p>Solutions</p>
    <p>PT trace: low-level representation &amp; no data values  Idea: extract the path profiles from PT trace and re-execute the program by KLEE to generate symbol values</p>
    <p>Absence of the thread information  Idea: use thread context switch information by Perf</p>
  </div>
  <div class="page">
    <p>H3 Overview core 0 core 1</p>
    <p>core 3core 2</p>
    <p>T0 Tn...Binary image</p>
    <p>Execution recorded by each core</p>
    <p>Packet log Decode</p>
    <p>user end Symbolic trace of each thread</p>
    <p>schedule</p>
    <p>Recording &amp; Decoding Offline Constraints Construction &amp; Solving</p>
    <p>- Path constraints - Core-based read-write constraints - Synchronization constraints - Memory order constraints</p>
    <p>- Path profiles generation</p>
    <p>- Symbolic execution</p>
    <p>PT tracing</p>
    <p>Phase 1: Control-flow tracing</p>
    <p>Phase 2: Offline analysis</p>
    <p>Reconstruct the execution on each core by decoding the packets generated by PT and thread information from Perf</p>
    <p>Path profiles of each thread  Symbolic trace of each thread  SMT constraints over the trace</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>T1 1: T2.start() 2: z=0 3: x++ 4: y++ 5: z=1 6: T2.join()</p>
    <p>T2 7: if (z==1) 8: assert(x+1==y)</p>
    <p>A</p>
    <p>CB</p>
    <p>D</p>
    <p>FE</p>
    <p>Packets log+</p>
    <p>line 1 line 2</p>
    <p>... line n</p>
    <p>Decoding</p>
    <p>Matching line numbers</p>
    <p>Binary image</p>
    <p>reconstructed execution program's cotrol flow</p>
    <p>Binary image</p>
    <p>Trace Packets</p>
    <p>Step1: Collecting path profiles of each thread</p>
    <p>libipt</p>
    <p>Init: x=1, y=2 PT: tracing control-flow of the programs execution</p>
    <p>perf context switch events (TID, CPUID, TIME)</p>
    <p>T1</p>
    <p>A</p>
    <p>CB</p>
    <p>D</p>
    <p>FE</p>
    <p>Packets log+</p>
    <p>line 1 line 2</p>
    <p>... line n</p>
    <p>Decoding</p>
    <p>Matching line numbers</p>
    <p>Binary image</p>
    <p>reconstructed execution program's cotrol flow</p>
    <p>T2</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>T1 1: T2.start() 2: z=0 3: x++ 4: y++ 5: z=1 6: T2.join()</p>
    <p>T2 7: if (z==1) 8: assert(x+1==y)</p>
    <p>BB1</p>
    <p>T1 : bb1</p>
    <p>T2 : bb1, bb2</p>
    <p>BB3</p>
    <p>BB1</p>
    <p>BB2</p>
    <p>Step1: Collecting path profiles of each thread</p>
    <p>Match to *.ll</p>
    <p>Init: x=1, y=2 PT: tracing control-flow of the programs execution</p>
    <p>A</p>
    <p>CB</p>
    <p>D</p>
    <p>FE</p>
    <p>Packets log+</p>
    <p>line 1 line 2</p>
    <p>... line n</p>
    <p>Decoding</p>
    <p>Matching line numbers</p>
    <p>Binary image</p>
    <p>reconstructed execution program's cotrol flow</p>
    <p>A</p>
    <p>CB</p>
    <p>D</p>
    <p>FE</p>
    <p>Packets log+</p>
    <p>line 1 line 2</p>
    <p>... line n</p>
    <p>Decoding</p>
    <p>Matching line numbers</p>
    <p>Binary image</p>
    <p>reconstructed execution program's cotrol flow</p>
    <p>T2</p>
    <p>T1</p>
    <p>path profile</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>T1 1: T2.start() 2: z=0 3: x++ 4: y++ 5: z=1 6: T2.join()</p>
    <p>T2 7: if (z==1) 8: assert(x+1==y)</p>
    <p>Init: x=1, y=2 Step2: symbolic trace generation</p>
    <p>KLEE[OSDI08]: execute the thread along the path profile</p>
    <p>&quot;# = 0 '(,'( = '( + 1 ,-,,- = ,- + 1 &quot;. = 1</p>
    <p>&quot;4 == 1 '5 + 1  ,5</p>
    <p>T1</p>
    <p>T2</p>
    <p>Using symbol values to represent concrete values, e.g., &quot;# : value written to z at line 2 '( : value read from z at line 3</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>T1 1: T2.start() 2: z=0 3: x++ 4: y++ 5: z=1 6: T2.join()</p>
    <p>T2 7: if (z==1) 8: assert(x+1==y)</p>
    <p>Init: x=1, y=2 Step 3: computing global failure schedule CLAP[PLDI13]: Reason dependencies of memory accesses</p>
    <p>Order variable O represents the order of a statement, e.g., O2&lt;O3</p>
    <p>means 2:z=0 happen before 3: x++</p>
    <p>T1</p>
    <p>T2</p>
    <p>Global</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>T1 1: T2.start() 2: z=0 3: x++ 4: y++ 5: z=1 6: T2.join()</p>
    <p>T2 7: if (z==1) 8: assert(x+1==y)</p>
    <p>Init: x=1, y=2 Step 3: computing global failure schedule</p>
    <p>CLAP[PLDI13]: Reason dependencies of memory accesses</p>
    <p>Read-Write Constraints (&quot;#$ = 0  )$ &lt; )+)</p>
    <p>(&quot;#$ = .#/  )/ &lt; )$  ()+ &lt; )/  )$ &lt; )+)) Memory Order Constraints</p>
    <p>SC PSO )0 &lt; )+ &lt; )1</p>
    <p>)0 &lt; )+ )/ &lt; )6 )1 23 &lt; )1</p>
    <p>Path Constraints Failure Constraints &quot;#$ = 1 &quot;87 + 1! = &quot;97</p>
    <p>match a read to a write</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>T1 1: T2.start() 2: z=0 3: x++ 4: y++ 5: z=1 6: T2.join()</p>
    <p>T2 7: if (z==1) 8: assert(x+1==y)</p>
    <p>Init: x=1, y=2 Step 3: computing global failure schedule CLAP[PLDI13]: Reason dependencies of memory accesses</p>
    <p>Read-Write Constraints (&quot;#$ = 0  )$ &lt; )+)</p>
    <p>(&quot;#$ = .#/  )/ &lt; )$  ()+ &lt; )/  )$ &lt; )+)) Memory Order Constraints</p>
    <p>SC PSO )0 &lt; )+ &lt; )1</p>
    <p>)0 &lt; )+ )/ &lt; )6 )1 23 &lt; )1</p>
    <p>Path Constraints Failure Constraints &quot;#$ = 1 &quot;87 + 1! = &quot;97</p>
    <p>rf</p>
    <p>HB match a read to a write</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>T1 1: T2.start() 2: z=0 3: x++ 4: y++ 5: z=1 6: T2.join()</p>
    <p>T2 7: if (z==1) 8: assert(x+1==y)</p>
    <p>Init: x=1, y=2 Step 3: computing global failure schedule CLAP[PLDI13]: Reason dependencies of memory accesses</p>
    <p>Read-Write Constraints (&quot;#$ = 0  )$ &lt; )+)</p>
    <p>(&quot;#$ = .#/  )/ &lt; )$  ()+ &lt; )/  )$ &lt; )+)) Memory Order Constraints</p>
    <p>SC PSO )0 &lt; )+ &lt; )1</p>
    <p>)0 &lt; )+ )/ &lt; )6 )1 23 &lt; )1</p>
    <p>Path Constraints Failure Constraints &quot;#$ = 1 &quot;87 + 1! = &quot;97</p>
    <p>rf HA</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>T1 1: T2.start() 2: z=0 3: x++ 4: y++ 5: z=1 6: T2.join()</p>
    <p>T2 7: if (z==1) 8: assert(x+1==y)</p>
    <p>Init: x=1, y=2 Step 3: computing global failure schedule</p>
    <p>CLAP[PLDI13]: Reason dependencies of memory accesses</p>
    <p>Read-Write Constraints (&quot;#$ = 0  )$ &lt; )+)</p>
    <p>(&quot;#$ = .#/  )/ &lt; )$  ()+ &lt; )/  )$ &lt; )+)) Memory Order Constraints</p>
    <p>SC PSO )0 &lt; )+ &lt; )1</p>
    <p>)0 &lt; )+ )/ &lt; )6 )1 23 &lt; )1</p>
    <p>Path Constraints Failure Constraints &quot;#$ = 1 &quot;87 + 1! = &quot;97</p>
    <p>execution should be allowed by the memory model</p>
    <p>reordering PSO</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>T1 1: T2.start() 2: z=0 3: x++ 4: y++ 5: z=1 6: T2.join()</p>
    <p>T2 7: if (z==1) 8: assert(x+1==y)</p>
    <p>Init: x=1, y=2 Step 3: computing global failure schedule CLAP[PLDI13]: Reason dependencies of memory accesses</p>
    <p>Read-Write Constraints (&quot;#$ = 0  )$ &lt; )+)</p>
    <p>(&quot;#$ = .#/  )/ &lt; )$  ()+ &lt; )/  )$ &lt; )+)) Memory Order Constraints</p>
    <p>SC PSO )0 &lt; )+ &lt; )1</p>
    <p>)0 &lt; )+ )/ &lt; )6 )1 23 &lt; )1</p>
    <p>Path Constraints Failure Constraints &quot;#$ = 1 &quot;87 + 1! = &quot;97</p>
    <p>True make the failure happen</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>T1 1: T2.start() 2: z=0 3: x++ 4: y++ 5: z=1 6: T2.join()</p>
    <p>T2 7: if (z==1) 8: assert(x+1==y)</p>
    <p>Init: x=1, y=2 Step 3: computing global failure schedule CLAP[PLDI13]: Reason dependencies of memory accesses</p>
    <p>Read-Write Constraints (&quot;#$ = 0  )$ &lt; )+)</p>
    <p>(&quot;#$ = .#/  )/ &lt; )$  ()+ &lt; )/  )$ &lt; )+)) Memory Order Constraints</p>
    <p>SC PSO )0 &lt; )+ &lt; )1</p>
    <p>)0 &lt; )+ )/ &lt; )6 )1 23 &lt; )1</p>
    <p>Path Constraints Failure Constraints &quot;#$ = 1 &quot;87 + 1! = &quot;97</p>
    <p>Violation make the failure happen</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>T1 1: T2.start() 2: z=0 3: x++ 4: y++ 5: z=1 6: T2.join()</p>
    <p>T2 7: if (z==1) 8: assert(x+1==y)</p>
    <p>Init: x=1, y=2 Step 3: computing global failure schedule</p>
    <p>O1=1, O2=2, O3=3, O5=4, O7=5, O8=6, O4=7</p>
    <p>Schedule: 1-2-3-5-7-8-4reordering</p>
  </div>
  <div class="page">
    <p>Core-based constraints reduction</p>
    <p>the potential inter-thread memory dependencies; and Fmo the memory model constraints. The formula contains two types of variables: (1) V - the symbolic value variables denoting the values returned by reads; and (2) O - the order variables the order of each operation in the final global schedule.</p>
    <p>Path Constraints (Fpath). The path constraints are constructed by a conjunction of all the path conditions of each thread, with each path condition corresponds to a branch decision by that path. The path conditions are collected by recording the decision of each branch via symbolic execution. Bug Constraints (Fbug). The bug constraints enforce the conditions for a bug to happen. A bug can be a crash segfault, an assert violation, a buffer overflow, or any program state-based property. To construct the bug constraints, an expression over the symbol values for satisfying the bug conditions is generated. For example, the violation of an assertion ex p can be modeled as !ex p. Synchronization Constraints (Fsync). The synchronization constraints consist of two parts: partial order constraints and locking constraints. The partial order constraints model the order between different threads caused by synchronizations fork/join/signal/wait. For example, The begin event of a thread t should happen after the fork event that starts t. A join event for a thread t should happen after the last event of t. The locking constraints ensures that events guarded by the same lock are mutually exclusive. It is constructed over the ordering of the lock and unlock events. More specifically, for each lock, all the lock/unlock pairs of events are extracted, and the following constraints for each two pairs (l1, u1) and (l2, u2) are constructed: Ou1 &lt; Ol2 _ Ou2 &lt; Ol1 . Memory Order Constraints (Fmo). The memory order constraints enforce orders specified by the underlying memory models. H3 currently supports three memory models: SC, TSO and PSO. For SC, all the events by a single thread should happen in the program order. TSO allows a read to complete before an earlier write to a different memory location, but maintains a total order over writes and operations accessing the same memory location. PSO is similar to TSO, except that it allows re-ordering writes on different memory locations. Read-Write Constraints (Frw). Frw matches reads and writes by encoding constraints to enforce the read to return the value written by the write. Consider a read r on a variable v and r is matched to a write w on the same variable; we must construct the following constraints: the order variables of all the other writes that r can be matched to are either less than Ow or greater than Or .</p>
    <p>As discussed in Section 2.1, Frw can be complicated because there may exist many potential matches between reads and writes. The size of Frw is cubic in the trace</p>
    <p>Figure 5: Core-based constraint reduction.</p>
    <p>size and its complexity is exponential in the trace size. Nevertheless, in next subsection, we show that both the size and complexity of Frw can be greatly reduced in H3.</p>
    <p>The key observation of this reduction is that the executed memory accesses on each core decoded from PT trace are already ordered, following the program order. Once the order of a certain write in the global schedule is determined, all the writes that happen before or after this write, on the same core, should occur before or after this write in the schedule correspondingly. This eliminates a large number of otherwise necessary read-write constraints for capturing the potential inter-thread memory dependencies.</p>
    <p>Consider an example in Figure 5, which has four cores with each executing four different writes. Suppose there is a read R that can be potentially matched with all of these writes, because each of them writes a different value to the same shared variable read by R. Without the partial order information of each core, we must include all writes and their orderings into the constraints.</p>
    <p>All the writes write a different value to the same memory location</p>
    <p>Match R to the write W7</p>
  </div>
  <div class="page">
    <p>Core-based constraints reduction</p>
    <p>Without the partial order on each core</p>
    <p>W7-R</p>
    <p>W1 W2 W3 W15 W16</p>
  </div>
  <div class="page">
    <p>Core-based constraints reduction</p>
    <p>Without the partial order on each core</p>
    <p>W7-R</p>
    <p>W1 W2 W3 W15 W16</p>
  </div>
  <div class="page">
    <p>Core-based constraints reduction</p>
    <p>Without the partial order on each core</p>
    <p>W7-R</p>
    <p>W1 W2 W3 W15 W16</p>
  </div>
  <div class="page">
    <p>Core-based constraints reduction</p>
    <p>Without the partial order on each core</p>
    <p>W7-R</p>
    <p>W1 W2 W3 W15 W16</p>
  </div>
  <div class="page">
    <p>Core-based constraints reduction</p>
    <p>Without the partial order on each core</p>
    <p>W7-R</p>
    <p>W1 W2 W3 W15 W16</p>
  </div>
  <div class="page">
    <p>Core-based constraints reduction</p>
    <p>Knowing the partial order on each core</p>
    <p>W7-R</p>
    <p>W1 W2 W3 W4</p>
    <p>W13 W14 W15 W16</p>
  </div>
  <div class="page">
    <p>Core-based constraints reduction</p>
    <p>Knowing the partial order on each core</p>
    <p>W7-R</p>
    <p>W1 W2 W3 W4</p>
    <p>W13 W14 W15 W16</p>
  </div>
  <div class="page">
    <p>Core-based constraints reduction</p>
    <p>Knowing the partial order on each core</p>
    <p>W7-R</p>
    <p>W1 W2 W3 W4</p>
    <p>W13 W14 W15 W16</p>
    <p>reduced from 215</p>
  </div>
  <div class="page">
    <p>H3 Implementation</p>
    <p>Control-flow tracing  PT decoding library &amp; Linux Perf tool</p>
    <p>Path profiles generation  Python scripts to extract the path profiles from PT trace</p>
    <p>Symbolic trace collecting  Modified KLEE[OSDI08] for symbolic execution along the path profiles</p>
    <p>Constraints construction  Modified CLAP[PLDI13] to implement the core-based constraints reduction  Z3 for solving the constraints</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Environment  4 core 3.5GHz Intel i7 6700HQ Skylake with 16 GB RAM  Ubuntu 14.04, Linux kernel 4.7</p>
    <p>Three sets of experiments  runtime overhead  how effective to reproduce bugs  how effective is the core-based constraints reduction</p>
  </div>
  <div class="page">
    <p>Benchmarks Table 2: Benchmarks. Program LOC #Threads #SV</p>
    <p>#insns #branches #branches Ratio Symb. (executed) (total) (app) app/total time</p>
    <p>racey 192 4 3 1,229,632 78,117 77,994 99.8% 107s pfscan 1026 3 13 1,287 237 43 18.1% 2.5s</p>
    <p>aget-0.4.1 942 4 30 3,748 313 5 1.6% 117s pbzip2-0.9.4 1942 5 18 1,844,445 272,453 5 0.0018% 8.7s</p>
    <p>bbuf 371 5 11 1,235 257 3 1.2% 5.5s sbuf 151 2 5 64,993 11,170 290 2.6% 1.6s</p>
    <p>httpd-2.2.9 643K 10 22 366,665 63,653 12,916 20.3% 712s httpd-2.0.48 643K 10 22 366,379 63,809 13,074 20.5% 698s httpd-2.0.46 643K 10 22 366,271 63,794 12,874 20.2% 643s</p>
    <p>then only need to disjunct the order constraints between w and those writes from a different core.</p>
    <p>Our evaluation of H3 focuses on answering two sets of questions:</p>
    <p>How is the runtime performance of H3? How much runtime improvement is achieved by H3 compared to CLAP?</p>
    <p>How effective is H3 for reproducing real-world Heisenbugs? How effective is the core-based constraint reduction technique?</p>
    <p>We evaluated H3 with a variety of multithreaded C/C++ programs collected from previous studies [18, 35, 6], including nine popular real-world applications containing known Heisenbugs. Table 2 summarizes these benchmarks. pfscan is a parallel file scanner containing a known bug; aget-0.4.1 is a parallel ftp/http downloading tool containing a deadlock; pbzip2-0.9.4 is a multithreaded implementation of bzip with a known order violation; bbuf is shared bounded buffer and sbuf is a C++ implementation of the JDK1.4 StringBuffer class; httpd2.2.9, httpd-2.0.48, httpd-2.0.46 are from the Apache HTTP Server each containing a known concurrency bug; We also included racey [6], a special benchmark with intensive races that are designed for evaluating RnR systems. We use Apache Bench (ab) to test httpd, which is set to handle 100 requests with a maximum of 10 requests running concurrently.</p>
    <p>We compared the runtime performance of H3 and CLAP by measuring the time and space overhead caused by PT tracing and software path-recording. We ran each benchmark five times and calculated the average. All</p>
    <p>experiments were performed on a 4 core 3.5GHz Intel i7 6700HQ Skylake CPU with 16 GB RAM running Ubuntu 14.04.</p>
    <p>We evaluated the effectiveness of H3 for reproducing bugs by checking if H3 can generate a failure reproducing schedule and by measuring the time taken by offline constraint solving. We set one hour timeout for Z3 to solve the constraints.</p>
    <p>For most benchmarks, the failures are difficult to manifest because the erroneous schedule for triggering the Heisenbugs is rare. Similar to CLAP, we inserted timing delays (sleep functions) at key places in each benchmark and executed it repeatedly until the failure is produced. We also added the corresponding assertion to denote the bug manifestation.</p>
    <p>Benchmark Characteristics. Table 2 reports the execution characteristics of the benchmarks. Columns 3 and 4 report the number of threads and shared variables, respectively, contained in the execution. We also profiled the total number of the executed instructions and branches in the assembly code, and the branches from the LLVM IR code, as reported in Columns 5-7. Column 8 reports the ratio of the number of the branches in the instrumented application code versus the total number of branches (in both the application code and all the external libraries). For most benchmarks (except racey), the ratio is smaller than or around 20%. Column 9 reports the time for constructing the symbolic trace for the corresponding recorded execution of the benchmark.</p>
  </div>
  <div class="page">
    <p>Runtime overhead</p>
    <p>racey pfscan aget pbzip2 bbuf sbuf httpd1 httpd2 httpd3</p>
    <p>Ru nt im</p>
    <p>e ov er he</p>
    <p>ad</p>
    <p>Comparison between H3 and CLAP</p>
    <p>CLAP H3</p>
  </div>
  <div class="page">
    <p>Runtime overhead</p>
    <p>racey pfscan aget pbzip2 bbuf sbuf httpd1 httpd2 httpd3</p>
    <p>Ru nt im</p>
    <p>e ov er he</p>
    <p>ad</p>
    <p>Comparison between H3 and CLAP</p>
    <p>CLAP H3</p>
    <p>CLAP: 64.3% vs H3: 12.9% reduction: 31.3%</p>
  </div>
  <div class="page">
    <p>Constraints reduction</p>
    <p>bbuf sbuf pfscan pbzip2 racey1 racey2 racey3</p>
    <p>#C on</p>
    <p>st ra in ts</p>
    <p>Core-based constraints reduction by H3 to CLAP</p>
    <p>CLAP H3</p>
    <p>reduced by &gt; 30%</p>
    <p>reduced by &gt; 90%</p>
  </div>
  <div class="page">
    <p>Bug reproduction</p>
    <p>bbuf sbuf pfscan pbzip2 racey1 racey2 racey3</p>
    <p>#C on</p>
    <p>st ra in ts</p>
    <p>Core-based constraints reduction by H3 to CLAP</p>
    <p>CLAP H3</p>
    <p>Reproduced by both</p>
    <p>Only reproduced by H3</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>H3: Reproducing Heisenbugs based on control flow tracing on commercial hardware (Intel PT)  Runtime Overhead  PARSEC 3.0 : ~4.9%  Real application: ~12.9% vs CLAP[PLDI13] ~64.3%</p>
    <p>Bug reproduction  reproduces one more bug than CLAP</p>
  </div>
  <div class="page">
    <p>Discussion</p>
    <p>Symbolic execution is slow  Eliminate symbolic execution: use hardware watchpoints to catch values and memory locations</p>
    <p>Constraints for long traces  Use checkpoints and periodic global synchronization</p>
    <p>Non-deterministic program inputs (e.g., syscall results)  Integrate with Mozilla RR [USENIX ATC17]  Key insight: use H3 to handle schedules, and RR to handle inputs</p>
  </div>
  <div class="page">
    <p>Thank you</p>
  </div>
</Presentation>
