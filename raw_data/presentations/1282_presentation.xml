<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Daydream: Accurately Estimating the Efficacy of Optimizations for DNN Training</p>
    <p>Hongyu Zhu1,2, Amar Phanishayee3, Gennady Pekhimenko1,2</p>
  </div>
  <div class="page">
    <p>Executive Summary</p>
    <p>Motivation: Benefits of many DNN optimizations are not easy to exploit because  Efficacy varies for different HW/SW deployments  It is onerous to implement optimizations</p>
    <p>Goal: Need to quickly find the effective optimizations for a given deployment  No need to FULLY implement the optimizations</p>
    <p>Our proposal: a system called Daydream, that can estimate runtime improvement of various DNN optimizations, using dependency graph analysis:  Tracking dependencies at the abstraction of GPU kernels (graph size is large)  Correlating low-level traces with layer organization of DNN models  Ability to model a diverse set of optimizations</p>
    <p>Evaluation: Low estimation error (8% average) on 5 optimizations, 5 DNN models  Accurately estimating distributed training runtime based on single-GPU profile</p>
  </div>
  <div class="page">
    <p>DNN compute requirements are growing exponentially</p>
    <p>Advances in ML Full Stack Research</p>
    <p>https://openai.com/blog/ai-and-compute/ https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259424&amp;tag=1</p>
    <p>Rapid advances in algorithms, systems optimizations &amp; hardware architectures</p>
    <p>Hard for a ML programmer to identify the efficacy of new algorithms, optimizations, and hardware improvements</p>
    <p>in their deployments.</p>
  </div>
  <div class="page">
    <p>What-if Questions</p>
    <p>ML Programmer</p>
    <p>Why is my DNN training workload running slow? What is the bottleneck?</p>
    <p>Will optimization X improve the performance of my model?</p>
    <p>Will upgrading to a faster network (for example, 10Gbps to 40Gbps) improve training throughput?</p>
    <p>How will my workload scale with the number of GPUs?</p>
    <p>What if I get the latest GPU and my compute is 2x faster?</p>
    <p>+</p>
  </div>
  <div class="page">
    <p>Why Dependency Analysis</p>
    <p>Answering what-if questions in non-ML contexts</p>
    <p>Making Sense of Performance in Data Analytics Frameworks (Ousterhout et al., NSDI 15)</p>
    <p>What-If Analysis of Page Load Time in Web Browsers Using Causal Profiling (Pourghassemi et al., SIGMETRICS 19)</p>
    <p>COZ: Finding Code that Counts with Causal Profiling (Curtsinger et al., SOSP 15)</p>
    <p>DNN Computational Graph</p>
    <p>Inception (2014)</p>
    <p>TensorFlows computational graph (2016)LSTM (2014)</p>
    <p>Similarities between the graph structures, unique challenges and opportunities for the ML context</p>
  </div>
  <div class="page">
    <p>Challenges for Dependency Graph Analysis in the ML context</p>
    <p>Challenge #1: Thousands of tasks, and dependency needs to be tracked across CPU threads, GPU streams, and interconnects.</p>
    <p>CPU Thread #1</p>
    <p>CPU Thread #2</p>
    <p>CPU Thread #3</p>
    <p>GPU Stream #1</p>
    <p>GPU Stream #2</p>
    <p>GPU Stream #3</p>
    <p>Communication</p>
    <p>launch cudaMalloc cudaFree</p>
    <p>cudaDeviceSynchronize</p>
    <p>launch launch launch</p>
    <p>cudaMemcpy</p>
    <p>volta_scudnn_128x64_relu_...</p>
    <p>void cudnn::detail::wgrad_alg0_enging&lt;float,</p>
    <p>MemCpy (DtoH)</p>
    <p>nccl::all_reduce(</p>
    <p>MemCpy (DtoH)</p>
    <p>launch</p>
    <p>void cudnn</p>
  </div>
  <div class="page">
    <p>Challenges for Dependency Graph Analysis in the ML context</p>
    <p>Challenge #2: Modeling DNN optimizations requiring correlation between kernel and layer abstractions.</p>
    <p>volta_scudnn_128x128</p>
    <p>CPU Thread</p>
    <p>GPU Stream #1 cudnn::detail::wgrad</p>
    <p>volta_sgemm_..._ZN2at6native18ele kernelPointwise</p>
    <p>What if I improve CONV layers? Which kernels belong to these layers?</p>
    <p>GPU Stream #2</p>
  </div>
  <div class="page">
    <p>Challenges for Dependency Graph Analysis in the ML context</p>
    <p>Challenge #3: Ability to easily model diverse DNN optimizations.</p>
    <p>How to make it easy to model of all potential ?</p>
    <p>Optimizations</p>
  </div>
  <div class="page">
    <p>Daydream Transformation Primitives</p>
    <p>Daydream Profiler</p>
    <p>Daydream Overview</p>
    <p>Kernel-level Traces</p>
    <p>Layer Graph</p>
    <p>Simulation</p>
    <p>Layer L0</p>
    <p>Layer L1</p>
    <p>Layer L2</p>
    <p>Daydreams Dependency Graph</p>
    <p>Post-Optimization Graph</p>
    <p>Input: an DNN training implementation X, an optimization Y</p>
    <p>Output: the estimation of runtime when applying Y to X</p>
    <p>Training Implementation X</p>
    <p>Optimization Y</p>
  </div>
  <div class="page">
    <p>Challenge 1: Tracking Dependencies</p>
    <p>Observation: GPU kernels are highly serialized for most DNN training workloads</p>
    <p>NVProf profile of one ResNet50 iteration NVProf profile of one BERTLARGE iteration</p>
    <p>GPU kernels</p>
    <p>CUDA APIs</p>
  </div>
  <div class="page">
    <p>Daydreams Graph Construction</p>
    <p>(1) Sequential CPU-CPU: two consecutive CPU calls on the same CPU thread</p>
    <p>We identify the six types of dependencies:</p>
    <p>(2) Sequential GPU-GPU: two consecutive GPU kernels on the same stream</p>
    <p>(3) CPU-GPU launching: A CPU call launching a GPU kernel/CUDA memory copies</p>
    <p>Launch K0 cudaMemcpyAsync</p>
    <p>K0 CUDAMemcpy</p>
    <p>CPU Thread</p>
    <p>GPU Stream</p>
    <p>cudaDeviceSynchronize Launch K1</p>
    <p>(4) GPU-CPU sync: A CPU synchronization call waiting for GPU kernel to finish</p>
  </div>
  <div class="page">
    <p>Daydreams Graph Construction (cont.)</p>
    <p>(5) CPU-Communication</p>
    <p>Parameter Server Architecture:</p>
    <p>CONV_BPCollapsed Compute CONV_FF</p>
    <p>Communication</p>
    <p>Server</p>
    <p>Push Pull</p>
    <p>Accumulate_Grad</p>
    <p>MPI-like Architecture:</p>
    <p>FC_BPCollapsed Compute CONV_FF</p>
    <p>Communication AllReduce Grad AllReduce Grad</p>
    <p>CONV_BP FC_FF</p>
    <p>POOL_BP RELU_BP POOL_FF</p>
    <p>(6) CPU-CPU (e.g. thread spawn, join, lock, )</p>
  </div>
  <div class="page">
    <p>Challenge 2: Trace-Layer Correlation</p>
    <p>Optimizations requiring correlation between low-level traces and DNN layers:  E.g., Fusing CONV and RELU layers</p>
    <p>Low-level traces have NO domain knowledge</p>
    <p>Nave approach: adding synchronization</p>
    <p>Launch K0 Launch K1 Launch K2</p>
    <p>K0 K1 K2</p>
    <p>CPU Timeline</p>
    <p>GPU Timeline</p>
    <p>sync</p>
    <p>Get timestamps</p>
  </div>
  <div class="page">
    <p>Daydreams Kernel-Layer Mapping</p>
    <p>Launch K0 Launch K1 Launch K2</p>
    <p>K0 K1 K2</p>
    <p>CPU Timeline</p>
    <p>GPU Timeline</p>
    <p>K0, K1 belong to L0 t0 t1</p>
    <p>Get L0s Timestamps</p>
    <p>Get L0s CPU tasks</p>
    <p>Map K0, K1 to L0 according to dependencies</p>
    <p>Little overhead (only need to instrument frameworks for per-layer timestamps)</p>
    <p>No alternation to the dependency graph (synchronization-free)</p>
  </div>
  <div class="page">
    <p>Challenge 3: Optimization Diversity</p>
    <p>Optimization Goals Strategy Technique Examples</p>
    <p>Improving Hardware Utilization in SingleWorker Environment</p>
    <p>Increasing Mini-batch Size by Reducing Memory Footprints</p>
    <p>vDNN (MICRO16), Gist (ISCA18), Echo (ISCA20)</p>
    <p>Reducing Precision Automatic Mixed Precision (arxiv17)</p>
    <p>Kernel/Layer Fusion FusedAdam, MetaFlow (MLSys19), TASO (SOSP19)</p>
    <p>Improving Kernel Implementation</p>
    <p>Restructuring Batchnorm (MLSys19), TVM (OSDI18), Tensor Comprehensions (arxiv18)</p>
    <p>Lowering Communication Overhead in Distributed Training</p>
    <p>Reducing Communication Workloads</p>
    <p>Deep Gradient Compression (ICLR18), QSGD (NeurIPS17), AdaComm (MLSys19), Parallax (EuroSys19), TernGrad (NeurIPS17)</p>
    <p>Improving Communication Efficiency/Overlap</p>
    <p>Wait-free Backprop (ATC17), P3 (MLSys19), BlueConnect (MLSys19), TicTac (MLSys19), BytePS (SOSP19), Blink (MLSys19)</p>
    <p>We evaluate some optimizations, and show that we can conveniently model others using Daydream</p>
  </div>
  <div class="page">
    <p>Daydreams Transformation Primitives</p>
    <p>(1) Select(expr): return tasks of interests for further process</p>
    <p>Most DNN optimizations can be described as a combination of the following primitives:</p>
    <p>Launch K0 Launch K1</p>
    <p>K0 (POOL) K1 (CONV)</p>
    <p>CPU Timeline</p>
    <p>GPU Timeline</p>
    <p>Launch K2</p>
    <p>K2 (POOL)</p>
    <p>Synchronize Launch K3</p>
    <p>K3 (CONV)</p>
    <p>Select(taskPtr(isOnGPU()))Select(taskPtr(isCONV()))</p>
    <p>(2) Shrinking/Scaling the task duration</p>
    <p>Shrink CONV layers by 2x</p>
    <p>K1 (CONV) K3 (CONV)</p>
    <p>Launch K0 Launch K1</p>
    <p>K0 (POOL)</p>
    <p>CPU Timeline</p>
    <p>GPU Timeline</p>
    <p>Launch K2</p>
    <p>K2 (POOL)</p>
    <p>sync Launch K3</p>
  </div>
  <div class="page">
    <p>Daydreams Transformation Primitives (cont.)</p>
    <p>CPU Thread insert</p>
    <p>remove</p>
    <p>CPU Thread</p>
    <p>GPU Stream</p>
    <p>insert</p>
    <p>remove</p>
    <p>(3) Insert(s, task, t): Insert a task between s and t</p>
    <p>(4) Remove(task): Remove a task from the graph</p>
  </div>
  <div class="page">
    <p>Daydreams Transformation Primitives (cont.)</p>
    <p>Compute L2_BP L1_BP</p>
    <p>Communication</p>
    <p>L0_BP</p>
    <p>Grad_L2 Grad_L1</p>
    <p>L0_FF</p>
    <p>Grad_L0</p>
    <p>L1_FF L2_FF</p>
    <p>Compute L2_BP L1_BP</p>
    <p>Communication</p>
    <p>L0_BP</p>
    <p>Grad_L2 Grad_L1</p>
    <p>L0_FF</p>
    <p>Grad_L0</p>
    <p>L1_FF L2_FF</p>
    <p>Reschedule Grad_L1 and Grad_L0</p>
    <p>(5) Schedule(Q: a queue of tasks that are ready to execute): --&gt; task Decide which task to execute when multiple tasks are ready</p>
  </div>
  <div class="page">
    <p>Example  Automatic Mixed Precision</p>
    <p>Using Daydream to estimate the efficacy of AMP (Micikevicius et al., arxiv 2017)</p>
    <p>def estimate_AMP(cupti_file, timestamps_file):</p>
    <p>graph = Graph(cupti_file)</p>
    <p>graph.mapping(timestamps_file)</p>
    <p>GPUNodes = [node for node in graph.nodes() if node.kind == KERNEL]</p>
    <p>for node in GPUNodes:</p>
    <p>if wgrad in node.name or sgemm in node.name:</p>
    <p>node.dur /= 3</p>
    <p>else:</p>
    <p>node.dur /= 2</p>
    <p>return graph.simulate()</p>
    <p>Low-level traces Per-layer timestamps</p>
    <p>Constructing kernel-level dependency graph Map low-level traces to DNN layers using per-layer timestamps</p>
    <p>Select all GPU tasks from the graph</p>
    <p>If we expect this task to use TensorCore</p>
    <p>Otherwise, use half-precision cores</p>
    <p>Simulate the timeline, return the elapsed execution time</p>
  </div>
  <div class="page">
    <p>Methodology</p>
    <p>Application Model Dataset</p>
    <p>Image Classification VGG-19 Imagenet</p>
    <p>DenseNet-121</p>
    <p>ResNet-50</p>
    <p>Machine Translation GNMT (Seq2Seq) WMT</p>
    <p>Language Modeling BERT SQuAD</p>
    <p>Woakloads: Setup:</p>
    <p>v1.0 v1.1 v1.0</p>
    <p>v2.4.2v7.4.2v10.0</p>
    <p>RTX 2080 Ti Quadro P4000</p>
    <p>Optimizations:</p>
    <p>Improving hardware utilization: Automatic Mixed Precision (AMP), FusedAdam, Reconstructing Batchnorm</p>
    <p>Distributed training: Data-parallel distributed training, Priority-based parameter propagation (P3)</p>
  </div>
  <div class="page">
    <p>Methodology (cont.)</p>
    <p>Given a and a , we evaluate:</p>
    <p>Baseline:</p>
    <p>Ground Truth: +</p>
    <p>Prediction:</p>
  </div>
  <div class="page">
    <p>Runtime Estimation Accuracy</p>
    <p>BERT_Base BERT_Large Seq2Seq ResNet-50 BERT_Base BERT_Large Seq2Seq DenseNet</p>
    <p>AMP FusedAdam RB</p>
    <p>It e</p>
    <p>ra ti</p>
    <p>o n</p>
    <p>T im</p>
    <p>e (</p>
    <p>m s)</p>
    <p>Baseline Ground Truth Prediction</p>
    <p>Estimating Automatic Mixed Precision (AMP), FusedAdam, and Restructuring Batchnorm (RB)</p>
    <p>Daydream achieves 8% estimation error on average (15% maximum)</p>
  </div>
  <div class="page">
    <p>Estimating Distributed Training</p>
    <p>Estimating data-parallel distributed training of BERTLARGE</p>
    <p>P re</p>
    <p>d ic</p>
    <p>ti o</p>
    <p>n E</p>
    <p>rr o</p>
    <p>r</p>
    <p>It e</p>
    <p>ra ti</p>
    <p>o n</p>
    <p>T im</p>
    <p>e (</p>
    <p>m s)</p>
    <p>System Configuration (# of machines x # of GPUs per machine, bandwidth)</p>
    <p>Ground Truth Prediction Error</p>
    <p>Daydream can accurately estimate the distributed performance for various system configurations</p>
  </div>
  <div class="page">
    <p>Estimating Distributed Training</p>
    <p>P re</p>
    <p>d ic</p>
    <p>ti o</p>
    <p>n E</p>
    <p>rr o</p>
    <p>r</p>
    <p>It e</p>
    <p>ra ti</p>
    <p>o n</p>
    <p>T im</p>
    <p>e (</p>
    <p>m s)</p>
    <p>System Configuration (# of machines x # of GPUs per machine, bandwidth)</p>
    <p>Ground Truth Prediction Error</p>
    <p>P re</p>
    <p>d ic</p>
    <p>ti o</p>
    <p>n E</p>
    <p>rr o</p>
    <p>r</p>
    <p>It e</p>
    <p>ra ti</p>
    <p>o n</p>
    <p>T im</p>
    <p>e (</p>
    <p>m s)</p>
    <p>System Configuration (# of machines x # of GPUs per machine, bandwidth)</p>
    <p>Ground Truth Prediction Error</p>
    <p>P re</p>
    <p>d ic</p>
    <p>ti o</p>
    <p>n E</p>
    <p>rr o</p>
    <p>r</p>
    <p>It e</p>
    <p>ra ti</p>
    <p>o n</p>
    <p>T im</p>
    <p>e (</p>
    <p>m s)</p>
    <p>System Configuration (# of machines x # of GPUs per machine, bandwidth)</p>
    <p>Ground Truth Prediction Error</p>
    <p>P re</p>
    <p>d ic</p>
    <p>ti o</p>
    <p>n E</p>
    <p>rr o</p>
    <p>r</p>
    <p>It e</p>
    <p>ra ti</p>
    <p>o n</p>
    <p>T im</p>
    <p>e (</p>
    <p>m s)</p>
    <p>System Configuration (# of machines x # of GPUs per machine, bandwidth)</p>
    <p>Ground Truth Prediction Error</p>
    <p>ResNet-50 GNMT</p>
    <p>BERTBASE BERTLARGE</p>
    <p>Daydream can accurately estimate the distributed performance for a variety of DNN models</p>
  </div>
  <div class="page">
    <p>Estimating Efficacy of P3</p>
    <p>Prediction accuracy for Priority-Based Parameter Propagation (P3)</p>
    <p>Runtime Prediction for ResNet-50 Runtime Prediction for VGG-19</p>
    <p>Using Daydream, we can successfully estimate whether P3 would provide significant or subtle improvement</p>
    <p>It e</p>
    <p>ra ti</p>
    <p>o n</p>
    <p>T im</p>
    <p>e (</p>
    <p>m s)</p>
    <p>Network Bandwidth (Gbps)</p>
    <p>Baseline</p>
    <p>Ground Truth</p>
    <p>Prediction</p>
    <p>It e</p>
    <p>ra ti</p>
    <p>o n</p>
    <p>T im</p>
    <p>e (</p>
    <p>m s)</p>
    <p>Network Bandwidth (Gbps)</p>
    <p>Baseline</p>
    <p>Ground Truth</p>
    <p>Prediction</p>
    <p>(we use 4 machines and 1 P400 GPU on each machine)</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Benefits of DNN optimizations are not easy to exploit:  Efficacy various across different hw/sw deployments  Often onerous to implement and debug</p>
    <p>Basic Idea: Dependency graph analysis</p>
    <p>Our Solution: The Daydream system allowing users to quickly estimate the performance of various DNN optimizations:</p>
    <p>Tracking dependencies at the kernel-level granularity  Sync-free trace-to-layer mapping  Simple graph transformation primitives</p>
    <p>Key Results: Estimation error of 8% on average (15% maximum) Modeling a wide range of optimizations (only 20 lines of code each)</p>
  </div>
  <div class="page">
    <p>Daydream: Accurately Estimating the Efficacy of Optimizations for DNN Training</p>
    <p>Hongyu Zhu1,2, Amar Phanishayee3, Gennady Pekhimenko1,2</p>
    <p>Thank you!</p>
    <p>serailhydra@cs.toronto.edu</p>
  </div>
</Presentation>
