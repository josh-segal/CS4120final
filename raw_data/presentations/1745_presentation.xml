<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>2009 VMware Inc. All rights reserved</p>
    <p>Ajay Gulati, VMware, Inc.</p>
    <p>Chethan Kumar, VMware, Inc.</p>
    <p>Irfan Ahmad, VMware, Inc.</p>
    <p>Karan Kumar, CMU</p>
    <p>BASIL: Automated IO Load Balancing across Storage Devices</p>
    <p>USENIX FAST  February 25, 2010</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Problem Description &amp; Motivation</p>
    <p>BASIL  Modeling &amp; Load Balancing</p>
    <p>Experimental Framework &amp; Results</p>
    <p>Conclusions &amp; Future Work</p>
  </div>
  <div class="page">
    <p>Datacenter AutomationState of the Art</p>
    <p>ESX Hosts</p>
    <p>Automated Load Balancing of</p>
    <p>CPU and Memory resources</p>
    <p>across a cluster of servers</p>
    <p>using live migration.</p>
    <p>e.g., VMware DRS (Distributed</p>
    <p>Resource Scheduler)</p>
  </div>
  <div class="page">
    <p>The ProblemStorage Management Not Automated</p>
    <p>ESX Hosts Storage Devices</p>
    <p>IT Admin</p>
  </div>
  <div class="page">
    <p>The ProblemStorage Management Not Automated</p>
    <p>ESX Hosts Storage Devices</p>
    <p>IT Admin</p>
  </div>
  <div class="page">
    <p>The ProblemStorage Management Not Automated</p>
    <p>ESX Hosts Storage Devices</p>
    <p>IT Admin</p>
  </div>
  <div class="page">
    <p>The ProblemStorage Management Not Automated</p>
    <p>ESX Hosts Storage Devices</p>
    <p>IT Admin Storage vMotion</p>
  </div>
  <div class="page">
    <p>The ProblemStorage Management Not Automated</p>
    <p>ESX Hosts Storage Devices</p>
    <p>IT Admin</p>
    <p>Management Nightmares</p>
    <p>IO load balancing?</p>
    <p>Virtual disk placement?</p>
  </div>
  <div class="page">
    <p>IOPS Latency (in ms)</p>
    <p>IOPS Latency (in ms)</p>
    <p>(in ms)</p>
    <p>% Change</p>
    <p>Example Scenario</p>
    <p>Final ConfigurationInitial Configuration</p>
    <p>LUN 3LUN 1 LUN 2LUN 3LUN 1 LUN 2</p>
  </div>
  <div class="page">
    <p>Shoulders of Giants</p>
    <p>Much characterization &amp; modeling work precedes us</p>
    <p>Workload Characterization Kavalanekar et al: IISWC 08 Gulati et al: VPACT 09</p>
    <p>Minerva, Hippodrome, Table-based Alvarez et al: ACM Trans. On Computing 01 Anderson et al: FAST 02</p>
    <p>Analytical device models Uysal et al: MASCOTS 01 Shriver et al: SIGMETRICS 98 Merchant et al: IEEE Trans. Computing 96 Ruemmler &amp; Wilkes: IEEE Computer 94</p>
    <p>Relative fitness modeling</p>
    <p>Mesnier et al: SIGMETRICS 07</p>
    <p>CART models Wang et al: MASCOTS 04</p>
    <p>Novel features</p>
    <p>Latency as primary</p>
    <p>metric</p>
    <p>Online and lightweight</p>
    <p>Different goal</p>
    <p>compared to existing</p>
    <p>literature</p>
  </div>
  <div class="page">
    <p>Latency as Main MetricWhy?</p>
    <p>L a te</p>
    <p>n c y</p>
    <p>Load</p>
    <p>L2</p>
    <p>T h</p>
    <p>ro u</p>
    <p>g h</p>
    <p>p u</p>
    <p>t</p>
    <p>Load</p>
    <p>T2</p>
    <p>L a te</p>
    <p>n c y</p>
    <p>L1</p>
    <p>T h</p>
    <p>ro u</p>
    <p>g h</p>
    <p>p u</p>
    <p>t T1</p>
    <p>L1 L2</p>
    <p>T2 T1</p>
    <p>LUN 1 LUN 2</p>
    <p>Load</p>
    <p>Load</p>
    <p>VMs load is What if a</p>
    <p>VMs load is moved.</p>
    <p>LUN 1  2</p>
    <p>Average Latency is lower.</p>
    <p>Overall throughput is similar or higher.</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Problem Description &amp; Motivation</p>
    <p>BASIL  Modeling &amp; Load Balancing</p>
    <p>Experimental Framework &amp; Results</p>
    <p>Conclusions &amp; Future Work</p>
  </div>
  <div class="page">
    <p>BASIL Sketch</p>
    <p>Online modeling</p>
    <p>Workload : capture dynamic behavior</p>
    <p>Device : capture device performance</p>
    <p>Load balancing based on</p>
    <p>Workload and device models</p>
    <p>Assign workloads to device in proportion to their metrics</p>
  </div>
  <div class="page">
    <p>Workload Modeling</p>
  </div>
  <div class="page">
    <p>I/O Workload Modeling</p>
    <p>Percentiles Data collected per-virtual disk</p>
    <p>Methodology</p>
    <p>Analyze impact of each parameter on latency</p>
    <p>Outstanding IOs</p>
    <p>IO Size</p>
    <p>Read/Write Ratio</p>
    <p>Randomness</p>
  </div>
  <div class="page">
    <p>I/O Workload Modeling</p>
    <p>Percentiles Data collected per-virtual disk</p>
    <p>IO Size</p>
    <p>Read/Write Ratio</p>
    <p>Randomness</p>
    <p>Latency varies linearly with #Outstanding IOs</p>
  </div>
  <div class="page">
    <p>I/O Workload Modeling</p>
    <p>Percentiles Data collected per-virtual disk</p>
    <p>Outstanding IOs</p>
    <p>Read/Write Ratio</p>
    <p>Randomness</p>
    <p>Latency varies linearly with IO Size</p>
    <p>(in KB)</p>
  </div>
  <div class="page">
    <p>I/O Workload Modeling</p>
    <p>Percentiles Data collected per-virtual disk</p>
    <p>Outstanding IOs</p>
    <p>IO Size</p>
    <p>Randomness</p>
    <p>Latency varies linearly with %Reads</p>
  </div>
  <div class="page">
    <p>I/O Workload Modeling</p>
    <p>Percentiles Data collected per-virtual disk</p>
    <p>Outstanding IOs</p>
    <p>IO Size</p>
    <p>Read/Write Ratio</p>
    <p>Latency varies linearly or Remains flat with %Randomness</p>
    <p>Anomalous behavior</p>
    <p>for extreme cases</p>
  </div>
  <div class="page">
    <p>I/O Workload Modeling</p>
    <p>Percentiles Data collected per-virtual disk</p>
    <p>Workload Model denoted as W</p>
    <p>K values fit from empirical data</p>
    <p>Outstanding IOs</p>
    <p>IO Size</p>
    <p>Read/Write Ratio</p>
    <p>Randomness</p>
    <p>)K 00(Random%/1)K (Read%/100)K (IOsize)K (OIOW 4321 ++++=</p>
    <p>K1 = 1.3</p>
    <p>K2 = 51</p>
    <p>K3 = 0.4</p>
    <p>K4 = 0.6</p>
    <p>OIO is the main contributor for most cases</p>
    <p>IO Size impacts only when change is large</p>
    <p>Read% and Random% have less impact, except extreme scenarios</p>
  </div>
  <div class="page">
    <p>Device Modeling</p>
  </div>
  <div class="page">
    <p>Device Modeling</p>
    <p>Device performance can vary widely</p>
    <p>Different number of disks: 4 vs.16 disk LUN</p>
    <p>Different disk types: FC vs. SATA</p>
    <p>RAID type</p>
    <p>% Disk occupancy</p>
    <p>BUT, device characteristics are hidden from hosts</p>
    <p>SATA 20 disks</p>
    <p>FC</p>
  </div>
  <div class="page">
    <p>Device Modeling</p>
    <p>Device Performance estimation</p>
    <p>&lt;OIO, Latency&gt; pairs collected using a reference workload</p>
    <p>Linear fit approximation of the pairs</p>
    <p>Slope indicates relative performance of the device</p>
  </div>
  <div class="page">
    <p>Device Modeling</p>
    <p>Device Performance estimation</p>
    <p>&lt;OIO, Latency&gt; pairs collected using a reference workload</p>
    <p>Linear fit approximation of the pairs</p>
    <p>Slope indicates relative performance of the device</p>
    <p>Slope = 0.50</p>
    <p>Slope = 0.12</p>
    <p>Slope = 0.24</p>
    <p>Slope = 0.16</p>
  </div>
  <div class="page">
    <p>Device Modeling</p>
    <p>Device Performance estimation</p>
    <p>&lt;OIO, Latency&gt; pairs collected using a reference workload</p>
    <p>Linear fit approximation of the pairs</p>
    <p>Slope indicates relative performance of the device</p>
  </div>
  <div class="page">
    <p>Online Device ModelingIssues</p>
    <p>Generally expect positive slope values</p>
    <p>We observe negative slope values in some cases</p>
    <p>Large write IO bursts in real applications going to cache</p>
    <p>IO size variation for different Outstanding IOs</p>
    <p>Large sequential bursts Write Bursts</p>
    <p>during high</p>
    <p>Outstanding IOs</p>
    <p>More Writes</p>
  </div>
  <div class="page">
    <p>Online Device ModelingSolution</p>
    <p>Filter out data from collected samples</p>
    <p>Writes: &lt;Read OIOs, Read latency &gt; pairs</p>
    <p>Large IOs: filter out if IO size &gt; 32 KB</p>
    <p>Sequential IOs: filter out if sequentiality &gt; 90 % Considering only</p>
    <p>Read IOs</p>
  </div>
  <div class="page">
    <p>Slopes are indicative of relative performance</p>
    <p>4 vs. 8 disks, other factors are constant</p>
    <p>FC better than SATA, other factors kept constant</p>
    <p>Incorporates cache effects</p>
    <p>Lower slope for arrays with smaller cache</p>
    <p>Online modeling</p>
    <p>Online modeling is highly useful in practice</p>
    <p>Filtering of online input needed to handle extreme workloads</p>
    <p>Key Takeaways</p>
    <p>Slope = 0.50</p>
    <p>Slope = 0.12</p>
    <p>Slope = 0.24</p>
    <p>Slope = 0.16</p>
  </div>
  <div class="page">
    <p>Load Balancing</p>
  </div>
  <div class="page">
    <p>Load Balancing</p>
    <p>Recall Workload metric: Wi</p>
    <p>Recall Device metric: Pj</p>
    <p>1 / slope of linear fit between &lt;Read OIO, Read latency&gt;</p>
    <p>Define Normalized Load on a device: NL</p>
    <p>Load balancing</p>
    <p>Assign workloads to devices in proportion to their performance</p>
    <p>Heuristic: Equalize NL across data stores</p>
    <p>Initial placement of virtual disks</p>
    <p>Pick device with minimum NL</p>
    <p>)K 00(Random%/1)K (Read%/100)K (IOsize)K (OIO W 4321i ++++=</p>
    <p>jP</p>
    <p>j device aon Wmetric Workload i =NL</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Problem Description &amp; Motivation</p>
    <p>BASIL  Modeling &amp; Load Balancing</p>
    <p>Experimental Framework &amp; Results</p>
    <p>Conclusions &amp; Future Work</p>
  </div>
  <div class="page">
    <p>Experimental Setup</p>
    <p>2 hosts running VMware ESX 4.0 hypervisor</p>
    <p>8 to 13 virtual machines (VMs)  mix of Windows, Linux OSes</p>
    <p>6 Data stores</p>
    <p>Devices (LUNs) spread across EMC CLARiiON &amp; NetApp FAS-3140</p>
    <p>Workloads</p>
    <p>Real Apps: Swingbench (DBMS: Oracle), DVD Store (DBMS: SQL)</p>
    <p>Filebench: varmail, OLTP, webserver</p>
    <p>Iometer configurations: OLTP, Workstation, Exchange Server, Web Server</p>
    <p>http://blogs.msdn.com/tvoellm/archive/2009/05/07/useful-io-profiles-for-simulatingvarious-workloads.aspx</p>
  </div>
  <div class="page">
    <p>The ProblemStorage Management Not Automated</p>
    <p>ESX Hosts Storage Devices</p>
    <p>Stats collection</p>
    <p>Online Device and Workload</p>
    <p>Model</p>
    <p>Load Balancer</p>
    <p>Recommendations</p>
    <p>Migrations</p>
  </div>
  <div class="page">
    <p>The ProblemStorage Management Not Automated</p>
    <p>ESX Hosts Storage Devices</p>
    <p>Stats collection</p>
    <p>Online Device and Workload</p>
    <p>Model</p>
    <p>Load Balancer</p>
    <p>Recommendations</p>
    <p>Migrations</p>
  </div>
  <div class="page">
    <p>The ProblemStorage Management Not Automated</p>
    <p>ESX Hosts Storage Devices</p>
    <p>Stats collection</p>
    <p>Online Device and Workload</p>
    <p>Model</p>
    <p>Load Balancer</p>
    <p>Recommendations</p>
    <p>Migrations</p>
  </div>
  <div class="page">
    <p>The ProblemStorage Management Not Automated</p>
    <p>ESX Hosts Storage Devices</p>
    <p>Stats collection</p>
    <p>Online Device and Workload</p>
    <p>Model</p>
    <p>Load Balancer</p>
    <p>Recommendations</p>
    <p>Migrations</p>
  </div>
  <div class="page">
    <p>The ProblemStorage Management Not Automated</p>
    <p>ESX Hosts Storage Devices</p>
    <p>Stats collection</p>
    <p>Online Device and Workload</p>
    <p>Model</p>
    <p>Load Balancer</p>
    <p>Recommendations</p>
    <p>Migrations</p>
  </div>
  <div class="page">
    <p>Device #disks Array RAID P= 1/slope</p>
    <p>Three devices for micro-benchmark experiments</p>
    <p>Three devices for real-workload experiments</p>
    <p>Device #disks Array RAID P= 1/slope</p>
    <p>EMC 6 FC EMC Clariion RAID-5 1.10</p>
    <p>NetApp-SP 6 FC NetApp FAS 3140</p>
    <p>RAID-5 0.83</p>
    <p>Netapp-DP 7 SATA NetApp FAS 3140</p>
    <p>RAID-6 0.48</p>
    <p>P: higher is better</p>
    <p>Device Models</p>
  </div>
  <div class="page">
    <p>IOPS Latency (in ms)</p>
    <p>IOPS Latency (in ms)</p>
    <p>(in ms)</p>
    <p>% Change</p>
    <p>Load Balancing</p>
    <p>Final ConfigurationInitial Configuration</p>
  </div>
  <div class="page">
    <p>Summary: 500 Runs</p>
    <p>Random placement vs. BASIL (80th percentile values)</p>
    <p>25% improvement in IOPS</p>
    <p>33% decrease in overall latency (computed using IOPS as weights)</p>
  </div>
  <div class="page">
    <p>Summary: 100 Initial Placements</p>
    <p>Random initial placement vs. BASIL (50th percentile values)</p>
    <p>53% improvement in IOPS</p>
    <p>45% decrease in overall latency (computed using IOPS as weights)</p>
  </div>
  <div class="page">
    <p>Space balanced</p>
    <p>BASIL Expert 1 Expert 2</p>
    <p>EMC</p>
    <p>Netapp-SP</p>
    <p>Netapp-DP</p>
    <p>Aggregate</p>
    <p>L a</p>
    <p>te n</p>
    <p>c y (</p>
    <p>m s )</p>
    <p>Space balanced</p>
    <p>BASIL Expert 1 Expert 2</p>
    <p>Netapp-DP</p>
    <p>Netapp-SP</p>
    <p>EMC</p>
    <p>IO P</p>
    <p>S</p>
    <p>BASIL provides lowest average latency and similar throughput</p>
    <p>Summary: Enterprise Workloads</p>
    <p>Human Experts vs. BASIL</p>
    <p>13 VMs: 3 DVDstore, 2 Swingbench, 4 mail servers, 2 oltp, 2 webservers</p>
    <p>2 ESX hosts, 3 storage devices</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Problem Description &amp; Motivation</p>
    <p>BASIL  Modeling &amp; Load Balancing</p>
    <p>Experimental Framework &amp; Results</p>
    <p>Conclusions &amp; Future Work</p>
  </div>
  <div class="page">
    <p>Conclusions and Future Work</p>
    <p>BASIL provides</p>
    <p>Practical online workload and device models</p>
    <p>Efficient initial placement</p>
    <p>Load balancing results in higher utilization, lower overall latency</p>
    <p>Future Work</p>
    <p>Ki values: static vs. dynamic</p>
    <p>Try out alternate workload models</p>
    <p>Separate device modeling for reads &amp; writes</p>
    <p>Detailed cost-benefit metric for storage vmotions</p>
  </div>
</Presentation>
