<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Jinho Hwang (IBM Research) Wei Zhang, Timothy Wood, H. Howie Huang (George Washington Univ.) K.K. Ramakrishnan (Rutgers University)</p>
  </div>
  <div class="page">
    <p>Two orders of magnitude more reads than writes  Solution: Deploy memcached hosts to handle the read</p>
    <p>capacity</p>
    <p>Background: Memory Caching</p>
    <p>Web Server</p>
    <p>DB Memcache</p>
    <p>DB DB</p>
  </div>
  <div class="page">
    <p>Databases are hard to scale Memcached is easy o Facebook has 10,000+ memcached servers</p>
    <p>Partition data and divide key space among all nodes</p>
    <p>o Simple data model. Stupid nodes.</p>
    <p>Web application must track where each object is stored o Or use a proxy (load-balancer) like moxi</p>
    <p>Memcached at Scale</p>
    <p>Clients Web Servers</p>
    <p>LB</p>
    <p>DB Memcached nodes</p>
  </div>
  <div class="page">
    <p>Random placement  Skewed popularity distributions</p>
    <p>Scales easily, but loads are imbalanced</p>
    <p>Load on Wikipedias memcached servers</p>
  </div>
  <div class="page">
    <p>Cache clusters are typically provisioned to support peak load, in terms of request processing capabilities and cache storage size o This worst-case provisioning can be very expensive o This does not take advantage of dynamic resource</p>
    <p>allocation and VM provisioning capabilities  There can be great diversity in both the workloads and</p>
    <p>types of nodes o This makes cluster management difficult</p>
    <p>Solution: large-scale self-managing caches</p>
    <p>Motivation</p>
  </div>
  <div class="page">
    <p>A high speed memcached load balancer o can forward millions of requests per second</p>
    <p>A hot spot detection algorithm o uses stream data mining techniques to efficiently determine</p>
    <p>the hottest keys  A two-level key mapping system</p>
    <p>o combines consistent hashing with a lookup table to flexibly control the placement and replication level of hot keys</p>
    <p>An automated server management system o determines the number of (types of) servers in the caching</p>
    <p>cluster</p>
    <p>Contributions</p>
  </div>
  <div class="page">
    <p>Background and Motivation</p>
    <p>Workload &amp; Server Heterogeneity</p>
    <p>Memcached Load Balancer Design</p>
    <p>Hotspot Detection Algorithm</p>
    <p>Conclusions</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Varied key popularity depending on applications  Read/write rates, churn rates, costs for cache misses,</p>
    <p>quality-of-service demands</p>
    <p>Workload Heterogeneity</p>
    <p>H as</p>
    <p>h S</p>
    <p>pa ce</p>
    <p>( 0</p>
    <p>Time (5 hours)</p>
    <p>Unpopular region (65%)</p>
    <p>Popular region (35%)</p>
    <p>Based on Wikipedia 2008 database dump and access trace</p>
  </div>
  <div class="page">
    <p>Traditionally, many applications share memcached servers</p>
    <p>Memcached Cluster Grouping</p>
    <p>Memcached Servers</p>
    <p>Web Server</p>
    <p>Application Server</p>
    <p>Media Server</p>
    <p>Streaming</p>
    <p>DB Query</p>
    <p>Static File</p>
    <p>Memcached Cluster</p>
    <p>Applications</p>
    <p>Today, to handle different applications, memcacheds are clustered manually</p>
    <p>Need smarter way to manage cache clusters</p>
  </div>
  <div class="page">
    <p>Software and hardware can be diverse  Different memory cache softwares out there  Many researches prototyped memcached on different HW</p>
    <p>architectures o GP-GPU [Hetherington:ISPASS12] o RDMA (remote direct memory access) [Stuedi:ATC12] o FPGA [Maysam:Computer_Architecture_Letter13] o Intel DPDK [Lim:NSDI14]</p>
    <p>Server Heterogeneity</p>
    <p>Dynamically adapt to workload heterogeneity and server heterogeneity</p>
  </div>
  <div class="page">
    <p>Background and Motivation</p>
    <p>Workload &amp; Server Heterogeneity</p>
    <p>Memcached Load Balancer Design</p>
    <p>Hotspot Detection Algorithm</p>
    <p>Conclusions</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Cache clustering system considers heterogeneous workloads and servers o Identifies server capabilities to adjust key space o Finds hot items based on the item frequency to handle them</p>
    <p>differently  Dynamically increase/decrease the number of</p>
    <p>memcached servers  Uses two-level key mapping system</p>
    <p>o Consistent hashing: applies to warm/cold items (LRU) o Forward table: applies to hot items</p>
    <p>Self-Managing Cache Clustering System</p>
  </div>
  <div class="page">
    <p>Use UDP protocol to redirect the packets directly from memcached servers to clients (lower load in load-balancer)</p>
    <p>Hot Spot Detector runs a streaming algorithm to find hot items  Server Manager manages the memcached servers  Key Replicator manages the key replication  Key Director manages forwarding table and consistent hashing ring</p>
    <p>Automated Load-Balancer Architecture</p>
    <p>Automated Load Balancer</p>
    <p>Key Director</p>
    <p>Consistent Hashing</p>
    <p>Ring</p>
    <p>Fwd Table k1 S1, S14</p>
    <p>k2 S3, S6</p>
    <p>k3 S2,S8,S9</p>
    <p>Hot Spot Detector</p>
    <p>Server Manager</p>
    <p>Key Replicator</p>
    <p>Heterogeneous Cache Servers</p>
    <p>Clients</p>
    <p>S1 S1</p>
  </div>
  <div class="page">
    <p>Background and Motivation</p>
    <p>Workload &amp; Server Heterogeneity</p>
    <p>Memcached Load Balancer Design</p>
    <p>Hotspot Detection Algorithm</p>
    <p>Conclusions</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Lossy counting algorithm is a one-pass deterministic streaming algorithm with user defined parameters o Support threshold s</p>
    <p>Given the stream length N, return at least sN o Error rate  ( &lt;&lt; s) o No item with true frequency &lt; (s - )N is returned</p>
    <p>(no false negative) o Memory size is not monotonically increasing</p>
    <p>Lossy Counting based Hot Spot Detection</p>
    <p>Counting Data &lt;key, val&gt;</p>
    <p>Parameters: , s</p>
    <p>Frequency Estimate Tracking</p>
    <p>N sN</p>
  </div>
  <div class="page">
    <p>Estimated frequency (i.e., request rate) seen by the top keys</p>
    <p>The goal is two-fold o Find hot items o Find groups of items that can balance the loads across</p>
    <p>servers</p>
    <p>Find Hot Items and Groups of Hot Items</p>
    <p>Fr eq</p>
    <p>ue nc</p>
    <p>y (x</p>
    <p>)</p>
    <p>Item Number</p>
  </div>
  <div class="page">
    <p>Given the number of servers, and found hot spot groups, the load-balancer decides to increase/decrease the number of keys</p>
    <p>In a scheduling window, we adjust the support parameter s to adjust the number of hot items</p>
    <p>Adaptively Sizing Number of Hot Items</p>
    <p>N um</p>
    <p>be r o</p>
    <p>f H ot</p>
    <p>It em</p>
    <p>s</p>
    <p>Stream Length N (x1000)</p>
    <p>Target Level</p>
    <p>Autonomic Lossy Counting Generic Lossy Counting</p>
  </div>
  <div class="page">
    <p>Summary o Self-managing cache clustering system</p>
    <p>Workload and server heterogeneity o Adaptive hot item groups</p>
    <p>Number of keys and groups based on servers o High speed load-balancer (~10 million requests per sec /</p>
    <p>single core) Leverage high-performing NICs and processors</p>
    <p>Ongoing work o Optimize the number of servers and replicas of hot items</p>
    <p>(cloud environment)</p>
    <p>Conclusion</p>
  </div>
</Presentation>
