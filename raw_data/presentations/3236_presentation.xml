<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Avoiding Communication in Sparse Matrix Computations</p>
    <p>Marghoob Mohiyuddin Mark Hoemmen James Demmel Katherine Yelick</p>
    <p>marghoob@eecs.berkeley.edu</p>
    <p>Department of Electrical Engineering and Computer Science</p>
    <p>University of California at Berkeley</p>
    <p>IEEE International Parallel and Distributed Processing Symposium, 2008</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 1/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Outline</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 2/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Motivation Problem Statement</p>
    <p>Communication is Costly, Computation is Cheap</p>
    <p>Gap between computational capability and communication cost increasing exponentially:</p>
    <p>Floating-point time  1/network BW  network latency Floating-point time  1/memory BW  memory latency</p>
    <p>Applications need to be designed with this gap in mind Communication hiding not enough (speedup  2x)</p>
    <p>Latency can be dealt with by overlap, but limited by the amount of computation</p>
    <p>Communication avoiding:</p>
    <p>Trade o communication with computation. Arbitrary speedups possible</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 3/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Motivation Problem Statement</p>
    <p>The Akx Kernel</p>
    <p>Given nn sparse matrix A, vector x, integer k &gt; 0, Compute the k vectors Ax,A2x, . . . ,Akx eciently.</p>
    <p>Parallel and sequential algorithms.</p>
    <p>Arises in Krylov Subspace Methods.</p>
    <p>Need to look at the linear subspace spanned by [x,Ax,A2x, . . . ,Akx].</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 4/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Setup</p>
    <p>Matrix A and vector x divided in to p row blocks.</p>
    <p>Parallel machine:</p>
    <p>Each proc. operates on a separate block. Interproc. communication for remote dependencies.</p>
    <p>Sequential machine:</p>
    <p>Each block stored contiguously in slow memory. Algorithm operates on a block-by-block basis.</p>
    <p>Output vectors computed on a per block basis.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 5/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Nave Algorithm: 9-pt Operator for 3 Iterations</p>
    <p>Matrix A denes the nearest neighbor connections</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 6/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Nave Algorithm: 9-pt Operator for 3 iterations</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 7/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Nave Algorithm: 9-pt Operator for 3 iterations</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 7/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Nave Algorithm: 9-pt Operator for 3 iterations</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 7/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Nave Algorithm: 9-pt Operator for 3 iterations</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 7/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Nave Algorithm: 9-pt Operator for 3 iterations</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 7/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Nave Algorithm: 9-pt Operator for 3 iterations</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 7/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Nave Algorithm: 9-pt Operator for 3 iterations</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 7/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Nave Algorithm: 9-pt Operator for 3 iterations</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 7/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Nave Algorithm: 9-pt Operator for 3 iterations</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 7/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Nave Algorithm: 9-pt Operator for 3 iterations</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 7/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Nave Algorithm: 9-pt Operator for 3 iterations</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 7/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Nave Algorithm: 9-pt Operator for 3 iterations</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 7/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Nave Algorithm: 9-pt Operator for 3 iterations</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 7/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Nave Algorithm: 9-pt Operator for 3 iterations</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 7/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Nave Algorithm: 9-pt Operator for 3 iterations</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 7/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Nave Algorithm: 9-pt Operator for 3 iterations</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 7/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Nave Algorithm</p>
    <p>For i = 1, . . . ,k, Compute Ai x using the product of A and Ai1x</p>
    <p>Fetch required entries of Ai1x from other procs/blocks.</p>
    <p>O(k) messages between any two procs/blocks.</p>
    <p>Latency cost is k times the minimum, namely O(1). Objective: O(1) messages between any 2 blocks/procs.</p>
    <p>Sequential machine: A and x read k times from slow to fast memory.</p>
    <p>Bandwidth cost is k times the minimum. Objective: Read A and x at most once.</p>
    <p>Minimum number of oating-point operations performed.</p>
    <p>Objective: Minimize number of extra ops.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 8/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving Nave Algorithm: 9-point operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 9/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving Nave Algorithm: 9-point operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 9/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving Nave Algorithm: 9-point operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 9/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving Nave Algorithm: 9-point operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 9/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving Nave Algorithm: 9-point operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 9/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving Nave Algorithm: 9-point operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 9/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving Nave Algorithm: 9-point operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 9/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving Nave Algorithm: 9-point operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 9/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving Nave Algorithm: 9-point operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 9/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving Nave Algorithm: 9-point operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 9/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Parallel Algorithm 1 (PA1)</p>
    <p>O(1) messages between any 2 procs.</p>
    <p>Redundant computations.</p>
    <p>Applicable to arbitrary sparse matrices</p>
    <p>Works well when the matrix is &quot;well partitioned&quot;  partitions have small &quot;surface to volume ratio&quot;</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 10/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving PA1: 9-pt operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 11/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving PA1: 9-pt operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 11/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving PA1: 9-pt operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 11/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving PA1: 9-pt operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 11/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving PA1: 9-pt operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 11/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving PA1: 9-pt operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 11/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving PA1: 9-pt operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 11/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving PA1: 9-pt operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 11/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving PA1: 9-pt operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 11/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Improving PA1: 9-pt operator for 3 iterations</p>
    <p>entries.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 11/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Parallel Algorithm 2 (PA2)</p>
    <p>O(1) messages between any 2 procs..</p>
    <p>Fewer ops than PA1.</p>
    <p>Half as much redundant computation as PA1</p>
    <p>Locally computable entries computed on only their host proc.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 12/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Sequential Algorithm</p>
    <p>Entries of x and A may be reordered to minimize the cost of accessing slow memory.</p>
    <p>Minimizing number of slow memory accesses.</p>
    <p>Minimizing number of entries fetched from slow memory:</p>
    <p>Extra entries fetched to reduce the number of slow memory accesses.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 13/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Setup Nave Algorithm Parallel Algorithms Sequential Algorithm</p>
    <p>Sequential Algorithm: Ordering Example for 9-pt Operator</p>
    <p>Block level ordering</p>
    <p>Left block needs 2 accesses to fetch the entries in 1, 7, 8.</p>
    <p>Other blocks need 1 access to fetch their needed entries.</p>
    <p>Global ordering</p>
    <p>Computing block 2 after block 1  colored regions of x do not need to be fetched</p>
    <p>Computing block 4 after block 1  only the blue regions of x do not need to fetched</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 14/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Modeling Speedup for Sequential Algorithm Modeling Speedup for Parallel Algorithm</p>
    <p>Modeled Speedup for Sequential Out-of-Core Algorithm on 9-pt Operator</p>
    <p>No. of blocks p (1p pmax) chosen for best perf.</p>
    <p>Speedups across whole</p>
    <p>range of problem sizes (at</p>
    <p>least 10x)</p>
    <p>Reading A and x always costs bw.  speedups always possible.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 15/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Modeling Speedup for Sequential Algorithm Modeling Speedup for Parallel Algorithm</p>
    <p>Modeled Speedup for Sequential Out-of-Core Algorithm on 27-point Operator</p>
    <p>Speedups across whole range of problem sizes (at least 7x).</p>
    <p>Speedups decrease after a certain k.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 16/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Modeling Speedup for Sequential Algorithm Modeling Speedup for Parallel Algorithm</p>
    <p>Modeled Speedup for Sequential Algorithm with On-Chip Cache as Fast Memory</p>
    <p>GBytes/s</p>
    <p>Models single core, single socket of a quad-core Intel Clovertown chip</p>
    <p>Matrix Range of n (Range of) Modeled Speedup</p>
    <p>Speedups always possible across all problem sizes</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 17/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Modeling Speedup for Sequential Algorithm Modeling Speedup for Parallel Algorithm</p>
    <p>Performance Model: Parallel Algorithm (PA2)</p>
    <p>memory=500 GBytes, lat=10 s, bw=4 GBytes/s</p>
    <p>Matrix Range of n Max Modeled Speedup</p>
    <p>Speedups for small problem sizes (for 9-pt operator, 210 n 213). Other problem sizes computation bound, so not limited by communication (hidden by overlap with communication).</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 18/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Modeling Speedup for Sequential Algorithm Modeling Speedup for Parallel Algorithm</p>
    <p>Performance Model: Parallel Algorithm (PA2)</p>
    <p>Grid: No. procs. = 125, proc. performance = 1 TFlops/s, memory=10 TBytes, lat=100 ms, bw=320 MBytes/s</p>
    <p>Matrix Range of n Max Modeled Speedup</p>
    <p>Small problem sizes run on 1 proc. Speedups for moderate problem sizes (for 9-pt operator, 215 n 219). Large problem sizes computation bound.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 19/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Implementation Results</p>
    <p>Implementation</p>
    <p>Parallel algorithm implemented in UPC (Unied Parallel C).</p>
    <p>Works for general sparse matrices. For PA1, entries of A and x reordered to make local computations as k invocations of Sparse Matrix Vector multiplication.</p>
    <p>Sequential (out-of-core) algorithm implemented in C.</p>
    <p>Slow memory assumed to be disk. Reordering done to minimize bandwidth cost for disk access using a randomized heuristic.</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 20/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Implementation Results</p>
    <p>Results: Sequential Out-of-Core Algorithm</p>
    <p>Itanium II node with 5.2 GFlops peak op rate.</p>
    <p>Performance 6x slower than ideal machine ( DRAM).</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 21/ 25</p>
  </div>
  <div class="page">
    <p>Background Algorithms</p>
    <p>Summary</p>
    <p>Summary and Future Work</p>
    <p>Sequential and parallel communication avoiding algorithms for the Akx kernel.</p>
    <p>Almost linear speedups possible. Minimum latency cost. Minimum bandwidth cost for the sequential algorithm.</p>
    <p>Performance modeling of the algorithms. Parallel implementation expected to achieve speedups for moderate problem sizes. Sequential implementation expected to achieve speedups across the whole range of problem sizes.</p>
    <p>Sequential implementation demonstrates speedup of 3x for a 27-point operator. Akx kernel part of a larger eort for communication avoiding iterative solvers</p>
    <p>Extensions to polynomial bases Incorporating preconditioning (matrix A multiplied by a preconditioner matrix M)</p>
    <p>Mohiyuddin et al. Avoiding Comm. in Sparse Matrix Comp. 22/ 25</p>
  </div>
  <div class="page">
    <p>Thank You!</p>
  </div>
  <div class="page">
    <p>Modeled Speedup for Sequential Algorithm with Cache as Fast Memory on 9-pt</p>
    <p>Operator</p>
    <p>GBytes, lat = 200 ns, bw</p>
    <p>= 5 GBytes/s.</p>
    <p>Models single core,</p>
    <p>single socket of a</p>
    <p>quad-core Intel</p>
    <p>Clovertown chip</p>
    <p>No. of blocks p (1p pmax) chosen for best perf.</p>
    <p>Speedups across whole</p>
    <p>range of problem sizes (at</p>
    <p>least 2.4x)</p>
  </div>
  <div class="page">
    <p>Modeled Speedup for Sequential Algorithm with Cache as Fast Memory on 27-pt</p>
    <p>Operator</p>
    <p>Speedups across whole range of problem sizes (at least 1.3x)</p>
    <p>Surface eects limit</p>
    <p>maximum range of k</p>
  </div>
</Presentation>
