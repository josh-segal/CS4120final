<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Categorizing and Inferring the</p>
    <p>Relationship Between the Text</p>
    <p>and Image of Twitter Posts</p>
    <p>Alakananda Vempala</p>
    <p>Daniel Preoiuc-Pietro</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Whats the largest difference in</p>
    <p>Twitter content in 2010 and 2019? 2010 2019</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Whats the largest difference in</p>
    <p>Twitter content in 2010 and 2019?</p>
    <p>Many more tweets contain images</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Whats the largest difference in</p>
    <p>Twitter content in 2010 and 2019?</p>
    <p>Many more tweets contain images</p>
    <p>Approximately 12% tweets are now</p>
    <p>accompanied by images &gt; 50M/day</p>
    <p>Very little is known about the text</p>
    <p>image relationship</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Text and image in a tweet can be related in</p>
    <p>several ways:</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Text and image in a tweet can be related in</p>
    <p>several ways:</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Text and image in a tweet can be related in</p>
    <p>several ways:</p>
  </div>
  <div class="page">
    <p>Applications</p>
    <p>Automatically hiding images that dont</p>
    <p>add additional content to a Twitter</p>
    <p>post to maximize screen estate</p>
    <p>Image can be hidden</p>
    <p>Two extra tweets can be displayed</p>
    <p>Image has additional content</p>
  </div>
  <div class="page">
    <p>Applications</p>
    <p>Automatically identify tweets that contain images and their captions</p>
    <p>Data can be used for distant supervision for image classification</p>
    <p>Identify tweets that contain creative descriptions for images</p>
  </div>
  <div class="page">
    <p>Data  Task Definition  Text Task</p>
    <p>Aim: Determine whether there is semantic overlap between the context of the text and the image</p>
    <p>None of the content words in the text are</p>
    <p>represented in the image</p>
    <p>(Text is not represented)</p>
    <p>Some or all of the content words in the</p>
    <p>text are represented in the image</p>
    <p>(Text is represented)</p>
  </div>
  <div class="page">
    <p>Data  Task Definition  Image Task</p>
    <p>Focuses on the role of the image to the semantics of the tweet</p>
    <p>Aim: Identify if the images content contributes with additional information to the meaning of the</p>
    <p>tweet beyond the text</p>
    <p>Image does not add additional content that</p>
    <p>represents the meaning of text &amp; image</p>
    <p>(Image does not add)</p>
    <p>Image has additional content that</p>
    <p>represents the meaning of text &amp; image</p>
    <p>(Image adds)</p>
  </div>
  <div class="page">
    <p>Data  Annotation</p>
    <p>We used Figure Eight (formerly CrowdFlower)</p>
    <p>Text task  Redundancy of 3</p>
    <p>Krippendorfs Alpha = 0.71 (Text Task)</p>
    <p>Annotators maintained &gt; 85% accuracy over test questions</p>
    <p>Image task  Redundancy of 5</p>
    <p>Krippendorfs Alpha = 0.46 (Text Task)</p>
    <p>Annotators maintained &gt; 75% accuracy over test questions</p>
    <p>Adjudication by majority vote</p>
  </div>
  <div class="page">
    <p>Data  Collection</p>
    <p>Collected annotations for 4,888 tweets  All tweets posted in the same year (2016)</p>
    <p>Split across original posts, retweets and favorited posts</p>
    <p>Deliberately sampled from users with known demographic traits</p>
    <p>Tweets are all in English</p>
    <p>Available online: https://github.com/danielpreotiuc/text-image-relationship</p>
  </div>
  <div class="page">
    <p>Data  Distribution</p>
    <p>Both task labels are combined to assign one of four classes to each text-image pair</p>
    <p>Image adds &amp; Text is represented</p>
    <p>Image adds &amp; Text not represented</p>
    <p>Image does not add &amp; Some text represented</p>
    <p>Image does not add &amp; Text not represented</p>
  </div>
  <div class="page">
    <p>Analysis  Text Task</p>
    <p>Univariate Point-Biserial Correlation between unigram features and text task outcome</p>
    <p>Age is correlated with text being represented in image  Especially when image also adds information</p>
    <p>More traditional type of relationship</p>
    <p>Simple tweet metadata not correlated</p>
    <p>None of the content words in the text</p>
    <p>are represented in the image</p>
    <p>(Text is not represented)</p>
    <p>Some or all of the content words in the</p>
    <p>text are represented in the image</p>
    <p>(Text is represented)</p>
  </div>
  <div class="page">
    <p>Analysis  Image Task</p>
    <p>Univariate Point-Biserial Correlation between unigram features and text task outcome</p>
    <p>Simple tweet metadata not correlated</p>
    <p>No demographic user information correlated  4-way analyses in the paper</p>
    <p>Image does not add additional content that</p>
    <p>represents the meaning of text &amp; image</p>
    <p>(Image does not add to meaning)</p>
    <p>Image has additional content that</p>
    <p>represents the meaning of text &amp; image</p>
    <p>(Image adds to meaning)</p>
  </div>
  <div class="page">
    <p>Prediction  Methods</p>
    <p>Demographics</p>
    <p>Metadata</p>
    <p>Text-Based Methods  Surface</p>
    <p>Unigrams</p>
    <p>BiLSTM</p>
    <p>Image-Based Methods  ImageNet Classes</p>
    <p>InceptionNet Tuned</p>
    <p>Joint Text+Image approaches  Linear ensemble of text and image predictions</p>
    <p>LSTM + InceptionNet architecture</p>
  </div>
  <div class="page">
    <p>Prediction  Baseline Methods</p>
    <p>Results in weighted F1, Train (80%), Test (20%), Parameters set via 10 -fold CV</p>
    <p>Three tasks: Image Task (binary), Text Task (binary), Image + Text (4 -class)</p>
    <p>Demographics, tweet metadata features almost no predictive value</p>
    <p>Image Task (Image adds to meaning)</p>
    <p>Text Task (Text is represented)</p>
    <p>Image + Text Task</p>
    <p>Majority Class</p>
  </div>
  <div class="page">
    <p>Prediction  Text-based Methods</p>
    <p>All tasks show improvements on the baseline  Higher predictive power on image task (does the image have additional content)</p>
    <p>LSTM models are marginally better than unigrams</p>
    <p>Image Task (Image adds to meaning)</p>
    <p>Text Task (Text is represented)</p>
    <p>Image + Text Task</p>
    <p>Majority Class</p>
    <p>Text-based</p>
  </div>
  <div class="page">
    <p>Prediction  Image-based Methods</p>
    <p>All tasks show improvements on the baseline  Image-based methods &gt; Text-based on the Image Task</p>
    <p>Image-based methods &lt; Text-based on the Text Task</p>
    <p>Tuned InceptionNet is the best image-based method</p>
    <p>Image Task (Image adds to meaning)</p>
    <p>Text Task (Text is represented)</p>
    <p>Image + Text Task</p>
    <p>Majority Class</p>
    <p>Text-based</p>
    <p>Image-based</p>
  </div>
  <div class="page">
    <p>Prediction  Joint Text + Image Methods</p>
    <p>Improves over the best text-based or image-based methods</p>
    <p>LSTM + InceptionNet performs better</p>
    <p>Image task is much more predictable using models</p>
    <p>Text task is significantly harder (similar to humans)</p>
    <p>Image Task (Image adds to meaning)</p>
    <p>Text Task (Text is represented)</p>
    <p>Image + Text Task</p>
    <p>Majority Class</p>
    <p>Text-based</p>
    <p>Image-based</p>
    <p>Text + Image</p>
  </div>
  <div class="page">
    <p>Text-Image relationship in tweets is complex:  Text does not always describe the image</p>
    <p>The image does not always illustrate text</p>
    <p>Text-image relationship is likely useful for downstream applications</p>
    <p>New classification schema and data set for text-image relationships on Twitter  https://github.com/danielpreotiuc/text-image-relationship</p>
    <p>Relationship type is predictable from both text and image  Best results on each subtask are obtained by methods using different modalities (text or</p>
    <p>image)</p>
    <p>Takeaways</p>
    <p>We are hiring:</p>
    <p>NYC  http://careers.bloomberg.com/job/detail/74022</p>
    <p>London  http://careers.bloomberg.com/job/detail/74154</p>
  </div>
</Presentation>
