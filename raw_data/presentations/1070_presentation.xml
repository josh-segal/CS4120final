<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Locality-Aware Software Throttling for Sparse Matrix Operation on GPUs</p>
    <p>Yanhao Chen1, Ari B. Hayes1, Chi Zhang2, Timothy Salmon1, Eddy Z. Zhang1</p>
  </div>
  <div class="page">
    <p>Sparse Matrix  Sparse Linear Systems</p>
    <p>- CG - GMRES -</p>
    <p>Physics Based Simulations - CFD</p>
    <p>Deep Learning Optimizations - Pruned Neural Networks</p>
  </div>
  <div class="page">
    <p>Sparse Matrix Operation</p>
    <p>y = A x Sparse Matrix</p>
    <p>A Input Vector</p>
    <p>x Output Vector</p>
    <p>y</p>
    <p>&amp;' = ()*+,) { .'/  1/}</p>
    <p>Binary Operator 3  1,,8 ,9  [1,,;]</p>
  </div>
  <div class="page">
    <p>Sparse Matrix Vector Multiplication (SpMV)</p>
    <p>!&quot;#$%&quot; = sum  =</p>
    <p>,- = ./0{2-,4  54}</p>
    <p>&lt; &lt; &lt; &lt;</p>
    <p>&lt; 7;,9 &lt; 7;,;</p>
    <p>=8 =9 =: =;</p>
    <p>&gt;8 &gt;9 &gt;: &gt;;</p>
    <p>* =</p>
    <p>A x y</p>
    <p>,- = !&quot;#$%&quot;{2-454}</p>
    <p>,: = 2:,8  58 + 2:,:  5:@  1,,D ,E  [1,,G]</p>
  </div>
  <div class="page">
    <p>Single Source Shortest Path (SSSP)</p>
    <p>!&quot;#$%&quot; = min  = +</p>
    <p>,- = ./0{23- + 43}</p>
    <p>,- = !&quot;#$%&quot;{2-343}</p>
    <p>S</p>
    <p>S 1 2 3 4 5 S 1 2 3 4 5</p>
    <p>Adjacent Matrix A</p>
    <p>y: distance vector of j th iteration x  (previous) distance vector of j-1 th iteration</p>
    <p>A  1,,E ,F  [1,,H]</p>
  </div>
  <div class="page">
    <p>Problem with Sparsity on GPUs  Low data reuse is always a big problem</p>
    <p>e.g. SpMV</p>
    <p>The input vector and the output vector can be reused a lot  They are usually too large to fit into GPUs cache</p>
    <p>The sparsity of the matrix causes irregular accesses of the vectors  This means low reuse of the data in the cache</p>
    <p>!&quot; = $%&amp;{(&quot;,*  ,*}</p>
  </div>
  <div class="page">
    <p>Existing Methods to Improve Data Reuse on GPUs</p>
    <p>Warp Scheduling Policy  Throttling concurrent threads  Limits the number of active warps [Rogers+, MICRO12]  DYNCTA: controls the number of CTAs [Kayiran+,PACT13]</p>
    <p>Computation and Data Layout Transformation  Reduce irregular memory accesses  Improve Memory Coalescing [Zhang+, ICS10]</p>
    <p>Need Hardware Modification!</p>
    <p>Only focus on Spatial Data Reuse!</p>
  </div>
  <div class="page">
    <p>Is the First Software Throttling implementation</p>
    <p>Is focused on Temporal Data Reuse</p>
    <p>Exploits the Trade-off between throttling performance and GPU throughput</p>
  </div>
  <div class="page">
    <p>SpMV with Software Throttling !&quot; !# !$ !%</p>
    <p>&amp;&quot; &amp;# &amp;$ &amp;%</p>
    <p>X =</p>
    <p>X Y</p>
    <p>'&quot;,&quot; '&quot;,# '&quot;,$ '&quot;,%</p>
    <p>) ) ) )</p>
    <p>'$,&quot; ) '$,$ )</p>
    <p>) '%,# ) '%,% A</p>
  </div>
  <div class="page">
    <p>SpMV with Software Throttling !&quot; !# !$ !%</p>
    <p>&amp;&quot; &amp;# &amp;$ &amp;%</p>
    <p>X =</p>
    <p>X Y</p>
    <p>'&quot;,&quot; '&quot;,# '&quot;,$ '&quot;,%</p>
    <p>) ) ) )</p>
    <p>'$,&quot; ) '$,$ )</p>
    <p>) '%,# ) '%,% A</p>
    <p>Matrix A is bypassing the cache</p>
  </div>
  <div class="page">
    <p>SpMV with Software Throttling</p>
    <p>{ &lt; !&quot; #&quot; &gt; &lt; !$ #&quot; &gt; &lt; !% #&quot; &gt; &lt; !&amp; #&quot; &gt; &lt; !&quot; #% &gt; &lt; !% #% &gt; &lt; !$ #&amp; &gt; &lt; !&amp; #&amp; &gt; }</p>
    <p>Original Case</p>
    <p>!&quot; !# !$ !%</p>
    <p>&amp;&quot; &amp;# &amp;$ &amp;%</p>
    <p>X =</p>
    <p>X Y</p>
    <p>'&quot;,&quot; '&quot;,# '&quot;,$ '&quot;,%</p>
    <p>) ) ) )</p>
    <p>'$,&quot; ) '$,$ )</p>
    <p>) '%,# ) '%,% A</p>
    <p>Matrix A is bypassing the cache</p>
    <p>Running at one time</p>
  </div>
  <div class="page">
    <p>SpMV with Software Throttling</p>
    <p>{ &lt; !&quot; #&quot; &gt; &lt; !$ #&quot; &gt; &lt; !% #&quot; &gt; &lt; !&amp; #&quot; &gt; &lt; !&quot; #% &gt; &lt; !% #% &gt; &lt; !$ #&amp; &gt; &lt; !&amp; #&amp; &gt; }</p>
    <p>Original Case</p>
    <p>Cache Capacity: 4</p>
    <p>!&quot; !# !$ !%</p>
    <p>&amp;&quot; &amp;# &amp;$ &amp;%</p>
    <p>X =</p>
    <p>X Y</p>
    <p>'&quot;,&quot; '&quot;,# '&quot;,$ '&quot;,%</p>
    <p>) ) ) )</p>
    <p>'$,&quot; ) '$,$ )</p>
    <p>) '%,# ) '%,% A</p>
    <p>!&quot; #&quot; !$ !% !&amp; #% #&amp;</p>
    <p>Matrix A is bypassing the cache</p>
    <p>Running at one time</p>
  </div>
  <div class="page">
    <p>SpMV with Software Throttling</p>
    <p>&lt; !&quot; #&quot; &gt; &lt; !&quot; #$ &gt; &lt; !$ #&quot; &gt; &lt; !$ #$ &gt;</p>
    <p>&lt; !% #&quot; &gt; &lt; !% #&amp; &gt; &lt; !&amp; #&quot; &gt; &lt; !&amp; #&amp; &gt;</p>
    <p>Ti m</p>
    <p>e</p>
    <p>Throttling Phase 1</p>
    <p>Cache Capacity: 4</p>
    <p>!&quot; !# !$ !%</p>
    <p>&amp;&quot; &amp;# &amp;$ &amp;%</p>
    <p>X =</p>
    <p>X Y</p>
    <p>'&quot;,&quot; '&quot;,# '&quot;,$ '&quot;,%</p>
    <p>) ) ) )</p>
    <p>'$,&quot; ) '$,$ )</p>
    <p>) '%,# ) '%,% A</p>
  </div>
  <div class="page">
    <p>SpMV with Software Throttling</p>
    <p>&lt; !&quot; #&quot; &gt; &lt; !&quot; #$ &gt; &lt; !$ #&quot; &gt; &lt; !$ #$ &gt;</p>
    <p>Throttling Phase 1</p>
    <p>&lt; !% #&quot; &gt; &lt; !% #&amp; &gt; &lt; !&amp; #&quot; &gt; &lt; !&amp; #&amp; &gt;</p>
    <p>Cache Capacity: 4</p>
    <p>Ti m</p>
    <p>e</p>
    <p>!&quot; #&quot; !$ #$</p>
    <p>All Data Can Fit into the Cache</p>
    <p>!&quot; !# !$ !%</p>
    <p>&amp;&quot; &amp;# &amp;$ &amp;%</p>
    <p>X =</p>
    <p>X Y</p>
    <p>'&quot;,&quot; '&quot;,# '&quot;,$ '&quot;,%</p>
    <p>) ) ) )</p>
    <p>'$,&quot; ) '$,$ )</p>
    <p>) '%,# ) '%,% A</p>
  </div>
  <div class="page">
    <p>SpMV with Software Throttling</p>
    <p>&lt; !&quot; #&quot; &gt; &lt; !&quot; #$ &gt; &lt; !$ #&quot; &gt; &lt; !$ #$ &gt;</p>
    <p>Throttling Phase 2</p>
    <p>&lt; !% #&quot; &gt; &lt; !% #&amp; &gt; &lt; !&amp; #&quot; &gt; &lt; !&amp; #&amp; &gt;</p>
    <p>Cache Capacity: 4</p>
    <p>Ti m</p>
    <p>e</p>
    <p>!&quot; !# !$ !%</p>
    <p>&amp;&quot; &amp;# &amp;$ &amp;%</p>
    <p>X =</p>
    <p>X Y</p>
    <p>'&quot;,&quot; '&quot;,# '&quot;,$ '&quot;,%</p>
    <p>) ) ) )</p>
    <p>'$,&quot; ) '$,$ )</p>
    <p>) '%,# ) '%,% A</p>
  </div>
  <div class="page">
    <p>SpMV with Software Throttling</p>
    <p>&lt; !&quot; #&quot; &gt; &lt; !&quot; #$ &gt; &lt; !$ #&quot; &gt; &lt; !$ #$ &gt;</p>
    <p>Throttling Phase 2</p>
    <p>&lt; !% #&quot; &gt; &lt; !% #&amp; &gt; &lt; !&amp; #&quot; &gt; &lt; !&amp; #&amp; &gt;</p>
    <p>Cache Capacity: 4</p>
    <p>Ti m</p>
    <p>e</p>
    <p>!% #&quot; !&amp; #&amp;</p>
    <p>All Data Can Fit into the Cache</p>
    <p>!&quot; !# !$ !%</p>
    <p>&amp;&quot; &amp;# &amp;$ &amp;%</p>
    <p>X =</p>
    <p>X Y</p>
    <p>'&quot;,&quot; '&quot;,# '&quot;,$ '&quot;,%</p>
    <p>) ) ) )</p>
    <p>'$,&quot; ) '$,$ )</p>
    <p>) '%,# ) '%,% A</p>
  </div>
  <div class="page">
    <p>What We Need for Software Throttling  An effective partitioning algorithm</p>
    <p>All data items in one partition can fit into the cache  The interaction between different partitions are minimized</p>
    <p>Applicable scheduling methods  Handle the trade-off between throttling and throughput</p>
  </div>
  <div class="page">
    <p>What We Need for Software Throttling  An effective partitioning algorithm</p>
    <p>All data items in one partition can fit into the cache  The interaction between different partitions are minimized</p>
    <p>Applicable scheduling methods  Handle the trade-off between throttling and throughput</p>
  </div>
  <div class="page">
    <p>Graph Representation  Graph Edge Partition Model</p>
    <p>Places an emphasis on Data  Node  Data object  Edge  Interaction between data</p>
    <p>(&quot; ($ (% (&amp;</p>
    <p>)&quot; )$ )% )&amp;</p>
    <p>X =</p>
    <p>A X Y X1 X2 X3 X4</p>
    <p>Y1 Y2 Y3 Y4</p>
  </div>
  <div class="page">
    <p>Why Edge Partition Model? 1. Better load balancing</p>
    <p>PowerGraph [OSDI12], Streaming Edge Partition [KDD14], SPAC [SIGMETRICS17]</p>
    <p>Balanced vertex partition is sometimes NOT equal to balanced workload</p>
  </div>
  <div class="page">
    <p>Different Edge Partition Models Load Balanced Partition Data Balanced Partition</p>
    <p>X1 X2 X3 X4</p>
    <p>Y1 Y2 Y3 Y4</p>
    <p>Partition 1 Partition 2</p>
    <p>X1 X2 X3 X4</p>
    <p>Y1 Y2 Y3 Y4</p>
    <p>Partition 1 Partition 2</p>
    <p># Nodes: 4 # Nodes: 4# Edges: 3 # Edges: 3 Cache-Fit Partition</p>
  </div>
  <div class="page">
    <p>Data Balanced Partition  Recursive Bisection Framework</p>
    <p>2-way Load Balanced Edge Partition  SPAC [Li+,SIGMETRICS17]</p>
    <p>Minimize vertex replica (data copy)</p>
    <p>X1 X2 X3 X4</p>
    <p>Y1 Y2 Y3 Y4</p>
    <p>Cache Capacity: 4</p>
  </div>
  <div class="page">
    <p>Data Balanced Partition  Recursive Bisection Framework</p>
    <p>2-way Load Balanced Edge Partition  SPAC [Li+,SIGMETRICS17]</p>
    <p>Minimize vertex replica (data copy)</p>
    <p>X1 X2 X3 X4</p>
    <p>Y1 Y2 Y3 Y4</p>
    <p>Partition A Partition B</p>
    <p>Cache Capacity: 4</p>
  </div>
  <div class="page">
    <p>Data Balanced Partition  Recursive Bisection Framework</p>
    <p>2-way Load Balanced Edge Partition  SPAC [Li+,SIGMETRICS17]</p>
    <p>Minimize vertex replica (data copy)</p>
    <p>X1 X2 X3 X4</p>
    <p>Y1 Y2 Y3 Y4</p>
    <p>Partition A Partition B</p>
    <p>Cache Capacity: 4</p>
  </div>
  <div class="page">
    <p>Data Balanced Partition  Recursive Bisection Framework</p>
    <p>2-way Load Balanced Edge Partition  SPAC [Li+,SIGMETRICS17]</p>
    <p>Minimize vertex replica (data copy)</p>
    <p>Cache Capacity: 4</p>
    <p>X2 X3 X4</p>
    <p>Y2 Y3 Y4</p>
    <p>Partition B Partition C</p>
  </div>
  <div class="page">
    <p>Data Balanced Partition  Recursive Bisection Framework</p>
    <p>2-way Load Balanced Edge Partition  SPAC [Li+,SIGMETRICS17]</p>
    <p>Minimize vertex replica (data copy)</p>
    <p>Cache Capacity: 4</p>
    <p>Partition B</p>
    <p>Partition C</p>
    <p>X1 X2 X3 X4</p>
    <p>Y1 Y2 Y3 Y4</p>
    <p>Partition A</p>
  </div>
  <div class="page">
    <p>What We Need for Software Throttling  A good partitioning algorithm</p>
    <p>All data items in one partition can fit into the cache  The interaction between different partitions are minimized</p>
    <p>Applicable scheduling methods  Handle the trade-off between throttling and throughput</p>
  </div>
  <div class="page">
    <p>Effective scheduling methods  Four different scheduling methods</p>
    <p>Cache-Fit (CF)  Cache-Fit Queue (CF-Q)  Split-Join (SJ)  Split-Join Queue (SJ-Q)</p>
  </div>
  <div class="page">
    <p>Effective scheduling methods  Four different scheduling methods</p>
    <p>Cache-Fit (CF)  Cache-Fit Queue (CF-Q)  Split-Join (SJ)  Split-Join Queue (SJ-Q)</p>
  </div>
  <div class="page">
    <p>Cache-Fit (CF) Scheduling  Isolate the computation of different Cache-Fit Partitions  Run one Cache-Fit Partition at one time</p>
    <p>TL: tuple list</p>
    <p>N: # of tuples</p>
    <p>TL: new tuple list</p>
    <p>Pi: # of tuples in TL[i]</p>
    <p>Strict Barriers</p>
    <p>CUDA Function</p>
  </div>
  <div class="page">
    <p>Low Pipeline Utilization</p>
    <p>Kernel 1 -- Partition ACache Capacity: 4</p>
    <p>Partition A Partition B</p>
    <p>Partition C</p>
    <p>X1 X2 X3 X4</p>
    <p>Y1 Y2 Y3 Y4</p>
    <p>X1</p>
    <p>Y1</p>
    <p>X1</p>
    <p>Y2</p>
    <p>X2</p>
    <p>Y1</p>
    <p>X2</p>
    <p>Y2</p>
  </div>
  <div class="page">
    <p>Low Throughput</p>
    <p>Cache Capacity: 4</p>
    <p>Partition A Partition B</p>
    <p>Partition C</p>
    <p>X1 X2 X3 X4</p>
    <p>Y1 Y2 Y3 Y4</p>
    <p>X2</p>
    <p>Y3</p>
    <p>X3</p>
    <p>Y3</p>
    <p>Kernel 2 -- Partition B</p>
    <p>IDLE</p>
  </div>
  <div class="page">
    <p>Low Pipeline Utilization</p>
    <p>Cache Capacity: 4</p>
    <p>Partition A Partition B</p>
    <p>Partition C</p>
    <p>X1 X2 X3 X4</p>
    <p>Y1 Y2 Y3 Y4</p>
    <p>X4</p>
    <p>Y3</p>
    <p>X4</p>
    <p>Y4</p>
    <p>Kernel 3 -- Partition C</p>
    <p>IDLE</p>
    <p>low pipeline utilization</p>
  </div>
  <div class="page">
    <p>Effective scheduling methods  Four different scheduling methods</p>
    <p>Cache-Fit (CF)  Cache-Fit Queue (CF-Q)  Split-Join (SJ)  Split-Join Queue (SJ-Q)</p>
  </div>
  <div class="page">
    <p>Cache-Fit Queue (CF-Q) Scheduling  Invoke a single kernel call but still</p>
    <p>enable throttling</p>
    <p>Set up a FIFO queue  Each entry corresponds to a chunk</p>
    <p>A chunk is part of a cache-fit partition  Adjacent chunks are from the same</p>
    <p>Cache-Fit Partition  Each warp fetches a chunk from the</p>
    <p>queue and processes it</p>
    <p>Cache-Fit Partition 1</p>
    <p>Chunk 1</p>
    <p>Chunk 2</p>
    <p>Chunk N</p>
    <p>Q ue</p>
    <p>ue</p>
    <p>Cache-Fit Partition 2</p>
    <p>Chunk 1</p>
    <p>Chunk 2</p>
    <p>Chunk M</p>
  </div>
  <div class="page">
    <p>Cache-Fit Queue (CF-Q) Scheduling cont.</p>
    <p>Cache-Fit Partition 1</p>
    <p>Chunk 1</p>
    <p>Chunk 2</p>
    <p>Chunk N</p>
    <p>Q ue</p>
    <p>ue</p>
    <p>Cache-Fit Partition 2</p>
    <p>Chunk 1</p>
    <p>Chunk 2</p>
    <p>Chunk M</p>
    <p>Ti m</p>
    <p>e</p>
    <p>Warp 1 Warp 2</p>
    <p>Chunk 1</p>
    <p>Chunk 4</p>
    <p>Chunk 2</p>
    <p>Chunk 3</p>
    <p>Chunk N Chunk 1</p>
    <p>Chunk 2 Chunk 3</p>
    <p>Relaxed Barrier</p>
    <p>Chunk 3</p>
    <p>Chunk 4</p>
  </div>
  <div class="page">
    <p>Effective scheduling methods  Four different scheduling methods</p>
    <p>Cache-Fit (CF)  Cache-Fit Queue (CF-Q)  Split-Join (SJ)  Split-Join Queue (SJ-Q)</p>
  </div>
  <div class="page">
    <p>Split-Join (SJ) Scheduling  Dynamically merge Cache-Fit Partitions</p>
    <p>Perform an Online Profiling to decide which partitions should be merged</p>
    <p>Use the Tree Representation of the data balanced partition to help the Online Profiling</p>
  </div>
  <div class="page">
    <p>Split-Join (SJ) Scheduling</p>
    <p>Cache Capacity: 4</p>
    <p>Partition A Partition B</p>
    <p>Partition C</p>
    <p>X1 X2 X3 X4</p>
    <p>Y1 Y2 Y3 Y4</p>
  </div>
  <div class="page">
    <p>Split-Join (SJ) Scheduling</p>
    <p>A.stime: 0.5 A.btime: 0.5</p>
    <p>stime: measured standalone running time btime: optimal running time on this node</p>
    <p>B.stime: 0.2 B.btime: 0.2</p>
    <p>C.stime: 0.2 C.btime: 0.2</p>
    <p>All Edges</p>
    <p>Partition A Partition B, C</p>
    <p>Partition B Partition C</p>
  </div>
  <div class="page">
    <p>Split-Join (SJ) Scheduling stime: measured standalone running time btime: optimal running time on this node</p>
    <p>B.stime: 0.2 B.btime: 0.2</p>
    <p>C.stime: 0.2 C.btime: 0.2</p>
    <p>BC.stime: 0.3 BC.btime: 0.3</p>
    <p>All.stime: 1.2 All.btime: 0.8</p>
    <p>BC.stime &lt; B.btime + C.btime</p>
    <p>All Edges</p>
    <p>Partition A Partition B, C</p>
    <p>Partition B Partition C</p>
    <p>All.stime &gt; A.btime + BC.btime</p>
    <p>A.stime: 0.5 A.btime: 0.5</p>
  </div>
  <div class="page">
    <p>Effective scheduling methods  Four different scheduling methods</p>
    <p>Cache-Fit (CF)  Cache-Fit Queue (CF-Q)  Split-Join (SJ)  Split-Join Queue (SJ-Q)</p>
  </div>
  <div class="page">
    <p>Split-Join Queue (SJ-Q) Scheduling  Provide strict barriers between different merged partitions</p>
    <p>No barriers inside a merged partition of SJ  No guarantee of the execution order</p>
    <p>Set up one FIFO queue for each merged partition  Provide relaxed barriers between cache-fit partitions from the same</p>
    <p>merged partition</p>
  </div>
  <div class="page">
    <p>Four Scheduling Methods Summary</p>
    <p>Methods Pipeline Utilization Profiling Barriers Queue Code</p>
    <p>Change CF Low No Strict No No</p>
    <p>CF-Q High No Relaxed Yes Yes SJ High Yes Strict No No</p>
    <p>SJ-Q High Yes Strict / Relaxed Yes Yes</p>
  </div>
  <div class="page">
    <p>Software Throttling Performance  Experiment Settings</p>
    <p>GPU Model Titan X GTX 745 Architecture Pascal Maxwell</p>
    <p>Core # 5376 576 L2 Cache 3MB 2MB</p>
    <p>CUDA Version CUDA 8.0 CUDA 8.0</p>
    <p>CPU Intel XeonE5-2620 Intel Core</p>
    <p>i7-4790</p>
  </div>
  <div class="page">
    <p>Benchmarks  Sparse Linear Algebra Workloads</p>
    <p>Sparse Matrix Vector Multiplication (SPMV)</p>
    <p>Graph Processing Workloads  Bellman-Ford (BMF)  Page Rank (PR)</p>
    <p>Neural Network Optimization  Deep Compression: Pruned AlexNet</p>
  </div>
  <div class="page">
    <p>Sparse Matrix Vector Multiplication  Baseline: CUSP  Matrices: Florida Sparse Matrix Collection</p>
    <p>Focus on large matrices: working set cannot fit into L2 cache  228 large matrices on GTX 745  192 large matrices on Titan X</p>
  </div>
  <div class="page">
    <p>Overall SPMV Performance</p>
    <p>Org + R CF SJ CF-Q SJ-Q</p>
    <p>N or</p>
    <p>m al</p>
    <p>ize d</p>
    <p>Sp ee</p>
    <p>du p</p>
    <p>Average Speedup For SPMV</p>
    <p>GTX 745 Titan X</p>
  </div>
  <div class="page">
    <p>Effect of Cache Hit Rate</p>
    <p>Org + R CF SJ CF-Q SJ-Q</p>
    <p>N or</p>
    <p>m al</p>
    <p>iz ed</p>
    <p>S pe</p>
    <p>ed up</p>
  </div>
  <div class="page">
    <p>Effect of Working Set Size</p>
    <p>Org + R CF SJ CF-Q SJ-Q</p>
    <p>N or</p>
    <p>m al</p>
    <p>iz ed</p>
    <p>S pe</p>
    <p>ed up 1X - 2X (cache size) 2X - 4X</p>
    <p>Titan X</p>
  </div>
  <div class="page">
    <p>Graph Application Performance</p>
    <p>Pokec WebGoogle Wikipedia* WikiTalk IMDB RoadCentral RoadCal</p>
    <p>N or</p>
    <p>m al</p>
    <p>iz ed</p>
    <p>S pe</p>
    <p>ed up</p>
    <p>BMF &amp; PR Performance using SJ w/ overhead</p>
    <p>BMF PR</p>
    <p>RoadCal is a small Graph</p>
    <p>Titan X</p>
  </div>
  <div class="page">
    <p>Graph Application Performance cont.</p>
    <p>Po ke</p>
    <p>c</p>
    <p>W eb</p>
    <p>Go og</p>
    <p>le</p>
    <p>W iki</p>
    <p>pe dia</p>
    <p>*</p>
    <p>W iki</p>
    <p>Ta lk</p>
    <p>IM DB</p>
    <p>Ro ad</p>
    <p>Ce nt</p>
    <p>ra l</p>
    <p>Ro ad</p>
    <p>Ca lL2</p>
    <p>C ac</p>
    <p>he H</p>
    <p>it R</p>
    <p>at e</p>
    <p>(% )</p>
    <p>BMF Cache Hit Rate</p>
    <p>Original SJ</p>
    <p>Po ke</p>
    <p>c</p>
    <p>W eb</p>
    <p>Go og</p>
    <p>le</p>
    <p>W iki</p>
    <p>pe dia</p>
    <p>*</p>
    <p>W iki</p>
    <p>Ta lk</p>
    <p>IM DB</p>
    <p>Ro ad</p>
    <p>Ce nt</p>
    <p>ra l</p>
    <p>Ro ad</p>
    <p>Ca lL2</p>
    <p>C ac</p>
    <p>he H</p>
    <p>it R</p>
    <p>at e</p>
    <p>(% )</p>
    <p>PR Cache Hit Rate</p>
    <p>Original SJ</p>
    <p>Titan XTitan X</p>
    <p>RoadCal is a small Graph</p>
  </div>
  <div class="page">
    <p>Deep Learning Benchmark  Deep Compression [Han+,ICLR16]</p>
    <p>Prune AlexNet to remove low weight elements in fully connected layers</p>
    <p>Deep Compression provide us sparse matrices</p>
    <p>fc6 fc7 fc8 Combined</p>
    <p>N or</p>
    <p>m al</p>
    <p>ize d</p>
    <p>Sp ee</p>
    <p>du p</p>
    <p>Speedup for AlexNet using Deep Compression</p>
    <p>CF SJ CF-Q SJ-Q</p>
    <p>Titan X</p>
    <p>fc7 and fc8 has small vector size</p>
  </div>
  <div class="page">
    <p>Conclusion  We proposed the first locality-aware Software</p>
    <p>Throttling framework for GPUs</p>
    <p>Our framework can increase data reuse by improving Temporal Locality</p>
    <p>We exploited the Trade-off between cache performance and pipeline utilization</p>
  </div>
  <div class="page"/>
</Presentation>
