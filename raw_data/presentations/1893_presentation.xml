<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Efficient Point to Multipoint Transfers Across Datacenters</p>
    <p>Mohammad Noormohammadpour1, Cauligi S. Raghavendra1, Sriram Rao2, Srikanth Kandula2</p>
  </div>
  <div class="page">
    <p>Source: https://azure.microsoft.com/en-us/overview/datacenters/how-to-choose/ (Jun 14, 2017)</p>
  </div>
  <div class="page">
    <p>Dedicated WAN networks for a single organization</p>
    <p>Connect many datacenters  Increased reliability  Load balancing  Content is usually served by datacenters closest to users</p>
    <p>Lower RTT to users  Higher average throughput (TCP)  Less hops to users  Saves WAN bandwidth</p>
    <p>Inter-Datacenter Networks</p>
    <p>Source: S. Jain et al., B4: Experience with a Globally-Deployed Software Defined WAN, ACM SIGCOMM 2013</p>
    <p>Source: C. Hong et al., Achieving High Utilization with Software-Driven WAN, ACM SIGCOMM 2013</p>
  </div>
  <div class="page">
    <p>Need data delivery from one point to multiple points</p>
    <p>Application</p>
    <p>CDN, Web</p>
    <p>Data Recovery</p>
    <p>Search</p>
    <p>Recommendation, Ads</p>
    <p>Databases</p>
    <p>Geo-Distributed Data Analytics</p>
    <p>Reason for delivery to multiple datacenters</p>
    <p>Getting closer to users</p>
    <p>Making backup copies</p>
    <p>Synchronization of state</p>
    <p>Global load balancing</p>
    <p>Input for next processing stages</p>
  </div>
  <div class="page">
    <p>An abstraction model  Single source</p>
    <p>Content is located on a source datacenter  Receivers are fixed once transfer begins</p>
    <p>No join/leaves</p>
    <p>Point to Multipoint (P2MP) Transfers</p>
    <p>A</p>
    <p>B</p>
    <p>C</p>
    <p>D</p>
    <p>XXXX</p>
  </div>
  <div class="page">
    <p>Usually performed as separate unicast transfers  Wastes bandwidth and can increase completion times</p>
    <p>Multicasting  Network-driven (e.g. IP Multicast)</p>
    <p>Locally and gradually built trees far from optimal  No load distribution management  Complex session management protocols</p>
    <p>Client-driven (e.g. Overlay Networks)  Limited visibility into network status  Limited control over routing</p>
    <p>Using Store-and-Forward  Storage and bandwidth costs on intermediate datacenters  Can lead to excessive delays  More engineering work (running agents, chunking, etc.)</p>
    <p>P2MP Transfers Today B</p>
    <p>C</p>
    <p>D</p>
    <p>A 1</p>
    <p>A</p>
    <p>B</p>
    <p>C</p>
    <p>D</p>
    <p>A</p>
    <p>B</p>
    <p>C</p>
    <p>D</p>
    <p>A</p>
    <p>B</p>
    <p>C</p>
    <p>D</p>
  </div>
  <div class="page">
    <p>Send traffic to all destinations over a forwarding tree  Saves bandwidth  A controller with global view of network status can examine options  Selection according to current network load conditions and transfer parameters</p>
    <p>Use rate-allocation and rate-limiting  A slotted timeline with fixed rates during timeslots  Rate-allocation at controller according to available bandwidth  Rate-limiting at end-points</p>
    <p>Main contribution  Forwarding tree selection</p>
    <p>Weight/Cost assignment to edges</p>
    <p>Our Solution: DCCast</p>
    <p>A</p>
    <p>B</p>
    <p>C</p>
    <p>D</p>
    <p>TE Server</p>
  </div>
  <div class="page">
    <p>Update()  Is executed at the end of every timeslot</p>
    <p>Dispatches rate-allocations to end-points (i.e., senders) for rate-limiting</p>
    <p>Allocate()  Is executed upon arrival of a transfer request</p>
    <p>DCCast Procedures</p>
    <p>DC1</p>
    <p>DC2</p>
    <p>DC3</p>
    <p>Update()</p>
    <p>Allocate(R)Rate Allocation Database</p>
    <p>Rates</p>
    <p>Requests</p>
    <p>TE Server</p>
  </div>
  <div class="page">
    <p>Assume a directed inter-datacenter graph   &amp; is the total outstanding amount of traffic allocated over any edge</p>
    <p>Upon arrival of request  with size of ), every edge  gets a weight of &amp; = ) + &amp;  s forwarding tree is obtained by finding a minimum weight Steiner Tree  Fast heuristics available that often provide results close to optimal</p>
    <p>Selection of Forwarding Trees</p>
    <p>t</p>
    <p>Rate (edge )</p>
    <p>/ 0 1 2 3 4</p>
    <p>&amp; = 5</p>
    <p>4=&gt;</p>
    <p>&amp;</p>
    <p>A</p>
    <p>B</p>
    <p>C</p>
    <p>D</p>
    <p>R (Size = 4)</p>
    <p>A</p>
    <p>B</p>
    <p>C</p>
    <p>D</p>
    <p>R 9 11</p>
    <p>A</p>
    <p>B</p>
    <p>C</p>
    <p>D</p>
    <p>R</p>
  </div>
  <div class="page">
    <p>Any forwarding tree has a cost that is sum of edge weights  Using this cost assignment we stay away from</p>
    <p>Highly loaded edges  Large trees</p>
    <p>Implications of this cost assignment  Smaller trees for larger requests ()  &amp;  &amp;  ))  Trees are selected according to edge loads for smaller requests ()  &amp;  &amp;  &amp;)</p>
    <p>Analysis of DCCast forwarding tree selection</p>
  </div>
  <div class="page">
    <p>Complex problem: Trade-offs  Static policies: FCFS, ALAP (as late as possible)</p>
    <p>More predictability  Dynamic policies: SRPT, Fair Sharing</p>
    <p>Better mean times (by resolving priority inversion)</p>
    <p>We used FCFS policy  Simple, no rate recalculations  Guaranteed completion times given no failures  Senders send at maximum available rate starting next timeslot</p>
    <p>Calculation of available rates across timeslots over trees  &amp;  is the available rate over edge  at time   Maximum rate of tree  at time  is D  = min&amp; D(&amp;  )</p>
    <p>Rate-allocation</p>
    <p>A</p>
    <p>R1R2R3</p>
  </div>
  <div class="page">
    <p>Evaluated Techniques  Selection of Forwarding Trees (Random, MINMAX, DCCast)  Rate-allocation policy (FCFS and SRPT)  DCCast (P2MP) vs. Point-to-Point (P2P-FCFS and P2P-SRPT)</p>
    <p>Performance Metrics  Mean TCT  Tail TCT  Total bandwidth usage</p>
    <p>Traffic Patterns  Artificially generated</p>
    <p>Poisson arrivals  Exponential transfer size distribution</p>
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>We considered three approaches  Randomly selecting a forwarding tree (Random)  Picking the tree with minimal maximum &amp; over any edge (MINMAX)</p>
    <p>Greedy approach  Method used in many research work (minimizing maximum utilization)</p>
    <p>Picking the tree with minimal sum of &amp; (DCCast)</p>
    <p>Results  Overall bandwidth usage (not shown)</p>
    <p>Same for all schemes  Mean and Tail TCT</p>
    <p>DCCast &lt; MINMAX &lt; Random</p>
    <p>Evaluation: Selection of Forwarding Trees</p>
  </div>
  <div class="page">
    <p>DCCast limits load balancing for improved BW savings  MINMAX does not account for number of edges  MINMAX does not account for request volume</p>
    <p>DCCast cost assignment makes it easier to find trees  Edge decomposable costs</p>
    <p>Benefits of DCCast cost assignment over MINMAX</p>
    <p>&amp; = 18</p>
    <p>Small Request with volume of 1 Large Request with volume of 10</p>
    <p>MINMAX</p>
    <p>DCCast</p>
  </div>
  <div class="page">
    <p>We proposed use of FCFS for DCCast  Simple scheduling and resources guaranteed one scheduled  But how much will it lose on Mean TCT?</p>
    <p>SRPT is the best policy for mean times  Challenging to implement: Tree eviction and rate recalculation</p>
    <p>as new requests arrive  Starvation of very large transfers</p>
    <p>Results  FCFS performs slightly better in Tail times  FCFS increases mean times by 50%</p>
    <p>Evaluation: Scheduling Policy</p>
  </div>
  <div class="page">
    <p>Properties of P2P-SRPT scheme  Based on K-Shortest paths (for every transfer)  Uses SRPT policy to achieve best Mean TCT  Rates are calculated using Linear Programming</p>
    <p>Results  Both Tail times and BW Usage improved by up to 50% using DCCast  DCCast better in Mean times when making larger number of copies</p>
    <p>Evaluation: Comparison with Point-to-Point (P2P)</p>
  </div>
  <div class="page">
    <p>Many inter-datacenter transfers follow the P2MP abstraction model  One object is to be delivered to many destinations  Source and destinations known upon arrival of transfers  No joins/leaves</p>
    <p>Perform every P2MP transfer jointly using a forwarding tree  Achieve bandwidth savings and reduce tail times</p>
    <p>Opportunistically and dynamically select forwarding trees  Allowing all available paths to be potentially used  The opposite would be pre-calculating and using K-Minimal Trees</p>
    <p>Summary</p>
  </div>
  <div class="page">
    <p>Thank you!</p>
  </div>
  <div class="page">
    <p>Improving Mean TCT  Multiple trees each connected to a subset of receivers (addressing the slow receiver)  Parallel trees to same subsets of receivers (increasing throughput)  SRPT with only BW preemption (trees selected upon request arrivals)  Combining forwarding trees with store-and-forward  Applying batching techniques for bursty arrival patterns (e.g. apply SJF policy to batches)  Applying the fair-sharing policy (rather than FCFS)</p>
    <p>Evaluation using real traces of inter-datacenter traffic  Choose scheduling policy according to traffic patterns</p>
    <p>Handling failures  Proactive approaches (leaving spare capacity, backup trees)  Reactive approaches (rescheduling affected transfers, local activation)</p>
    <p>Future Work &amp; Discussion</p>
  </div>
</Presentation>
