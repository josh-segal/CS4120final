<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Belief in Information FlowBelief in Information Flow</p>
    <p>Michael Clarkson, Andrew Myers, Fred B. Schneider</p>
    <p>Cornell University</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow2</p>
    <p>Password CheckerPassword Checker</p>
    <p>PWC: if p = g then a := 1 else a := 0</p>
    <p>Some programs require leakage of information</p>
    <p>p: stored password g: guessed password a: authentication flag</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow3</p>
    <p>Password CheckerPassword Checker</p>
    <p>PWC: if p = g then a := 1 else a := 0 a depends on p:</p>
    <p>Noninterference is too strong</p>
    <p>But intuitively secure because PWC leaks little information about p</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow4</p>
    <p>Quantitative Information FlowQuantitative Information Flow</p>
    <p>Quantitative security policies:</p>
    <p>Expected rate of flow is at most k bits per second</p>
    <p>At most k bits leak in any execution</p>
    <p>Enforcing these requires a model for quantitative information flow (QIF)</p>
    <p>This work: A model for QIF</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow5</p>
    <p>Traditional Model for QIFTraditional Model for QIF</p>
    <p>Flow = Uncertainty(Hin)  Uncertainty(Hin | Lout)</p>
    <p>Uncertainty measured with some variant of entropy [Denning 82; McIver and Morgan 03; Clark, Hunt, and Malacaria 05]</p>
    <p>S Hin</p>
    <p>Lin</p>
    <p>Hout</p>
    <p>Lout</p>
    <p>probability distributions</p>
    <p>Information flows when uncertainty is decreased</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow6</p>
    <p>Adding Beliefs to ModelAdding Beliefs to Model</p>
    <p>Model attackers uncertainty about H inputs as a probability distribution</p>
    <p>We call this distribution a belief</p>
    <p>S Hin</p>
    <p>Lin</p>
    <p>Hout</p>
    <p>Lout</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow7</p>
    <p>Analyzing PWCAnalyzing PWC</p>
    <p>PWC: if p = g then a := 1 else a := 0</p>
    <p>Attacker guesses A:</p>
    <p>g = A</p>
    <p>Attacker believes:</p>
    <p>p = A 0.98 B 0.01 C 0.01</p>
    <p>After observing a = 0, attacker believes:</p>
    <p>p = A 0 B 0.5 C 0.5</p>
    <p>(Password is really C)</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow8</p>
    <p>Analyzing PWCAnalyzing PWC</p>
    <p>p = A 0.98 B 0.01 C 0.01</p>
    <p>p = A 0 B 0.5 C 0.5 more uncertaintya little uncertainty</p>
    <p>Prebelief Postbelief</p>
    <p>Information flows when uncertainty is decreased Traditional metric:</p>
    <p>Uncertainty = closeness to uniform distribution</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow9</p>
    <p>Why Uncertainty FailsWhy Uncertainty Fails</p>
    <p>Uncertainty-based approach addresses objective probabilities on</p>
    <p>system but not subjective probabilities of attacker</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow1 0</p>
    <p>Metric for BeliefMetric for Belief</p>
    <p>p = A 0.98 B 0.01 C 0.01</p>
    <p>prebelief</p>
    <p>p = A 0 B 0.5 C 0.5</p>
    <p>postbelief</p>
    <p>p = A 0 B 0 C 1</p>
    <p>reality</p>
    <p>d1 &gt; d2: postbelief closer to reality because of observation of program</p>
    <p>d1 d2</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow1 1</p>
    <p>AccuracyAccuracy</p>
    <p>Accuracy: Distance from a belief to reality</p>
    <p>Certainty</p>
    <p>Accuracy</p>
    <p>Accuracy is the correct metric for QIF</p>
    <p>p = A 0 B 0.5 C 0.5</p>
    <p>postbelief</p>
    <p>p = A 0.98 B 0.01 C 0.01</p>
    <p>prebelief</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow1 2</p>
    <p>Belief in Information FlowBelief in Information Flow</p>
    <p>Experiment protocol Describes how attackers revise beliefs from observation of program execution</p>
    <p>Accuracy metric How change in accuracy of belief can be used to measure the amount of information flow</p>
    <p>Extensions Repeated experiments, other metrics, and misinformation</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow1 3</p>
    <p>ExperimentsExperiments</p>
    <p>p = A 0.98 B 0.01 C 0.01</p>
    <p>p = A 0 B 0.5 C 0.5</p>
    <p>Prebelief Postbelief</p>
    <p>Experiment: How an attacker revises his belief</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow1 4</p>
    <p>Experiment ProtocolExperiment Protocol</p>
    <p>S Hin</p>
    <p>Lin</p>
    <p>Hout</p>
    <p>Lout</p>
    <p>preB postB</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow1 5</p>
    <p>Experiment ProtocolExperiment Protocol</p>
    <p>S Hin</p>
    <p>Lin</p>
    <p>Hout</p>
    <p>Lout</p>
    <p>preB postB</p>
    <p>preB</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow1 6</p>
    <p>Experiment ProtocolExperiment Protocol</p>
    <p>S Hin</p>
    <p>Lin</p>
    <p>Hout</p>
    <p>Lout</p>
    <p>preB postB</p>
    <p>preB</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow1 7</p>
    <p>Experiment ProtocolExperiment Protocol</p>
    <p>Execution modeled as a distribution transformer semantics:</p>
    <p>S : Dist ! Dist</p>
    <p>S Hin</p>
    <p>Lin</p>
    <p>Hout</p>
    <p>Lout</p>
    <p>preB postB</p>
    <p>preB</p>
    <p>observation</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow1 8</p>
    <p>Experiment ProtocolExperiment Protocol</p>
    <p>preB postB</p>
    <p>preB</p>
    <p>SLin Hin</p>
    <p>Lin</p>
    <p>Hout</p>
    <p>Lout observation</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow1 9</p>
    <p>Hin</p>
    <p>Experiment ProtocolExperiment Protocol</p>
    <p>SLin Hout</p>
    <p>Lout</p>
    <p>predictio n</p>
    <p>HinpreB</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow2 0</p>
    <p>Experiment ProtocolExperiment Protocol</p>
    <p>preB postB</p>
    <p>preB</p>
    <p>S observation</p>
    <p>Hin</p>
    <p>Lin</p>
    <p>S preB</p>
    <p>Lin</p>
    <p>predicti on</p>
    <p>postB prediction= | observation</p>
    <p>Bayesian inference</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow2 1</p>
    <p>Belief Revision in PWCBelief Revision in PWC</p>
    <p>postB = prediction | observation</p>
    <p>p,a = A,0 0 A,1 0.98 B,0 0.01 B,1 0 C,0 0.01 C,1 0</p>
    <p>a = 0|=</p>
    <p>p = A 0 B 0.5 C 0.5</p>
    <p>p = A 0.98 B 0.01 C 0.01</p>
    <p>preB =</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow2 2</p>
    <p>Accuracy MetricAccuracy Metric</p>
    <p>Amount of flow Q is improvement in accuracy of belief i.e. (initial error)  (final error)</p>
    <p>Q = D(preB ! Hin)  D(postB ! Hin)</p>
    <p>pre B</p>
    <p>postB Hin</p>
    <p>D(preB ! Hin) D(postB ! Hin)</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow2 3</p>
    <p>Belief DistanceBelief Distance</p>
    <p>Unit is (information theoretic) bits</p>
    <p>Relative entropy:</p>
    <p>When D is defined as relative entropy, Q is the amount of information that the</p>
    <p>attackers observation contains about the high input.</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow2 4</p>
    <p>Amount of Flow from PWCAmount of Flow from PWC</p>
    <p>Q = D(.98, .01, .01 ! 0, 0, 1)  D(0, .5, .5 ! 0, 0, 1)</p>
    <p>= 5.6 bits</p>
    <p>Information is in the eye of the beholder</p>
    <p>Max leakage of lg 3 bits implies uniform prebelief:</p>
    <p>p = A,B,C 1/3 each</p>
    <p>0, 0, 11/3, 1/3, 1/3</p>
    <p>.98, .01, .01</p>
    <p>0, .5, .5</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow2 5</p>
    <p>Repeated ExperimentsRepeated Experiments</p>
    <p>Experiment protocol is compositional</p>
    <p>B Exp B Exp B</p>
    <p>Information flow is also compositional</p>
    <p>The amount of information flow over a series of experiments is equal to the sum of</p>
    <p>the amount of information flow in each individual experiment.</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow2 6</p>
    <p>Extensions of MetricExtensions of Metric</p>
    <p>So far: exact flow for a single execution</p>
    <p>Extend to: {Expected, maximum}</p>
    <p>amount of information flow {for a given experiment, over all</p>
    <p>experiments}</p>
    <p>Language for quantitative flow policies</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow2 7</p>
    <p>Non-probabilistic programs cannot create misinformation.</p>
    <p>MisinformationMisinformation</p>
    <p>Certainty</p>
    <p>Accuracy</p>
    <p>?</p>
    <p>FPWC: if p = g then a := 1 else a := 0; if random() &lt; .1 then a := !a</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow2 8</p>
    <p>SummarySummary</p>
    <p>Attackers have beliefs</p>
    <p>Quantifying information flow with beliefs requires accuracy  Traditional uncertainty model is inappropriate</p>
    <p>Presented more expressive, fine-grained model of quantitative information flow  Compositional experiment protocol  Probabilistic language semantics  Accuracy-based metric</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow2 9</p>
    <p>Related WorkRelated Work</p>
    <p>Information theory in information flow  [Denning 82], [Millen 87], [Wittbold, Johnson</p>
    <p>Quantitative information flow  Using uncertainty: [Lowe 02], [McIver, Morgan</p>
    <p>Wiklicky 00 - 05]</p>
    <p>Database privacy  Using relative entropy: [Evfimievski, Gehrke,</p>
    <p>Srikant 03]</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow3 0</p>
    <p>Future WorkFuture Work</p>
    <p>Extended programming language  Lattice of security levels  Static analysis  Quantitative security policies</p>
  </div>
  <div class="page">
    <p>Belief in Information FlowBelief in Information Flow</p>
    <p>Michael Clarkson, Andrew Myers, Fred B. Schneider</p>
    <p>Cornell University</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow3 2</p>
    <p>Extra SlidesExtra Slides</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow3 3</p>
    <p>Beliefs as DistributionsBeliefs as Distributions</p>
    <p>Other choices: Dempster-Shafer belief functions, plausibility measures, etc.</p>
    <p>Probability distributions are:  Quantitative  Axiomatically justifiable  Straightforward  Familiar</p>
    <p>Abstract operations  Product: combine disjoint beliefs  Update: condition belief to include new</p>
    <p>information  Distance: quantification of difference between</p>
    <p>two beliefs</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow3 4</p>
    <p>Program SemanticsProgram Semantics</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow3 5</p>
    <p>Postbeliefs are BayesianPostbeliefs are Bayesian</p>
    <p>Standard techniques for inference in applied statistics  Bayesian inference  Sampling/frequentist theory</p>
    <p>Bayesian inference:  Formalization of scientific method  Consistent with principles of rationality</p>
    <p>in a betting game  May be subjective but is not arbitrary</p>
  </div>
  <div class="page">
    <p>Clarkson et al.: Belief in Information Flow3 6</p>
    <p>Interpreting Flow QuantitiesInterpreting Flow Quantities</p>
    <p>Uncertainty (entropy) interpreted as:  Improvement of expected codeword</p>
    <p>length</p>
    <p>Accuracy (relative entropy) interpreted as:  Improvement in efficiency of optimal</p>
    <p>code</p>
  </div>
</Presentation>
