<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Virtualized Infrastructures, Systems, &amp; Applications</p>
    <p>Wenji Li, Ming Zhao</p>
    <p>Arizona State University</p>
    <p>Gregory Jean-Baptiste, Juan Riveros, Giri Narasimhan</p>
    <p>Florida International University</p>
    <p>Tong Zhang</p>
    <p>Rensselaer Polytechnic Institute</p>
  </div>
  <div class="page">
    <p>Flash Caching Background</p>
    <p>Benefits o Exploit the high performance of flash storage o Avoid the long latency from primary storage</p>
    <p>Challenges o Limited capacity w.r.t. dataset sizes o Limited endurance (limited P/E cycles)</p>
    <p>Caching makes it worse!</p>
    <p>Also applicable to other NVM caches</p>
    <p>VMM VMs</p>
    <p>HOST</p>
    <p>STORAGE</p>
    <p>$</p>
    <p>$</p>
    <p>$</p>
    <p>iSCSI, NBD,  $</p>
  </div>
  <div class="page">
    <p>Cache Deduplication</p>
    <p>Potential solution for flash capacity and endurance issues o Reduce data footprint by eliminating duplicate copies of data o Reduce writes to flash by eliminating unnecessary cache insertions/updates</p>
    <p>But simply stacking deduplication with caching is inefficient</p>
    <p>Cache management</p>
    <p>Dedup management</p>
    <p>Cache device</p>
    <p>Primary storage</p>
    <p>Dedup management</p>
    <p>Cache managementPrimary storage</p>
    <p>Cannot exploit space reduction by deduplication</p>
    <p>Redundant metadata</p>
    <p>Deduplication has to manage for the whole primary storage</p>
    <p>Read/Write Read/Write</p>
    <p>Cache device</p>
  </div>
  <div class="page">
    <p>Overview of CacheDedup</p>
    <p>Integrated cache and deduplication management o Efficient metadata and data management o Support sophisticated cache replacement</p>
    <p>algorithms</p>
    <p>Duplication-aware cache replacement o Improve cache performance and endurance</p>
    <p>by utilizing duplication information</p>
    <p>Integrated cache and deduplication</p>
    <p>Primary storage</p>
    <p>Read/Write</p>
    <p>Cache device</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Background</p>
    <p>Integrated Cache and Deduplication</p>
    <p>Duplication-aware Cache Replacement</p>
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>Architecture</p>
    <p>Separated Metadata Cache and Data Cache o Consider metadata management as a cache replacement problem</p>
    <p>(Deduplication) Metadata Cache o Source Address Index: map an address of primary storage to a fingerprint o Fingerprint Store: map a fingerprint to a data block in the Data Cache</p>
    <p>Data Cache o Cache blocks stored on the flash cache device</p>
    <p>Primary storage</p>
    <p>Read/Write</p>
    <p>source address X</p>
    <p>Traditional Cache</p>
    <p>Cache BlocksSource Address Index</p>
    <p>Metadata Datacache address Y</p>
    <p>CacheDedup</p>
    <p>Cache BlocksSource Address Index</p>
    <p>Fingerprint Store</p>
    <p>Metadata Cache Data Cache</p>
    <p>cache address Yfingerprint F</p>
  </div>
  <div class="page">
    <p>Metadata Cache</p>
    <p>Operations</p>
    <p>Fingerprint Store</p>
    <p>Fingerprint A</p>
    <p>Fingerprint B</p>
    <p>Data Cache</p>
    <p>Cache Block A</p>
    <p>Cache Block B</p>
    <p>Source Address Index</p>
    <p>Address 1</p>
    <p>Address 2</p>
    <p>Address 3</p>
    <p>Address 4</p>
    <p>Primary storage</p>
    <p>Read address 4</p>
    <p>Metadata Cache and Data Cache replacement are managed by the duplication-aware algorithms</p>
    <p>Data Block C</p>
    <p>Read address 1</p>
    <p>Address 1</p>
    <p>Fingerprint AFingerprint A Cache Block A</p>
    <p>Fingerprint B = C</p>
  </div>
  <div class="page">
    <p>Duplication-aware Cache Replacement Algorithms</p>
    <p>D-LRU (pronounced dollar-u) o A duplication-aware variant of LRU algorithm o Simple and efficient</p>
    <p>D-ARC (pronounced dark) o A duplication-aware variant of ARC algorithm o Adaptive and scan-resistant</p>
    <p>Metadata Cache Data Cache</p>
    <p>CacheDedup</p>
    <p>cache blocksSource Address Index</p>
    <p>Fingerprint Store</p>
  </div>
  <div class="page">
    <p>D-LRU</p>
    <p>Apply LRU on both Metadata Cache and Data Cache</p>
    <p>Metadata Cache</p>
    <p>Fingerprint Store</p>
    <p>Fingerprint A</p>
    <p>Fingerprint C</p>
    <p>Data Cache Cache Block A</p>
    <p>Cache Block C</p>
    <p>Source Address Index</p>
    <p>Address 1</p>
    <p>Address 2</p>
    <p>Address 3</p>
    <p>Address nMRU</p>
    <p>LRU LRU</p>
    <p>MRU</p>
    <p>Evict Evict</p>
    <p>Cache Block BFingerprint B</p>
  </div>
  <div class="page">
    <p>D-LRU</p>
    <p>Simple and efficient o Easy to implement</p>
    <p>Metadata and Data Caches managed separately using LRU</p>
    <p>o No wastage  Orphaned metadata and orphaned data will not exist simultaneously</p>
    <p>But not scan-resistant o Scan sequence: request with low temporal locality o Waste space and cause unnecessary wear-out</p>
  </div>
  <div class="page">
    <p>Metadata</p>
    <p>Review: ARC</p>
    <p>Store recently accessed and frequently accessed items separately</p>
    <p>Use two ghost LRU lists to store historical source addresses</p>
    <p>Adaptive and scan-resistant</p>
    <p>T2</p>
    <p>B1</p>
    <p>B2</p>
    <p>Up to C items</p>
    <p>T1 Evict</p>
    <p>Evict</p>
    <p>Recently accessed items</p>
    <p>Frequently accessed items</p>
    <p>C number of cache blocks</p>
    <p>Data Cache</p>
    <p>Cache Block A</p>
    <p>Cache Block B</p>
  </div>
  <div class="page">
    <p>D-ARC</p>
    <p>Metadata cache (managed using modified ARC) o Increase T1+T2 to C+X for storing additional source addresses o Introduce an extra ghost list B3 to store additional historical source addresses</p>
    <p>Data cache o Evict only the block with no mappings in T1 and T2</p>
    <p>Metadata Cache</p>
    <p>Fingerprint Store</p>
    <p>Data Cache Cache Block A</p>
    <p>Cache Block B</p>
    <p>Source address index managed by modified ARC</p>
    <p>Source Address Index</p>
    <p>T1</p>
    <p>T2</p>
    <p>B1</p>
    <p>B2</p>
    <p>B3</p>
    <p>Up to C + X items Up to C items</p>
    <p>Evict</p>
    <p>Evict</p>
    <p>Evict</p>
    <p>Evict</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Background</p>
    <p>Integrated Cache and Deduplication</p>
    <p>Duplication-aware Cache Replacement</p>
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Block-device virtualization</p>
    <p>Testbed o Two 6-core 2.4GHz Operon CPUs, 24GB</p>
    <p>of RAM, Linux 3.2.20 o Server storage: 1TB 7.2K RPM SAS disk o Client flash storage 120GB MLC SATA SSD</p>
    <p>FIU traces: WebVM, Homes, Mail departmental servers</p>
    <p>Fio benchmark</p>
    <p>Name Total I/Os (GB)</p>
    <p>Working Set(GB)</p>
    <p>Write-toread ratio</p>
    <p>Unique Data (GB)</p>
    <p>WebVM 54.5 2.1 3.6 23.4</p>
    <p>Homes 67.3 5.9 31.5 44.4</p>
    <p>Mail 1741 57.1 8.1 171.3</p>
    <p>iSCSI</p>
    <p>App1</p>
    <p>Appn</p>
    <p>HOST/dev/mapper/cache#</p>
    <p>/dev/sdc</p>
    <p>flash cache</p>
    <p>storage</p>
    <p>CacheDedup</p>
  </div>
  <div class="page">
    <p>Miss Ratio</p>
    <p>R ea</p>
    <p>d M</p>
    <p>is s</p>
    <p>R at</p>
    <p>io (%</p>
    <p>)</p>
    <p>Cache size (Percentage of WSS)</p>
    <p>LRU D-LRU</p>
    <p>ARC D-ARC</p>
    <p>W rit</p>
    <p>e M</p>
    <p>is s</p>
    <p>R at</p>
    <p>io (%</p>
    <p>)</p>
    <p>Cache size (Percentage of WSS)</p>
    <p>LRU D-LRU</p>
    <p>ARC D-ARC</p>
    <p>To ta</p>
    <p>l M is</p>
    <p>s R</p>
    <p>at io</p>
    <p>(% )</p>
    <p>Cache size (Percentage of WSS)</p>
    <p>LRU D-LRU</p>
    <p>ARC D-ARC</p>
    <p>Miss ratio from WebVM</p>
    <p>D-LRU/D-ARC reduce total miss ratio by up to 20%</p>
  </div>
  <div class="page">
    <p>Writes to Flash Ratio</p>
    <p>W rit</p>
    <p>e to</p>
    <p>F la</p>
    <p>sh R</p>
    <p>at io</p>
    <p>(% )</p>
    <p>Cache size (Percentage of WSS)</p>
    <p>LRU D-LRU</p>
    <p>ARC D-ARC</p>
    <p>W rit</p>
    <p>e to</p>
    <p>F la</p>
    <p>sh R</p>
    <p>at io</p>
    <p>(% )</p>
    <p>Cache size (Percentage of WSS)</p>
    <p>LRU D-LRU</p>
    <p>ARC D-ARC</p>
    <p>W rit</p>
    <p>e to</p>
    <p>F la</p>
    <p>sh R</p>
    <p>at io</p>
    <p>(% )</p>
    <p>Cache size (Percentage of WSS)</p>
    <p>LRU D-LRU</p>
    <p>ARC D-ARC</p>
    <p>WebVMHomesMail</p>
    <p>Percentage of writes sent to the flash device vs. total # of requests o Indirect measure of wear-out</p>
    <p>D-LRU/D-ARC reduce writes to flash by up to 89%</p>
  </div>
  <div class="page">
    <p>Traces Replay I/O Latency</p>
    <p>D-LRU and D-ARC reduce the latency by up to 48% and 51%</p>
    <p>I/O latency from WebVM, Homes and Mail with 40% WSS cache size</p>
    <p>WebVM Homes Mail</p>
    <p>Ti m</p>
    <p>e (u</p>
    <p>s)</p>
    <p>LRU D-LRU</p>
    <p>ARC D-ARC</p>
  </div>
  <div class="page">
    <p>Overhead</p>
    <p>Fingerprinting adds a 10-20s latency</p>
    <p>Concurrent I/Os fingerprinting operations can be overlapped</p>
    <p>Insignificant fingerprinting overhead in overall throughput</p>
    <p>FIO random reads and writes throughput with 8 concurrent threads</p>
    <p>Read (Cold)</p>
    <p>Read (Warm)</p>
    <p>Th ro</p>
    <p>ug hp</p>
    <p>ut (M</p>
    <p>B /s</p>
    <p>)</p>
    <p>LRU D-LRU D-ARC</p>
    <p>Write (Cold)</p>
    <p>Write (Warm)</p>
    <p>Th ro</p>
    <p>ug hp</p>
    <p>ut (M</p>
    <p>B /s</p>
    <p>)</p>
    <p>LRU D-LRU D-ARC</p>
  </div>
  <div class="page">
    <p>CD-ARC vs Nitro</p>
    <p>Nitro: use both compression and deduplication for caching</p>
    <p>CD-ARC: compression-aware and duplication-aware cache replacement</p>
    <p>CD-ARC reduces the read miss ratio by up to 12.56%</p>
    <p>Read miss ratio in compression ratio 2 and 4 when cache size is 5% and 10% WebVM WSS</p>
    <p>R ea</p>
    <p>d M</p>
    <p>is s</p>
    <p>R at</p>
    <p>io (%</p>
    <p>)</p>
    <p>CD-ARC Compress 2 Nitro Compress 2</p>
    <p>CD-ARC Compress 4 Nitro Compress 4</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>Flash caching o Frameworks: Mercury, ioCache, vSphere cache, dm-cace o Enhancements: consistency [FAST13], reliability [Systor14], cache</p>
    <p>allocation (vCacheShare, CloudCache)</p>
    <p>o Complementary to CacheDedup</p>
    <p>Flash Deduplication o CA-FTL, [FAST11], [MSST12] o CacheDedup optimizes deduplication for caching</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Integrated cache and deduplication architecture is key to efficient management</p>
    <p>Duplication-aware cache replacement exploits duplication information to improve performance and endurance</p>
    <p>Our results show up to 20% reduction in miss ratio, 51% in latency, and 89% in writes to cache</p>
  </div>
  <div class="page">
    <p>Acknowledgements</p>
    <p>Co-authors o Gregory Jean-Baptiste: design of D-ARC,  o Juan Riveros, Giri Narasimhan: algorithm analysis,  o Tong Zhang: flash device endurance,</p>
    <p>VISA colleagues o Dulcardo Arteaga: dm-cache framework,  o Saman Biookaghazadeh : trace collection,</p>
    <p>Sponsors o NSF CAREER award CNS-125394 o DOD award W911NF-13-1-0157</p>
  </div>
</Presentation>
