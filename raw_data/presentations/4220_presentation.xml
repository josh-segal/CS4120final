<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Structural Neural Encoders for AMR-to-text Generation NAACL 2019</p>
    <p>Marco Damonte, Shay Cohen</p>
    <p>School of Informatics, University of Edinburgh, UK</p>
  </div>
  <div class="page">
    <p>Abstract Meaning Representation (AMR)</p>
    <p>eat-01</p>
    <p>he pizza finger :ARG0 :ARG1 :instrument</p>
    <p>:part-of</p>
    <p>He ate the pizza with his fingers.</p>
  </div>
  <div class="page">
    <p>AMR-to-text generation (English)</p>
    <p>eat-01</p>
    <p>he pizza finger :ARG0 :ARG1 :instrument</p>
    <p>:part-of</p>
    <p>He ate the pizza with his fingers.</p>
  </div>
  <div class="page">
    <p>AMR-to-text generation (English)</p>
    <p>eat-01</p>
    <p>he pizza finger :ARG0 :ARG1 :instrument</p>
    <p>:part-of</p>
    <p>He ate the pizza with his fingers.</p>
  </div>
  <div class="page">
    <p>Previous work</p>
    <p>eat-01</p>
    <p>he pizza finger</p>
    <p>:ARG0 :ARG1 :instrument</p>
    <p>:part-of</p>
    <p>Konstas et al. (2017): sequential encoder;</p>
    <p>Song et al. (2018), Beck et al. (2018): graph encoder;</p>
  </div>
  <div class="page">
    <p>This work</p>
    <p>He ate the pizza with his fingers.</p>
    <p>eat-01</p>
    <p>he pizza finger</p>
    <p>:ARG0 :ARG1 :instrument</p>
    <p>:part-of</p>
    <p>Are improvements in graph encoders due to reentrancies?</p>
    <p>To answer, compare:</p>
  </div>
  <div class="page">
    <p>Sequential input (Konstas et al., 2017)</p>
    <p>eat-01</p>
    <p>he pizza finger</p>
    <p>:ARG0 :ARG1 :instrument</p>
    <p>:part-of</p>
    <p>eat-01 :arg0 he :arg1 pizza :instrument finger :part-of he</p>
  </div>
  <div class="page">
    <p>Sequential input (Konstas et al., 2017)</p>
    <p>eat-01 :arg0 he :arg1 pizza :instr. finger part-of he</p>
    <p>BiLSTM</p>
  </div>
  <div class="page">
    <p>Sequential input (Konstas et al., 2017)</p>
    <p>eat-01</p>
    <p>he pizza finger :ARG0 :ARG1 :instrument</p>
    <p>:part-of</p>
    <p>eat-01 :arg0 he :arg1 pizza :instrument finger :part-of he</p>
  </div>
  <div class="page">
    <p>Tree-structured input</p>
    <p>eat-01</p>
    <p>he pizza finger :ARG0 :ARG1 :instrument</p>
    <p>:part-of</p>
    <p>eat-01 :arg0 he :arg1 pizza :instrument finger :part-of he</p>
  </div>
  <div class="page">
    <p>Tree-structured input</p>
    <p>BiLSTM</p>
    <p>TreeLSTM</p>
    <p>eat-01 :arg0 he :arg1 pizza :instr. finger part-of he</p>
    <p>eat-01 :arg0 he :arg1 pizza :instrument finger :part-of he</p>
  </div>
  <div class="page">
    <p>Tree-structured input</p>
    <p>BiLSTM</p>
    <p>GCN</p>
    <p>eat-01 :arg0 he :arg1 pizza :instr. finger part-of he</p>
    <p>eat-01 :arg0 he :arg1 pizza :instrument finger :part-of he</p>
  </div>
  <div class="page">
    <p>Tree-structured input</p>
    <p>eat-01</p>
    <p>he pizza finger</p>
    <p>:ARG0 :ARG1 :instrument</p>
    <p>:part-of</p>
    <p>eat-01 :arg0 he :arg1 pizza :instrument finger :part-of he</p>
  </div>
  <div class="page">
    <p>Graph-structured input</p>
    <p>eat-01</p>
    <p>he pizza finger</p>
    <p>:ARG0 :ARG1 :instrument</p>
    <p>:part-of</p>
    <p>eat-01 :arg0 he :arg1 pizza :instrument finger :part-of he</p>
  </div>
  <div class="page">
    <p>Graph-structured input</p>
    <p>BiLSTM</p>
    <p>GCN</p>
    <p>eat-01 :arg0 he :arg1 pizza :instr. finger part-of he</p>
    <p>eat-01 :arg0 he :arg1 pizza :instrument finger :part-of he</p>
  </div>
  <div class="page">
    <p>Data</p>
    <p>AMR R2: 39260 sentences</p>
    <p>AMR R1: 19572 sentences (subset of R1)</p>
  </div>
  <div class="page">
    <p>Comparison between models (dev set R1)</p>
    <p>Seq TreeLSTM GCN-Tree GCN-Graph 10</p>
    <p>B LE</p>
    <p>U</p>
  </div>
  <div class="page">
    <p>Comparison with previous work (test set R1)</p>
    <p>Konstas(seq) Song(graph) GCN-Tree GCN-Graph 10</p>
    <p>U</p>
    <p>Konstas: sequential baseline, Konstas et al. (2017) Song: graph encoder (GRN), Song et al. (2018)</p>
  </div>
  <div class="page">
    <p>Comparison with previous work (test set R2)</p>
    <p>Beck(graph) GCN-Tree GCN-Graph 10</p>
    <p>B LE</p>
    <p>U</p>
    <p>Beck: graph encoder (GGNN), Beck et al. (2018) 19 / 23</p>
  </div>
  <div class="page">
    <p>Reentrancies He ate the pizza with his fingers.</p>
    <p>eat-01 :arg0 he :arg1 pizza :instrument finger :part-of he</p>
    <p>Model Number of reentrancies 0 1-5 6-20</p>
    <p>(619) (679) (70) Seq 42.94 31.64 23.33 Tree +0.63 +1.41 +0.76 Graph +1.67 +1.54 +3.08</p>
  </div>
  <div class="page">
    <p>Long-range dependencies</p>
    <p>He ate the pizza with a fork.</p>
    <p>eat-01 :arg0 he :arg1 pizza :instrument fork</p>
    <p>Model Max dependency length 0-10 11-50 51-200 (307) (297) (18)</p>
    <p>Seq 50.49 36.28 24.14 Tree -0.48 +1.66 +2.37 Graph +1.22 +2.05 +3.04</p>
  </div>
  <div class="page">
    <p>Generation example tell-01</p>
    <p>youneed-01 person</p>
    <p>go-06</p>
    <p>communicate-01</p>
    <p>all</p>
    <p>lawyer</p>
    <p>have-rel-role-91</p>
    <p>significant-other ex</p>
    <p>:ARG1 :ARG0 :ARG2</p>
    <p>:ARG1</p>
    <p>:ARG0</p>
    <p>:mod</p>
    <p>:path</p>
    <p>:ARG0-of:ARG1</p>
    <p>:ARG2 :time</p>
    <p>REF tell your ex that all communication needs to go through the lawyer</p>
    <p>Seq tell that all the communication go through lawyer</p>
    <p>Tree tell your ex, tell your ex, the need for all the communication</p>
    <p>Graph tell your ex the need to go through a lawyer</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Graph encoders based on GCN and BiLSTM gives best results for AMR-to-text generation;</p>
    <p>Reentrancies and long-range dependencies contribute to the improvements of graph encoders;</p>
    <p>Demo and source code: http://cohort.inf.ed.ac.uk/amrgen.html</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Do reentrancies help with generating pronouns?</p>
    <p>He ate the pizza with his fingers.</p>
    <p>eat-01 :arg0 he :arg1 pizza :instrument finger :part-of he</p>
    <p>Contrastive pair analysis (Sennrich, 2017):  Compute probability of a reference output sentence and the probability of a sentence containing a mistake;</p>
    <p>Compute accuracy of model in assigning a higher probability to the reference sentence.</p>
  </div>
  <div class="page">
    <p>Do reentrancies help with generating pronouns?</p>
    <p>He ate the pizza with his fingers  He ate the pizza with he fingers</p>
    <p>He ate the pizza with his fingers  He ate the pizza with him fingers</p>
    <p>He ate the pizza with his fingers  He ate the pizza with their fingers</p>
    <p>He ate the pizza with his fingers  He ate the pizza with her fingers</p>
    <p>Model Antecedent Type Num. Gender (251) (912) (1840) (95)</p>
    <p>Seq 96.02 97.70 94.89 94.74 Tree 96.02 96.38 93.70 92.63 Graph 96.02 96.49 95.11 95.79</p>
  </div>
  <div class="page">
    <p>Input Model BLEU Meteor Seq Seq 21.40 22.00</p>
    <p>Tree</p>
    <p>SeqTreeLSTM 21.84 22.34 TreeLSTMSeq 22.26 22.87 TreeLSTM 22.07 22.57 SeqGCN 21.84 22.21 GCNSeq 23.62 23.77 GCN 15.83 17.76</p>
    <p>Graph SeqGCN 22.06 22.18 GCNSeq 23.95 24.00 GCN 15.94 17.76</p>
  </div>
  <div class="page">
    <p>More examples</p>
    <p>h (k+1) i =</p>
    <p>(  jN(i)</p>
    <p>W (k) dir(j,i)h</p>
    <p>(k) j + b</p>
    <p>(k)</p>
    <p>) , (1)</p>
  </div>
  <div class="page">
    <p>More examples</p>
    <p>REF i dont tell him but he finds out. Seq i didnt tell him but he was out. Tree i dont tell him but found out. Graph i dont tell him but he found out.</p>
  </div>
  <div class="page">
    <p>More examples</p>
    <p>REF if you tell people they can help you , Seq if you tell him, you can help you ! Tree if you tell person_name you, you can help you . Graph if you tell them, you can help you .</p>
  </div>
  <div class="page">
    <p>More examples</p>
    <p>REF i d recommend you go and see your doctor too. Seq i recommend you go to see your doctor who is</p>
    <p>going to see your doctor. Tree you recommend going to see your doctor too. Graph i recommend you going to see your doctor too.</p>
  </div>
</Presentation>
