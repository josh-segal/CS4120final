<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Representations of language in a model of visually</p>
    <p>grounded speech signal</p>
    <p>Grzegorz Chrupaa Lieke Gelderloos Afra Alishahi</p>
  </div>
  <div class="page">
    <p>Automatic Speech Recognition</p>
    <p>A major commercial success story in Language Technology</p>
  </div>
  <div class="page">
    <p>Very heavy-handed supervision</p>
    <p>I can see you</p>
  </div>
  <div class="page">
    <p>Grounded speech perception</p>
  </div>
  <div class="page">
    <p>Data</p>
    <p>Flickr8K Audio (Harwath &amp; Glass 2015)  8K images, five audio captions each</p>
    <p>MS COCO Synthetic Spoken Captions</p>
    <p>300K images, five synthetically spoken captions each</p>
  </div>
  <div class="page">
    <p>Project speech and image to joint space</p>
    <p>a bird walks on a beam</p>
    <p>bears play in water</p>
  </div>
  <div class="page">
    <p>Image model</p>
    <p>BOAT</p>
    <p>BIRD</p>
    <p>BOAR</p>
    <p>P re</p>
    <p>-cla ssif</p>
    <p>ca t io</p>
    <p>n la</p>
    <p>y e</p>
    <p>r</p>
  </div>
  <div class="page">
    <p>Speech model</p>
    <p>Input: MFCC  Subsampling CNN  Recurrent</p>
    <p>Highway Network (Zilly et al 2016)</p>
    <p>Attention</p>
  </div>
  <div class="page">
    <p>Model settings</p>
  </div>
  <div class="page">
    <p>Image retrieval</p>
    <p>Flickr8K</p>
    <p>MSCOCO</p>
    <p>Newer CNN architecture: Harwath et al 2016 (NIPS), Harwath and Glass 2017 (ACL)</p>
  </div>
  <div class="page">
    <p>Levels of representation</p>
    <p>What aspects of sentences are encoded?</p>
    <p>Which layers encode form, which encode meaning?</p>
    <p>Auxiliary tasks (Adi et al 2017)</p>
  </div>
  <div class="page">
    <p>Form-related aspects</p>
    <p>Use activation vectors to decode  Utterance length in words  Presence of specific words</p>
  </div>
  <div class="page">
    <p>Number of words</p>
    <p>Input  Activations for</p>
    <p>utterance  Model</p>
    <p>Linear regression</p>
  </div>
  <div class="page">
    <p>Word presence</p>
    <p>Input  Activations for</p>
    <p>utterance  MFCC for word</p>
    <p>Model  MLP</p>
  </div>
  <div class="page">
    <p>Semantic aspects</p>
  </div>
  <div class="page">
    <p>Representational Similarity</p>
    <p>Correlations between sets of pairwise similarities according to  Activations</p>
    <p>AND  Edit ops on written</p>
    <p>sentences  Human judgments</p>
    <p>(SICK dataset)</p>
  </div>
  <div class="page">
    <p>Homonym disambiguation</p>
  </div>
  <div class="page">
    <p>Follow-up work</p>
    <p>Afra Alishahi, Marie Barking and Grzegorz Chrupaa. Encoding of phonology in a recurrent neural model of grounded speech</p>
    <p>Friday, session #4 at CoNLL</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Encodings of form and meaning emerge and evolve in hidden layers of stacked RHN listening to grounded speech</p>
    <p>Code: github.com/gchrupala/visually-grounded-speech Data: doi.org/10.5281/zenodo.400926</p>
  </div>
  <div class="page"/>
  <div class="page"/>
  <div class="page">
    <p>Error analysis</p>
    <p>Text usually better  Speech better:</p>
    <p>Long descriptions</p>
    <p>Misspellings</p>
    <p>Text Speech</p>
    <p>a yellow and white birtd is in flight</p>
  </div>
  <div class="page">
    <p>Length</p>
  </div>
  <div class="page">
    <p>Text model</p>
    <p>Convolution word embedding  No attention</p>
  </div>
</Presentation>
