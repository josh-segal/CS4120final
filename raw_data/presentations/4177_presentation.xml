<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Predicting Semantic Relations using Global Graph Properties</p>
    <p>Yuval Pinter and Jacob Eisenstein @yuvalpi @jacobeisenstein</p>
    <p>code: github.com/yuvalpinter/m3gm contact: uvp@gatech.edu</p>
  </div>
  <div class="page">
    <p>Semantic Graphs</p>
    <p>WordNet-like resources are curated to describe relations between word senses</p>
    <p>The graph is directed  Edges have form &lt;S, r, T&gt;: &lt;zebra, is-a, equine&gt;  Still, some relations are symmetric</p>
    <p>Relation types include:  Hypernym (is-a) &lt;zebra, r, equine&gt;  Meronym (is-part-of) &lt;tree, r, forest&gt;  Is-instance-of &lt;rome, r, capital&gt;  Derivational Relatedness &lt;nice, r, nicely&gt;</p>
    <p>mammal</p>
    <p>canineequine</p>
    <p>horse zebra wolf fenec</p>
  </div>
  <div class="page">
    <p>Semantic Graphs - Relation Prediction</p>
    <p>The task of predicting relations (zebra is a &lt;BLANK&gt;)  Local models use embeddings-based composition for</p>
    <p>scoring edges</p>
    <p>equinezebra hypernym</p>
  </div>
  <div class="page">
    <p>s = - (|| + - ||)</p>
    <p>Semantic Graphs - Relation Prediction</p>
    <p>The task of predicting relations (zebra is a &lt;BLANK&gt;)  Local models use embeddings-based composition for</p>
    <p>scoring edges</p>
    <p>equinezebra hypernym</p>
    <p>Translational Embeddings (transE) [Bordes et al. 2013]</p>
  </div>
  <div class="page">
    <p>s = * *</p>
    <p>Semantic Graphs - Relation Prediction</p>
    <p>The task of predicting relations (zebra is a &lt;BLANK&gt;)  Local models use embeddings-based composition for</p>
    <p>scoring edges</p>
    <p>equinezebra hypernym</p>
    <p>Full-Bilinear (Bilin) [Nickel et al. 2011]</p>
  </div>
  <div class="page">
    <p>Semantic Graphs - Relation Prediction</p>
    <p>The task of predicting relations (zebra is a &lt;BLANK&gt;)  Local models use embeddings-based composition for</p>
    <p>scoring edges  Problem: task-driven method can learn unreasonable</p>
    <p>graphs</p>
    <p>mammal</p>
    <p>equine</p>
    <p>horse zebra</p>
    <p>canine equine</p>
    <p>zebra</p>
  </div>
  <div class="page">
    <p>Incorporating a Global View</p>
    <p>We want to avoid unreasonable graphs  Imposing hard constraints isnt flexible enough</p>
    <p>Only takes care of impossible graphs  Requires domain knowledge</p>
    <p>We still want the local signal to matter - its very strong.</p>
  </div>
  <div class="page">
    <p>Incorporating a Global View</p>
    <p>We want to avoid unreasonable graphs  Imposing hard constraints isnt flexible enough</p>
    <p>Only takes care of impossible graphs  Requires domain knowledge</p>
    <p>We still want the local signal to matter - its very strong.  Our solution: an additive, learnable global graph score</p>
    <p>Score(&lt;zebra, hypernym, equine&gt;| WordNet) =</p>
    <p>slocal(edge) + (sglobal(WN + edge), sglobal(WN)) 9</p>
  </div>
  <div class="page">
    <p>Global Graph Score</p>
    <p>Based on a framework called Exponential Random Graph Model (ERGM)  The score sglobal(WN) is derived from a log-linear distribution across possible</p>
    <p>graphs that have a fixed number n of nodes</p>
    <p>pERGM(WN)  exp(T  (WN))</p>
    <p>Weights vector</p>
    <p>Graph features</p>
  </div>
  <div class="page">
    <p>Global Graph Score</p>
    <p>Based on a framework called Exponential Random Graph Model (ERGM)  The score sglobal(WN) is derived from a log-linear distribution across possible</p>
    <p>graphs that have a fixed number n of nodes</p>
    <p>OK. What are the features?</p>
    <p>pERGM(WN)  exp(T  (WN))</p>
    <p>Weights vector</p>
    <p>Graph features</p>
  </div>
  <div class="page">
    <p>Graph Features (Motifs)</p>
    <p>#edges: 6  #targets: 4  #3-cycles: 0  #2-paths: 4  Transitivity:  = 0.25</p>
  </div>
  <div class="page">
    <p>Graph Features (Motifs)</p>
    <p>#edges: 6  #targets: 4  #3-cycles: 0  #2-paths: 4  Transitivity:  = 0.25</p>
  </div>
  <div class="page">
    <p>Graph Features (Motifs)</p>
    <p>#edges: 6  #targets: 4  #3-cycles: 0  #2-paths: 4  Transitivity:  = 0.25</p>
  </div>
  <div class="page">
    <p>Graph Features (Motifs)</p>
    <p>#edges: 6  #targets: 4  #3-cycles: 0  #2-paths: 4  Transitivity:  = 0.25</p>
  </div>
  <div class="page">
    <p>Graph Features (Motifs)</p>
    <p>#edges: 6  #targets: 4  #3-cycles: 0  #2-paths: 4  Transitivity:  = 0.25</p>
  </div>
  <div class="page">
    <p>Graph Motifs (multiple relations)</p>
    <p>#edges: 6  #targets: 4  #3-cycles: 0  #2-paths: 4  Transitivity:  = 0.25</p>
    <p>(some) joint blue/orange motifs:</p>
    <p>#edges {b, o}: 9  #2-cycles {b, o}: 1  #3-cycles (b-o-o): 1  #3-cycles (b-b-o): 0</p>
    <p>#2-paths (b-b): 4  #2-paths (b-o): 3  #2-paths (o-b): 4  Transitivity (b-o-b):  = 0.67</p>
  </div>
  <div class="page">
    <p>Graph Motifs (multiple relations)</p>
    <p>#edges: 6  #targets: 4  #3-cycles: 0  #2-paths: 4  Transitivity:  = 0.25</p>
    <p>(some) joint blue/orange motifs:</p>
    <p>#edges {b, o}: 9  #2-cycles {b, o}: 1  #3-cycles (b-o-o): 1  #3-cycles (b-b-o): 0</p>
    <p>#2-paths (b-b): 4  #2-paths (b-o): 3  #2-paths (o-b): 4  Transitivity (b-o-b):  = 0.67</p>
  </div>
  <div class="page">
    <p>Graph Motifs (multiple relations)</p>
    <p>#edges: 6  #targets: 4  #3-cycles: 0  #2-paths: 4  Transitivity:  = 0.25</p>
    <p>(some) joint blue/orange motifs:</p>
    <p>#edges {b, o}: 9  #2-cycles {b, o}: 1  #3-cycles (b-o-o): 1  #3-cycles (b-b-o): 0</p>
  </div>
  <div class="page">
    <p>Graph Motifs (multiple relations)</p>
    <p>#edges: 6  #targets: 4  #3-cycles: 0  #2-paths: 4  Transitivity:  = 0.25</p>
    <p>(some) joint blue/orange motifs:</p>
    <p>#edges {b, o}: 9  #2-cycles {b, o}: 1  #3-cycles (b-o-o): 1  #3-cycles (b-b-o): 0</p>
    <p>#2-paths (b-b): 4  #2-paths (b-o): 3  #2-paths (o-b): 4  Transitivity (b-o-b):  = 0.67</p>
  </div>
  <div class="page">
    <p>ERGM Training</p>
    <p>Estimating the scores for all possible graphs to obtain a probability distribution is implausible  Number of possible directed graphs with n nodes: O(exp(n2))  n nodes, R relations: O(exp(R*n2))  Estimation begins to be hard at ~n=100 for R=1. In WordNet: n = 40K, R = 11.</p>
  </div>
  <div class="page">
    <p>ERGM Training</p>
    <p>Estimating the scores for all possible graphs to obtain a probability distribution is implausible  Number of possible directed graphs with n nodes: O(exp(n2))  n nodes, R relations: O(exp(R*n2))  Estimation begins to be hard at ~n=100 for R=1. In WordNet: n = 40K, R = 11.</p>
    <p>Unlike other structured problems, theres no known dynamic programming algorithm either</p>
  </div>
  <div class="page">
    <p>ERGM Training</p>
    <p>Estimating the scores for all possible graphs to obtain a probability distribution is implausible  Number of possible directed graphs with n nodes: O(exp(n2))  n nodes, R relations: O(exp(R*n2))  Estimation begins to be hard at ~n=100 for R=1. In WordNet: n = 40K, R = 11.</p>
    <p>Unlike other structured problems, theres no known dynamic programming algorithm either</p>
    <p>What can we do?</p>
    <p>Decompose score over dyads (node pairs) in graph  Draw and score negative sample graphs</p>
  </div>
  <div class="page">
    <p>Max-Margin Markov Graph Model (M3GM)</p>
    <p>Sample negative graphs from the local neighborhood of the true WN</p>
  </div>
  <div class="page">
    <p>Max-Margin Markov Graph Model (M3GM)</p>
    <p>Sample negative graphs from the local neighborhood of the true WN</p>
  </div>
  <div class="page">
    <p>Max-Margin Markov Graph Model (M3GM)</p>
    <p>Sample negative graphs from the local neighborhood of the true WN</p>
  </div>
  <div class="page">
    <p>Max-Margin Markov Graph Model (M3GM)</p>
    <p>Sample negative graphs from the local neighborhood of the true WN</p>
  </div>
  <div class="page">
    <p>Max-Margin Markov Graph Model (M3GM)</p>
    <p>Sample negative graphs from the local neighborhood of the true WN</p>
    <p>Loss = Max {0, 1 + score(negative sample) - score(WN)}</p>
  </div>
  <div class="page">
    <p>Max-Margin Markov Graph Model (M3GM)</p>
    <p>Its important to choose an appropriate proposal distribution (source of the negative samples)</p>
    <p>s v</p>
    <p>t</p>
    <p>v v</p>
    <p>v</p>
  </div>
  <div class="page">
    <p>Max-Margin Markov Graph Model (M3GM)</p>
    <p>Its important to choose an appropriate proposal distribution (source of the negative samples)</p>
    <p>We want to make things hard for the scorer</p>
    <p>Q(v|s, r)  slocal(&lt;s, r, v&gt;)</p>
    <p>s v</p>
    <p>t</p>
    <p>v v</p>
    <p>v</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Dataset - WN18RR  No reciprocal relations (hypernym  hyponym)  Still includes symmetric relations</p>
    <p>Metrics - MRR, H@10</p>
    <p>Rule baseline - take symmetric if exists in train  Used in all models as default for symmetric relations</p>
    <p>Local models  Synset embeddings - averaged from FastText</p>
    <p>M3GM (re-rank top 100 from local)  ~ 3000 motifs, ~900 non-zero</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Dataset - WN18RR  No reciprocal relations (hypernym  hyponym)  Still includes symmetric relations</p>
    <p>Metrics - MRR, H@10</p>
    <p>Rule baseline - take symmetric if exists in train  Used in all models as default for symmetric relations</p>
    <p>Local models  Synset embeddings - averaged from FastText</p>
    <p>M3GM (re-rank top 100 from local)  ~ 3000 motifs, ~900 non-zero</p>
    <p>transE</p>
    <p>DistMult</p>
    <p>Bilin</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Dataset - WN18RR  No reciprocal relations (hypernym  hyponym)  Still includes symmetric relations</p>
    <p>Metrics - MRR, H@10</p>
    <p>Rule baseline - take symmetric if exists in train  Used in all models as default for symmetric relations</p>
    <p>Local models  Synset embeddings - averaged from FastText</p>
    <p>M3GM (re-rank top 100 from local)  ~ 3000 motifs, ~900 non-zero</p>
    <p>transE</p>
  </div>
  <div class="page">
    <p>[Bordes et al. 2013]</p>
    <p>[Trouillon et al. 2016]</p>
  </div>
  <div class="page">
    <p>Feature Analysis</p>
    <p>Motifs with heavy positive weights:  Targets of has_part  Two-paths hypernym  derivationally_related_form</p>
    <p>Motifs with heavy negative weights:  Targets of hypernym  Two-cycles of hypernym  Target of both has_part and verb_group</p>
  </div>
  <div class="page">
    <p>Feature Analysis</p>
    <p>Motifs with heavy positive weights:  Targets of has_part  Two-paths hypernym  derivationally_related_form</p>
    <p>Motifs with heavy negative weights:  Targets of hypernym  Two-cycles of hypernym  Target of both has_part and verb_group vienna</p>
    <p>france</p>
    <p>austria</p>
    <p>european union</p>
    <p>germany...</p>
    <p>Seen in training data</p>
    <p>Local-only prediction</p>
    <p>M3GM prediction</p>
    <p>Unseen in data 36</p>
  </div>
  <div class="page">
    <p>Feature Analysis</p>
    <p>Motifs with heavy positive weights:  Targets of has_part  Two-paths hypernym  derivationally_related_form</p>
    <p>Motifs with heavy negative weights:  Targets of hypernym  Two-cycles of hypernym  Target of both has_part and verb_group</p>
    <p>indian lettuce</p>
    <p>lettuce</p>
    <p>herb</p>
    <p>garden lettuce ......</p>
    <p>......</p>
    <p>Seen in training data</p>
    <p>Local-only prediction</p>
    <p>M3GM prediction</p>
  </div>
  <div class="page">
    <p>Motifs with heavy positive weights:  Targets of has_part  Two-paths hypernym  derivationally_related_form</p>
    <p>Motifs with heavy negative weights:  Targets of hypernym  Two-cycles of hypernym  Target of both has_part and verb_group</p>
    <p>Feature Analysis</p>
    <p>mammal</p>
    <p>equine</p>
  </div>
  <div class="page">
    <p>Motifs with heavy positive weights:  Targets of has_part  Two-paths hypernym  derivationally_related_form</p>
    <p>Motifs with heavy negative weights:  Targets of hypernym  Two-cycles of hypernym  Target of both has_part and verb_group</p>
    <p>Feature Analysis</p>
    <p>Hypernym</p>
    <p>Deriv. Related form</p>
    <p>Derivations occur in the abstract parts of the graph</p>
    <p>(bodega / canteen vs. shop)</p>
  </div>
  <div class="page">
    <p>Feature Analysis</p>
    <p>Motifs with heavy positive weights:  Targets of has_part  Two-paths hypernym  derivationally_related_form</p>
    <p>Motifs with heavy negative weights:  Targets of hypernym  Two-cycles of hypernym  Target of both has_part and verb_group</p>
    <p>Nouns Verbs</p>
  </div>
  <div class="page">
    <p>Multilingual transfers of semantic graphs</p>
    <p>Future Work</p>
    <p>mammal</p>
    <p>canineequine</p>
    <p>horse zebra wolf fenec</p>
  </div>
  <div class="page">
    <p>Multilingual transfers of semantic graphs align embeddings / translate concepts</p>
    <p>Future Work</p>
    <p>mammal</p>
    <p>canineequine</p>
    <p>horse zebra wolf fenec</p>
  </div>
  <div class="page">
    <p>Multilingual transfers of semantic graphs align embeddings / translate concepts  Can we introduce global features to help?</p>
    <p>Future Work</p>
    <p>mammal</p>
    <p>canineequine</p>
    <p>horse zebra wolf fenec</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Global reasoning of graph features is beneficial for relation prediction   Works well on top of strong local models   Applicable to large graphs with dozens of relation types  M3GM   Orthogonal of word / synset embedding techniques   Finds a wide variety of linguistic patterns in semantic graphs</p>
  </div>
  <div class="page">
    <p>Computational Linguistics lab @Georgia Tech</p>
    <p>Thanks</p>
    <p>code + bonus WordNet analysis tools: github.com/yuvalpinter/m3gm</p>
    <p>contact: uvp@gatech.edu</p>
  </div>
  <div class="page">
    <p>Computational Linguistics lab @Georgia Tech</p>
    <p>Bloomberg Data Science PhD. Fellowship Program</p>
    <p>Thanks</p>
    <p>code + bonus WordNet analysis tools: github.com/yuvalpinter/m3gm</p>
    <p>contact: uvp@gatech.edu</p>
  </div>
  <div class="page">
    <p>Computational Linguistics lab @Georgia Tech</p>
    <p>Bloomberg Data Science PhD. Fellowship Program</p>
    <p>YOU!</p>
    <p>Thanks</p>
    <p>code + bonus WordNet analysis tools: github.com/yuvalpinter/m3gm</p>
    <p>contact: uvp@gatech.edu</p>
  </div>
</Presentation>
