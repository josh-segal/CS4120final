<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Performance Characterization of a</p>
    <p>W. Feng P. Balaji C. Baron</p>
    <p>L. N. Bhuyan D. K. Panda</p>
    <p>Advanced Computing Lab,</p>
    <p>Los Alamos National Lab</p>
    <p>Network Based Computing Lab,</p>
    <p>Ohio State University</p>
    <p>CARES Group,</p>
    <p>U. C. Riverside</p>
  </div>
  <div class="page">
    <p>Ethernet Overview</p>
    <p>Ethernet is the most widely used network infrastructure today</p>
    <p>Traditionally Ethernet has been notorious for performance issues</p>
    <p>Near an order-of-magnitude performance gap compared to IBA, Myrinet, etc.</p>
    <p>Cost conscious architecture</p>
    <p>Most Ethernet adapters were regular (layer 2) adapters</p>
    <p>Relied on host-based TCP/IP for network and transport layer support</p>
    <p>Compatibility with existing infrastructure (switch buffering, MTU)</p>
    <p>Used by 42.4% of the Top500 supercomputers</p>
    <p>Key: Reasonable performance at low cost</p>
    <p>TCP/IP over Gigabit Ethernet (GigE) can nearly saturate the link for current systems</p>
    <p>Several local stores give out GigE cards free of cost !</p>
    <p>10-Gigabit Ethernet (10GigE) recently introduced</p>
    <p>10-fold (theoretical) increase in performance while retaining existing features</p>
  </div>
  <div class="page">
    <p>Regular 10GigE adapters</p>
    <p>Layer-2 adapters</p>
    <p>Rely on host-based TCP/IP to provide network/transport functionality</p>
    <p>Could achieve a high performance with optimizations</p>
    <p>TCP Offload Engines (TOEs)</p>
    <p>Layer-4 adapters</p>
    <p>Have the entire TCP/IP stack offloaded on to hardware</p>
    <p>Sockets layer retained in the host space</p>
    <p>RDDP-aware adapters</p>
    <p>Layer-4 adapters</p>
    <p>Entire TCP/IP stack offloaded on to hardware</p>
    <p>Support more features than TCP Offload Engines</p>
    <p>No sockets ! Richer RDDP interface !</p>
    <p>E.g., Out-of-order placement of data, RDMA semantics</p>
    <p>[feng03:hoti, feng03:sc]</p>
    <p>[Evaluation based on the Chelsio T110 TOE adapters]</p>
  </div>
  <div class="page">
    <p>Presentation Overview</p>
    <p>Introduction and Motivation</p>
    <p>TCP Offload Engines Overview</p>
    <p>Experimental Evaluation</p>
    <p>Conclusions and Future Work</p>
  </div>
  <div class="page">
    <p>Sockets Interface</p>
    <p>Application or Library</p>
    <p>What is a TCP Offload Engine (TOE)?</p>
    <p>Hardware</p>
    <p>User</p>
    <p>Kernel</p>
    <p>TCP</p>
    <p>IP</p>
    <p>Device Driver</p>
    <p>Network Adapter (e.g., 10GigE)</p>
    <p>Sockets Interface</p>
    <p>Application or Library</p>
    <p>Hardware</p>
    <p>User</p>
    <p>Kernel</p>
    <p>TCP</p>
    <p>IP</p>
    <p>Device Driver</p>
    <p>Network Adapter (e.g., 10GigE)</p>
    <p>Offloaded TCP</p>
    <p>Offloaded IP</p>
    <p>Traditional TCP/IP stack TOE stack</p>
  </div>
  <div class="page">
    <p>Sockets Layer</p>
    <p>Interfacing with the TOE</p>
    <p>Application or Library</p>
    <p>Traditional Sockets Interface</p>
    <p>High Performance Sockets</p>
    <p>User-level Protocol</p>
    <p>TCP/IP</p>
    <p>Device Driver</p>
    <p>High Performance Network Adapter</p>
    <p>Network Features (e.g., Offloaded Protocol)</p>
    <p>TOM</p>
    <p>Application or Library</p>
    <p>toedev</p>
    <p>TCP/IP</p>
    <p>Device Driver</p>
    <p>High Performance Network Adapter</p>
    <p>Network Features (e.g., Offloaded Protocol)</p>
    <p>High Performance Sockets TCP Stack Override</p>
    <p>No changes required to the core kernel</p>
    <p>Some of the sockets functionality duplicated</p>
    <p>Kernel needs to be patched</p>
    <p>Some of the TCP functionality duplicated</p>
    <p>No duplication in the sockets functionality</p>
    <p>Control Path</p>
    <p>Data Path</p>
  </div>
  <div class="page">
    <p>compatibility with existing</p>
    <p>TCP/IP/Ethernet; Application-level</p>
    <p>compatibility with the sockets interface</p>
    <p>no longer restricted by the performance</p>
    <p>of traditional host-based TCP/IP stack</p>
    <p>interface restricted to the sockets</p>
    <p>interface !</p>
    <p>What does the TOE (NOT) provide?</p>
    <p>Hardware</p>
    <p>Kernel or Hardware</p>
    <p>User Application or Library</p>
    <p>Traditional Sockets Interface</p>
    <p>Transport Layer (TCP)</p>
    <p>Network Layer (IP)</p>
    <p>Device Driver</p>
    <p>Network Adapter (e.g., 10GigE)</p>
    <p>Kernel</p>
    <p>[rait05]: Support iWARP compatibility and features for regular network adapters. P. Balaji, H. W. Jin, K.</p>
    <p>Vaidyanathan and D. K. Panda. In the RAIT workshop; held in conjunction with Cluster Computing, Aug 26 th, 2005.</p>
    <p>[rait05]</p>
  </div>
  <div class="page">
    <p>Presentation Overview</p>
    <p>Introduction and Motivation</p>
    <p>TCP Offload Engines Overview</p>
    <p>Experimental Evaluation</p>
    <p>Conclusions and Future Work</p>
  </div>
  <div class="page">
    <p>Experimental Test-bed and the Experiments</p>
    <p>Two test-beds used for the evaluation</p>
    <p>Two 2.2GHz Opteron machines with 1GB of 400MHz DDR SDRAM</p>
    <p>Nodes connected back-to-back</p>
    <p>Four 2.0GHz quad-Opteron machines with 4GB of 333MHz DDR SDRAM</p>
    <p>Nodes connected with a Fujitsu XG1200 switch (450ns flow-through latency)</p>
    <p>Evaluations in three categories</p>
    <p>Sockets-level evaluation</p>
    <p>Single-connection Micro-benchmarks</p>
    <p>Multi-connection Micro-benchmarks</p>
    <p>MPI-level Micro-benchmark evaluation</p>
    <p>Application-level evaluation with the Apache Web-server</p>
  </div>
  <div class="page">
    <p>Latency and Bandwidth Evaluation (MTU 9000)</p>
    <p>TOE achieves a latency of about 8.6us and a bandwidth of 7.6Gbps at the sockets layer</p>
    <p>Host-based TCP/IP achieves a latency of about 10.5us (25% higher) and a bandwidth of 7.2Gbps (5% lower)</p>
    <p>For Jumbo frames, host-based TCP/IP performs quite close to the TOE</p>
  </div>
  <div class="page">
    <p>Latency and Bandwidth Evaluation (MTU 1500)</p>
    <p>No difference in latency for either stack</p>
    <p>The bandwidth of host-based TCP/IP drops to 4.9Gbps (more interrupts; higher overhead)</p>
    <p>For standard sized frames, TOE significantly outperforms host-based TCP/IP (segmentation offload is the key)</p>
  </div>
  <div class="page">
    <p>Multi-Stream Bandwidth</p>
    <p>The throughput of the TOE stays between 7.2 and 7.6Gbps</p>
  </div>
  <div class="page">
    <p>Hot Spot Latency Test (1 byte)</p>
    <p>Connection scalability tested up to 12 connections; TOE achieves similar or better</p>
    <p>scalability as the host-based TCP/IP stack</p>
  </div>
  <div class="page">
    <p>Fan-in and Fan-out Throughput Tests</p>
    <p>Fan-in and Fan-out tests show similar scalability</p>
  </div>
  <div class="page">
    <p>MPI-level Comparison</p>
    <p>MPI latency and bandwidth show similar trends as socket-level latency and bandwidth</p>
  </div>
  <div class="page">
    <p>Application-level Evaluation: Apache Web-Server</p>
    <p>Apache Web-server</p>
    <p>Web Client</p>
    <p>Web Client</p>
    <p>Web Client</p>
    <p>We perform two kinds of evaluations with the Apache web-server:</p>
    <p>Not diluted by other system and workload parameters</p>
    <p>is constant for a given trace; it represents the temporal locality of a trace</p>
    <p>A high  value represents a high percent of requests for small files</p>
  </div>
  <div class="page">
    <p>Apache Web-server Evaluation</p>
  </div>
  <div class="page">
    <p>Presentation Overview</p>
    <p>Introduction and Motivation</p>
    <p>TCP Offload Engines Overview</p>
    <p>Experimental Evaluation</p>
    <p>Conclusions and Future Work</p>
  </div>
  <div class="page">
    <p>Conclusions  For a wide-spread acceptance of 10-GigE in clusters</p>
    <p>Compatibility</p>
    <p>Performance</p>
    <p>Feature-rich interface</p>
    <p>Network as well as Application-level compatibility is available  On-the-wire protocol is still TCP/IP/Ethernet</p>
    <p>Application interface is still the sockets interface</p>
    <p>Performance Capabilities  Significant performance improvements compared to the host-stack</p>
    <p>Close to 65% improvement in bandwidth for standard sized (1500byte) frames</p>
    <p>Feature-rich interface: Not quite there yet !  Extended Sockets Interface</p>
    <p>iWARP offload</p>
  </div>
  <div class="page">
    <p>Continuing and Future Work</p>
    <p>Comparing 10GigE TOEs to other interconnects</p>
    <p>Sockets Interface [cluster05]</p>
    <p>MPI Interface</p>
    <p>File and I/O sub-systems</p>
    <p>Extending the sockets interface to support iWARP capabilities</p>
    <p>[rait05]</p>
    <p>Extending the TOE stack to allow protocol offload for UDP sockets</p>
  </div>
  <div class="page">
    <p>Web Pointers</p>
    <p>http://public.lanl.gov/radiant</p>
    <p>http://nowlab.cse.ohio-state.edu</p>
    <p>feng@lanl.gov</p>
    <p>balaji@cse.ohio-state.edu</p>
    <p>Network Based Computing</p>
    <p>Laboratory NOWLAB</p>
  </div>
</Presentation>
