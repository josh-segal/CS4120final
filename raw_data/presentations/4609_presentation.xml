<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Flexible Flexible ArchitecturalArchitectural SupportSupport forfor FineFineGGrainrain SchedulingScheduling</p>
    <p>Daniel Daniel SanchezSanchez RichardRichard MM YooYooRichard Richard M. M. YooYoo</p>
    <p>ChristosChristos KozyrakisKozyrakis</p>
    <p>MarchMarch 1616thth 20102010 StanfordStanford UniversityUniversity</p>
  </div>
  <div class="page">
    <p>OverviewOverview</p>
    <p>Our focus: Userlevel schedulers for parallel runtimes  Cilk, TBB, OpenMP,</p>
    <p>Trends:  More cores/chip  Deeper memory hierarchies</p>
    <p>Need to exploit finergrain parallelism</p>
    <p>C i ti th h h d Deeper memory hierarchies  Costlier cache coherence</p>
    <p>Existing finegrain schedulers:</p>
    <p>Communication through shared memory increasingly inefficient</p>
    <p>g g  Softwareonly: Slow, do not scale  Hardwareonly: Fast, but inflexible</p>
    <p>Our contribution: Hardwareaided approach  HW: Fast, asynchronous messages between threads (ADM)</p>
    <p>SW: Scalable message passing schedulers</p>
    <p>SW: Scalable messagepassing schedulers  ADM schedulers scale like HW, flexible like SW schedulers</p>
  </div>
  <div class="page">
    <p>OutlineOutline</p>
    <p>Introduction</p>
    <p>Asynchronous Direct Messages (ADM)</p>
    <p>ADM schedulers</p>
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>FineFinegrain parallelismgrain parallelism</p>
    <p>Finegrain parallelism: Divide work in parallel phase in small tasks (~1K10K instructions)( )</p>
    <p>Potential advantages:  Expose more parallelismp p  Reduce load imbalance  Adapt to a dynamic environment (e.g. changing # cores)</p>
    <p>Potential disadvantages:  Large scheduling overheadsg g  Poor locality (if application has intertask locality)</p>
  </div>
  <div class="page">
    <p>TaskTaskstealing schedulersstealing schedulers</p>
    <p>T0 T1 Tn Threads</p>
    <p>Dequeue</p>
    <p>Task</p>
    <p>Enqueue</p>
    <p>Task Queues</p>
    <p>Steal</p>
    <p>One task queue per thread  Threads dequeue and enqueue tasks from queues  When a thread runs out of work, it tries to steal tasks</p>
    <p>, from another thread</p>
  </div>
  <div class="page">
    <p>TaskTaskstealing: Componentsstealing: Components</p>
    <p>T0 T1 Tn 2. Policies Enq/deq</p>
    <p>T0 T1 Tn</p>
    <p>Steal 3. Communication</p>
    <p>In software schedulers: Starved</p>
    <p>Queues and policies are cheap</p>
    <p>Communication through shared memory increasingly expensive!</p>
    <p>Queues</p>
    <p>Stealing</p>
    <p>Starved</p>
    <p>memory increasingly expensive! App</p>
  </div>
  <div class="page">
    <p>Hardware schedulers: CarbonHardware schedulers: Carbon</p>
    <p>Carbon [ISCA 07]: HW queues, policies, communication  One hardware LIFO task queue per core  Special instructions to enqueue/dequeue tasks</p>
    <p>Implementation:  Centralized queues for fast stealing (Global Task Unit)  One small task buffer per core to hide GTU latency (Local Task Units)</p>
    <p>l</p>
    <p>Starved 31x 26x</p>
    <p>Queues</p>
    <p>App</p>
    <p>Stealing</p>
    <p>Large benefits if app matches HW policies</p>
    <p>Useless if app doesnt match HW policies</p>
    <p>matches HW policies match HW policies</p>
  </div>
  <div class="page">
    <p>Approaches to fineApproaches to finegrain schedulinggrain scheduling</p>
    <p>Finegrain scheduling</p>
    <p>Hardwareonly Hardwareaided</p>
    <p>OpenMP Cilk</p>
    <p>Carbon GPUs</p>
    <p>Asynchronous Direct Messages</p>
    <p>Softwareonly</p>
    <p>TBB X10</p>
    <p>...</p>
    <p>SW queues &amp; policies SW communication</p>
    <p>HW queues &amp; policies HW communication</p>
    <p>SW queues &amp; policies HW communication</p>
    <p>Highoverhead Flexible</p>
    <p>Lowoverhead Inflexible</p>
    <p>Lowoverhead Flexible</p>
    <p>Flexible No extra HW</p>
    <p>Inflexible Specialpurpose HW</p>
    <p>Flexible Generalpurpose HW</p>
  </div>
  <div class="page">
    <p>OutlineOutline</p>
    <p>Introduction</p>
    <p>Asynchronous Direct Messages (ADM)</p>
    <p>ADM schedulers</p>
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>Asynchronous Direct MessagesAsynchronous Direct Messages</p>
    <p>ADM: Messaging between threads tailored to scheduling and control needs: Lowoverhead</p>
    <p>Short messages</p>
    <p>Send from/receive to registers Independent from coherence</p>
    <p>Overlap communication Asynchronous messages with user level interruptsand computation</p>
    <p>G l</p>
    <p>with userlevel interrupts</p>
    <p>Generic interface Generalpurpose Allows reuse</p>
  </div>
  <div class="page">
    <p>ADM ADM MicroarchitectureMicroarchitecture</p>
    <p>One ADM unit per core: One ADM unit per core:  Receive buffer holds messages until dequeued by thread Send buffer holds sent messages pending acknowledgement Send buffer holds sent messages pending acknowledgement</p>
    <p>Thread ID Translation Buffer translates TID  core ID on sends  Small structures (1632 entries), don't grow with # cores</p>
    <p>Small structures (16 32 entries), don t grow with # cores</p>
  </div>
  <div class="page">
    <p>ADM ISAADM ISA</p>
    <p>InstructionInstruction DescriptionDescription</p>
    <p>adm_send r1, r2 Sends a message of (r1) words (06) to thread with ID (r2)</p>
    <p>adm_peek r1, r2 Returns source and message length at head of rx buffer</p>
    <p>adm_rx r1, r2 Dequeues message at head of rx buffer</p>
    <p>adm ei / adm di Enable / disable receive interrupts</p>
    <p>Send and receive are atomic (single instruction)  Send completes when message is copied to send buffer</p>
    <p>adm_ei / adm_di Enable / disable receive interrupts</p>
    <p>Send completes when message is copied to send buffer</p>
    <p>Receive blocks if buffer is empty  Peek doesn't block, enables polling</p>
    <p>ADM unit generates an userlevel interrupt on the running thread when a message is received</p>
    <p>No stack switching, handler code partially saves context (used registers)  fast</p>
    <p>Interrupts can be disabled to preserve atomicity w.r.t. message reception</p>
  </div>
  <div class="page">
    <p>OutlineOutline</p>
    <p>Introduction</p>
    <p>Asynchronous Direct Messages (ADM)</p>
    <p>ADM schedulers</p>
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>ADM ADM SchedulersSchedulers  Messagepassing schedulers  Replace parallel runtimes (e.g. TBB) scheduler</p>
    <p>Application programmer is oblivious to this</p>
    <p>Threads can perform two roles:  Worker: Execute parallel phase, enqueue &amp; dequeue tasks  Manager: Coordinate task stealing &amp; parallel phase termination</p>
    <p>Centralized scheduler: Single manager coordinates all</p>
    <p>T0T0 is managerd k ! Manager</p>
    <p>! 0and worker!!</p>
  </div>
  <div class="page">
    <p>Centralized Scheduler: UpdatesCentralized Scheduler: Updates</p>
    <p>Manager164 2 4 6 18224 4 4 64 8 4 6 Approx task counts T0</p>
    <p>UPDATE &lt;4&gt; UPDATE &lt;8&gt;</p>
    <p>Task Queues</p>
    <p>Manager keeps approximate task counts of each worker</p>
    <p>Workers only notify manager at exponential thresholds</p>
  </div>
  <div class="page">
    <p>Centralized Scheduler: StealsCentralized Scheduler: Steals</p>
    <p>Manager</p>
    <p>STEAL_REQ</p>
    <p>T0</p>
    <p>UPDATE &lt;1&gt; _ Q</p>
    <p>&lt;T1&gt;T2, 1&gt;</p>
    <p>TASK</p>
    <p>Task Queues</p>
    <p>Manager requests a steal from the worker with most tasks</p>
  </div>
  <div class="page">
    <p>Hierarchical SchedulerHierarchical Scheduler</p>
    <p>Centralized scheduler: Does all communication through messages</p>
    <p>Enables directed stealing, task prefetching</p>
    <p>Does not scale beyond ~16 threads</p>
    <p>Solution: Hierarchical scheduler Workers and managers form a tree</p>
    <p>T1 2nd Level Manager</p>
    <p>T0 1st Level ManagersT4</p>
  </div>
  <div class="page">
    <p>Hierarchical Scheduler: StealsHierarchical Scheduler: Steals</p>
    <p>Steals can span multiple levels</p>
    <p>TASK (x2) TASK</p>
    <p>TASK (x4)</p>
    <p>p p  A single steal rebalances two partitions at once</p>
    <p>Scales to hundreds of threads</p>
  </div>
  <div class="page">
    <p>OutlineOutline</p>
    <p>Introduction</p>
    <p>Asynchronous Direct Messages (ADM)</p>
    <p>ADM schedulers</p>
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>EvaluationEvaluation</p>
    <p>Simulated machine: Tiled CMP  32, 64, 128 inorder dualthread SPARC cores (64 256 h d )</p>
    <p>CMP tile</p>
    <p>(64  256 threads)</p>
    <p>3level cache hierarchy, directory coherence</p>
    <p>Benchmarks: Loop parallel: canneal cg gtfold Loopparallel: canneal, cg, gtfold</p>
    <p>Taskparallel: maxflow, mergesort, ced, hashjoin  Focus on representative subset of results,p , see paper for full set</p>
  </div>
  <div class="page">
    <p>ResultsResults QueuesApp Stealing Starved</p>
    <p>SW scalability limited by scheduling overheads SW scalability limited by scheduling overheads  Carbon and ADM: Small overheads that scale</p>
    <p>ADM matches Carbon No need for HW scheduler</p>
  </div>
  <div class="page">
    <p>Flexible policies: Flexible policies: gtfoldgtfold case studycase study</p>
    <p>In gtfold, FIFO queues allow tasks to clear critical dependences fasterp FIFO queues trivial in SW and ADM</p>
    <p>Carbon (HW) stuck with LIFO 31x 26x</p>
    <p>ADM achieves 40x speedup over Carbon</p>
    <p>Cant implement all scheduling policies in HW!</p>
  </div>
</Presentation>
