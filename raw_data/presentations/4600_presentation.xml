<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Knowledge Discovery over the Deep Web, Semantic Web and XML</p>
    <p>Aparna S. Varde, Fabian M. Suchanek, Richi Nayak and Pierre Senellart</p>
    <p>DASFAA 2009, Brisbane, Australia</p>
  </div>
  <div class="page">
    <p>Introduction</p>
    <p>The Web is a vast source of information  Various developments in the Web</p>
    <p>Deep Web  Semantic Web  XML Mining  Domain-Specific Markup Languages</p>
    <p>These enhance knowledge discovery</p>
  </div>
  <div class="page">
    <p>Agenda</p>
    <p>Section 1: Deep Web  Slides by Pierre Senellart</p>
    <p>Section 2: Semantic Web  Slides by Fabian M. Suchanek</p>
    <p>Section 3: XML Mining  Slides by Richi Nayak</p>
    <p>Section 4: Domain-Specific Markup Languages  Slides by Aparna Varde</p>
    <p>Summary and Conclusions</p>
  </div>
  <div class="page">
    <p>Section 1: Deep Web</p>
    <p>Pierre Senellart Department of Computer Science and Networking</p>
    <p>Telecom Paristech Paris, France</p>
    <p>pierre@senellart.com</p>
  </div>
  <div class="page">
    <p>What is the Deep Web Definition (Deep Web, Hidden Web) All the content of the Web that is not directly accessible through hyperlinks. In particular: HTML forms, Web services.</p>
    <p>Size estimate  [Bri00] 500 times more content than on the surface Web! Dozens of thousands of databases.  [HPWC07] ~ 400 000 deep Web databases.</p>
  </div>
  <div class="page">
    <p>Sources of the Deep Web</p>
    <p>Examples  Yellow Pages and other directories;  Library catalogs;  Publication databases;  Weather services;  Geolocalization services;  US Census Bureau data;  etc.</p>
  </div>
  <div class="page">
    <p>Discovering Knowledge from the Deep Web</p>
    <p>Content of the deep Web hidden to classical Web search engines (they just follow links)</p>
    <p>But very valuable and high quality!  Even services allowing access through the surface</p>
    <p>Web (e.g., e-commerce) have more semantics when accessed from the deep Web</p>
    <p>How to benefit from this information?  How to do it automatically, in an unsupervised</p>
    <p>way? 7</p>
  </div>
  <div class="page">
    <p>Extensional Approach</p>
    <p>WWW discovery</p>
    <p>siphoning</p>
    <p>bootstrap Index</p>
    <p>indexing</p>
  </div>
  <div class="page">
    <p>Notes on the Extensional Approach</p>
    <p>Main issues:  Discovering services  Choosing appropriate data to submit forms  Use of data found in result pages to bootstrap the</p>
    <p>siphoning process  Ensure good coverage of the database</p>
    <p>Approach favored by Google [MHC+06], used in production</p>
    <p>Not always feasible (huge load on Web servers) 9</p>
  </div>
  <div class="page">
    <p>Notes on the Extensional Approach</p>
    <p>Main issues:  Discovering services  Choosing appropriate data to submit forms  Use of data found in result pages to bootstrap the</p>
    <p>siphoning process  Ensure good coverage of the database</p>
    <p>Approach favored by Google [MHC+06], used in production</p>
    <p>Not always feasible (huge load on Web servers) 10</p>
  </div>
  <div class="page">
    <p>Intensional Approach</p>
    <p>WWW discovery</p>
    <p>probing</p>
    <p>analyzing Form wrapped as</p>
    <p>a Web service</p>
    <p>query 11</p>
  </div>
  <div class="page">
    <p>Notes on the Intensional Approach</p>
    <p>More ambitious [CHZ05, SMM+08]  Main issues:</p>
    <p>Discovering services  Understanding the structure and semantics of a form  Understanding the structure and semantics of result</p>
    <p>pages (wrapper induction)  Semantic analysis of the service as a whole</p>
    <p>No significant load imposed on Web servers</p>
  </div>
  <div class="page">
    <p>Discovering deep Web forms</p>
    <p>Crawling the Web and selecting forms  But not all forms!</p>
    <p>Hotel reservation  Mailing list management  Search within a Web site</p>
    <p>Heuristics: prefer GET to POST, no password, no credit card number, more than one field, etc.</p>
    <p>Given domain of interest: use focused crawling to restrict to this domain</p>
  </div>
  <div class="page">
    <p>Web forms</p>
    <p>Simplest case: associate each form field with some domain concept</p>
    <p>Assumption: fields independent from each other (not always true!), can be queried with words that are part of a domain instance</p>
  </div>
  <div class="page">
    <p>Structural analysis of a form (1/2)</p>
    <p>ontology 4) Obtain in this way candidate annotations</p>
  </div>
  <div class="page">
    <p>Structural analysis of a form (1/2)</p>
    <p>ontology 4) Obtain in this way candidate annotations</p>
  </div>
  <div class="page">
    <p>Structural analysis of a form (2/2)</p>
    <p>page (e.g., clustering along the DOM tree structure of the pages), to distinguish error pages and result pages</p>
    <p>For each field annotated with concept c:</p>
  </div>
  <div class="page">
    <p>Structural analysis of a form (2/2)</p>
    <p>page (e.g., clustering along the DOM tree structure of the pages), to distinguish error pages and result pages</p>
    <p>For each field annotated with concept c:</p>
  </div>
  <div class="page">
    <p>Bootstrapping the siphoning</p>
    <p>Siphoning (or probing) a deep Web database requires many relevant data to submit the form with</p>
    <p>Idea: use most frequent words in the content of the result pages</p>
    <p>Allows bootstrapping the siphoning with just a few words!</p>
  </div>
  <div class="page">
    <p>Inducing wrappers from result pages</p>
    <p>Pages resulting from a given form submission:  share the same structure  set of records with fields  unknown presentation!</p>
    <p>Goal Building wrappers for a given kind of result pages, in a fully automatic way.</p>
  </div>
  <div class="page">
    <p>Information extraction systems [CKGS06]</p>
  </div>
  <div class="page">
    <p>Unsupervised Wrapper Induction</p>
    <p>Use the (repetitive) structure of the result pages to infer a wrapper for all pages of this type</p>
    <p>Possibly: use in parallel with annotation by recognized concept instances to learn with both the structure and the content</p>
  </div>
  <div class="page">
    <p>Some perspectives</p>
    <p>Dealing with complex forms (fields allowing Boolean operators, dependencies between fields, etc.)</p>
    <p>Static analysis of JavaScript code to determine which fields of a form are required, etc.</p>
    <p>A lot of this is also applicable to Web 2.0/AJAX applications</p>
  </div>
  <div class="page">
    <p>References</p>
    <p>[Bri00] BrightPlanet. The deep Web: Surfacing hidden value. White paper, July 2000. [CHZ05] K. C.-C. Chang, B. He, and Z. Zhang. Towards large scale integration: Building a metaquerier over databases on the Web. In Proc. CIDR, Asilomar, USA, Jan. 2005. [CKGS06] C.-H. Chang, M. Kayed, M. R. Girgis, and K. F. Shaalan. A survey of Web information extraction systems. IEEE Transactions on Knowledge and Data Engineering, 18(10):1411-1428, Oct. 2006. [CMM01] V. Crescenzi, G. Mecca, and P. Merialdo. Roadrunner: Towards automatic data extraction from large Web sites. In Proc. VLDB, Roma, Italy, Sep. 2001. [HPWC07] B. He, M. Patel, Z. Zhang, and K. C.-C. Chang. Accessing the deep Web: A survey. Communications of the ACM, 50(2):94101 May 2007. [MHC+06] J. Madhavan, A. Y. Halevy, S. Cohen, X. Dong, S. R. Jeffery, D. Ko, and C. Yu. Structured data meets the Web: A few observations. IEEE Data Engineering Bulletin, 29(4):1926, Dec. 2006. [SMM+08] P. Senellart, A. Mittal, D. Muschick, R. Gilleron et M. Tommasi, Automatic Wrapper Induction from Hidden-Web Sources with Domain Knowledge. In Proc. WIDM, Napa, USA, Oct. 2008.</p>
  </div>
  <div class="page">
    <p>Section 2: Semantic Web</p>
    <p>Fabian M. Suchanek Databases and Information Systems Max Planck Institute for Informatics</p>
    <p>Saarbrucken, Germany suchanek@mpi-inf.mpg.de</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>scientists from Brisbane</p>
    <p>Australia's scientists visit Brisbane The National Science Education Unit invites Australian scientists to gather in Brisbane www.nsceu.au/brisbane</p>
    <p>&lt;HTML&gt; Sam Smart is a scientist from Brisbane. &lt;/HTML&gt;</p>
    <p>Brisbane</p>
    <p>Sam Smart</p>
    <p>bornIn</p>
    <p>label</p>
    <p>Today's state of the art Vision of the Sematic Web</p>
  </div>
  <div class="page">
    <p>The Semantic Web</p>
    <p>The Semantic Web is the project of creating a common framework that allows data to be shared and reused across application, enterprise, and community boundaries.</p>
    <p>Goals:</p>
    <p>make computers understand the data they store</p>
    <p>allow them to answer semantic queries</p>
    <p>allow them to share information across different systems</p>
    <p>Techniques: (= this talk)</p>
    <p>defining semantics in a machine-readable way (RDFS)</p>
    <p>identifying entities in a globally unique way (URIs)</p>
    <p>defining logical consistency in a uniform way (OWL)</p>
    <p>linking together existing resources (LOD) http://www.w3.org/2001/sw/27</p>
  </div>
  <div class="page">
    <p>The Resource Description Framework (RDF)</p>
    <p>Brisbane bornIn</p>
    <p>RDF is a format of knowledge representation that is similar to the Entity-Relationship-Model.</p>
    <p>SamSmart bornIn Brisbane</p>
    <p>ObjectPredicate/PropertySubject</p>
    <p>http://www.w3.org/TR/rdf-prier/</p>
    <p>Statement: A triple of subject,</p>
    <p>predicate and object</p>
    <p>RDF is used as the only knowledge representation language. =&gt; All information is represented in a simple, homogeneous, computer-processable way.</p>
  </div>
  <div class="page">
    <p>n-ary relationships</p>
    <p>Brisbane</p>
    <p>aboutPerson</p>
    <p>SamSmart livesIn Brisbane in 2009</p>
    <p>living42</p>
    <p>aboutPlace aboutTime</p>
    <p>living42 aboutPerson SamSmart living42 aboutPlace Brisbane living42 aboutTime 2009</p>
    <p>n-ary relationships can always be reduced to binary relationships by introducing a new identifier.</p>
  </div>
  <div class="page">
    <p>Uniform Resource Identifiers (URIs)</p>
    <p>Brisbane bornIn</p>
    <p>SamSmart: http://brisbane-corp.au/people/SamSmart</p>
    <p>bornIn: http://mpii.de/yago/resource/bornIn</p>
    <p>Brisbane: http://brisbane.au</p>
    <p>URIs are used as globally unique identifiers for resources. =&gt; Knowledge can be interlinked. A knowledge base on one server can refer to concepts from another knowledge base on another server.</p>
    <p>resource (= entity)</p>
    <p>http://www.ietf.org/rfc/rfc3986.txt</p>
    <p>A URI is similar to a URL, but it is not necessarily downloadable. It identifies a concept uniquely.</p>
    <p>URI</p>
  </div>
  <div class="page">
    <p>Namespaces</p>
    <p>Brisbane bornIn</p>
    <p>&lt;http://bsco.au/people/SamSmart&gt; &lt;http://mpii.de/yago/bornIn&gt; &lt;http://brisbane.au&gt;</p>
    <p>Without namespaces, our statement is a triple of 3 URIs -- quite verbose</p>
    <p>Namespace bsco := http://bsco.au/people/... Namespace yago := http://mpii.de/yago/...</p>
    <p>bsco:SamSmart yago:bornIn &lt;http://brisbane.au&gt;</p>
    <p>Namespaces are used to abbreviate URIs =&gt; Namespaces with useful concepts can become popular. This facilitates a common vocabulary across different knowledge bases.</p>
    <p>Namespaces make our statement much</p>
    <p>less verbose</p>
    <p>A namespace is a shorthand notation for the first part of a URI.</p>
  </div>
  <div class="page">
    <p>Popular Namespaces: Basic</p>
    <p>rdf: The basic RDF vocabulary http://www.w3.org/1999/02/22-rdf-syntax-ns#</p>
    <p>rdfs: RDF Schema vocabulary (predicates for classes etc., later in this talk) http://www.w3.org/1999/02/22-rdf-syntax-ns#</p>
    <p>owl: Web Ontology Language (for reasoning, later in this talk) http://www.w3.org/2002/07/owl#</p>
    <p>dc: Dublin Core (predicates for describing documents, such as author, title etc.) http://purl.org/dc/elements/1.1/</p>
    <p>xsd: XML Schema (definition of basic datatypes) http://www.w3.org/2001/XMLSchema#</p>
    <p>Standard namespaces are used for basic concepts =&gt; The basic concepts are the same across all RDF knowledge bases</p>
  </div>
  <div class="page">
    <p>Popular Namespaces: Specific</p>
    <p>dbp: The DBpedia ontology (real-world predicates and resources, e.g. Albert Einstein) http://dbpedia.org/resource/</p>
    <p>yago: The YAGO ontology (real-world predicates and resources, e.g. Albert Einstein) http://mpii.de/yago/resource/</p>
    <p>foaf: Friend Of A Friend (predicates for relationships between people) http://xmlns.com/foaf/0.1/</p>
    <p>cc: Creative Commons (types of licences) http://creativecommons.org/ns#</p>
    <p>.... and many, many more</p>
    <p>There exist already a number of specific namespaces =&gt; Knowledge engineers don't have to start from scratch</p>
  </div>
  <div class="page">
    <p>Literals</p>
    <p>Brisbane bornIn</p>
    <p>example:SamSmart yago:bornIn &lt;http://brisbane.au&gt;</p>
    <p>example:SamSmart rdfs:label Sam Smart^^xsd:string</p>
    <p>label Sam Smart</p>
    <p>We are using standard RDF vocabulary here</p>
    <p>The objects of statements can also be literals</p>
    <p>The literals can be typed. Types are identified by a URI</p>
    <p>Popular types: xsd:string xsd:date xsd:nonNegativeInteger xsd:byte</p>
    <p>Literals are can be labeled with pre-defined types =&gt; They come with a well-defined semantics. http://www.w3.org/TR/xmlschema-2/ 34</p>
  </div>
  <div class="page">
    <p>Classes</p>
    <p>Brisbane bornIn</p>
    <p>example:SamSmart yago:bornIn &lt;http://brisbane.au&gt; example:SamSmart rdf:type example:scientist example:scientist rdfs:subclassOf example:person</p>
    <p>scientist</p>
    <p>type</p>
    <p>person</p>
    <p>subclassOf More general classes</p>
    <p>subsume more specific classes</p>
    <p>type</p>
    <p>Due to historical reasons, some vocabulary is</p>
    <p>defined in RDF, other in RDFS</p>
    <p>http://www.w3.org/TR/rdf-schema/</p>
    <p>A class is a resource that represents a set of similar resources</p>
  </div>
  <div class="page">
    <p>Meta-Data</p>
    <p>Brisbane bornIn</p>
    <p>yago:bornIn rdf:type rdf:Property yago:bornIn rdfs:domain example:person yago:bornIn rdfs:range example:city example:person rdf:type rdfs:Class rdfs:Class rdf:type rdfs:Class</p>
    <p>RDFS can be used to talk about classes and properties, too =&gt; There is no concept of meta-data in RDFS</p>
    <p>city</p>
    <p>person</p>
    <p>Class</p>
    <p>Property</p>
    <p>bornIn</p>
    <p>type</p>
    <p>type</p>
    <p>type</p>
    <p>range</p>
    <p>domain</p>
    <p>type</p>
    <p>Properties themselves are resources in RDF</p>
    <p>http://www.w3.org/TR/rdf-schema/</p>
    <p>Meta-Data is data about classes and properties</p>
  </div>
  <div class="page">
    <p>Reasoning</p>
    <p>yago:bornIn rdf:type owl:FunctionalProperty example:Meat owl:disjointWith example:Fruit</p>
    <p>The OWL vocabulary can be used to express properties of classes and predicates =&gt; We can express logical consistency</p>
    <p>FunctionalProperty</p>
    <p>bornIn</p>
    <p>type</p>
    <p>A person can only be born in one place</p>
    <p>Class</p>
    <p>Meat</p>
    <p>type</p>
    <p>Meat is not Fruit</p>
    <p>Fruit</p>
    <p>type</p>
    <p>disjointWith</p>
    <p>The owl namespace defines vocabulary for set operations on classes, restrictions on properties and equivalence of classes.</p>
  </div>
  <div class="page">
    <p>Reasoning: Flavors of OWL</p>
    <p>OWL Lite</p>
    <p>OWL DL</p>
    <p>OWL Full</p>
    <p>Reification</p>
    <p>Classes as instances</p>
    <p>full RDF</p>
    <p>disjointWith</p>
    <p>cardinality constraints</p>
    <p>set operations on classes</p>
    <p>OWL Full is very powerful, but undecideable</p>
    <p>OWL DL has the expressive power of Description Logics</p>
    <p>OWL Lite is a simplified subset of OWL DL</p>
    <p>http://www.w3.org/TR/owl-guide/</p>
    <p>There exist 3 different flavors of OWL that trade off expressivity with tractability.</p>
  </div>
  <div class="page">
    <p>Formats of RDF data</p>
    <p>RDF is just the model of knowledge representation, there exist different formats to store it.</p>
    <p>FACT(resource, predicate, resource)</p>
    <p>@prefix yago http://mpii.de/yago/resource yago:SamSmart yago:bornIn &lt;http://brisbane.au&gt;</p>
  </div>
  <div class="page">
    <p>Existing OWL/RDF knowlegde bases: General</p>
    <p>There exist already a number of knowledge bases in RDF.</p>
    <p>Dataset URL #Statements</p>
    <p>Freebase</p>
    <p>(community collaboration) http://www.freebase.com 2.5m</p>
    <p>OpenCyc</p>
    <p>(spin-off from commerical ontology Cyc) http://www.opencyc.org 60k</p>
    <p>DBpedia</p>
    <p>(extraction from Wikipedia, focus on coverage)</p>
    <p>http://www.dbpedia.org 270m</p>
    <p>YAGO</p>
    <p>(extraction from Wikipedia, focus on accuracy) http://mpii.de/yago 20m</p>
  </div>
  <div class="page">
    <p>Existing OWL/RDF knowlegde bases: Specific</p>
    <p>=&gt; The Semantic Web has already a reasonable number of knowledge bases</p>
    <p>Dataset URL #Statements</p>
    <p>MusicBrainz</p>
    <p>(Artists, Songs, Albums)</p>
    <p>http://www.musicbrainz.org 23k</p>
    <p>Geonames</p>
    <p>(Countries, Cities, Capitals) http://www.geonames.org 85k</p>
    <p>DBLP</p>
    <p>(Papers, Authors, Citations) http://www4.wiwiss.fu-berlin.de/dblp/ 15m</p>
    <p>US Census</p>
    <p>(Population statistics)</p>
    <p>...and many more....</p>
    <p>http://www.rdfabout.com/demo/census/ 1000m</p>
  </div>
  <div class="page">
    <p>The Linking Open Data Project yago:AlbertEinstein owl:sameAs dbpedia:Albert_Einstein</p>
  </div>
  <div class="page">
    <p>Querying the knowledge bases: SPARQL</p>
    <p>PREFIX rdf:http://www.w3.org/1999/02/22-rdf-syntax-ns# PREFIX example:....</p>
    <p>SELECT ?x WHERE { ?x rdf:type example:scientist . ?x example:bornIn example:Brisbane }</p>
    <p>http://www.w3.org/TR/rdf-sparql-query/</p>
    <p>Which scientists are from Brisbane?</p>
    <p>SPARQL is a query language for RDF data. It is similar to SQL</p>
    <p>Define our namespaces</p>
    <p>Pose the query in SQL style</p>
  </div>
  <div class="page">
    <p>Sample Query on YAGO</p>
    <p>Which scientists are from Brisbane?</p>
  </div>
  <div class="page">
    <p>References Specifications</p>
    <p>RDF http://www.w3.org/TR/rdf-primer/</p>
    <p>RDFS http://www.w3.org/TR/rdf-schema/</p>
    <p>URIs http://www.ietf.org/rfc/rfc3986.txt</p>
    <p>Literals http://www.ietf.org/rfc/rfc3986.txt</p>
    <p>OWL http://www.w3.org/TR/owl-guide/</p>
    <p>SPARQL http://www.w3.org/TR/rdf-sparql-query/</p>
    <p>Projects</p>
    <p>YAGO Fabian M. Suchanek, Gjergji Kasneci, Gerhard Weikum YAGO - A Core of Sematic Knowledge (WWW 2007)</p>
    <p>DBpedia S. Auer, C. Bizer, J. Lehmann, G. Kobilarov, R. Cyganiak, Z. Ives DBpedia: A Nucleus for a Web of Open Data (ISWC 2007)</p>
    <p>LOD Christian Bizer, Tom Heath, Danny Ayers, Yves Raimond Interlinking Open Data on the Web (ESWC 2007)</p>
  </div>
  <div class="page">
    <p>Section 3: XML Mining</p>
    <p>Richi Nayak Faculty of Information Technology</p>
    <p>Queensland University of Technology Brisbane, Australia</p>
    <p>r.nayak@qut.edu.au</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>What XML is?  What XML Mining is?  Why should we do XML mining?  How we do XML mining?  Future directions</p>
  </div>
  <div class="page">
    <p>XML  XML: eXtensible Markup Language</p>
    <p>XML v. HTML  HTML: restricted set of tags, e.g. &lt;TABLE&gt;, &lt;H1&gt;, &lt;B&gt;, etc.  XML: you can create your own tags</p>
    <p>Selena Sol (2000) highlights the four major benefits of using XML language:  XML separates data from presentation which means making changes to</p>
    <p>the display of data does not affect the XML data;  Searching for data in XML documents becomes easier as search engines</p>
    <p>can parse the description-bearing tags of the XML documents;  XML tag is human readable, even a person with no knowledge of XML</p>
    <p>language can still read an XML document;  Complex structures and relations of data can be encoded using XML.</p>
  </div>
  <div class="page">
    <p>XML: An Example</p>
    <p>XML is a semi structured language</p>
    <p>&lt;?xml version=&quot;1.0&quot; encoding=&quot;ISO-8859-1&quot;?&gt; &lt;note&gt;</p>
    <p>&lt;to&gt;Tom&lt;/to&gt; &lt;from&gt;Mary&lt;/from&gt; &lt;heading&gt;Reminder&lt;/heading&gt; &lt;body&gt; Tomorrow is meeting. &lt;/body&gt;</p>
    <p>&lt;/note&gt;</p>
  </div>
  <div class="page">
    <p>XML: Data Model</p>
    <p>XML can be represented as a tree or graph oriented data model.</p>
  </div>
  <div class="page">
    <p>XML Schemas</p>
    <p>XML allows the possibility of defining document schema.</p>
    <p>Document schema contains the grammar for restricting syntax and structure of XML documents.</p>
    <p>Two commonly used schemas are:  Document Type Definition (DTD)  XML Schema Definition (XSD)</p>
    <p>Allows more extensive datachecking</p>
    <p>Valid XML documents conforms to its schema.</p>
  </div>
  <div class="page">
    <p>Requirements for XML mining</p>
    <p>What is specific to XML data that defines the requirements for XML mining?</p>
    <p>Structures and Content  Flexibility in its design  Multimodal  Scalability  Heterogeneous  Online  Distributed  Autonomous</p>
  </div>
  <div class="page">
    <p>A XML Mining Taxonomy</p>
    <p>XML Mining</p>
    <p>XML Structure</p>
    <p>Mining</p>
    <p>XML Content Mining</p>
    <p>IntraStructure</p>
    <p>Mining</p>
    <p>InterStructure</p>
    <p>Mining Content Analysis</p>
    <p>Structure Clarification</p>
  </div>
  <div class="page">
    <p>XML Mining Process</p>
    <p>XML Documents or/and schemas</p>
    <p>Tree/Graph/Matrix Representation</p>
    <p>Post processing</p>
    <p>Interpreting Patterns</p>
    <p>Pre-processing Inferring Structure Inferring Content</p>
    <p>Pattern Discovery Classification Clustering Association</p>
  </div>
  <div class="page">
    <p>d1 d2 d3 d4</p>
    <p>R/E1 1 1 1 2</p>
    <p>R/E2 1 1 1 0</p>
    <p>R/E3/</p>
    <p>E3.1</p>
    <p>R/E3/</p>
    <p>E3.2</p>
    <p>R/E3 1 1 1 2</p>
    <p>Four Example XML Documents</p>
    <p>Equivalent Content Matrix Representation Equivalent Structure Matrix Representation</p>
    <p>R</p>
    <p>E1 E2 E3</p>
    <p>E31 E32 (t1, t2, t3)</p>
    <p>(t4, t3, t6)</p>
    <p>(t5, t4, t7)</p>
    <p>(t5, t2, t1) (t7, t9)</p>
    <p>Equivalent Tree Representation</p>
  </div>
  <div class="page">
    <p>Some Mining Examples</p>
    <p>Mining frequent tree patterns  Grouping and classifying documents/schemas  Schema discovery  Schema-based mining  Mining association rules  Mining XML queries  Etc.</p>
  </div>
  <div class="page">
    <p>XML Clustering: Types and Approaches</p>
  </div>
  <div class="page">
    <p>XML Clustering: Data Models and Methods</p>
    <p>Structure  Edit distance (string, tree, ordered tree, graph)  Vector Space Models</p>
    <p>Content  Vector Space Models</p>
    <p>Mixing Structure and Content  Vector Space Models  Tensor models</p>
  </div>
  <div class="page">
    <p>The clustering process</p>
    <p>Find similarities between XML sources  by considering the XML semantic information such as the linguistic and the</p>
    <p>context of the elements  as well as the hierarchical structure information such as parent, children,</p>
    <p>and siblings.</p>
    <p>The process usually starts by considering the tree structures, as derived in the pre-processing step.</p>
    <p>The semantic similarity is measured by comparing each pair of elements of two trees primarily based on their names taking into account the acronyms, synonyms, hyponyms, hypernyms.</p>
    <p>The structural similarity is measured by considering the hierarchical positions of elements in the tree.  The utilization of sequential patterns mining algorithms has been used</p>
    <p>by many researchers to measure structural similarity.</p>
    <p>The semantic and structural similarity is combined to measure how similar two documents are.</p>
    <p>The pair-wise matrix becomes input for a clustering algorithm.</p>
  </div>
  <div class="page">
    <p>Frequent Tree Mining</p>
    <p>XML sources are generally represented as an ordered labelled or unordered labelled tree.</p>
    <p>The task is to build up associations among trees (or sub-trees or subgraphs or paths) rather than items as in traditional mining.</p>
    <p>The frequent tree mining extracts substructures that occur frequently among a set of XML documents or within an individual XML document.</p>
    <p>These frequent substructures generate association rules.  However, the frequent substructures are hierarchical and counting support</p>
    <p>requires more than just the join of flat sets.</p>
  </div>
  <div class="page">
    <p>Classifications of Tree Mining algorithms</p>
    <p>Based on:  Tree Representation</p>
    <p>Free trees, Rooted Unordered Tree, Rooted Ordered Tree</p>
    <p>Subtree Representation  Induced Subtree, Embedded Subtree</p>
    <p>Traversal strategy  Depth-first, Breadth-first, Depth-first &amp; Breadth</p>
    <p>first</p>
  </div>
  <div class="page">
    <p>Classifications of Tree Mining algorithms</p>
    <p>Based on:  Canonical representation</p>
    <p>Pre-order string encoding, Level-wise encoding</p>
    <p>Tree mining approach  Candidate generation (extension, Join), Pattern</p>
    <p>growth</p>
    <p>Condensed representation  Closed, Maximal</p>
  </div>
  <div class="page">
    <p>XML Classification Mining</p>
    <p>The task is to find structural rules in order to classify XML documents into the set of predefined classifications of documents.</p>
    <p>In the training phase, a set of structural classification rules are built that can be used in the learning phase to classify data (with unknown classes).</p>
    <p>The existing classification algorithms are not efficient to classify the XML documents because they are not capable of exploring the structural information.</p>
    <p>Few researchers have developed generic (e.g., information retrieval (IR) based and association based) classifiers as well as specific (e.g. rule based according to structures) classifiers for XML.</p>
  </div>
  <div class="page">
    <p>XML Classification Mining</p>
    <p>The IR-based methods treat each document as a bag of words.  These methods use the actual text of the XML data, and do not take into</p>
    <p>account a considerable amount of structural information inside the documents.</p>
    <p>The association-based methods use the associations among different nodes visited in a session in order to perform the classification.</p>
    <p>An effective rule-based classifier for XML, XRules, uses a set of structural rules for the classification of XML documents.  It first mines frequent structures in a collection of XML trees.  The frequent structures according to their support count for each class of</p>
    <p>documents are generated.  The next task is to find distinction between groups of rules for each class so a</p>
    <p>group of rules can uniquely define a class.  XRules uses the bayesian induction algorithm to combine the strength of</p>
    <p>structure frequency and an optimal neighbourhood ratio for a given set of documents.</p>
  </div>
  <div class="page">
    <p>Future Directions</p>
    <p>Scalability  Incremental Approaches</p>
    <p>Combining structure and content efficiently  Advanced data representational models and</p>
    <p>mining methods</p>
    <p>Application Context</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>XML mining, in order to be more than a temporary fade, must deliver useful solutions for practical applications.</p>
    <p>Applications with large amounts of raw strategic data in XML will be there.</p>
    <p>XML data mining techniques will be a plus for the adoption of XML as a data model for modern applications.</p>
  </div>
  <div class="page">
    <p>Reading Articles</p>
    <p>R. Nayak (2008) XML Data Mining: Process and Applications, Chapter 15 in Handbook of Research on Text and Web Mining Technologies, Ed: Min Song and Yi-Fang Wu. Publisher: Idea Group Inc., USA. PP. 249 -271.</p>
    <p>S. Kutty and R. Nayak (2008) Frequent Pattern Mining on XML documents, Chapter 14 in Handbook of Research on Text and Web Mining Technologies, Ed: Min Song and Yi-Fang Wu. Publisher: Idea Group Inc., USA. PP. 227 -248.</p>
    <p>R. Nayak (2008) Fast and Effective Clustering of XML Data Utilizing their Structural Information. Knowledge and Information Systems (KAIS). Volume 14, No. 2, February 2008 pp 197-215.</p>
    <p>C. C. Aggarwal, N. Ta, J. Wang, J. Feng, and M. Zaki, &quot;Xproj: a framework for projected structural clustering of xml documents,&quot; in Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining San Jose, California, USA: ACM, 2007, pp. 46-55.</p>
    <p>Nayak, R., &amp; Zaki, M. (Eds.). (2006). Knowledge Discovery from XML documents: PAKDD 2006 Workshop Proceedings (Vol. 3915): Springer-Verlag Heidelberg.</p>
    <p>NAYAK, R. AND TRAN, T. 2007. A progressive clustering algorithm to group the XML data by structural and semantic similarity. International Journal of Pattern Recognition and Artificial Intelligence 21, 4, 723743.</p>
    <p>Y. Chi, S. Nijssen, R. R. Muntz, and J. N. Kok, &quot;Frequent Subtree Mining- An Overview,&quot; in Fundamenta Informaticae. vol. 66: IOS Press, 2005, pp. 161-198.</p>
    <p>L. Denoyer and P. Gallinari, &quot;Report on the XML mining track at INEX 2005 and INEX 2006: categorization and clustering of XML documents,&quot; SIGIR Forum, vol. 41, pp. 79-90, 2007.</p>
    <p>BERTINO, E., GUERRINI, G., AND MESITI, M. 2008. Measuring the structural similarity among XML documents and DTDs. Intelligent Information Systems 30, 1, 5592.</p>
    <p>BEX, G. J., NEVEN, F., AND VANSUMMEREN, S. 2007. Inferring XML schema definitions from XML data. In Proceedings of the 33rd International Conference on Very Large Data Bases. Vienna, Austria, 9981009.</p>
    <p>BILLE, P. 2005. A survey on tree edit distance and related problems. Theoretical Computer Science 337, 1-3, 217239.</p>
    <p>BONIFATI, A., MECCA, G., PAPPALARDO, A., RAUNICH, S., AND SUMMA, G. 2008. Schema mapping verification:the spicy way. In EDBT. 8596.</p>
  </div>
  <div class="page">
    <p>Related Publications</p>
    <p>BOUKOTTAYA, A. AND VANOIRBEEK, C. 2005. Schema matching for transforming structured documents. In DocEng05. 101110.</p>
    <p>FLESCA, S., MANCO, G., MASCIARI, E., PONTIERI, L., AND PUGLIESE, A. 2005. Fast detection of XML structural similarity. IEEE Trans. on Knowledge and Data Engineering 17, 2, 160175.</p>
    <p>GOU, G. AND CHIRKOVA, R. 2007. Efficiently querying large XML data repositories: A survey. IEEE Trans. on Knowledge and Data Engineering 19, 10, 13811403.</p>
    <p>NAYAK, R. AND IRYADI,W. 2007. XML schema clustering with semantic and hierarchical similarity measures. Knowledge-based Systems 20, 336349.</p>
    <p>Kutty, S., Nayak, R., &amp; Li, Y. (2007). PCITMiner- Prefix-based Closed Induced Tree Miner for finding closed induced frequent subtrees. Paper presented at the the Sixth Australasian Data Mining Conference (AusDM 2007), Gold Coast, Australia.</p>
    <p>TAGARELLI, A. AND GRECO, S. 2006. Toward semantic XML clustering. In SDM 2006. 188199.  Rusu, L. I., Rahayu, W., &amp; Taniar, D. (2007). Mining Association Rules from XML Documents. In A. Vakali &amp; G.</p>
    <p>Pallis (Eds.), Web Data Management Practices:  Li, H.-F., Shan, M.-K., &amp; Lee, S.-Y. (2006). Online mining of frequent query trees over XML data streams. In</p>
    <p>Proceedings of the 15th international conference on World Wide Web (pp. 959-960). Edinburgh, Scotland: ACM Press.</p>
    <p>Zaki, M. J.:(2005):Efficiently mining frequent trees in a forest: algorithms and applications. IEEE Transactions on Knowledge and Data Engineering, 17 (8): 1021-1035</p>
    <p>Zaki, M. J., &amp; Aggarwal, C. C. (2003). XRules: An Effective Structural Classifier for XML Data. Paper presented at the SIGKDD.</p>
    <p>Wan, J. W. W. D., G. (2004). Mining Association rules from XML data mining query. Research and practice in Information Technology, 32, 169-174.</p>
  </div>
  <div class="page">
    <p>Section 4: Domain-Specific Markup Languages</p>
    <p>Aparna Varde Department of Computer Science</p>
    <p>Montclair State University Montclair, NJ, USA</p>
    <p>(vardea@mail.montclair.edu</p>
  </div>
  <div class="page">
    <p>What is a Domain-Specific Markup Language?</p>
    <p>Medium of communication for users of the domain</p>
    <p>Follows XML syntax</p>
    <p>Encompasses the semantics of the domain</p>
  </div>
  <div class="page">
    <p>Examples of Domain-Specific Markup Languages</p>
    <p>MML: Medical Markup Language ChemML: Chemical Markup Language MatML: Materials Markup Language AniML: Analytical Information Markup Language MathML: Mathematics Markup Language WML: Wireless Markup Language</p>
  </div>
  <div class="page">
    <p>Steps in Markup Language Development</p>
  </div>
  <div class="page">
    <p>Domain Knowledge Acquistion</p>
    <p>Terminology Study  Understand concepts in domain well  Find out if new markup language should</p>
    <p>be an extension to an existing markup or an independent language</p>
    <p>Data Modeling  Use ER models, UML etc.  This also serves as a medium of</p>
    <p>communication</p>
    <p>Requirements Specifications  Conduct interviews with domain experts</p>
    <p>who can convey user needs  Develop Requirement Specifications</p>
    <p>accordingly</p>
    <p>Example of ER model for Heat Treating of Materials</p>
    <p>in Materials Science domain</p>
  </div>
  <div class="page">
    <p>Ontology Creation  Ontology is a system of</p>
    <p>nomenclature used in a given domain</p>
    <p>Important considerations in ontology are synonyms and homographs</p>
    <p>Once initial ontology is established, it is useful to have discussions with experts and other users to make changes</p>
    <p>Revision of the ontology can go through several rounds of discussion and testing</p>
    <p>Quenchant: This refers to the medium used for cooling in the heat treatment process of rapid cooling or Quenching.  Alternative Term(s): CoolingMedium  PartSurface: The characteristics pertaining to the surface of the part undergoing heat treatment are recorded here.  Alternative Term(s): ProbeSurface, WorkpieceSurface  Manufacturing: The details of the processes used in the production of the concerned part such as welding and stamping are stored here.  Alternative Term(s): Production  QuenchConditions: This records the input parameters under which the Quenching process occurs, e.g., the temperature of the cooling medium, the extent to which the medium is agitated and so forth.  Alternative Term(s): InputConditions, InputParameters, QuenchParameters  Results: This stores the outcome of the Quenching process in terms of properties such as cooling rate (change in part temperature with respect to time) and heat transfer coeffiicent (measurement of heat extraction capacity of the whole process of rapid cooling).  Alternative Term(s): Output, Outcome</p>
    <p>Example of Ontology for QuenchML: Quenching Markup Language for</p>
    <p>Heat Treating of Materials</p>
  </div>
  <div class="page">
    <p>Schema Development  Schema provides the structure of the</p>
    <p>markup language  E-R model, requirements specification</p>
    <p>and ontology serve as the basis for schema design</p>
    <p>Each entity in E-R model significant in requirements specification typically corresponds to a schema element</p>
    <p>First schema draft is revised until users are satisfied that it adequately represents their needs</p>
    <p>Schema revision may involve several iterations, including discussions with standards bodies Example Partial Snapshot of</p>
    <p>QuenchML Schema</p>
  </div>
  <div class="page">
    <p>Desired Properties of Markup Languages</p>
    <p>Avoidance of Redundancy  If information about an entity or attribute is stored in an existing markup</p>
    <p>language, it should not be repeated in the new markup language  E.g., Thermal Conductivity stored in MatML, do not repeat in QuenchML</p>
    <p>Non-Ambiguous Presentation of Information  Consider concepts such as synonyms, e.g., in Salary and Income, and</p>
    <p>homographs, e.g., Share (part of something or stocks) in Financial fields</p>
    <p>Easy Interpretability of Information  Readers should be able to understand stored information without much</p>
    <p>reference to related documentation  E.g., in Scientific fields, store Input Conditions of experiments before Results</p>
    <p>Incorporation of Domain-Specific Requirements  Issues such as primary keys, e.g., Student ID in Academic fields</p>
  </div>
  <div class="page">
    <p>Application of XML Features in Language Development</p>
  </div>
  <div class="page">
    <p>Sequence Constraint</p>
    <p>Used to declare elements to occur in a certain order</p>
    <p>Example:  Quenching is a step in Heat</p>
    <p>Treatment of Materials  QuenchML proposed as</p>
    <p>extension to MatML  QuenchConditions must</p>
    <p>come before Results for meaningful interpretation</p>
  </div>
  <div class="page">
    <p>Choice Constraint</p>
    <p>Used to declare mutually exclusive elements, i.e., only one of them can exist</p>
    <p>Example  In Heat Treating, part being</p>
    <p>heated can be manufactured by either Casting or Powder Metallurgy, not both</p>
    <p>In Finance, a person can be either Solvent or Bankrupt, not both</p>
  </div>
  <div class="page">
    <p>Key Constraint</p>
    <p>Used to declare an attribute to be a unique identifier</p>
    <p>Analogous to primary key in relational databases</p>
    <p>Example:  In Heat Treating, name</p>
    <p>of Quenchant  In Census Applications,</p>
    <p>SSN of a person</p>
  </div>
  <div class="page">
    <p>Occurrence Constraint</p>
    <p>Used to declare minimum and maximum permissible occurrences of an element</p>
    <p>Example:  In Heat Treating, Cooling Rate</p>
    <p>must be recorded for at least 8 points, no upper bound</p>
    <p>In same context, at most 3 Graphs are stored, no lower bound</p>
  </div>
  <div class="page">
    <p>Convenient Access to Information for Knowledge Discovery</p>
  </div>
  <div class="page">
    <p>XQuery</p>
    <p>XQuery (XML Query Language) developed by the World Wide Web Consortium (W3C)</p>
    <p>XQuery can retrieve information stored using domain-specific markup languages designed with XML tags</p>
    <p>It is thus advisable to design the markup language to facilitate retrieval using XQuery  Storing data in a case sensitive manner  Using additional tags for storage to enhance querying efficiency</p>
  </div>
  <div class="page">
    <p>XSLT</p>
    <p>XSLT stands for XML Style Sheet Language Transformations</p>
    <p>It is a language for transforming XML documents into other XML documents</p>
    <p>This includes an XML vocabulary for specifying formatting</p>
    <p>Information stored using an XML based Markup Language is easily accessible through XSLT</p>
  </div>
  <div class="page">
    <p>XPath</p>
    <p>XPath, the XML Path Language, is a language for addressing parts of an XML document</p>
    <p>In support of this primary purpose, it also provides basic facilities for manipulation of strings, numbers and booleans</p>
    <p>XPath models an XML document as a tree of nodes  There are different types of nodes, including element nodes,</p>
    <p>attribute nodes and text nodes  XPath fully supports XML Namespaces  All this further enhances the retrieval of information with</p>
    <p>reference to context</p>
  </div>
  <div class="page">
    <p>Data Mining with Association Rules  Association Rules are of</p>
    <p>the type A =&gt; B  Example: fever =&gt; flu</p>
    <p>Interestingness measures  Rule confidence : P(B/A)  Rule support: P(AUB)</p>
    <p>Data stored in a markup language facilitates rule derivation over text sources of information</p>
    <p>This helps to discover knowledge from text data</p>
    <p>&lt;fever&gt; yes &lt;/fever&gt; in 9/10 instances  &lt;flu&gt; yes &lt;/flu&gt; in 7/10 instances</p>
    <p>6 of these in common with fever  This helps to discover a rule</p>
    <p>fever = yes =&gt; flu = yes  Rule confidence: 6/9 = 67%  Rule support: 6/10 = 60%</p>
  </div>
  <div class="page">
    <p>Real World Applications</p>
    <p>Data stored using markup languages can be used to develop efficient Management Information Systems (MIS) in given domains</p>
    <p>Rule derivation from text sources can serve as basis for knowledge discovery to develop Expert Systems</p>
    <p>Other techniques such as document clustering can be applied over text data stored using markup languages for better Information Retrieval</p>
  </div>
  <div class="page">
    <p>References</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Developments in Web technology outlined  Deep Web  Semantic Web  XML  Domain Specific Markup Languages</p>
    <p>Discussion on how these developments facilitate knowledge discovery included</p>
    <p>Suitable examples and applications provided</p>
  </div>
</Presentation>
