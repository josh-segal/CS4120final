<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Pelican: A building block for exascale cold data storage</p>
    <p>Shobana Balakrishnan, Richard Black, Austin Donnelly, Paul England, Adam Glass, Dave Harper, Sergey Legtchenko, Aaron</p>
    <p>Ogus, Eric Peterson, Antony Rowstron</p>
    <p>Microsoft Research</p>
  </div>
  <div class="page">
    <p>Background: cold data in the cloud</p>
    <p>Cold data: written once  read rarely access pattern</p>
    <p>Large fraction of stored data</p>
    <p>Hot</p>
    <p>Warm</p>
    <p>Cold</p>
    <p>Archival</p>
    <p>?</p>
    <p>Hot tier  Provisioned for peak  High throughput  Low latency  High cost</p>
    <p>Archive tier  Low cost  High latency (hours)</p>
    <p>$$$$$</p>
    <p>$$$$</p>
    <p>$$$</p>
    <p>$</p>
  </div>
  <div class="page">
    <p>Background: cold data in the cloud</p>
    <p>Cold data: written once  read rarely access pattern</p>
    <p>Large fraction of stored data</p>
    <p>Hot</p>
    <p>Warm</p>
    <p>Cold</p>
    <p>Archival</p>
    <p>Hot tier  Provisioned for peak  High throughput  Low latency  High cost</p>
    <p>$$$$$</p>
    <p>$$$$</p>
    <p>$$$</p>
    <p>$</p>
    <p>Pelican vs. Tape:  Better performance  Similar cost</p>
    <p>Cold tier:  High density  Low hardware cost  Low operating cost  Latency lower than</p>
    <p>tape</p>
  </div>
  <div class="page">
    <p>Right-provisioning</p>
    <p>Provision resources just for the cold data workload: Disks:</p>
    <p>Archival and SMR instead of commodity Power</p>
    <p>Cooling</p>
    <p>Bandwidth</p>
    <p>Enough for bandwidth required by workload instead of</p>
    <p>for all disks spinning</p>
    <p>Servers:</p>
    <p>Enough for data management instead of 1 server/ 40 disks</p>
    <p>Benefits of removing unnecessary resources:  High density of storage</p>
    <p>Low hardware cost</p>
    <p>Low operating cost (capped performance) 4</p>
  </div>
  <div class="page">
    <p>Pelican: rack-scale appliance for cold data</p>
    <p>Converged design:</p>
    <p>Power, cooling, mechanical, storage &amp; software co-designed</p>
    <p>Right-provisioned for cold data workload:</p>
    <p>Resources for just workload requirements</p>
    <p>At most 8% disks spun up</p>
    <p>2 servers</p>
    <p>No Top of Rack switch</p>
    <p>4x 10Gbps uplinks from the servers</p>
    <p>1,152 disks in 52U: 22 disks/U</p>
    <p>5+ PB of raw storage</p>
    <p>Pelican rack prototype</p>
    <p>Other disk-based storage: Up to 15/U</p>
  </div>
  <div class="page">
    <p>Pelican: rack-scale appliance for cold data</p>
    <p>Converged design:</p>
    <p>Power, cooling, mechanical, storage &amp; software co-designed</p>
    <p>Right-provisioned for cold data workload:</p>
    <p>Resources for just workload requirements</p>
    <p>At most 8% disks spun up</p>
    <p>2 servers</p>
    <p>No Top of Rack switch</p>
    <p>4x 10Gbps uplinks from the servers</p>
    <p>1,152 disks in 52U: 22 disks/U</p>
    <p>5+ PB of raw storage</p>
    <p>Pelican rack prototype</p>
    <p>Other disk-based storage: Up to 15/U</p>
    <p>Total cost of ownership comparable to tape  Lower latency than tape</p>
    <p>Challenging resource limitations managed in software</p>
  </div>
  <div class="page">
    <p>Pelican storage stack: handling right-provisioning</p>
    <p>Co-designed with hardware</p>
    <p>Constraints over sets of active disks:</p>
    <p>Hard: power, cooling, failure domains</p>
    <p>Soft: bandwidth, vibration</p>
    <p>Placement</p>
    <p>IOs to disks</p>
    <p>*.sys</p>
    <p>kernel userspace</p>
    <p>requests Blob store API</p>
    <p>Scheduler</p>
    <p>Software challenges:</p>
    <p>Data placement: concurrency of requests</p>
    <p>IO scheduling: minimize spin ups, fairness</p>
    <p>Recovery: minimize window of vulnerability</p>
    <p>In this talk</p>
  </div>
  <div class="page">
    <p>Impact of right provisioning on resources</p>
    <p>Systems provisioned for peak performance:</p>
    <p>Any disk can be active at any time</p>
    <p>Right-provisioned system:</p>
    <p>Disk part of a domain for each resource</p>
    <p>Domain supplies limited resources</p>
    <p>Disk active if enough resources in all its domains</p>
    <p>Pelican domains:</p>
    <p>power, cooling, vibration, bandwidth</p>
    <p>Resource limitations:</p>
    <p>2 active out of 16 per power domain</p>
    <p>1 active out of 12 per cooling domain</p>
    <p>1 active out of 2 per vibration domain</p>
    <p>Disk d</p>
    <p>Power domain of d</p>
    <p>Cooling domain of d</p>
    <p>Rack: 3D array of disks</p>
  </div>
  <div class="page">
    <p>Data placement: maximizing request concurrency</p>
    <p>Blob erasure-encoded on a set of concurrently active disks</p>
    <p>In fully provisioned systems:</p>
    <p>Any two sets can be active</p>
    <p>No impact of placement on concurrency</p>
    <p>In right-provisioned systems:</p>
    <p>Sets can conflict in resource requirements</p>
    <p>Conflicting cannot be concurrently active</p>
    <p>Challenge: form sets that minimize P Disks of blob 1</p>
    <p>Rack: 3D array of disks</p>
    <p>First approach: random placement</p>
    <p>Disks of blob 2</p>
    <p>Conflict Conflict</p>
  </div>
  <div class="page">
    <p>Data placement: maximizing request concurrency</p>
    <p>Blob erasure-encoded on a set of concurrently active disks</p>
    <p>In fully provisioned systems:</p>
    <p>Any two sets can be active</p>
    <p>No impact of placement on concurrency</p>
    <p>In right-provisioned systems:</p>
    <p>Sets can conflict in resource requirements</p>
    <p>Conflicting cannot be concurrently active</p>
    <p>Challenge: form sets that minimize P Disks of blob 1</p>
    <p>Rack: 3D array of disks</p>
    <p>First approach: random placement</p>
    <p>Disks of blob 2</p>
    <p>Conflict Conflict</p>
    <p>Random placement: Storing blobs on n disks,</p>
    <p>P O(n)Conflict</p>
  </div>
  <div class="page">
    <p>Pelican data placement</p>
    <p>Intuition: concentrate all conflicts over a few sets of disks</p>
    <p>Statically partition disks in groups in which disks can be concurrently active</p>
    <p>Property:</p>
    <p>Either fully conflicting</p>
    <p>Or fully independent</p>
    <p>Schematic side-view of the rack</p>
    <p>Power domain</p>
    <p>C o</p>
    <p>o li</p>
    <p>n g</p>
    <p>d o</p>
    <p>m a</p>
    <p>in</p>
    <p>Blob is stored in one group</p>
    <p>P O(n) Conflict</p>
    <p>Groups encapsulate constraints:</p>
    <p>Unit of IO scheduling</p>
    <p>No constraint management at runtime</p>
  </div>
  <div class="page">
    <p>Pelican data placement</p>
    <p>Intuition: concentrate all conflicts over a few sets of disks</p>
    <p>Statically partition disks in groups in which disks can be concurrently active</p>
    <p>Property:</p>
    <p>Either fully conflicting</p>
    <p>Or fully independent</p>
    <p>Schematic side-view of the rack</p>
    <p>Power domain</p>
    <p>C o</p>
    <p>o li</p>
    <p>n g</p>
    <p>d o</p>
    <p>m a</p>
    <p>in</p>
    <p>Blob is stored in one group</p>
    <p>P O(n) Conflict</p>
    <p>Groups encapsulate constraints:</p>
    <p>Unit of IO scheduling</p>
    <p>No constraint management at runtime</p>
  </div>
  <div class="page">
    <p>Pelican data placement</p>
    <p>Intuition: concentrate all conflicts over a few sets of disks</p>
    <p>Statically partition disks in groups in which disks can be concurrently active</p>
    <p>Property:</p>
    <p>Either fully conflicting</p>
    <p>Or fully independent</p>
    <p>Schematic side-view of the rack</p>
    <p>Power domain</p>
    <p>C o</p>
    <p>o li</p>
    <p>n g</p>
    <p>d o</p>
    <p>m a</p>
    <p>in</p>
    <p>Class: 12 fully-conflicting groups</p>
    <p>Blob is stored in one group</p>
    <p>P O(n) Conflict</p>
    <p>Groups encapsulate constraints:</p>
    <p>Unit of IO scheduling</p>
    <p>No constraint management at runtime</p>
  </div>
  <div class="page">
    <p>Pelican data placement</p>
    <p>Intuition: concentrate all conflicts over a few sets of disks</p>
    <p>Statically partition disks in groups in which disks can be concurrently active</p>
    <p>Property:</p>
    <p>Either fully conflicting</p>
    <p>Or fully independent</p>
    <p>Schematic side-view of the rack</p>
    <p>Power domain</p>
    <p>C o</p>
    <p>o li</p>
    <p>n g</p>
    <p>d o</p>
    <p>m a</p>
    <p>in</p>
    <p>Class: 12 fully-conflicting groups</p>
    <p>48 groups of 24 disks</p>
    <p>4 classes of 12 fully-conflicting groups</p>
    <p>Class is independent: concurrency = 4</p>
    <p>Blob is stored over 18 disks</p>
    <p>15+3 erasure coding  Blob is stored in one group</p>
    <p>P O(n) Conflict</p>
    <p>Groups encapsulate constraints:</p>
    <p>Unit of IO scheduling</p>
    <p>No constraint management at runtime</p>
  </div>
  <div class="page">
    <p>IO Scheduling: spin up is the new seek</p>
    <p>Four independent schedulers</p>
    <p>Each scheduler: 12 groups, only one can be active</p>
    <p>Nave scheduler: FIFO</p>
    <p>Avg. group activation time: 14.2 sec</p>
    <p>High probability of spinup after each request</p>
    <p>Time is spent doing spinups!</p>
    <p>Time</p>
    <p>Spin upSpin upSpin up</p>
    <p>Pelican scheduler: Request batching</p>
    <p>Limit on maximum re-ordering</p>
    <p>Trade-off between throughput and fairness</p>
    <p>Weighted fair-share between client and rebuild traffic</p>
    <p>Time</p>
    <p>Spin up</p>
    <p>IO batch</p>
    <p>Spin up  IO batch</p>
  </div>
  <div class="page">
    <p>Outline: challenges of right-provisioning</p>
    <p>Solution: constraint-aware data placement</p>
    <p>Solution: IO scheduler that amortizes spinup latency</p>
    <p>Last part of the talk:</p>
    <p>Performance impact of right-provisioning</p>
  </div>
  <div class="page">
    <p>Evaluating impact of right-provisioning</p>
    <p>Pelican vs. rack with all disks active (called FP)</p>
    <p>Cross-validated discrete-event simulator</p>
    <p>Metrics (more in the paper):</p>
    <p>Rack throughput</p>
    <p>Latency (time to first byte)</p>
    <p>Power consumption</p>
    <p>Open loop workload:</p>
    <p>Poisson arrival process</p>
    <p>Read requests on 1GB blobs</p>
    <p>Varying workload rate up to 8 requests/s</p>
  </div>
  <div class="page">
    <p>First step: simulator cross-validation</p>
    <p>Burst workload, varying burst intensity</p>
    <p>Simulator accurately predicts real system behaviour for all metrics. See paper for more results.</p>
    <p>T h</p>
    <p>ro u</p>
    <p>g h</p>
    <p>p u</p>
    <p>t (G</p>
    <p>b p</p>
    <p>s)</p>
    <p>Simulator</p>
    <p>Rack</p>
    <p>im e</p>
    <p>t o</p>
    <p>f ir</p>
    <p>st b</p>
    <p>y te</p>
    <p>( s)</p>
    <p>Simulator</p>
    <p>Rack</p>
    <p>Burst intensity (#req/burst) Burst intensity (#req/burst)</p>
  </div>
  <div class="page">
    <p>Rack throughput</p>
    <p>. th</p>
    <p>ro u</p>
    <p>g h</p>
    <p>p u</p>
    <p>t (G</p>
    <p>b p</p>
    <p>s)</p>
    <p>Workload rate (req/s)</p>
    <p>Random placement</p>
  </div>
  <div class="page">
    <p>Rack throughput</p>
    <p>. th</p>
    <p>ro u</p>
    <p>g h</p>
    <p>p u</p>
    <p>t (G</p>
    <p>b p</p>
    <p>s)</p>
    <p>Workload rate (req/s)</p>
    <p>FP</p>
    <p>Random placement</p>
  </div>
  <div class="page">
    <p>Rack throughput</p>
    <p>. th</p>
    <p>ro u</p>
    <p>g h</p>
    <p>p u</p>
    <p>t (G</p>
    <p>b p</p>
    <p>s)</p>
    <p>Workload rate (req/s)</p>
    <p>FP</p>
    <p>Pelican</p>
    <p>Random placement</p>
  </div>
  <div class="page">
    <p>Time to first byte</p>
    <p>T im</p>
    <p>e t</p>
    <p>o f</p>
    <p>ir st</p>
    <p>b y</p>
    <p>te (</p>
    <p>se c)</p>
    <p>Workload rate (req/s)</p>
    <p>FP Pelican</p>
  </div>
  <div class="page">
    <p>Power consumption</p>
    <p>A g</p>
    <p>g re</p>
    <p>g a</p>
    <p>te d</p>
    <p>is k</p>
    <p>p o</p>
    <p>w e</p>
    <p>r d</p>
    <p>ra w</p>
    <p>( k</p>
    <p>W )</p>
    <p>Workload rate (req/s)</p>
    <p>All disks spun down</p>
  </div>
  <div class="page">
    <p>Power consumption</p>
    <p>A g</p>
    <p>g re</p>
    <p>g a</p>
    <p>te d</p>
    <p>is k</p>
    <p>p o</p>
    <p>w e</p>
    <p>r d</p>
    <p>ra w</p>
    <p>( k</p>
    <p>W )</p>
    <p>Workload rate (req/s)</p>
    <p>All disks spun down All disks active</p>
  </div>
  <div class="page">
    <p>Power consumption</p>
    <p>A g</p>
    <p>g re</p>
    <p>g a</p>
    <p>te d</p>
    <p>is k</p>
    <p>p o</p>
    <p>w e</p>
    <p>r d</p>
    <p>ra w</p>
    <p>( k</p>
    <p>W )</p>
    <p>Workload rate (req/s)</p>
    <p>Pelican average All disks spun down</p>
    <p>All disks active</p>
  </div>
  <div class="page">
    <p>Power consumption: 3x lower peak</p>
    <p>A g</p>
    <p>g re</p>
    <p>g a</p>
    <p>te d</p>
    <p>is k</p>
    <p>p o</p>
    <p>w e</p>
    <p>r d</p>
    <p>ra w</p>
    <p>( k</p>
    <p>W )</p>
    <p>Workload rate (req/s)</p>
    <p>Pelican average All disks spun down</p>
    <p>All disks active Pelican peak</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Rack-scale hardware/software co-design  Storage right-provisioned for cold data workload</p>
    <p>Efficient constraint-aware software storage stack</p>
    <p>Prototype rack storing 5+ PB of raw data in 52U</p>
    <p>Challenging design process:</p>
    <p>Many constraints to handle manually</p>
    <p>Sensitive to hardware changes</p>
    <p>Follow up work:  Flamingo: Synthesizing cold storage stacks for Pelican-like systems</p>
    <p>See our poster in tonights session</p>
  </div>
</Presentation>
