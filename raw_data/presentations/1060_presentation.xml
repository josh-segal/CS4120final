<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>technicolor.com</p>
    <p>NICOLAS LE SCOUARNEC</p>
    <p>JOINT WORK WITH FABIEN ANDR,</p>
    <p>STPHANE GOUACHE, ANTOINE MONSIFROT</p>
  </div>
  <div class="page">
    <p>Typical internet access network</p>
    <p>Customer Premise Equipment</p>
    <p>(Residential Gateway)</p>
    <p>Access Network</p>
    <p>Internet</p>
  </div>
  <div class="page">
    <p>vCPE Rationale</p>
    <p>Simplify software running on millions of</p>
    <p>embedded devices</p>
    <p>Easier upgrades</p>
    <p>Better integration</p>
    <p>Provide visibility into home network</p>
    <p>Secure IoT</p>
    <p>Remote troubleshooting</p>
  </div>
  <div class="page">
    <p>Building middleboxes for residential networks</p>
    <p>InternetMiddlebox</p>
    <p>(e.g., NAT and Firewall)</p>
    <p>Customer Premise Equipment</p>
    <p>(Residential Gateway)</p>
    <p>Access Network</p>
  </div>
  <div class="page">
    <p>What (not) to use ?</p>
    <p>NFV approach (virtualized appliances)</p>
    <p>One VM/container per customer</p>
    <p>Running existing software (e.g., OpenWRT or Linux)</p>
    <p>As done for example in R-CORD</p>
    <p>Virtual Switches for traffic dispatching to VM</p>
    <p>Does not scale to millions of VMs/containers</p>
    <p>Not cost effective</p>
  </div>
  <div class="page">
    <p>Which equipment to use ?</p>
    <p>Vendor B</p>
    <p>(HW Appliance)</p>
    <p>Vendor C</p>
    <p>(HW Appliance)</p>
    <p>(40 cores)</p>
    <p>Vendor A</p>
    <p>(VM)</p>
    <p>StatelessNF</p>
    <p>(NSDI17)</p>
    <p>L4 Throughput</p>
    <p>(Simple IMIX)</p>
    <p>Cost 65 K$ (HW+SW) 200 K$</p>
    <p>(HW+SW)</p>
    <p>(HW)</p>
    <p>Redundancy</p>
    <p>model</p>
    <p>Objective:</p>
    <p>Available SW for running</p>
    <p>on COTS server</p>
  </div>
  <div class="page">
    <p>The residential vCPE challenge</p>
    <p>Build a middlebox (firewall, NAT, )</p>
    <p>for residential networks</p>
    <p>from COTS hardware</p>
    <p>Efficient, Reliable, Scalable</p>
    <p>L4 connection tracking</p>
    <p>For millions of users</p>
  </div>
  <div class="page">
    <p>Best practices for high-performance networking software</p>
    <p>Avoid context switches</p>
    <p>Use kernel-bypass systems (e.g., DPDK)</p>
    <p>Dont lock, dont share</p>
    <p>Cross-core sharing is expensive even without explicit locking</p>
    <p>Run-to-completion model</p>
    <p>Receive, process, transmit, without buffering nor blocking</p>
    <p>Applying all these principles everywhere is non-trivial</p>
  </div>
  <div class="page">
    <p>Reliable - sharding and replication</p>
    <p>Shard 1</p>
    <p>Shard 2</p>
    <p>Shard 3</p>
    <p>Shard 4</p>
    <p>Shard 5 Assign both a master server and</p>
    <p>a slave server to each shard Replicate state</p>
    <p>from master to slave for each shard</p>
    <p>Provide reliability by design, not as an afterthought</p>
  </div>
  <div class="page">
    <p>Replication - Availability rather than Consistency</p>
    <p>No external DB  Faster insertion and lookup rate (450M lookups/second on 18 cores)</p>
    <p>Non-blocking (no remote memory access)</p>
    <p>Availability rather than consistency  Networks are unreliable, applications will recover</p>
    <p>Yet, even short unavailabilities are noticed by user</p>
    <p>Master does not wait for acknowledgment from slave</p>
    <p>Efficient lock-less replication  Batching for improved performance</p>
    <p>Same thread for packet processing and replication</p>
    <p>Traffic not interrupted during slave initialization, using support from hash table</p>
  </div>
  <div class="page">
    <p>Efficient (I)  Sharding to the core</p>
    <p>Shard 1</p>
    <p>Shard 2</p>
    <p>Shard 3</p>
    <p>Shard 4</p>
    <p>Shard 5</p>
  </div>
  <div class="page">
    <p>Efficient (I) - Sharding to the core</p>
    <p>Shard 1</p>
    <p>Shard 2</p>
    <p>Shard 3</p>
    <p>Shard 4</p>
    <p>Shard 5</p>
    <p>Enforce share-nothing by binding each shard exclusively to a single CPU core</p>
    <p>All packet processing &amp; management done by the corresponding thread 12</p>
  </div>
  <div class="page">
    <p>Efficient (II) - Expose each core to the network</p>
    <p>Shard 1</p>
    <p>Shard 2</p>
    <p>Shard 3</p>
    <p>Shard 4</p>
    <p>Shard 5 Expose an independant identity for each core (not server nor NIC) on the network</p>
    <p>One single mechanism to address between and within servers</p>
    <p>Each core appears in the system as a independent router</p>
  </div>
  <div class="page">
    <p>Efficient (II) - Scalable load-balancing by NICs and Switches</p>
    <p>Shard 1</p>
    <p>Shard 2</p>
    <p>Shard 3</p>
    <p>Shard 4</p>
    <p>Shard 5</p>
    <p>Leverage existing top-of-rack switches and server-class NIC to entirely offload load-balancing</p>
    <p>Physical L3 Switches are much more efficient than virtual switches</p>
    <p>BGP</p>
    <p>BGP</p>
    <p>BGP</p>
    <p>IP Routing Table</p>
  </div>
  <div class="page">
    <p>Efficient (III)  Handle reverse traffic efficiently</p>
    <p>Shard 1</p>
    <p>Shard 2</p>
    <p>Shard 3</p>
    <p>Shard 4</p>
    <p>Shard 5</p>
    <p>IP Routing Table</p>
    <p>Shard 1</p>
    <p>Shard 2</p>
    <p>Shard 3</p>
    <p>Shard 4</p>
    <p>Shard 5</p>
    <p>IP routing allows precise control on reverse path and also failover path</p>
    <p>Traffic is highly asymetrical, use VLAN to improve hardware usage</p>
    <p>IP routing allows more control than RSS or ECMP based distribution</p>
    <p>VLAN 4 / VLAN 5 / 06:00:00:52:11:45 / 172.25.0.1 06:00:00:02:12:45 / 172.24.0.1</p>
    <p>IP Routing Table</p>
  </div>
  <div class="page">
    <p>Our design: benefits</p>
    <p>Distribution across servers and across cores identical</p>
    <p>Simplified implementation</p>
    <p>Performance scale linearly across cores and across servers</p>
    <p>Dynamic load-balancing included (dynamic routing + replication)</p>
    <p>Re-balance the load between servers</p>
    <p>Scale-out and in as demand evolve : elasticity</p>
    <p>Daily Internet Traffic Unused resources</p>
    <p>(75% potential savings</p>
    <p>energy, cooling,)</p>
  </div>
  <div class="page">
    <p>Benchmarking</p>
    <p>Multi-core, multi-server benchmarking tool following the same principles</p>
    <p>System under test</p>
    <p>(large-scale and multi-server)</p>
    <p>Traffic generator</p>
  </div>
  <div class="page">
    <p>Benchmarking</p>
    <p>Multi-core, multi-server benchmarking tool following the same principles</p>
    <p>System under test</p>
    <p>(large-scale and multi-server)</p>
  </div>
  <div class="page">
    <p>Performance</p>
    <p>Linux (e.g., R-CORD)</p>
    <p>Krononat</p>
    <p>M p</p>
    <p>p s</p>
    <p>Performance (12 cores) for established connections</p>
  </div>
  <div class="page">
    <p>Scalability</p>
    <p>M p</p>
    <p>p s</p>
    <p>Core</p>
    <p>Performance for established connections</p>
    <p>Linux Krononat (without replication) Krononat (with replication) Objective</p>
    <p>Objective:</p>
  </div>
  <div class="page">
    <p>Availability - Server departure</p>
    <p>o c c u</p>
    <p>rr e</p>
    <p>n c e</p>
    <p>s</p>
    <p>Service interruption duration (ms)</p>
    <p>Less than 600 ms  below network timeouts</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Resilient distributed middlebox using COTS hardware  77 million packets per second on only 12 cores</p>
    <p>6,4 Mpps/core above objective (4,5 Mpps/core)  Recover from failures automatically without users noticing</p>
    <p>Cost-effective N+1 redundancy</p>
    <p>Redundancy and dynamic load-balancing allow elasticity</p>
    <p>Re-usable design  Expose each core as a distinct entity to the network</p>
    <p>Push per-core traffic steering to the networking equipments (NIC, switches)</p>
    <p>Applied to multi-server multi-core benchmarking tool</p>
  </div>
  <div class="page">
    <p>References</p>
    <p>Dont share, Dont lock: Large-scale Software Connection Tracking with Krononat</p>
    <p>Fabien Andr, Stphane Gouache, Nicolas Le Scouarnec and Antoine Monsifrot</p>
    <p>USENIX ATC18</p>
    <p>Cuckoo++ Hash Tables: High-Performance Hash Tables for Networking</p>
    <p>Applications</p>
    <p>Nicolas Le Scouarnec</p>
    <p>ACM/IEEE ANCS18</p>
  </div>
  <div class="page">
    <p>APPENDIX</p>
  </div>
  <div class="page">
    <p>Building a distributed software CG-NAT/FW/</p>
    <p>Bi-directional traffic</p>
    <p>Must filter unknown connections</p>
    <p>L4 Load-balancers</p>
    <p>Maglev</p>
    <p>Ananta</p>
    <p>Fastly@NSDI</p>
    <p>SilkRoad</p>
    <p>Access network</p>
    <p>No-reverse path traffic (DSR)</p>
    <p>Leverage deterministic hashing</p>
  </div>
  <div class="page">
    <p>Availability : Graceful departure</p>
    <p>o c c u</p>
    <p>rr e</p>
    <p>n c e</p>
    <p>s</p>
    <p>Service interruption duration (ms)</p>
    <p>Failure detection and recovery</p>
    <p>Load</p>
    <p>rebalancing</p>
  </div>
  <div class="page">
    <p>Availability : Hard Failure</p>
    <p>o c c u</p>
    <p>re n</p>
    <p>c e</p>
    <p>s</p>
    <p>Service interruption duration (ms)</p>
    <p>Failure detection and recoveryLoad</p>
    <p>rebalancing</p>
    <p>Less than 7s  below many network timeouts</p>
  </div>
</Presentation>
