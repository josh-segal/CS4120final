<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Towards Linux Open Telecom Platforms</p>
    <p>Ibrahim.Haddad@Ericsson.com Open Systems Lab  Ericsson Research</p>
    <p>http://www.Linux.Ericsson.ca</p>
    <p>USENIX</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>From proprietary to open platforms</p>
    <p>Open, standardized, and components-based platforms</p>
    <p>Carrier Grade Linux: architecture, working group, requirements</p>
    <p>Examples of needed features</p>
    <p>Challenges</p>
  </div>
  <div class="page">
    <p>Yesterday vs. Today</p>
    <p>Traditionally</p>
    <p>Communications and data service networks were built on proprietary platforms that had to meet very specific requirements in areas of:</p>
    <p>availability,  reliability,  performance, and  service response time.</p>
    <p>Today</p>
    <p>Communications service providers are challenged to meet their needs cost-effectively for new services and new architectures while maintaining highly available, scalable, secure, and reliable systems that have predictable performance and that are easy to maintain and upgrade.</p>
  </div>
  <div class="page">
    <p>Proprietary vs. Open Platforms</p>
    <p>Proprietary platforms are:  closed systems,</p>
    <p>expensive to develop, and</p>
    <p>often lacking support of the current and upcoming standards.</p>
    <p>The current trend is to deliver the next generation communication services using carrier grade platforms that are designed and implemented using common-off-the-shelf SW and HW components as building blocks.</p>
  </div>
  <div class="page">
    <p>Proprietary to Open and Standardized Solutions</p>
    <p>Standards-BasedProprietary</p>
    <p>Network Element</p>
    <p>Proprietary Hardware</p>
    <p>Proprietary Applications</p>
    <p>Proprietary HA Middleware</p>
    <p>Proprietary Real-time Operating System</p>
    <p>Network Element</p>
    <p>Standard HA Hardware</p>
    <p>Proprietary and 3rd Party Applications</p>
    <p>HA Middleware</p>
    <p>Standard Carrier Grade Operating System</p>
    <p>Application Interface</p>
    <p>Hardware Interface</p>
    <p>SA Forum Interfaces</p>
    <p>PICMG ATCA</p>
    <p>Carrier Grade Linux</p>
    <p>From proprietary to open, standardized, &amp; component based HW and SW Solutions</p>
  </div>
  <div class="page">
    <p>Motivations for Open Platforms</p>
    <p>There are many motivations behind the trend of migrating towards open platforms that are based on open standards:  Ensure portability, and integration capabilities,  Ensure interoperability with third-party software,  Make application development easier,  Provide faster time to market,  Ensure lower costs using COTS components, and  Help focus on core competencies to allow faster</p>
    <p>innovation.</p>
  </div>
  <div class="page">
    <p>Linux Kernel with Carrier Grade Enhancements</p>
    <p>Standard Interfaces (LSB, POSIX...)</p>
    <p>High Availability Interfaces Service Interfaces</p>
    <p>Hardened Device Drivers Co-Processor Interfaces Hardware Configuration &amp; Management Interfaces</p>
    <p>Platform Management Middleware</p>
    <p>Applications</p>
    <p>Application Management and High Availability Services Middleware</p>
    <p>Database Communication Directory Protocols</p>
    <p>S y s te</p>
    <p>m M</p>
    <p>a n</p>
    <p>a g</p>
    <p>e m</p>
    <p>e n</p>
    <p>t</p>
    <p>High Availability Hardware Platforms</p>
    <p>S o</p>
    <p>ftw a re</p>
    <p>D e v e lo</p>
    <p>p m</p>
    <p>e n</p>
    <p>t T o</p>
    <p>o ls</p>
    <p>Who is defining what?</p>
    <p>Hardware Platform Interface Specification</p>
    <p>Application Interface Specification</p>
    <p>Scope of</p>
    <p>HA HW (ATCA)</p>
  </div>
  <div class="page">
    <p>Carrier Grade Linux</p>
    <p>What, who, why, architecture, specs, roadmap, etc.</p>
  </div>
  <div class="page">
    <p>What is Carrier Grade?</p>
    <p>Carrier Grade is a term for public network telecommunications products that require a reliability percentage up to 5 or 6 nines  5 nines (99.999%) -- associated with Carrier Grade servers</p>
    <p>Less than 5 minutes of downtime per year  6 nines (99.9999%) -- associated with Carrier Grade switches</p>
    <p>Less than 30 seconds of downtime per year</p>
    <p>Carrier Grade Linux is a flavor of Linux targeted for communication platforms.</p>
  </div>
  <div class="page">
    <p>CGL Working Group</p>
    <p>An industry forum to support and accelerate the development of Linux functionality for</p>
    <p>telecommunication applications</p>
    <p>MEMBER COMPANIES</p>
  </div>
  <div class="page">
    <p>CGL Architecture</p>
    <p>Solution-specific components to be defined by vendors</p>
    <p>Scope of the Carrier Grade Linux Working Group</p>
    <p>Applications</p>
    <p>Middleware Components</p>
    <p>High Availability Hardware Platforms</p>
    <p>High Availability ComponentsHA Platform Interfaces</p>
    <p>HA Application Interfaces</p>
    <p>Java CORBA Databases ...</p>
    <p>Linux OS with Carrier Grade Enhancements</p>
    <p>Standard Interfaces (LSB, POSIX...)</p>
    <p>High Availability Interfaces Service Interfaces</p>
    <p>Hardened Device Drivers Co-Processor Interfaces Hardware Configuration and</p>
    <p>Management Interfaces</p>
  </div>
  <div class="page">
    <p>Carrier Grade Linux (CGL) Summary</p>
    <p>CGL Working Group Started January, 2002</p>
    <p>CGL Version 1.1  Released October 2002  CGL 1.1 based distributions are already available in the market</p>
    <p>CGL Version 2.0  Released October 2003  CGL 2.0 based distribution are expected to be available by Q1 2005</p>
    <p>CGL Version 3.0  First public draft was released in May 2004</p>
  </div>
  <div class="page">
    <p>CGL Specs Requirement Categories</p>
    <p>Standards: CGL specifies standards, important to Carrier Grade servers, that are required for compliance.</p>
    <p>Examples: LSB, POSIX, IETF RFCs, and SA Forum compliance, etc.</p>
    <p>Platform: Support interactions with the hardware platforms.</p>
    <p>Examples: Hot swap, hot insert, hot remove, hot device identity, Remote boot, support for diskless systems, boot cycle detection, etc.</p>
    <p>Availability: Support heightened availability of carrier grade servers and aim to improve the robustness of SW components and support recovery from failure of HW or SW.</p>
    <p>Examples: Watchdog timer, Application heartbeat, RAID Support, Disk and volume management, Hardened driver support, etc.</p>
  </div>
  <div class="page">
    <p>CGL Specs Requirement Categories</p>
    <p>Serviceability: Support servicing and managing HW and SW on carrier server systems.  Examples: Resource monitoring, Kernel dumps, etc.</p>
    <p>Tools: Support auxiliary capabilities not directly involved in normal execution of carrier server systems.  Examples debuggers used to develop modules, drivers, applications, etc.</p>
    <p>Performance: Support performance levels necessary for the environments expected to be encountered by carrier server systems.  Examples: Soft real time support, Raid 0 support, Application (pre)</p>
    <p>loading, etc.</p>
    <p>Security: Features for building secure systems. one size fits all is not achievable; therefore, not all features will always be used together.</p>
  </div>
  <div class="page">
    <p>CGL Specs Requirement Categories</p>
    <p>Clustering: Requirements that support the use of multiple carrier server systems to provide a horizontally-scaled environment supporting increased throughput and to support higher levels of service availability through redundant resources and recovery capabilities.</p>
    <p>Scalability: Requirements that support vertical and horizontal scaling of carrier server systems such  Addition of HW resources results in acceptable increases in capacity.</p>
  </div>
  <div class="page">
    <p>Integration with Mainstream Linux Kernel</p>
    <p>Integration with the kernel takes time</p>
    <p>Some of the enhancements will be or are already proposed for kernel 2.7 integration</p>
    <p>Others will follow in later kernel releases</p>
    <p>All enhancements are available from their SourceForge or project web sites</p>
    <p>Linux Kernel</p>
    <p>Serviceability</p>
    <p>Process Management</p>
    <p>Clustering Support</p>
    <p>Standards</p>
    <p>Reliability</p>
    <p>Memory Management</p>
    <p>Security</p>
    <p>Performance</p>
    <p>Availability</p>
    <p>Enhancing the Linux Kernel with Carrier Grade Characteristics</p>
  </div>
  <div class="page">
    <p>Examples of Needed Features for Server Nodes Operating in Mission Critical</p>
    <p>Environments</p>
    <p>TIPC, DigSig, AEM</p>
  </div>
  <div class="page">
    <p>TIPC: Transparent Inter-Process Communication Protocol</p>
    <p>Contact info: Jon Maloy</p>
    <p>JonMaloy@users.sourceforge.net</p>
  </div>
  <div class="page">
    <p>Linux Inter-Cluster Communication Protocol</p>
    <p>TIPC is a specially designed protocol for intra-cluster communication.</p>
    <p>Supports inter cluster communication too.</p>
    <p>Provides a framework for supervising and reporting topology changes.</p>
    <p>It is provided as a portable source code package, ~14000 lines C code</p>
    <p>It has been used as a part of Ericsson products for years, deployed at hundreds of sites around the globe.</p>
    <p>TIPC is a useful toolbox for anyone wanting to develop/use HA/Carrier Grade Linux clusters.</p>
    <p>It provides the necessary infrastructure for cluster, network and software management functionality.</p>
    <p>It provides a good support for designing scalable, distributed, site independent, highly available, and high-performance applications.</p>
  </div>
  <div class="page">
    <p>TIPC Status</p>
    <p>TIPC &amp; Linux Kernel:</p>
    <p>TIPC is supported on both 2.4 and 2.6 kernel series</p>
    <p>After receiving feedback, TIPC code was changed to make it more suitable for inclusion in the kernel.</p>
    <p>TIPC was released to Open Source on February 3, 2003 and announced on LKML on June 28, 2004 (http://lwn.net/Articles/91634/)</p>
    <p>TIPC &amp; CGL:</p>
    <p>TIPC meets several Priority 1 and Priority 2 Cluster Communication Requirements in CGL 2.0.</p>
    <p>General Interest in TIPC:</p>
    <p>TIPC received a lot of interest from commercial sector and Linux Distributors.</p>
    <p>The IETF ForCES (Forwarding and Control Element Separation) working group is interested in using TIPC as the standard transport protocol for distributed routers.</p>
  </div>
  <div class="page">
    <p>DigSig: Distributed Digital Signature</p>
    <p>Contact info: Makan Pourzandi</p>
    <p>Makan@users.sourceforge.net</p>
  </div>
  <div class="page">
    <p>Distributed Signature Verification (DigSig)</p>
    <p>DigSig is part of a larger project called the Distributed Security Infrastructure (DSI).</p>
    <p>DSI started as a research project in Ericsson in 2001 to provide a security framework for real-time distributed applications running on large scale carrier grade Linux clusters.</p>
    <p>DSI was released to Open Source in January 2003 under the GPL license.</p>
  </div>
  <div class="page">
    <p>DigSig</p>
    <p>DigSig is a kernel module that inserts digital signatures inside the ELF binary and verifies this signature before loading the binary.</p>
    <p>It is based on the Linux Security Module (LSM) hooks.</p>
    <p>The DigSig approach has been to use the existing solutions like GPG and BSign.</p>
    <p>The local administrator signs binaries they trusts with their private key.</p>
    <p>DigSig guarantees two things:</p>
    <p>If you signed a binary, nobody else can modify that binary without being detected, and</p>
    <p>Nobody can run a binary which is not signed, or badly signed.</p>
  </div>
  <div class="page">
    <p>DigSig Status</p>
    <p>DigSig &amp; Linux Kernel:</p>
    <p>DigSig is supported on kernel series 2.5 and 2.6</p>
    <p>It was announced on LKML on Sept 17, 2003 http://lwn.net/Articles/49640</p>
    <p>DigSig &amp; CGL:</p>
    <p>DigSig meets a Priority 1 security requirement in OSDL CGL 2.0.</p>
    <p>General Interest in DigSig:</p>
    <p>Patched by Hardened Gentoo Linux distribution developers to be used as a secondary kernel module with SE Linux.</p>
    <p>Submitted to SE Linux mailing list.</p>
    <p>There is a lot of interest from commercial companies</p>
  </div>
  <div class="page">
    <p>Kernel Asynchronous Event Mechanism</p>
    <p>Contact info: Frederic Rossi</p>
    <p>FJRossi@users.sourceforge.net</p>
  </div>
  <div class="page">
    <p>Why we need support for Asynchronous Event Mechanism?  Communication Applications Requirements include:</p>
    <p>A highresponse rate,  A minimum down-time,  Scalability w.r.t external requests and hardware,  Soft Real-Time capabilities (Hard Real-Time capabilities in some cases)</p>
    <p>Carrier Grade Platform Requirements include:  Live software upgrade, hardware hot-swap,  Large database, fail-over, memory utilization  Huge number of processes, fault detection and prevention, application</p>
    <p>restart, process reload,</p>
    <p>Carrier Grade systems must handle many events quickly</p>
  </div>
  <div class="page">
    <p>Asynchronous Event Mechanism Project</p>
    <p>AEM implements a native support for asynchronous events in the Linux kernel and aims to bring carriergrade characteristics to Linux in areas of scalability and soft real-time responsiveness.</p>
    <p>AEM targets applications scalability</p>
    <p>AEM is implemented as a kernel patch and a set of modules.</p>
    <p>It was released to Open Source in January 2003 under the GPL license.</p>
  </div>
  <div class="page">
    <p>AEM Status</p>
    <p>AEM &amp; Linux Kernel:</p>
    <p>AEM is supported on both Linux Kernel series 2.4 and 2.6.</p>
    <p>AEM was announced on LKML</p>
    <p>Received a lot of feedback, and undergone a lot of design/implementation changes since then.</p>
    <p>AEM &amp; CGL:</p>
    <p>AEM implements a Priority 1 requirement of OSDL CGL 2.0: Efficient Low-Level Asynchronous Events</p>
    <p>Currently</p>
    <p>AEM is undergoing testing and stabilization.</p>
  </div>
  <div class="page">
    <p>Conclusion!</p>
  </div>
  <div class="page">
    <p>Challenges</p>
    <p>The migration of Carrier Grade servers towards Linux is dependent on:  The availability of kernel mechanisms and features needed by such</p>
    <p>servers operating in mission critical environments, and</p>
    <p>The integration of these mechanisms into the kernel (including AEM, TIPC, DigSig)</p>
    <p>Other challenges include:  Changing ways of working, as part of interacting with Open Source and</p>
    <p>following more open working methods  Avoiding duplicated efforts  Harmony and synergy among all efforts  Building enablers together</p>
  </div>
  <div class="page">
    <p>Thank you. Questions?</p>
    <p>Ibrahim Haddad Researcher Research and Innovation</p>
    <p>Ericsson Canada Inc. 8400 Decarie Blvd Phone: 1.514.345.7900 x5484 Town of Mount Royal Fax: 1.514.345.6105 Quebec H4P 2N2 Web: http://www.linux.ericsson.ca Canada Email:Ibrahim.Haddad@Ericsson.com</p>
  </div>
  <div class="page">
    <p>Resources</p>
    <p>Ericsson Open Systems Lab http://www.linux.ericsson.ca</p>
    <p>TIPC http://tipc.sourceforge.net http://www.ietf.org/internet-drafts/draft-maloy-tipc-00.txt</p>
    <p>DSI http://tipc.sourceforge.net</p>
    <p>AEM http://aem.sourceforge.net</p>
    <p>OSDL http://www.osdl.org</p>
  </div>
  <div class="page">
    <p>Backup slides</p>
  </div>
  <div class="page">
    <p>Linux for Telecom Platforms</p>
    <p>Will next generation &amp; multimedia communication services be delivered using Linux-based open standard platforms?</p>
  </div>
  <div class="page">
    <p>Motivations for Linux</p>
    <p>Cost: Linux is available for free. No runtime royalties.  Availability of source code: We have full access to the source code</p>
    <p>allowing us to tailor the kernel to our needs.  Open development process: The development process of the</p>
    <p>kernel is open to anyone to participate and contribute.  The process is based on the concept of release early, release often.</p>
    <p>Peer review &amp; testing resources: With access to the source code, people using a wide variety of platforms &amp; compiler combinations can compile, link, and run the code on their systems to test for portability, compatibility and bugs.</p>
    <p>Vendor independent: No longer locked-in to a specific vendor.  Openness: In terms of hw, languages, interoperability, 3rd party sw.</p>
  </div>
  <div class="page">
    <p>Motivations for Linux</p>
    <p>High innovation rate: New features are usually implemented on Linux before they are available on commercial or proprietary systems.</p>
    <p>Open for all:</p>
    <p>People can contribute to Linux the required hooks for efficient integration of the upper-layer HA middleware.</p>
    <p>People can rapidly fix faults or add features to the kernel.  Other contributing factors:</p>
    <p>Support for a broad range of processors &amp; peripherals  Availability of commercial support  High performance networking,  A proven record of being a stable, and reliable server platform.</p>
  </div>
  <div class="page">
    <p>CGL Working Method</p>
    <p>Technical Specifications</p>
    <p>CGL Distributions</p>
    <p>CGL Marketing WG</p>
    <p>CGL Marketing WG</p>
    <p>Marketing Requirements</p>
    <p>(MRD) CGL Technical</p>
    <p>WG CGL Technical</p>
    <p>WG</p>
    <p>CGL Registration</p>
    <p>WG</p>
    <p>CGL Registration</p>
    <p>WG</p>
    <p>Carriers, ISP, etc.</p>
    <p>Open Source POC Projects</p>
    <p>Network Equipment Providers</p>
    <p>Middleware Providers</p>
    <p>Independent Software Vendors</p>
    <p>Platform Providers</p>
    <p>Linux Distributors</p>
    <p>OSDL Members 6</p>
    <p>CGL Steering Group</p>
    <p>Open Source Development Community</p>
    <p>Mutual Contribution</p>
    <p>Register Distro</p>
    <p>Special Interest Groups (Clustering,</p>
    <p>Security, etc)</p>
    <p>Special Interest Groups (Clustering,</p>
    <p>Security, etc)</p>
    <p>OSDL Members</p>
    <p>Contributions</p>
  </div>
  <div class="page">
    <p>CGL Benefits</p>
    <p>For NEPs and platform providers:  Lower cost  Faster TTM  Leverage COTS hardware  Flexible service models</p>
    <p>For Linux vendors  Consolidated customer requirements  Customer and community support for open source developments  Exchange consideration for reference implementations</p>
    <p>For member companies (in general)  chance to communicate members' customers requests to tune the requirements as</p>
    <p>they go into the ecosystem  to reduce individual investments in the development of capabilities  to leverage open source expertise in working with the development community</p>
  </div>
  <div class="page">
    <p>What does OSDL/CGL expect from the community</p>
    <p>From the development community at large: Nothing. Making demands on the development community is not only like pushing a chain, it creates animosity.</p>
    <p>From the member companies:  well defined capabilities that represent real customer requirements</p>
    <p>sample/reference implementations that deserve consideration for acceptance in the open source community.</p>
    <p>cooperation with other member companies in determining common objectives and capability requirements.</p>
  </div>
  <div class="page">
    <p>Changes to TIPC</p>
    <p>Code style, code and directory structure</p>
    <p>Memory management, lock handling, and debug support has been completely rewritten.</p>
    <p>Adhering to the standard mechanisms and techniques used in the Linux kernel (for example TIPC now relies entirely on the linux native memory management)</p>
    <p>Changing configuration support,</p>
    <p>The API has been rewritten, and is now as conformant to POSIX</p>
    <p>We have modified the protocol header and added the framework for providing reliable multicast, among other things.</p>
    <p>We have also added an unreliable transfer mode&quot; which can be set per socket.</p>
    <p>etc</p>
  </div>
  <div class="page">
    <p>Distributed Security Infrastructure</p>
    <p>Primary Security Server Node</p>
    <p>Node 1 Node 2 Node 3</p>
    <p>DSMSS DSM DSM</p>
    <p>Proc123 Proc978 Proc222</p>
    <p>K er</p>
    <p>n e l</p>
    <p>Security Broker</p>
    <p>Secondary</p>
    <p>Data TrafficIn si</p>
    <p>de th</p>
    <p>e C</p>
    <p>l u s t</p>
    <p>er</p>
    <p>Security and O&amp;M/IDS</p>
    <p>O ut</p>
    <p>si d e</p>
    <p>th e</p>
    <p>C lu</p>
    <p>st er</p>
    <p>SS Security Server</p>
    <p>SM Security Manager Authenticated Encrypted Communications</p>
    <p>SMSMSM</p>
    <p>DSM Distributed Security Module</p>
  </div>
  <div class="page">
    <p>DigSig</p>
    <p>The DigSig approach has been to use the existing solutions like GPG and BSign rather than reinventing the wheel.</p>
    <p>To reduce the overhead in the kernel, DigSig took the minimum code necessary from GPG.</p>
    <p>This helped reduce the amount of code imported to the kernel in source code of the original (only 1/10 of the original GnuPG 1.2.2 source code has been imported to the kernel module).</p>
  </div>
  <div class="page">
    <p>aem vs. epoll</p>
    <p>AEM and epoll are quite difference mechanisms:  AEM provides a generic asynchronous support to applications  epoll is a synchronous (polling) system call for read/write/exception</p>
    <p>changes on standard descriptors.</p>
    <p>AEM provides many modules/functionalities that are not in the scope of select/poll/epoll:  POSIX timers  File change notification  TIPC asynchronous interface  Asynchronous accept()  Asynchronous closing socket notification  Process death notification</p>
    <p>More coming soon</p>
  </div>
  <div class="page">
    <p>On Performance</p>
    <p>AEM targets application scalability  epoll is a select/poll optimization</p>
    <p>Benchmarks:  A benchmark is available on the web site of AEM</p>
    <p>http://aem.sourceforge.net</p>
    <p>AEMhttpd is an adaptation of dphttpd written to benchmark epoll and figures are available from: http://lse.sourceforge.net/epoll/index.html</p>
  </div>
  <div class="page">
    <p>Support for Multi-FIP (Multiple Forwarding Information Bases)</p>
  </div>
  <div class="page">
    <p>Background</p>
    <p>Routers are core elements of modern telecom networks.  They propagate and direct billion of data packets everyday  They must operate as fast as the medium in order to deliver excellent</p>
    <p>quality of service and have a negligible effect on communications.  The Linux IP stack works fine for home or small business routers.</p>
    <p>We are able to achieve around 2.000 routes/sec.  However, with the high requirements and the new HW capabilities, it</p>
    <p>appears as barely possible to use Linux as an efficient forwarding and routing element of a high-end router for large network (core/border/access router) or a high-end server with routing capabilities.</p>
    <p>Our target with Linux is to achieve is a predictable performance from 10.000 to 500.000 routes per second.</p>
  </div>
  <div class="page">
    <p>Support for Multi-FIP -- Problem Statement</p>
    <p>Lack of support for multi-FIB with overlapping interface's IP address</p>
    <p>Lack of appropriate interfaces for addressing FIB</p>
    <p>Limited scalability of the routing table  Lack of predictable performance: In environments that require</p>
    <p>predictable performance, different kinds of problems arise:  We are not able to predict access time, because of the chaining in</p>
    <p>the hash table of the routing cache.  The route cache and the routing table are not kept synchronized</p>
    <p>most of the time (path MTU, just to name one).  The route cache flush is executed regularly; therefore, any updates</p>
    <p>on the cache are lost and they need to be rebuilt.</p>
  </div>
  <div class="page">
    <p>What is the solution?</p>
    <p>Solution: Provide support for multi-FIB with overlapping IP address, as such, we can have on different VLAN or different physical interfaces, independent network in the same Linux box.</p>
    <p>Advantages: We can have one Linux box serving two different customers using the same IP address. ISPs adopt this approach by providing services for multiple customers sharing the same server (server partitioning), instead of using a server per customer.</p>
  </div>
  <div class="page">
    <p>Example</p>
    <p>We can have two HTTP servers serving two different networks with potentially the same IP address. One HTTP server will serve the network/FIB 10, and the other HTTP server will serves the network/FIB 20.</p>
    <p>I</p>
    <p>P</p>
    <p>S</p>
    <p>T</p>
    <p>A</p>
    <p>C</p>
    <p>K</p>
    <p>FIB 20</p>
    <p>FIB 10</p>
    <p>Kernel User</p>
    <p>HTTPD 10</p>
    <p>HTTPD 20</p>
  </div>
  <div class="page">
    <p>How to achieve this?</p>
    <p>The way to achieve this is to have an ID (an identifier that identifies the customer or user of the service) to completely separate the routing table in memory.</p>
    <p>Two approaches exist: 1. Have separate routing tables, each routing table is looked up by</p>
    <p>their ID; within that table the lookup is done on the prefix.</p>
    <p>Key = ID + Prefix</p>
  </div>
  <div class="page">
    <p>Support for Multi-FIP -- What is needed?</p>
    <p>To support routing requirements of server nodes operating in high performance mission critical environments, Linux should support: 1. An implementation of multi-FIB using tree (radix, patricia, etc.):</p>
    <p>It is very important to have predictable performance in insert/delete/lookup from 10.000 to 500.000 routes.</p>
    <p>It is favorable to have the same data structure for both IPv4 and IPv6.</p>
    <p>Affected areas in the kernel:  Network layer (large changes): net/core, net/ipv4, net/ipv6  Transport layer (minimal impact): socket, TCP, UDP, RAW,</p>
    <p>NAT, IPIP, IGMP, etc.</p>
  </div>
</Presentation>
