<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Jinho Hwang and Timothy Wood George Washington University</p>
  </div>
  <div class="page">
    <p>Two orders of magnitude more reads than writes  Solution: Deploy memcached hosts to handle the read</p>
    <p>capacity</p>
    <p>Background: Memory Caching</p>
    <p>Web Server</p>
    <p>DB Memcache</p>
    <p>DB DB</p>
  </div>
  <div class="page">
    <p>Databases are hard to scale Memcached is easy o Facebook has 10,000+ memcached servers</p>
    <p>Partition data and divide key space among all nodes</p>
    <p>o Simple data model. Stupid nodes.</p>
    <p>Web application must track where each object is stored o Or use a proxy like moxi</p>
    <p>Memcached at Scale</p>
    <p>Clients Web Servers</p>
    <p>moxi</p>
    <p>DB Memcached nodes</p>
  </div>
  <div class="page">
    <p>Random placement  Skewed popularity distributions</p>
    <p>Scales easily, but loads are imbalanced</p>
    <p>Load on Wikipedias memcached servers</p>
  </div>
  <div class="page">
    <p>Consistent hashing does not evenly load data across memory cache servers o Variation in number of keys assigned to each server o Key popularity is skewed and changes over time</p>
    <p>Solution: dynamically balance load according to the performance</p>
    <p>Motivation</p>
    <p>H as</p>
    <p>h S</p>
    <p>pa ce</p>
    <p>( 0</p>
    <p>Time (5 hours)</p>
    <p>Unpopular region (65%)</p>
    <p>Popular region (35%)</p>
    <p>Based on Wikipedia 2008 database dump and access trace</p>
  </div>
  <div class="page">
    <p>A hash space allocation scheme o allows for targeted load shifting between unbalanced</p>
    <p>servers  Adaptive partitioning of the caches hash space</p>
    <p>o automatically meet hit rate and server utilization goals  An automated replica management system</p>
    <p>o adds or removes cache replicas based on overall cache performance</p>
    <p>Contributions</p>
  </div>
  <div class="page">
    <p>Background and Motivation</p>
    <p>Initial Hash Space Partitioning</p>
    <p>Dynamic Adaptation</p>
    <p>Evaluation</p>
    <p>Conclusions</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Simple Hashing o hash(key) % [# of server] o Once assigned, never changes o If node added or removed, all objects</p>
    <p>need to be rearranged</p>
    <p>Consistent hashing o Treat hash space as ring with nodes</p>
    <p>assigned to each region o Node addition / removal only affects</p>
    <p>adjacent nodes o Used in P2P systems and by popular</p>
    <p>memcached proxy system Moxi</p>
    <p>Background: Hash Space Allocation</p>
    <p>N1</p>
    <p>N2</p>
    <p>N3</p>
    <p>N4</p>
    <p>N2</p>
    <p>N3</p>
    <p>N1</p>
    <p>N4</p>
    <p>Key Hash Space 2^32</p>
    <p>Key</p>
    <p>belong to</p>
    <p>Memory Server</p>
    <p>Memory Server</p>
    <p>Memory Server</p>
    <p>Load Balancer server[key % 3]</p>
  </div>
  <div class="page">
    <p>To enable efficient repartitioning of the hash space: o Every node is adjacent to every other node o This allows a simple transfer of load between two nodes by</p>
    <p>adjusting just one boundary</p>
    <p>Required number of duplicate nodes =  Total number of nodes =  Multiply number of virtual nodes</p>
    <p>Initial Assignment</p>
    <p>N1 N2 N3 N4 N5 N1 N3 N5 N2</p>
    <p>N4</p>
    <p>N3N1N4N2N5N4N1N5N3 N2</p>
  </div>
  <div class="page">
    <p>Two factors to measure server performance: o Hit rate: enough memory for popular data o Usage ratio: server processing</p>
    <p>Minimize {cost = hit rate + usage ratio}</p>
    <p>Scheduling decision: o Find the most different two memory servers o Find the most different two adjacent virtual nodes</p>
    <p>Size of hash space moved at each scheduling decision o Determine the speed of adaptability, but more fluctuation o Using ratio value:</p>
    <p>Dynamic Hash Space Scheduling</p>
  </div>
  <div class="page">
    <p>Balance out the requests across replicas that overall performance improves</p>
    <p>Highly overloaded server(s) sustaining a certain period of time should be backed by new server(s)</p>
    <p>Find the most costly memory server, and its virtual node</p>
    <p>Find the least costly memory server, and its virtual node</p>
    <p>Node Addition / Removal</p>
    <p>sksi Migrate</p>
    <p>new node sj</p>
    <p>Node Addition</p>
    <p>Set</p>
    <p>removed sksi sjsi</p>
    <p>Set</p>
    <p>moved</p>
    <p>Node Removal</p>
  </div>
  <div class="page">
    <p>Background and Motivation</p>
    <p>Initial Hash Space Partitioning</p>
    <p>Dynamic Adaptation</p>
    <p>Evaluation</p>
    <p>Conclusions</p>
    <p>Outline</p>
  </div>
  <div class="page">
    <p>Lab setup o Five experimental servers(4 Intel Xeon X3450 2.67GHz</p>
    <p>processor, 16GB, and a 500GB 7200RPM hard drive)  Amazon setup</p>
    <p>o 15 medium instances</p>
    <p>All workloads are from Wikipedia data and access traces</p>
    <p>Experimental Setup</p>
    <p>Clients</p>
    <p>memcd memcd memcd</p>
    <p>memcd memcd memcd</p>
    <p>Memory Pool50 1 2 3 4</p>
    <p>Proxy Elastic Decision (+/-)</p>
    <p>memcd</p>
    <p>web</p>
  </div>
  <div class="page">
    <p>5 memory servers used (total 500 virtual nodes) o For consistent hashing, 100 virtual nodes per each server o For our scheme, the initial set is 5 x 4 = 20, and 25 virtual</p>
    <p>nodes per node</p>
    <p>The largest gap between the biggest hash size and the smallest hash size is 381,114,554 ( 20% more)</p>
    <p>Initial Hash Space Assignment</p>
    <p>Se rv</p>
    <p>er N</p>
    <p>um be</p>
    <p>r</p>
    <p>Se rv</p>
    <p>er N</p>
    <p>um be</p>
    <p>r</p>
    <p>Hash Space (0 - 232)</p>
    <p>H as</p>
    <p>h Sp</p>
    <p>ac e</p>
    <p>Si ze</p>
    <p>(x 10</p>
    <p>Consistent Adaptive</p>
  </div>
  <div class="page">
    <p>Dynamic Partitioning</p>
    <p>H as</p>
    <p>h Sp</p>
    <p>ac e</p>
    <p>(0</p>
    <p>Time (5 hours)</p>
    <p>Host 1 Host 2 Host 3</p>
    <p>= 1.0 (only hit rate)</p>
    <p>= 0 (only usage ratio)</p>
    <p>H it</p>
    <p>R at</p>
    <p>e</p>
    <p>Time (5 hours)</p>
    <p>Host 1 Host 2 Host 3</p>
    <p># of</p>
    <p>R eq</p>
    <p>ue st</p>
    <p>s (p</p>
    <p>er m</p>
    <p>in )</p>
    <p>Time (5 hours)</p>
    <p>Host 1 Host 2 Host 3</p>
    <p># of</p>
    <p>R eq</p>
    <p>ue st</p>
    <p>s (p</p>
    <p>er m</p>
    <p>in )</p>
    <p>Time (5 hours)</p>
    <p>Host 1 Host 2 Host 3</p>
    <p>H as</p>
    <p>h Sp</p>
    <p>ac e</p>
    <p>(0</p>
    <p>Time (5 hours)</p>
    <p>Host 1 Host 2 Host 3</p>
    <p>H it</p>
    <p>R at</p>
    <p>e</p>
    <p>Time (5 hours)</p>
    <p>Host 1 Host 2 Host 3</p>
  </div>
  <div class="page">
    <p>When  = 0.5,  = 0.01</p>
    <p>Behavior</p>
    <p>H it</p>
    <p>R at</p>
    <p>e</p>
    <p>Time (5 hours)</p>
    <p>Host 1 Host 2 Host 3</p>
    <p># of</p>
    <p>R eq</p>
    <p>s pe</p>
    <p>r m in</p>
    <p>(x 10</p>
    <p>Time (5 hours)</p>
    <p>Host 1 Host 2 Host 3</p>
    <p>C os</p>
    <p>t</p>
    <p>Time (5 hours)</p>
    <p>Host 1 Host 2 Host 3</p>
    <p>H as</p>
    <p>h Sp</p>
    <p>ac e</p>
    <p>(0</p>
    <p>)</p>
    <p>Time (5 hours)</p>
    <p>Host 1 Host 2 Host 3</p>
  </div>
  <div class="page">
    <p>Addition  A new node takes</p>
    <p>reduces load on the overloaded server</p>
    <p>Node Addition / Removal</p>
    <p># of</p>
    <p>R eq</p>
    <p>s pe</p>
    <p>r m</p>
    <p>in (x</p>
    <p>Time (3 hours)</p>
    <p>Host added</p>
    <p>H as</p>
    <p>h Sp</p>
    <p>ac e</p>
    <p>(0</p>
    <p>)</p>
    <p>Time (3 hours) 0 50 100 150 200</p>
    <p>Host added</p>
    <p># of</p>
    <p>R eq</p>
    <p>s pe</p>
    <p>r m</p>
    <p>in (x</p>
    <p>Time (3 hours)</p>
    <p>Host removed H as</p>
    <p>h S</p>
    <p>pa ce</p>
    <p>( 0</p>
    <p>Time (3 hours) 0 50 100 150 200</p>
    <p>Host removed  Removal  Removing an</p>
    <p>underloaded server gives cost benefits while maintaining performance</p>
  </div>
  <div class="page">
    <p>Amount ratio of hash space movement  Determine the speed of adaptability  Use  = 0.01 (1%) to show the behavior</p>
    <p>Behavior</p>
    <p># of</p>
    <p>R eq</p>
    <p>s pe</p>
    <p>r m in</p>
    <p>(x 10</p>
    <p>Time (5 hours)</p>
    <p>Host 1 Host 2 Host 3</p>
    <p>ed H</p>
    <p>as h</p>
    <p>Sp ac</p>
    <p>e Si</p>
    <p>ze (x</p>
    <p>) Time (5 hours)</p>
    <p>` = 0.01</p>
    <p>Traffic changes over 5 hours Moved hash space per each scheduling</p>
  </div>
  <div class="page">
    <p>Dynamically add / remove server(s) depending on amount of load intensity</p>
    <p>Watch each server for a period of time (5 min) to check high load sustainability</p>
    <p>To maximize variation,  = 1 (hit rate only)  5 Wikipedia traffic generators used</p>
    <p>Scaling Up / Down</p>
    <p># of</p>
    <p>R eq</p>
    <p>s Pe</p>
    <p>r M in</p>
    <p>(x 10</p>
    <p># of</p>
    <p>S er</p>
    <p>ve rs</p>
    <p>Time (5 hours)</p>
  </div>
  <div class="page">
    <p>Wikipedia workload achieves better response time as hit rate increases ( 45% increase)</p>
    <p>But the number of servers used increases as well  As recommendation, the combination of hit rate and</p>
    <p>usage rate ( = 0.5) is a good administrative choice</p>
    <p>QoE Improvement</p>
    <p>A vg</p>
    <p>. R es</p>
    <p>po ns</p>
    <p>e T</p>
    <p>im e</p>
    <p>(m s)</p>
    <p>_ Value [0.0, 1.0]</p>
    <p>Ketama</p>
    <p>Hit rate Usage rate</p>
    <p># of</p>
    <p>U se</p>
    <p>d M</p>
    <p>em or</p>
    <p>y Se</p>
    <p>rv er</p>
    <p>s</p>
    <p>_ Value [0.0, 1.0]</p>
    <p>Ketama</p>
  </div>
  <div class="page">
    <p>[Stoica, ToN 03] Chord Peer-to-Peer architecture</p>
    <p>[Nishtala, NSDI 13] Scaling Memcached at Facebook</p>
    <p>[Zhu, HotCloud 12] Shrinking memcached to save $$</p>
    <p>Ideas may apply to many other key-value based storage systems: couchebase, redis, SILT, FAWN, etc</p>
    <p>Related Work</p>
  </div>
  <div class="page">
    <p>Summary o A hash space allocation scheme</p>
    <p>Carefully place nodes to ensure adjacency</p>
    <p>o Adaptive partitioning of the caches hash space Maximize hit rate and minimize difference in utilization rate</p>
    <p>o An automated replica management system Detect sustained overload and add or remove nodes</p>
    <p>Future works o Automatic  value adjustment to minimize response time o Targeted management of hot objects without impacting</p>
    <p>application performance</p>
    <p>Conclusion</p>
  </div>
</Presentation>
