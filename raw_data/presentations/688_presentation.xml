<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Resizable, Scalable, Concurrent Hash Tables via Relativistic Programming</p>
    <p>Josh Triplett1 Paul E. McKenney2 Jonathan Walpole1</p>
    <p>June 16, 2011</p>
  </div>
  <div class="page">
    <p>Synchronization = Waiting</p>
    <p>Concurrent programs require synchronization  Synchronization requires some threads to wait on others  Concurrent programs spend a lot of time waiting</p>
  </div>
  <div class="page">
    <p>Locking</p>
    <p>One thread accesses shared data  The rest wait for the lock</p>
    <p>Straightforward to get right  Minimal concurrency</p>
  </div>
  <div class="page">
    <p>Locking</p>
    <p>One thread accesses shared data  The rest wait for the lock  Straightforward to get right  Minimal concurrency</p>
  </div>
  <div class="page">
    <p>Fine-grained Locking</p>
    <p>Use different locks for different data  Disjoint-access parallelism  Reduce waiting, allow multiple threads to proceed</p>
    <p>Many expensive synchronization instructions  Wait on memory  Wait on the bus  Wait on cache coherence</p>
  </div>
  <div class="page">
    <p>Fine-grained Locking</p>
    <p>Use different locks for different data  Disjoint-access parallelism  Reduce waiting, allow multiple threads to proceed  Many expensive synchronization instructions</p>
    <p>Wait on memory  Wait on the bus  Wait on cache coherence</p>
  </div>
  <div class="page">
    <p>Fine-grained Locking</p>
    <p>Use different locks for different data  Disjoint-access parallelism  Reduce waiting, allow multiple threads to proceed  Many expensive synchronization instructions  Wait on memory  Wait on the bus  Wait on cache coherence</p>
  </div>
  <div class="page">
    <p>Reader-writer locking</p>
    <p>Dont make readers wait on other readers  Readers still wait on writers and vice versa</p>
    <p>Same expensive synchronization instructions  Dwarfs the actual reader critical section  No actual reader parallelism; readers get serialized</p>
  </div>
  <div class="page">
    <p>Reader-writer locking</p>
    <p>Dont make readers wait on other readers  Readers still wait on writers and vice versa  Same expensive synchronization instructions  Dwarfs the actual reader critical section</p>
    <p>No actual reader parallelism; readers get serialized</p>
  </div>
  <div class="page">
    <p>Reader-writer locking</p>
    <p>Dont make readers wait on other readers  Readers still wait on writers and vice versa  Same expensive synchronization instructions  Dwarfs the actual reader critical section  No actual reader parallelism; readers get serialized</p>
  </div>
  <div class="page">
    <p>Non-blocking synchronization</p>
    <p>Right there in the name: non-blocking  So, no waiting, right?</p>
    <p>Expensive synchronization instructions  All but one thread must retry  Useless parallelism: waiting while doing busywork  At best equivalent to fine-grained locking</p>
  </div>
  <div class="page">
    <p>Non-blocking synchronization</p>
    <p>Right there in the name: non-blocking  So, no waiting, right?  Expensive synchronization instructions</p>
    <p>All but one thread must retry  Useless parallelism: waiting while doing busywork  At best equivalent to fine-grained locking</p>
  </div>
  <div class="page">
    <p>Non-blocking synchronization</p>
    <p>Right there in the name: non-blocking  So, no waiting, right?  Expensive synchronization instructions  All but one thread must retry  Useless parallelism: waiting while doing busywork  At best equivalent to fine-grained locking</p>
  </div>
  <div class="page">
    <p>Transactional memory</p>
    <p>Non-blocking synchronization made easy  (Often implemented using locks for performance)</p>
    <p>Theoretically equivalent performance to NBS  In practice, somewhat more expensive  Fancy generic abstraction wrappers around waiting</p>
  </div>
  <div class="page">
    <p>Transactional memory</p>
    <p>Non-blocking synchronization made easy  (Often implemented using locks for performance)  Theoretically equivalent performance to NBS  In practice, somewhat more expensive</p>
    <p>Fancy generic abstraction wrappers around waiting</p>
  </div>
  <div class="page">
    <p>Transactional memory</p>
    <p>Non-blocking synchronization made easy  (Often implemented using locks for performance)  Theoretically equivalent performance to NBS  In practice, somewhat more expensive  Fancy generic abstraction wrappers around waiting</p>
  </div>
  <div class="page">
    <p>How do we stop waiting?</p>
    <p>Reader-writer locking had the right idea  But readers needed synchronization to wait on writers  Some waiting required to check for potential writers  Can readers avoid synchronization entirely?</p>
    <p>Readers should not wait at all  Joint-access parallelism: Can we allow concurrent readers and</p>
    <p>writers on the same data at the same time?</p>
    <p>What does at the same time mean, anyway?</p>
  </div>
  <div class="page">
    <p>How do we stop waiting?</p>
    <p>Reader-writer locking had the right idea  But readers needed synchronization to wait on writers  Some waiting required to check for potential writers  Can readers avoid synchronization entirely?  Readers should not wait at all</p>
    <p>Joint-access parallelism: Can we allow concurrent readers and writers on the same data at the same time?</p>
    <p>What does at the same time mean, anyway?</p>
  </div>
  <div class="page">
    <p>How do we stop waiting?</p>
    <p>Reader-writer locking had the right idea  But readers needed synchronization to wait on writers  Some waiting required to check for potential writers  Can readers avoid synchronization entirely?  Readers should not wait at all  Joint-access parallelism: Can we allow concurrent readers and</p>
    <p>writers on the same data at the same time?</p>
    <p>What does at the same time mean, anyway?</p>
  </div>
  <div class="page">
    <p>How do we stop waiting?</p>
    <p>Reader-writer locking had the right idea  But readers needed synchronization to wait on writers  Some waiting required to check for potential writers  Can readers avoid synchronization entirely?  Readers should not wait at all  Joint-access parallelism: Can we allow concurrent readers and</p>
    <p>writers on the same data at the same time?</p>
    <p>What does at the same time mean, anyway?</p>
  </div>
  <div class="page">
    <p>Modern computers</p>
    <p>Shared address space  Distributed memory  Expensive illusion of coherent shared memory</p>
    <p>At the same time gets rather fuzzy  Shared address spaces make communication simple  Incredibly optimized communication via cache coherence  When we have to communicate, lets take advantage of that!  (and not just to accelerate message passing)</p>
  </div>
  <div class="page">
    <p>Modern computers</p>
    <p>Shared address space  Distributed memory  Expensive illusion of coherent shared memory  At the same time gets rather fuzzy</p>
    <p>Shared address spaces make communication simple  Incredibly optimized communication via cache coherence  When we have to communicate, lets take advantage of that!  (and not just to accelerate message passing)</p>
  </div>
  <div class="page">
    <p>Modern computers</p>
    <p>Shared address space  Distributed memory  Expensive illusion of coherent shared memory  At the same time gets rather fuzzy  Shared address spaces make communication simple  Incredibly optimized communication via cache coherence</p>
    <p>When we have to communicate, lets take advantage of that!  (and not just to accelerate message passing)</p>
  </div>
  <div class="page">
    <p>Modern computers</p>
    <p>Shared address space  Distributed memory  Expensive illusion of coherent shared memory  At the same time gets rather fuzzy  Shared address spaces make communication simple  Incredibly optimized communication via cache coherence  When we have to communicate, lets take advantage of that!  (and not just to accelerate message passing)</p>
  </div>
  <div class="page">
    <p>Relativistic Programming</p>
    <p>By analogy with relativity: no absolute reference frame  No global order for non-causally-related events  Readers do no waiting at all, for readers or writers  Minimize expensive communication and synchronization  Writers do all the waiting, when necessary  Reads linearly scalable</p>
  </div>
  <div class="page">
    <p>What if readers see partial writes?</p>
    <p>Writers must not disrupt concurrent readers  Data structures must stay consistent after every write  Writers order their writes by waiting  No impact to concurrent readers</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Synchronization = Waiting  Introduction to Relativistic Programming  Relativistic synchronization primitives  Relativistic data structures  Hash-table algorithm  Results  Future work</p>
  </div>
  <div class="page">
    <p>Relativistic synchronization primitives</p>
    <p>Delimited readers  No waiting: Notification, not permission</p>
    <p>Pointer publication  Ensures ordering between initialization and publication</p>
    <p>Updaters can wait for readers  Existing readers only, not new readers</p>
  </div>
  <div class="page">
    <p>Relativistic synchronization primitives</p>
    <p>Delimited readers  No waiting: Notification, not permission</p>
    <p>Pointer publication  Ensures ordering between initialization and publication</p>
    <p>Updaters can wait for readers  Existing readers only, not new readers</p>
  </div>
  <div class="page">
    <p>Relativistic synchronization primitives</p>
    <p>Delimited readers  No waiting: Notification, not permission</p>
    <p>Pointer publication  Ensures ordering between initialization and publication</p>
    <p>Updaters can wait for readers  Existing readers only, not new readers</p>
  </div>
  <div class="page">
    <p>Example: Relativistic linked list insertion</p>
    <p>a</p>
    <p>b</p>
    <p>c</p>
    <p>Potential readers</p>
    <p>Initial state of the list; writer wants to insert b.</p>
    <p>Initialize bs next pointer to point to c  The writer can then publish b to node as next pointer  Readers can immediately begin observing the new node</p>
  </div>
  <div class="page">
    <p>Example: Relativistic linked list insertion</p>
    <p>a</p>
    <p>b</p>
    <p>c</p>
    <p>Potential readers</p>
    <p>Initial state of the list; writer wants to insert b.  Initialize bs next pointer to point to c</p>
    <p>The writer can then publish b to node as next pointer  Readers can immediately begin observing the new node</p>
  </div>
  <div class="page">
    <p>Example: Relativistic linked list insertion</p>
    <p>a</p>
    <p>b</p>
    <p>c</p>
    <p>Potential readers</p>
    <p>Initial state of the list; writer wants to insert b.  Initialize bs next pointer to point to c  The writer can then publish b to node as next pointer</p>
    <p>Readers can immediately begin observing the new node</p>
  </div>
  <div class="page">
    <p>Example: Relativistic linked list insertion</p>
    <p>a</p>
    <p>b</p>
    <p>c</p>
    <p>Potential readers</p>
    <p>Initial state of the list; writer wants to insert b.  Initialize bs next pointer to point to c  The writer can then publish b to node as next pointer  Readers can immediately begin observing the new node</p>
  </div>
  <div class="page">
    <p>Example: Relativistic linked list removal</p>
    <p>a b c</p>
    <p>Potential readers</p>
    <p>Initial state of the list; writer wants to remove node b</p>
    <p>Sets as next pointer to c, removing b from the list for all future readers</p>
    <p>Wait for existing readers to finish  Once no readers can hold references to b, the writer can safely</p>
    <p>reclaim it.</p>
  </div>
  <div class="page">
    <p>Example: Relativistic linked list removal</p>
    <p>a b c</p>
    <p>Potential readers</p>
    <p>Initial state of the list; writer wants to remove node b  Sets as next pointer to c, removing b from the list for all</p>
    <p>future readers</p>
    <p>Wait for existing readers to finish  Once no readers can hold references to b, the writer can safely</p>
    <p>reclaim it.</p>
  </div>
  <div class="page">
    <p>Example: Relativistic linked list removal</p>
    <p>a b c</p>
    <p>Potential readers</p>
    <p>Initial state of the list; writer wants to remove node b  Sets as next pointer to c, removing b from the list for all</p>
    <p>future readers</p>
    <p>Wait for existing readers to finish</p>
    <p>Once no readers can hold references to b, the writer can safely reclaim it.</p>
  </div>
  <div class="page">
    <p>Example: Relativistic linked list removal</p>
    <p>a c</p>
    <p>Potential readers</p>
    <p>Initial state of the list; writer wants to remove node b  Sets as next pointer to c, removing b from the list for all</p>
    <p>future readers</p>
    <p>Wait for existing readers to finish  Once no readers can hold references to b, the writer can safely</p>
    <p>reclaim it.</p>
  </div>
  <div class="page">
    <p>Relativistic data structures</p>
    <p>Linked lists  Radix trees  Tries  Balanced trees  Hash tables</p>
  </div>
  <div class="page">
    <p>Relativistic hash tables</p>
    <p>Open chaining with relativistic linked lists  Insertion and removal supported  Atomic move operation (see previous work)</p>
    <p>What about resizing?  Necessary to maintain constant-time performance and</p>
    <p>reasonable memory usage</p>
    <p>Must keep the table consistent at all times</p>
  </div>
  <div class="page">
    <p>Relativistic hash tables</p>
    <p>Open chaining with relativistic linked lists  Insertion and removal supported  Atomic move operation (see previous work)  What about resizing?  Necessary to maintain constant-time performance and</p>
    <p>reasonable memory usage</p>
    <p>Must keep the table consistent at all times</p>
  </div>
  <div class="page">
    <p>Relativistic hash tables</p>
    <p>Open chaining with relativistic linked lists  Insertion and removal supported  Atomic move operation (see previous work)  What about resizing?  Necessary to maintain constant-time performance and</p>
    <p>reasonable memory usage</p>
    <p>Must keep the table consistent at all times</p>
  </div>
  <div class="page">
    <p>Existing approaches to resizing</p>
    <p>Dont: allocate a fixed-size table and never resize it  Poor performance or wasted memory</p>
    <p>Dynamic Dynamic Data Structures (DDDS)  Readers must check old and new data structures  Readers have to wait until no concurrent resizes  Slows down the common case  Significantly slows lookups while resizing</p>
    <p>Herbert Xus resizable relativistic hash tables  Extra linked-list pointers in every node  High memory usage</p>
  </div>
  <div class="page">
    <p>Existing approaches to resizing</p>
    <p>Dont: allocate a fixed-size table and never resize it  Poor performance or wasted memory</p>
    <p>Dynamic Dynamic Data Structures (DDDS)  Readers must check old and new data structures  Readers have to wait until no concurrent resizes  Slows down the common case  Significantly slows lookups while resizing</p>
    <p>Herbert Xus resizable relativistic hash tables  Extra linked-list pointers in every node  High memory usage</p>
  </div>
  <div class="page">
    <p>Existing approaches to resizing</p>
    <p>Dont: allocate a fixed-size table and never resize it  Poor performance or wasted memory</p>
    <p>Dynamic Dynamic Data Structures (DDDS)  Readers must check old and new data structures  Readers have to wait until no concurrent resizes  Slows down the common case  Significantly slows lookups while resizing</p>
    <p>Herbert Xus resizable relativistic hash tables  Extra linked-list pointers in every node  High memory usage</p>
  </div>
  <div class="page">
    <p>Defining consistent</p>
    <p>A reader traversing a hash bucket must always observe all elements in that bucket</p>
    <p>. . . but if it observes more, no harm done  Imprecise hash buckets contain elements from other buckets</p>
  </div>
  <div class="page">
    <p>Defining consistent</p>
    <p>A reader traversing a hash bucket must always observe all elements in that bucket</p>
    <p>. . . but if it observes more, no harm done</p>
    <p>Imprecise hash buckets contain elements from other buckets</p>
  </div>
  <div class="page">
    <p>Defining consistent</p>
    <p>A reader traversing a hash bucket must always observe all elements in that bucket</p>
    <p>. . . but if it observes more, no harm done  Imprecise hash buckets contain elements from other buckets</p>
  </div>
  <div class="page">
    <p>Shrinking: Initial state</p>
    <p>odd</p>
    <p>even</p>
  </div>
  <div class="page">
    <p>Shrinking: Initialize new buckets</p>
    <p>odd</p>
    <p>even</p>
    <p>all</p>
  </div>
  <div class="page">
    <p>Shrinking: Link old chains</p>
    <p>odd</p>
    <p>even</p>
    <p>all</p>
  </div>
  <div class="page">
    <p>Shrinking: Publish new buckets</p>
    <p>all</p>
    <p>odd</p>
    <p>even</p>
  </div>
  <div class="page">
    <p>Shrinking: Wait for readers</p>
    <p>all</p>
    <p>odd</p>
    <p>even</p>
  </div>
  <div class="page">
    <p>Shrinking: Reclaim</p>
    <p>all 1 3 2 4</p>
  </div>
  <div class="page">
    <p>Expanding: Initial state</p>
    <p>all 1 2 3 4</p>
  </div>
  <div class="page">
    <p>Expanding: Initialize new buckets</p>
    <p>all</p>
    <p>odd</p>
    <p>even</p>
  </div>
  <div class="page">
    <p>Expanding: Publish new buckets</p>
    <p>all</p>
    <p>odd</p>
    <p>even</p>
  </div>
  <div class="page">
    <p>Expanding: Wait for readers</p>
    <p>aux</p>
    <p>odd</p>
    <p>even</p>
  </div>
  <div class="page">
    <p>Expanding: Unzip one step</p>
    <p>aux</p>
    <p>odd</p>
    <p>even</p>
  </div>
  <div class="page">
    <p>Expanding: Wait for readers</p>
    <p>aux</p>
    <p>odd</p>
    <p>even</p>
  </div>
  <div class="page">
    <p>Expanding: Unzip again</p>
    <p>aux</p>
    <p>odd</p>
    <p>even</p>
  </div>
  <div class="page">
    <p>Expanding: Final state</p>
    <p>odd</p>
    <p>even</p>
  </div>
  <div class="page">
    <p>Benchmarking methodology</p>
    <p>Implemented a microbenchmark as a Linux kernel module  Used Linuxs Read-Copy Update (RCU) implementation  Relativistic Programming primitives map to RCU operations</p>
    <p>Lookups with no resize as a baseline  Lookups with continuous resizing as a worst-case scenario  Compared: our algorithm, DDDS, rwlock</p>
  </div>
  <div class="page">
    <p>Benchmarking methodology</p>
    <p>Implemented a microbenchmark as a Linux kernel module  Used Linuxs Read-Copy Update (RCU) implementation  Relativistic Programming primitives map to RCU operations  Lookups with no resize as a baseline  Lookups with continuous resizing as a worst-case scenario</p>
    <p>Compared: our algorithm, DDDS, rwlock</p>
  </div>
  <div class="page">
    <p>Benchmarking methodology</p>
    <p>Implemented a microbenchmark as a Linux kernel module  Used Linuxs Read-Copy Update (RCU) implementation  Relativistic Programming primitives map to RCU operations  Lookups with no resize as a baseline  Lookups with continuous resizing as a worst-case scenario  Compared: our algorithm, DDDS, rwlock</p>
  </div>
  <div class="page">
    <p>Results: fixed-size table baseline</p>
    <p>RP</p>
    <p>DDDS</p>
    <p>rwlock</p>
    <p>Reader threads</p>
    <p>L o</p>
    <p>o k</p>
    <p>u p</p>
    <p>s/ se</p>
    <p>co n</p>
    <p>d (m</p>
    <p>il li</p>
    <p>o n</p>
    <p>s)</p>
  </div>
  <div class="page">
    <p>Results - continuous resizing</p>
    <p>RP</p>
    <p>DDDS</p>
    <p>Reader threads</p>
    <p>L o</p>
    <p>o k</p>
    <p>u p</p>
    <p>s/ se</p>
    <p>co n</p>
    <p>d (m</p>
    <p>il li</p>
    <p>o n</p>
    <p>s)</p>
  </div>
  <div class="page">
    <p>Results - our resize versus fixed</p>
    <p>resize</p>
    <p>Reader threads</p>
    <p>L o</p>
    <p>o k</p>
    <p>u p</p>
    <p>s/ se</p>
    <p>co n</p>
    <p>d (m</p>
    <p>il li</p>
    <p>o n</p>
    <p>s)</p>
  </div>
  <div class="page">
    <p>Results - DDDS resize versus fixed</p>
    <p>resize</p>
    <p>Reader threads</p>
    <p>L o</p>
    <p>o k</p>
    <p>u p</p>
    <p>s/ se</p>
    <p>co n</p>
    <p>d (m</p>
    <p>il li</p>
    <p>o n</p>
    <p>s)</p>
  </div>
  <div class="page">
    <p>Hang on a minute. . .</p>
    <p>This is USENIX!  We dont settle for microbenchmarks here  We care about real-world implementations</p>
  </div>
  <div class="page">
    <p>memcached</p>
    <p>Network-accessible key-value store  Used for caching  Performance-critical</p>
    <p>. . . and it uses a global table lock</p>
  </div>
  <div class="page">
    <p>memcached</p>
    <p>Network-accessible key-value store  Used for caching  Performance-critical  . . . and it uses a global table lock</p>
  </div>
  <div class="page">
    <p>memcached with relativistic hash tables</p>
    <p>Uses the userspace RCU implementation, urcu  Adds a fast path for GET requests using relativistic lookups  Copies value while still in a relativistic reader  Falls back to the slow path for expiry, eviction  Writers use safe relativistic memory reclamation</p>
  </div>
  <div class="page">
    <p>memcached results</p>
    <p>RP GET</p>
    <p>default GET</p>
    <p>default SET</p>
    <p>RP SET</p>
    <p>mc-benchmark processes</p>
    <p>R eq</p>
    <p>u es</p>
    <p>ts /</p>
    <p>se co</p>
    <p>n d</p>
    <p>(t h</p>
    <p>o u</p>
    <p>sa n</p>
    <p>d s)</p>
  </div>
  <div class="page">
    <p>Future work: Relativistic data structures</p>
    <p>New relativistic algorithms currently require careful construction</p>
    <p>We have a general methodology for algorithm construction  Write an algorithm assuming our memory model  Use this methodology to mechanically place barriers and</p>
    <p>wait-for-readers operations</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Relativistic programming allows linearly scalable readers  Relativistic hash tables support resizing now</p>
    <p>Now suitable for general-purpose usage</p>
    <p>Real-world code scales better with relativistic programming</p>
    <p>Questions?</p>
  </div>
</Presentation>
