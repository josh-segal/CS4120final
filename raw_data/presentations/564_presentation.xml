<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>USENIX ATCUSENIX ATC1111</p>
    <p>HiTune</p>
    <p>Dataflow-Based Performance Analysis for Big Data Cloud</p>
    <p>Jinquan (Jason) Dai, Jie Huang, Shengsheng Huang, Bo Huang, Yan Liu</p>
    <p>Intel Asia-Pacific Research and Development Ltd</p>
    <p>Shanghai, China, 200241</p>
  </div>
  <div class="page">
    <p>Big Data</p>
    <p>Industrial Revolution of Data</p>
    <p>The heartbeat of mobile, cloud and social computing</p>
    <p>Expanding faster than Moores law</p>
    <p>E.g., Internet of Things</p>
    <p>What is Big Data?</p>
    <p>Too large to work with using traditional tools (e.g., RDBMS)</p>
    <p>Require a new architecture</p>
    <p>Massively parallel software running on 100s~1000s of servers</p>
  </div>
  <div class="page">
    <p>Dataflow Model for Big Data Analytics</p>
    <p>User</p>
    <p>Applications modeled as dataflow graphs</p>
    <p>Write subroutines running on the vertices</p>
    <p>Abstracted away from messy details of distributed computing</p>
    <p>System runtime</p>
    <p>Dynamically map dataflow graphs to the cluster</p>
    <p>Handles all the low level details</p>
    <p>Data partitioning, task distribution, load balancing, node communications, fault tolerance,</p>
    <p>D</p>
    <p>A</p>
    <p>T</p>
    <p>A</p>
    <p>MAP</p>
    <p>MAP</p>
    <p>MAP</p>
    <p>MAP</p>
    <p>RE</p>
    <p>DU</p>
    <p>CE</p>
    <p>Partitioned Input</p>
    <p>Aggregated Output</p>
    <p>spill</p>
    <p>Streaming dataflow</p>
    <p>D</p>
    <p>A</p>
    <p>A</p>
    <p>map</p>
    <p>map</p>
    <p>map</p>
    <p>map</p>
    <p>reduce</p>
    <p>Aggregated Output</p>
    <p>Partitioned Input</p>
    <p>copier</p>
    <p>copier</p>
    <p>copier sort</p>
    <p>sort</p>
    <p>sortmerge</p>
    <p>merge</p>
    <p>merge</p>
    <p>reduce</p>
    <p>reduce</p>
    <p>Sequential dataflow</p>
    <p>shuffle</p>
    <p>shuffle</p>
    <p>shuffle</p>
    <p>spill</p>
    <p>Spill</p>
    <p>spill</p>
    <p>T</p>
    <p>Map Tasks Reduce Tasks</p>
    <p>MapReduce</p>
    <p>Hadoop</p>
    <p>Dryad</p>
  </div>
  <div class="page">
    <p>What Worked</p>
    <p>Parallel programming is hard</p>
    <p>Distributed programming is harder</p>
    <p>Dataflow model makes it a lot easier</p>
    <p>An appropriately high level of abstraction</p>
    <p>User required to consider data parallelisms exposed by the dataflow</p>
    <p>Runtime distributes executions of subroutines by exploiting data dependencies encoded in the dataflow</p>
    <p>Nontrivial software written with threads, semaphores, and mutexes are incomprehensible to humans.</p>
    <p>Edward A. Lee CGO 2007, March 2007</p>
    <p>Auto-Partitioning Compiler for Intel Network Processor (IXP)</p>
  </div>
  <div class="page">
    <p>What Didnt Work</p>
    <p>Dataflow abstraction makes Big Data system appear as a black box</p>
    <p>Very difficult for the user to understand runtime behaviors</p>
    <p>Performance analysis &amp; tuning remain a big challenge</p>
    <p>Key challenges of performance analysis for Big Data</p>
    <p>Massively distributed system</p>
    <p>How to correlate concurrent performance activities (across 10000s of programs and machines)?</p>
    <p>High level dataflow abstraction</p>
    <p>How to relate low level performance activities to high level dataflow model?</p>
  </div>
  <div class="page">
    <p>HiTune: Vtune for Hadoop</p>
    <p>Distributed instrumentations</p>
    <p>Lightweight sampling using binary instrumentation</p>
    <p>No source code modifications</p>
    <p>Implemented using Java programming language agents</p>
    <p>Generic sampling information collected</p>
    <p>Dataflow-driven analysis</p>
    <p>Re-constructing dataflow execution process using low level sampling information</p>
    <p>Based on a dataflow specification</p>
    <p>Implemented as several Hadoop jobs</p>
  </div>
  <div class="page">
    <p>HiTune 0.9</p>
    <p>Adaptor</p>
    <p>Adaptor</p>
    <p>Adaptor</p>
    <p>Chukwa</p>
    <p>Agent</p>
    <p>Adaptor</p>
    <p>Adaptor</p>
    <p>Adaptor</p>
    <p>Chukwa</p>
    <p>Collector</p>
    <p>HDFS</p>
    <p>Chukwa</p>
    <p>Demux</p>
    <p>Local HiTune</p>
    <p>data</p>
    <p>Local HiTune</p>
    <p>data</p>
    <p>Local HiTune</p>
    <p>data</p>
    <p>Local HiTune</p>
    <p>data</p>
    <p>Local HiTune</p>
    <p>data</p>
    <p>Local HiTune</p>
    <p>data HiTune</p>
    <p>Paser</p>
    <p>HiTune</p>
    <p>Paser</p>
    <p>HiTune</p>
    <p>Analyzer</p>
    <p>Hadoop</p>
    <p>Job</p>
    <p>Hadoop</p>
    <p>Job</p>
    <p>HiTune Report (.csv)</p>
    <p>Instrumentation</p>
    <p>PostProcess</p>
    <p>Analysis</p>
    <p>Hive</p>
    <p>HiveQL</p>
    <p>Hive Query Excel Spreadsheet</p>
    <p>Visual</p>
    <p>Report Samples (.xlsm)</p>
    <p>Chukwa</p>
    <p>Agent</p>
    <p>Chukwa</p>
    <p>Collector</p>
    <p>Chukwa</p>
    <p>Collector</p>
    <p>Aggregation</p>
    <p>Status</p>
    <p>Used intensively both inside Intel and by several external customers</p>
    <p>Open sourced under Apache License 2.0</p>
    <p>Available at https://github.com/hitune/hitune</p>
  </div>
  <div class="page">
    <p>Overhead</p>
    <p>Ratio of instrumented vs. uninstrumented clusters</p>
    <p>Less than 2% runtime overhead due to instrumentation</p>
    <p>Sort WordCount Nutch indexing</p>
    <p>R a</p>
    <p>ti o</p>
    <p>o f</p>
    <p>C o</p>
    <p>m p</p>
    <p>le ti</p>
    <p>o n</p>
    <p>T im</p>
    <p>e</p>
    <p>Workloads</p>
    <p>Sort WordCount Nutch indexing</p>
    <p>R a</p>
    <p>ti o</p>
    <p>o f</p>
    <p>C P</p>
    <p>U U</p>
    <p>ti li z a</p>
    <p>ti o</p>
    <p>n</p>
    <p>Workloads</p>
    <p>Sort WordCount Nutch indexingR a</p>
    <p>ti o</p>
    <p>o f</p>
    <p>M e</p>
    <p>m o</p>
    <p>ry U</p>
    <p>ti li z a</p>
    <p>ti o</p>
    <p>n</p>
    <p>Workloads</p>
    <p>Sort WordCount Nutch indexing</p>
    <p>R a</p>
    <p>ti o</p>
    <p>o f</p>
    <p>T h</p>
    <p>ro u</p>
    <p>g h</p>
    <p>p u</p>
    <p>t</p>
    <p>Workloads</p>
  </div>
  <div class="page">
    <p>The Hadoop Dataflow Model</p>
    <p>spill</p>
    <p>Streaming dataflow</p>
    <p>D</p>
    <p>A</p>
    <p>A</p>
    <p>map</p>
    <p>map</p>
    <p>map</p>
    <p>map</p>
    <p>reduce</p>
    <p>Aggregated Output</p>
    <p>Partitioned Input</p>
    <p>copier</p>
    <p>copier</p>
    <p>copier sort</p>
    <p>sort</p>
    <p>sortmerge</p>
    <p>merge</p>
    <p>merge</p>
    <p>reduce</p>
    <p>reduce</p>
    <p>Sequential dataflow</p>
    <p>shuffle</p>
    <p>shuffle</p>
    <p>shuffle</p>
    <p>spill</p>
    <p>Spill</p>
    <p>spill</p>
    <p>T</p>
    <p>Map Tasks Reduce Tasks</p>
  </div>
  <div class="page">
    <p>Case Study: Limitation of Traditional Tools</p>
    <p>Sorting many small files (3200 500KB-sized files) using Hadoop 0.20.1</p>
    <p>Cluster very lightly utilized (extremely low CPU, disk I/O and network utilization)</p>
    <p>No obvious bottlenecks or hotspots in the cluster</p>
    <p>Traditional tools (e.g., system monitors and program profilers) fail to reveal the root cause</p>
  </div>
  <div class="page">
    <p>Case Study: Limitation of Traditional Tools</p>
    <p>HiTune results (dataflow execution) reveal the root cause</p>
    <p>Upgrading to Fair Scheduler 2.0 fixes the issue</p>
    <p>Dataflow Dataflow</p>
    <p>Execution ChartExecution Chart</p>
    <p>M a</p>
    <p>p /R</p>
    <p>e d</p>
    <p>u ce</p>
    <p>T a</p>
    <p>sk s</p>
    <p>M a</p>
    <p>p /R</p>
    <p>e d</p>
    <p>u ce</p>
    <p>T a</p>
    <p>sk s</p>
    <p>M a</p>
    <p>p /R</p>
    <p>e d</p>
    <p>u ce</p>
    <p>T a</p>
    <p>sk s</p>
    <p>Time line</p>
    <p>The FixThe Fix The Low Utilization IssueThe Low Utilization Issue</p>
    <p>bootstrap</p>
    <p>map</p>
    <p>shuffle</p>
    <p>sort</p>
    <p>reduce</p>
    <p>idle</p>
    <p>Time line</p>
  </div>
  <div class="page">
    <p>Case Study: Limitation of Hadoop Logs</p>
    <p>TeraSort</p>
    <p>Large gap between end of map and end of shuffle</p>
    <p>None of CPU, disk I/O and network bandwidth are bottlenecked during the gap</p>
    <p>Shuffle Fetchers Busy Percent metric reported by Hadoop is always 100%</p>
    <p>Increasing the number of copier threads brings no improvement</p>
    <p>Traditional tools or Hadoop logs fail to reveal the root cause</p>
    <p>gap</p>
  </div>
  <div class="page">
    <p>Case Study: Limitation of Hadoop Logs</p>
    <p>HiTune results (dataflow-based hotspot breakdown) reveal the root cause</p>
    <p>Copier threads idle 80% of the time, waiting for memory merge thread</p>
    <p>memory merge thread busy mostly due to compression</p>
    <p>Changing compression codec to LZO fixes this issue</p>
    <p>Copier threads</p>
    <p>Busy, 20%</p>
    <p>Idle, 80% reserve, 79%</p>
    <p>Others,1%</p>
    <p>Compress, 81%</p>
    <p>Memory Merge threads</p>
    <p>Idle, 13% Busy, 87%</p>
    <p>Others, 6%</p>
  </div>
  <div class="page">
    <p>Case Study: Extensibility</p>
    <p>Easily extended to support Hive</p>
    <p>Simply changing the dataflow specification</p>
    <p>Aggregation query in Hive performance benchmarks</p>
    <p>68% of time spent on data input/output, Hadoop/Hive initialization &amp; cleanup</p>
    <p>Critical to reduce intermediate results, improve data input/output, and reduce Hadoop/Hive overheads</p>
    <p>Hive</p>
    <p>Init</p>
    <p>Hive</p>
    <p>Active</p>
    <p>Hive</p>
    <p>Close</p>
    <p>Hive Processing Period</p>
    <p>Active</p>
    <p>Hive data flow stage timeline</p>
    <p>map stage timeline</p>
    <p>Stage</p>
    <p>Init</p>
    <p>Stage</p>
    <p>Close</p>
    <p>Hive</p>
    <p>Init</p>
    <p>Hive</p>
    <p>Active</p>
    <p>Hive</p>
    <p>Close</p>
    <p>Stage</p>
    <p>Init</p>
    <p>Hive</p>
    <p>Init</p>
    <p>Hive</p>
    <p>Active</p>
    <p>Hive</p>
    <p>Close</p>
    <p>Hive Processing Period</p>
    <p>Active</p>
    <p>Hive data flow stage timeline</p>
    <p>map stage timeline</p>
    <p>Stage</p>
    <p>Init</p>
    <p>Stage</p>
    <p>Close</p>
    <p>Hive</p>
    <p>Init</p>
    <p>Hive</p>
    <p>Active</p>
    <p>Hive</p>
    <p>Close</p>
    <p>Stage</p>
    <p>Init</p>
    <p>Hive Processing Period</p>
    <p>Active</p>
    <p>Hive data flow stage timeline</p>
    <p>reduce stage timeline</p>
    <p>Stage</p>
    <p>Close</p>
    <p>Hive</p>
    <p>Init</p>
    <p>Hive</p>
    <p>Active</p>
    <p>Hive</p>
    <p>Close</p>
    <p>Hive Processing Period</p>
    <p>Active</p>
    <p>Hive data flow stage timeline</p>
    <p>reduce stage timeline</p>
    <p>Stage</p>
    <p>Close</p>
    <p>Hive</p>
    <p>Init</p>
    <p>Hive</p>
    <p>Active</p>
    <p>Hive</p>
    <p>Close</p>
    <p>Hive Init</p>
    <p>Hive</p>
    <p>Close</p>
    <p>Stage Close</p>
    <p>Hive Input</p>
    <p>Hive</p>
    <p>Operations</p>
    <p>Hive Output</p>
    <p>Hive Active</p>
    <p>Hive Init</p>
    <p>Hive</p>
    <p>Close</p>
    <p>Stage Close</p>
    <p>Hive Input</p>
    <p>Hive</p>
    <p>Operations</p>
    <p>Hive Output</p>
    <p>Hive Active</p>
    <p>Map Tasks Reduce Tasks</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>HiTune - VTune for Hadoop</p>
    <p>Better insights on Hadoop runtime behaviors</p>
    <p>Dataflow-based analysis</p>
    <p>Extremely low runtime overheads</p>
    <p>Very good scalability &amp; extensibility</p>
    <p>v0.9 open sourced under Apache License 2.0</p>
    <p>See https://github.com/hitune/hitune</p>
  </div>
  <div class="page"/>
</Presentation>
