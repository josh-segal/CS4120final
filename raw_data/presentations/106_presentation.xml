<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Variational Bayesian Image Process ing on Stochastic Factor Graphs</p>
    <p>Xin LiXin Li</p>
    <p>Lane Dept. of CSEELane Dept. of CSEE</p>
    <p>West Virginia UniversityWest Virginia University</p>
  </div>
  <div class="page">
    <p>OutlineOutline</p>
    <p>Statistical modeling of natural imagesStatistical modeling of natural images  From old-fashioned local models to newly-proposed nFrom old-fashioned local models to newly-proposed n</p>
    <p>onlocal models onlocal models  Factor graph based image modelingFactor graph based image modeling</p>
    <p>A powerful framework unifying local and nonlocal appA powerful framework unifying local and nonlocal app roachesroaches</p>
    <p>EM-based inference on stochastic factor graphsEM-based inference on stochastic factor graphs  Applications and experimental resultsApplications and experimental results</p>
    <p>Denoising, inpainting, interpolation, post-processing, Denoising, inpainting, interpolation, post-processing, inverse halftoning, deblurring ... ...inverse halftoning, deblurring ... ...</p>
  </div>
  <div class="page">
    <p>Cast Signal/Image Cast Signal/Image Processing Under a Processing Under a</p>
    <p>Bayesian FrameworkBayesian Framework  Image restoration (Besag Image restoration (Besag</p>
    <p>et al.1991)et al.1991)  Image denoising Image denoising</p>
    <p>(Simoncelli&amp;Adelson199(Simoncelli&amp;Adelson199 6)6)</p>
    <p>Interpolation Interpolation (Mackay1992) and super-(Mackay1992) and superresolution (Schultz&amp; resolution (Schultz&amp; Stevenson1996 )Stevenson1996 )</p>
    <p>Inverse halftoning Inverse halftoning (Wong1995)(Wong1995)</p>
    <p>Image segmentation Image segmentation (Bouman&amp;Shapiro1994)(Bouman&amp;Shapiro1994)</p>
    <p>( | , ) ( | ) ( | , )</p>
    <p>( | )</p>
    <p>p H p H p H</p>
    <p>p H</p>
    <p>y x x x y</p>
    <p>y</p>
    <p>x: Unobservable data</p>
    <p>y: Observation data</p>
    <p>Image prior (the focus of this talk)</p>
    <p>Likelihood (varies from application</p>
    <p>to application)</p>
  </div>
  <div class="page">
    <p>Statistical Modeling of Statistical Modeling of Natural Images:Natural Images:</p>
    <p>the Pursuit of a Good Priorthe Pursuit of a Good Prior  Local modelsLocal models</p>
    <p>Markov Random Field (MRF) and its extensions (e.g., 2D Markov Random Field (MRF) and its extensions (e.g., 2D Kalman-filtering, Field-of-Expert)Kalman-filtering, Field-of-Expert)</p>
    <p>Sparsity-based: DCT, wavelets, steerable pyramids, geomSparsity-based: DCT, wavelets, steerable pyramids, geom etric wavelets (edgelets, curvelets, ridgelets, bandelets)etric wavelets (edgelets, curvelets, ridgelets, bandelets)</p>
    <p>Nonlocal modelsNonlocal models  Bilateral filtering (Tomasi et al. ICCV1998)Bilateral filtering (Tomasi et al. ICCV1998)  Texture synthesis (Efros&amp;Leung ICCV1999)Texture synthesis (Efros&amp;Leung ICCV1999)  Exemplar-based inpainting (Criminisi et al. TIP2004)Exemplar-based inpainting (Criminisi et al. TIP2004)  Nonlocal mean denoising (Buades et al. CVPR2005)Nonlocal mean denoising (Buades et al. CVPR2005)  Total Least-Square denoising (Hirakawa&amp;Parks TIP2006)Total Least-Square denoising (Hirakawa&amp;Parks TIP2006)  Block-matching 3D denoising (Dabov et al. TIP2007)Block-matching 3D denoising (Dabov et al. TIP2007)</p>
  </div>
  <div class="page">
    <p>Introducing a New Introducing a New Language of Factor Graphs Language of Factor Graphs</p>
    <p>Why Factor Graphs?Why Factor Graphs?  The most general form of graphical probability models (both MRF The most general form of graphical probability models (both MRF</p>
    <p>and Bayesian networks can be converted to FGs)and Bayesian networks can be converted to FGs)  Widely used in computer science and engineering (Widely used in computer science and engineering (forward-backward</p>
    <p>algorithm, Viterbi algorithm, turbo decoding algorithm, Pearls belief propagation algorithm, Kalman filter1))</p>
    <p>What is Factor Graph?What is Factor Graph?  a bipartite graph that expresses which variables are arguments of</p>
    <p>which local functions  Factor/function node (solid squares) vs. variable nodes (empty Factor/function node (solid squares) vs. variable nodes (empty</p>
    <p>circles)circles)</p>
    <p>B1 B2 B7 B8B3 B4 B5 B6</p>
    <p>f1 f2 f3 f4 f1 f2 f3 f4</p>
    <p>L:F  V</p>
  </div>
  <div class="page">
    <p>Variable Nodes=Image Variable Nodes=Image PatchesPatches</p>
    <p>Neuroscience: Neuroscience: receptive fields of receptive fields of neighboring cells in neighboring cells in human vision system human vision system have severe have severe overlappingoverlapping</p>
    <p>Engineering: patch Engineering: patch has been under the has been under the disguise of many disguise of many different names such different names such as as windowswindows in digital in digital filters, filters, blocksblocks in JPEG in JPEG and the and the supportsupport of of wavelet bases wavelet bases</p>
    <p>Cited from D. Hubel, Eye, Brain and Vision, 1988</p>
  </div>
  <div class="page">
    <p>Factorization: the Art of Factorization: the Art of Statistical Image ModelingStatistical Image Modeling</p>
    <p>Wavelet-based statistical models (geometric proximity defines</p>
    <p>the neighborhood)</p>
    <p>Locally linear embedding1</p>
    <p>(perceptual similarity defines the neighborhood)</p>
    <p>SP ML</p>
    <p>Domain-Markovian</p>
    <p>Range-Markovian</p>
    <p>(22 December 2000),Science 290 (5500), 2323.</p>
  </div>
  <div class="page">
    <p>Unification Using Factor Unification Using Factor GraphsGraphs</p>
    <p>f1 f2 f3 f4</p>
    <p>B1 B2 B3 B4</p>
    <p>naive Bayesian (DCT/wavelet-based models)</p>
    <p>MRF-based</p>
    <p>B0</p>
    <p>B1 B2</p>
    <p>B3</p>
    <p>x</p>
    <p>B0 B1 B3B2</p>
    <p>B0</p>
    <p>B1</p>
    <p>B2 B3</p>
    <p>kNN/kmeans clustering (nonlocal image models)</p>
  </div>
  <div class="page">
    <p>A Manifold Interpretation A Manifold Interpretation of Nonlocal Image Priorof Nonlocal Image Prior</p>
    <p>MRN</p>
    <p>B1 Bk</p>
    <p>B0</p>
    <p>][ 10BD</p>
    <p>]''[' 10 BD</p>
    <p>How to maximize the sparsity of a representation? Conventional wisdom: adapt basis to signal (e.g., basis pursuit, matching pursuit) New proposal: adapt signal to basis (by probing its underlying organization principle)</p>
  </div>
  <div class="page">
    <p>Organizing Principle: Organizing Principle: Latent Variable LLatent Variable L</p>
    <p>P(y|x) x y</p>
    <p>image denoising</p>
    <p>image inpainting</p>
    <p>image coding</p>
    <p>image halftoning</p>
    <p>L B11</p>
    <p>B22 B14B13B12</p>
    <p>B41 B31</p>
    <p>B21 B33B32</p>
    <p>B23 B24 B34</p>
    <p>B44B43B42</p>
    <p>fBfA fC</p>
    <p>image deblurring</p>
    <p>Ff</p>
    <p>jj Ff</p>
    <p>jj</p>
    <p>jj</p>
    <p>ffp )()()( 1STDx</p>
    <p>)()1()0( kiiij BBBD  sparsifying transform</p>
    <p>Nature is not economical of structures but organizing principles. - Stanislaw M. Ulam</p>
    <p>L</p>
  </div>
  <div class="page">
    <p>Maximum-Likelihood Maximum-Likelihood Estimation of Graph Estimation of Graph</p>
    <p>Structure LStructure L</p>
    <p>Pack into 3D Array D</p>
    <p>For. Trans.</p>
    <p>Coring</p>
    <p>B0 BkB1</p>
    <p>Inv. Trans.</p>
    <p>unpack into 2D patches</p>
    <p>B0 BkB1  ^ ^ ^</p>
    <p>Update the estimate of L</p>
    <p>Update the estimate of x</p>
    <p>loop over every factor node fj</p>
    <p>A variational interpretation of such EM-based inference on FGs is referred to the paper</p>
    <p>P(y|x)</p>
  </div>
  <div class="page">
    <p>Problem 1: Image Problem 1: Image DenoisingDenoising</p>
    <p>PSNR(DB) PERFORMANCE COMPARISON AMO NG DIFFERENT SCHEMES FOR 12 TEST IMAGE S ATw = 100</p>
    <p>SSIM PERFORMANCE COMPARISON AMONG D IFFERENT SCHEMES FOR 12 TEST IMAGES AT w = 100</p>
    <p>BM3D (kNN,iter=2)</p>
    <p>SFG (kmeans,iter=20)  w</p>
    <p>org. 200 400 600 800 1000</p>
  </div>
  <div class="page">
    <p>Problem 2: Image Problem 2: Image RecoveryRecovery</p>
    <p>top-down: test1, test3, test5</p>
    <p>top-down: test2, test4, test6</p>
    <p>DCT FoE EXP BM3D LSP SFG</p>
    <p>PSNR(dB) performance comparison</p>
    <p>SSIM performance comparison</p>
    <p>Local models: DCT, FoE and LSP Nonlocal models: EXP, BM3D1 and SFG 1Our own extension into image recovery</p>
    <p>x y</p>
  </div>
  <div class="page">
    <p>x y bicubic NEDI1 FG</p>
    <p>Problem 3: Resolution Problem 3: Resolution EnhancementEnhancement</p>
  </div>
  <div class="page">
    <p>x y DT KR FG1</p>
    <p>Problem 4: Irregular Problem 4: Irregular InterpolationInterpolation</p>
    <p>DT- Delauney Triangle-based (griddata under MATLAB)</p>
    <p>KR- Kernal Regression-based (Takeda et al. IEEE TIP 2007 w/o parameter optimization)</p>
  </div>
  <div class="page">
    <p>Problem 5: Post-Problem 5: Postprocessingprocessing</p>
    <p>JPEG-decoded at rate of 0.32bpp (PSNR=32.07dB)</p>
    <p>SFG-enhanced at rate of 0.32bpp (PSNR=33.22dB)</p>
    <p>SPIHT-decoded at rate of 0.20bpp (PSNR=26.18dB)</p>
    <p>SFG-enhanced at rate of 0.20bpp (PSNR=27.33dB)</p>
    <p>Maximum-Likelihood (ML) Decoding</p>
    <p>Maximum a Posterior (MAP) Decoding</p>
  </div>
  <div class="page">
    <p>Problem 6: Inverse Problem 6: Inverse HalftoningHalftoning</p>
    <p>without nonlocal prior1 (PSNR=31.84dB, SSIM=0.8390)</p>
    <p>with nonlocal prior (PSNR=32.82dB, SSIM=0.8515)</p>
  </div>
  <div class="page">
    <p>Conclusions and Conclusions and PerspectivesPerspectives</p>
    <p>Despite the rich structures in natural images, Despite the rich structures in natural images, the underlying organization principle is simple the underlying organization principle is simple (self-similarity(self-similarity  We have shown how We have shown how similaritysimilarity can lead to can lead to sparsitysparsity in in</p>
    <p>a nonlinear representation of imagesa nonlinear representation of images  FG only represents one mathematical language for FG only represents one mathematical language for</p>
    <p>interpreting such principle (multifractal formalism is interpreting such principle (multifractal formalism is another)another)</p>
    <p>Image processing (low-level vision) could Image processing (low-level vision) could benefit from data clustering (higher-level benefit from data clustering (higher-level vision): how does human visual cortex learn to vision): how does human visual cortex learn to decode the latent variable L through decode the latent variable L through unsupervised learning?unsupervised learning?</p>
    <p>Reproducible Research: MATLAB codes accompanying this work are available at http://www.csee.wvu.edu/~xinl/sfg.html (more will be added)</p>
  </div>
</Presentation>
