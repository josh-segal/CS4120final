<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>ClickOS and the Art of Network Function Virtualization</p>
    <p>Joao Martins*, Mohamed Ahmed*, Costin Raiciu, Roberto Bifulco*, Vladimir Olteanu, Michio Honda*, Felipe Huici*</p>
    <p>* NEC Labs Europe, Heidelberg, Germany</p>
    <p>University Politehnica of Bucharest</p>
    <p>firstname.lastname@neclab.eu, firstname.lastname@cs.pub.ro</p>
  </div>
  <div class="page">
    <p>The Idealized Network</p>
    <p>Physical</p>
    <p>Datalink</p>
    <p>Network</p>
    <p>Transport</p>
    <p>Application</p>
    <p>Physical</p>
    <p>Datalink</p>
    <p>Network</p>
    <p>Transport</p>
    <p>Application</p>
    <p>Physical</p>
    <p>Datalink</p>
    <p>Network</p>
    <p>Physical</p>
    <p>Datalink</p>
    <p>Page 2</p>
  </div>
  <div class="page">
    <p>A Middlebox World</p>
    <p>Page 3</p>
    <p>carrier-grade NAT</p>
    <p>load balancer</p>
    <p>DPI QoE monitor</p>
    <p>ad insertion</p>
    <p>BRAS</p>
    <p>session border controller</p>
    <p>transcoder</p>
    <p>WAN accelerator</p>
    <p>DDoS protection</p>
    <p>firewall</p>
    <p>IDS</p>
  </div>
  <div class="page">
    <p>Hardware Middleboxes - Drawbacks</p>
    <p>Expensive equipment/power costs</p>
    <p>Difcult to add new features (vendor lock-in)</p>
    <p>Difcult to manage</p>
    <p>Cannot be scaled on demand (peak planning)</p>
    <p>Page 4</p>
  </div>
  <div class="page">
    <p>Page 5</p>
    <p>Shifting Middlebox Processing to Software</p>
    <p>Can share the same hardware across multiple users/tenants</p>
    <p>Reduced equipment/power costs through consolidation</p>
    <p>Safe to try new features on a operational network/platform</p>
    <p>But can it be built using commodity hardware while still achieving high performance?</p>
    <p>ClickOS: tiny Xen-based virtual machine that runs Click</p>
  </div>
  <div class="page">
    <p>From Thought to Reality - Requirements</p>
    <p>Page 6</p>
    <p>ClickOSClickOS</p>
    <p>provided by Xen</p>
    <p>* for most packet sizes</p>
    <p>provided by Click</p>
    <p>Fast Instantiation</p>
    <p>Small footprint</p>
    <p>Isolation</p>
    <p>Performance</p>
    <p>Flexibility</p>
  </div>
  <div class="page">
    <p>What's ClickOS ?</p>
    <p>domU</p>
    <p>paravirt</p>
    <p>apps</p>
    <p>guest OS</p>
    <p>ClickOS</p>
    <p>paravirt</p>
    <p>Click</p>
    <p>mini OS</p>
    <p>Page 7</p>
    <p>Work consisted of:  Build system to create ClickOS images (5 MB in size)  Emulating a Click control plane over MiniOS/Xen  Reducing boot times (roughly 30 milliseconds)  Optimizations to the data plane (10 Gb/s for almost all pkt sizes)  Implementation of a wide range of middleboxes</p>
  </div>
  <div class="page">
    <p>netback</p>
    <p>packet size (bytes)</p>
    <p>Performance analysis</p>
    <p>Page 8</p>
    <p>Driver Domain (or Dom 0) ClickOS Domain</p>
    <p>Xen bus/store</p>
    <p>Event channel</p>
    <p>netfront</p>
    <p>Xen ring API (data)</p>
    <p>NW driver OVS</p>
    <p>vif</p>
    <p>Click</p>
    <p>ToDevice</p>
    <p>FromDevice</p>
  </div>
  <div class="page">
    <p>Performance analysis</p>
    <p>Page 9</p>
    <p>Copying packets between guests greatly afects packet I/O (1)</p>
    <p>Packet metadata allocations (2)</p>
    <p>Backend switch is slow (3)</p>
    <p>MiniOS netfront not as good as Linux</p>
    <p>netback</p>
    <p>Driver Domain (or Dom 0) ClickOS Domain</p>
    <p>Xen bus/store</p>
    <p>Event channel</p>
    <p>netfront</p>
    <p>Xen ring API</p>
    <p>NW driver OVS</p>
    <p>vif</p>
    <p>Click</p>
    <p>ToDevice</p>
    <p>FromDevice</p>
  </div>
  <div class="page">
    <p>Optimizing Network I/O  Backend Switch</p>
    <p>Page 10</p>
    <p>VALE</p>
    <p>netback</p>
    <p>Driver Domain (or Dom 0) ClickOS Domain</p>
    <p>netfront Xen bus/store</p>
    <p>Event channel</p>
    <p>Xen ring API (data)</p>
    <p>NW driver (netmap mode)</p>
    <p>port</p>
    <p>Click</p>
    <p>FromDevice</p>
    <p>ToDevice</p>
    <p>Reuse Xen page permissions (frontend)</p>
    <p>Introduce VALE[1] as the backend switch</p>
    <p>Increase I/O requests batch size</p>
    <p>OVS</p>
    <p>[1] VALE, a switched ethernet for virtual machines, ACM CoNEXT'2012 Luigi Rizzo, Giuseppe Lettieri Universita di Pisa</p>
  </div>
  <div class="page">
    <p>VALE</p>
    <p>Optimizing Network I/O</p>
    <p>Page 11</p>
    <p>Driver Domain (or Dom 0) ClickOS Domain</p>
    <p>netfront</p>
    <p>NW driver Click</p>
    <p>FromDevice</p>
    <p>ToDevice</p>
    <p>netback</p>
    <p>Netmap API (data)</p>
    <p>Minimal memory requirements  For max. throughput a guest only needs 4 MB of</p>
    <p>memory</p>
    <p>Breaks other (non-MiniOS) guests  But we have implemented Linux netfront driver</p>
    <p>slots KB (per ring)</p>
    <p># grants (per ring)</p>
    <p>netback</p>
    <p>port</p>
    <p>Xen bus/store</p>
    <p>Event channel</p>
    <p>Xen ring API (data)</p>
  </div>
  <div class="page">
    <p>ClickOS Prototype Overview</p>
    <p>Click changes are minimal ~600 LoC</p>
    <p>New toolstack for fast boot times</p>
    <p>Cross compile toolchain for MiniOS-based apps</p>
    <p>netback changes comprise ~500 LoC</p>
    <p>netfront (Linux/MiniOS) around ~600 LoC</p>
    <p>VALE switch extended to:  Connect NIC ports and modular switching</p>
    <p>Page 12</p>
  </div>
  <div class="page">
    <p>EVALUATION</p>
    <p>Page 13</p>
  </div>
  <div class="page">
    <p>Experiments</p>
    <p>ClickOS Instantiation  State reading/insertion performance  Delay compared with other systems  Memory footprint</p>
    <p>Switch performance for 1+ NICs  ClickOS/MiniOS performance  Chaining experiments  Scalability over multiple guests  Scalability over multiple NICs  Implementation and evaluation of middleboxes  Linux Performance</p>
    <p>Page 15</p>
  </div>
  <div class="page">
    <p>ClickOS Base Performance</p>
    <p>Intel Xeon E1220 4-core 3.2GHz (Sandy bridge) 16GB RAM, 1x Intel x520 10Gb/s NIC. One CPU core assigned to VMs, the rest to the Domain-0 Linux 3.6.10</p>
    <p>Page 16</p>
    <p>ClickOS Measurement Box</p>
  </div>
  <div class="page">
    <p>ClickOS Base TX Performance</p>
    <p>Page 17</p>
  </div>
  <div class="page">
    <p>ClickOS (virtualized) Middlebox Performance</p>
    <p>Page 18</p>
    <p>ClickOS Host 2Host 1</p>
    <p>Intel Xeon E1220 4-core 3.2GHz (Sandy bridge) 16GB RAM, 2x Intel x520 10Gb/s NIC. One CPU core assigned to Vms, 3 CPU cores Domain-0 Linux 3.6.10</p>
  </div>
  <div class="page">
    <p>ClickOS (virtualized) Middlebox Performance</p>
    <p>Page 19</p>
  </div>
  <div class="page">
    <p>Linux Guest Performance</p>
    <p>Note that our Linux optimizations apply only to netmap-based applications</p>
    <p>Page 20</p>
  </div>
  <div class="page">
    <p>It's Open Source!</p>
    <p>Page 21</p>
    <p>Checkout http://cnp.neclab.eu  ClickOS, Backend Switch, Xen optimizations and more!  Github ( https://github.com/cnplab )  Tutorials  Better performance!</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Page 22</p>
    <p>Virtual machines can do fexible high speed networking</p>
    <p>ClickOS: Tailor-made operating system for network processing  Small is better: Low footprint is the key to heavy consolidation  Memory footprint: 5MB  Boot time: 30ms</p>
    <p>Future work:  Massive consolidation of VMs (thousands)  Improved Inter-VM communication for service chaining  Reactive VMs (e.g., per-fow)</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>ClickOS Boot times</p>
    <p>Page 24</p>
  </div>
  <div class="page">
    <p>Scaling out  Multiple NICs/VMs</p>
    <p>Intel Xeon E1650 6-core 3.2GHz, 16GB RAM, dual-port Intel x520 10Gb/s NIC. 3 cores assigned to VMs, 3 cores for dom0</p>
    <p>Page 25</p>
    <p>ClickOS Host 2</p>
    <p>Host 1</p>
  </div>
  <div class="page">
    <p>Scaling out  100 VMs Aggregate Throughput</p>
    <p>Intel Xeon E1650 6-core 3.2GHz, 16GB RAM, dual-port Intel x520 10Gb/s NIC. 3 cores assigned to VMs, 3 cores for dom0</p>
    <p>Page 26</p>
  </div>
  <div class="page">
    <p>ClickOS Delay vs. Other Systems</p>
    <p>Page 27</p>
  </div>
</Presentation>
