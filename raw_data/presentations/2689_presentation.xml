<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Ernest Efficient Performance Prediction for Large-Scale Advanced Analytics</p>
    <p>Shivaram Venkataraman, Zongheng Yang Michael Franklin, Benjamin Recht, Ion Stoica</p>
  </div>
  <div class="page">
    <p>Workload TRENDS: ADVANCED ANALYTICS</p>
  </div>
  <div class="page">
    <p>Workload Trends: Advanced Analytics</p>
  </div>
  <div class="page">
    <p>Workload Trends: Advanced Analytics</p>
  </div>
  <div class="page">
    <p>Workload Trends: Advanced Analytics</p>
  </div>
  <div class="page">
    <p>Keystone-ML TIMIT PIPELINE</p>
    <p>Cosine Transform Normalization Linear Solver Raw Data</p>
  </div>
  <div class="page">
    <p>Cosine Transform</p>
    <p>Normalization</p>
    <p>Linear Solver</p>
    <p>~100 iterations</p>
    <p>Iterative (each iteration many jobs)</p>
    <p>Long Running  Expensive</p>
    <p>Numerically Intensive</p>
    <p>Keystone-ML TIMIT PIPELINE Raw Data</p>
    <p>Properties</p>
  </div>
  <div class="page">
    <p>Cloud Computing CHOICEs</p>
    <p>Amazon EC2</p>
    <p>t2.nano, t2.micro, t2.small m4.large, m4.xlarge, m4.2xlarge, m4.4xlarge, m3.medium, c4.large, c4.xlarge, c4.2xlarge, c3.large, c3.xlarge, c3.4xlarge, r3.large, r3.xlarge, r3.4xlarge, i2.2xlarge, i2.4xlarge, d2.xlarge d2.2xlarge, d2.4xlarge,</p>
    <p>MICROSOFT AZURE</p>
    <p>Basic tier: A0, A1, A2, A3, A4 Optimized Compute : D1, D2, D3, D4, D11, D12, D13 D1v2, D2v2, D3v2, D11v2, Latest CPUs: G1, G2, G3,  Network Optimized: A8, A9 Compute Intensive: A10, A11,</p>
    <p>n1-standard-1, ns1-standard-2, ns1-standard-4, ns1-standard-8, ns1-standard-16, ns1highmem-2, ns1-highmem-4, ns1-highmem-8, n1-highcpu-2, n1-highcpu-4, n1highcpu-8, n1-highcpu-16, n1highcpu-32, f1-micro, g1-small</p>
    <p>Google Cloud Engine</p>
    <p>Instance Types and Number of Instances</p>
  </div>
  <div class="page">
    <p>TYRANNY of CHOICE</p>
  </div>
  <div class="page">
    <p>User Concerns</p>
    <p>What is the cheapest configuration to run my job in 2 hours? Given a budget, how fast can I run my job ? What kind of instances should I use on EC2 ?</p>
  </div>
  <div class="page">
    <p>DO CHOICES MATTER ? MATRIX MULTIPLY</p>
    <p>Ti m</p>
    <p>e (s</p>
    <p>)</p>
    <p>Matrix size: 400K by 1K</p>
    <p>Cores = 16 Memory = 244 GB Cost = $2.66/hr</p>
  </div>
  <div class="page">
    <p>DO CHOICES MATTER ?</p>
    <p>Ti m</p>
    <p>e (s</p>
    <p>)</p>
    <p>Matrix Multiply: 400K by 1K</p>
    <p>Ti m</p>
    <p>e (s</p>
    <p>)</p>
    <p>QR Factorization 1M by 1K</p>
    <p>Network Bound Mem Bandwidth Bound</p>
  </div>
  <div class="page">
    <p>Ti m</p>
    <p>e (s</p>
    <p>)</p>
    <p>Cores</p>
    <p>Actual Ideal</p>
    <p>r3.4xlarge instances, QR Factorization:1M by 1K</p>
    <p>Do choices MATTER ?</p>
    <p>Computation + Communication  Non-linear Scaling</p>
  </div>
  <div class="page">
    <p>APPROACH</p>
    <p>Job Data +</p>
    <p>Performance Model</p>
    <p>Challenges</p>
    <p>Black Box Jobs</p>
    <p>Model Building Overhead</p>
    <p>Regular Structure + Few Iterations</p>
  </div>
  <div class="page">
    <p>Modeling Jobs</p>
  </div>
  <div class="page">
    <p>Computation patterns</p>
    <p>Time INPUT Time 1 machines</p>
  </div>
  <div class="page">
    <p>Communication Patterns</p>
    <p>ONE-To-ONE Tree DAG All-to-one</p>
    <p>CONSTANT LOG LINEAR</p>
  </div>
  <div class="page">
    <p>BASIC Model</p>
    <p>time = x1 + x2  input</p>
    <p>machines + x3  log(machines)+ x4 (machines)</p>
    <p>Serial Execution</p>
    <p>Computation (linear)</p>
    <p>Tree DAG</p>
    <p>All-to-One DAG</p>
    <p>Collect Training Data Fit Linear Regression</p>
  </div>
  <div class="page">
    <p>COLLECTING TRAINING DATA</p>
    <p>In pu</p>
    <p>t</p>
    <p>Machines</p>
    <p>Grid of input, machines</p>
    <p>Associate cost with each experiment</p>
    <p>Baseline: Cheapest configurations first</p>
  </div>
  <div class="page">
    <p>OPTIMAL Design of EXPERIMENTS</p>
    <p>p ro b ab</p>
    <p>il it y of</p>
    <p>co rr ec t d et ec ti on</p>
    <p>Figure 7.8 The Chernoff lower bound (solid line) and a Monte Carlo estimate (dashed line) of the probability of correct detection of symbol s1, as a function of . In this example the noise is Gaussian with zero mean and covariance 2I.</p>
    <p>We consider the problem of estimating a vector x  Rn from measurements or experiments</p>
    <p>yi = a T i x + wi, i = 1, . . . , m,</p>
    <p>where wi is measurement noise. We assume that wi are independent Gaussian random variables with zero mean and unit variance, and that the measurement vectors a1, . . . , am span R</p>
    <p>n. The maximum likelihood estimate of x, which is the same as the minimum variance estimate, is given by the least-squares solution</p>
    <p>x =</p>
    <p>! m&quot;</p>
    <p>i=1</p>
    <p>aia T i</p>
    <p>#1 m&quot;</p>
    <p>i=1</p>
    <p>yiai.</p>
    <p>The associated estimation error e = x  x has zero mean and covariance matrix</p>
    <p>E = E eeT =</p>
    <p>! m&quot;</p>
    <p>i=1</p>
    <p>aia T i</p>
    <p>#1 .</p>
    <p>The matrix E characterizes the accuracy of the estimation, or the informativeness of the experiments. For example the -confidence level ellipsoid for x is given by</p>
    <p>E = {z | (z  x)T E1(z  x)  },</p>
    <p>where  is a constant that depends on n and . We suppose that the vectors a1, . . . , am, which characterize the measurements,</p>
    <p>can be chosen among p possible test vectors v1, . . . , vp  Rn, i.e., each ai is one of</p>
    <p>Given a Linear Model</p>
    <p>Lower variance  Better model</p>
    <p>i - Fraction of times each experiment is run comparing two schemes: in the first scheme we collect data in an increasing order of machines and in the second scheme we use a mixed strategy as shown in Figure 6. From the figure we make two important observations: (a) in this particular case, the mixed strategy gets to a lower error quickly. After three data points we get to less than 15% error. (b) We see a trend of diminishing returns where adding more data points does not improve accuracy by much. Thus, in order to minimize the time spent on collecting training data we need techniques that will help us find how much training data is required and what those data points should be.</p>
    <p>More formally, consider the problem where we are trying to fit a linear model X given measurements y1, . . . , ym and features a1, . . . , am for each measurement. Each feature vector could in turn consist of a number of dimensions (say n dimensions). In the case of a linear model we typically estimate X using linear regression. We can denote this estimate as X and X  X is the estimation error or a measure of how far our model is from the true model.</p>
    <p>To measure estimation error we can compute the Mean Squared Error (MSE) which takes into account both the bias and the variance of the estimator. In the case of the linear model above if we have m data points each having n features, then the variance of the estimator is represented</p>
    <p>by the n  n covariance matrix ( mP i=1</p>
    <p>aia T i )</p>
    <p>1. The key point</p>
    <p>to note here is that the covariance matrix only depends on the feature vectors that were used for this experiment and not on the model that we are estimating.</p>
    <p>In optimal experiment design we choose feature vectors (i.e. ai) that minimize the estimation error. Thus we can frame this as an optimization problem where we minimize the estimation error subject to some constraints on the cost or number of experiments we wish to run. More formally we</p>
    <p>can set i as the fraction of time an experiment is chosen and minimize the trace of the covariance matrix:</p>
    <p>Minimize tr(( mX</p>
    <p>i=1</p>
    <p>iaia T i )</p>
    <p>1 )</p>
    <p>subject to i  0, i  1</p>
    <p>Using Experiment Design: The predictive model we described in the previous section can be formulated as an experiment design problem. The feature set used for model design consisted of just the scale of the data used and the number of machines used for the experiment. Given some bounds for the scale and number of machines we want to explore, we can come up with all the features that could be used in our experiment. For example if the scale bounds range from say 1% to 10% of the data and the number of machine we can use ranges from 1 to 5, we can enumerate 50 different feature vectors from all the scale and machine values possible. We can then feed these feature vectors into the experiment design setup described above and only choose to run those experiments whose  values are non-zero. Accounting for Cost: One additional factor we need to consider in using experiment design is that each experiment we run costs a different amount. This cost could be in terms of time (i.e. it is more expensive to train with larger fraction of the input) or in terms of machines (i.e. there is a fixed cost to say launching a machine). To account for the cost of an experiment we can augment the optimization problem we setup above with an additional constraint that the total cost should be lesser than some budget. That is if we have a cost function which gives us a cost ci for an experiment with scale si and mi machines, we add a constraint to our solver that</p>
    <p>mP i=1</p>
    <p>cii  B where B is the total budget. For the rest</p>
    <p>of this paper we use the time taken to collect training data as the cost and ignore any machine setup costs as we can usually amortize that cost over all the training data we need to collect. However we can plug-in in any user-defined cost function in our framework. Implementation: The optimization problem we defined above can be solved using any standard convex programming solver like CVX [38, 39]. Even for a large range of scale and machine values we find that the time to complete this process is a few seconds. Thus we believe that there should be no additional overhead due to this step. Finally we also note that the results from experiment design can be used across multiple jobs as it only depends on the scale and number of machines under consideration.</p>
    <p>Bound total cost</p>
    <p>comparing two schemes: in the first scheme we collect data in an increasing order of machines and in the second scheme we use a mixed strategy as shown in Figure 6. From the figure we make two important observations: (a) in this particular case, the mixed strategy gets to a lower error quickly. After three data points we get to less than 15% error. (b) We see a trend of diminishing returns where adding more data points does not improve accuracy by much. Thus, in order to minimize the time spent on collecting training data we need techniques that will help us find how much training data is required and what those data points should be.</p>
    <p>More formally, consider the problem where we are trying to fit a linear model X given measurements y1, . . . , ym and features a1, . . . , am for each measurement. Each feature vector could in turn consist of a number of dimensions (say n dimensions). In the case of a linear model we typically estimate X using linear regression. We can denote this estimate as X and X  X is the estimation error or a measure of how far our model is from the true model.</p>
    <p>To measure estimation error we can compute the Mean Squared Error (MSE) which takes into account both the bias and the variance of the estimator. In the case of the linear model above if we have m data points each having n features, then the variance of the estimator is represented</p>
    <p>by the n  n covariance matrix ( mP i=1</p>
    <p>aia T i )</p>
    <p>1. The key point</p>
    <p>to note here is that the covariance matrix only depends on the feature vectors that were used for this experiment and not on the model that we are estimating.</p>
    <p>In optimal experiment design we choose feature vectors (i.e. ai) that minimize the estimation error. Thus we can frame this as an optimization problem where we minimize the estimation error subject to some constraints on the cost or number of experiments we wish to run. More formally we</p>
    <p>can set i as the fraction of time an experiment is chosen and minimize the trace of the covariance matrix:</p>
    <p>Minimize tr(( mX</p>
    <p>i=1</p>
    <p>iaia T i )</p>
    <p>1 )</p>
    <p>subject to i  0, i  1</p>
    <p>Using Experiment Design: The predictive model we described in the previous section can be formulated as an experiment design problem. The feature set used for model design consisted of just the scale of the data used and the number of machines used for the experiment. Given some bounds for the scale and number of machines we want to explore, we can come up with all the features that could be used in our experiment. For example if the scale bounds range from say 1% to 10% of the data and the number of machine we can use ranges from 1 to 5, we can enumerate 50 different feature vectors from all the scale and machine values possible. We can then feed these feature vectors into the experiment design setup described above and only choose to run those experiments whose  values are non-zero. Accounting for Cost: One additional factor we need to consider in using experiment design is that each experiment we run costs a different amount. This cost could be in terms of time (i.e. it is more expensive to train with larger fraction of the input) or in terms of machines (i.e. there is a fixed cost to say launching a machine). To account for the cost of an experiment we can augment the optimization problem we setup above with an additional constraint that the total cost should be lesser than some budget. That is if we have a cost function which gives us a cost ci for an experiment with scale si and mi machines, we add a constraint to our solver that</p>
    <p>mP i=1</p>
    <p>cii  B where B is the total budget. For the rest</p>
    <p>of this paper we use the time taken to collect training data as the cost and ignore any machine setup costs as we can usually amortize that cost over all the training data we need to collect. However we can plug-in in any user-defined cost function in our framework. Implementation: The optimization problem we defined above can be solved using any standard convex programming solver like CVX [38, 39]. Even for a large range of scale and machine values we find that the time to complete this process is a few seconds. Thus we believe that there should be no additional overhead due to this step. Finally we also note that the results from experiment design can be used across multiple jobs as it only depends on the scale and number of machines under consideration.</p>
  </div>
  <div class="page">
    <p>OPTIMAL Design of EXPERIMENTS</p>
    <p>In pu</p>
    <p>t</p>
    <p>Machines</p>
    <p>Use off-the-shelf solver (CVX)</p>
  </div>
  <div class="page">
    <p>USING ERNEST</p>
    <p>Training Jobs</p>
    <p>Job Binary</p>
    <p>Machines, Input Size</p>
    <p>Linear Model</p>
    <p>Experiment Design</p>
    <p>Use few iterations for training</p>
    <p>Ti m</p>
    <p>e</p>
    <p>Machines</p>
    <p>ERNEST</p>
  </div>
  <div class="page">
    <p>MORE in the paper</p>
    <p>Detecting when the model is wrong Model extensions Amazon EC2 variations over time Straggler mitigation strategies Sparse datasets</p>
  </div>
  <div class="page">
    <p>EVALUATION</p>
  </div>
  <div class="page">
    <p>Workloads Keystone-ML</p>
    <p>Spark MLlib ADAM</p>
    <p>GenBase Sparse GLMs</p>
    <p>Random Projections</p>
    <p>OBJECTIVES Optimal number of machines Prediction accuracy Model training overhead Importance of experiment design Choosing EC2 instance types Model extensions</p>
  </div>
  <div class="page">
    <p>Workloads Keystone-ML</p>
    <p>Spark MLlib ADAM</p>
    <p>GenBase Sparse GLMs</p>
    <p>Random Projections</p>
    <p>OBJECTIVES Optimal number of machines Prediction accuracy Model training overhead Importance of experiment design Choosing EC2 instance types Model extensions</p>
  </div>
  <div class="page">
    <p>NUMBER OF INSTANCES: Keystone-ml</p>
    <p>TIMIT Pipeline on r3.xlarge instances, 100 iterations</p>
    <p>Ti m</p>
    <p>e (s</p>
    <p>)</p>
    <p>Machines</p>
    <p>For 2 hour deadline, up to 5x lower cost</p>
  </div>
  <div class="page">
    <p>ACCURACY: Keystone-ml</p>
    <p>TIMIT Pipeline on r3.xlarge instances, Time Per Iteration</p>
    <p>e Pe</p>
    <p>r I te</p>
    <p>ra tio</p>
    <p>n (s</p>
    <p>)</p>
    <p>Machines</p>
  </div>
  <div class="page">
    <p>TRAINING TIME: Keystone-ml</p>
    <p>TIMIT Pipeline on r3.xlarge instances, 100 iterations</p>
    <p>EXPERIMENT DESIGN</p>
    <p>Time (s)</p>
    <p>Training Time Running Time</p>
  </div>
  <div class="page">
    <p>Regression</p>
    <p>Classification</p>
    <p>KMeans</p>
    <p>PCA</p>
    <p>TIMIT</p>
    <p>Prediction Error (%)</p>
    <p>Experiment Design</p>
    <p>Cost-based</p>
    <p>Is Experiment Design useful ?</p>
  </div>
  <div class="page">
    <p>IN Conclusion</p>
    <p>Workload Trends: Advanced Analytics in the Cloud Computation, Communication patterns affect scalability Ernest: Performance predictions with low overhead</p>
    <p>End-to-end linear model Optimal experimental design</p>
  </div>
</Presentation>
