<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Raising the Bar for Using GPUs! in</p>
    <p>Software Packet Processing</p>
    <p>Anuj Kalia (CMU) Dong Zhou (CMU)</p>
    <p>Michael Kaminsky (Intel Labs) David Andersen (CMU)</p>
  </div>
  <div class="page">
    <p>Software Packet Processing  Is important</p>
    <p>!</p>
    <p>But slow</p>
    <p>eXpressive Internet Architecture</p>
    <p>x86 ASIC</p>
  </div>
  <div class="page">
    <p>GPU acceleration IPv4/IPv6: PacketShader[SIGCOMM 10], GALE[INFOCOM 11], GAMT[ANCS 13], NBA[EuroSys 15]</p>
    <p>NDN: MATA[NSDI 13]</p>
    <p>NIDS: Kargus[CCS 12], NBA[EuroSys 15], Snap[ANCS 14] !</p>
    <p>Frameworks: GASPP[ATC 14], Snap[ANCS 14], NBA[EuroSys 15]</p>
  </div>
  <div class="page">
    <p>Raising the bar: optimize CPU code</p>
    <p>Fa ct</p>
    <p>or s</p>
    <p>pe ed</p>
    <p>up</p>
    <p>IPv4 L2 Switch IPv6</p>
    <p>GPU acceleration CPU code optimization (G-Opt)</p>
  </div>
  <div class="page">
    <p>CPU/GPU Packet Processing</p>
    <p>&gt; 10x computing power ~ 4x memory bandwidth</p>
  </div>
  <div class="page">
    <p>Rethink GPU advantages</p>
    <p>Higher computation power</p>
    <p>Most applications not compute intensive</p>
    <p>Higher memory bandwidth Most applications not memory intensive</p>
    <p>Memory latency hiding</p>
  </div>
  <div class="page">
    <p>Memory latency hiding</p>
    <p>Thread 1 Thread 2 Thread 1</p>
    <p>Fast, hardware-supported context switch</p>
    <p>CuckooSwitch [CoNEXT 13]: manual group-prefetching  Grappa [U. Washington]: lightweight context switching</p>
    <p>to hide RDMA latency</p>
    <p>CPUs</p>
    <p>GPUs</p>
  </div>
  <div class="page">
    <p>find(key *K, value *V) {! int i! for(i = 0; i &lt; B; i++) {! int idx = hash(K[i])! value *ptr = table[idx].ptr! V[i] = *ptr! }! }</p>
    <p>table</p>
    <p>K1 K2</p>
    <p>KB</p>
    <p>Value V1 V2</p>
    <p>VB</p>
    <p>Cache misses!</p>
    <p>CPU memory latency hiding</p>
  </div>
  <div class="page">
    <p>find(key *K, value *V) {! int i, idx[B]! value *ptr[B]! ! for(i = 0; i &lt; B; i++) {! idx[i] = hash(K[i])! prefetch(&amp;table[idx[i]])! }! ! for(i = 0; i &lt; B; i++) {! ptr[i] = table[idx[i]].ptr! prefetch(ptr[i])! }! ! V[i] = *ptr[i]! }! 9</p>
    <p>idx[0] = hash(k[0])! prefetch()</p>
    <p>idx[1] = hash(k[1])! prefetch()</p>
    <p>idx[2] = hash(k[2])! prefetch()</p>
    <p>ptr[0] = ..</p>
    <p>Strawman: Group Prefetching</p>
  </div>
  <div class="page">
    <p>int idx = hash(K[i])! value *ptr = table[idx].ptr! V[i] = *ptr</p>
    <p>entry</p>
    <p>exit</p>
    <p>entry</p>
    <p>for.cond</p>
    <p>T F</p>
    <p>for.body</p>
    <p>T F</p>
    <p>for.end</p>
    <p>T F</p>
    <p>if.then if.end</p>
    <p>if.then8</p>
    <p>if.end28</p>
    <p>for.inc</p>
    <p>for.cond11</p>
    <p>T F</p>
    <p>for.body13</p>
    <p>T F</p>
    <p>for.end27</p>
    <p>if.then19 if.end24</p>
    <p>for.inc25</p>
    <p>Toy hash table Cuckoo hashing</p>
  </div>
  <div class="page">
    <p>GPU programming model Programmer writes batched independent code</p>
    <p>find(key *K, value *V) {! int i! for(i = 0; i &lt; B; i++) {! int idx = hash(K[i])! value *ptr = table[idx].ptr! V[i] = *ptr! }! }</p>
    <p>Switching on CPUs is fast with batched independent code.</p>
  </div>
  <div class="page">
    <p>G-Opt: Element switching!</p>
    <p>Specialization to batched independent functions: Save state in local arrays. Switch using goto.</p>
    <p>SpeedGenerality</p>
    <p>Kernel threads! Preemptive scheduling Independent threads ~500 ns (2 M/s)</p>
    <p>Grappas user threads! Cooperative scheduling Same application ~25 ns (40 M/s)</p>
    <p>GPU threads (SIMD)! From batched independent code Hardware speed</p>
    <p>G-Opt elements! From batched independent code 100-300 M/s</p>
  </div>
  <div class="page">
    <p>find(key K, value V) {! int idx! value *ptr! ! idx = hash(K)! ! ptr = table[idx].ptr! ! V = *ptr! ! }</p>
    <p>A G-Opt example</p>
    <p>_expensive_(&amp;table[idx])</p>
    <p>_expensive_(ptr)</p>
  </div>
  <div class="page">
    <p>_expensive_(&amp;table[idx[I]])</p>
    <p>find(key *K, value *V) {! int idx[B]! value *ptr[B]! ! idx[I] = hash(K[I])! ! ptr[I] = table[idx[I]].ptr! ! V[I] = *ptr[I]! ! }</p>
    <p>Convert to batched function</p>
    <p>_expensive_(ptr[I])</p>
  </div>
  <div class="page">
    <p>_expensive_(&amp;table[idx[I]])</p>
    <p>_expensive_(ptr[I])</p>
    <p>find(key *K, value *V) {! int idx[B]! value *ptr[B]! ! idx[I] = hash(K[I])! ! ptr[I] = table[idx[I]].ptr! ! V[I] = *ptr[I]! ! }</p>
    <p>State = Arrays + saved PPs Prefetch, Save, Switch! ! PSS(addr, PP):! // PREFETCH! prefetch(addr)! ! // SAVE! PP[I] = PP! ! // SWITCH! I = (I + 1) % B! goto *PP[I]</p>
  </div>
  <div class="page">
    <p>find(key *K, value *V) {! int idx[B]! value *ptr[B]! ! ! ! ! idx[I] = hash(K[I])! PSS(&amp;table[idx[I]], label_1)! label_1:! ptr[I] = table[idx[I]].ptr! ! PSS(ptr[I], label_2)! label_2:! V[I] = *ptr[I]! ! ! ! ! }</p>
    <p>// Setup code! label_0:</p>
    <p>label_end:! // Termination code</p>
  </div>
  <div class="page">
    <p>Why G-Opt works More variables, code, branches = Optimization?</p>
    <p>Fa ct</p>
    <p>or in</p>
    <p>cr ea</p>
    <p>se w</p>
    <p>ith</p>
    <p>G -O</p>
    <p>pt</p>
    <p>Cuckoo Ptr Chasing IPv6</p>
    <p>Instruction count IPC</p>
    <p>Cuckoo Ptr Chasing IPv6</p>
    <p>G-Opt speedup Manual speedup</p>
  </div>
  <div class="page">
    <p>G-Opt for Packet Processing</p>
    <p>Application Code Lines of code Annotations</p>
    <p>IPv4 forwarding DPDK library 42 1</p>
    <p>IPv6 forwarding DPDK library 43 1</p>
    <p>Layer-2 switch Our own 54 2</p>
    <p>NDN forwarding Our own 79 2</p>
  </div>
  <div class="page">
    <p>Experiment Setup</p>
    <p>Intel Xeon E5-2680 NVIDIA GTX 980</p>
    <p>Execution units 8 SandyBridge cores 2048 CUDA cores</p>
    <p>Sequential memory bandwidth 51.2 GB/s 224 GB/s</p>
  </div>
  <div class="page">
    <p>Th ro</p>
    <p>ug hp</p>
    <p>ut (M</p>
    <p>pp s)</p>
    <p>Total CPU cores 0 1 2 3 4 5</p>
    <p>IPv4 forwarding 1.6x throughput increase Cost of IPv4 lookup ~9%</p>
    <p>Fo rwa</p>
    <p>rdi ng</p>
    <p>lim it</p>
    <p>Base line</p>
    <p>IPv4</p>
    <p>GP U I</p>
    <p>Pv4</p>
    <p>GOp</p>
    <p>t IP v4</p>
  </div>
  <div class="page">
    <p>Th ro</p>
    <p>ug hp</p>
    <p>ut (M</p>
    <p>pp s)</p>
    <p>Total CPU cores 0 1 2 3 4 5</p>
    <p>Layer-2 switch</p>
    <p>Basel ine</p>
    <p>G-O pt</p>
    <p>GPU</p>
  </div>
  <div class="page">
    <p>Th ro</p>
    <p>ug hp</p>
    <p>ut (M</p>
    <p>pp s)</p>
    <p>Total CPU cores 0 1 2 3 4 5</p>
    <p>Baseline GPU G-Opt</p>
    <p>GPU (C=4) &gt; G-Opt (C=4)</p>
    <p>G-Opt (C=5) ~ GPU (C=4)</p>
    <p>IPv6 forwarding 3.8x throughput increase</p>
  </div>
  <div class="page">
    <p>GPU assumptions  CPU opts</p>
    <p>Optimizations for batched independent code</p>
    <p>This talk: G-Opt: General-purpose, automatic memory latency hiding</p>
    <p>In paper: Manual optimization of CPU pattern matching: 2.4x speedup</p>
    <p>The future: &lt;your optimization here&gt;</p>
  </div>
  <div class="page">
    <p>Summary  Improve CPU packet processing under GPU</p>
    <p>assumptions</p>
    <p>Fast switching for memory latency hiding</p>
    <p>Raising the bar with better baselines</p>
    <p>Code is online: https://github.com/efficient/gopt</p>
  </div>
  <div class="page">
    <p>Thanks!</p>
  </div>
</Presentation>
