<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Lance Hammond, Vicky Wong, Mike Chen, Brian D. Carlstrom, John D. Davis, Ben Hertzberg, Manohar K. Prabhu, Honggo Wijaya,</p>
    <p>Christos Kozyrakis, and Kunle Olukotun</p>
    <p>Stanford University http://tcc.stanford.edu</p>
    <p>June 21, 2004</p>
    <p>Transactional Memory Coherence and Consistency</p>
    <p>all transactions, all the time</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 2</p>
    <p>The Need for Parallelism</p>
    <p>Uniprocessor system scaling is hitting limits  Power consumption increasing dramatically  Wire delays becoming a limiting factor  Design and verification complexity is now overwhelming  Exploits limited instruction-level parallelism (ILP)</p>
    <p>So we need support for multiprocessors  Inherently avoid many of the design problems</p>
    <p>Replicate small cores, dont design big ones  Exploit thread-level parallelism (TLP)</p>
    <p>But can still use ILP within cores  But now we have new problems . . .</p>
    <p>Motivation</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 3</p>
    <p>Parallel Software Problems</p>
    <p>Parallel systems are often programmed with:  Synchronization through barriers  Shared variable access control through locks . . .</p>
    <p>Lock granularity and organization must balance performance and correctness  Coarse-grain locking: Lock contention  Fine-grain locking: Extra overhead  Must be careful to avoid deadlocks or races  Must be careful not to leave anything unprotected for correctness</p>
    <p>Performance tuning is not intuitive  Performance bottlenecks are related to low level events</p>
    <p>Such as: false sharing, coherence misses,   Feedback is often indirect (cache lines, not variables)</p>
    <p>Motivation</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 4</p>
    <p>Parallel Hardware Complexity</p>
    <p>Cache coherence protocols are complex  Must track ownership of cache lines  Difficult to implement and verify all corner cases</p>
    <p>Consistency protocols are complex  Must provide rules to correctly order individual loads/stores  Difficult for both hardware and software</p>
    <p>Current protocols rely on low latency, not bandwidth  Critical short control messages on ownership transfers (2-3 hops)  Latency of short messages unlikely to scale well in the future  Bandwidth likely to scale much better</p>
    <p>High-speed inter-chip connections Chip multiprocessors = on-chip bandwidth!</p>
    <p>Motivation</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 5</p>
    <p>The Key Question</p>
    <p>Is there a shared memory model with:  A simple programming model?  A simple hardware implementation?  Good performance?</p>
    <p>Motivation</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 6</p>
    <p>TCC: Using Transactions</p>
    <p>Yes! Provide generalized transactions  Programmer-defined groups of instructions within a program</p>
    <p>Begin Transaction Start Buffering Results Instruction #1 Instruction #2 . . .</p>
    <p>End Transaction Commit Results Now</p>
    <p>Can only commit machine state at the end of each transaction Each must update machine state atomically, all at once To other processors, all instructions within a transaction appear to execute only when the transaction commits These commits impose an order on how processors may modify machine state</p>
    <p>Just requires:  Register checkpointing mechanism  Transactional memory support . . .</p>
    <p>Overview</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 7</p>
    <p>Transactional Memory I</p>
    <p>Transactions appear to execute in the commit order  RAW dependence errors cause transaction violation &amp; restart</p>
    <p>Overview</p>
    <p>Time</p>
    <p>Transaction B</p>
    <p>Transaction A</p>
    <p>LOAD X</p>
    <p>STORE X LOAD X</p>
    <p>STORE X Commit X</p>
    <p>Time</p>
    <p>Transaction B</p>
    <p>Transaction A</p>
    <p>LOAD X</p>
    <p>STORE X LOAD X</p>
    <p>STORE X Commit X</p>
    <p>Violation!Time</p>
    <p>Transaction B</p>
    <p>Transaction A</p>
    <p>LOAD X</p>
    <p>STORE X LOAD X</p>
    <p>STORE X Commit X</p>
    <p>LOAD X</p>
    <p>STORE X</p>
    <p>Violation!</p>
    <p>Re-execute with new</p>
    <p>data</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 8</p>
    <p>Transactional Memory II</p>
    <p>Antidependencies are automatically handled  WAW are handled by writing buffers only in commit order  WAR are handled by keeping all writes private until commit</p>
    <p>Overview</p>
    <p>Time</p>
    <p>Transaction B</p>
    <p>Transaction A</p>
    <p>ST X = 1</p>
    <p>LOAD X</p>
    <p>Commit X</p>
    <p>ST X = 2</p>
    <p>LOAD X</p>
    <p>LOAD XCommit X</p>
    <p>Time</p>
    <p>Transaction B</p>
    <p>Transaction A</p>
    <p>ST X = 1</p>
    <p>LD X = 1</p>
    <p>Commit X</p>
    <p>Any Local Stores</p>
    <p>Supply Data</p>
    <p>ST X = 2</p>
    <p>LD X = 2</p>
    <p>LD X = 2Commit X</p>
    <p>Time</p>
    <p>Transaction B</p>
    <p>Transaction A</p>
    <p>ST X = 1</p>
    <p>LD X = 1</p>
    <p>X = 1</p>
    <p>X = 2 Commit X</p>
    <p>Later Transactions Started / Updated with Shared State</p>
    <p>Any Local Stores</p>
    <p>Supply Data</p>
    <p>ST X = 2</p>
    <p>LD X = 2 Commit X LD X = 2</p>
    <p>Time</p>
    <p>Transaction B</p>
    <p>Transaction A</p>
    <p>STORE X STORE X</p>
    <p>Commit X</p>
    <p>Commit X</p>
    <p>Transaction B</p>
    <p>Transaction A</p>
    <p>STORE X STORE X</p>
    <p>Commit X</p>
    <p>Commit X</p>
    <p>Local Buffer</p>
    <p>Shared Memory</p>
    <p>TimeTime</p>
    <p>Transaction B</p>
    <p>Transaction A</p>
    <p>STORE X STORE X</p>
    <p>Commit X</p>
    <p>Commit X</p>
    <p>Local Buffer</p>
    <p>Local Buffer</p>
    <p>Shared Memory</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 9</p>
    <p>TCCs Difference</p>
    <p>So what? Transactional memory is old news . . . .  Herlihy, et.al., proposed to replace locks a decade ago  Rajwar and Goodman / Martinez and Torrellas proposed more</p>
    <p>automated versions of the same thing recently  Thread-level speculation (TLS) uses transactional memory</p>
    <p>TCCs New Idea: Leave transactions on all of the time  Provides MANY new benefits  Completely eliminates conventional cache coherence and</p>
    <p>consistency models</p>
    <p>Overview</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 10</p>
    <p>The TCC Cycle</p>
    <p>Transactions now run in a cycle  Continues for all execution</p>
    <p>Speculatively execute code and buffer</p>
    <p>Wait for commit permission  Phase provides synchronization, if necessary  Arbitrate with other CPUs</p>
    <p>Commit stores together, as a block  Provides a well-defined write ordering  Can invalidate or update other caches  Large block utilizes bandwidth effectively</p>
    <p>And repeat!</p>
    <p>Overview</p>
    <p>Execute Code</p>
    <p>P0 Transaction</p>
    <p>Starts</p>
    <p>Wait for Phase</p>
    <p>Arbitrate</p>
    <p>Commit</p>
    <p>Transaction Completes</p>
    <p>Requests Commit</p>
    <p>Starts Commit</p>
    <p>Finishes Commit</p>
    <p>Execute Code</p>
    <p>P0 Transaction</p>
    <p>Starts</p>
    <p>Wait for Phase</p>
    <p>Arbitrate</p>
    <p>Commit</p>
    <p>Transaction Completes</p>
    <p>Requests Commit</p>
    <p>Starts Commit</p>
    <p>Finishes Commit</p>
    <p>P1 P2</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 11</p>
    <p>Advantages of TCC</p>
    <p>Trades bandwidth for simplicity &amp; latency tolerance  Easier to build  Not dependent on timing/latency of loads/stores</p>
    <p>Transactions eliminate locks  Transactions are inherently atomic  Catches most common parallel programming errors</p>
    <p>Shared memory consistency is simplified  Conventional model sequences individual loads and stores  Now only have hardware sequence transaction commits</p>
    <p>Shared memory coherence is simplified  Processors may have copies of cache lines in any state (no MESI)  Commit order implies an ownership sequence</p>
    <p>Overview</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 12</p>
    <p>How to Use TCC I</p>
    <p>Divide code into potentially parallel tasks  Usually loop iterations, after function calls, etc.  For initial division, tasks = transactions</p>
    <p>But can be subdivided up or grouped to match hardware limits (buffering)  Similar to threading in conventional parallel programming, but:</p>
    <p>We do not have to verify parallelism in advance Locking is handled automatically Therefore, much easier to get a parallel program running correctly!</p>
    <p>Programmer then orders transactions as necessary  Ordering techniques implemented using phase numbers</p>
    <p>Assign an age number to each transaction Deadlock-free (at least one transaction is always oldest) Livelock-free (watchdog hardware can easily insert barriers anywhere)</p>
    <p>Three common scenarios . . .</p>
    <p>Overview</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 13</p>
    <p>How to Use TCC II  Unordered for purely parallel code  Fully ordered to specify sequential tasks  Partially ordered to insert synchronization like barriers</p>
    <p>Barrier = Phase Transition</p>
    <p>Unordered Transactions</p>
    <p>Parallelized Sequential Code</p>
    <p>Transactions</p>
    <p>CPU 0 CPU 1 CPU 2</p>
    <p>Time</p>
    <p>Overview</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 14</p>
    <p>Sample TCC Hardware</p>
    <p>Write buffers and some L1 cache bits (TLS-like) Write buffer in processor, before broadcast</p>
    <p>A broadcast bus or network to distribute commit packets All processors see the commits in a single order Snooping on broadcasts triggers violations, if necessary</p>
    <p>Commit arbitration/sequencing logic</p>
    <p>Overview</p>
    <p>Local Cache Hierarchy</p>
    <p>Processor Core Stores Only</p>
    <p>Loads and Stores</p>
    <p>Commits to other nodes</p>
    <p>Write Buffer</p>
    <p>Snooping from other nodes</p>
    <p>Commit Control</p>
    <p>Phase Node 0: Node 1: Node 2:</p>
    <p>Broadcast Bus or Network</p>
    <p>Node #0</p>
    <p>Transaction Control Bits L1 Cache</p>
    <p>Read, Modified, etc.</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 15</p>
    <p>Evaluation Methodology</p>
    <p>We simulated a wide range of applications:  SPLASH-2, SPEC, Java, SpecJBB  Divided into transactions using a preliminary TCC API</p>
    <p>Trace-based analysis  Generated execution traces from sequential execution  Then analyzed the traces while varying:</p>
    <p>Number of processors Interconnect bandwidth Communication overheads</p>
    <p>Simplifications Results shown assume infinite caches and write-buffers</p>
    <p>But we track the amount of state stored in them Fixed one cycle/instruction</p>
    <p>Would require a reasonable superscalar processor for this rate</p>
    <p>Results</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 16</p>
    <p>Speedups with TCC</p>
    <p>TCC speedups are similar to conventional ones  And sometimes better: SPECjbb eliminates locking overhead</p>
    <p>within warehouses</p>
    <p>B</p>
    <p>B</p>
    <p>B</p>
    <p>B</p>
    <p>B B</p>
    <p>JJ J</p>
    <p>J J</p>
    <p>J</p>
    <p>H</p>
    <p>H</p>
    <p>H</p>
    <p>H</p>
    <p>H H</p>
    <p>F</p>
    <p>F</p>
    <p>F</p>
    <p>F</p>
    <p>F F</p>
    <p>M</p>
    <p>M</p>
    <p>M</p>
    <p>M</p>
    <p>M M</p>
    <p>S p</p>
    <p>e e</p>
    <p>d u</p>
    <p>p O</p>
    <p>v e</p>
    <p>r 1</p>
    <p>P ro</p>
    <p>c e</p>
    <p>s s o</p>
    <p>r</p>
    <p>Number of Processors</p>
    <p>B euler</p>
    <p>J fft</p>
    <p>H jbyte_B5</p>
    <p>F jbyte_B6</p>
    <p>jbyte_B8</p>
    <p>jbyte_B9</p>
    <p>moldyn</p>
    <p>mtrt</p>
    <p>M raytrace</p>
    <p>shallow</p>
    <p>Explicitly Parallel Applications TLS-Java Applications</p>
    <p>B</p>
    <p>B</p>
    <p>B</p>
    <p>B</p>
    <p>B B</p>
    <p>J</p>
    <p>J</p>
    <p>J</p>
    <p>J JJ</p>
    <p>H</p>
    <p>H</p>
    <p>H</p>
    <p>H</p>
    <p>H H</p>
    <p>F</p>
    <p>F</p>
    <p>F</p>
    <p>F</p>
    <p>F F</p>
    <p>MM</p>
    <p>M</p>
    <p>M M</p>
    <p>S p e e d u p O</p>
    <p>v e r</p>
    <p>ro c e s s o r</p>
    <p>Number of Processors</p>
    <p>B art</p>
    <p>J equake_l</p>
    <p>H equake_s</p>
    <p>F lu</p>
    <p>radix</p>
    <p>SPECjbb</p>
    <p>swim</p>
    <p>tomcatv</p>
    <p>M water</p>
    <p>Results</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 17</p>
    <p>Write Buffering Needs  Only a few KB of write buffering needed</p>
    <p>Set by the natural transaction sizes in applications Occasional overflow can be handled by committing early Reasonable for on-chip buffers</p>
    <p>Results</p>
    <p>m o</p>
    <p>ld y n</p>
    <p>e q</p>
    <p>u a</p>
    <p>k e</p>
    <p>_ s</p>
    <p>e u</p>
    <p>le r</p>
    <p>jb y te</p>
    <p>_ B</p>
    <p>ra y tr</p>
    <p>a c e</p>
    <p>jb y te</p>
    <p>_ B</p>
    <p>jb y te</p>
    <p>_ B</p>
    <p>s h</p>
    <p>a ll o</p>
    <p>w</p>
    <p>e q</p>
    <p>u a</p>
    <p>k e</p>
    <p>_ l</p>
    <p>jb y te</p>
    <p>_ B</p>
    <p>a rt</p>
    <p>w a</p>
    <p>te r</p>
    <p>s w</p>
    <p>im</p>
    <p>m tr</p>
    <p>t</p>
    <p>to m</p>
    <p>c a</p>
    <p>tv</p>
    <p>lu -8</p>
    <p>P</p>
    <p>ra d</p>
    <p>ix -m</p>
    <p>-8 P</p>
    <p>ra d</p>
    <p>ix -x</p>
    <p>s -8</p>
    <p>P</p>
    <p>ra d</p>
    <p>ix -s</p>
    <p>-8 P</p>
    <p>W ri te</p>
    <p>S ta</p>
    <p>te i n K</p>
    <p>B (</p>
    <p>w it h 6</p>
    <p>l in</p>
    <p>e s )</p>
    <p>Applications</p>
    <p>S P</p>
    <p>E C</p>
    <p>jb b</p>
    <p>-8 P</p>
    <p>ra d</p>
    <p>ix -l -8</p>
    <p>P</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 18</p>
    <p>Broadcast Bandwidth</p>
    <p>Another issue is broadcast bandwidth  If data is sent with commit, to avoid broadcast saturation:</p>
    <p>Needs about 16 bytes/cycle/IPC @ 32p with whole modified lines Needs only about 8 bytes/cycle/IPC @ 32p with dirty data only</p>
    <p>High, but feasible on-chip</p>
    <p>B y te</p>
    <p>s p</p>
    <p>e r</p>
    <p>C y c le</p>
    <p>Dirty Data Only</p>
    <p>Whole Lines</p>
    <p>SPECjbbradix (xl, l, m, s, xs) tomcatv fft</p>
    <p>Results</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 19</p>
    <p>Bandwidth Sensitivity</p>
    <p>Most parallel applications are tolerant of limited BW  SPECjbb shows some server-code noise speedup variation</p>
    <p>B B B</p>
    <p>B</p>
    <p>B</p>
    <p>J J</p>
    <p>J</p>
    <p>J</p>
    <p>J</p>
    <p>H H H H H F F F F F</p>
    <p>M M M</p>
    <p>M</p>
    <p>M</p>
    <p>! 68 17 8 4 0</p>
    <p>N o rm</p>
    <p>a li z e d S</p>
    <p>p e e d u p</p>
    <p>Bandwidth Limit, Bytes/Cycle</p>
    <p>B euler</p>
    <p>J fft</p>
    <p>H jbyte_B5</p>
    <p>F jbyte_B6</p>
    <p>jbyte_B8</p>
    <p>jbyte_B9</p>
    <p>moldyn</p>
    <p>mtrt</p>
    <p>M raytrace</p>
    <p>shallow</p>
    <p>B B</p>
    <p>B</p>
    <p>B</p>
    <p>B</p>
    <p>J J</p>
    <p>J</p>
    <p>J</p>
    <p>J</p>
    <p>H H H H</p>
    <p>H</p>
    <p>F F F F</p>
    <p>F</p>
    <p>M M</p>
    <p>M</p>
    <p>M</p>
    <p>M</p>
    <p>! 68 17 8 4 0</p>
    <p>N o rm</p>
    <p>a li z e d S</p>
    <p>p e e d u p</p>
    <p>Bandwidth Limit, bytes/cycle</p>
    <p>B art</p>
    <p>J equake_l</p>
    <p>H equake_s</p>
    <p>F lu</p>
    <p>radix_xl</p>
    <p>radix_l</p>
    <p>radix_m</p>
    <p>radix_s</p>
    <p>M radix_xs</p>
    <p>SPECjbb</p>
    <p>swim</p>
    <p>water</p>
    <p>Results</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 20</p>
    <p>Snoop Bandwidth</p>
    <p>Snooping requirements are quite reasonable  Significantly less than 1 address/cycle on most systems</p>
    <p>Address-only commits could reduce BW requirements  Only broadcast addresses for an invalidation-based protocol  Send full packets only to memory  Needs only about 12 bytes/cycle/IPC @ 32p</p>
    <p>Results</p>
    <p>A d</p>
    <p>d re</p>
    <p>s s e</p>
    <p>s p</p>
    <p>e r</p>
    <p>C y c le</p>
    <p>SPECjbbradix (xl, l, m, s, xs) tomcatv fft</p>
  </div>
  <div class="page">
    <p>Transactional Coherence &amp; Consistency 21</p>
    <p>TCC simplifies shared memory control hardware  Trades higher interconnect bandwidth for simpler protocols  Eliminates traditional MESI coherence protocols  Most communication in large, less latency-sensitive packets  Scaling trends favor these trade-offs in the future</p>
    <p>TCC eases parallel programming  Transactions provide error tolerance and free locking  Allows all-manual to nearly automated parallelization  More on this at ASPLOS-XI in October</p>
    <p>Conclusions Conclusions</p>
  </div>
  <div class="page">
    <p>TCC all transactions, all the time</p>
    <p>More info at: http://tcc.stanford.edu</p>
  </div>
</Presentation>
