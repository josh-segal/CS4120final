<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Polisis: Automated Analysis and Presentation of Privacy Policies Using Deep Learning</p>
    <p>Hamza Harkous (EPFL) Kassem Fawaz (U. Wisconsin) Rmi Lebret (EPFL) Florian Schaub (U. Michigan) Kang G. Shin (U. Michigan) Karl Aberer (EPFL)</p>
  </div>
  <div class="page">
    <p>Problem?</p>
  </div>
  <div class="page">
    <p>PRIVACY POLICIES ARE LONG AND COMPLEX</p>
    <p>3</p>
  </div>
  <div class="page">
    <p>APPROACHES SO FAR? Put more lawyers on the task.</p>
    <p>4</p>
  </div>
  <div class="page">
    <p>Standardization</p>
    <p>A Nutrition Label for privacy  Required providers to act  Surprise: They didnt.</p>
    <p>5</p>
    <p>Kelley et al., &quot;A nutrition label for privacy.&quot; SOUPS09</p>
  </div>
  <div class="page">
    <p>Crowdsourcing  TOSDR.org  Limited by volunteers availability  Available for ~100 policies  Unstructured  can only be used for limited</p>
    <p>automated labeling*</p>
    <p>6 *Zimmeck and Bellovin , &quot;Privee: An Architecture for Automatically Analyzing Web Privacy Policies&quot;. USENIX Security 2014</p>
  </div>
  <div class="page">
    <p>Manual work doesnt scale.</p>
    <p>Fails to cope with emerging technologies.</p>
    <p>7</p>
  </div>
  <div class="page">
    <p>Unstructured Query (User Questions) 8</p>
    <p>Read the whole policy? Show tables on small screens?</p>
    <p>Voice-Activated Devices</p>
  </div>
  <div class="page">
    <p>Regulation Compliance (e.g. GDPR)</p>
    <p>Structured Query</p>
    <p>Get Segments such that</p>
    <p>Category: third party sharing</p>
    <p>personal information type: health information</p>
    <p>9</p>
    <p>Find Statements About Health Data Sharing</p>
  </div>
  <div class="page">
    <p>Solution</p>
  </div>
  <div class="page">
    <p>Unified Framework for Privacy Policies Analysis</p>
    <p>pribot.org</p>
    <p>POLISIS</p>
    <p>Once we automate policies analysis, we can create a new interface for millions of policies with a single program.</p>
    <p>Unstructured Queries</p>
    <p>Structured Queries</p>
    <p>11</p>
  </div>
  <div class="page">
    <p>Segmenter Segment Classifier</p>
    <p>Query Module</p>
    <p>Query Analyzer</p>
    <p>App</p>
    <p>policy segments</p>
    <p>user query</p>
    <p>privacy policy link</p>
    <p>Application Layer</p>
    <p>ML LayerData Layer</p>
    <p>Class Comparison</p>
    <p>query classes</p>
    <p>classified segments</p>
    <p>Framework</p>
    <p>12</p>
    <p>(ML Classifiers)</p>
  </div>
  <div class="page">
    <p>Segmenter Segment Classifier</p>
    <p>Query Module</p>
    <p>Query Analyzer</p>
    <p>App</p>
    <p>policy segments</p>
    <p>user query</p>
    <p>privacy policy link</p>
    <p>Application Layer</p>
    <p>ML LayerData Layer</p>
    <p>Class Comparison</p>
    <p>query classes</p>
    <p>classified segments</p>
    <p>13</p>
  </div>
  <div class="page">
    <p>Policy Segmenter</p>
    <p>Text Segmentation into semantically coherent segments*</p>
    <p>*Glavas et al., &quot;Unsupervised Text Segmentation Using Semantic Relatedness Graphs&quot;, ACL 2016</p>
    <p>{Merge short lists</p>
    <p>{ Prepend the intro:</p>
    <p>Coarse Segmentation according to HTML Tags</p>
    <p>HTML Preprocessing</p>
    <p>S1</p>
    <p>S2</p>
  </div>
  <div class="page">
    <p>Segmenter Segment Classifier</p>
    <p>Query Module</p>
    <p>Query Analyzer</p>
    <p>App</p>
    <p>policy segments</p>
    <p>user query</p>
    <p>privacy policy link</p>
    <p>Application Layer</p>
    <p>ML LayerData Layer</p>
    <p>Class Comparison</p>
    <p>query classes</p>
    <p>classified segments</p>
    <p>15</p>
  </div>
  <div class="page">
    <p>We may need to retain certain information for recordkeeping</p>
    <p>purposes, as required under applicable legal obligations, and/or to</p>
    <p>complete any transactions that you began prior to requesting such</p>
    <p>change or deletion () Some of your information may remain within</p>
    <p>our systems and other records, in compliance with applicable law.</p>
    <p>Intels Privacy Policy</p>
    <p>info type</p>
    <p>generic</p>
    <p>purpose</p>
    <p>legal requirement</p>
    <p>Data Retention</p>
    <p>E X P E R T A N N O T A T I O N S</p>
    <p>*OPP-115 dataset by Wilson et al., ACL 2016</p>
    <p>E X A M P L E</p>
    <p>16</p>
  </div>
  <div class="page">
    <p>115 annotated policies  23K annotations</p>
    <p>Online Privacy Policies Dataset</p>
    <p>Collection Mode</p>
    <p>Information Type</p>
    <p>Purpose</p>
    <p>Action</p>
    <p>Information Type</p>
    <p>Purpose</p>
    <p>Access, Edit, Delete</p>
    <p>Access Scope</p>
    <p>Access Rights</p>
    <p>Data Retention</p>
    <p>Retention Period</p>
    <p>Retention Purpose</p>
    <p>Information Type</p>
    <p>Data Security</p>
    <p>Security Measure</p>
    <p>Specific Audiences</p>
    <p>Audience group</p>
    <p>Do Not Track</p>
    <p>Do Not Track Policy</p>
    <p>Policy Change</p>
    <p>Change Type</p>
    <p>User Choice</p>
    <p>Notification Type</p>
    <p>Other</p>
    <p>Introductory</p>
    <p>Contact Information</p>
    <p>Practice not covered</p>
    <p>Choice, Control</p>
    <p>Choice Type</p>
    <p>Choice Scope</p>
    <p>financial  health  contact  location</p>
    <p>Information Type</p>
    <p>opt-in  opt-out  opt-out-link</p>
    <p>Choice Type</p>
    <p>advertising  marketing  analytics  legal requirement</p>
    <p>Purpose</p>
    <p>stated period  limited  indefinitely  unspecified  other</p>
    <p>Retention Period</p>
  </div>
  <div class="page">
    <p>Hierarchical Data Hierarchical Architecture</p>
  </div>
  <div class="page">
    <p>Hierarchical Architecture</p>
    <p>Category-level Classifier</p>
    <p>Info Type Classifier Purpose Classifier Collection Mode Classifier</p>
    <p>Financial Location Marketing Legal On-website From 3rd Party... ... ...</p>
    <p>...</p>
    <p>...Category Labels</p>
    <p>Value-level Classifiers</p>
    <p>Value Labels</p>
  </div>
  <div class="page">
    <p>Hierarchical Architecture</p>
    <p>Category-level Classifier</p>
    <p>Info Type Classifier Purpose Classifier Collection Mode Classifier</p>
    <p>Financial Location Marketing Legal On-website From 3rd Party... ... ...</p>
    <p>...</p>
    <p>...Category Labels</p>
    <p>Value-level Classifiers</p>
    <p>Value Labels</p>
    <p>Embeddings Layer</p>
    <p>S eg</p>
    <p>m en</p>
    <p>t w1 w2</p>
    <p>CNN +</p>
    <p>MaxPooling</p>
    <p>+ Relu</p>
    <p>Dense 1 +</p>
    <p>Relu Dense 2</p>
    <p>Sigmoid</p>
    <p>Classes Probs</p>
    <p>Similar architecture for the 21 classifiers</p>
    <p>Embeddings size: 300, Number of filters: 200, Filter Size: 3, Dense Layer Size: 100, Batch Size: 40</p>
    <p>Loss function: multi-label cross entropy</p>
  </div>
  <div class="page">
    <p>Segmenter Segment Classifier</p>
    <p>Query Module</p>
    <p>Query Analyzer</p>
    <p>App</p>
    <p>policy segments</p>
    <p>user query</p>
    <p>privacy policy link</p>
    <p>Application Layer</p>
    <p>ML LayerData Layer</p>
    <p>Class Comparison</p>
    <p>query classes</p>
    <p>classified segments</p>
    <p>Structured Querying</p>
    <p>Unstructured Querying</p>
    <p>20</p>
  </div>
  <div class="page">
    <p>Structured Querying Privacy Icon Assignment as a Case Study</p>
  </div>
  <div class="page">
    <p>Automated Privacy Icons Assignment</p>
    <p>[2] https://wiki.mozilla.org/Privacy_Icons [1] https://web.archive.org/web/20170709022651/https://disconnect.me/icons[2]</p>
    <p>[1]</p>
  </div>
  <div class="page">
    <p>Deployment of Disconnect Icons</p>
    <p>Chrome Extension</p>
    <p>Web App</p>
    <p>Discontiuned in 2017</p>
  </div>
  <div class="page">
    <p>Disconnect Icons Description</p>
  </div>
  <div class="page">
    <p>Segmenter Segment Classifier</p>
    <p>Query Module</p>
    <p>Query Analyzer</p>
    <p>App</p>
    <p>policy segments</p>
    <p>user query</p>
    <p>privacy policy link</p>
    <p>Application Layer</p>
    <p>ML LayerData Layer</p>
    <p>Class Comparison</p>
    <p>query classes</p>
    <p>classified segments</p>
    <p>Structured Query Get Segments such that</p>
    <p>Category: third party sharing</p>
    <p>purpose: advertising</p>
    <p>First Order Logic</p>
    <p>(Identity Function)</p>
    <p>(ML Classifier) 25</p>
  </div>
  <div class="page">
    <p>Structured Query</p>
    <p>color: yellow category_filters: fun: include_some_in_list lst: ['third-party-sharing-collection']</p>
    <p>value_filters: fun: include_some_in_list lst: ['purpose_advertising','purpose_analytics-research']</p>
    <p>fun: include_some_in_list lst: ['action-third-party_track-on-first-party-website-app', 'action-third-party_collect-on-first-party-website-app']</p>
    <p>fun: include_some_in_list lst: ['choice-type_opt-out-link', 'choice-type_opt-out-via-contacting-company']</p>
    <p>decider: fun: not_empty</p>
    <p>Expected Collection</p>
    <p>Does this websites privacy policy disclose whether it allows other companies like ad providers and analytics firms to track users on the site?</p>
    <p>Red = Yes, without choice to opt-out. Or, undisclosed. Yellow = Yes, with choice to opt-out. Green = No. Gray = Info unavailable.</p>
  </div>
  <div class="page">
    <p>Structured Query</p>
    <p>color: yellow category_filters: fun: include_some_in_list lst: ['third-party-sharing-collection']</p>
    <p>value_filters: fun: include_some_in_list lst: ['purpose_advertising','purpose_analytics-research']</p>
    <p>fun: include_some_in_list lst: ['action-third-party_track-on-first-party-website-app', 'action-third-party_collect-on-first-party-website-app']</p>
    <p>fun: include_some_in_list lst: ['choice-type_opt-out-link', 'choice-type_opt-out-via-contacting-company']</p>
    <p>decider: fun: not_empty</p>
    <p>Icon assignment based on law students labels</p>
    <p>Icon assignment based on Polisis labels</p>
    <p>Same rules, on 50 policies from OPP-115 dataset</p>
    <p>vs.</p>
    <p>Table 2: The list of Disconnect icons with their description, our interpretation, and Polisis queries.</p>
    <p>Icon Disconnect Description Disconnect Color Assignment Interpretation as Labels Automated Color Assignment</p>
    <p>Expected Use</p>
    <p>Discloses whether data it collects about you is used in ways other than you would reasonably expect given the sites service?</p>
    <p>Red: Yes, w/o choice to opt-out. Or, undisclosed. Yellow: Yes, with choice to</p>
    <p>opt-out. Green: No.</p>
    <p>Let S be the segments with category: first-party-collection-use and purpose: advertising. 9</p>
    <p>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;=</p>
    <p>&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;;</p>
    <p>Yellow: All segments in S have category: user-choice-control and choice-type 2 [opt-in, opt-out-link, opt-out-via-contacting-company]</p>
    <p>Green: S = f Red: Otherwise</p>
    <p>Expected Collection</p>
    <p>Discloses whether it allows other companies like ad providers and analytics firms to track users on the site?</p>
    <p>Red: Yes, w/o choice to opt-out. Or, undisclosed. Yellow: Yes, with choice to</p>
    <p>opt-out. Green: No.</p>
    <p>Let S be the segments with category: third-party-sharing-collection, purpose: 2 [advertising,analytics-research ], and action-third-party 2 [track-on-first-party-website-app,collecton-first-party-website-app].</p>
    <p>Precise Location</p>
    <p>Discloses whether the site or service tracks a users actual geolocation?</p>
    <p>Red: Yes, possibly w/o choice. Yellow: Yes, with choice. Green: No.</p>
    <p>Let S be the segments with personal-information-type: location.</p>
    <p>Data Retention Discloses how long they</p>
    <p>retain your personal data?</p>
    <p>Red: No data retention policy. Yellow: 12+ months. Green: 0-12 months.</p>
    <p>Let S be the segments with category: data-retention.</p>
    <p>Green: All segments in S have retention-period: 2 [stated-period, limited ]. Red: S = f Yellow: Otherwise</p>
    <p>Children Privacy Has this website received</p>
    <p>TrustArcs Childrens Privacy Certification?</p>
    <p>Green: Yes. Gray: No. Let S be the segments with category: international-and-specific-audiences and audience-type: children</p>
    <p>Green: length(S) &gt; 0 Red: Otherwise</p>
    <p>Table 3: Prediction accuracy and k for icon prediction, with the distribution of icons per color based on OPP-115 labels.</p>
    <p>Icon Accuracy Cohen k Hellingerdistance N(R) N(G) N(Y)</p>
    <p>Exp. Use 92% 0.76 0.12 41 8 1 Exp. Collection 88% 0.69 0.19 35 12 3 Precise Location 84% 0.68 0.21 32 14 4 Data Retention 80% 0.63 0.13 29 16 5 Children Privacy 98% 0.95 0.02 12 38 NA</p>
    <p>bels. We report the results for the Expected Use and Expected Collection icons as they are directly interpretable by Polisis. We do not report the rest of the icons because the location information label in the OPP-115 taxonomy included non-precise location (e.g., zip codes), and there was no label that distinguishes the exact retention period. Moreover, the Children privacy icon is assigned through a certification process that does not solely rely on the privacy policy.</p>
    <p>Fig. 5 shows the distribution of automatically extracted icons vs. the distribution of icons from Disconnect, when they were available. The discrepancy between the two distributions is obvious: the vast majority of the Disconnect icons have a yellow label, indicating that the policies offer the user an opt-out choice (from unexpected use or collection). The Hellinger distances between those distributions are 0.71 and 0.61 for Expected Use and Expected Collection, respectively (i.e.,</p>
    <p>assignment strategy in Table 2, where we assign a yellow label only when All segments in S (the concerned subset) include the opt-in/opt-out choice, which could be considered as conservative. In Fig. 6, we show the icon distributions when relaxing the yellow-icon condition to become: At least one segment in S includes the opt-in/opt-out choice. Intuitively, this means that the choice segment, when present, should explicitly mention advertising/analytics (depending on the icon type). Although the number of yellow icons increases slightly, the icons with the new permissive strategy are significantly red-dominated. The Hellinger distances between those distributions drop to 0.47 and 0.50 for Expected Use and Expected Collection, respectively. This result indicates that the majority of policies do not provide users a choice within the same segments describing data usage for advertising or data collection by third parties.</p>
    <p>We go one step further to follow an even more permissive strategy where we assign the yellow label to any policy with S! = f , given that there is at least one segment in the whole policy (i.e., even outside S) with opt-in/opt-out choice. For example, a policy where third-party advertising is mentioned in the middle of the policy while the opt-out choice about another action is mentioned at the end of the policy would still receive a yellow label. The icon distributions, in this case, are illustrated in Fig. 7,</p>
  </div>
  <div class="page">
    <p>Unstructured Querying: Answer Selection as a Case Study</p>
  </div>
  <div class="page">
    <p>Answer Selection</p>
    <p>Do you share my address with other companies?</p>
    <p>We will provide your location to third parties.</p>
  </div>
  <div class="page">
    <p>Segmenter Segment Classifier</p>
    <p>Query Module</p>
    <p>Query Analyzer</p>
    <p>App</p>
    <p>policy segments</p>
    <p>user query</p>
    <p>privacy policy link</p>
    <p>Application Layer</p>
    <p>ML LayerData Layer</p>
    <p>Class Comparison</p>
    <p>query classes</p>
    <p>classified segments</p>
    <p>Unstructured Queries</p>
    <p>30</p>
    <p>(Custom Class Matching)</p>
    <p>(ML Classifiers)</p>
    <p>Do you share my address with other companies?</p>
    <p>(ML Classifiers)</p>
  </div>
  <div class="page">
    <p>Segment Classifier</p>
    <p>Query Analyzer</p>
    <p>policy segments</p>
    <p>ML Layer</p>
    <p>classes for query q</p>
    <p>classes for segment a</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 5: Conservative icons interpretation</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 6: Permissive icons interpretation</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 7: Very permissive icons interpretation</p>
    <p>the number of yellow icons increases slightly, the icons with the new permissive strategy are significantly red-dominated. The Hellinger distances between those distributions drop to 0.47 and 0.50 for Expected Use and Collection, respectively. This result indicates that the majority of policies do not provide users a choice within the same segments describing data usage for advertising or data collection by third parties.</p>
    <p>We go one step further to follow an even more permissive (and potentially unrealistic) strategy where we assign the yellow label to any policy with S! = f , given that there is at least one segment in the whole policy (i.e., even outside S) with opt-in/opt-out choice. For example, a policy where third-party advertising is mentioned in the middle of the policy while the opt-out choice about another action is mentioned at the end of the policy would still receive a yellow label. The icon distributions, in this case, are illustrated in Fig. 7, with Hellinger distance of 0.22 for Expected Use and 0.19 for Expected Collection. Only in this highly unrealistic interpretation of the icons would the distributions of Disconnect and Polisis come to a reasonable proximity. This finding suggests that the icons assigned by Disconnect based on TRUSTes database might be highly permissive.</p>
    <p>two of the icons; they provided the needed evidence of Disconnect following a permissive strategy when assigning icons to policies. A developer could still utilize Polisis to extract the rest of the icons by either augmenting the existing taxonomy or by performing additional natural language processing on the Polisiss returned segments.</p>
    <p>Furthermore, by automatically generating icons, we do not intend to push the human completely outside the loop, especially in situations where legal liability issues might arise. Polisis can assist human annotators by providing initial answers to their queries and the supporting evidence. In other words, it accurately flags the segments of interest to an annotators query so that the annotator can make the final decision.</p>
    <p>enables free-form queries (in the form of user questions) on privacy policies. QAPri is primarily motivated by the rise of conversation-first devices, such as voice-activated digital assistants (e.g., Amazon Alexa and Google Assistant) and smartwatches. For those devices, the existing techniques of linking to a privacy policy or reading it aloud are not usable; they might require the user to access privacy-related</p>
    <p>information and controls on a different device, which is not desirable in the long run [54].</p>
    <p>To support these new forms of services and the emerging need for automated customer support in this domain [56], we present QAPri as an intuitive and user-friendly method to communicate privacy information. QAPri answers free-form user questions from a previously unseen privacy policy, in real time and with high accuracy. Next, we first formalize the problem of free-form privacy QA and then describe how we leverage Polisis to build QAPri.</p>
    <p>about a privacy policy. QAPri passes q to the ML layer and the policys link to the Data Layer. The ML layer probabilistically annotates q and each policys segments with the privacy categories and attribute-value pairs of Fig. 3.</p>
    <p>The segments in the privacy policy constitute the pool of candidate answers {a1,a2,...,aM}. A subset G of the answer pool is the ground-truth. We consider an answer ak as correct if ak 2G and as incorrect if ak /2G. If G is empty, then no answers exist in the privacy policy.</p>
    <p>aaa ={p(ci|a)2p(v j|a)|8ci 2C,v j 2V(ci)} for categories ci 2C and values v j 2V(ci) descending from ci. Similarly, given the output of the Query Analyzer, the question is represented as:</p>
    <p>bbb ={p(ci|q)2p(v j|q)|8ci 2C,v j 2V(ci)} The category probability in both aaa and bbb is squared to put more weight on the categories at comparison time. Next, we compute a certainty measure of the answers high-level categorization. This measure is the entropy of the normalized probability distribution (pn) of the predicted categories:</p>
    <p>cer(a)=1((pn(ci|a)ln(pn(ci|a))/ln(|C|)). (1) Akin to a dot product between two vectors, we compute</p>
    <p>the score s(q,a) as:</p>
    <p>s(q,a)= i(bimin(bi,ai))</p>
    <p>ib 2i cer(a) (2)</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 5: Conservative icons interpretation</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 6: Permissive icons interpretation</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 7: Very permissive icons interpretation</p>
    <p>the number of yellow icons increases slightly, the icons with the new permissive strategy are significantly red-dominated. The Hellinger distances between those distributions drop to 0.47 and 0.50 for Expected Use and Collection, respectively. This result indicates that the majority of policies do not provide users a choice within the same segments describing data usage for advertising or data collection by third parties.</p>
    <p>We go one step further to follow an even more permissive (and potentially unrealistic) strategy where we assign the yellow label to any policy with S! = f , given that there is at least one segment in the whole policy (i.e., even outside S) with opt-in/opt-out choice. For example, a policy where third-party advertising is mentioned in the middle of the policy while the opt-out choice about another action is mentioned at the end of the policy would still receive a yellow label. The icon distributions, in this case, are illustrated in Fig. 7, with Hellinger distance of 0.22 for Expected Use and 0.19 for Expected Collection. Only in this highly unrealistic interpretation of the icons would the distributions of Disconnect and Polisis come to a reasonable proximity. This finding suggests that the icons assigned by Disconnect based on TRUSTes database might be highly permissive.</p>
    <p>two of the icons; they provided the needed evidence of Disconnect following a permissive strategy when assigning icons to policies. A developer could still utilize Polisis to extract the rest of the icons by either augmenting the existing taxonomy or by performing additional natural language processing on the Polisiss returned segments.</p>
    <p>Furthermore, by automatically generating icons, we do not intend to push the human completely outside the loop, especially in situations where legal liability issues might arise. Polisis can assist human annotators by providing initial answers to their queries and the supporting evidence. In other words, it accurately flags the segments of interest to an annotators query so that the annotator can make the final decision.</p>
    <p>enables free-form queries (in the form of user questions) on privacy policies. QAPri is primarily motivated by the rise of conversation-first devices, such as voice-activated digital assistants (e.g., Amazon Alexa and Google Assistant) and smartwatches. For those devices, the existing techniques of linking to a privacy policy or reading it aloud are not usable; they might require the user to access privacy-related</p>
    <p>information and controls on a different device, which is not desirable in the long run [54].</p>
    <p>To support these new forms of services and the emerging need for automated customer support in this domain [56], we present QAPri as an intuitive and user-friendly method to communicate privacy information. QAPri answers free-form user questions from a previously unseen privacy policy, in real time and with high accuracy. Next, we first formalize the problem of free-form privacy QA and then describe how we leverage Polisis to build QAPri.</p>
    <p>about a privacy policy. QAPri passes q to the ML layer and the policys link to the Data Layer. The ML layer probabilistically annotates q and each policys segments with the privacy categories and attribute-value pairs of Fig. 3.</p>
    <p>The segments in the privacy policy constitute the pool of candidate answers {a1,a2,...,aM}. A subset G of the answer pool is the ground-truth. We consider an answer ak as correct if ak 2G and as incorrect if ak /2G. If G is empty, then no answers exist in the privacy policy.</p>
    <p>aaa ={p(ci|a)2p(v j|a)|8ci 2C,v j 2V(ci)} for categories ci 2C and values v j 2V(ci) descending from ci. Similarly, given the output of the Query Analyzer, the question is represented as:</p>
    <p>bbb ={p(ci|q)2p(v j|q)|8ci 2C,v j 2V(ci)} The category probability in both aaa and bbb is squared to put more weight on the categories at comparison time. Next, we compute a certainty measure of the answers high-level categorization. This measure is the entropy of the normalized probability distribution (pn) of the predicted categories:</p>
    <p>cer(a)=1((pn(ci|a)ln(pn(ci|a))/ln(|C|)). (1) Akin to a dot product between two vectors, we compute</p>
    <p>the score s(q,a) as:</p>
    <p>s(q,a)= i(bimin(bi,ai))</p>
    <p>ib 2i cer(a) (2)</p>
    <p>Query Vector</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 5: Conservative icons interpretation</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 6: Permissive icons interpretation</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 7: Very permissive icons interpretation</p>
    <p>the number of yellow icons increases slightly, the icons with the new permissive strategy are significantly red-dominated. The Hellinger distances between those distributions drop to 0.47 and 0.50 for Expected Use and Collection, respectively. This result indicates that the majority of policies do not provide users a choice within the same segments describing data usage for advertising or data collection by third parties.</p>
    <p>We go one step further to follow an even more permissive (and potentially unrealistic) strategy where we assign the yellow label to any policy with S! = f , given that there is at least one segment in the whole policy (i.e., even outside S) with opt-in/opt-out choice. For example, a policy where third-party advertising is mentioned in the middle of the policy while the opt-out choice about another action is mentioned at the end of the policy would still receive a yellow label. The icon distributions, in this case, are illustrated in Fig. 7, with Hellinger distance of 0.22 for Expected Use and 0.19 for Expected Collection. Only in this highly unrealistic interpretation of the icons would the distributions of Disconnect and Polisis come to a reasonable proximity. This finding suggests that the icons assigned by Disconnect based on TRUSTes database might be highly permissive.</p>
    <p>two of the icons; they provided the needed evidence of Disconnect following a permissive strategy when assigning icons to policies. A developer could still utilize Polisis to extract the rest of the icons by either augmenting the existing taxonomy or by performing additional natural language processing on the Polisiss returned segments.</p>
    <p>Furthermore, by automatically generating icons, we do not intend to push the human completely outside the loop, especially in situations where legal liability issues might arise. Polisis can assist human annotators by providing initial answers to their queries and the supporting evidence. In other words, it accurately flags the segments of interest to an annotators query so that the annotator can make the final decision.</p>
    <p>enables free-form queries (in the form of user questions) on privacy policies. QAPri is primarily motivated by the rise of conversation-first devices, such as voice-activated digital assistants (e.g., Amazon Alexa and Google Assistant) and smartwatches. For those devices, the existing techniques of linking to a privacy policy or reading it aloud are not usable; they might require the user to access privacy-related</p>
    <p>information and controls on a different device, which is not desirable in the long run [54].</p>
    <p>To support these new forms of services and the emerging need for automated customer support in this domain [56], we present QAPri as an intuitive and user-friendly method to communicate privacy information. QAPri answers free-form user questions from a previously unseen privacy policy, in real time and with high accuracy. Next, we first formalize the problem of free-form privacy QA and then describe how we leverage Polisis to build QAPri.</p>
    <p>about a privacy policy. QAPri passes q to the ML layer and the policys link to the Data Layer. The ML layer probabilistically annotates q and each policys segments with the privacy categories and attribute-value pairs of Fig. 3.</p>
    <p>The segments in the privacy policy constitute the pool of candidate answers {a1,a2,...,aM}. A subset G of the answer pool is the ground-truth. We consider an answer ak as correct if ak 2G and as incorrect if ak /2G. If G is empty, then no answers exist in the privacy policy.</p>
    <p>aaa ={p(ci|a)2p(v j|a)|8ci 2C,v j 2V(ci)} for categories ci 2C and values v j 2V(ci) descending from ci. Similarly, given the output of the Query Analyzer, the question is represented as:</p>
    <p>bbb ={p(ci|q)2p(v j|q)|8ci 2C,v j 2V(ci)} The category probability in both aaa and bbb is squared to put more weight on the categories at comparison time. Next, we compute a certainty measure of the answers high-level categorization. This measure is the entropy of the normalized probability distribution (pn) of the predicted categories:</p>
    <p>cer(a)=1((pn(ci|a)ln(pn(ci|a))/ln(|C|)). (1) Akin to a dot product between two vectors, we compute</p>
    <p>the score s(q,a) as:</p>
    <p>s(q,a)= i(bimin(bi,ai))</p>
    <p>ib 2i cer(a) (2)</p>
    <p>Answer vector</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 5: Conservative icons interpretation</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 6: Permissive icons interpretation</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 7: Very permissive icons interpretation</p>
    <p>the number of yellow icons increases slightly, the icons with the new permissive strategy are significantly red-dominated. The Hellinger distances between those distributions drop to 0.47 and 0.50 for Expected Use and Collection, respectively. This result indicates that the majority of policies do not provide users a choice within the same segments describing data usage for advertising or data collection by third parties.</p>
    <p>We go one step further to follow an even more permissive (and potentially unrealistic) strategy where we assign the yellow label to any policy with S! = f , given that there is at least one segment in the whole policy (i.e., even outside S) with opt-in/opt-out choice. For example, a policy where third-party advertising is mentioned in the middle of the policy while the opt-out choice about another action is mentioned at the end of the policy would still receive a yellow label. The icon distributions, in this case, are illustrated in Fig. 7, with Hellinger distance of 0.22 for Expected Use and 0.19 for Expected Collection. Only in this highly unrealistic interpretation of the icons would the distributions of Disconnect and Polisis come to a reasonable proximity. This finding suggests that the icons assigned by Disconnect based on TRUSTes database might be highly permissive.</p>
    <p>two of the icons; they provided the needed evidence of Disconnect following a permissive strategy when assigning icons to policies. A developer could still utilize Polisis to extract the rest of the icons by either augmenting the existing taxonomy or by performing additional natural language processing on the Polisiss returned segments.</p>
    <p>Furthermore, by automatically generating icons, we do not intend to push the human completely outside the loop, especially in situations where legal liability issues might arise. Polisis can assist human annotators by providing initial answers to their queries and the supporting evidence. In other words, it accurately flags the segments of interest to an annotators query so that the annotator can make the final decision.</p>
    <p>enables free-form queries (in the form of user questions) on privacy policies. QAPri is primarily motivated by the rise of conversation-first devices, such as voice-activated digital assistants (e.g., Amazon Alexa and Google Assistant) and smartwatches. For those devices, the existing techniques of linking to a privacy policy or reading it aloud are not usable; they might require the user to access privacy-related</p>
    <p>information and controls on a different device, which is not desirable in the long run [54].</p>
    <p>To support these new forms of services and the emerging need for automated customer support in this domain [56], we present QAPri as an intuitive and user-friendly method to communicate privacy information. QAPri answers free-form user questions from a previously unseen privacy policy, in real time and with high accuracy. Next, we first formalize the problem of free-form privacy QA and then describe how we leverage Polisis to build QAPri.</p>
    <p>about a privacy policy. QAPri passes q to the ML layer and the policys link to the Data Layer. The ML layer probabilistically annotates q and each policys segments with the privacy categories and attribute-value pairs of Fig. 3.</p>
    <p>The segments in the privacy policy constitute the pool of candidate answers {a1,a2,...,aM}. A subset G of the answer pool is the ground-truth. We consider an answer ak as correct if ak 2G and as incorrect if ak /2G. If G is empty, then no answers exist in the privacy policy.</p>
    <p>aaa ={p(ci|a)2p(v j|a)|8ci 2C,v j 2V(ci)} for categories ci 2C and values v j 2V(ci) descending from ci. Similarly, given the output of the Query Analyzer, the question is represented as:</p>
    <p>bbb ={p(ci|q)2p(v j|q)|8ci 2C,v j 2V(ci)} The category probability in both aaa and bbb is squared to put more weight on the categories at comparison time. Next, we compute a certainty measure of the answers high-level categorization. This measure is the entropy of the normalized probability distribution (pn) of the predicted categories:</p>
    <p>cer(a)=1((pn(ci|a)ln(pn(ci|a))/ln(|C|)). (1) Akin to a dot product between two vectors, we compute</p>
    <p>the score s(q,a) as:</p>
    <p>s(q,a)= i(bimin(bi,ai))</p>
    <p>ib 2i cer(a) (2)</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 5: Conservative icons interpretation</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 6: Permissive icons interpretation</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 7: Very permissive icons interpretation</p>
    <p>the number of yellow icons increases slightly, the icons with the new permissive strategy are significantly red-dominated. The Hellinger distances between those distributions drop to 0.47 and 0.50 for Expected Use and Collection, respectively. This result indicates that the majority of policies do not provide users a choice within the same segments describing data usage for advertising or data collection by third parties.</p>
    <p>We go one step further to follow an even more permissive (and potentially unrealistic) strategy where we assign the yellow label to any policy with S! = f , given that there is at least one segment in the whole policy (i.e., even outside S) with opt-in/opt-out choice. For example, a policy where third-party advertising is mentioned in the middle of the policy while the opt-out choice about another action is mentioned at the end of the policy would still receive a yellow label. The icon distributions, in this case, are illustrated in Fig. 7, with Hellinger distance of 0.22 for Expected Use and 0.19 for Expected Collection. Only in this highly unrealistic interpretation of the icons would the distributions of Disconnect and Polisis come to a reasonable proximity. This finding suggests that the icons assigned by Disconnect based on TRUSTes database might be highly permissive.</p>
    <p>two of the icons; they provided the needed evidence of Disconnect following a permissive strategy when assigning icons to policies. A developer could still utilize Polisis to extract the rest of the icons by either augmenting the existing taxonomy or by performing additional natural language processing on the Polisiss returned segments.</p>
    <p>Furthermore, by automatically generating icons, we do not intend to push the human completely outside the loop, especially in situations where legal liability issues might arise. Polisis can assist human annotators by providing initial answers to their queries and the supporting evidence. In other words, it accurately flags the segments of interest to an annotators query so that the annotator can make the final decision.</p>
    <p>enables free-form queries (in the form of user questions) on privacy policies. QAPri is primarily motivated by the rise of conversation-first devices, such as voice-activated digital assistants (e.g., Amazon Alexa and Google Assistant) and smartwatches. For those devices, the existing techniques of linking to a privacy policy or reading it aloud are not usable; they might require the user to access privacy-related</p>
    <p>information and controls on a different device, which is not desirable in the long run [54].</p>
    <p>To support these new forms of services and the emerging need for automated customer support in this domain [56], we present QAPri as an intuitive and user-friendly method to communicate privacy information. QAPri answers free-form user questions from a previously unseen privacy policy, in real time and with high accuracy. Next, we first formalize the problem of free-form privacy QA and then describe how we leverage Polisis to build QAPri.</p>
    <p>about a privacy policy. QAPri passes q to the ML layer and the policys link to the Data Layer. The ML layer probabilistically annotates q and each policys segments with the privacy categories and attribute-value pairs of Fig. 3.</p>
    <p>The segments in the privacy policy constitute the pool of candidate answers {a1,a2,...,aM}. A subset G of the answer pool is the ground-truth. We consider an answer ak as correct if ak 2G and as incorrect if ak /2G. If G is empty, then no answers exist in the privacy policy.</p>
    <p>aaa ={p(ci|a)2p(v j|a)|8ci 2C,v j 2V(ci)} for categories ci 2C and values v j 2V(ci) descending from ci. Similarly, given the output of the Query Analyzer, the question is represented as:</p>
    <p>bbb ={p(ci|q)2p(v j|q)|8ci 2C,v j 2V(ci)} The category probability in both aaa and bbb is squared to put more weight on the categories at comparison time. Next, we compute a certainty measure of the answers high-level categorization. This measure is the entropy of the normalized probability distribution (pn) of the predicted categories:</p>
    <p>cer(a)=1((pn(ci|a)ln(pn(ci|a))/ln(|C|)). (1) Akin to a dot product between two vectors, we compute</p>
    <p>the score s(q,a) as:</p>
    <p>s(q,a)= i(bimin(bi,ai))</p>
    <p>ib 2i cer(a) (2)</p>
    <p>Category Certainty Measure</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 5: Conservative icons interpretation</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 6: Permissive icons interpretation</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 7: Very permissive icons interpretation</p>
    <p>the number of yellow icons increases slightly, the icons with the new permissive strategy are significantly red-dominated. The Hellinger distances between those distributions drop to 0.47 and 0.50 for Expected Use and Collection, respectively. This result indicates that the majority of policies do not provide users a choice within the same segments describing data usage for advertising or data collection by third parties.</p>
    <p>We go one step further to follow an even more permissive (and potentially unrealistic) strategy where we assign the yellow label to any policy with S! = f , given that there is at least one segment in the whole policy (i.e., even outside S) with opt-in/opt-out choice. For example, a policy where third-party advertising is mentioned in the middle of the policy while the opt-out choice about another action is mentioned at the end of the policy would still receive a yellow label. The icon distributions, in this case, are illustrated in Fig. 7, with Hellinger distance of 0.22 for Expected Use and 0.19 for Expected Collection. Only in this highly unrealistic interpretation of the icons would the distributions of Disconnect and Polisis come to a reasonable proximity. This finding suggests that the icons assigned by Disconnect based on TRUSTes database might be highly permissive.</p>
    <p>two of the icons; they provided the needed evidence of Disconnect following a permissive strategy when assigning icons to policies. A developer could still utilize Polisis to extract the rest of the icons by either augmenting the existing taxonomy or by performing additional natural language processing on the Polisiss returned segments.</p>
    <p>Furthermore, by automatically generating icons, we do not intend to push the human completely outside the loop, especially in situations where legal liability issues might arise. Polisis can assist human annotators by providing initial answers to their queries and the supporting evidence. In other words, it accurately flags the segments of interest to an annotators query so that the annotator can make the final decision.</p>
    <p>enables free-form queries (in the form of user questions) on privacy policies. QAPri is primarily motivated by the rise of conversation-first devices, such as voice-activated digital assistants (e.g., Amazon Alexa and Google Assistant) and smartwatches. For those devices, the existing techniques of linking to a privacy policy or reading it aloud are not usable; they might require the user to access privacy-related</p>
    <p>information and controls on a different device, which is not desirable in the long run [54].</p>
    <p>To support these new forms of services and the emerging need for automated customer support in this domain [56], we present QAPri as an intuitive and user-friendly method to communicate privacy information. QAPri answers free-form user questions from a previously unseen privacy policy, in real time and with high accuracy. Next, we first formalize the problem of free-form privacy QA and then describe how we leverage Polisis to build QAPri.</p>
    <p>about a privacy policy. QAPri passes q to the ML layer and the policys link to the Data Layer. The ML layer probabilistically annotates q and each policys segments with the privacy categories and attribute-value pairs of Fig. 3.</p>
    <p>The segments in the privacy policy constitute the pool of candidate answers {a1,a2,...,aM}. A subset G of the answer pool is the ground-truth. We consider an answer ak as correct if ak 2G and as incorrect if ak /2G. If G is empty, then no answers exist in the privacy policy.</p>
    <p>aaa ={p(ci|a)2p(v j|a)|8ci 2C,v j 2V(ci)} for categories ci 2C and values v j 2V(ci) descending from ci. Similarly, given the output of the Query Analyzer, the question is represented as:</p>
    <p>bbb ={p(ci|q)2p(v j|q)|8ci 2C,v j 2V(ci)} The category probability in both aaa and bbb is squared to put more weight on the categories at comparison time. Next, we compute a certainty measure of the answers high-level categorization. This measure is the entropy of the normalized probability distribution (pn) of the predicted categories:</p>
    <p>cer(a)=1((pn(ci|a)ln(pn(ci|a))/ln(|C|)). (1) Akin to a dot product between two vectors, we compute</p>
    <p>the score s(q,a) as:</p>
    <p>s(q,a)= i(bimin(bi,ai))</p>
    <p>ib 2i cer(a) (2)</p>
    <p>Answer-Query Score</p>
    <p>prioritizes answers that include the questions classes with high probability</p>
    <p>(but not necessarily vice-versa)</p>
    <p>31</p>
    <p>category</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 5: Conservative icons interpretation</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 6: Permissive icons interpretation</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 7: Very permissive icons interpretation</p>
    <p>the number of yellow icons increases slightly, the icons with the new permissive strategy are significantly red-dominated. The Hellinger distances between those distributions drop to 0.47 and 0.50 for Expected Use and Collection, respectively. This result indicates that the majority of policies do not provide users a choice within the same segments describing data usage for advertising or data collection by third parties.</p>
    <p>We go one step further to follow an even more permissive (and potentially unrealistic) strategy where we assign the yellow label to any policy with S! = f , given that there is at least one segment in the whole policy (i.e., even outside S) with opt-in/opt-out choice. For example, a policy where third-party advertising is mentioned in the middle of the policy while the opt-out choice about another action is mentioned at the end of the policy would still receive a yellow label. The icon distributions, in this case, are illustrated in Fig. 7, with Hellinger distance of 0.22 for Expected Use and 0.19 for Expected Collection. Only in this highly unrealistic interpretation of the icons would the distributions of Disconnect and Polisis come to a reasonable proximity. This finding suggests that the icons assigned by Disconnect based on TRUSTes database might be highly permissive.</p>
    <p>two of the icons; they provided the needed evidence of Disconnect following a permissive strategy when assigning icons to policies. A developer could still utilize Polisis to extract the rest of the icons by either augmenting the existing taxonomy or by performing additional natural language processing on the Polisiss returned segments.</p>
    <p>Furthermore, by automatically generating icons, we do not intend to push the human completely outside the loop, especially in situations where legal liability issues might arise. Polisis can assist human annotators by providing initial answers to their queries and the supporting evidence. In other words, it accurately flags the segments of interest to an annotators query so that the annotator can make the final decision.</p>
    <p>enables free-form queries (in the form of user questions) on privacy policies. QAPri is primarily motivated by the rise of conversation-first devices, such as voice-activated digital assistants (e.g., Amazon Alexa and Google Assistant) and smartwatches. For those devices, the existing techniques of linking to a privacy policy or reading it aloud are not usable; they might require the user to access privacy-related</p>
    <p>information and controls on a different device, which is not desirable in the long run [54].</p>
    <p>To support these new forms of services and the emerging need for automated customer support in this domain [56], we present QAPri as an intuitive and user-friendly method to communicate privacy information. QAPri answers free-form user questions from a previously unseen privacy policy, in real time and with high accuracy. Next, we first formalize the problem of free-form privacy QA and then describe how we leverage Polisis to build QAPri.</p>
    <p>about a privacy policy. QAPri passes q to the ML layer and the policys link to the Data Layer. The ML layer probabilistically annotates q and each policys segments with the privacy categories and attribute-value pairs of Fig. 3.</p>
    <p>The segments in the privacy policy constitute the pool of candidate answers {a1,a2,...,aM}. A subset G of the answer pool is the ground-truth. We consider an answer ak as correct if ak 2G and as incorrect if ak /2G. If G is empty, then no answers exist in the privacy policy.</p>
    <p>aaa ={p(ci|a)2p(v j|a)|8ci 2C,v j 2V(ci)} for categories ci 2C and values v j 2V(ci) descending from ci. Similarly, given the output of the Query Analyzer, the question is represented as:</p>
    <p>bbb ={p(ci|q)2p(v j|q)|8ci 2C,v j 2V(ci)} The category probability in both aaa and bbb is squared to put more weight on the categories at comparison time. Next, we compute a certainty measure of the answers high-level categorization. This measure is the entropy of the normalized probability distribution (pn) of the predicted categories:</p>
    <p>cer(a)=1((pn(ci|a)ln(pn(ci|a))/ln(|C|)). (1) Akin to a dot product between two vectors, we compute</p>
    <p>the score s(q,a) as:</p>
    <p>s(q,a)= i(bimin(bi,ai))</p>
    <p>ib 2i cer(a) (2)</p>
    <p>values</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 5: Conservative icons interpretation</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 6: Permissive icons interpretation</p>
    <p>(a) Exp. Use (b) Exp. Collection Fig. 7: Very permissive icons interpretation</p>
    <p>the number of yellow icons increases slightly, the icons with the new permissive strategy are significantly red-dominated. The Hellinger distances between those distributions drop to 0.47 and 0.50 for Expected Use and Collection, respectively. This result indicates that the majority of policies do not provide users a choice within the same segments describing data usage for advertising or data collection by third parties.</p>
    <p>We go one step further to follow an even more permissive (and potentially unrealistic) strategy where we assign the yellow label to any policy with S! = f , given that there is at least one segment in the whole policy (i.e., even outside S) with opt-in/opt-out choice. For example, a policy where third-party advertising is mentioned in the middle of the policy while the opt-out choice about another action is mentioned at the end of the policy would still receive a yellow label. The icon distributions, in this case, are illustrated in Fig. 7, with Hellinger distance of 0.22 for Expected Use and 0.19 for Expected Collection. Only in this highly unrealistic interpretation of the icons would the distributions of Disconnect and Polisis come to a reasonable proximity. This finding suggests that the icons assigned by Disconnect based on TRUSTes database might be highly permissive.</p>
    <p>two of the icons; they provided the needed evidence of Disconnect following a permissive strategy when assigning icons to policies. A developer could still utilize Polisis to extract the rest of the icons by either augmenting the existing taxonomy or by performing additional natural language processing on the Polisiss returned segments.</p>
    <p>Furthermore, by automatically generating icons, we do not intend to push the human completely outside the loop, especially in situations where legal liability issues might arise. Polisis can assist human annotators by providing initial answers to their queries and the supporting evidence. In other words, it accurately flags the segments of interest to an annotators query so that the annotator can make the final decision.</p>
    <p>enables free-form queries (in the form of user questions) on privacy policies. QAPri is primarily motivated by the rise of conversation-first devices, such as voice-activated digital assistants (e.g., Amazon Alexa and Google Assistant) and smartwatches. For those devices, the existing techniques of linking to a privacy policy or reading it aloud are not usable; they might require the user to access privacy-related</p>
    <p>information and controls on a different device, which is not desirable in the long run [54].</p>
    <p>To support these new forms of services and the emerging need for automated customer support in this domain [56], we present QAPri as an intuitive and user-friendly method to communicate privacy information. QAPri answers free-form user questions from a previously unseen privacy policy, in real time and with high accuracy. Next, we first formalize the problem of free-form privacy QA and then describe how we leverage Polisis to build QAPri.</p>
    <p>about a privacy policy. QAPri passes q to the ML layer and the policys link to the Data Layer. The ML layer probabilistically annotates q and each policys segments with the privacy categories and attribute-value pairs of Fig. 3.</p>
    <p>The segments in the privacy policy constitute the pool of candidate answers {a1,a2,...,aM}. A subset G of the answer pool is the ground-truth. We consider an answer ak as correct if ak 2G and as incorrect if ak /2G. If G is empty, then no answers exist in the privacy policy.</p>
    <p>aaa ={p(ci|a)2p(v j|a)|8ci 2C,v j 2V(ci)} for categories ci 2C and values v j 2V(ci) descending from ci. Similarly, given the output of the Query Analyzer, the question is represented as:</p>
    <p>bbb ={p(ci|q)2p(v j|q)|8ci 2C,v j 2V(ci)} The category probability in both aaa and bbb is squared to put more weight on the categories at comparison time. Next, we compute a certainty measure of the answers high-level categorization. This measure is the entropy of the normalized probability distribution (pn) of the predicted categories:</p>
    <p>cer(a)=1((pn(ci|a)ln(pn(ci|a))/ln(|C|)). (1) Akin to a dot product between two vectors, we compute</p>
    <p>the score s(q,a) as:</p>
    <p>s(q,a)= i(bimin(bi,ai))</p>
    <p>ib 2i cer(a) (2)</p>
    <p>Classifier/Analyzer 1st Party Collection</p>
    <p>Collection Mode</p>
    <p>Information Type</p>
    <p>Purpose</p>
    <p>Action</p>
    <p>Information Type</p>
    <p>Purpose</p>
    <p>Access, Edit, Delete</p>
    <p>Access Scope</p>
    <p>Access Rights</p>
    <p>Data Retention</p>
    <p>Retention Period</p>
    <p>Retention Purpose</p>
    <p>Information Type</p>
    <p>Data Security</p>
    <p>Security Measure</p>
    <p>Specific Audiences</p>
    <p>Audience group</p>
    <p>Do Not Track</p>
    <p>Do Not Track Policy</p>
    <p>Policy Change</p>
    <p>Change Type</p>
    <p>User Choice</p>
    <p>Notification Type</p>
    <p>Other</p>
    <p>Introductory</p>
    <p>Contact Information</p>
    <p>Practice not covered</p>
    <p>Choice, Control</p>
    <p>Choice Type</p>
    <p>Choice Scope</p>
    <p>financial  health  contact  location</p>
    <p>Information Type</p>
    <p>opt-in  opt-out  opt-out-link</p>
    <p>Choice Type</p>
    <p>stated period  limited  indefinitely  unspecified  other</p>
    <p>Retention Period</p>
  </div>
  <div class="page">
    <p>Evaluation Baselines</p>
    <p>Classifier</p>
    <p>Info Type: Financial Info Type :Location Purpose: Marketing Purpose: Legal Security Measure: Access Limitation Security Measure: Secure Storage ...</p>
  </div>
  <div class="page">
    <p>120 questions about 102 companies:</p>
    <p>Twitter Dataset</p>
  </div>
  <div class="page">
    <p>Evaluation Metrics</p>
    <p>Predictive Accuracy (compared to experts answers)</p>
    <p>User-perceived Utility (how users perceived the answers)</p>
  </div>
  <div class="page">
    <p>Predictive Accuracy</p>
    <p>Two Experts</p>
    <p>A5, A11</p>
    <p>A1 A26 A1</p>
    <p>A2</p>
    <p>Segmenter</p>
    <p>How many questions</p>
    <p>have an expert answer</p>
    <p>in top-k? Ranking</p>
    <p>Model</p>
    <p>A4 A11 A28</p>
    <p>top-k</p>
  </div>
  <div class="page">
    <p>Predictive Accuracy: top-k score</p>
    <p>Hierarchical: 82% of questions had accurate</p>
    <p>answers in top 3</p>
    <p>Random Retrieval SemVec Hierarchical</p>
    <p>Differences become less significant with</p>
    <p>higher k</p>
    <p>fraction of Qs with answer among top-k answersQuestion: What is your worth then? You cant do it? Nuts. Answer: @skychief26 3/3 You can view our privacy policy at http://t.co/ksmaIK1WaY. Thanks.</p>
    <p>As we wanted to evaluate the answers to these questions with a user study, our estimates of an adequately sized study led us to randomly sample 120 tweets out of the tweets which both annotators labeled as valid questions. We provide these tweets in the Appendix, and we henceforth refer to them as the Twitter QA Dataset.</p>
    <p>approaches that we developed: (1) Retrieval reflects the state-of-the-art in term-matching retrieval algorithms, (2) SemVec representing a single neural network classifier, and (3) Random as a control approach where questions are answered with randomly chosen segments from the policy.</p>
    <p>Our first baseline, Retrieval, builds on the BM25 algorithm [50], which is the state-of-the-art in ranking models employing term-matching. It has been used successfully across a range of search tasks, such as the TREC evaluations [2]. We improve on the basic BM25 model by computing the inverse document frequency on the Policies Corpus of Sec. 4.2 instead of a single policy. Retrieval ranks the segments in the policy according to their similarity score with the users question. This score depends on the presence of distinctive words that link a users question to an answer.</p>
    <p>Our second baseline, SemVec employs a single classifier trained to distinguish among all the (mandatory) attributevalues (with &gt;20 annotations) from the OPP-115 dataset (81 classes in total). An example segment is geographic location information or other location-based information about you and your device that was labeled as{Information Type: Location}. We obtain a micro-average precision of 0.56 (i.e., the classifier is on average predicting the right label across the 81 classes in 56% of the cases compared to 3.6% precision for a random classifier). After training this model, we extract a semantic vector, which is a representation vector that accounts for the distribution of attribute values in the input text. We extract this vector as the input of the to the second dense layer (shown Fig. 4). SemVec ranks the similarity between a question and a policy segment using the Euclidean distance between semantic vectors. This approach is similar to what has been applied previously in image retrieval, where image representations learned from a large-scale image classification task were effective in visual search applications [49].</p>
    <p>QA model by comparing its predicted answers against expert-generated ground-truth answers for the questions of the Twitter QA Dataset. Ground-truth Generation: Two of the authors generated the ground-truth answers to the questions from the Twitter</p>
    <p>Random Retrieval SemVec QAPri</p>
    <p>(a) top-k score (b) NDCG Fig. 8: Accuracy metrics as a function of k.</p>
    <p>QA Dataset. They were given a users question (tweet) and the segments of the corresponding policy. Each policy consists of 45 segments on average (min=12, max=344, std=37). Each annotator selected, independently, the subset of these segments which they consider as best responding to the users question. This annotation took place prior to generating the answers using our models to avoid any bias. While deciding on the answers, the annotators accounted for the fact that multiple segments of the policy might answer a question.</p>
    <p>After finishing the individual annotations, the two annotators consolidated the differences in their labels to reach an agreed-on set of segments; each assumed to be answering the question. We call this the ground-truth set for each question. The annotators agreed on at least one answer in 88% of the questions for which they found matching segments, thus signifying a substantial overlap. Cohens k, measuring the agreement on one or more answer, was 0.65, indicating substantial agreement [30].</p>
    <p>We generated, for each question, the predicted ranked list of answers according to each QA model (QAPri and the other three baselines). In what follows, we evaluate the predictive accuracy of these models. Top-k Score: We first report the top-k score, a widely used and easily interpretable metric, which denotes the portion of questions having at least one correct answer in the top k returned answers. It is desirable to achieve a high top-k score for low values of k so that user has to process less information before reaching a correct answer. We show in Fig. 8a how the top-k score varies as a function of k. QAPris model has the best performance over the other three models by a large margin, especially at the low values of k. For example, at k=1, QAPri has a top-k score of 0.68, which is significantly larger than the scores of 0.39 (Retrieval), 0.27 (SemVec), and 0.08 (Random) (p-value&lt;0.05 according to pairwise Fishers exact test, corrected with Bonferroni method for multiple comparisons). QAPri further reaches a top-k score of 0.75, 0.83, and 0.87 for k 2[2,3,4]. To put these numbers in the wider context of free-form QA systems, we note that the top-1 accuracy reported by IBM Watsons team on a large insurance domain dataset (a training set of 12,889 questions and 21,325 answers) was 0.65 in 2015 [17] and was later improved to 0.69 in 2016 [58]. Given that QAPri had to overcome the absence of publicly available QA datasets, our top-1 accuracy value of 0.68 is on par with such systems. We also observe that the Retrieval model outperforms the SemVec model.</p>
  </div>
  <div class="page">
    <p>DEMO</p>
  </div>
  <div class="page">
    <p>!38</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Coming Soon!</p>
  </div>
  <div class="page">
    <p>Users of the app Minutes on our apps Websites analyzed</p>
    <p>&gt;35,000 &gt;88,000 &gt;21,000</p>
    <p>Impact</p>
  </div>
  <div class="page">
    <p>Take-aways  Polisis:  Unified framework for querying privacy policies  Assisting users, regulators, and researchers  Two applications:  Structured querying: privacy icons generation  Unstructured querying: question answering from the privacy policy.</p>
    <p>Read more at:  Our paper  WIRED: Polisis AI Reads Privacy Policies So You Don't Have To  Fast Company: This Data Viz Tool Explains Privacy Policies You're Too Lazy to Read  WSJ: Those Privacy Policies Flooding Your Inbox? Print Them Out and They Span a Football Field</p>
  </div>
</Presentation>
