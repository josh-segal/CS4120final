<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Topic Modeling with Network Regularization</p>
    <p>Qiaozhu Mei, Deng Cai, Duo Zhang, ChengXiang Zhai</p>
    <p>University of Illinois at Urbana-Champaign</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Motivation: topic modeling with network structure</p>
    <p>An optimization framework  probabilistic topic model with graph</p>
    <p>regularization</p>
    <p>Instantiation: NetPLSA</p>
    <p>Experiments</p>
    <p>Summary</p>
  </div>
  <div class="page">
    <p>Text Collections with Network Structure</p>
    <p>Literature + coauthor/citation network</p>
    <p>Email + sender/receiver network</p>
    <p>3</p>
    <p>Blog articles + friend network News + geographic network</p>
    <p>Web page + hyperlink structure</p>
  </div>
  <div class="page">
    <p>Probabilistic Topic Models for Text Mining</p>
    <p>Text Collections</p>
    <p>Probabilistic Topic Modeling</p>
    <p>web 0.21 search 0.10 link 0.08 graph 0.05</p>
    <p>Subtopic discovery</p>
    <p>Opinion comparison</p>
    <p>Summarization</p>
    <p>Topical pattern analysis</p>
    <p>term 0.16 relevance 0.08 weight 0.07 feedback 0.04 independ. 0.03 model 0.03</p>
    <p>Topic models (Multinomial distributions)</p>
    <p>PLSA [Hofmann 99] LDA [Blei et al. 03]</p>
    <p>Author-Topic [Steyvers et al. 04]</p>
    <p>CPLSA [Mei &amp; Zhai 06]</p>
    <p>Pachinko allocation [Li &amp; McCallum 06]</p>
    <p>CTM [Blei et al. 06] Usually dont include</p>
    <p>network structure</p>
  </div>
  <div class="page">
    <p>Social Network Analysis</p>
    <p>Generation, evolution e.g., [Leskovec 05]</p>
    <p>Community extraction e.g., [Kleinberg 00];</p>
    <p>Diffusion [Gruhl 04]; [Backstrom 06]</p>
    <p>Ranking e.g., [Brin and Page 98]; [Kleinberg 98]</p>
    <p>Structural patterns e.g., [Yan 02]</p>
    <p>- Kleinberg and Backstrom 2006, New York Times</p>
    <p>Usually dont model topics in text- Jeong et al. 2001 Nature 411</p>
  </div>
  <div class="page">
    <p>Importance of Topic Modeling Plus Network Analysis</p>
    <p>physicist, physics, scientist, theory, gravitation</p>
    <p>writer, novel, best-sell, book, language, film</p>
    <p>Topic modeling to help community extraction</p>
    <p>Information Retrieval + Data Mining + Machine Learning,</p>
    <p>= Domain Review + Algorithm + Evaluation,</p>
    <p>or Computer Science Literature</p>
    <p>Network analysis to help topic extraction</p>
    <p>?</p>
  </div>
  <div class="page">
    <p>Intuitions</p>
    <p>People working on the same topic belong to the same topical community</p>
    <p>Good community: coherent topic + well connected</p>
    <p>A topic is semantically coherent if people working on this topic also collaborate a lot</p>
    <p>IR</p>
    <p>IR</p>
    <p>IR ?</p>
    <p>More likely to be an IR person or a compiler person?</p>
    <p>Intuition: my topics are similar to my neighbors</p>
  </div>
  <div class="page">
    <p>Social Network Context for Topic Modeling</p>
    <p>Context = author  Coauthor = similar contexts  Intuition: I work on similar topics to</p>
    <p>my neighbors</p>
    <p>Smoothed Topic distributions  P(j|author)</p>
    <p>e.g. coauthor network</p>
  </div>
  <div class="page">
    <p>Challenging Research Questions</p>
    <p>How to formalize the intuitive assumption?  smoothed topic distributions over neighbors</p>
    <p>without hurting topic modeling</p>
    <p>How to map a topic on a network structure?</p>
    <p>How to interpret the semantics of communities on a network?  These vertices form a community, but why?</p>
    <p>Topical Communities</p>
  </div>
  <div class="page">
    <p>A Unified Optimization Framework</p>
    <p>Probabilistic topic modeling as an optimization problem (e.g., PLSA/LDA: Maximum Likelihood):</p>
    <p>Regularized objective function with network constrains  Topic distribution are smoothed over adjacent vertices</p>
    <p>Flexibility in selecting topic models and regularizers</p>
    <p>))|(log()|( ModelCollectionPModelCollectionO</p>
    <p>)|,( ModelNetworkCollectionO</p>
    <p>),(e))|(log( NetworkModelgularizerRModelCollectionP</p>
    <p>)|][,(maxarg ModelNetworkCollectionOsModelParam params</p>
  </div>
  <div class="page">
    <p>A Document d</p>
    <p>Probabilistic Latent Semantic Analysis (Hofmann 99)</p>
    <p>Topics 1k</p>
    <p>government</p>
    <p>donation</p>
    <p>New Orleans</p>
    <p>government 0.3 response 0.2..</p>
    <p>donate 0.1 relief 0.05 help 0.02 ..</p>
    <p>city 0.2 new 0.1 orleans 0.05 ..</p>
    <p>P(i|d)</p>
    <p>government</p>
    <p>donate</p>
    <p>new</p>
    <p>Draw a word from i</p>
    <p>response</p>
    <p>aid help</p>
    <p>Orleans</p>
    <p>Criticism of government response to the hurricane primarily consisted of criticism of its response to  The total shut-in oil production from the Gulf of Mexico  approximately 24% of the annual production and the shutin gas production  Over seventy countries pledged monetary donations or other assistance.</p>
    <p>Choose a topic</p>
    <p>Generation Process: ))|()|(log),()()(</p>
    <p>d w</p>
    <p>k</p>
    <p>j j wpdpdwcCLCO</p>
    <p>Can be contextsensitive; topic distributions unconstrained -- overfits data</p>
  </div>
  <div class="page">
    <p>Evu</p>
    <p>k</p>
    <p>j jj</p>
    <p>j d w</p>
    <p>k</p>
    <p>j j</p>
    <p>vpupvuw</p>
    <p>wpdpdwcGCO</p>
    <p>, 1</p>
    <p>)))|()|((),( 2</p>
    <p>))|()|(log),(()1(),(</p>
    <p>Instantiation: NetPLSA</p>
    <p>Basic Assumption: Neighbors have similar topic distribution</p>
    <p>PLSA</p>
    <p>Graph Harmonic Regularizer,</p>
    <p>Generalization of [Zhu 03],</p>
    <p>Evu</p>
    <p>k</p>
    <p>j jj</p>
    <p>j d w</p>
    <p>k</p>
    <p>j j</p>
    <p>vpupvuw</p>
    <p>wpdpdwcGCO</p>
    <p>, 1</p>
    <p>)))|()|((),( 2</p>
    <p>))|()|(log),(()1(),(</p>
    <p>importance (weight) of an edge</p>
    <p>tradeoff</p>
    <p>topic distribution of a document</p>
    <p>)|( , 2</p>
    <p>...1</p>
    <p>upfwhereff juj kj</p>
    <p>j T j</p>
    <p>difference of topic distribution</p>
  </div>
  <div class="page">
    <p>Parameter Estimation</p>
    <p>PLSA: EM algorithm</p>
    <p>NetPLSA: Generalized EM Algorithm</p>
    <p>E-Step );( nQ  M-Step  Compute expectation Maximize, closed form solution</p>
    <p>Maximize, using Newton-Raphson</p>
    <p>Efficient Alg.: Improve</p>
    <p>E-Step );( nQ  M-Step  Compute expectation</p>
    <p>Regularized complete likelihood</p>
  </div>
  <div class="page">
    <p>How it Works in M Step</p>
    <p>PLSA:</p>
    <p>NetPLSA:</p>
    <p>n 1n</p>
    <p>Maximizing likelihood</p>
    <p>n</p>
    <p>Maximizing likelihood</p>
    <p>Smooth using network Regularizer;</p>
    <p>iteratively until Q drops</p>
    <p>T</p>
  </div>
  <div class="page">
    <p>Variations and Utilities</p>
    <p>Use different regularizers for different network structure</p>
    <p>P(|u) = P(|du) if one document per vertex</p>
    <p>Topic Mapping  Map a topic on the network using p(|u)  p(|u) should be smooth on the graph</p>
    <p>Topical community extraction:  We may use p(|u) to decide which cluster u should be in</p>
    <p>)|(maxarg* upj j j</p>
    <p>ud</p>
    <p>udpdpup )|()|()|(</p>
  </div>
  <div class="page">
    <p>Experiments</p>
    <p>Bibliography data and coauthor</p>
    <p>networks  DBLP: text = titles; network = coauthors</p>
    <p>Four conferences (expect 4 topics): SIGIR, KDD, NIPS, WWW</p>
    <p>Blog articles and Geographic network  Blogs from spaces.live.com</p>
    <p>containing topical words, e.g. weather</p>
    <p>Network: US states (adjacent states)</p>
  </div>
  <div class="page">
    <p>Topical Communities with PLSA</p>
    <p>Topic 1 Topic 2 Topic 3 Topic 4</p>
    <p>term 0.02 peer 0.02 visual 0.02 interface 0.02</p>
    <p>question 0.02 patterns 0.01 analog 0.02 towards 0.02</p>
    <p>protein 0.01 mining 0.01 neurons 0.02 browsing 0.02</p>
    <p>training 0.01 clusters 0.01 vlsi 0.01 xml 0.01</p>
    <p>weighting 0.01</p>
    <p>stream 0.01 motion 0.01 generation 0.01</p>
    <p>multiple 0.01 frequent 0.01 chip 0.01 design 0.01</p>
    <p>recognition 0.01 e 0.01 natural 0.01 engine 0.01</p>
    <p>relations 0.01 page 0.01 cortex 0.01 service 0.01</p>
    <p>library 0.01 gene 0.01 spike 0.01 social 0.01</p>
    <p>?? ? ?</p>
    <p>Noisy community assignment</p>
  </div>
  <div class="page">
    <p>Topical Communities with NetPLSA</p>
    <p>Topic 1 Topic 2 Topic 3 Topic 4</p>
    <p>retrieval 0.13 mining 0.11 neural 0.06 web 0.05</p>
    <p>information 0.05 data 0.06 learning 0.02 services 0.03</p>
    <p>document 0.03 discovery 0.03 networks 0.02 semantic 0.03</p>
    <p>query 0.03 databases 0.02 recognition 0.02 services 0.03</p>
    <p>text 0.03 rules 0.02 analog 0.01 peer 0.02</p>
    <p>search 0.03 association 0.02 vlsi 0.01 ontologies 0.02</p>
    <p>evaluation 0.02 patterns 0.02 neurons 0.01 rdf 0.02</p>
    <p>user 0.02 frequent 0.01 gaussian 0.01 management 0.01</p>
    <p>relevance 0.02 streams 0.01 network 0.01 ontology 0.01</p>
    <p>Information Retrieval</p>
    <p>Data mining Machine learning</p>
    <p>Web</p>
    <p>Coherent community assignment</p>
  </div>
  <div class="page">
    <p>Coherent Topical Communities</p>
    <p>Semantics of community: Data Mining (KDD)</p>
    <p>NetPLSA</p>
    <p>mining 0.11</p>
    <p>data 0.06</p>
    <p>discovery 0.03</p>
    <p>databases 0.02</p>
    <p>rules 0.02</p>
    <p>association 0.02</p>
    <p>patterns 0.02</p>
    <p>frequent 0.01</p>
    <p>streams 0.01</p>
    <p>PLSA</p>
    <p>peer 0.02</p>
    <p>patterns 0.01</p>
    <p>mining 0.01</p>
    <p>clusters 0.01</p>
    <p>stream 0.01</p>
    <p>frequent 0.01</p>
    <p>e 0.01</p>
    <p>page 0.01</p>
    <p>gene 0.01</p>
    <p>PLSA</p>
    <p>visual 0.02</p>
    <p>analog 0.02</p>
    <p>neurons 0.02</p>
    <p>vlsi 0.01</p>
    <p>motion 0.01</p>
    <p>chip 0.01</p>
    <p>natural 0.01</p>
    <p>cortex 0.01</p>
    <p>spike 0.01</p>
    <p>NetPLSA</p>
    <p>neural 0.06</p>
    <p>learning 0.02</p>
    <p>networks 0.02</p>
    <p>recognition 0.02</p>
    <p>analog 0.01</p>
    <p>vlsi 0.01</p>
    <p>neurons 0.01</p>
    <p>gaussian 0.01</p>
    <p>network 0.01</p>
    <p>Semantics of community: machine learning (NIPS)</p>
  </div>
  <div class="page">
    <p>Topic Modeling and SNA Improve Each Other</p>
    <p>Methods Cut Edge Weights</p>
    <p>Ratio Cut/ Norm. Cut</p>
    <p>Community Size</p>
    <p>Community 1</p>
    <p>Community 2</p>
    <p>Community 3</p>
    <p>Community 4</p>
    <p>PLSA 4831 2.14/1.25 2280 2178 2326 2257</p>
    <p>NetPLSA 662 0.29/0.13 2636 1989 3069 1347</p>
    <p>NCut 855 0.23/0.12 2699 6323 8 11</p>
    <p>-Ncut: spectral clustering with normalized cut. J. Shi et al. 2000 - pure network based community finding</p>
    <p>Network Regularization helps extract coherent communities (network assures the focus of topics)</p>
    <p>Topic Modeling helps balancing communities (text implicitly bridges authors)</p>
    <p>The smaller the better The smaller the better</p>
  </div>
  <div class="page">
    <p>Smoothed Topic Map</p>
    <p>The Windy States -Blog articles: weather -US states network: -Topic: windy</p>
    <p>PLSA NetPLSA</p>
    <p>Real reference</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Combine Topic modeling and network analysis</p>
    <p>A unified optimization framework</p>
    <p>NetPLSA = PLSA + Network Regularization</p>
    <p>Topical communities and topic map</p>
    <p>Future work:  Using other topic models (e.g., LDA)</p>
    <p>More network properties (e.g., small world)</p>
    <p>Topic evolution/spreading on network</p>
  </div>
  <div class="page">
    <p>Thanks!</p>
  </div>
</Presentation>
