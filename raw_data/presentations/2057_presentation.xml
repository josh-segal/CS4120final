<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>TRASH DAY: COORDINATING GARBAGE COLLECTION IN DISTRIBUTED SYSTEMS</p>
    <p>Martin Maas*  Tim Harris Krste Asanovic* John Kubiatowicz* *University of California, Berkeley  Oracle Labs, Cambridge</p>
  </div>
  <div class="page">
    <p>TRASH DAY: COORDINATING GARBAGE COLLECTION IN DISTRIBUTED SYSTEMS</p>
    <p>Martin Maas*  Tim Harris Krste Asanovic* John Kubiatowicz* *University of California, Berkeley  Oracle Labs, Cambridge</p>
    <p>Why you should care about GARBAGE</p>
    <p>COLLECTION in Data Center Applications</p>
  </div>
  <div class="page">
    <p>Most Popular Languages 2015</p>
  </div>
  <div class="page">
    <p>Popular Frameworks using GC</p>
  </div>
  <div class="page">
    <p>GC used by Cloud Companies</p>
  </div>
  <div class="page">
    <p>Why Managed Languages?</p>
    <p>Productivity Gains</p>
    <p>Avoiding Bugs</p>
    <p>Enable Certain Optimizations</p>
    <p>[Targeting* Dynamic*Compilation*for* Embedded*Environments,* Michael*Chen*and*Kunle Olukotun,*JVM02]</p>
  </div>
  <div class="page">
    <p>What is the Cost of GC?</p>
    <p>GC overhead workload and heap-size dependent, 5-20% on single machine</p>
    <p>In Distributed Applications, additional overheads emerge. Applications run across independent runtime systems:</p>
    <p>ISCA12: Cao et al.</p>
    <p>Node #3 Node #4</p>
    <p>RuntimeRuntime</p>
    <p>Node #1 Node #2</p>
    <p>RuntimeRuntime</p>
  </div>
  <div class="page">
    <p>Two Example Workloads</p>
    <p>Throughput-oriented Batch-style</p>
    <p>Latency-sensitive Interactive</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>Spark Running PageRank</p>
    <p>PageRank on 56 GB Wikipedia web graph</p>
  </div>
  <div class="page">
    <p>Spark Running PageRank</p>
    <p>Execution is divided into supersteps</p>
  </div>
  <div class="page">
    <p>Spark Running PageRank</p>
    <p>Execution is divided into supersteps Each superstep runs independent tasks</p>
  </div>
  <div class="page">
    <p>Spark Running PageRank</p>
    <p>Red  Synchronization at end of superstep</p>
  </div>
  <div class="page">
    <p>Spark Running PageRank</p>
    <p>Green  Major GC Pause</p>
    <p>Red  Synchronization at end of superstep</p>
    <p>GC prevents superstep from completing</p>
  </div>
  <div class="page">
    <p>Spark Running PageRank</p>
    <p>Execution stalls due to GC on other node</p>
    <p>Different node</p>
  </div>
  <div class="page">
    <p>Impact on Superstep Times</p>
    <p>White = No GC during superstep Dark = One or more GCs (the darker the more GCs)</p>
    <p>Nodes perform GC in different supersteps</p>
  </div>
  <div class="page">
    <p>Idea: Coordinate GC on different nodes</p>
    <p>Trigger collection on all nodes at the when any one reaches a threshold</p>
    <p>Policy: Stop-the-world Everywhere, STWE</p>
  </div>
  <div class="page">
    <p>Memory Occupancy over Time</p>
    <p>Without STWE With STWE 18</p>
  </div>
  <div class="page">
    <p>Before</p>
    <p>Impact of STWE Policy Nodes perform GC in same supersteps</p>
    <p>Overall improvement in execution time (~15%)</p>
  </div>
  <div class="page"/>
  <div class="page">
    <p>YCSB Workload Generator</p>
    <p>Cassandra with YCSB 4-node Cassandra Cluster 3-way replicated</p>
    <p>Requests sent to arbitrary node; becomes coordinator and contacts replicas to assemble quorum.</p>
  </div>
  <div class="page">
    <p>Blue  mean latency over a 10ms window</p>
    <p>Grey Bars  minor GC on any node in the cluster</p>
    <p>Query Latencies over Time</p>
  </div>
  <div class="page">
    <p>Blue  mean latency over a 10ms window</p>
    <p>Grey Bars  minor GC on any node in the cluster</p>
    <p>Query Latencies over Time</p>
  </div>
  <div class="page">
    <p>Sources of Stragglers</p>
  </div>
  <div class="page">
    <p>Sources of Stragglers</p>
  </div>
  <div class="page">
    <p>GC-aware Work Distribution Steer client requests to Cassandra</p>
    <p>nodes, avoiding ones that will need a minor collection soon Policy: Request Steering, STEER</p>
  </div>
  <div class="page">
    <p>YCSB Workload Generator</p>
    <p>Steering Cassandra Requests</p>
    <p>Monitor memory on all nodes</p>
    <p>If one node is close to GC, send to other nodes instead</p>
  </div>
  <div class="page">
    <p>YCSB Workload Generator</p>
    <p>Steering Cassandra Requests</p>
    <p>Monitor memory on all nodes</p>
    <p>If one node is close to GC, send to other nodes instead&gt;80% full</p>
  </div>
  <div class="page">
    <p>YCSB Workload Generator</p>
    <p>Steering Cassandra Requests</p>
    <p>Monitor memory on all nodes</p>
    <p>If one node is close to GC, send to other nodes instead&gt;80% full</p>
  </div>
  <div class="page">
    <p>Blue  without steering Red  with steering</p>
    <p>Impact of Request Steering Reads Updates</p>
  </div>
  <div class="page">
    <p>Are These Problems Common?</p>
    <p>GC problems affect a large number of applications</p>
    <p>Have existed since dawn of warehouse-scale computing</p>
    <p>Current surge of interest in both industry and academia (6 new papers in last 4 mo.)</p>
    <p>SOSP 01, Welsh et al.</p>
  </div>
  <div class="page">
    <p>Common Solutions</p>
    <p>Rewrite at lower level</p>
    <p>Respond to GC Pauses</p>
    <p>Concurrent Collectors</p>
    <p>Cinnober on: GC pause-free Java applications through orchestrated memory management</p>
    <p>Cinnobers latest innovation captures the best of two worlds in a single state-of-the-art solution: a functionality-rich trading system with consistently low latency.</p>
    <p>Predictable low latency</p>
    <p>Transaction flow example 1. Incoming transaction</p>
    <p>A request is received by the primary nodes Ultra communication framework, providing pause-free processing. The transaction is assigned a sequence number and sent to the primary and standby servers for execution.</p>
    <p>A shared memory transport mechanism sends the transaction to the primary server. Expected latency for shared memory communication is on the order of 300 nanoseconds.</p>
    <p>The incoming transaction is replicated to the corresponding communication framework process on the standby side using RDMA (Remote Direct Memory Access) and from there to the standby execution server using shared memory transport. Expected latency for RDMA communication is on the order of 2-3 microseconds, depending on message size.</p>
    <p>The communication framework sends an acknowledgement message back to the primary node to verify that the standby has received it.</p>
    <p>The primary and standby servers both execute the request in parallel and provide identical transaction responses and broadcasts. The responses are sent via the shared memory transport to the Ultra communication framework. The standby side sends the response to the primary sides Ultra communication framework, again using RDMA communication.</p>
    <p>The primary side sends out the response as soon as it is received from either the primary or the standby, whichever arrives first.</p>
    <p>This is the key to allowing orchestrated JVM pauses in the primary and standby servers.</p>
    <p>Orchestration of JVM pauses The Ultra communication framework handles the orchestration of JVM pauses.</p>
    <p>Since the primary and standby servers execute the same code with essentially the same memory turnover behavior, the orchestration mechanism does not need to be overly complex. Measuring memory turnover at maximum transaction load, the orchestrator only needs to keep track of current memory usage and calculate when a garbage collection should occur. The initial garbage collection for one of the servers is requested so that future garbage collections will occur with optimal time spacing.</p>
    <p>Next step Cinnober will publish an extensive white paper about orchestrated memory management in TRADExpress in conjunction with the coming version release that is scheduled for the second quarter of 2014.</p>
    <p>Rewrite in C/C++  Use non-idiomatic</p>
    <p>language constructs</p>
    <p>Lose language advantages, lack</p>
    <p>of generality  Substantial effort to adopt</p>
    <p>Performance overheads, still</p>
    <p>have pauses</p>
  </div>
  <div class="page">
    <p>Common Solutions</p>
    <p>Rewrite at lower level</p>
    <p>Respond to GC Pauses</p>
    <p>Concurrent collectors</p>
    <p>Cinnober on: GC pause-free Java applications through orchestrated memory management</p>
    <p>Cinnobers latest innovation captures the best of two worlds in a single state-of-the-art solution: a functionality-rich trading system with consistently low latency.</p>
    <p>Predictable low latency</p>
    <p>Transaction flow example 1. Incoming transaction</p>
    <p>A request is received by the primary nodes Ultra communication framework, providing pause-free processing. The transaction is assigned a sequence number and sent to the primary and standby servers for execution.</p>
    <p>A shared memory transport mechanism sends the transaction to the primary server. Expected latency for shared memory communication is on the order of 300 nanoseconds.</p>
    <p>The incoming transaction is replicated to the corresponding communication framework process on the standby side using RDMA (Remote Direct Memory Access) and from there to the standby execution server using shared memory transport. Expected latency for RDMA communication is on the order of 2-3 microseconds, depending on message size.</p>
    <p>The communication framework sends an acknowledgement message back to the primary node to verify that the standby has received it.</p>
    <p>The primary and standby servers both execute the request in parallel and provide identical transaction responses and broadcasts. The responses are sent via the shared memory transport to the Ultra communication framework. The standby side sends the response to the primary sides Ultra communication framework, again using RDMA communication.</p>
    <p>The primary side sends out the response as soon as it is received from either the primary or the standby, whichever arrives first.</p>
    <p>This is the key to allowing orchestrated JVM pauses in the primary and standby servers.</p>
    <p>Orchestration of JVM pauses The Ultra communication framework handles the orchestration of JVM pauses.</p>
    <p>Since the primary and standby servers execute the same code with essentially the same memory turnover behavior, the orchestration mechanism does not need to be overly complex. Measuring memory turnover at maximum transaction load, the orchestrator only needs to keep track of current memory usage and calculate when a garbage collection should occur. The initial garbage collection for one of the servers is requested so that future garbage collections will occur with optimal time spacing.</p>
    <p>Next step Cinnober will publish an extensive white paper about orchestrated memory management in TRADExpress in conjunction with the coming version release that is scheduled for the second quarter of 2014.</p>
    <p>Rewrite in C/C++  Use non-idiomatic</p>
    <p>language constructs</p>
    <p>Lose language advantages</p>
    <p>Substantial effort to adopt</p>
    <p>Performance Overheads</p>
    <p>No general, widely adopted solution!</p>
  </div>
  <div class="page">
    <p>The problem is not GC, it is language runtime system coordination</p>
  </div>
  <div class="page">
    <p>Current Approach Language Runtime Systems are</p>
    <p>completely independent (not just GC) Cluster Scheduler</p>
    <p>App #3</p>
    <p>Commodity OS</p>
    <p>App #4</p>
    <p>RuntimeRuntime</p>
    <p>App #1</p>
    <p>Commodity OS</p>
    <p>App #2</p>
    <p>RuntimeRuntime</p>
  </div>
  <div class="page">
    <p>Current Approach</p>
    <p>Cluster Scheduler</p>
    <p>App #3</p>
    <p>Commodity OS</p>
    <p>App #4</p>
    <p>RuntimeRuntime</p>
    <p>App #1</p>
    <p>Commodity OS</p>
    <p>App #2</p>
    <p>RuntimeRuntimeIntra-node Interference</p>
    <p>Language Runtime Systems are completely independent (not just GC)</p>
  </div>
  <div class="page">
    <p>Cluster Scheduler</p>
    <p>App #3</p>
    <p>Commodity OS</p>
    <p>App #4</p>
    <p>RuntimeRuntime</p>
    <p>App #1</p>
    <p>Commodity OS</p>
    <p>App #2</p>
    <p>RuntimeRuntimeIntra-node Interference</p>
    <p>Lack of Coordination</p>
    <p>Current Approach</p>
    <p>Language Runtime Systems are completely independent (not just GC)</p>
  </div>
  <div class="page">
    <p>Cluster Scheduler</p>
    <p>App #3</p>
    <p>Commodity OS</p>
    <p>App #4</p>
    <p>RuntimeRuntime</p>
    <p>App #1</p>
    <p>Commodity OS</p>
    <p>App #2</p>
    <p>RuntimeRuntimeIntra-node Interference</p>
    <p>Lack of Coordination</p>
    <p>Redundancy JIT JIT</p>
    <p>Current Approach</p>
    <p>Language Runtime Systems are completely independent (not just GC)</p>
  </div>
  <div class="page">
    <p>Cluster Scheduler</p>
    <p>App #3</p>
    <p>Commodity OS</p>
    <p>App #4</p>
    <p>RuntimeRuntime</p>
    <p>Commodity OS</p>
    <p>App</p>
    <p>RTIntra-node Interference</p>
    <p>Lack of Coordination</p>
    <p>RedundancyElasticity App</p>
    <p>RT</p>
    <p>App</p>
    <p>RT</p>
    <p>Current Approach</p>
    <p>Language Runtime Systems are completely independent (not just GC)</p>
  </div>
  <div class="page">
    <p>Holistic Runtime Systems Apply the Distributed OS Ideas to design a Distributed Language Runtime System</p>
    <p>Cluster Scheduler</p>
    <p>App #3 App #4</p>
    <p>RuntimeRuntime</p>
    <p>App #1 App #2</p>
    <p>RuntimeRuntime</p>
  </div>
  <div class="page">
    <p>Holistic Runtime Systems Apply the Distributed OS Ideas to design a Distributed Language Runtime System</p>
    <p>Cluster Scheduler</p>
    <p>App #3 App #4App #1 App #2</p>
    <p>Distributed Runtime Holistic Runtime SystemRuntimeRuntimeRuntimeRuntime</p>
  </div>
  <div class="page">
    <p>Our Prototype  Coordinated runtime decisions using</p>
    <p>a feedback loop with dist. consensus  Configured by Policy (written in DSL)  Drop-in replacement for Java VM  No modifying of application required</p>
  </div>
  <div class="page">
    <p>System Design</p>
    <p>Hotspot JVM Hotspot JVM</p>
    <p>Application Node 0 Application Node 1</p>
    <p>M em</p>
    <p>or y</p>
    <p>Oc cu</p>
    <p>pa nc</p>
    <p>y, St</p>
    <p>at e</p>
    <p>Plan, Reconfiguration, State updates</p>
    <p>User-supplied Policy</p>
    <p>Ho lis</p>
    <p>tic R</p>
    <p>un tim</p>
    <p>e S ys</p>
    <p>te m</p>
    <p>Monitor Monitor</p>
    <p>State State</p>
  </div>
  <div class="page">
    <p>Why This Approach?  Easy to adopt (just pick policy, almost</p>
    <p>no configuration required)  Minimally invasive to runtime system  Expressive (can express a large range</p>
    <p>of GC coordination policies) 44</p>
  </div>
  <div class="page">
    <p>Our plan is to make the system available as open source</p>
  </div>
  <div class="page">
    <p>Would you use it?</p>
  </div>
  <div class="page">
    <p>Thank you! Any Questions?</p>
    <p>Martin Maas, Tim Harris, Krste Asanovic, John Kubiatowicz {maas,krste,kubitron}@eecs.berkeley.edu timothy.l.harris@oracle.com</p>
    <p>Work started while at Oracle Labs, Cambridge.</p>
  </div>
</Presentation>
