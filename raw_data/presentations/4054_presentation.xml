<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Fuzzing E-mail Filters with Generative Grammars and N-Gram Analysis</p>
    <p>Presented by</p>
    <p>Sean Palka / George Mason University</p>
    <p>And</p>
    <p>Damon McCoy / International Computer Science Institute</p>
    <p>WOOT 2015</p>
  </div>
  <div class="page">
    <p>/bin/whoami</p>
    <p>Graduate Student at George Mason University  Senior Penetration Tester at Booz Allen Hamilton  Social Engineering Researcher</p>
  </div>
  <div class="page">
    <p>Acknowledgements</p>
    <p>This research could not have been accomplished without the assistance of:</p>
    <p>Dr. Damon McCoy  Dr. Harry Wechsler  Dr. Mihai Boicu  Dr. Dana Richards  Dr. Duminda Wijesekera  George Mason Department of Computer Science  Booz Allen Hamilton</p>
  </div>
  <div class="page">
    <p>Current Phishing Landscape</p>
    <p>Phishing is no longer just a broad spectrum attack.</p>
    <p>Highly evolved, targeted attack strategies</p>
    <p>Phishing, Smishing, Twishing, Whaling, Spear-phishing.</p>
    <p>Open-source attack frameworks</p>
    <p>Social engineering toolkit (SET), Phishing Frenzy, Wifiphisher</p>
    <p>Threat has evolved, but so has detection</p>
  </div>
  <div class="page">
    <p>Phishing Detection and Prevention</p>
    <p>Technical Models</p>
    <p>Known examples used as training datasets</p>
    <p>Identification of threat signatures using various analysis techniques</p>
    <p>User-Centric Models</p>
    <p>Detected attacks and crafted examples used in awareness training</p>
    <p>Modified examples used as payloads in live exercises and simulations</p>
    <p>Technical Models</p>
    <p>Known examples used as training datasets</p>
    <p>Identification of threat signatures using various analysis techniques</p>
  </div>
  <div class="page">
    <p>Typical Email Filtering</p>
    <p>Keyword Filtering</p>
    <p>Triggers on specific phrases or keywords regardless of context</p>
    <p>Signature-based approach, not very flexible</p>
    <p>Suffers from same limitation as blacklisting in other media</p>
    <p>Bayesian Models</p>
    <p>Determines threat based on word probabilities</p>
    <p>Each word contributes to the overall threat score</p>
    <p>Requires training on known good and bad e-mails to be effective</p>
  </div>
  <div class="page">
    <p>Goal</p>
    <p>Defensive: Given the number of potential email variations, how can we evaluate whether a given filtering approach is effective?</p>
    <p>Offensive: Can we figure out a way to increase the odds of an attack succeeding by finding kinks in the armor?</p>
    <p>Answer: Fuzzing</p>
  </div>
  <div class="page">
    <p>Vary input to identify boundary conditions that may be exploitable</p>
    <p>Basic Example: TCP/IP packet fuzzing</p>
    <p>Fuzzing Overview</p>
  </div>
  <div class="page">
    <p>E-mail Variation Headers</p>
    <p>Start</p>
    <p>Middle</p>
    <p>End</p>
    <p>Date</p>
    <p>Salutation</p>
    <p>Introduction</p>
    <p>Threat</p>
    <p>Action</p>
    <p>Name</p>
    <p>Address</p>
  </div>
  <div class="page">
    <p>Building an e-mail</p>
    <p>Previously we used generative grammars to dynamically create useful phishing e-mail contents for exercises (PhishGen)</p>
    <p>By varying the different production rules, we cause variations in the different sections and subsections in the e-mail</p>
    <p>Our original approach was used to avoid repetition in e-mails for exercises, and the same approach works for intelligent fuzzing</p>
  </div>
  <div class="page">
    <p>ID Left Rule Right Rule</p>
    <p>Example of Production Rules and Placeholders</p>
  </div>
  <div class="page">
    <p>Expansion Example</p>
    <p>Expand {START} using production rule 1</p>
    <p>Expand {INTRO} using production rule 2</p>
    <p>Expand {PROBLEM} using production rule 4</p>
    <p>Expand {RESOLVE} using production rule 5</p>
    <p>Remove {} delimiters</p>
    <p>Apply relevant values to global and relational placeholder variables</p>
    <p>{START}</p>
    <p>{INTRO}{PROBLEM}{RESOLVE}</p>
    <p>{Hello, [FIRSTNAME].}{PROBLEM}{RESOLVE}</p>
    <p>{Hello, [FIRSTNAME].} {Your hasEmployee() has a hasMisc(hasEmployee([X])).}</p>
    <p>{RESOLVE}</p>
    <p>{Hello, [FIRSTNAME].} {Your hasEmployee() has a hasMisc(hasEmployee([X])).} {Please</p>
    <p>click here to have your hasEmployee([X]) updated.}</p>
    <p>Hello, Bob. Your computer has a virus. Please click</p>
    <p>here to have your computer updated.</p>
  </div>
  <div class="page">
    <p>Signatures</p>
    <p>Each generated e-mail has a signature defined by the production rules that were used to create it.</p>
    <p>Previous example:</p>
    <p>Previous grammar could also have generated:</p>
  </div>
  <div class="page">
    <p>Identifying Filtered Rules</p>
    <p>If we sent the previous e-mail, and it was filtered, how could we determine which rule (or combination or rules) resulted in the filtering?</p>
    <p>What if a different variations was not filtered?</p>
    <p>FILTERED: 12  4  5  G1  R1  R2</p>
    <p>UNFILTERED: 12  3  6  G1  R2</p>
  </div>
  <div class="page">
    <p>N-Grams</p>
    <p>N=1</p>
    <p>G1</p>
    <p>R1</p>
    <p>R2</p>
  </div>
  <div class="page">
    <p>N-Grams</p>
    <p>N=1</p>
    <p>G1</p>
    <p>R1</p>
    <p>R2</p>
    <p>N=2</p>
    <p>G1  R1 R1  R2</p>
  </div>
  <div class="page">
    <p>N-Grams</p>
    <p>N=1</p>
    <p>G1</p>
    <p>R1</p>
    <p>R2</p>
    <p>N=2</p>
    <p>G1  R1</p>
    <p>R1  R2</p>
    <p>N=3</p>
    <p>G1  R1 R2</p>
    <p>N=3 , N=4, N=5 ..</p>
  </div>
  <div class="page">
    <p>Fuzzing Strategy</p>
    <p>Generator</p>
    <p>Known-good production rules</p>
    <p>are favored in future generations</p>
    <p>N=1: 1 3 5 6</p>
    <p>N=2: 1  3 3 5</p>
    <p>N=3: 1  3  5</p>
    <p>N=4:</p>
    <p>Exercise Domain</p>
    <p>Send E-mails</p>
    <p>N=1: 3 4 5 7</p>
    <p>N=2: 3 5</p>
    <p>Update Status</p>
    <p>N=1: 1 3 5 6</p>
    <p>N=2: 1  3 3 5</p>
    <p>N=3: 1  3  5</p>
    <p>N=4:</p>
    <p>N=1: 1 3 5 6</p>
    <p>N=2: 1  3 3 5</p>
    <p>N=3: 1  3  5</p>
    <p>N=4:</p>
  </div>
  <div class="page">
    <p>Simulations</p>
    <p>To test our approach, we ran simulations in two different environments:</p>
    <p>Production environment supporting several thousand users with existing detection measures</p>
    <p>Trained environment using SpamAssassin and Bayesian probabilistic classification (795,092 training samples)</p>
    <p>For each environment, we ran 4 rounds of simulations. Each had 4 sets of 100 generated e-mails, and used feedback from the exercise domain to update production rules</p>
  </div>
  <div class="page">
    <p>Results</p>
    <p>D e</p>
    <p>te ct</p>
    <p>e d</p>
    <p>E -m</p>
    <p>a il</p>
    <p>s (%</p>
    <p>)</p>
    <p>Simulation Round</p>
    <p>Detection Rates in Production and Trained Environments</p>
    <p>Production Environment</p>
    <p>Trained Environment</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>After 4 rounds of testing, our generator was able to bypass all detection filters and get all 100 e-mails through to the inbox</p>
    <p>Successful but very noisy approach, better suited for administrators than attackers</p>
    <p>To request a copy of PhishGen, please send an e-mail to spalka (at) gmu.edu with subject line: Phishgen Request</p>
  </div>
  <div class="page">
    <p>Questions</p>
  </div>
</Presentation>
