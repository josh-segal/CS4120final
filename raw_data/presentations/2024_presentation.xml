<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Toward Lighter Containers for the Edge</p>
    <p>Misun Park misun@gatech.edu Ketan Bhardwaj ketanbj@gatech.edu Ada Gavrilovska ada@cc.gatech.edu</p>
  </div>
  <div class="page">
    <p>K. Bilal, O. Khalid, A. Erbad and S. U. Khan, Potentials, trends, and prospects in edge technologies: Fog, cloudlet, mobile edge, and micro data centers, Computer Networks, vol 130, pp 94120, 1 2018, doi: 10.1016/j.comnet.2017.10.002.</p>
    <p>Migrate Things from Cloud to the Edge</p>
  </div>
  <div class="page">
    <p>Challenges in Edge Computing</p>
    <p>Cloud native applications can be adopted directly to the edge?</p>
    <p>Limited Resource</p>
    <p>Image Bloat</p>
    <p>Slow Startup</p>
  </div>
  <div class="page">
    <p>Limited Resources</p>
  </div>
  <div class="page">
    <p>Image Size Bloat  Containerized applications with bloated size</p>
    <p>Due to heavy/complex runtimes  Hardware acceleration supports</p>
    <p>With GPU suppo rt like CUDA run</p>
    <p>time,</p>
    <p>the number bec omes far worse</p>
  </div>
  <div class="page">
    <p>Slow Launch Time</p>
    <p>Workload execution starts</p>
    <p>Docker run</p>
    <p>Runc run</p>
    <p>Python language runtime bootup</p>
    <p>Import TensorFlow</p>
  </div>
  <div class="page">
    <p>Alternative approach: Checkpoint/Restore</p>
    <p>approach solves the lengthened bootup latency?</p>
    <p>heavy resource pressure -- C/R incurs a high memory cost.</p>
    <p>MB</p>
    <p>Figure: Comparison of maximum memory usage of containers with TensorFlow application, using between checkpoint restore and cold boot, respectively.</p>
    <p>Not solving image bloat</p>
    <p>Nimble to start?</p>
    <p>Resourcedemanding</p>
    <p>Checkpointing requires additional memory by nature.</p>
  </div>
  <div class="page">
    <p>Alternative approach: Single long-running monolithic container</p>
    <p>Runtime</p>
    <p>Application</p>
    <p>+ Limit resource requirement to a single runtime</p>
    <p>+ Remove need for on-demand launch time</p>
    <p>- Exposes new programming and deployment APIs</p>
    <p>- Does not leverage existing container-based infrastructure</p>
  </div>
  <div class="page">
    <p>Addressing the Gap</p>
    <p>Runtime</p>
    <p>Application</p>
    <p>Seeking opportunity to satisfy the edge requirements while retaining the benefits from containerization</p>
    <p>Our answer is: shared backend</p>
  </div>
  <div class="page">
    <p>Addressing the Gap: Shared Runtime Backend</p>
    <p>Application</p>
    <p>Runtime</p>
    <p>Shared backend is a long running service process, warms up thick runtimes in advance and allows them to be shared among multiple instances</p>
    <p>Applications do not need to include, or launch heavy runtime itself, but just borrow them</p>
  </div>
  <div class="page">
    <p>A1</p>
    <p>Runtime</p>
    <p>ANA2</p>
    <p>Addressing the Gap: Shared Runtime Backend + Lightweight Application Containers</p>
    <p>Benefits from containerization retained with smaller image size</p>
  </div>
  <div class="page">
    <p>A1</p>
    <p>Runtime</p>
    <p>ANA2</p>
    <p>Addressing the Gap: Shared Runtime Backend + Lightweight Application Containers</p>
    <p>Resource pressure reduced thanks to not instantiating multiple runtimes for each applications</p>
  </div>
  <div class="page">
    <p>Pocket</p>
    <p>A service container</p>
    <p>Application containers</p>
    <p>a new lightweight system to support edge computing</p>
    <p>splits containerized applications into two parts: application container and a bloat-causing runtime service container</p>
    <p>+ retains benefits of container technologies + achieves lower resource pressure, higher</p>
    <p>responsiveness, and better scalability</p>
  </div>
  <div class="page">
    <p>Execution Model / Programming Model</p>
    <p>File System Devices</p>
    <p>Python Tensorflow PyTorch</p>
    <p>Application Container</p>
    <p>Application Container</p>
    <p>Application Container</p>
    <p>Pocket Interface</p>
    <p>Service Container</p>
    <p>Concurrency and Dynamic Resource Scaling in Runtime</p>
    <p>High Performance IPC request</p>
    <p>response</p>
    <p>Workload Isolation</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>Experimental Setup</p>
    <p>https://github.com/zzh8829/yolov3-tf2</p>
  </div>
  <div class="page">
    <p>Pocket demands less resource when # instances are equivalent.  Pocket application does not include Tensorflow in it, but monolithic application package must</p>
    <p>possess Tensorflow as its part  One Tensorflow-service process vs. N Tensorflow-service process</p>
    <p>Pocket achieves higher resource efficiency</p>
  </div>
  <div class="page">
    <p>Pocket outperforms monolithic with regard to mean execution time  Pocket benefits from shared backend, and also shared model</p>
    <p>Pocket improves application performance</p>
    <p># Instances Pocket Monolithic</p>
    <p>(second)</p>
    <p>Mean time to launch 1 &amp; 10 concurrent instances</p>
  </div>
  <div class="page">
    <p>Pocket allows for lightweight application containers</p>
    <p>Lightweight communication mechanism is necessary  gRPC and its dependency take time to import</p>
    <p># Instances Pocket-ssh Pocket-rpc Monolithic</p>
    <p>(millisecond)</p>
    <p>Mean time to launch 1 &amp; 10 concurrent instances</p>
  </div>
  <div class="page">
    <p>Summary of Contributions</p>
    <p>Pocket approach to application stack for the edge</p>
    <p>Problems</p>
    <p>Image bloat Slow startup</p>
    <p>Resource pressure</p>
    <p>Path Forward</p>
    <p>Compact containers for the edge with</p>
    <p>shared backend runtimes</p>
    <p>Open Questions</p>
    <p>Concurrency, isolation, with lightweight and</p>
    <p>high-performance IPC</p>
  </div>
</Presentation>
