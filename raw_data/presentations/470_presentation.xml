<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>The Conjunction of the Knowledge Gradient and the Economic Approach to Simulation Selection</p>
    <p>Stephen E. Chick1</p>
    <p>Peter I. Frazier2</p>
    <p>Tuesday December 15, 2009 Winter Simulation Conference, Austin</p>
    <p>Chick, Frazier (INSEAD,Cornell) WSC 2009 1 / 20</p>
  </div>
  <div class="page">
    <p>Ranking and Selection for Discrete Event Simulation</p>
    <p>We have a discrete event simulator with which we can estimate the consequences of a future real-world decision. For example:</p>
    <p>Designs of a queuing network. Inventory policies for a supply chain. Pricing strategies for a revenue management problem. . . .</p>
    <p>We want to find a real-world decision that will work well, according to the simulator.</p>
    <p>Our simulator requires significant time to accurately characterize a decision, and we do not have enough time to do so for each one.</p>
    <p>Question: which real-world decisions should we simulate and for how long?</p>
    <p>Chick, Frazier (INSEAD,Cornell) WSC 2009 2 / 20</p>
  </div>
  <div class="page">
    <p>Ranking &amp; Selection (R&amp;S)</p>
    <p>We have k alternatives. Alternative x {1, . . . , k} has true value, Ux . There is also a standard option with known value U0, e.g., U0 = 0 is the value of doing nothing.</p>
    <p>Sampling alternative x gives a noisy observation of Ux ,</p>
    <p>y  Normal(Ux ,  2x ),</p>
    <p>where we suppose the measurement variance  2x is known.</p>
    <p>To describe our belief about U1, . . . , Uk , we assume an independent normal prior distribution. Let ~0 be a vector containing the means and variances of the prior.</p>
    <p>After observing a sequence of samples, we will have a posterior distribution that is also normal. Let ~t be this posterior.</p>
    <p>Chick, Frazier (INSEAD,Cornell) WSC 2009 3 / 20</p>
  </div>
  <div class="page">
    <p>Bayesian Posterior Probability Distribution</p>
    <p>P o s te</p>
    <p>ri o r</p>
    <p>M e a n</p>
    <p>Time (t)</p>
    <p>Prior Mean</p>
    <p>True value U</p>
    <p>Sunday, December 13, 2009</p>
    <p>Chick, Frazier (INSEAD,Cornell) WSC 2009 4 / 20</p>
  </div>
  <div class="page">
    <p>Cost and Benefit of Sampling</p>
    <p>A fully sequential policy  is a rule for choosing at each time t to either:</p>
    <p>Sample an alternative i (t) of our choosing, and pay a cost ci(t); We call the rule for choosing i (t) the allocation rule. Or, stop sampling (T = t), select an alternative I (T ) for implementation, and receive a reward UI (T ). We call the rule for choosing T the stopping rule.</p>
    <p>Sampling incurs a direct cost, but improves our eventual choice I (T ).</p>
    <p>The value of a policy  given the information in the posterior  is</p>
    <p>V  () = E</p>
    <p>[ T1</p>
    <p>t=0</p>
    <p>ci(t) + UI (T ) |~0 = ~</p>
    <p>] .</p>
    <p>Our goal is to find a policy with optimal value V (~) = sup V  (~).</p>
    <p>Chick, Frazier (INSEAD,Cornell) WSC 2009 5 / 20</p>
  </div>
  <div class="page">
    <p>Previous Literature</p>
    <p>This work builds on two related sections of the literature.</p>
    <p>Economics of simulation: [Chick and Gans, 2009] considers a discounted version of our problem. We extend this work by considering the undiscounted case, and by developing novel stopping and allocation rules.</p>
    <p>Knowledge-gradient: [Gupta and Miescke, 1996, Frazier et al., 2008] derive an allocation rule based on a single-step expected value of information calculation. [Frazier and Powell, 2008] extends this idea to stopping rules. We extend this work by considering multi-step valuations of information.</p>
    <p>Chick, Frazier (INSEAD,Cornell) WSC 2009 6 / 20</p>
  </div>
  <div class="page">
    <p>Special Case: k = 1</p>
    <p>Consider the special case of comparing a single alternative against a known standard. Then the problem becomes,</p>
    <p>V (~) = sup</p>
    <p>E [ cT + max{U0, T}|~0 = ~</p>
    <p>] where T = E[U1 |~T ] is the posterior mean of the alternative. This is an optimal stopping problem.</p>
    <p>We relax our single-alternative problem by allowing T to take real values, instead of just integers.</p>
    <p>Then the posterior mean T becomes a diffusion, and the optimal stopping problem becomes a free-boundary problem.</p>
    <p>Chick, Frazier (INSEAD,Cornell) WSC 2009 7 / 20</p>
  </div>
  <div class="page">
    <p>Optimal Stopping Boundary</p>
    <p>P o</p>
    <p>s te</p>
    <p>ri o</p>
    <p>r M</p>
    <p>e a</p>
    <p>n</p>
    <p>Time (t)</p>
    <p>Stopping Time (T)</p>
    <p>Expected value upon stopping</p>
    <p>Upper Stopping Boundary</p>
    <p>Lower Stopping Boundary</p>
    <p>Monday, December 14, 2009</p>
    <p>Chick, Frazier (INSEAD,Cornell) WSC 2009 8 / 20</p>
  </div>
  <div class="page">
    <p>Ease of Use</p>
    <p>If we solve the free-boundary problem once for standard values c = 1,  = 1, U0 = 0, we may easily transform to solve for any values c &gt; 0,  &gt; 0, U0.</p>
    <p>For the standard problem, let b(1/t) be the optimal boundary. For general problems, the optimal boundary is</p>
    <p>m1b(1/(t)),</p>
    <p>where  = c1/32/3 and  = c2/3/2/3.</p>
    <p>One can use the following approximation to the standard boundary b with little loss in performance.</p>
    <p>b(s)b(s)=</p>
    <p>Practitioners need not solve the free-boundary problem.</p>
    <p>Chick, Frazier (INSEAD,Cornell) WSC 2009 9 / 20</p>
  </div>
  <div class="page">
    <p>Multiple Alternatives</p>
    <p>We now consider multiple alternatives, and derive or re-derive stopping and allocation rules using the idea of value of information.</p>
    <p>In general, the optimal stopping rule is</p>
    <p>T = inf</p>
    <p>{ t  0 : V (~t ) max</p>
    <p>x=0,...,k Tx = 0</p>
    <p>} .</p>
    <p>maxx Tx is the value obtained by taking no more samples. V (~t ) is the maximal value that can be extracted given ~t .</p>
    <p>V (~t )maxx Tx  0 is the net value of continuing to sample in an optimal way.</p>
    <p>V (~t ) is hard to calculate for k &gt; 1. Instead, we approximate the value of continuing to sample.</p>
    <p>Chick, Frazier (INSEAD,Cornell) WSC 2009 10 / 20</p>
  </div>
  <div class="page">
    <p>Stopping Rules</p>
    <p>Each of the following stopping rules approximate the net value of sampling with best achievable within a simple class of policies. Each stops when its approximation is 0.</p>
    <p>KG1: single alternative, single sample. KG: single alternative, deterministic sample size. PDE: single alternative, adaptive sample size. EOCc,k : multiple alternatives, deterministic sample size. optimal: multiple alternatives, adaptive sample size and allocation. (the optimal policy is compuationally intractable)</p>
    <p>KG, PDE, and EOCc,k require further approximations to find the best policy within their class.</p>
    <p>Of these rules, KG and PDE are new.</p>
    <p>Chick, Frazier (INSEAD,Cornell) WSC 2009 11 / 20</p>
  </div>
  <div class="page">
    <p>Stopping Boundary</p>
    <p>Effective number of replications, t</p>
    <p>P os</p>
    <p>te ri</p>
    <p>or m</p>
    <p>ea n,</p>
    <p>y t/t Upper stopping boundary</p>
    <p>KG 1</p>
    <p>KG 10</p>
    <p>KG 50</p>
    <p>PDE</p>
    <p>From PDE or Quick Approx. KG(*)/EOC KG(*)/EOC Approx KG</p>
    <p>Stopping boundaries with k = 1 alternative and parameter values c = 1,  = 105, m = 0.</p>
    <p>Chick, Frazier (INSEAD,Cornell) WSC 2009 12 / 20</p>
  </div>
  <div class="page">
    <p>Numerical Results (k = 1)</p>
    <p>Expected loss of stopping rules for k = 1, c = 1, 0 = 0, t0 = 100, and  = 105 calculated using Monte Carlo simulation with 106 samples. OC = Opportunity Cost = maxi Ui UI (T )</p>
    <p>% subStopping Rule E[cT] E[OC] E[cT+OC] optimality</p>
    <p>PDEb 321.850.25 2631 5851  EOCc,k 142.530.11 6122 7552 4.99% KG 136.510.11 6342 7702 5.45% KG1 10.530.01 25055 25155 56.69%</p>
    <p>Better approximations to the value of information result directly in better expected performance.</p>
    <p>Chick, Frazier (INSEAD,Cornell) WSC 2009 13 / 20</p>
  </div>
  <div class="page">
    <p>Allocation Rules</p>
    <p>These approximations to the value of information also imply allocation rules.</p>
    <p>KG1: Sample the alternative with the largest expected value of information (EVI).</p>
    <p>KG: Sample the alternative with the largest average EVI per sample (over deterministic rules).</p>
    <p>PDE: Sample the alternative whose posterior mean is furthest from the k = 1 stopping boundary.</p>
    <p>Sequential LL (based on EOC): Sample the alternative to which the most samples are allocated by the allocation with the best net EVI.</p>
    <p>Chick, Frazier (INSEAD,Cornell) WSC 2009 14 / 20</p>
  </div>
  <div class="page">
    <p>Numerical Results (k &gt; 1)</p>
    <p>Table shows expected loss E [cT + OC ] for pairs of stopping and allocation rules. Rows are sorted by loss at k = 100. The best (lowest loss) are at the bottom.</p>
    <p>PDE stopping with KG allocation is the best policy.</p>
    <p>It is better than LL, EOCc,1, which was best in the large empirical study [Branke et al., 2007].</p>
    <p>Stop,Alloc k=3 10 20 50 100</p>
    <p>KG1,KG1 350812 714018 876719 1086267 1250072 KG,KG 6744 14456 17616 224523 266625 Equal,EOCc,k 4332 10403 18153 422016 842529 LL,EOCc,k 4292 8214 10954 157717 216822 KG,EOCc,k 4242 7993 10574 148916 202719 KG1,EOCc,k 4192 7283 9163 122311 157711 KG1, PDE 3482 6943 8753 115810 151610 PDE, PDE 3442 7003 8563 107511 130812 KG, PDE 3272 6002 7223 9058 11119 Chick, Frazier (INSEAD,Cornell) WSC 2009 15 / 20</p>
  </div>
  <div class="page">
    <p>Numerical Results (k &gt; 1): Stopping Rule</p>
    <p>Consider the effect of the stopping rule.</p>
    <p>PDE is the best stopping rule, followed in order by EOCc,k , KG, and KG1. KG1 performed very badly because it dramatically underestimates the value of information.</p>
    <p>k=3 10 20 50 100</p>
    <p>KG1,KG1 350812 714018 876719 1086267 1250072 Equal,EOCc,k 4332 10403 18153 422016 842529 KG,KG 6744 14456 17616 224523 266625 LL,EOCc,k 4292 8214 10954 157717 216822 KG,EOCc,k 4242 7993 10574 148916 202719 KG1,EOCc,k 4192 7283 9163 122311 157711 KG1,PDE 3482 6943 8753 115810 151610 PDE,PDE 3442 7003 8563 107511 130812 KG,PDE 3272 6002 7223 9058 11119</p>
    <p>Chick, Frazier (INSEAD,Cornell) WSC 2009 16 / 20</p>
  </div>
  <div class="page">
    <p>Numerical Results (k &gt; 1): Allocation Rule</p>
    <p>Consider the effect of the allocation rule.</p>
    <p>KG and KG1 are the best allocation rules, despite poor performance as stopping rules. They consistently underestimate the value of information, but this bias cancels when making allocation decisions.</p>
    <p>The PDE allocation rule also performs well.</p>
    <p>k=3 10 20 50 100</p>
    <p>KG1, KG1 350812 714018 876719 1086267 1250072 KG,KG 6744 14456 17616 224523 266625 Equal,EOCc,k 4332 10403 18153 422016 842529 LL,EOCc,k 4292 8214 10954 157717 216822 KG,EOCc,k 4242 7993 10574 148916 202719 KG1,EOCc,k 4192 7283 9163 122311 157711 KG1,PDE 3482 6943 8753 115810 151610 PDE,PDE 3442 7003 8563 107511 130812 KG,PDE 3272 6002 7223 9058 11119 Chick, Frazier (INSEAD,Cornell) WSC 2009 17 / 20</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>This approach balances the cost of sampling with the rewards of having information  financial criteria may be more appropriate than statistical criteria in most business decisions.</p>
    <p>We can solve the k = 1 case exactly when the variance is known with a PDE, and that solution supports understanding of the k &gt; 1 problem.</p>
    <p>We extended both the KG and economics of simulation approaches with new stopping rules and allocation rules that are empirically better than those from prior experiments.</p>
    <p>We believe that this approach may have application in more complex simulation optimization problems (e.g. unknown variances, CRN, correlated beliefs, metamodels), not just independent variance-known ranking and selection.</p>
    <p>Chick, Frazier (INSEAD,Cornell) WSC 2009 18 / 20</p>
  </div>
  <div class="page">
    <p>Branke, J., Chick, S., and Schmidt, C. (2007).</p>
    <p>Selecting a selection procedure.</p>
    <p>Management Sci., 53(12):19161932.</p>
    <p>Chick, S. and Gans, N. (2009).</p>
    <p>Economic analysis of simulation selection problems.</p>
    <p>Management Sci., to appear.</p>
    <p>Frazier, P. and Powell, W. (2008).</p>
    <p>The knowledge-gradient stopping rule for ranking and selection.</p>
    <p>Winter Simul. Conf. Proc., 2008.</p>
    <p>Frazier, P., Powell, W. B., and Dayanik, S. (2008).</p>
    <p>A knowledge gradient policy for sequential information collection.</p>
    <p>SIAM J. on Control and Optimization, 47(5):24102439.</p>
    <p>Gupta, S. and Miescke, K. (1996).</p>
    <p>Bayesian look ahead one-stage sampling allocations for selection of the best population.</p>
    <p>Journal of statistical planning and inference, 54(2):229244. Chick, Frazier (INSEAD,Cornell) WSC 2009 19 / 20</p>
  </div>
  <div class="page">
    <p>Thank You</p>
    <p>Any questions?</p>
    <p>Chick, Frazier (INSEAD,Cornell) WSC 2009 20 / 20</p>
  </div>
</Presentation>
