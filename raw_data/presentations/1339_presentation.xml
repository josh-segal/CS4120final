<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Empirical Study of Power Consumption of x86-64 Instruction Decoder</p>
    <p>Mikael Hirki, Zhonghong Ou, Kashif Nizam Khan , Jukka K. Nurminen, Tapio Niemi</p>
  </div>
  <div class="page">
    <p>2</p>
    <p>Motivation</p>
    <p>Study the differences between ARM vs Intel in terms of energy consumption</p>
    <p>Commonly cited difference : Instruction Set (RISC vs CISC)</p>
    <p>Goal: Investigate whether x86-64 processors consume more energy because of their complex instruction set</p>
  </div>
  <div class="page">
    <p>3</p>
    <p>Problem</p>
    <p>How can we measure the energy consumption of instruction decoders?</p>
  </div>
  <div class="page">
    <p>4</p>
    <p>Methodology</p>
    <p>Using micro-benchmarks that specifically trigger the instruction decoders by exceeding the capacity of the decoded instruction cache</p>
    <p>Leverage Intels RAPL (Running Average Power Limit) Micro-op cache</p>
  </div>
  <div class="page">
    <p>5</p>
    <p>Intel RAPL</p>
    <p>https://software.intel.com/en-us/articles/intel-power-governor</p>
  </div>
  <div class="page">
    <p>6</p>
    <p>Intel Haswell pipeline L1 instruction cache</p>
    <p>Pre-decoding</p>
    <p>Instruction queue</p>
    <p>Complex decoder</p>
    <p>Simple decoder</p>
    <p>Simple decoder</p>
    <p>Simple decoder</p>
    <p>Micro-code</p>
    <p>Micro-ops cache</p>
    <p>Decode queue (56 micro-ops)</p>
    <p>6 instructions</p>
    <p>Renaming and scheduling</p>
    <p>Execution ports</p>
    <p>Retirement</p>
  </div>
  <div class="page">
    <p>7</p>
    <p>Instruction decoder benchmarks</p>
    <p>Simple arithmetic operations Float and integer data types Arrays or registers Uses L1 or L2 caches Uses loop unrolling to increase the code size</p>
    <p>D += A[ j ] + B[ j ] C[ j ] ;</p>
    <p>D += (A[ j ] &lt;&lt; 3) * (A[ j ] &lt;&lt; 4) * ( (B[ j ] &lt;&lt; 2) * 5 + 1 ) ;</p>
  </div>
  <div class="page">
    <p>8</p>
    <p>Loop unrolling</p>
    <p>Original loop for(int j=0;j&lt;n;j++) D += A[j] + B[j] * C[j]</p>
    <p>Unrolled loop for(int j=0;j&lt;n;j+=256) { D += A[j] + B[j] * C[j] D += A[j+1] + B[j+1] * C[j+1]</p>
    <p>D += A[j+ 255] + B[j+255] * C[j+255] }</p>
    <p>Idea: Trigger the instruction decoders by using a big unroll count for a single loop</p>
  </div>
  <div class="page">
    <p>9</p>
    <p>Advantages of Loop unrolling</p>
    <p>Increases performance Opportunities to find instruction level parallelism</p>
    <p>What we do: manually unroll the loop up to 2048 times Increases the code size Triggers instruction decoder</p>
    <p>Idea: If the loop is still executed in the same time as before, the observed difference in power consumption can be attributed to instruction decoding pipeline</p>
  </div>
  <div class="page">
    <p>10</p>
    <p>Evaluation - Power consumption vs. Code Size</p>
    <p>U n r o l l c o u n t</p>
    <p>P ac</p>
    <p>ka ge</p>
    <p>e ne</p>
    <p>rg y</p>
    <p>co m</p>
    <p>su m</p>
    <p>pt io</p>
    <p>n (J</p>
    <p>)</p>
    <p>Instruction Decoder is activated</p>
    <p>L1 Icache capacity exceeds</p>
  </div>
  <div class="page">
    <p>11</p>
    <p>Evaluation - Power consumption vs. Code Size</p>
    <p>U n r o l l c o u n t</p>
    <p>P ac</p>
    <p>ka ge</p>
    <p>e ne</p>
    <p>rg y</p>
    <p>co m</p>
    <p>su m</p>
    <p>pt io</p>
    <p>n (J</p>
    <p>)</p>
    <p>Normal Case Extreme Case</p>
  </div>
  <div class="page">
    <p>12</p>
    <p>Power Modeling</p>
  </div>
  <div class="page">
    <p>13</p>
    <p>Evaluation- Power consumption breakdown</p>
    <p>Uncore static 12%</p>
    <p>Cores static 44% Micro-op Execution 10%</p>
    <p>Instruction decoders 3%</p>
    <p>L1 cache dynamic 9%</p>
    <p>L2 &amp; L3 cache dynamic 22%</p>
    <p>Normal case</p>
  </div>
  <div class="page">
    <p>14</p>
    <p>Evaluation- Power consumption breakdown</p>
    <p>Uncore static 13%</p>
    <p>Cores static 47%</p>
    <p>Micro-op Execution 22%</p>
    <p>Instruction decoders 10%</p>
    <p>L1 cache dynamic 8% Extreme case</p>
  </div>
  <div class="page">
    <p>15</p>
    <p>Summary</p>
    <p>The x86-64 instruction decoders consume relatively little power Instruction decoder consumes 3% - 10% of the processor package power The instruction set is not a significant drawback compared to ARM We plan to port our benchmark to ARM platforms</p>
    <p>Microbenchmark code https://github.com/mhirki/idq-bench2</p>
  </div>
  <div class="page">
    <p>16</p>
    <p>Green Big Data Project overview</p>
    <p>Overall Research Focus Energy efficiency analysis in High Performance Scientific Computing  Port IgProf to 64-bit ARM  Energy profiler module  Techniques and tools for measuring energy efficiency  Intel RAPL(Running Average Power Limit) evaluation</p>
    <p>https://twiki.cern.ch/twiki/bin/view/Main/GreenBigData</p>
  </div>
  <div class="page">
    <p>17</p>
    <p>Thank you!</p>
    <p>Questions?</p>
  </div>
</Presentation>
