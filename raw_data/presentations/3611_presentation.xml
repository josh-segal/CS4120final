<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>On Training Robust PDF Malware Classifiers</p>
    <p>Yizheng Chen, Shiqi Wang, Dongdong She and Suman Jana Columbia University</p>
  </div>
  <div class="page">
    <p>Security Classifiers</p>
    <p>Malicious</p>
    <p>Benign</p>
    <p>High Accuracy, Low False Positive Rate But very easy to evade</p>
  </div>
  <div class="page">
    <p>Evading Gmails PDF Malware Classifier</p>
    <p>Inserted /Root/Pages from to</p>
  </div>
  <div class="page">
    <p>Evading Gmails PDF Malware Classifier</p>
    <p>Inserted /Root/Pages from to Benign</p>
    <p>The PDF is still malicious</p>
  </div>
  <div class="page">
    <p>What Changed in the PDF Malware?</p>
    <p>/Catalog</p>
    <p>/Pages /Page</p>
    <p>Exploit /Javascript</p>
    <p>/FlateDecode 1573</p>
    <p>/Root /Type</p>
    <p>/OpenAction</p>
    <p>/JS /S</p>
    <p>/Pages</p>
    <p>/Kids</p>
    <p>/Type</p>
    <p>/Count</p>
    <p>/Type /Filter /Length</p>
  </div>
  <div class="page">
    <p>What Changed in the PDF Malware?</p>
    <p>/Catalog</p>
    <p>/Pages /Page</p>
    <p>Exploit /Javascript</p>
    <p>/FlateDecode 1573</p>
    <p>/Root /Type</p>
    <p>/OpenAction</p>
    <p>/JS /S</p>
    <p>/Pages</p>
    <p>/Kids</p>
    <p>/Type</p>
    <p>/Count</p>
    <p>/Type /Filter /Length</p>
    <p>Inserted 12,188 objects under the /Root/Pages Subtree</p>
    <p>PDF is still malicious</p>
  </div>
  <div class="page">
    <p>Example Robustness Property</p>
    <p>/Catalog</p>
    <p>/Pages /Page</p>
    <p>Exploit /Javascript</p>
    <p>/FlateDecode 1573</p>
    <p>/Root /Type</p>
    <p>/OpenAction</p>
    <p>/JS /S</p>
    <p>/Pages</p>
    <p>/Kids</p>
    <p>/Type</p>
    <p>/Count</p>
    <p>/Type /Filter /Length</p>
    <p>The classifier should keep malicious prediction no matter how many pages are inserted</p>
  </div>
  <div class="page">
    <p>Example Robustness Property</p>
    <p>/Catalog</p>
    <p>/Pages /Page</p>
    <p>Exploit /Javascript</p>
    <p>/FlateDecode</p>
    <p>/Root /Type</p>
    <p>/OpenAction</p>
    <p>/JS /S</p>
    <p>/Pages</p>
    <p>/Kids</p>
    <p>/Type</p>
    <p>/Count</p>
    <p>/Type /Filter</p>
    <p>Deleted</p>
    <p>The classifier should keep malicious prediction if non-functional objects are deleted</p>
  </div>
  <div class="page">
    <p>Why are Robustness Properties Useful? o Unbounded attackers can always</p>
    <p>evade the classifier</p>
  </div>
  <div class="page">
    <p>Why are Robustness Properties Useful? o Unbounded attackers can always</p>
    <p>evade the classifier</p>
    <p>o Robust against reasonably bounded attackers</p>
    <p>o Generalize to robustness against unbounded attackers</p>
  </div>
  <div class="page">
    <p>Why are Robustness Properties Useful? o Unbounded attackers can always</p>
    <p>evade the classifier</p>
    <p>o Robust against reasonably bounded attackers o Robustness Properties o Robust Accuracy</p>
    <p>o Generalize to robustness against unbounded attackers</p>
    <p>All Samples</p>
    <p>Robust and</p>
    <p>Accurate</p>
    <p>Accurate</p>
  </div>
  <div class="page">
    <p>Robust Accuracy</p>
    <p>The percentage of test samples that are correctly classified against any attacker within a specified bound.  e.g., !&quot;  0.1 bounded attacker against an image classifier</p>
    <p>Estimated Robust Accuracy (ERA) measures robustness using attacks.  Restricted attackers within the bound  Unrestricted attackers as the bound increases</p>
    <p>Verified Robust Accuracy (VRA) measures robustness using sound overapproximation methods.  Overapproximates attacks  Lower bound of the percentage of robust and accurate samples</p>
  </div>
  <div class="page">
    <p>Sound Over-Approximation</p>
    <p>Symbolic Linear Relaxation Wang et al. USENIX Security 2018, NIPS 2018.</p>
    <p>Symbolic Linear Relaxation o Propagate Symbolic Intervals o Over-approximates attacks o Measures VRA</p>
    <p>https://github.com/tcwangshiqi-columbia/symbolic_interval</p>
  </div>
  <div class="page">
    <p>Regular Training min(errors)</p>
    <p>Robust Training</p>
    <p>Verifiable Training Increases VRA</p>
    <p>min( max( errors by successful evasions ) )</p>
  </div>
  <div class="page">
    <p>Regular Training min(errors)</p>
    <p>Robust Training min( max( errors by successful evasions ) )</p>
    <p>Adversarial Verifiable</p>
    <p>Verifiable Training Increases VRA</p>
    <p>Sound Over-approximation</p>
  </div>
  <div class="page">
    <p>Challenges</p>
    <p>How to train a single model to be robust against different attackers?</p>
    <p>How to maintain low false positive rate?</p>
    <p>Does verifiable robustness generalize to unrestricted attackers?</p>
  </div>
  <div class="page">
    <p>Robust Against Different Attackers</p>
    <p>Obtain VRA for multiple robustness properties and regular accuracy  The underlying optimization problem is harder</p>
    <p>Mixed Training  Combined training objective  Mix the batches</p>
    <p>Accuracy</p>
    <p>Property 1 VRA Property 2 VRA</p>
    <p>Property 3 VRA</p>
  </div>
  <div class="page">
    <p>New Distance Metric</p>
    <p>To bound attackers that reasonably mimic real attackers  Does not affect false positive rate</p>
    <p>Adversarial malware examples  x -&gt; x, s.t. f(x) = benign and O(x) is malicious, imperceptible by machine</p>
  </div>
  <div class="page">
    <p>Searching for Evasive PDF Malware</p>
    <p>Attacks can be decomposed to building block operations  Feature insertion-only attacks. Grosse et. al., Hu et al.  Mimicry, merging with benign features. rndi et al.  Mutation operations (insert, replace, delete). Xu et al., Dang et al.</p>
    <p>Optimization  Greedy (Gradient Descent)  Genetic Evolution  Hill Climbing</p>
    <p>Benign</p>
  </div>
  <div class="page">
    <p>Subtree Distance</p>
    <p>A PDF malware variant needs correct syntax and correct semantic.  PDF file is parsed into a tree structure</p>
    <p>/Catalog</p>
    <p>/Pages /Page</p>
    <p>Exploit /Javascript</p>
    <p>/FlateDecode 1573</p>
    <p>/Root /Type</p>
    <p>/OpenAction</p>
    <p>/JS /S</p>
    <p>/Pages</p>
    <p>/Kids</p>
    <p>/Type</p>
    <p>/Count</p>
    <p>/Type</p>
    <p>/Filter /Length</p>
  </div>
  <div class="page">
    <p>Subtree Distance</p>
    <p>A PDF malware variant needs correct syntax and correct semantic.  PDF file is parsed into a tree structure  # of different subtrees under the root between variants</p>
    <p>/Catalog</p>
    <p>/Pages /Page</p>
    <p>Exploit /Javascript</p>
    <p>/FlateDecode 1573</p>
    <p>/Root /Type</p>
    <p>/OpenAction</p>
    <p>/JS /S</p>
    <p>/Pages</p>
    <p>/Kids</p>
    <p>/Type</p>
    <p>/Count</p>
    <p>/Type</p>
    <p>/Filter /Length</p>
    <p>/Catalog</p>
    <p>/Pages /Page</p>
    <p>Exploit /Javascript</p>
    <p>/FlateDecode</p>
    <p>/Root /Type</p>
    <p>/OpenAction</p>
    <p>/JS /S</p>
    <p>/Pages</p>
    <p>/Kids</p>
    <p>/Type</p>
    <p>/Count</p>
    <p>/Type</p>
    <p>/Filter</p>
    <p>Subtree Distance One: arbitrary changes in 1 out of N subtrees under root</p>
  </div>
  <div class="page">
    <p>Building Block Robustness Properties</p>
    <p>Small subtree distance maintains low FPR  Subtree insertion property (subtree distance one)  Subtree deletion property (subtree distance one)</p>
  </div>
  <div class="page">
    <p>Subtree Insertion (Distance One)</p>
    <p>/Catalog</p>
    <p>/Pages /Page</p>
    <p>Exploit /Javascript</p>
    <p>/FlateDecode 1573</p>
    <p>/Root /Type</p>
    <p>/OpenAction</p>
    <p>/JS /S</p>
    <p>/Pages</p>
    <p>/Kids</p>
    <p>/Type</p>
    <p>/Count</p>
    <p>/Type /Filter /Length</p>
    <p>Robust against insertion in any 1 out of N subtrees</p>
  </div>
  <div class="page">
    <p>Subtree Deletion (Distance One)</p>
    <p>Robust against arbitrary deletion in one of the existing subtrees</p>
    <p>/Catalog</p>
    <p>/Pages /Page</p>
    <p>Exploit</p>
    <p>/Root /Type</p>
    <p>/OpenAction</p>
    <p>/JS</p>
    <p>/Pages</p>
    <p>/Kids</p>
    <p>/Type</p>
    <p>/Count</p>
    <p>/Type</p>
  </div>
  <div class="page">
    <p>Building Block Robustness Properties</p>
    <p>Small subtree distance maintains low FPR  Subtree insertion property (subtree distance one)  Subtree deletion property (subtree distance one)  Binary path features (Hidost rndi et al. NDSS 13)</p>
    <p>Monotonic Classifier Verifiably Robust Model</p>
    <p>Accuracy 99.04% 99.74%</p>
    <p>False positive Rate 1.78% 0.56%</p>
    <p>Subtree Insertion VRA 99.04% 91.86%</p>
    <p>Subtree Deletion VRA 7.67% 99.68%</p>
    <p>Monotonic classifier f: if x  x, f(x)  f(x)</p>
  </div>
  <div class="page">
    <p>ERA against Adaptive Attackers</p>
    <p>Adapt the genetic evolutionary attack (Xu et al., NDSS 2016.)  Monotonic: move exploit, i.e. deletion but keep the exploit.  Verifiably robust model: insert and delete under different subtrees.  Our verifiably robust model requires 3.7 times more mutations and 10</p>
    <p>times larger L0 distance to be evaded by adaptive attackers. 26</p>
    <p>E R</p>
    <p>A</p>
    <p>Verifiably Robust Model Monotonic 100</p>
    <p>E R A</p>
  </div>
  <div class="page">
    <p>More Evaluations in the Paper</p>
    <p>12 baseline models  Regular trained neural networks, adversarial training, ensemble classifiers,</p>
    <p>monotonic classifiers</p>
    <p>Generate evasive variants  7 different attackers  2 Unrestricted Whitebox Attacks (Gradient, MILP)  3 Unrestricted Blackbox Attacks (Reverse Mimicry, Evolutionary, Adaptive)</p>
    <p>We raise the bar against unbounded attackers 27</p>
  </div>
  <div class="page">
    <p>Thank You</p>
    <p>https://github.com/surrealyz/pdfclassifier</p>
    <p>We have released our source code and models.</p>
  </div>
</Presentation>
