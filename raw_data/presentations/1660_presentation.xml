<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>ARPE Analyzing the relationship between</p>
    <p>parameters and effectors</p>
    <p>Martina Maggio, Henry Hoffmann Lund University, University of Chicago</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Controlling computing systems is messy</p>
    <p>Often you hear modeling that system is too complicated, therefore...</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>And its actually true</p>
    <p>Depending on the model level, creating a model for a computing system might be really complicated</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>Example:</p>
    <p>Suppose we want to model power consumption of a software piece given the datasheet power consumption of the instruction set</p>
    <p>We   need   to   know   that   the   software   code   translates   into   a   set   of   atomic   operations</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>This might be really complicated</p>
    <p>However, often it is much easier to grasp the relationship between the variable that can be changed and some final effect</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>This is a first step to respond to the question of how to automatically control the system</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Methodology</p>
    <p>Experimental evaluation</p>
    <p>Conclusion and future work</p>
  </div>
  <div class="page">
    <p>Methodology</p>
    <p>what   we   can   change what   we   can   measure ideally:             something   that             generates   one             or   more   models</p>
  </div>
  <div class="page">
    <p>Methodology</p>
    <p>what   we   can   change what   we   can   measure CG</p>
  </div>
  <div class="page">
    <p>Methodology</p>
    <p>what   we   can   change what   we   can   measure CG</p>
    <p>Configuration   generator</p>
  </div>
  <div class="page">
    <p>Configuration generator</p>
    <p>Selects a set of configurations given the parameter list and their values</p>
    <p>Automatically generates scripts to execute experiments on the system to build the model</p>
  </div>
  <div class="page">
    <p>Methodology</p>
    <p>what   we   can   change what   we   can   measure CG DC</p>
    <p>data   collector</p>
  </div>
  <div class="page">
    <p>Data collector</p>
    <p>Executes experiments on the system collecting relevant data automatically</p>
  </div>
  <div class="page">
    <p>Methodology</p>
    <p>what   we   can   change what   we   can   measure CG DC DA</p>
    <p>data   analyzer</p>
  </div>
  <div class="page">
    <p>Data analyzer</p>
    <p>Given the collected data generated many different models of the system and selects the less error prone</p>
  </div>
  <div class="page">
    <p>Data analyzer</p>
    <p>Single parameter linear regression to explain the relationship between one parameter and the measured effect</p>
    <p>Multiple parameters multivariate linear regression to build a comprehensive model</p>
  </div>
  <div class="page">
    <p>Data analyzer example</p>
    <p>Execute tomcat from the DaCapo benchmark suite 50 times per configuration</p>
    <p>Parameters: number of threads (1 to 32), iterations (1 to 10)</p>
    <p>Model the real execution time of one instance</p>
  </div>
  <div class="page">
    <p>Experimental results</p>
    <p>Execution time</p>
    <p>Energy consumed</p>
  </div>
  <div class="page">
    <p>Execution time</p>
    <p>Comparison of models for execution time given performance counter or heartbeats</p>
  </div>
  <div class="page">
    <p>Execution time</p>
    <p>We measure the number of instructions retired per second with OProfile and the number of heartbeats retired per second for instrumeted applications: swaptions and x264 from the PARSEC benchmark suite</p>
  </div>
  <div class="page">
    <p>swaptions</p>
    <p>heart rate instructions retired</p>
    <p>training set 0.00027 [s] 0.00034 [s]</p>
    <p>test set 0.00030 [s] 0.04130 [s]</p>
  </div>
  <div class="page">
    <p>x264</p>
    <p>heart rate instructions retired</p>
    <p>training set 0.00494 [s] 0.00072 [s]</p>
    <p>test set 0.00353 [s] 0.00072 [s]</p>
  </div>
  <div class="page">
    <p>Execution time</p>
    <p>Results insight:</p>
    <p>There is no unique parameter to predict execution time, for some benchmark the heart rate does a better job, for others the number of instructions retired is more insightful</p>
    <p>future   work   might   be:   how   do   we   distinguish?</p>
  </div>
  <div class="page">
    <p>Energy consumption</p>
    <p>Do we really need hardware power sensors or can we infer the power consumption of CPU-intensive applications based on the CPU consumption parameter?</p>
  </div>
  <div class="page">
    <p>Energy consumption</p>
    <p>We measure the execution time, the power consumption and the CPU consumption of sunflow, treadbeans (from the DaCapo benchmark suite) and lookbusy</p>
  </div>
  <div class="page">
    <p>Energy consumption Table 5: Error (in joules) using different sensors, computed as specified in (2), lower is better.</p>
    <p>power &amp; time CPU &amp; time</p>
    <p>sunflow 16.10077 287.9064 tradebeans 59.9971 126.0322</p>
    <p>lookbusy 20.6270 19.4846</p>
    <p>the application. Running with more than 6 threads does not provide any benefit. Neither the application execution time nor the amount of consumed energy decreases. However, up to the parallelism degree of the application, it is confirmed that the race to idle approach  allocating all the possible resources to compute and terminate faster  saves some energy. It is possible to automatically produce a very accurate model of the energy consumption based on the power consumption sensor and of the execution time. It is also possible to synthesize a model that is comparable in terms of accuracy to map the percentage of CPU consumed by the application and its execution time to the total energy consumed during the benchmark execution. In this case, the two parameters are combined into a single one (either texec  power or texec  %cpu) and the coefficient of this parameter is identified, together with an offset to take into account the idle power of the machine.</p>
    <p>The data for the benchmark is shown in Table 5. The model built with the CPU consumption produces an error which is about 10% of the maximum value. The model built using power consumption is obviously more accurate with an error of about 0.5% of the energy value. The analysis phase took 0.086 seconds as measured by Matlab command tic/toc. In this case, APRE allows us to find a model that predicts the energy consumption with close to perfect accuracy given power information. Alternatively, APRE also identifies a model that can predict energy without measuring power consumption on the fly. This second model gives up some accuracy, but does not require runtime power measurement.</p>
    <p>The case of tradebeans is completely different. The application exposes a very limited amount of parallelism  as shown in Figure 5, in fact, the percentage of cpu consumed during its execution hardly reaches 125%. This means that in order to consume less energy, only two threads should be executed, not spawning useless threads onto the other cores. In this case, the analysis was able to detect an optimal point for the execution of the application. Also, the same model structure identified for sunflow explains very well the data for this application, both if the percentage of CPU is used and if the average power consumption is used.</p>
    <p>The error data is reported Table 5. The model built with the CPU consumption produces an error about 1%</p>
    <p>en er</p>
    <p>gy [J</p>
    <p>]</p>
    <p>po w</p>
    <p>er [W</p>
    <p>]</p>
    <p>cp u</p>
    <p>[% ]</p>
    <p>#threads</p>
    <p>el a</p>
    <p>ps ed</p>
    <p>ti m</p>
    <p>e [s</p>
    <p>]</p>
    <p>Figure 5: Energy results for tradebeans.</p>
    <p>of the maximum value. The model built using power consumption is more accurate with an average error of 0.5% of the energy value. The analysis phase took 0.002 seconds as measured by Matlab command tic/toc. When the same methodology is applied to other benchmarks from the DaCapo, the same two types of behavior are experienced. For example, h2 and xalan falls into the category where there is an optimal point in terms of energy consumption, while lusearch is similar to sunflow.</p>
    <p>In order to avoid the degree of parallelism limitation, we conducted an experiment with lookbusy4. Lookbusy loads the CPU up to a certain parameter passed at the command line, which we chose to be 80%. Another parameter selects the number of CPUs to be loaded, and in our experiments we are vary that parameter from 1 to 8 and measuring the power and energy consumption. We also keep the execution time of the benchmark constant.</p>
    <p>Figure 6 shows the result obtained varying the number of CPUs to be loaded with lookbusy. As can be seen, the amount of average power consumed during the benchmark execution depends linearly on the number of CPUs loaded. Table 5 summarizes the results of building a model from CPU consumption and power consumption</p>
    <p>Table 5: Error (in joules) using different sensors, computed as specified in (2), lower is better.</p>
    <p>power &amp; time CPU &amp; time</p>
    <p>sunflow 16.10077 287.9064 tradebeans 59.9971 126.0322</p>
    <p>lookbusy 20.6270 19.4846</p>
    <p>the application. Running with more than 6 threads does not provide any benefit. Neither the application execution time nor the amount of consumed energy decreases. However, up to the parallelism degree of the application, it is confirmed that the race to idle approach  allocating all the possible resources to compute and terminate faster  saves some energy. It is possible to automatically produce a very accurate model of the energy consumption based on the power consumption sensor and of the execution time. It is also possible to synthesize a model that is comparable in terms of accuracy to map the percentage of CPU consumed by the application and its execution time to the total energy consumed during the benchmark execution. In this case, the two parameters are combined into a single one (either texec  power or texec  %cpu) and the coefficient of this parameter is identified, together with an offset to take into account the idle power of the machine.</p>
    <p>The data for the benchmark is shown in Table 5. The model built with the CPU consumption produces an error which is about 10% of the maximum value. The model built using power consumption is obviously more accurate with an error of about 0.5% of the energy value. The analysis phase took 0.086 seconds as measured by Matlab command tic/toc. In this case, APRE allows us to find a model that predicts the energy consumption with close to perfect accuracy given power information. Alternatively, APRE also identifies a model that can predict energy without measuring power consumption on the fly. This second model gives up some accuracy, but does not require runtime power measurement.</p>
    <p>The case of tradebeans is completely different. The application exposes a very limited amount of parallelism  as shown in Figure 5, in fact, the percentage of cpu consumed during its execution hardly reaches 125%. This means that in order to consume less energy, only two threads should be executed, not spawning useless threads onto the other cores. In this case, the analysis was able to detect an optimal point for the execution of the application. Also, the same model structure identified for sunflow explains very well the data for this application, both if the percentage of CPU is used and if the average power consumption is used.</p>
    <p>The error data is reported Table 5. The model built with the CPU consumption produces an error about 1%</p>
    <p>en er</p>
    <p>gy [J</p>
    <p>]</p>
    <p>po w</p>
    <p>er [W</p>
    <p>]</p>
    <p>cp u</p>
    <p>[% ]</p>
    <p>#threads</p>
    <p>el a</p>
    <p>ps ed</p>
    <p>ti m</p>
    <p>e [s</p>
    <p>]</p>
    <p>Figure 5: Energy results for tradebeans.</p>
    <p>of the maximum value. The model built using power consumption is more accurate with an average error of 0.5% of the energy value. The analysis phase took 0.002 seconds as measured by Matlab command tic/toc. When the same methodology is applied to other benchmarks from the DaCapo, the same two types of behavior are experienced. For example, h2 and xalan falls into the category where there is an optimal point in terms of energy consumption, while lusearch is similar to sunflow.</p>
    <p>In order to avoid the degree of parallelism limitation, we conducted an experiment with lookbusy4. Lookbusy loads the CPU up to a certain parameter passed at the command line, which we chose to be 80%. Another parameter selects the number of CPUs to be loaded, and in our experiments we are vary that parameter from 1 to 8 and measuring the power and energy consumption. We also keep the execution time of the benchmark constant.</p>
    <p>Figure 6 shows the result obtained varying the number of CPUs to be loaded with lookbusy. As can be seen, the amount of average power consumed during the benchmark execution depends linearly on the number of CPUs loaded. Table 5 summarizes the results of building a model from CPU consumption and power consumption</p>
  </div>
  <div class="page">
    <p>Energy consumption</p>
    <p>er gy</p>
    <p>[J ]</p>
    <p>po w</p>
    <p>er [W</p>
    <p>]</p>
    <p>el a</p>
    <p>ps ed</p>
    <p>ti m</p>
    <p>e [s</p>
    <p>]</p>
    <p>cp u</p>
    <p>[% ]</p>
    <p>#cores Figure 6: Energy results for lookbusy.</p>
    <p>in that case. The analysis phase took 0.002 seconds. In this case, using the two models results in almost identical errors, therefore they can be both considered reliable. The results confirm what previously seen with the execution of real applications. The error percentage in this case is even more limited, and it is around 0.1%</p>
    <p>To summarize the contributions of this set of experiments, we used APRE to find that using power consumption for energy prediction is ideal. However, if one does not have any power consumption sensor, it is possible to use the percentage of CPU consumed to have an estimate of the energy consumed by the benchmark. With the entire set of benchmarks we experienced errors in the range 0.1  10%.</p>
    <p>The last experiment uses the Apache Hadoop MapReduce framework5. Many parameters can be set when launching a map-reduce experiments. Among these, we focus on the number of mappers and the number of reducers. We use mrbench [19] in a single node installation of Hadoop. We collect data about elapsed time for the benchmark execution varying the number of mappers and reducers.</p>
    <p>First, we fix the number of reducers and use APRE to build a model from the number of mappers to the execution time. Then we use APRE to build a model that takes as input the number of reducers and estimates the elapsed time, keeping the number of mappers constant. Next, we use APRE to combine the two models and identify a best configuration candidate. We run a final experiment when we simultaneously change the number of mappers and reducers and we use APRE to perform multivariate linear regression and build the model from the two parameters</p>
    <p># mappers# reducers</p>
    <p>el a</p>
    <p>ps ed</p>
    <p>ti m</p>
    <p>e [s</p>
    <p>]</p>
    <p>Figure 7: Map-Reduce parameter exploration.</p>
    <p>to the elapsed time. We verify the difference between this model and the two separate ones and what is the best configuration (both in the experiments and according to the multivariate model).</p>
    <p>The range of variation of both the parameters  the number of mappers and reducers  is from 1 to 5, which is reasonable given the execution on a single node. Every experiment with a fixed number of workers is repeated keeping this number fixed in all the possible combinations. Therefore in the first experiment the number of reducers is fixed to 1 and the number of mappers varies in the whole range. In the second experiment the number of reducers is 2 and so on. The number of input lines to be processed is 10. For each experiment, the number of iterations is 10. When the number of reducers is in the set [1,2,3] the best value is reached when two mappers are activated. If the number of reducers is 4 or 5, the number of mappers that ensures the fastest execution is 1. Whichever is the number of mappers, the best configuration is always reached when only one reducer is spawned. The multivariate linear regression reports an error of 1.6165 [s] when building the model with both the number of mappers and reducers. Empirically, the best configuration is two mappers and one reducer. Figure 7 shows the average data over the experiment.</p>
    <p>Concluding, we wanted to show how APRE can be used when dealing with Map-Reduce parameters. In line with the current research trends, we also recorded the CPU consumption within the execution. Since the experiment is on the same benchmark, intuitively, the same usage pattern appears. One could use APRE to collect data and analyze the similarity of different CPU traces.</p>
    <p>In this paper we presented APRE, a tool for automating large experimental campaigns involving multiple parameters and to derive models from the obtained data. We developed the tool starting from our needs and we introduced different situations in which it proved useful.</p>
  </div>
  <div class="page">
    <p>Errors</p>
    <p>power &amp; time CPU &amp; time</p>
    <p>sunflow 16.10 [J] 287.90 [J]</p>
    <p>treadbeans 59.99 [J] 126.03 [J]</p>
    <p>lookbusy 20.62 [J] 19.48 [J]</p>
  </div>
  <div class="page">
    <p>Highlight</p>
    <p>Note that all the sensors used are already coded in the released version, for example the tool automatically measures and stores CPU consumption during the benchmark execution without human intervention</p>
  </div>
  <div class="page">
    <p>Conclusion We have developed a tool to build models based on the execution of applications on specific hardware</p>
    <p>The tool is given a parameter list and reasonable values or intervals and executes the application with different configuration producing equation based models</p>
  </div>
  <div class="page">
    <p>Future work</p>
    <p>Automatic controller generation, based on models</p>
    <p>Exploration of diagnostic features given the output of the tool - is self healing possible?</p>
    <p>Workload diversity checker</p>
  </div>
  <div class="page">
    <p>Questions? Thanks for the attention</p>
    <p>http://github.com/martinamaggio/arpe</p>
  </div>
</Presentation>
