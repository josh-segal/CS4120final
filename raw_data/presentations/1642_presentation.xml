<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Quiver: An informed storage cache for Deep Learning</p>
    <p>Abhishek Vijaya Kumar, Muthian Sivathanu</p>
    <p>Microsoft Research India</p>
  </div>
  <div class="page">
    <p>Deep Learning: Important systems workload</p>
    <p>Already powers many real-world applications  Voice assistants</p>
    <p>Web search</p>
    <p>Compute intensive  expensive hardware e.g. GPUs</p>
  </div>
  <div class="page">
    <p>Deep Learning: Important systems workload</p>
    <p>Already powers many real-world applications  Voice assistants</p>
    <p>Web search</p>
    <p>Compute intensive  expensive hardware e.g. GPUs</p>
    <p>Storage</p>
  </div>
  <div class="page">
    <p>Deep Learning: Important systems workload</p>
    <p>Already powers many real-world applications  Voice assistants</p>
    <p>Web search</p>
    <p>Compute intensive  expensive hardware e.g. GPUs</p>
    <p>Storage</p>
    <p>Same setting on Cloud</p>
  </div>
  <div class="page">
    <p>Deep Learning: Important systems workload</p>
    <p>Already powers many real-world applications  Voice assistants</p>
    <p>Web search</p>
    <p>Compute intensive  expensive hardware e.g. GPUs</p>
    <p>Storage</p>
    <p>Same setting on Cloud</p>
  </div>
  <div class="page">
    <p>Deep Learning: Important systems workload</p>
    <p>Already powers many real-world applications  Voice assistants</p>
    <p>Web search</p>
    <p>Compute intensive  expensive hardware e.g. GPUs</p>
    <p>Storage</p>
    <p>Same setting on Cloud</p>
  </div>
  <div class="page">
    <p>Example workload</p>
    <p>Resnet50 is a popular vision model</p>
    <p>Process 10,500 images/sec on 8 Nvidia V100s</p>
    <p>Goal: Keep GPUs busy and utilize them efficiently</p>
    <p>Remote store with several TBs of training data</p>
  </div>
  <div class="page">
    <p>Example workload</p>
    <p>Resnet50 is a popular vision model</p>
    <p>Process 10,500 images/sec on 8 Nvidia V100s</p>
    <p>Goal: Keep GPUs busy and utilize them efficiently</p>
    <p>Remote store with several TBs of training data</p>
    <p>JOB K</p>
    <p>.</p>
    <p>.</p>
    <p>.</p>
    <p>JOB 1</p>
    <p>Hyper-parameter tuning</p>
  </div>
  <div class="page">
    <p>Example workload</p>
    <p>Resnet50 is a popular vision model</p>
    <p>Process 10,500 images/sec on 8 Nvidia V100s</p>
    <p>Goal: Keep GPUs busy and utilize them efficiently</p>
    <p>Remote store with several TBs of training data</p>
    <p>JOB K</p>
    <p>.</p>
    <p>.</p>
    <p>.</p>
    <p>JOB 1</p>
    <p>Hyper-parameter tuning</p>
    <p>Load on Storage</p>
    <p>Load on Network</p>
  </div>
  <div class="page">
    <p>Example workload</p>
    <p>Resnet50 is a popular vision model</p>
    <p>Process 10,500 images/sec on 8 Nvidia V100s</p>
    <p>Goal: Keep GPUs busy and utilize them efficiently</p>
    <p>Remote store with several TBs of training data</p>
    <p>JOB K</p>
    <p>.</p>
    <p>.</p>
    <p>.</p>
    <p>JOB 1</p>
    <p>Cheap Preemptible VMs =&gt; Job Migration</p>
    <p>Large datasets</p>
    <p>Hyper-parameter tuning</p>
    <p>Load on Storage</p>
    <p>Load on Network</p>
  </div>
  <div class="page">
    <p>Quiver: Key ideas</p>
    <p>Domain specific intelligence at caching layer  Substitutability  Use existing contents of the cache to avoid thrashing</p>
    <p>Hash-based content addressing for security</p>
    <p>Co-designed with deep-learning framework (PyTorch)</p>
    <p>Dynamically manages cache allocation</p>
    <p>Improve cluster throughput up-to 2.3x</p>
  </div>
  <div class="page">
    <p>Structure</p>
    <p>Introduction &amp; Motivation</p>
    <p>Background</p>
    <p>Design</p>
    <p>Implementation</p>
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>Background: Deep Learning</p>
    <p>Learn a model to represent training data</p>
    <p>Iterate over random subsets of input data  Mini batch</p>
    <p>Perform Gradient Descent (SGD) on each mini-batch</p>
    <p>Process the entire dataset in random order  Epoch</p>
  </div>
  <div class="page">
    <p>A cache for DLT jobs</p>
    <p>DLT datasets are accessed multiple times  Within same job: Multiple epochs read the entire dataset</p>
    <p>Across jobs: Hyperparameter exploration, popular datasets (e.g. ImageNet)</p>
    <p>Good fit for caching</p>
  </div>
  <div class="page">
    <p>A cache for DLT jobs</p>
    <p>DLT datasets are accessed multiple times  Within same job: Multiple epochs read the entire dataset</p>
    <p>Across jobs: Hyperparameter exploration, popular datasets (e.g. ImageNet)</p>
    <p>Good fit for caching</p>
    <p>Challenges  Random access within epoch =&gt; Partial caching can cause thrashing (e.g. LRU)</p>
    <p>Job Heterogeneity =&gt; Not all jobs benefit the same from caching</p>
    <p>Secure inter-job data access</p>
  </div>
  <div class="page">
    <p>A cache for DLT jobs</p>
    <p>DLT datasets are accessed multiple times  Within same job: Multiple epochs read the entire dataset  Across jobs: Hyperparameter exploration, popular datasets (e.g. ImageNet)</p>
    <p>Good fit for caching</p>
    <p>Challenges  Random access within epoch =&gt; Partial caching can cause thrashing (e.g. LRU)  Job Heterogeneity =&gt; Not all jobs benefit the same from caching  Secure inter-job data access</p>
    <p>Quiver: Use domain intelligence to address these challenges</p>
  </div>
  <div class="page">
    <p>#1: Thrashing-proof partial caching</p>
    <p>Two I/O properties  Each input touched once in an epoch</p>
    <p>Every mini-batch needs to be randomly sampled</p>
    <p>Substitutable hits  I/O is substitutable</p>
    <p>Mini-batch samples order does not matter, as long as it is random</p>
  </div>
  <div class="page">
    <p>#1: Thrashing-proof partial caching</p>
    <p>Substitutability while sampling</p>
    <p>Looks up more than the number of indices and returns whatever is in the cache (substitutable hits)</p>
  </div>
  <div class="page">
    <p>#1: Thrashing-proof partial caching</p>
    <p>Substitutability while sampling</p>
    <p>Looks up more than the number of indices and returns whatever is in the cache (substitutable hits)</p>
    <p>Default Sampling (1 hit, 2 misses)</p>
  </div>
  <div class="page">
    <p>#1: Thrashing-proof partial caching</p>
    <p>Substitutability while sampling</p>
    <p>Looks up more than the number of indices and returns whatever is in the cache (substitutable hits)</p>
    <p>Quiver Sampling (3 hits, 6 misses)</p>
    <p>Default Sampling (1 hit, 2 misses)</p>
  </div>
  <div class="page">
    <p>#2: Job heterogeneity and caching</p>
    <p>Benefit-aware caching to handle Job heterogeneity  Time per mini-batch is an application-specific metric for performance</p>
    <p>Allows cheap profiling to measure benefits from cache</p>
    <p>Predictability  Measure time per minibatch with different caching modes</p>
    <p>Given total space budget, the manager allocates cache per dataset</p>
  </div>
  <div class="page">
    <p>#3: Secure Inter-Job Data access</p>
    <p>Multiple jobs and users share cache</p>
    <p>Data needs reuse/sharing while retaining isolation</p>
    <p>Each file is addressed by its hash instead of its name</p>
  </div>
  <div class="page">
    <p>#3: Secure Inter-Job Data access</p>
    <p>Multiple jobs and users share cache</p>
    <p>Data needs reuse/sharing while retaining isolation</p>
    <p>Each file is addressed by its hash instead of its name</p>
  </div>
  <div class="page">
    <p>#3: Secure Inter-Job Data access</p>
    <p>Multiple jobs and users share cache</p>
    <p>Data needs reuse/sharing while retaining isolation</p>
    <p>Each file is addressed by its hash instead of its name</p>
    <p>User1/imagenet/file.jpg</p>
    <p>User2/imgnt/file.jpg</p>
  </div>
  <div class="page">
    <p>#3: Secure Inter-Job Data access</p>
    <p>Multiple jobs and users share cache</p>
    <p>Data needs reuse/sharing while retaining isolation</p>
    <p>Each file is addressed by its hash instead of its name</p>
    <p>User1/imagenet/file.jpg</p>
    <p>User2/imgnt/file.jpg</p>
    <p>hash(file.jpg)</p>
    <p>hash(file.jpg)</p>
  </div>
  <div class="page">
    <p>Structure</p>
    <p>Introduction &amp; Motivation</p>
    <p>Background</p>
    <p>Design</p>
    <p>Implementation</p>
    <p>Evaluation</p>
  </div>
  <div class="page">
    <p>Architecture of Quiver</p>
    <p>Quiver cache server</p>
    <p>Quiver cache client codesigned with PyTorch</p>
    <p>Quiver cache manager</p>
    <p>Quiver instance types 1. Entire cluster</p>
    <p>PyTorch Quiver Client</p>
    <p>Quiver Server</p>
    <p>Hash Lookup /</p>
    <p>Insert</p>
    <p>Cache Miss</p>
    <p>Quiver Cache Manager</p>
    <p>Co-ordinated Eviction</p>
    <p>Mini-batch time probing for Benefit aware caching</p>
    <p>Set caching policy for datasets</p>
  </div>
  <div class="page">
    <p>Architecture of Quiver</p>
    <p>Quiver cache server</p>
    <p>Quiver cache client codesigned with PyTorch</p>
    <p>Quiver cache manager</p>
    <p>Quiver instance types 1. Entire cluster</p>
    <p>PyTorch Quiver Client</p>
    <p>Quiver Server</p>
    <p>Hash Lookup /</p>
    <p>Insert</p>
    <p>Cache Miss</p>
    <p>Quiver Cache Manager</p>
    <p>Co-ordinated Eviction</p>
    <p>Mini-batch time probing for Benefit aware caching</p>
    <p>Set caching policy for datasets</p>
    <p>PyTorch Quiver Client</p>
    <p>Quiver Server</p>
    <p>Hash Lookup /</p>
    <p>Insert</p>
    <p>PyTorch Quiver Client</p>
    <p>Quiver Server</p>
    <p>Hash Lookup /</p>
    <p>Insert</p>
  </div>
  <div class="page">
    <p>Architecture of Quiver</p>
    <p>Quiver cache server</p>
    <p>Quiver cache client codesigned with PyTorch</p>
    <p>Quiver cache manager</p>
    <p>Quiver instance types 1. Entire cluster</p>
    <p>PyTorch Quiver Client</p>
    <p>Quiver Server</p>
    <p>Hash Lookup /</p>
    <p>Insert</p>
    <p>Cache Miss</p>
    <p>Quiver Cache Manager</p>
    <p>Co-ordinated Eviction</p>
    <p>Mini-batch time probing for Benefit aware caching</p>
    <p>Set caching policy for datasets</p>
    <p>PyTorch Quiver Client</p>
    <p>Quiver Server</p>
    <p>Hash Lookup /</p>
    <p>Insert</p>
    <p>PyTorch Quiver Client</p>
    <p>Quiver Server</p>
    <p>Hash Lookup /</p>
    <p>Insert</p>
    <p>VM Boundary Container Boundary</p>
  </div>
  <div class="page">
    <p>Cache Access</p>
    <p>Client is integrated with PyTorch data-layer  Fetches files from remote on misses</p>
    <p>Populates the cache servers</p>
    <p>Works with hash-digest file</p>
    <p>Incorporates substitutable hits and co-operative miss handling</p>
  </div>
  <div class="page">
    <p>Hash digest and Partition</p>
    <p>Dataset is represented by a hash-digest</p>
    <p>Major components of an entry in the hash-file  &lt;content_hash: file_location&gt;</p>
    <p>Key space is partitioned across servers</p>
  </div>
  <div class="page">
    <p>Hash digest and Partition</p>
    <p>Dataset is represented by a hash-digest</p>
    <p>Major components of an entry in the hash-file  &lt;content_hash: file_location&gt;</p>
    <p>Key space is partitioned across servers</p>
    <p>Cache server 1 Cache server 2</p>
    <p>F1 F5F3F2 F4</p>
  </div>
  <div class="page">
    <p>Hash digest and Partition</p>
    <p>Dataset is represented by a hash-digest</p>
    <p>Major components of an entry in the hash-file  &lt;content_hash: file_location&gt;</p>
    <p>Key space is partitioned across servers</p>
    <p>Cache server 1 Cache server 2</p>
    <p>F1 F5F3F2 F4</p>
  </div>
  <div class="page">
    <p>Co-operative miss handling</p>
    <p>Misses are sharded across jobs using same dataset.  Sharding is implicit by randomizing indices</p>
    <p>Happens naturally in DLT access pattern</p>
    <p>Jobs benefit from other jobs as they progress</p>
  </div>
  <div class="page">
    <p>Co-operative miss handling</p>
    <p>Misses are sharded across jobs using same dataset.  Sharding is implicit by randomizing indices</p>
    <p>Happens naturally in DLT access pattern</p>
    <p>Jobs benefit from other jobs as they progress</p>
  </div>
  <div class="page">
    <p>Co-operative miss handling</p>
    <p>Misses are sharded across jobs using same dataset.  Sharding is implicit by randomizing indices</p>
    <p>Happens naturally in DLT access pattern</p>
    <p>Jobs benefit from other jobs as they progress</p>
  </div>
  <div class="page">
    <p>Co-operative miss handling</p>
    <p>Misses are sharded across jobs using same dataset.  Sharding is implicit by randomizing indices</p>
    <p>Happens naturally in DLT access pattern</p>
    <p>Jobs benefit from other jobs as they progress</p>
  </div>
  <div class="page">
    <p>Co-ordinated eviction</p>
    <p>Dataset partition  Digest file is partitioned into</p>
    <p>given number of chunks</p>
    <p>Double buffering of chunks  Chunks allow coordinated</p>
    <p>access of cache</p>
    <p>Co-ordinated eviction  Mark for eviction  no new refs</p>
    <p>Then evict</p>
    <p>Similar to UNIX unlink call</p>
    <p>Double buffer of a Cache server</p>
    <p>J1 J2</p>
  </div>
  <div class="page">
    <p>Co-ordinated eviction</p>
    <p>Dataset partition  Digest file is partitioned into</p>
    <p>given number of chunks</p>
    <p>Double buffering of chunks  Chunks allow coordinated</p>
    <p>access of cache</p>
    <p>Co-ordinated eviction  Mark for eviction  no new refs</p>
    <p>Then evict</p>
    <p>Similar to UNIX unlink call</p>
    <p>C1 Double buffer of a Cache server</p>
    <p>J1 J2</p>
  </div>
  <div class="page">
    <p>Co-ordinated eviction</p>
    <p>Dataset partition  Digest file is partitioned into</p>
    <p>given number of chunks</p>
    <p>Double buffering of chunks  Chunks allow coordinated</p>
    <p>access of cache</p>
    <p>Co-ordinated eviction  Mark for eviction  no new refs</p>
    <p>Then evict</p>
    <p>Similar to UNIX unlink call</p>
    <p>C1 Double buffer of a Cache server</p>
    <p>J1 J2</p>
  </div>
  <div class="page">
    <p>Co-ordinated eviction</p>
    <p>Dataset partition  Digest file is partitioned into</p>
    <p>given number of chunks</p>
    <p>Double buffering of chunks  Chunks allow coordinated</p>
    <p>access of cache</p>
    <p>Co-ordinated eviction  Mark for eviction  no new refs</p>
    <p>Then evict</p>
    <p>Similar to UNIX unlink call</p>
    <p>C2 C1 Double buffer of a Cache server</p>
    <p>J1 J2</p>
  </div>
  <div class="page">
    <p>Co-ordinated eviction</p>
    <p>Dataset partition  Digest file is partitioned into</p>
    <p>given number of chunks</p>
    <p>Double buffering of chunks  Chunks allow coordinated</p>
    <p>access of cache</p>
    <p>Co-ordinated eviction  Mark for eviction  no new refs</p>
    <p>Then evict</p>
    <p>Similar to UNIX unlink call</p>
    <p>C2 C1 Double buffer of a Cache server</p>
    <p>J1 J2 J3</p>
  </div>
  <div class="page">
    <p>Co-ordinated eviction</p>
    <p>Dataset partition  Digest file is partitioned into</p>
    <p>given number of chunks</p>
    <p>Double buffering of chunks  Chunks allow coordinated</p>
    <p>access of cache</p>
    <p>Co-ordinated eviction  Mark for eviction  no new refs</p>
    <p>Then evict</p>
    <p>Similar to UNIX unlink call</p>
    <p>C2C3 Double buffer of a Cache server</p>
    <p>J1 J2 J3</p>
  </div>
  <div class="page">
    <p>Structure</p>
    <p>Introduction &amp; Motivation</p>
    <p>Design</p>
    <p>Implementation &amp; Evaluation</p>
  </div>
  <div class="page">
    <p>Implementation</p>
    <p>Cache client (900 LoC)  Dataloader of PyTorch (v 1.1.0)</p>
    <p>Dataset of PyTorch</p>
    <p>Sampler of PyTorch</p>
    <p>Cache server (1200 LOC)  A C++ key value store</p>
    <p>Cache manager  A python program</p>
  </div>
  <div class="page">
    <p>Evaluation Setup</p>
    <p>Cluster (48 GPUs)  6 VMs with 4 NVIDIA P100 GPUs</p>
    <p>6 VMs with 4 NVIDIA P40 GPUs</p>
    <p>Workloads  Resnet50 on Imagenet dataset (154 GB)</p>
    <p>Inception_V3 on openimages dataset (531 GB)</p>
    <p>DeepSpeech2 on LibriSpeech dataset (90 GB)</p>
  </div>
  <div class="page">
    <p>Impact on accuracy</p>
    <p>RESNET50 on Imagenet</p>
    <p>Config Word Error Rate (WER)</p>
    <p>Baseline Sampling 22.29</p>
    <p>Quiver Sampling 22.32</p>
    <p>DeepSpeech2 on LibriSpeech</p>
    <p>Similar curves</p>
  </div>
  <div class="page">
    <p>Throughput increase because of quvier</p>
    <p>Resnet50</p>
    <p>Time for 7000 mini-batches (s)Workload</p>
    <p>Resnet50 2505 646 (3.88x) 1064 (2.35x) Baseline HIT CO-OP</p>
  </div>
  <div class="page">
    <p>Throughput increase because of quvier</p>
    <p>Resnet50 InceptionV3 DeepSpeech2</p>
    <p>Baseline Quiver (HIT) Quiver (CO-OP) Resnet50 2505 646 (3.88x) 1064 (2.35x) Inception 2874 1274 (2.26x) 1817 (1.58x)</p>
    <p>DeepSpeech 1614 1234 (1.31x) 1265 (1.28x)</p>
    <p>Time for 7000 mini-batches (s)Workload</p>
    <p>Resnet50 2505 646 (3.88x) 1064 (2.35x) Baseline HIT CO-OP</p>
  </div>
  <div class="page">
    <p>Co-ordinated eviction in action (s</p>
    <p>e c)</p>
  </div>
  <div class="page">
    <p>Co-ordinated eviction in action</p>
    <p>2 Chunks cached at a time</p>
    <p>New jobs start using 3rd chunk</p>
    <p>(s e</p>
    <p>c)</p>
  </div>
  <div class="page">
    <p>Co-ordinated eviction in action</p>
    <p>2 Chunks cached at a time</p>
    <p>New jobs start using 3rd chunk</p>
    <p>(s e</p>
    <p>c)</p>
  </div>
  <div class="page">
    <p>Benefit aware caching</p>
  </div>
  <div class="page">
    <p>Benefit aware caching</p>
    <p>Mixed workload  12 Different jobs  Quiver preferentially allocates cache to different datasets  Quiver yields sizeable benefits even with tiny cache (100G)  Improvement in cluster throughput ranges between 1.6x to 2.3x</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>Quiver is a domain-specific storage cache for DLT jobs</p>
    <p>Utilizes I/O behavior of deep learning training jobs  Substitutable hits =&gt; New thrash-proof partial caching</p>
    <p>Predictability =&gt; Benefit-aware caching</p>
    <p>Improves cluster GPU utilization by reducing I/O wait time</p>
    <p>Implemented in PyTorch</p>
  </div>
</Presentation>
