<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Its Time for Low Latency</p>
    <p>Steve Rumble, Diego Ongaro, Ryan Stutsman, Mendel Rosenblum, John Ousterhout</p>
    <p>Stanford University</p>
  </div>
  <div class="page">
    <p>Future Web Applications Need Low Latency</p>
    <p>They will access more bytes of data  Bandwidth problem  Commodity net bandwidth has increased &gt; 3,000x in 30 years</p>
    <p>But also more pieces of inter-dependent data  Latency problem  Commodity net latency has decreased only ~30x in 30 years</p>
    <p>Facebook is a glimpse into future applications  Huge datasets, DRAM-based storage, small requests,</p>
    <p>random dependent data accesses, low locality</p>
    <p>Dependent on network latency: Can only afford 100-150 dependent accesses per page request</p>
  </div>
  <div class="page">
    <p>Datacenter Latency Is Too High</p>
    <p>Simple RPCs take 300-500us in current datacenters</p>
    <p>Component Delay Round-Trip</p>
    <p>Switch 10-30us/hop 100-300us</p>
    <p>NIC 2.5-32us 10-128us</p>
    <p>OS Net Stack 15us 60us</p>
    <p>Server Code 1us 1us</p>
    <p>Speed of Light 5ns/m &lt; 2us</p>
    <p>Not limited by server execution or propagation delay!</p>
    <p>App</p>
    <p>Kernel</p>
    <p>NIC</p>
    <p>Server</p>
    <p>Kernel</p>
    <p>NIC Kernel: 15us</p>
    <p>Switches: 100+ us Switches: 100+ us</p>
    <p>NIC: 2.5-32us</p>
    <p>Server: 1us</p>
    <p>NIC: 2.5-32us</p>
    <p>Kernel: 15us</p>
  </div>
  <div class="page">
    <p>On The Cusp Of Low Latency  Low latency available in the HPC space (Infiniband)  100ns switches  &lt; 1us NIC latencies  OS Bypass (U-Net style)  But, wont displace Ethernet</p>
    <p>Some migration into commodity Ethernet space  Fulcrum Microsystems, Mellanox: Sub-500ns switches  RDMA on commodity NICs (e.g. iWarp)</p>
    <p>Now we need to pull in the rest of the ideas  Lets get the OS community involved and do it right  Goal: 5-10us RTTs in the short term</p>
  </div>
  <div class="page">
    <p>An Opportunity To Define The Right Structure</p>
    <p>Re-think APIs: Apps need speed and simplicity  Infiniband verbs too complex, RDMA too low-level  Developers used to sockets, but can we make them fast?</p>
    <p>Network Protocols  Can we live with TCP? (Needs in-order delivery, Slow stacks)  How do we scale low-latency to 100,000+ nodes?  Closed datacenter ecosystem makes new protocols feasible</p>
    <p>OS</p>
    <p>App NIC</p>
    <p>OS</p>
    <p>App NIC</p>
    <p>Net Stack</p>
    <p>Net Stack</p>
    <p>OS</p>
    <p>App NIC Net Stack</p>
    <p>Ethernet Infiniband U-Net</p>
  </div>
  <div class="page">
    <p>Getting The Lowest Possible Latency</p>
    <p>Today: 5-10 Years:</p>
    <p>CPU MEM NIC</p>
    <p>C ac</p>
    <p>he</p>
    <p>PCIe accesses &amp; memory accesses too slow Transmit/Receive directly from/to cache</p>
    <p>The NIC will become the bottleneck under 10us</p>
    <p>500ns round-trip propagation in 50m diameter  1us round-trip switching latency (10 x 100ns hops)  Even fast NICs take nearly 2us on each end!</p>
    <p>One microsecond RTTs possible in 5-10 years</p>
    <p>CPU</p>
    <p>C ac</p>
    <p>he</p>
    <p>MEMNIC PCIe</p>
  </div>
  <div class="page">
    <p>Low Latency Is Up To Us</p>
    <p>Low latency is the future of web applications  If we dont take action to make it happen, we risk:  Not getting it at all, or  Missing the opportunity to re-architect</p>
    <p>(and getting something that sucks)</p>
  </div>
</Presentation>
