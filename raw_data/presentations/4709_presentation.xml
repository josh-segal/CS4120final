<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Algorithm Portfolios through Empirical Hardness Models</p>
    <p>Case Studies on Combinatorial Auction Winner Determination and Satisfiability</p>
    <p>Kevin Leyton-Brown</p>
    <p>University of British Columbia</p>
    <p>Eugene Nudelman</p>
    <p>James McFadden</p>
    <p>Galen Andrew</p>
    <p>Yoav Shoham</p>
    <p>Stanford University</p>
    <p>Wed like to acknowledge assistance from Ryan Porter, Carla Gomes and Bart Selman, and support from the Cornell Intelligent Information Systems Institute, a Stanford Graduate Fellowship and DARPA (F30602-00-2-0598).</p>
  </div>
  <div class="page">
    <p>The Algorithm Selection Problem</p>
    <p>What is the best algorithm for a given problem?  worst-/average-case measure doesnt tell the whole story  ideally, select algorithm on a per-instance basis [Rice]</p>
    <p>Our approach:  Identify:</p>
    <p>a target distribution of problem instances, D  a set of algorithms, where each algorithm has a significant probability</p>
    <p>of outperforming the others on instances drawn from D</p>
    <p>polytime-computable features of problem instances  Learn per-algorithm empirical hardness models  Use the models to construct an algorithm portfolio by choosing the</p>
    <p>algorithm with the best predicted runtime</p>
  </div>
  <div class="page">
    <p>Combinatorial Auction Winner Determination</p>
    <p>Equivalent to weighted set packing  Input: n goods, m bids  Objective: find revenue-maximizing non-conflicting</p>
    <p>allocation</p>
  </div>
  <div class="page">
    <p>WDP: Runtime Variation</p>
    <p>Complete algorithms:  CPLEX [ILOG Inc.]  CASS [Leyton-Brown et.al],  GL [Gonen and Lehman]</p>
    <p>Gathered runtime data using various distributions</p>
    <p>randomly sampled generators parameters for each instance</p>
    <p>Even holding problem size constant, runtimes vary by many orders of magnitude across and within distributions</p>
    <p>-1 0 1</p>
    <p>Paths</p>
    <p>Sche duling</p>
    <p>L6 L2</p>
    <p>R egions</p>
    <p>L4 Arbitrary</p>
    <p>L7 L3</p>
    <p>CPLEX</p>
    <p>Running</p>
    <p>Time</p>
    <p>log10(s e c)</p>
    <p>Dis tribution</p>
    <p>in e ach</p>
  </div>
  <div class="page">
    <p>WDP: Features</p>
    <p>Bid</p>
    <p>Bid</p>
    <p>Bid</p>
    <p>Bid</p>
    <p>Good</p>
    <p>Good</p>
    <p>Good</p>
    <p>Bid</p>
    <p>Bid Bid</p>
    <p>BidBid</p>
  </div>
  <div class="page">
    <p>WDP: Empirical Hardness Models</p>
    <p>Quadratic regression can be used to learn very accurate models  predicting log10 of CPLEX runtime</p>
    <p>Root mean squared error: 0.216 (test data)</p>
    <p>-2</p>
    <p>-1</p>
    <p>-2 -1 0 1 2 3 4 5</p>
    <p>log(Actual Runtime)</p>
    <p>P re</p>
    <p>d ic</p>
    <p>te d l o g (R</p>
    <p>u n ti m</p>
    <p>e )</p>
  </div>
  <div class="page">
    <p>WDP: From Models to a Portfolio</p>
    <p>CPLEX Portfolio Optimal</p>
    <p>GL CASS CPLEX</p>
    <p>T im</p>
    <p>e (s</p>
    <p>)</p>
    <p>CA SS GL CPLEX</p>
    <p>Optimal Algorithm Selection Portfolio Algorithm Selection</p>
  </div>
  <div class="page">
    <p>SATZilla: A Portfolio for SAT</p>
    <p>Algorithms in the portfolio:  2clseq [Bacchus] Limmat [Biere]  OKsolver [Kullmann] relsat [Bayardo]  Satz-Rand [Kautz, Li] SATO [Zhang]  zChaff [Zhang] Jerusat [Nadel]</p>
    <p>Satzilla2 (Hors-Concours) added:  eqsatz [Li] HeerHugo [Groote]  AutoWalkSat [Patterson, Kautz] (preprocessing)</p>
    <p>Developed in just over two weeks!</p>
  </div>
  <div class="page">
    <p>SATzilla: Features</p>
    <p>Var</p>
    <p>Var</p>
    <p>Var</p>
    <p>Clause</p>
    <p>Clause</p>
    <p>rest of features are normalized by these</p>
    <p>variables occur in the same clause)</p>
    <p>Clause (CG, edge whenever two clauses share a variable with opposite sign)</p>
    <p>compute stats=(max, min, stdev, mean, entropy) over node degrees</p>
    <p>for VCG, both for vars and clauses</p>
    <p># of unary, binary, ternary clauses</p>
    <p>stats of the CG clustering coefficients</p>
    <p>Var</p>
    <p>Var Var</p>
    <p>VarVar</p>
    <p>Clause Clause</p>
    <p>Clause Clause</p>
  </div>
  <div class="page">
    <p>SATzilla: Features</p>
    <p>#unit props after reaching depths 1, 4, 16, 64, 256</p>
    <p>Local search probing (100 probes, each probe runs to plateau/max)  stats of climb height (in #clauses)  stats of #steps taken  stats of fraction of satisfied clauses  stats of break counts/#vars</p>
    <p>Search space size probing (5000 random search paths with unit-prop)  average depth to contradiction, estimate log-num-nodes in search tree</p>
    <p>k1</p>
  </div>
  <div class="page">
    <p>Slide 10</p>
    <p>k1 # pos/# neg: should be abs(0.5 - #pos / (#pos + #neg)) so that flipping all pos and neg doesn't change the stat kevinlb, 1/1/2004</p>
  </div>
  <div class="page">
    <p>SATzilla: Models and Portfolio</p>
    <p>Learned linear regression models for each algorithm  trained on more than 20000 instances</p>
    <p>included 2002 competition instances  highly skewed towards random instances</p>
    <p>training set preprocessed to exclude instances that were solved by all solvers, or by none of them</p>
    <p>terrible RMSE on test set  enough predictive power to discriminate well</p>
    <p>On the training set, SATzillas choice takes on average 92 seconds longer to run than the optimal choice  gives SATzilla an edge over its subsolvers, especially on harder</p>
    <p>instances</p>
  </div>
  <div class="page">
    <p>SATzilla: SAT-2003 Competition</p>
    <p>2nd in Random instances track  3rd in Handmade track; 2nd in Handmade track, SAT only</p>
    <p>Only solver with good performance in more than one track  Success measured in #series solved, not #benchmarks solved</p>
    <p>Satzilla 2 solved more random instances than kcnfs</p>
  </div>
  <div class="page">
    <p>SATzilla: Areas for Improvement</p>
    <p>Add new algorithms to the portfolio  SATzilla outperformed all its constituent algorithms</p>
    <p>Construct better models  as we continue to study and analyze SAT data, our</p>
    <p>model accuracy is increasing</p>
    <p>Spend more development time to eliminate bugs  LP features timed out on many industrial benchmarks</p>
    <p>instead of using a fallback solver (zChaff), SATzilla picked one essentially at random, but most dont do well on industrial</p>
    <p>some random instances were solved but didnt count!  Relsat was chosen, and actually solved them, but it had an</p>
    <p>output bug</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>WDP  models: very mature, high accuracy  algorithms: one is dominant, limiting the size of</p>
    <p>possible gains from a portfolio approach</p>
    <p>SAT  models: more of a proof of concept, much room for</p>
    <p>improvement. However, discrimination accuracy is much better than prediction accuracy.</p>
    <p>algorithms: many are strong and correlation is fairly low, making this an excellent domain for future study</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Overall, our techniques provide a quick and relatively automatic blueprint for building algorithm portfolios, suitable when there are:  two or more algorithms with relatively uncorrelated runtimes  a set of good features  lots of data</p>
  </div>
</Presentation>
