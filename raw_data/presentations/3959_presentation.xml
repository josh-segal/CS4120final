<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>FAWNdamentally Power-efficient Clusters</p>
    <p>Vijay Vasudevan, Jason Franklin, David Andersen, Amar Phanishayee, Lawrence Tan, Michael Kaminsky*, Iulian Moraru</p>
    <p>Carnegie Mellon University, *Intel Research Pittsburgh</p>
  </div>
  <div class="page">
    <p>Monthly energy statement considered harmful</p>
    <p>Power is a limiting factor in computing  3-year TCO soon to be dominated by</p>
    <p>power cost [EPA 2007]</p>
    <p>Influences location, technology choices</p>
  </div>
  <div class="page">
    <p>Approaches to saving power</p>
    <p>Infrastructure Efficiency</p>
    <p>Dynamic Power Scaling</p>
    <p>Computational Efficiency</p>
    <p>Power generation Power distribution</p>
    <p>Cooling</p>
    <p>Sleeping when idle Rate adaptation</p>
    <p>VM consolidation</p>
    <p>FAWN</p>
  </div>
  <div class="page">
    <p>Approaches to saving power</p>
    <p>Infrastructure Efficiency</p>
    <p>Dynamic Power Scaling</p>
    <p>Computational Efficiency</p>
    <p>Power generation Power distribution</p>
    <p>Cooling</p>
    <p>Sleeping when idle Rate adaptation</p>
    <p>VM consolidation</p>
    <p>FAWN</p>
    <p>Goal of computational efficiency: Reduce the amount of energy to do useful work</p>
  </div>
  <div class="page">
    <p>FAWN Fast Array of Wimpy Nodes</p>
    <p>Improve computational efficiency of data-intensive computing using an array of well-balanced low-power systems.</p>
    <p>Understanding Data-Intensive Workloads on FAWN</p>
    <p>Iulian Moraru, Lawrence Tan, Vijay Vasudevan 15-849 Low Power Project</p>
    <p>Abstract</p>
    <p>In this paper, we explore the use of the Fast Array of Wimpy Nodes (FAWN) architecture for a wide class of data-intensive workloads. While the benefits of FAWN are highest for I/O-bound workloads where the CPU cycles of traditional machines are often wasted, we find that CPU-bound workloads run on FAWN can be up to six times more efficient in work done per Joule of energy than traditional machines.</p>
    <p>Power has become a dominating factor in the cost of provisioning and operation of large datacenters. This work focuses on one promising approach to reduce both average and peak power using a Fast Array of Wimpy Node (FAWN) architecture [2], which proposes using a large cluster of low-power nodes instead of a cluster of traditional, high power nodes. FAWN (Figure 1) was originally designed to target mostly I/O-bound workloads, where the additional processing capabilities of high-speed processors were often wasted. While the FAWN architecture has been shown to be significantly more energy efficient than traditional architectures for seek-bound workloads [16], an open question is whether this architecture is well-suited for other data-intensive workloads common in cluster-based computing.</p>
    <p>Recent work has shown that the FAWN architecture benefits from fundamental trends in computing and powerrunning at a lower speed saves energy, while the low-power processors used in FAWN are significantly more efficient in work done per joule [16]. Combined with the inherent parallelism afforded by popular computing frameworks</p>
    <p>!&quot;#$</p>
    <p>%&amp;'</p>
    <p>()*</p>
    <p>()* %&amp;' +,-#.</p>
    <p>()* %&amp;' +,-#.</p>
    <p>()* %&amp;' +,-#.</p>
    <p>()* %&amp;' +,-#.</p>
    <p>()*</p>
    <p>()* ()* ()* %&amp;' +,-#.</p>
    <p>()* %&amp;' +,-#.</p>
    <p>()* %&amp;' +,-#.</p>
    <p>()* %&amp;' +,-#.</p>
    <p>/001 201</p>
    <p>Figure 1: FAWN architecture</p>
    <p>such as Hadoop [1] and Dryad [9], a FAWN systems improvement in both CPU-I/O balance and instruction efficiency allows for an increase in overall energy efficiency for a much larger class of datacenter workloads.</p>
    <p>In this work, we present a taxonomy and analysis of some primitive data-intensive workloads and operations to understand when FAWN can perform as well as a traditional cluster architecture and reduce energy consumption for data centers.</p>
    <p>To understand where FAWN improves energy efficiency for data-intensive computing, we investigate a wide-range of benchmarks common in frameworks such as Hadoop [1], finding that FAWN is between three to ten times more efficient than a traditional machine in performing operations such as distributed grep and sort. For more CPUbound operations, such as encryption and compression, FAWN architectures are still between three to six times more energy efficient. We believe these two categories of workloadsCPU-bound and I/Oboundencompass a large enough range of com</p>
  </div>
  <div class="page">
    <p>FAWN Fast Array of Wimpy Nodes</p>
    <p>Improve computational efficiency of data-intensive computing using an array of well-balanced low-power systems.</p>
    <p>Understanding Data-Intensive Workloads on FAWN</p>
    <p>Iulian Moraru, Lawrence Tan, Vijay Vasudevan 15-849 Low Power Project</p>
    <p>Abstract</p>
    <p>In this paper, we explore the use of the Fast Array of Wimpy Nodes (FAWN) architecture for a wide class of data-intensive workloads. While the benefits of FAWN are highest for I/O-bound workloads where the CPU cycles of traditional machines are often wasted, we find that CPU-bound workloads run on FAWN can be up to six times more efficient in work done per Joule of energy than traditional machines.</p>
    <p>Power has become a dominating factor in the cost of provisioning and operation of large datacenters. This work focuses on one promising approach to reduce both average and peak power using a Fast Array of Wimpy Node (FAWN) architecture [2], which proposes using a large cluster of low-power nodes instead of a cluster of traditional, high power nodes. FAWN (Figure 1) was originally designed to target mostly I/O-bound workloads, where the additional processing capabilities of high-speed processors were often wasted. While the FAWN architecture has been shown to be significantly more energy efficient than traditional architectures for seek-bound workloads [16], an open question is whether this architecture is well-suited for other data-intensive workloads common in cluster-based computing.</p>
    <p>Recent work has shown that the FAWN architecture benefits from fundamental trends in computing and powerrunning at a lower speed saves energy, while the low-power processors used in FAWN are significantly more efficient in work done per joule [16]. Combined with the inherent parallelism afforded by popular computing frameworks</p>
    <p>!&quot;#$</p>
    <p>%&amp;'</p>
    <p>()*</p>
    <p>()* %&amp;' +,-#.</p>
    <p>()* %&amp;' +,-#.</p>
    <p>()* %&amp;' +,-#.</p>
    <p>()* %&amp;' +,-#.</p>
    <p>()*</p>
    <p>()* ()* ()* %&amp;' +,-#.</p>
    <p>()* %&amp;' +,-#.</p>
    <p>()* %&amp;' +,-#.</p>
    <p>()* %&amp;' +,-#.</p>
    <p>/001 201</p>
    <p>Figure 1: FAWN architecture</p>
    <p>such as Hadoop [1] and Dryad [9], a FAWN systems improvement in both CPU-I/O balance and instruction efficiency allows for an increase in overall energy efficiency for a much larger class of datacenter workloads.</p>
    <p>In this work, we present a taxonomy and analysis of some primitive data-intensive workloads and operations to understand when FAWN can perform as well as a traditional cluster architecture and reduce energy consumption for data centers.</p>
    <p>To understand where FAWN improves energy efficiency for data-intensive computing, we investigate a wide-range of benchmarks common in frameworks such as Hadoop [1], finding that FAWN is between three to ten times more efficient than a traditional machine in performing operations such as distributed grep and sort. For more CPUbound operations, such as encryption and compression, FAWN architectures are still between three to six times more energy efficient. We believe these two categories of workloadsCPU-bound and I/Oboundencompass a large enough range of com</p>
    <p>AMD Geode 256MB DRAM</p>
  </div>
  <div class="page">
    <p>Target: Data-intensive computing</p>
    <p>Large amounts of data  Highly-parallelizable  Fine-grained, independent tasks</p>
    <p>Workloads amenable to scale-out approach</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>What is FAWN?  Why FAWN?  When FAWN?  Challenges (How FAWN?)</p>
  </div>
  <div class="page">
    <p>Why FAWN?</p>
  </div>
  <div class="page">
    <p>Figure adapted from Tolia et. al HotPower 08</p>
    <p>Po w</p>
    <p>er (W</p>
    <p>)</p>
    <p>System Utilization(%)</p>
    <p>No DVFS DVFS</p>
    <p>Ideal</p>
    <p>Power (W)</p>
  </div>
  <div class="page">
    <p>Figure adapted from Tolia et. al HotPower 08</p>
    <p>Po w</p>
    <p>er (W</p>
    <p>)</p>
    <p>System Utilization(%)</p>
    <p>No DVFS DVFS</p>
    <p>Ideal</p>
    <p>Power (W)</p>
  </div>
  <div class="page">
    <p>Figure adapted from Tolia et. al HotPower 08</p>
    <p>Po w</p>
    <p>er (W</p>
    <p>)</p>
    <p>System Utilization(%)</p>
    <p>No DVFS DVFS</p>
    <p>}Fixed power costs Ideal</p>
    <p>Power (W)</p>
  </div>
  <div class="page">
    <p>How do we balance?  Big CPUs clocked</p>
    <p>down?</p>
    <p>Embedded CPUs?  Why not use</p>
    <p>more disks with big CPUs?</p>
    <p>CPU/Disk Gap</p>
    <p>Year</p>
    <p>CPU-to-Disk seek Speed Ratio</p>
  </div>
  <div class="page">
    <p>In s tr</p>
    <p>u c ti o n</p>
    <p>s /s</p>
    <p>e c /W</p>
    <p>i n</p>
    <p>m il li o n s</p>
    <p>Instructions/sec in millions</p>
    <p>Custom ARM Mote</p>
    <p>XScale 800Mhz</p>
    <p>Xeon7350</p>
    <p>Atom Z500</p>
    <p>Speed vs. Efficiency</p>
  </div>
  <div class="page">
    <p>In s tr</p>
    <p>u c ti o n</p>
    <p>s /s</p>
    <p>e c /W</p>
    <p>i n</p>
    <p>m il li o n s</p>
    <p>Instructions/sec in millions</p>
    <p>Custom ARM Mote</p>
    <p>XScale 800Mhz</p>
    <p>Xeon7350</p>
    <p>Atom Z500</p>
    <p>Speed vs. Efficiency</p>
    <p>mask memory wall at the cost of efficiency</p>
  </div>
  <div class="page">
    <p>In s tr</p>
    <p>u c ti o n</p>
    <p>s /s</p>
    <p>e c /W</p>
    <p>i n</p>
    <p>m il li o n s</p>
    <p>Instructions/sec in millions</p>
    <p>Custom ARM Mote</p>
    <p>XScale 800Mhz</p>
    <p>Xeon7350</p>
    <p>Atom Z500</p>
    <p>Speed vs. Efficiency</p>
    <p>mask memory wall at the cost of efficiency</p>
  </div>
  <div class="page">
    <p>Speed vs. Efficiency</p>
    <p>In st</p>
    <p>ru ct</p>
    <p>io ns</p>
    <p>/s ec</p>
    <p>/W in</p>
    <p>m ill</p>
    <p>io ns</p>
    <p>Instructions/sec in millions</p>
    <p>Custom ARM Mote</p>
    <p>XScale 800Mhz</p>
    <p>Xeon7350</p>
    <p>Atom Z500</p>
    <p>Fast processors mask memory wall</p>
    <p>at the cost of efficiency</p>
  </div>
  <div class="page">
    <p>Speed vs. Efficiency</p>
    <p>In st</p>
    <p>ru ct</p>
    <p>io ns</p>
    <p>/s ec</p>
    <p>/W in</p>
    <p>m ill</p>
    <p>io ns</p>
    <p>Instructions/sec in millions</p>
    <p>Custom ARM Mote</p>
    <p>XScale 800Mhz</p>
    <p>Xeon7350</p>
    <p>Atom Z500</p>
    <p>Fast processors mask memory wall</p>
    <p>at the cost of efficiency</p>
  </div>
  <div class="page">
    <p>Speed vs. Efficiency</p>
    <p>In st</p>
    <p>ru ct</p>
    <p>io ns</p>
    <p>/s ec</p>
    <p>/W in</p>
    <p>m ill</p>
    <p>io ns</p>
    <p>Instructions/sec in millions</p>
    <p>Custom ARM Mote</p>
    <p>XScale 800Mhz</p>
    <p>Xeon7350</p>
    <p>Atom Z500</p>
    <p>Fast processors mask memory wall</p>
    <p>at the cost of efficiency</p>
    <p>Fixed power costs can dominate efficiency for slow processors</p>
  </div>
  <div class="page">
    <p>Speed vs. Efficiency</p>
    <p>In st</p>
    <p>ru ct</p>
    <p>io ns</p>
    <p>/s ec</p>
    <p>/W in</p>
    <p>m ill</p>
    <p>io ns</p>
    <p>Instructions/sec in millions</p>
    <p>Custom ARM Mote</p>
    <p>XScale 800Mhz</p>
    <p>Xeon7350</p>
    <p>Atom Z500</p>
    <p>Fast processors mask memory wall</p>
    <p>at the cost of efficiency</p>
    <p>Fixed power costs can dominate efficiency for slow processors</p>
    <p>FAWN targets sweet spot in processor efficiency when</p>
    <p>including fixed costs</p>
  </div>
  <div class="page">
    <p>Provisioning for peak power requires: 1. worst case cooling requirements</p>
    <p>investment</p>
  </div>
  <div class="page">
    <p>Provisioning for peak power requires: 1. worst case cooling requirements</p>
    <p>investment</p>
  </div>
  <div class="page">
    <p>Provisioning for peak power requires: 1. worst case cooling requirements</p>
    <p>investment</p>
  </div>
  <div class="page">
    <p>Provisioning for peak power requires: 1. worst case cooling requirements</p>
    <p>investment</p>
  </div>
  <div class="page">
    <p>What is FAWN good for?</p>
    <p>Random-access workloads (Key-value Lookup)  Scan-bound workloads (Hadoop, Data Analytics)  CPU-bound workloads (Compression, Encryption)</p>
  </div>
  <div class="page">
    <p>Performance Efficiency Density Cost</p>
    <p>Important metrics</p>
    <p>Work time</p>
    <p>Perf Watt</p>
    <p>Perf $</p>
    <p>Perf Volume</p>
  </div>
  <div class="page">
    <p>FAWN + CF (4W)</p>
    <p>Traditional + HD (87W)</p>
    <p>Traditional + SSD (83W)</p>
    <p>Random access workloads</p>
  </div>
  <div class="page">
    <p>Random access workloads</p>
  </div>
  <div class="page">
    <p>Random access workloads</p>
    <p>Queries/sec</p>
    <p>FAWN (4W) Traditional + HD (87W) Traditional + SSD (83W)</p>
    <p>Performance</p>
  </div>
  <div class="page">
    <p>Random access workloads</p>
    <p>Queries/sec</p>
    <p>FAWN (4W) Traditional + HD (87W) Traditional + SSD (83W)</p>
    <p>Queries/Joule</p>
    <p>Performance Efficiency</p>
  </div>
  <div class="page">
    <p>Random access workloads</p>
    <p>Queries/sec</p>
    <p>FAWN (4W) Traditional + HD (87W) Traditional + SSD (83W)</p>
    <p>Queries/Joule</p>
    <p>Performance Efficiency</p>
    <p>FAWN is 6-200x more efficient than traditional systems</p>
  </div>
  <div class="page">
    <p>CPU-bound encryption</p>
    <p>Encryption Speed (MB/s)</p>
    <p>FAWN (5W) Traditional + HD (87W)</p>
    <p>AES encryption/decryption of a 512MB file with a 256-bit key</p>
    <p>Performance</p>
  </div>
  <div class="page">
    <p>CPU-bound encryption</p>
    <p>Encryption Speed (MB/s)</p>
    <p>FAWN (5W) Traditional + HD (87W)</p>
    <p>Encryption Efficiency (MB/J)</p>
    <p>AES encryption/decryption of a 512MB file with a 256-bit key</p>
    <p>Performance Efficiency</p>
  </div>
  <div class="page">
    <p>CPU-bound encryption</p>
    <p>Encryption Speed (MB/s)</p>
    <p>FAWN (5W) Traditional + HD (87W)</p>
    <p>Encryption Efficiency (MB/J)</p>
    <p>AES encryption/decryption of a 512MB file with a 256-bit key</p>
    <p>FAWN is 2x more efficient for CPU-bound operations!</p>
    <p>Performance Efficiency</p>
  </div>
  <div class="page">
    <p>When to use FAWN for random access workloads?</p>
    <p>Total cost of ownership  Capital cost + 3 year power @ $0.10/kWh</p>
    <p>What is the cheapest architecture for serving random access workloads?</p>
    <p>Traditional + {Disks, SSD, DRAM}?  FAWN + {Disks, SSD, DRAM}?</p>
  </div>
  <div class="page">
    <p>Architecture with lowest TCO</p>
    <p>for random access workloads</p>
    <p>Ratio of query rate to dataset size informs storage technology</p>
    <p>!&quot;#$</p>
    <p>!$</p>
    <p>!$&quot;</p>
    <p>!$&quot;&quot;</p>
    <p>!$&quot;&quot;&quot;</p>
    <p>!$&quot;&quot;&quot;&quot;</p>
    <p>!&quot;#$ !$ !$&quot; !$&quot;&quot; !$&quot;&quot;&quot;</p>
    <p>% &amp; '&amp; ( ) '! * +, ) !+ !. /</p>
    <p>!&quot; #$ %&amp;% '( #) *+ *, . /</p>
  </div>
  <div class="page">
    <p>Architecture with lowest TCO</p>
    <p>for random access workloads</p>
    <p>Ratio of query rate to dataset size informs storage technology</p>
    <p>!&quot;#$</p>
    <p>!$</p>
    <p>!$&quot;</p>
    <p>!$&quot;&quot;</p>
    <p>!$&quot;&quot;&quot;</p>
    <p>!$&quot;&quot;&quot;&quot;</p>
    <p>!&quot;#$ !$ !$&quot; !$&quot;&quot; !$&quot;&quot;&quot;</p>
    <p>% &amp; '&amp; ( ) '! * +, ) !+ !. /</p>
    <p>!&quot; #$ %&amp;% '( #) *+ *, . /</p>
  </div>
  <div class="page">
    <p>Architecture with lowest TCO</p>
    <p>for random access workloads</p>
    <p>Ratio of query rate to dataset size informs storage technology</p>
    <p>!&quot;#$</p>
    <p>!$</p>
    <p>!$&quot;</p>
    <p>!$&quot;&quot;</p>
    <p>!$&quot;&quot;&quot;</p>
    <p>!$&quot;&quot;&quot;&quot;</p>
    <p>!&quot;#$ !$ !$&quot; !$&quot;&quot; !$&quot;&quot;&quot;</p>
    <p>% &amp; '&amp; ( ) '! * +, ) !+ !. /</p>
    <p>!&quot; #$ %&amp;% '( #) *+ *, . /</p>
  </div>
  <div class="page">
    <p>Architecture with lowest TCO</p>
    <p>for random access workloads</p>
    <p>FAWN-based systems can provide lower cost per {GB, QueryRate}</p>
    <p>Ratio of query rate to dataset size informs storage technology</p>
    <p>!&quot;#$</p>
    <p>!$</p>
    <p>!$&quot;</p>
    <p>!$&quot;&quot;</p>
    <p>!$&quot;&quot;&quot;</p>
    <p>!$&quot;&quot;&quot;&quot;</p>
    <p>!&quot;#$ !$ !$&quot; !$&quot;&quot; !$&quot;&quot;&quot;</p>
    <p>% &amp; '&amp; ( ) '! * +, ) !+ !. /</p>
    <p>!&quot; #$ %&amp;% '( #) *+ *, . /</p>
  </div>
  <div class="page">
    <p>Challenges</p>
    <p>Algorithms and Architectures at 10x scale  Dealing with Amdahls law</p>
    <p>High performance using low performance nodes  Todays software may not run out of the box</p>
    <p>Manageability, failures, network design, power cost vs. engineering cost</p>
    <p>Each decimal order of magnitude increase in parallelism requires a major redesign and rewrite of parallel code - Kathy Yelick</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>FAWN improves the computational efficiency of datacenters</p>
    <p>Informed by fundamental system power trends</p>
    <p>Challenges: programming for 10x scale, running todays software on yesterdays machines...</p>
  </div>
  <div class="page">
    <p>Hot enough for industry</p>
  </div>
</Presentation>
