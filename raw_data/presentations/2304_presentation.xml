<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Performance Inconsistency in Large Scale Data Processing Clusters</p>
    <p>Mingyuan Xia, Nan Zhu, Yuxiong He, Sameh Elnikety, Xue Liu</p>
  </div>
  <div class="page">
    <p>Large CompuBng Clusters</p>
    <p>e.g., MapReduce, Hadoop, Cosmos  Enable large data processing applicaBons</p>
    <p>Sharing  Each user pays for using a fracBon of the enBre cluster (virtual cluster)</p>
    <p>Fixed capacity, but resources can be shared among VCs to promote uBlizaBon</p>
  </div>
  <div class="page">
    <p>ProducBon trace</p>
    <p>the total work (server hours) /VC capacity (number of servers)</p>
    <p>average job slow down (compared with ideal run @me)</p>
  </div>
  <div class="page">
    <p>ProducBon trace</p>
    <p>Performance Inconsistency</p>
  </div>
  <div class="page">
    <p>Cosmos</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM VM</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM VM</p>
    <p>VM</p>
    <p>VM VM</p>
    <p>VM</p>
    <p>Physical clusters</p>
  </div>
  <div class="page">
    <p>Cosmos</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM VM</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM VM</p>
    <p>VM</p>
    <p>VM VM</p>
    <p>VM</p>
    <p>Virtual Cluster (6)</p>
    <p>Virtual Cluster (4)</p>
    <p>Management VMs</p>
    <p>Physical clusters</p>
  </div>
  <div class="page">
    <p>Cosmos</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM VM</p>
    <p>VM</p>
    <p>VM VM</p>
    <p>VM</p>
    <p>Virtual Cluster (6)</p>
    <p>Virtual Cluster (4)</p>
    <p>Management VMs</p>
    <p>Physical clusters</p>
  </div>
  <div class="page">
    <p>Job execuBon model</p>
    <p>VC1 alloc=0 cap=6</p>
    <p>VC2 alloc=0 cap=8</p>
  </div>
  <div class="page">
    <p>Job execuBon model</p>
    <p>VC1 alloc=4 cap=6</p>
    <p>VC2 alloc=0 cap=6</p>
    <p>Job1 demands at most 4 VMs &lt;mapred.map.tasks&gt;</p>
    <p>Input_file_size/DFS_block_size</p>
    <p>OR</p>
    <p>[1] hYp://wiki.apache.org/hadoop/HowManyMapsAndReduces</p>
  </div>
  <div class="page">
    <p>Job execuBon model</p>
    <p>VC1 alloc=4 cap=6</p>
    <p>VC2 alloc=4 cap=8</p>
  </div>
  <div class="page">
    <p>Job execuBon model</p>
    <p>VC1 alloc=8 cap=6</p>
    <p>VC2 alloc=4 cap=8</p>
    <p>Sharing promotes overall system uBlizaBon</p>
    <p>job1</p>
    <p>job2</p>
  </div>
  <div class="page">
    <p>Job execuBon model</p>
    <p>VC1 alloc=8</p>
    <p>VC2 alloc=4</p>
    <p>VC scheduler</p>
    <p>cluster scheduler</p>
    <p>Our work tackles fairness at the cluster scheduler level.</p>
  </div>
  <div class="page">
    <p>Instantaneous fairness</p>
    <p>Consider parameters at a given Bme point</p>
    <p>MaxMin: Maximize the minimum allocaBon  Hadoops fair scheduler is a variaBon</p>
  </div>
  <div class="page">
    <p>MaxMin: how it works</p>
    <p>VC1 (cap=6)</p>
    <p>VC2 (cap=8)</p>
    <p>VC3 (cap=4)</p>
    <p>VC1=4/6 VC2=4/8 VC3=0/4</p>
    <p>VC1=8/6 VC2=8/8 VC3=0/4</p>
    <p>VC1=8/6 VC2=0/8 VC3=10/4 Total VMs = 18</p>
    <p>Maximize the minimum allocaBon</p>
  </div>
  <div class="page">
    <p>MaxMin VC1 VC2 VC3</p>
    <p>AllocaBon 0 0 0 Demand 8 0 12 Capacity 6 8 4</p>
    <p>Stage I (8 remaining) AllocaBon 6 0 4 Demand 2 0 8 Capacity 6 8 4</p>
    <p>Stage II (4 remaining) AllocaBon 6+2 0 4+2 Demand 0 0 6 Capacity 6 8 4</p>
  </div>
  <div class="page">
    <p>Long-term?</p>
    <p>Previous contribuBon is not rewarded VC1</p>
    <p>(cap=4)</p>
    <p>VC2 (cap=4)</p>
    <p>VC3 (cap=4)</p>
    <p>VC1=0/4 VC2=8/4 VC3=0/4</p>
    <p>VC1=6/4 VC2=6/4 VC3=0/4</p>
  </div>
  <div class="page">
    <p>Long-term?</p>
    <p>Large VCs win fewer resources VC1</p>
    <p>(cap=10)</p>
    <p>VC2 (cap=4)</p>
    <p>VC3 (cap=8)</p>
    <p>VC1=0/10 VC2=8/4 VC3=0/8</p>
    <p>VC1=14/10 VC2=8/4 VC3=0/8</p>
  </div>
  <div class="page">
    <p>Trace-driven simulaBon</p>
    <p>Build a simulator  ProducBon trace from a commercial cluster  50,000 servers shared by 115 VCs  One month period  Job submit Bme, size, etc</p>
    <p>Pick 6 VCs (two under-loaded, three full- loaded and one over-loaded) to assess the performance inconsistency</p>
  </div>
  <div class="page">
    <p>Overall load fluctuaBon</p>
  </div>
  <div class="page">
    <p>Overall VC performance</p>
  </div>
  <div class="page">
    <p>Load fluctuaBon</p>
    <p>Fast VC Slow VC</p>
  </div>
  <div class="page">
    <p>Fast VC: under-loaded days</p>
    <p>Fast VC Slow VC</p>
  </div>
  <div class="page">
    <p>Slow VC: under-loaded days</p>
    <p>Fast VC Slow VC</p>
  </div>
  <div class="page">
    <p>Performance</p>
    <p>Fast VC Slow VC</p>
  </div>
  <div class="page">
    <p>Fast VC: Under-loaded day performance</p>
    <p>The fast VC performs opBmally when it is under-loaded</p>
    <p>Fast VC Slow VC</p>
  </div>
  <div class="page">
    <p>Slow VC: Under-loaded day performance</p>
    <p>The slow VC performs opBmally in most under-loaded days</p>
    <p>Fast VC Slow VC</p>
  </div>
  <div class="page">
    <p>CongesBon</p>
    <p>CongesBon: a slow day may affect the next upcoming day</p>
    <p>Fast VC Slow VC</p>
  </div>
  <div class="page">
    <p>Contending days</p>
    <p>Six contending days: both VCs are overloaded</p>
    <p>Fast VC Slow VC</p>
  </div>
  <div class="page">
    <p>Contending day performance</p>
    <p>Slow VC loses totally to the fast VC</p>
    <p>Fast VC Slow VC</p>
  </div>
  <div class="page">
    <p>Summary Slow VC Fast VC</p>
    <p>Capacity 900 350</p>
    <p>Load characterisBc (both~=1)</p>
    <p>Under-loaded day performance</p>
    <p>- 14 days stretch~=1 - 6 day stretch &gt;1 due to congesBon</p>
    <p>Stretch~=1</p>
  </div>
  <div class="page">
    <p>Summary (cont.) Slow VC Fast VC</p>
    <p>Capacity 900 350</p>
    <p>Load characterisBc (both~=1)</p>
    <p>Under-loaded day performance</p>
    <p>- 14 days stretch~=1 - 6 day stretch &gt;1 due to congesBon</p>
    <p>Stretch~=1</p>
    <p>(Six) Contending days</p>
    <p>Stretch = 10 ~ 35 - contribuBon not rewarded - Small VC bias</p>
    <p>Stretch~=1</p>
    <p>(Five) Overloaded days</p>
    <p>Stretch = 4 ~ 10 - Meets full-uBlized days Stretch ~=1</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>ContribuBon not rewarded  Small VC bias  CongesBon</p>
  </div>
  <div class="page">
    <p>SoluBons?</p>
    <p>Consider usage history  Idea: gain credits when contribuBng; lose credits when overusing</p>
    <p>Higher credits more allocaBon  Deficit Round-Robin (DRR) for network switches  Xen credit scheduler  LoYery-based scheduler: accumulate loYery to increase the chances of wining more resources</p>
  </div>
  <div class="page">
    <p>A straighrorward accounBng method</p>
    <p>Open a saving account for free resource contribuBon  ContribuBng free resources -&gt; gain credits  Overusing -&gt; lose credits</p>
    <p>Allocate more VMs to VCs with higher credits</p>
  </div>
  <div class="page">
    <p>Challenges</p>
    <p>Give credits as long as VCs are underuBlized</p>
    <p>Make promise for more future allocaBon</p>
    <p>Users further decrease load to gain more credits</p>
    <p>The system becomes even more underuBlized</p>
  </div>
  <div class="page">
    <p>Challenges</p>
    <p>The counBng scheme should provide good incenBves of user behaviors</p>
    <p>We desire the users to  Contribute resources  Promote overall system uBlizaBon  Shape their workload and avoid peaks</p>
    <p>Straighrorward scheme may not be enough!</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Show the performance inconsistency with Instantaneous fair schedulers</p>
    <p>IdenBfy three causes  Usage history should be considered when making scheduling decisions</p>
    <p>Credit counBng should enforce fairness while providing incenBves to promote overall uBlizaBon</p>
  </div>
  <div class="page">
    <p>Performance Inconsistency in Large Scale Data Processing Clusters</p>
    <p>Mingyuan Xia, Nan Zhu, Yuxiong He, Sameh Elnikety, Xue Liu</p>
  </div>
  <div class="page">
    <p>Backup</p>
  </div>
  <div class="page">
    <p>Parallelism esBmaBon</p>
    <p>VC</p>
    <p>esBmated actual</p>
    <p>Future work: use job info to refine</p>
    <p>de m an d</p>
    <p>de m an d</p>
  </div>
  <div class="page">
    <p>Short-term or long-term fairness</p>
    <p>MapReduce jobs are long (~hours), especially in large clusters like Cosmos</p>
    <p>Scheduling decisions are made on a minute basis</p>
    <p>Short-term fairness -&gt; accumulated effects -&gt; observe unfairness at job level</p>
  </div>
  <div class="page">
    <p>DRF scheduler</p>
    <p>Dominant Resource Fairness  Find the dominant resource type  Make MaxMin decision on that type (sBll only at a given Bme point)</p>
  </div>
  <div class="page">
    <p>Challenges</p>
    <p>More credits lead to more alloca@on in the future</p>
  </div>
  <div class="page">
    <p>BursBness impact</p>
    <p>MaxMin: If you peak meets others peak you lose</p>
    <p>Ideal long term fairness: you will be treat beYer</p>
  </div>
  <div class="page">
    <p>Dynamic joining/leaving users</p>
  </div>
</Presentation>
