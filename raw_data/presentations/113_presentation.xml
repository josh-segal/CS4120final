<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Fast approximate planning in POMDPs</p>
    <p>Geoff Gordon</p>
    <p>ggordon@cs.cmu.edu</p>
    <p>Joelle Pineau, Geoff Gordon, Sebastian Thrun. Point-based</p>
    <p>value iteration: an anytime algorithm for POMDPs</p>
    <p>Fast approximate planningin POMDPs  p.1/37</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>POMDPs are too slow</p>
    <p>Fast approximate planningin POMDPs  p.2/37</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>POMDPs are too slow</p>
    <p>Fast approximate planningin POMDPs  p.3/37</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>Review of POMDPs</p>
    <p>Review of POMDP value iteration algorithms</p>
    <p>Point-based value iteration</p>
    <p>Theoretical results</p>
    <p>Actual results</p>
    <p>Fast approximate planningin POMDPs  p.4/37</p>
  </div>
  <div class="page">
    <p>POMDP overview</p>
    <p>Planning in an uncertain world</p>
    <p>Actions have random effects</p>
    <p>Dont observe full world state</p>
    <p>Fast approximate planningin POMDPs  p.5/37</p>
  </div>
  <div class="page">
    <p>POMDP definition</p>
    <p>State x  X, actions a  A, observations z  Z</p>
    <p>Rewards ra (column vectors), discount   [0, 1)</p>
    <p>Belief b  P (X) (row vectors)</p>
    <p>Starting belief b0</p>
    <p>Fast approximate planningin POMDPs  p.6/37</p>
  </div>
  <div class="page">
    <p>POMDP definition contd</p>
    <p>Transitions b  bTa (Ta stochastic)</p>
    <p>Observation likelihoods wz (row vectors)</p>
    <p>z</p>
    <p>wz = 1</p>
    <p>Observation update:</p>
    <p>b  wz  b</p>
    <p>where  is pointwise multiplication</p>
    <p>Fast approximate planningin POMDPs  p.7/37</p>
  </div>
  <div class="page">
    <p>Value functions</p>
    <p>Just like MDP value function (but bigger)</p>
    <p>V (b) = expected total discounted future reward starting from b</p>
    <p>Knowing V means planning is 1-step lookahead</p>
    <p>If we discretize belief simplex, we are done</p>
    <p>From b get to bz1, bz2, . . . according to P (z | b, a)</p>
    <p>Fast approximate planningin POMDPs  p.8/37</p>
  </div>
  <div class="page">
    <p>Value functions</p>
    <p>Additional structure: convexity</p>
    <p>Consider beliefs b1, b2, b3 = b1+b2</p>
    <p>b3: flip a coin, then start in b1 if heads, b2 if tails</p>
    <p>b3 is always worse than average of b1, b2</p>
    <p>Fast approximate planningin POMDPs  p.9/37</p>
  </div>
  <div class="page">
    <p>Representation</p>
    <p>Represent V as the upper surface of a (possibly infinite) set of hyperplanes</p>
    <p>V is set of hyperplanes</p>
    <p>Hyperplanes represented by normals v (column vectors)</p>
    <p>V (b) = maxvV b  v</p>
    <p>Fast approximate planningin POMDPs  p.10/37</p>
  </div>
  <div class="page">
    <p>Value iteration</p>
    <p>Bellmans equation:</p>
    <p>V (b) = max a</p>
    <p>Q(b, a)</p>
    <p>Q(b, a) = ra +</p>
    <p>z</p>
    <p>P (z | b, a)V (baz)</p>
    <p>where baz = (bTa)  wz</p>
    <p>Fast approximate planningin POMDPs  p.11/37</p>
  </div>
  <div class="page">
    <p>Convergence</p>
    <p>Backup operator T : V  T V</p>
    <p>T is a contraction on P (X) 7 R</p>
    <p>b  b = maxx |b(x)  b (x)|</p>
    <p>Fast approximate planningin POMDPs  p.12/37</p>
  </div>
  <div class="page">
    <p>Sondiks algorithm (1972)</p>
    <p>Rearrange Bellman equation to make it linear:</p>
    <p>1 = P (z | b, a), and V (b) = V (b), so</p>
    <p>Q(b, a) = ra +</p>
    <p>z</p>
    <p>V ((bTa)  wz)</p>
    <p>= ra +</p>
    <p>z</p>
    <p>max vV</p>
    <p>((bTa)  wz)  v</p>
    <p>= ra +</p>
    <p>z</p>
    <p>max vV</p>
    <p>b  Ta(wz  v)</p>
    <p>Fast approximate planningin POMDPs  p.13/37</p>
  </div>
  <div class="page">
    <p>Evaluate from inside out</p>
    <p>Suppose Vt(b) = b  v</p>
    <p>vz = wz  v</p>
    <p>vaz = Tavz</p>
    <p>va = vaz1 + vaz2 + . . .</p>
    <p>V = {va1, va2, . . .}</p>
    <p>Now Vt+1(b) = maxvV b  v</p>
    <p>Fast approximate planningin POMDPs  p.14/37</p>
  </div>
  <div class="page">
    <p>More than 1 hyperplane</p>
    <p>Suppose Vt(b) = maxvV b  v</p>
    <p>Vz = wz V set ops are elementwise</p>
    <p>Vaz = TaVz</p>
    <p>Va = ra + Vaz1 Vaz2  . . . expensive!</p>
    <p>V = Va1 Va2  . . .</p>
    <p>Now Vt+1(b) = maxvV b  v</p>
    <p>above representation due to [Cassandra et al]</p>
    <p>Fast approximate planningin POMDPs  p.15/37</p>
  </div>
  <div class="page">
    <p>A note on complexity</p>
    <p>Or, some very large numbers</p>
    <p>Set Comment Total size Time/element Vz same size as V |Z| |V| O(|X|) Vaz still same size |A| |Z| |V| O(|X|2) Va big! |A| |V||Z| O(|X|)</p>
    <p>For example, w/ 5 actions, 5 observations:</p>
    <p>Fast approximate planningin POMDPs  p.16/37</p>
  </div>
  <div class="page">
    <p>Witnesses (Littman 1994)</p>
    <p>Dont need all elements of V</p>
    <p>Just those which are arg max b  v for some b</p>
    <p>If we have the b (a witness), fast to check that v is indeed arg max</p>
    <p>Fast approximate planningin POMDPs  p.17/37</p>
  </div>
  <div class="page">
    <p>Witness details</p>
    <p>Linear feasibility problem (size about |V| |X|)</p>
    <p>b  v  b  vi i</p>
    <p>b  1 = 1</p>
    <p>b  0</p>
    <p>Solve one LF per element of Vexpensive, but well worth it</p>
    <p>Can add margin  &gt; 0 for approximate solution  dont have to have all witnesses</p>
    <p>Fast approximate planningin POMDPs  p.18/37</p>
  </div>
  <div class="page">
    <p>Incremental pruning</p>
    <p>(Cassandra, Littman, Zhang 1997)</p>
    <p>Prune Vz, Vaz, and Va as they are constructed</p>
    <p>Another big win in runtime</p>
    <p>We are now up to 16-state POMDPs</p>
    <p>Fast approximate planningin POMDPs  p.19/37</p>
  </div>
  <div class="page">
    <p>Summary so far</p>
    <p>Solve POMDPs by repeatedly applying backup T</p>
    <p>Represent V with set of hyperplanes V</p>
    <p>V grows fast</p>
    <p>Can prune V using witnesses</p>
    <p>Fast approximate planningin POMDPs  p.20/37</p>
  </div>
  <div class="page">
    <p>Plan for rest of talk</p>
    <p>Better use of witnesses: point backups</p>
    <p>Better way to find witnesses: exploration</p>
    <p>PBVI = point backups + exploration for witnesses</p>
    <p>PBVI examples</p>
    <p>Fast approximate planningin POMDPs  p.21/37</p>
  </div>
  <div class="page">
    <p>Backups at a point</p>
    <p>Computing witnesses is expensive</p>
    <p>What if we knew a witness b already?</p>
    <p>Fast to compute both V (b) and d db</p>
    <p>V (b)</p>
    <p>Intuitive, then formal derivation</p>
    <p>Fast approximate planningin POMDPs  p.22/37</p>
  </div>
  <div class="page">
    <p>Point backupintuition</p>
    <p>V (b) depends on P (z | b, a)baz for all a, z</p>
    <p>P (z | b, a)baz are linear functions of b</p>
    <p>V (P (z | b, a)baz) is scaled/shifted copy of V</p>
    <p>Adding these copies: hard over P (X), easy at b</p>
    <p>Fast approximate planningin POMDPs  p.23/37</p>
  </div>
  <div class="page">
    <p>Point backupmath</p>
    <p>When V V, we want maxvV b  v</p>
    <p>Thats maxa maxvV a b  v, since V = Va1 Va2 . . .</p>
    <p>But maxvV a b  v is</p>
    <p>max v1Vaz</p>
    <p>b  v1 + max v2Vaz</p>
    <p>b  v2 + . . .</p>
    <p>since any v Va is v1 + v2 + . . .</p>
    <p>. . . and Vaz is quick to compute.</p>
    <p>Fast approximate planningin POMDPs  p.24/37</p>
  </div>
  <div class="page">
    <p>Advantage of point-based backups</p>
    <p>Suppose we have a set B of witnesses and V of hyperplanes</p>
    <p>Pruning V takes time O(|B| |V| |X|) (w/ small constant)</p>
    <p>Without knowing witnesses, solve |V| LFs, each |V| |X|</p>
    <p>Higher order, worse constants</p>
    <p>Fast approximate planningin POMDPs  p.25/37</p>
  </div>
  <div class="page">
    <p>Where do witnesses come from?</p>
    <p>Grids (note difference to discretizing belief simplex)</p>
    <p>Random (Poon 2001)</p>
    <p>Interleave point-based with incremental pruning (Zhang &amp; Zhang 2000)</p>
    <p>We are now up to 90-state POMDPs</p>
    <p>Fast approximate planningin POMDPs  p.26/37</p>
  </div>
  <div class="page">
    <p>New theorem</p>
    <p>Bound error of the point-based backup operator</p>
    <p>Bound depends on how densely we sample reachable beliefs</p>
    <p>Probably exists an extension to easily reachable beliefs</p>
    <p>Error bound on one step + contraction of value iteration = overall error bound</p>
    <p>First result of this sort for POMDP VI</p>
    <p>Fast approximate planningin POMDPs  p.27/37</p>
  </div>
  <div class="page">
    <p>Definitions</p>
    <p>Let  be the set of reachable beliefs</p>
    <p>Let B be a set of witnesses</p>
    <p>Let (B) be the worst-case density of B in :</p>
    <p>(B) = max b</p>
    <p>min bB b  b1</p>
    <p>Fast approximate planningin POMDPs  p.28/37</p>
  </div>
  <div class="page">
    <p>Theorem</p>
    <p>A single point-based backups error is</p>
    <p>(B)(Rmax  Rmin)</p>
    <p>That means the error after value iteration is</p>
    <p>(B)(Rmax  Rmin)</p>
    <p>(1  )2</p>
    <p>plus a bit for stopping at finite horizon</p>
    <p>Fast approximate planningin POMDPs  p.29/37</p>
  </div>
  <div class="page">
    <p>Policy error</p>
    <p>We therefore have that policy error is:</p>
    <p>(B)(Rmax  Rmin)</p>
    <p>(1  )3</p>
    <p>(1  )3, ouch! But it does go to 0 as (B)  0</p>
    <p>Fast approximate planningin POMDPs  p.30/37</p>
  </div>
  <div class="page">
    <p>Exploration</p>
    <p>Theorem tells us we want to sample reachable beliefs with high worst-case 1-norm density</p>
    <p>We can do this by simulating forward from b0</p>
    <p>Generate a set of candidate witnesses</p>
    <p>Accept those which are farthest (1-norm) from current set</p>
    <p>Fast approximate planningin POMDPs  p.31/37</p>
  </div>
  <div class="page">
    <p>Selecting new witnesses</p>
    <p>.</p>
    <p>.</p>
    <p>.</p>
    <p>.</p>
    <p>.</p>
    <p>*</p>
    <p>.</p>
    <p>.</p>
    <p>Fast approximate planningin POMDPs  p.32/37</p>
  </div>
  <div class="page">
    <p>Summary of algorithm</p>
    <p>B {b0}</p>
    <p>V = {0} (or whatevere.g., use QMDP)</p>
    <p>Do some point-based backups on V using B</p>
    <p>we backup k times, where k is small</p>
    <p>Add more beliefs to B  we double the size of B each time</p>
    <p>Repeat</p>
    <p>Fast approximate planningin POMDPs  p.33/37</p>
  </div>
  <div class="page">
    <p>Tag problem</p>
    <p>fixed opponent policy</p>
    <p>Fast approximate planningin POMDPs  p.34/37</p>
  </div>
  <div class="page">
    <p>Results</p>
    <p>Fast approximate planningin POMDPs  p.35/37</p>
  </div>
  <div class="page">
    <p>Results</p>
    <p>Catches opponent 60% of time</p>
    <p>Dont know of another value iteration algorithm which could do this well</p>
    <p>On smaller problems, gets policies as good as other algorithms</p>
    <p>But uses a small fraction of the compute time</p>
    <p>Fast approximate planningin POMDPs  p.36/37</p>
  </div>
  <div class="page">
    <p>Contributions and Conclusion</p>
    <p>Others have used point-based backups  mostly in combination with other, more</p>
    <p>expensive ops</p>
    <p>Others have tried to select witnesses quickly  on small problems, random &amp; grid are good</p>
    <p>heuristics</p>
    <p>Pushed to 10 larger problems with efficient algorithm and intelligent search for witnesses</p>
    <p>Our theorem is the strongest of its type Fast approximate planningin POMDPs  p.37/37</p>
  </div>
</Presentation>
