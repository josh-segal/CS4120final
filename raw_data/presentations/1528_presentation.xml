<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Virtualized Infrastructures, Systems, &amp; Applications</p>
    <p>CloudCache: On-demand Flash Cache Management</p>
    <p>for Cloud Computing</p>
    <p>Dulcardo Arteaga</p>
    <p>Jorge Cabrera</p>
    <p>Jing Xu</p>
    <p>Swaminathan Sundararaman</p>
    <p>Ming Zhao</p>
    <p>Florida International University</p>
    <p>Florida International University</p>
    <p>VMware Inc.</p>
    <p>Parallel Machines</p>
    <p>Arizona State University</p>
  </div>
  <div class="page">
    <p>Background</p>
    <p>Networked storage systems are important building</p>
    <p>blocks for cloud computing</p>
    <p>Benefits</p>
    <p>o Efficient storage utilization</p>
    <p>o Reliable VM storage</p>
    <p>o Live VM migrations</p>
    <p>Challengescalability</p>
    <p>o Increasingly level of consolidation</p>
    <p>o Increasing data-intensive workloads</p>
    <p>iSCSI, NBD,</p>
    <p>VMM</p>
    <p>VMs</p>
    <p>HOST</p>
    <p>STORAGE</p>
  </div>
  <div class="page">
    <p>Flash caching to the rescue?</p>
    <p>Client-side caching</p>
    <p>o Exploit the locality in VM I/Os using the storage available on the client-side</p>
    <p>Flash-based cache devices</p>
    <p>o Exploit the high performance of flash storage</p>
    <p>o Avoid the long latency from the networked storage</p>
    <p>Challenges:</p>
    <p>o Limited cache capacity</p>
    <p>Still small compared to dataset sizes</p>
    <p>o Limited device endurance</p>
    <p>Caching makes it worseboth writes in the workloads</p>
    <p>and read misses cause wear-out</p>
    <p>Also applicable to other NVM based caches</p>
    <p>VMM</p>
    <p>VMs</p>
    <p>HOST</p>
    <p>STORAGE</p>
    <p>$</p>
    <p>$</p>
    <p>$</p>
    <p>iSCSI, NBD,</p>
  </div>
  <div class="page">
    <p>Overview of CloudCache</p>
    <p>On-demand cache allocation</p>
    <p>o Allocate shared cache capacity to VMs according</p>
    <p>to their demands</p>
    <p>Target</p>
    <p>STORAGE</p>
    <p>IP-SAN</p>
    <p>/SAN</p>
    <p>VM</p>
    <p>VM</p>
    <p>VM1</p>
    <p>VMn HOST1</p>
    <p>On-demand</p>
    <p>cache allocation</p>
    <p>flash cache</p>
    <p>flash cache</p>
    <p>HOSTm</p>
    <p>VM storage</p>
    <p>VM disk1</p>
    <p>VM</p>
    <p>migration</p>
    <p>Dynamic cache</p>
    <p>migration</p>
    <p>VM diskmn</p>
    <p>Dynamic cache migration</p>
    <p>o Balance cache load across hosts by</p>
    <p>migrating VMs and their cached data</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Background</p>
    <p>On-demand cache allocation</p>
    <p>Dynamic cache migration</p>
    <p>Putting everything together</p>
  </div>
  <div class="page">
    <p>On-demand cache allocation</p>
    <p>Allocate cache capacity</p>
    <p>according to the workload</p>
    <p>cache demand</p>
    <p>How to model the cache</p>
    <p>demand of a workload?</p>
    <p>How to use the model to</p>
    <p>manage the cache?</p>
    <p>VMM</p>
    <p>VMs</p>
    <p>HOST</p>
    <p>STORAGE</p>
    <p>$</p>
    <p>$</p>
    <p>$</p>
    <p>iSCSI, NBD,</p>
    <p>Time (days)</p>
  </div>
  <div class="page">
    <p>Working set and reuse working set</p>
    <p>Traditional Working Set WS(t,T)</p>
    <p>(Denning, 1968)</p>
    <p>o Set of distinct blocks referenced during</p>
    <p>[t-T, t]</p>
    <p>o Include data with low temporal locality</p>
    <p>Waste cache space, hurt endurance</p>
    <p>Our proposed Reuse Working Set</p>
    <p>RWSN(t,T)</p>
    <p>o Set of distinct blocks reused at least N</p>
    <p>times during [t-T, t]</p>
    <p>o Keep only the really useful data</p>
    <p>Exclude low-temporal-locality data</p>
    <p>WS (, t1) = {1,2,6,3,4,5,7,8} WSS = 8</p>
    <p>RWS1 (, t1) = {6,4} RWSS1= 2</p>
    <p>t1</p>
    <p>t</p>
  </div>
  <div class="page">
    <p>cache usage</p>
    <p>WS vs. RWS</p>
    <p>flash writes N</p>
    <p>Number of times an address has been reused</p>
    <p>Analysis of different RWSN o 36 MSR traces</p>
    <p>RWSN  N is the number of</p>
    <p>times an address has been</p>
    <p>reused</p>
    <p>Flash write ratio:</p>
    <p>percentage of writes sent to</p>
    <p>the flash device</p>
    <p>o Indirect measurement of</p>
    <p>wear-out</p>
  </div>
  <div class="page">
    <p>RWS-based cache allocation</p>
    <p>Measure the RWS size (RWSS) of each</p>
    <p>workload online</p>
    <p>o Window size typically set to days</p>
    <p>Predict the workload cache demands using</p>
    <p>observed RWSSes</p>
    <p>o Exponential smoothing with self-tuning</p>
    <p>smoothing factor</p>
    <p>Allocate cache capacity according to the</p>
    <p>predicted RWSSes</p>
    <p>Reduces cache usage up to 76%</p>
    <p>Observed</p>
    <p>Predicted</p>
  </div>
  <div class="page">
    <p>Cache admission</p>
    <p>Addresses/Data</p>
    <p>referenced only once</p>
    <p>Reuse Working Set</p>
    <p>(RWS)</p>
    <p>reused data</p>
    <p>Stage</p>
    <p>(Main memory)</p>
    <p>Cache</p>
    <p>(Flash device)</p>
    <p>VM HOST</p>
    <p>read/write</p>
    <p>Admit only reused data into cache</p>
    <p>o Avoid low-temporal-locality data from</p>
    <p>polluting the cache and causing unnecessary</p>
    <p>wear-out</p>
    <p>Stagingstore candidates in memory</p>
    <p>before admitting them into cache</p>
    <p>o Address stagingstage only addresses of the</p>
    <p>candidates</p>
    <p>o Data stagingstage both addresses and data</p>
    <p>of the candidates</p>
    <p>Reduce second-access misses</p>
    <p>o Hybrid stagingseparate areas for staging</p>
    <p>addresses and data</p>
    <p>Can stage more addresses than data items</p>
    <p>WS (, t1) = {1,2,6,3,4,5,7,8} WSS = 8</p>
    <p>RWS1 (, t1) = {6,4} RWSS1= 2</p>
    <p>t1</p>
    <p>t</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Name Time</p>
    <p>(days)</p>
    <p>Write</p>
    <p>(%)</p>
    <p>WSS</p>
    <p>(GB)</p>
    <p>Webserver 281 51 110</p>
    <p>Moodle 161 13 226</p>
    <p>Fileserver 152 22 1037</p>
    <p>Prototype</p>
    <p>o Based on block device virtualization</p>
    <p>(dm-cache, visa.lab.asu.edu/dmcache)</p>
    <p>o Transparent support for Linux-based (virtualized)</p>
    <p>environments</p>
    <p>Traces</p>
    <p>o Collected from several departmental servers</p>
    <p>o visa.lab.asu.edu/traces ([Systor14])</p>
    <p>Testbed</p>
    <p>o iSCSI; Intel 120GB MLC SSD; XEN 4.1</p>
    <p>IP-SAN</p>
    <p>VM1</p>
    <p>VMn</p>
    <p>HOST /dev/mapper/cache#</p>
    <p>/dev/sdc</p>
    <p>flash cache</p>
    <p>VM storage</p>
    <p>CloudCache</p>
  </div>
  <div class="page">
    <p>Hit ratio</p>
    <p>o Up to 9% lower than No Allocation</p>
    <p>o Up to 4% lower than WSS</p>
    <p>Latency</p>
    <p>o 1% higher than No Allocation</p>
    <p>o Similar to WSS</p>
    <p>RWSS vs. WSS based allocation</p>
    <p>Latency (msec)</p>
    <p>No-Alloc WSS RWSS 12</p>
    <p>Flash Writes (%)</p>
    <p>No-Alloc WSS RWSS</p>
    <p>Allocation (GB)</p>
    <p>No-Alloc WSS RWSS</p>
    <p>Hit Ratio (%)</p>
    <p>No-Alloc WSS RWSS</p>
    <p>Cache usage</p>
    <p>o Up to 72GB less than No Allocation</p>
    <p>o Up to 5GB less than WSS</p>
    <p>Flash write ratio</p>
    <p>o Up to 6% lower than No Allocation</p>
    <p>o Up to 37% lower than WSS</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Background</p>
    <p>On-demand cache allocation</p>
    <p>Dynamic cache migration</p>
    <p>Putting everything together</p>
  </div>
  <div class="page">
    <p>Dynamic cache migration</p>
    <p>CloudCache allocates cache according to</p>
    <p>VMs cache demands (RWSSes)</p>
    <p>o How to handle situations where the cache</p>
    <p>capacity is insufficient?</p>
    <p>Live VM migration can be used to balance</p>
    <p>the cache load across hosts</p>
    <p>o How to handle the cached (possibly dirty) data?    STORAGE</p>
    <p>$</p>
    <p>$</p>
    <p>VM1 VMm</p>
    <p>Live migrate</p>
    <p>VM1</p>
  </div>
  <div class="page">
    <p>Challenges</p>
    <p>Cached data is critical to performance</p>
    <p>o Warmup may take a long time ([ATC13, Systor14])</p>
    <p>Dirty pages on cache must be synched from</p>
    <p>source to destination</p>
    <p>o Write-back caching provides better performance</p>
    <p>o But flushing dirty data may take a long time before</p>
    <p>migration</p>
    <p>STORAGE</p>
    <p>$</p>
    <p>$</p>
    <p>VM1</p>
    <p>VMm</p>
    <p>Dirty</p>
    <p>VMms</p>
    <p>RWS</p>
    <p>VM1s</p>
    <p>RWS</p>
  </div>
  <div class="page">
    <p>Dynamic cache migration</p>
    <p>On-demand migration of dirty data</p>
    <p>o Zero downtime to migrated VM</p>
    <p>o Cache immediately available to the VM</p>
    <p>Background migration of RWS</p>
    <p>o Quickly warmup the cache</p>
    <p>o Migrate only the useful data</p>
    <p>Rate limiting</p>
    <p>o Limit number of blocks transferred</p>
    <p>per period of time</p>
    <p>o Limit the impact to co-hosted VMs</p>
    <p>Dirty</p>
    <p>VMms</p>
    <p>RWS</p>
    <p>VM1s</p>
    <p>RWS</p>
    <p>STORAGE</p>
    <p>$</p>
    <p>$</p>
    <p>VMm</p>
    <p>Dirty blocks</p>
    <p>on-demand</p>
    <p>VM1</p>
    <p>RWS</p>
    <p>background</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>A day-long moodle trace</p>
    <p>o Read intensive</p>
    <p>o RWS: 5GB, 15% dirty</p>
    <p>On-demand migration enables zero</p>
    <p>downtime</p>
    <p>o 54s downtime otherwise</p>
    <p>Background migration allows fast</p>
    <p>cache warm-up</p>
    <p>-33%</p>
    <p>-64%</p>
    <p>Migrated VMs latency</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Background</p>
    <p>On-demand cache allocation</p>
    <p>Dynamic cache migration</p>
    <p>Putting everything together</p>
  </div>
  <div class="page">
    <p>Putting everything together</p>
    <p>Allocate cache capacity proportionally</p>
    <p>to RWSSes</p>
    <p>Migrate VMs and their cached data when</p>
    <p>a cache is overloaded</p>
    <p>o After exceeding the 90% watermark for 3</p>
    <p>consecutive periods</p>
    <p>Choose the destination host by</p>
    <p>minimizing the cache load imbalance</p>
    <p>VMs</p>
    <p>STORAGE</p>
    <p>$</p>
    <p>$</p>
    <p>On-demand cache allocation</p>
    <p>$</p>
    <p>Dynamic</p>
    <p>cache migration</p>
    <p>VM migration</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>No cache</p>
    <p>allocation</p>
    <p>CloudCache</p>
    <p>Setup</p>
    <p>o 2 hosts each w/ 64GB cache</p>
    <p>o 10-day Webserver trace</p>
    <p>o 12 VMs</p>
    <p>RWS-based allocation allows</p>
    <p>every VM got a fair share</p>
    <p>Dynamic cache migration</p>
    <p>balances cache load</p>
    <p>28% higher hit ratio, 27% lower</p>
    <p>a latency</p>
    <p>VM 11</p>
    <p>migrated</p>
  </div>
  <div class="page">
    <p>Related work</p>
    <p>Cache allocation (S-CAVE, vCacheShare,</p>
    <p>Centaur)</p>
    <p>o Admit all referenced data into cache</p>
    <p>o Do not consider dynamic cache migration to</p>
    <p>deal with overloaded cache</p>
    <p>Cache admission (HEC, LARC)</p>
    <p>o Do not consider how to allocate shared cache</p>
    <p>to concurrent workloads</p>
    <p>o RWSS-based cache admission achieves better</p>
    <p>reduction in cache footprint and wear-out</p>
    <p>Processor and memory cache</p>
    <p>allocation ([ICPADS01, ASPLOS04,</p>
    <p>ASPLOS09, MICRO08, FAST03] )</p>
    <p>o Flash cache presents different</p>
    <p>challenges and opportunities</p>
    <p>o Low-locality data are detrimental to</p>
    <p>performance and endurance</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>The RWS model can capture data with good temporal locality</p>
    <p>Allocation based on RWSS can efficiently meet workload cache</p>
    <p>demands</p>
    <p>Dynamically migrating VMs and cached data can effectively balance</p>
    <p>cache load across host with minimal performance impact</p>
    <p>Our results show:</p>
    <p>o Single VM: Up to 76% reduction in cache usage and up to 37% in flash writes</p>
    <p>o 12 concurrent VMs: 28% higher hit ratio and 27% lower latency, on average</p>
  </div>
  <div class="page">
    <p>Acknowledgements</p>
    <p>Sponsors</p>
    <p>o National Science Foundation CAREER</p>
    <p>award CNS-125394</p>
    <p>o Department of Defense award W911NF</p>
    <p>VISA research lab</p>
    <p>o http://visa.lab.asu.edu</p>
    <p>Thank you!</p>
  </div>
</Presentation>
