<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Presented by:</p>
    <p>AI4DL: Mining Behaviors of Deep Learning Workloads for Resource Management 12th USENIX Workshop on Hot Topics in Cloud Computing, July 2020</p>
    <p>Josep Llus Berral josep.berral@bsc.es</p>
    <p>Josep L. Berral, Chen Wang, Alaa Youssef</p>
    <p>Barcelona Supercomputing Center IBM  Container Cloud Platform</p>
  </div>
  <div class="page">
    <p>Context (Background &amp; Motivation)</p>
    <p>Background</p>
    <p>Concepts:  Cloud-native DL workloads  Efficient resource usage</p>
    <p>Problem to tackle: Better workload management/provisioning  Our Environment: Containers for Deep Learning training applications</p>
    <p>Motivation  Increasing use of DL services on the Cloud</p>
    <p>Not just inference but training!  DL platforms over Cloud</p>
    <p>Different providers  Resources changing/increasing over time</p>
    <p>Containers allow higher usage/sharing of machines  Must manage better to avoid competition/underprivison</p>
    <p>Learn about the workload  Make better decisions</p>
    <p>Resource management: How many resources should I allocate for that job?  Auto-Scaling: Increase/decrease container provisioning?</p>
  </div>
  <div class="page">
    <p>In this work:  Discover behavior phases from resource usage metrics  CRBM for multi-dimensional time-series  Estimate resource demand from phase information  Statistical information  Devise container auto-scaling policies for DL workloads  Based on phase identification + stats</p>
    <p>Basic Questions:</p>
    <p>Introduction</p>
    <p>Can we identify common behaviors in workloads?</p>
    <p>(Characterization / Phase discovery)</p>
    <p>Can we exploit that to properly provision?</p>
    <p>(Learning phase characteristics)</p>
  </div>
  <div class="page">
    <p>Previous Work</p>
    <p>Workload characterization and learning</p>
    <p>Previous work:  Use of data mining techniques to model workloads (ALOJA project) *  Characterization / Detection of Phases (Hi-EST project) **</p>
    <p>Related work:  Focus on direct resource prediction / continuous modeling</p>
    <p>Problems with burstiness / variability and sudden behaviors  Phase-modeling to detect shapes rather than punctual values</p>
    <p>Use of Time-Series techniques  Systems with high variability are better modelled by periods (here with phases)  Adaptive modeling may require constant learning. Here we try to reduce model update to extremely novel workloads</p>
    <p>Reactive methods  Constant adaption of resources. Here we leverage anticipation or recognition of current trend</p>
    <p>* ALOJA: A Framework for Benchmarking and Predictive Analytics in Big Data Deployments http://dx.doi.org/10.1109/TETC.2015.2496504 ** Automatic Generation of Workload Profiles using Unsupervised Learning Pipelines http://dx.doi.org/10.1109/TNSM.2017.2786047</p>
    <p>Modeling towards Optimal Configuration for Hadoop/Spark</p>
  </div>
  <div class="page">
    <p>Methodology</p>
    <p>Characterization to DL containerized workloads</p>
    <p>Training and Inference process:</p>
    <p>Workload (Application traces &amp;</p>
    <p>monitoring)</p>
    <p>Learn model to discover phases on resource</p>
    <p>demand Get statistics per phase</p>
    <p>Learn phase sequences</p>
    <p>Phase model &amp; Statistics</p>
    <p>Execution Tree or Graph</p>
    <p>New application running</p>
    <p>Learning</p>
    <p>Training Dataset</p>
    <p>New Data</p>
    <p>Detect phase and allocate resources</p>
    <p>Phase detection model</p>
    <p>Runtime</p>
    <p>Potential phase forecasting</p>
  </div>
  <div class="page">
    <p>Example:</p>
    <p>Phase Discovery and Detection</p>
    <p>Collected Information per phase:</p>
    <p>Green Phase  Warm up / Low resource demand</p>
    <p>Blue phase  Low memory / Low CPU</p>
    <p>Red Phase  CPU w. variation / High Memory</p>
    <p>Gray Phase  High CPU &amp; Mem demand</p>
  </div>
  <div class="page">
    <p>Phase Discovery and Detection</p>
    <p>Conditional Restricted Boltzmann Machines (CRBM)</p>
    <p>Clustering methods</p>
    <p>Characterization through Phases</p>
    <p>Understand workloads</p>
    <p>Retrieve statistics for phaseIdentification of behavior pattern (phase)</p>
    <p>Encoding of current footprint into hash code</p>
    <p>E xe</p>
    <p>cu tio</p>
    <p>n</p>
    <p>Ti m</p>
    <p>e</p>
    <p>Resources</p>
    <p>S lid</p>
    <p>in g</p>
    <p>w in</p>
    <p>do w</p>
    <p>co de Clustering</p>
    <p>Hyper-params (k = num. phases)</p>
    <p>P ha</p>
    <p>se ID</p>
    <p>Phase statistics</p>
    <p>Hyper-params (num. neurons, learning rate)</p>
    <p>C R</p>
    <p>BM</p>
    <p>Forecasting Model</p>
    <p>Tree/graph of Exec. Phases (trained from executions)</p>
    <p>Find similar codes  similar behaviors along time  E.g. k-means method (k with best cluster cohesion, SSW)</p>
    <p>Multi-dimensional Time-series encoder  Code shares similarity among similar inputs</p>
    <p>Each phase has characteristics mean, st.dev, min/max,   Each workload is represented by a sequence of phases</p>
  </div>
  <div class="page">
    <p>Modeling Executions as Phase-series</p>
    <p>Executions by similarity. Example:</p>
  </div>
  <div class="page">
    <p>Modeling Executions as Phase-series</p>
    <p>Prototype representation  Probabilistic tree form</p>
    <p>Jump from phase to phase  Considering phase lengths in bins</p>
    <p>Describe sequences of phases by tree.</p>
    <p>Observations</p>
    <p>- Spawn of tree - Variability in our workload  Reduced set of standard executions</p>
    <p>- Branches with high probability  Consistency on executions  Our prototypes</p>
  </div>
  <div class="page">
    <p>Modeling Executions as Phase-series</p>
    <p>Prototype representation</p>
    <p>Graph representation  E.g. State-graph or Markov Chain</p>
    <p>Solve problems found in trees:  Alternate sequences of phases  Different lengths in different executions  Convergence in variations in middle-execution</p>
    <p>Phase2</p>
    <p>Phase5</p>
    <p>Phase1</p>
    <p>Phase2</p>
    <p>Phase2</p>
    <p>Phase5</p>
    <p>Phase1</p>
    <p>Phase2</p>
    <p>i times</p>
    <p>j times</p>
    <p>Phase2</p>
    <p>Phase5</p>
    <p>Phase1</p>
    <p>Phase2</p>
    <p>Phase4</p>
    <p>Phase2</p>
    <p>Phase5 Phase1</p>
    <p>Phase4</p>
  </div>
  <div class="page">
    <p>Resource Provisioning Policies</p>
    <p>Types of Policies:</p>
    <p>Dynamic Policies: We know a priori the load for next time-window  Adaptive Policies: We observe what happened last time-window, use that same information  Phase-based Policies: From last time-window, we detect the current phase and its expected stats</p>
    <p>Statistic Values</p>
    <p>Using mean + 2 standard deviation: Provide the container the expected 95th percentile ceiling, to avoid outliers  Using maximum observed: Provide the container the maximum observed</p>
    <p>Not in phase-based policy, to avoid carrying the global maximum observed per phase  Here we can consider a tolerance margin between 0-10% for any policy</p>
  </div>
  <div class="page">
    <p>Experiments</p>
    <p>Evaluation benchmark:  IBM DLaaS services, with +5500 containers</p>
    <p>Set-Up  Traces for DLaaS (Deep Learning as a Service) Kubernetes containers from IBM Watson ML services  Telemetry: recording of CPU &amp; Memory demands and usage each 15 seconds.</p>
    <p>Dataset division  Training dataset: Create and validate models, CRBMs, clustering,   Handy set for experimentation (5000 execs)  Testing dataset: Test the method with new data  Large data set (550 execs)</p>
    <p>Training Environment  CRBM package (R-cran + C + OpenBlas + GSL) + k-Means from R-base  Code also available in Python, open source in https://github.com/HiEST/AI4DL</p>
  </div>
  <div class="page">
    <p>Experiments: Phase Behavior</p>
    <p>Identification of behaviors for each phase  Phase discovery + prototype discovery (CPU and Memory)</p>
    <p>Variability and behavior for each detected phase  Discovered 6 major prototypes (here the 3 principal ones) X-axis: TIME (15 sec. PHASES)</p>
    <p>Y-axis: CPU &amp; MEM USAGE</p>
  </div>
  <div class="page">
    <p>Experiments</p>
    <p>Representation of Phase sequences</p>
    <p>Graph &amp; Tree  Tree: Observed 6 prototypes</p>
    <p>(branches) concentrating ~90% of executions</p>
    <p>Also we observe their variations</p>
    <p>Phase changes  Some phases are stable (easy to</p>
    <p>follow)  Others are clearly temporary phases</p>
    <p>(constant switch between phases)</p>
  </div>
  <div class="page">
    <p>Experiments</p>
    <p>Phase-based resource provisioning  Re-scheduling window</p>
    <p>10 minutes (here by system policy)</p>
    <p>Evaluation dataset:  Consumption tested over the full dataset of +550</p>
    <p>executions longer than 10 minutes</p>
    <p>Consumption close to a-priori policies  Improvement over adaptive policies  Saving up to 30% on CPU/Memory consumption in</p>
    <p>total</p>
    <p>Quality of service  Fulfillment of 95% of CPU/Memory demand</p>
    <p>Allowing over/under-provisioning margin between a -10% / +10%</p>
    <p>No degradation compared to prev.step policy:  Same amount of OOM/CPU Throttling scenarios  2 out of this 5% unfulfilled are bursts or outliers</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Approach &amp; Contribution</p>
    <p>Discover behavior phases from resource usage metrics  Use of CRBM encoding + Clustering method</p>
    <p>Estimate resource demand from phase information  Study diversity of behaviors on resources demand</p>
    <p>Devise container auto-scaling policies for DL workloads  Resource allocation strategy according to specific statistics</p>
    <p>Codification of DLaaS applications into behaviors (i.e. phases)  Finding prototypes and phase-sequences (graph/tree representations)</p>
    <p>Knowledge from applications  Specific resource demands in determined execution moments</p>
    <p>Leverage a-priori information from identified phases  Better heuristic to know in advance resource demands</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>Discussion:  Different bottlenecks in Workloads</p>
    <p>E.g. network and storage  Sophistication of policies</p>
    <p>How to leverage phase information, or add new info  Forecasting Phases</p>
    <p>Additional information for graph transitions  Time in the current phase towards observing a change?  MX with N-memory to avoid Loss of prototype information?</p>
    <p>Updatability of models!  Do we choose models easy to adapt?</p>
    <p>Future Work  Phase forecasting in workloads</p>
    <p>Refine prediction of future phases  Refine resource allocations strategy per phase</p>
    <p>E.g. advance resource scheduling from a-priori phase changes  E.g. slow reduction of provisioning to prevent hysteresis and reduce re-provision rounds</p>
    <p>Containerized services for ML inference  Also other kinds of workload!</p>
  </div>
  <div class="page">
    <p>Presented by:</p>
    <p>Thank you for your attention Any questions?</p>
    <p>Josep Llus Berral josep.berral@bsc.es</p>
  </div>
</Presentation>
