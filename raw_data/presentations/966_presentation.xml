<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Kinetic Modeling of Data Eviction in Cache</p>
    <p>Xiameng Hu, Xiaolin Wang, Lan Zhou, YingweiLuo Peking University</p>
    <p>Chen Ding University of Rochester</p>
    <p>Zhenlin Wang Michigan Technological University</p>
  </div>
  <div class="page">
    <p>Background  Miss Ratio Curve (MRC) is a powerful metric for cache optimization:  Allocation, Partition, Scheduling, QoS managing</p>
    <p>Online MRC profiling techniques have been developed for decades.</p>
    <p>Ultimate goals:  Less space consumption.  Lower time complexity.</p>
  </div>
  <div class="page">
    <p>Background</p>
    <p>A brief history of MRC techniques.</p>
  </div>
  <div class="page">
    <p>Our Model: Average Eviction Time</p>
    <p>Linear time Constant space Composability</p>
  </div>
  <div class="page">
    <p>Eviction Time</p>
    <p>d a b c</p>
    <p>a d b c</p>
    <p>c a d b</p>
    <p>b c a d</p>
    <p>e b c a</p>
    <p>a d b c</p>
    <p>Eviction</p>
    <p>d a b c</p>
    <p>a b c e</p>
    <p>a</p>
    <p>d</p>
    <p>a</p>
    <p>d</p>
    <p>a</p>
    <p>c</p>
    <p>b</p>
    <p>e</p>
    <p>data</p>
    <p>Residence time</p>
    <p>Eviction time</p>
    <p>time</p>
    <p>d e b cd93nd access</p>
    <p>MRU LRU</p>
  </div>
  <div class="page">
    <p>Eviction Time</p>
    <p>The eviction time is the time between the last access and the eviction. Property of eviction time:</p>
    <p>If the reuse time of an access is larger than its eviction time, its a miss.</p>
    <p>Reuse time: the time between an access and its next reuse. The reuse time of cold miss is defined as infinite.</p>
  </div>
  <div class="page">
    <p>Back to the example</p>
    <p>d a b c</p>
    <p>a d b c</p>
    <p>c a d b</p>
    <p>b c a d</p>
    <p>e b c a</p>
    <p>a d b c</p>
    <p>d a b c</p>
    <p>a b c ea</p>
    <p>d</p>
    <p>a</p>
    <p>d</p>
    <p>a</p>
    <p>c</p>
    <p>b</p>
    <p>e</p>
    <p>data</p>
    <p>Eviction time = 4</p>
    <p>d e b cd</p>
    <p>Hit!</p>
    <p>Cold Miss!</p>
    <p>Miss!</p>
    <p>Reuse time =</p>
    <p>Reuse time = 2</p>
    <p>Reuse time = 5</p>
    <p>time</p>
    <p>MRU LRU</p>
  </div>
  <div class="page">
    <p>Average Eviction Time</p>
    <p>Average Eviction Time (AET) is the mean eviction time of all data evictions in a fully associative LRU cache. We can assume all data references with a reuse time larger than AET are misses.</p>
  </div>
  <div class="page">
    <p>How to model AET?  Move condition #1:</p>
    <p>Cache hit inserts the lower priority position data to the LRU stack top.</p>
    <p>Move condition #2:  Cache miss inserts a missed data to the LRU stack top.</p>
    <p>d a b c</p>
    <p>a d b c</p>
    <p>d a b c</p>
    <p>e d a b</p>
    <p>access: a</p>
    <p>access: e</p>
    <p>MRU LRU</p>
    <p>MRU LRU</p>
  </div>
  <div class="page">
    <p>How to model AET?  Stay condition :</p>
    <p>Cache hit inserts the higher priority position data to the LRU stack top.</p>
    <p>a b d c</p>
    <p>b a d c access: b</p>
    <p>MRU LRU</p>
  </div>
  <div class="page">
    <p>How to model AET?  We define the arrival time % as the expected time it takes for an evicting data to reach the m-th position (from its last access).</p>
    <p>A data block at position  move one step down whenever the reuse time of current access is greater than the %.</p>
    <p>() is the probability for an access with a reuse time greater than  .</p>
    <p>The movement condition is now a probability. Every access , a data block at stack position  moves by (%) .</p>
  </div>
  <div class="page">
    <p>Kinetic Model  Data travels in one direction with changing speed:</p>
    <p>In general, if the time that evicting data already traveled is , its current evicting speed is ().</p>
    <p>top d bottom</p>
    <p>() = ()</p>
  </div>
  <div class="page">
    <p>Average Eviction Time  Physics: the integration of speed over time is travel distance.  The length of LRU list is the travel distance of every eviction. Which is the cache size .</p>
    <p>With ,we calculate AETs of different cache sizes in linear time.   can be acquired online by monitoring the reuse time histogram.</p>
  </div>
  <div class="page">
    <p>From AET to MRC</p>
    <p>The miss ratio () at cache size c is the probability that a reuse time is greater than the average eviction time   :</p>
    <p>() = (())</p>
  </div>
  <div class="page">
    <p>AET Design Overview</p>
    <p>Program Monitoring</p>
    <p>Access Trace</p>
    <p>Reuse Time Histogram AET</p>
    <p>Miss Ratio Curve</p>
  </div>
  <div class="page">
    <p>Random Sampling</p>
    <p>Randomly pick current accessed data to monitor its reuse time.</p>
    <p>The distance between two sampled is a random value.  Constrain the random value range to control sampling rate.  A hash table is required. It maintains current monitored data.  The space consumption is linear but limited.</p>
  </div>
  <div class="page">
    <p>Reservoir Sampling</p>
    <p>To bound the space cost to constant. (1)  When the -th sampled data arrives, reservoir sampling keeps the new data in monitoring set with probability min (1,/) and randomly discards an old data when the set is full.</p>
    <p>It ensures the equal probability for every sampled reuse to update reuse time histogram.</p>
    <p>While the number of samples be recorded is bounded.</p>
  </div>
  <div class="page">
    <p>AET in Shared Cache  Composabilityco-run behavior can be computed from the metric of solo-runs.</p>
    <p>When  programs share the cache of size , all  + 1 co-run , I() for each program i and () for the group, are the same:</p>
    <p>Detailed modeling is described in paper.</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>AET vs Counter Stacks (OSDI14) AET vs SHARDS (FAST15) Shared Cache AET</p>
  </div>
  <div class="page">
    <p>AET vs Counter Stacks</p>
    <p>Counter Stacks:  Only requires extremely small space while maintaining an acceptable accuracy.</p>
    <p>HyperLogLog counter to track reuse distance.  Balance accuracy and space by limiting the number of counters.</p>
    <p>Benchmarks:  Microsoft Research Cambridge (MSR) storage traces.  Configured with only read requests of 4KB cache blocks.</p>
  </div>
  <div class="page">
    <p>AET vs Counter Stacks</p>
  </div>
  <div class="page">
    <p>AET vs Counter Stacks</p>
    <p>AET Random Sampling (  M)</p>
    <p>AET Reservoir Sampling 8k entries</p>
    <p>Counter Stacks High fidelity (d = 1M, s = 60,  = 0.02)</p>
    <p>Counter Stacks Low fidelity (d = 1M, s = 3600,  = 0.1)</p>
    <p>Mean Absolute Error</p>
    <p>Average Space Cost</p>
    <p>Average Throughput</p>
  </div>
  <div class="page">
    <p>AET vs SHARDS  SHARDS:</p>
    <p>hash-based spatial sampling  a splay tree to track the reuse distances of the sampled data.  Limits the space overhead to a constant by adaptively lowering the sampling rate.</p>
    <p>Benchmarks:  master MSR, which is a 2.4 billion-access trace combining all 13 MSR traces by ranking the time stamps of all accesses.</p>
  </div>
  <div class="page">
    <p>AET vs SHARDS</p>
  </div>
  <div class="page">
    <p>AET vs SHARDS</p>
    <p>AET Random Sampling (  M)</p>
    <p>AET Reservoir Sampling 8k samples</p>
    <p>SHARDS 8k samples</p>
    <p>Counter Stacks</p>
    <p>Mean Absolute Error</p>
    <p>Average Space Cost</p>
    <p>Average Throughput</p>
  </div>
  <div class="page">
    <p>Shared Cache AET</p>
    <p>We choose Four MSR storage traces {prn, src2, web, stg} as a co-run group.</p>
    <p>Generate a combined trace from the four traces under equal speed assumption.</p>
    <p>We compare MRC composed by individual AET modeling of each trace, as well as the real MRC of the combined trace.</p>
  </div>
  <div class="page">
    <p>Shared Cache AET</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>A new model to characterize cache behavior. Enable fast MRC profiling with O(1) space and O(n) time. Predict shared cache MRC without co-run testing. Perfect for online deployment with limited overhead.</p>
  </div>
  <div class="page">
    <p>Thank you for your attention!</p>
    <p>Q&amp;A Email: hxm@pku.edu.cn</p>
  </div>
  <div class="page">
    <p>AET vs StatStack  StatStack:</p>
    <p>Designed for CPU workloads.  It samples cache blocks and measures their reuse time using performance counters and watchpoints.</p>
    <p>Reuse time histogram -&gt; Reuse distance histogram.  Benchmarks:</p>
    <p>SPEC CPU2006, 30 benchmarks.  For each benchmark, we intercept 1 billion references from their execution using the instrumentation tool Pin.</p>
    <p>We measure the cumulative distribution function (CDF) of absolute error of full-trace StatStack, full-trace AET, sampling AET.</p>
  </div>
  <div class="page">
    <p>AET vs StatStack</p>
  </div>
</Presentation>
