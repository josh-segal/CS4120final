<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>GePSeA: A General Purpose</p>
    <p>Software Acceleration Framework for</p>
    <p>Lightweight Task Offloading</p>
    <p>Ajeet Singh Pavan Balaji Wu-chun Feng</p>
    <p>Dept. of Computer Science, Virginia Tech</p>
    <p>Math. and Computer Science, Argonne National Laboratory</p>
  </div>
  <div class="page">
    <p>Hardware Offload Engines</p>
    <p>Specialized Engines  Widely used in High-End Computing (HEC) systems for</p>
    <p>accelerating task processing  Built for specific purposes</p>
    <p>Not easily extendable or programmable  Serve a small niche of applications</p>
    <p>Trends in HEC systems: Increasing size and complexity  Difficult for hardware to deal with complexity</p>
    <p>Fault tolerance (understanding application and system requirements is complex and too environment specific)</p>
    <p>Multi-path communication (optimal solution is NP-complete)</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>General Purpose Processors</p>
    <p>Multi- and Manycore Processors  Quad- and hex-core processors are</p>
    <p>commodity components today  Intel Larrabee will have 16-cores; Intel</p>
    <p>Terascale will have 80-cores  Simultaneous Multi-threading (SMT or</p>
    <p>Hyperthreading) is becoming common</p>
    <p>Expected future  Each physical node will have a</p>
    <p>massive number of processing elements (Terascale on the chip)</p>
    <p>Future multicore systems</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>Benefits of Multicore Architectures</p>
    <p>Cost  Cheap: Moores law will continue to drive costs down  HEC is a small market; Multicores != HEC</p>
    <p>Flexibility  General purpose processing units  A huge number of tools already exist to program and utilize</p>
    <p>them (e.g., debuggers, performance measuring tools)  Extremely flexible and extendable</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>Multicore vs. Hardware Accelarators</p>
    <p>Will multicore architectures eradicate hardware accelerators?  Unlikely: Hardware accelerators have their own benefits  Hardware accelerators provide two advantages:</p>
    <p>More processing power, better on-board memory bandwidth  Dedicated processing capabilities</p>
    <p>They run compute kernels in a dedicated manner  Do not deal with shared mode processing like CPUs</p>
    <p>But more complex machines need dedicated processing for more things  More powerful hardware offload techniques possible, but</p>
    <p>decreasing returns!</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>GePSeA: General Purpose Software Acceleration  Hybrid hardware-software engines</p>
    <p>Utilize hardware offload engines for low-hanging fruit  Where return for investment is maximum</p>
    <p>Utilize software onload engines for more complex tasks  Can imitate some of the benefits of hardware offload engines,</p>
    <p>such as dedicated processing</p>
    <p>Basic Idea of GePSeA  Dedicate a small subset of processing elements on a multi</p>
    <p>core architecture for protocol onloading</p>
    <p>Different capabilities added to GePSeA as plugins</p>
    <p>Application interacts with GePSeA for dedicated processing</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>GePSeA: Basic Overview</p>
    <p>GePSeA does not try to take over tasks performed well by hardware offload engines</p>
    <p>It only supplements their capabilities</p>
    <p>Application or Software middleware</p>
    <p>Advanced hardware</p>
    <p>acceleration Basic</p>
    <p>hardware acceleration</p>
    <p>No intelligent hardware offload</p>
    <p>GePSeA GePSeA</p>
    <p>GePSeA</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>Previous Work: ProOnE</p>
    <p>ProOnE was an initial design of GePSeA concentrating on communication onloading</p>
    <p>Studied issues related to onloading MPI internal protocols on a dedicated core  Showed significant performance benefits</p>
    <p>This paper extends this previous work for more general purpose onloading  Presents the design for such onloading and a case study</p>
    <p>application</p>
    <p>ICPP 09/24/2009</p>
    <p>ProOnE: A General Purpose Protocol Onload Engine for Multi- and Many-core Architectures, P.</p>
    <p>Lai, P. Balaji, R. Thakur and D. K. Panda, ISC 2009.</p>
  </div>
  <div class="page">
    <p>Presentation Roadmap</p>
    <p>Introduction and Motivation</p>
    <p>GePSeA: General Purpose Software Acceleration</p>
    <p>Case Study: mpiBLAST</p>
    <p>Experimental Results and Analysis</p>
    <p>Conclusions and Future Work</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>GePSeA Infrastructure</p>
    <p>P -&gt; Application Process</p>
    <p>A -&gt; Accelerator</p>
    <p>Application-Accelerator interaction for a three-node cluster</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>GePSeA: Intra-node Infrastructure</p>
    <p>Application Process 1</p>
    <p>Application Process 2</p>
    <p>Message Processing Block (Logical)</p>
    <p>Accelerator</p>
    <p>Intra-node Service Queue (Higher Priority)</p>
    <p>Inter-node Service Queue (Low Priority)</p>
    <p>Registration Request 1</p>
    <p>Registration Request 2</p>
    <p>Notify All</p>
    <p>Notify All</p>
    <p>GePSeA Communication Layer</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>Memory Management Component Memory Management Component</p>
    <p>Output Processing ComponentOutput Processing Component</p>
    <p>Application</p>
    <p>Reliable Advertising</p>
    <p>Service</p>
    <p>Distributed Lock</p>
    <p>Management</p>
    <p>Directory Services</p>
    <p>Distrib uted Data</p>
    <p>Cachin g</p>
    <p>Global Process-state Management</p>
    <p>Data Strea ming</p>
    <p>Servic e Global</p>
    <p>Memory Aggregator</p>
    <p>Distrib uted Data</p>
    <p>Sorting</p>
    <p>High Speed Network</p>
    <p>Data Management ComponentData Management Component</p>
    <p>Distributed Data</p>
    <p>Caching</p>
    <p>Data Streaming</p>
    <p>Service</p>
    <p>Data Compression</p>
    <p>Engine</p>
    <p>Distributed Data</p>
    <p>Sorting</p>
    <p>Application Plug-ins Layer</p>
    <p>Overview of GePSeA Capabilities</p>
    <p>Core Components</p>
    <p>Dynamic Load</p>
    <p>Balancing</p>
    <p>Bulletin Board Service</p>
    <p>High-Speed Reliable UDP Data Transfer</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>Data Management Core Components</p>
    <p>Responsible for all data movement and the data processing associated with the application</p>
    <p>GePSeA currently includes  Distributed Data Sorting</p>
    <p>Data sorting service that is distributed across multiple nodes (incremental sorting and merging)</p>
    <p>Data Compression Engine  Compress and Uncompress Data  Convert output data to meta-data and vice-versa</p>
    <p>Distributed Data Streaming  Responsible for pre-fetching of data for the application from other nodes; Swap</p>
    <p>data</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>Memory Management Core Components</p>
    <p>Allows processes to access entire system memory as a single aggregate memory space</p>
    <p>GePSeA currently includes:  Global Memory Aggregator</p>
    <p>Keeps track of cluster-wide memory  Maintains local-global address mappings  Store and retrieve data from global memory if local memory is committed</p>
    <p>Database Directory Services  Maintains up-to-date information about various database fragments across</p>
    <p>the cluster</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>I/O Processing Core Components  Facilitates efficient output data processing  Coordinating and synchronization of output data  GePSeA currently includes:</p>
    <p>Reliable Advertisement Service  Messaging Service, used by Communication Layer</p>
    <p>Dynamic Load Balancing  Responsible for balancing the load among nodes</p>
    <p>Global Process-state Management  Maintains current status of nodes in cluster at all time</p>
    <p>High-Speed Connectionless Data Transfer  Provides high-speed UDP based data transfer</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>Presentation Roadmap</p>
    <p>Introduction and Motivation</p>
    <p>GePSeA: General Purpose Software Acceleration</p>
    <p>Case Study: mpiBLAST</p>
    <p>Experimental Results and Analysis</p>
    <p>Conclusions and Future Work</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>mpiBLAST- Introduction (1/2)</p>
    <p>Parallel Genome Sequence Search Application  Identify regions of similarity between two sequences to</p>
    <p>discover functional, structural, or evolutionary relationships between the sequences.</p>
    <p>Image Source: mpiblast.org</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>mpiBLAST- Introduction (2/2)</p>
    <p>Database and Query Segmentation  Scatter-Search-Gather Approach</p>
    <p>Input Queries</p>
    <p>Database Fragments</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>mpiBLAST over GePSeA</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>mpiBLAST Plug-ins</p>
    <p>Asynchronous Output Consolidation  Utilizes accelerator capability to merge/sort the data</p>
    <p>distributed across all multiple nodes in parallel  Remove bottlenecks</p>
    <p>Runtime Output Compression  Our results show that BLAST output can compressed be</p>
    <p>less than 10%  Significantly reduces output data transfer time over network</p>
    <p>Hot-Swap Database Fragments  Swaps its DB fragment with the DB fragment on demand  Useful for load balancing</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>Presentation Roadmap</p>
    <p>Introduction and Motivation</p>
    <p>GePSeA: General Purpose Software Acceleration</p>
    <p>Case Study: mpiBLAST</p>
    <p>Experimental Results and Analysis</p>
    <p>Conclusions and Future Work</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>P1P1</p>
    <p>Core 1 Core 2</p>
    <p>Core 3 Core 4</p>
    <p>P3P3 P4P4</p>
    <p>A1P2P2</p>
    <p>mpiBLAST over GePSeA: Committed Core</p>
    <p>Running Accelerator on Committed Core  Speed-up over mpiBLAST</p>
    <p>mpiBLAST with Accelerator</p>
    <p>mpiBLAST without Accelerator</p>
    <p>P1P1</p>
    <p>Core 1 Core 2</p>
    <p>Core 3 Core 4</p>
    <p>P3P3 P4P4</p>
    <p>P2P2</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>Worker Search Time</p>
    <p>Without Accelerator With Accelerator</p>
    <p>Number of workers</p>
    <p>% W</p>
    <p>o rk</p>
    <p>e r</p>
    <p>s e</p>
    <p>a rc</p>
    <p>h t</p>
    <p>im e</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>Output Consolidation</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>Output Compression</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>Presentation Roadmap</p>
    <p>Introduction and Motivation</p>
    <p>GePSeA: General Purpose Software Acceleration</p>
    <p>Case Study: mpiBLAST</p>
    <p>Experimental Results and Analysis</p>
    <p>Conclusions and Future Work</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>Concluding Remarks and Future Work</p>
    <p>Proposed, designed and evaluated a general purpose software accelerator (GePSeA)  Utilize a small subset of the cores to onload complex tasks</p>
    <p>Presented detailed design of the GePSeA infrastructure  Onloaded mpiBLAST application as a case study</p>
    <p>GePSeA-enabled mpiBLAST provides significant performance benefits</p>
    <p>Future Work:  Study performance and scalability on large-scale systems</p>
    <p>ICPP 09/24/2009</p>
  </div>
  <div class="page">
    <p>Thank You!</p>
    <p>Contacts:</p>
    <p>Pavan Balaji: balaji@mcs.anl.gov</p>
    <p>Wu-chun Feng: feng@cs.vt.edu</p>
  </div>
</Presentation>
