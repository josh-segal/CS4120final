<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>2009 VMware Inc. All rights reserved</p>
    <p>mClock: Handling Throughput Variability for</p>
    <p>Hypervisor IO Scheduling</p>
    <p>USENIX / ACM OSDI</p>
    <p>October 6, 2010</p>
    <p>Ajay Gulati, VMware Inc.</p>
    <p>Arif Merchant, Google Inc. (work done while at HP Labs)</p>
    <p>Peter J. Varman, Rice University</p>
  </div>
  <div class="page">
    <p>Resource ManagementState of the Art</p>
    <p>Hypervisor multiplexes hardware resources between VMs</p>
    <p>Three Controls</p>
    <p>Reservation: minimum guarantee</p>
    <p>Limits: maximum allowed</p>
    <p>Shares: proportional allocation</p>
    <p>Supported for CPU, Memory in ESX since 2003</p>
    <p>How about IO resource</p>
    <p>allocation?</p>
  </div>
  <div class="page">
    <p>Variable IOPS Capacity Seen by VMs</p>
    <p>Contention for I/O resources can arbitrarily lower a VMs allocation</p>
    <p>VM 5 Active</p>
    <p>+VM1 Active</p>
    <p>+VMs 2 &amp; 3 Active</p>
    <p>+VM4 Active</p>
    <p>VM1 Inactive</p>
    <p>VMs 2 &amp;3</p>
    <p>Inactive</p>
    <p>VM4 Inactive</p>
    <p>Each VM is running DVDStore on MS SQL Server</p>
  </div>
  <div class="page">
    <p>Why is Storage IO Allocation Hard?</p>
    <p>Storage workload</p>
    <p>characteristics are variable</p>
    <p>Available throughput</p>
    <p>changes with time</p>
    <p>Must adjust allocation</p>
    <p>dynamically</p>
    <p>Distributed shared access</p>
    <p>Limit</p>
    <p>Reservation</p>
    <p>Time (s)</p>
    <p>T h</p>
    <p>ro u</p>
    <p>g h</p>
    <p>p u</p>
    <p>t</p>
    <p>P ro</p>
    <p>p o</p>
    <p>rt io</p>
    <p>n a</p>
    <p>l</p>
    <p>A ll</p>
    <p>o c</p>
    <p>a ti</p>
    <p>o n</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Problem Description &amp; Motivation</p>
    <p>Related Work</p>
    <p>mClock Algorithm</p>
    <p>Experimental Results</p>
    <p>Conclusions &amp; Future Work</p>
  </div>
  <div class="page">
    <p>Shoulders of Giants</p>
    <p>A lot of fair-queuing, reservation control work precedes us</p>
    <p>Proportional Share Algorithms</p>
    <p>WFQ, virtual-clock, SFQ, Self-clocked, WF2Q, SFQ(D), DRR, Argon, Aqua,</p>
    <p>Stonehenge</p>
    <p>Algorithms with support for latency-sensitive applications</p>
    <p>BVT, SMART, Lottery scheduling</p>
    <p>Reservation-based Algorithms</p>
    <p>Rialto, CPU &amp; Memory management in ESX, Hierarchical CPU scheduling</p>
    <p>Novel features of mClock</p>
    <p>Supports all controls in a single algorithm</p>
    <p>Handles variable &amp; unknown capacity</p>
    <p>Easy to implement</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Problem Description &amp; Motivation</p>
    <p>Related Work</p>
    <p>mClock Algorithm</p>
    <p>Experimental Results</p>
    <p>Conclusions &amp; Future Work</p>
  </div>
  <div class="page">
    <p>Typical Proportional-Share Scheduling</p>
    <p>Each application has a weight wi</p>
    <p>Each request is assigned a tag</p>
    <p>Tags are spaced 1/ wi apart  service allocated in proportion to wi</p>
    <p>Example: 3 VMs A, B, C with weights 1/2, 1/3, 1/6</p>
    <p>How to synchronize idle applications?</p>
    <p>Global virtual time (gvt) : gets updated on every request completion</p>
    <p>),/1( 1</p>
    <p>gvtwsMaxs i rr</p>
    <p>gvt = minimum start tag in the system</p>
    <p>B</p>
    <p>A</p>
    <p>C</p>
  </div>
  <div class="page">
    <p>mClock Algorithm</p>
    <p>Three key ideas:</p>
    <p>Real-time tags</p>
    <p>Needed for tracking reservations &amp; limits</p>
    <p>Virtual time loses track of actual allocation vs. time</p>
    <p>Separate tags for reservation, shares &amp; limit</p>
    <p>Dynamic tag selection and synchronization</p>
    <p>Need to decide which tag to use</p>
    <p>Need to synchronize tags after idleness</p>
  </div>
  <div class="page">
    <p>mClock Algorithm: Multiple Tags</p>
    <p>Three real-time tags</p>
    <p>Reservation tag : R Reservation = ri</p>
    <p>Shares tag : P Shares = wi</p>
    <p>Limit tag : L Limit = li</p>
    <p>),/1( 1</p>
    <p>ecurrentTimrRMaxR i rr</p>
    <p>),/1( 1</p>
    <p>ecurrentTimlLMaxL i rr</p>
    <p>),/1( 1</p>
    <p>ecurrentTimwPMaxP i rr</p>
  </div>
  <div class="page">
    <p>mClock Algorithm: Tag selection</p>
    <p>Two phases of Scheduling:</p>
    <p>if ( smallest reservation tag &lt; current time) // constraint-based</p>
    <p>Schedule smallest eligible reservation tag</p>
    <p>else // weight-based, reservations are met</p>
    <p>Schedule smallest eligible shares tag</p>
    <p>Subtract 1/rk from reservation tags of VM k.</p>
    <p>A VM is eligible if (limit tag &lt; current time)</p>
    <p>Synchronization on request arrival from VM vi:</p>
    <p>if ( vi was idle)</p>
    <p>Make minimum P tag = current time</p>
    <p>Shift all P tags accordingly to maintain the relative ordering</p>
  </div>
  <div class="page">
    <p>mClock: Storage-specific Issues</p>
    <p>Burst Handling</p>
    <p>Allow VMs to gain idle-credit by pushing back P tags by</p>
    <p>Key property: reservations are not impacted</p>
    <p>IO size</p>
    <p>IO cost increases sub-linearly with request size</p>
    <p>Scale the number of requests based on size</p>
    <p>Request Location</p>
    <p>mClock schedules a bounded batch from a VM if addresses within 2 - 4 MB</p>
    <p>)/,/1( 1</p>
    <p>ii rr</p>
    <p>wtwPMaxP</p>
  </div>
  <div class="page">
    <p>dmClock: Clustered Storage Architectures</p>
    <p>A LUN is striped across local storage devices</p>
    <p>Host forwards VMs traffic, with certain tags</p>
    <p>dmClock enforces R, L, S controls (details in paper)</p>
    <p>LAN</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Problem Description &amp; Motivation</p>
    <p>Related Work</p>
    <p>mClock Algorithm</p>
    <p>Experimental Results</p>
    <p>Conclusions &amp; Future Work</p>
  </div>
  <div class="page">
    <p>Experimental Setup</p>
    <p>Dell PowerEdge 2950 server running VMware ESX hypervisor</p>
    <p>3 to 6 virtual machines (VMs)  mix of Windows, Linux OSes</p>
    <p>Data stores on EMC CLARiiON storage array  10 disk Raid 0, Raid 5 groups</p>
    <p>Workloads</p>
    <p>Iometer configurations and a Linux based micro-benchmark</p>
    <p>Filebench: OLTP</p>
    <p>mClock</p>
    <p>ESX host VMFS Datastore over SAN</p>
    <p>Virtual-disks virtual machines</p>
  </div>
  <div class="page">
    <p>mClock: Reservation &amp; Limits Enforcement</p>
    <p>4 VMs, Shares in ratio 2:2:1:1</p>
    <p>VM2 has a limit of 700 IOPS, VM4 has reservation of 250 IOPS</p>
    <p>VMs are started every 60 sec</p>
    <p>SFQ(D) mClock</p>
    <p>Enforces reservations, Limits</p>
  </div>
  <div class="page">
    <p>mClock: Burst Handling</p>
    <p>Recall idle VM gets benefit when next there is spare capacity</p>
    <p>2 VMs</p>
    <p>Results with idle credit of 1 and 64</p>
    <p>VM R, L,S Workload</p>
    <p>VM1 0,Unlimited, 1 Bursty:128 IOs every 400ms, 80% random</p>
    <p>VM2 0, Unlimited, 1 16 KB reads, 20% random,32 OIOs</p>
    <p>= 1 = 64</p>
    <p>VM IOPS Latency IOPS Latency</p>
    <p>VM1 312 49 ms 316 30.8 ms</p>
    <p>VM2 2420 13.2 ms 2460 12.9 ms</p>
  </div>
  <div class="page">
    <p>mClock: Filebench workloads</p>
    <p>VM1, VM2 running Filebench OLTP workload</p>
    <p>Windows VM3 running Iometer started at t = 115 sec</p>
    <p>SFQ(D),</p>
    <p>OLTP2 misses reservation</p>
    <p>mClock,</p>
    <p>Reservations are met</p>
  </div>
  <div class="page">
    <p>dmClock Result</p>
    <p>3 Servers, 3 Clients (VMs) with shares in ratio 1:4:6</p>
    <p>Clients accessing servers in a uniform manner</p>
    <p>No Reservations to reservations of [800,1000,100]</p>
    <p>Shares are</p>
    <p>respected</p>
    <p>Reservations are</p>
    <p>enforced along</p>
    <p>with shares</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Problem Description &amp; Motivation</p>
    <p>Related Work</p>
    <p>mClock Algorithm</p>
    <p>Experimental Results</p>
    <p>Conclusions &amp; Future Work</p>
  </div>
  <div class="page">
    <p>Conclusions and Future Work</p>
    <p>Storage IO allocation is hard</p>
    <p>mClock contributions</p>
    <p>Supports reservation, limit and shares in one place</p>
    <p>Handles variable IO performance seen by hypervisor</p>
    <p>Can be used for other resources such as CPU, memory &amp; Network IO allocation as well</p>
    <p>Future work</p>
    <p>Better estimation of reservation capacity in terms of IOPS</p>
    <p>Add priority control along with RLS</p>
    <p>Mechanisms to set R, L,S and other controls to meet application-level goals</p>
    <p>Can we abstract out such controls into applications SLAs</p>
    <p>i.e. An upper bound on latency, lower bound on IOPS</p>
  </div>
  <div class="page">
    <p>Backup Slides</p>
  </div>
  <div class="page">
    <p>mClock: Reservation &amp; Limits Enforcement</p>
    <p>4 VMs, Shares in ratio 2:2:1:1</p>
    <p>VM2 has a limit of 700 IOPS, VM4 has reservation of 250 IOPS</p>
    <p>VMs are started every 60 sec</p>
    <p>VM workloads:</p>
  </div>
  <div class="page">
    <p>mClock: Filebench Application Performance</p>
    <p>VM1 (lat) VM2 (lat) VM1 (Ops/s) VM2 (Ops/s)</p>
    <p>Without-mClock</p>
    <p>With-mClock</p>
    <p>VM1, VM2 running Filebench OLTP workload</p>
    <p>Windows VM3 running Iometer started at t=115s</p>
    <p>With mClock VM2s latency is lower; application Ops/s are higher</p>
    <p>Application</p>
    <p>Ops/s or</p>
    <p>ms/Op</p>
  </div>
  <div class="page">
    <p>mClock: Limit Enforcement</p>
    <p>VM Shares Limit Workload</p>
    <p>VDI 200 Unlimited Bursty (128 IOs/s)</p>
    <p>OLTP 200 Unlimited 8 KB, random, 75% reads, 16 OIOs</p>
    <p>DM 100 300 (at t=140) 32 KB, seq reads, 32 OIOs</p>
    <p>Throughput Latency</p>
  </div>
  <div class="page">
    <p>mClock: Reservation Enforcement</p>
    <p>5 VMs, Shares in ratio 1:1:2:2:2</p>
    <p>VM1 and VM2 have reservation of 250 and 300 IOPS</p>
    <p>VMs are started every 60 sec</p>
    <p>SFQ(D) mClock</p>
    <p>Meets reservations</p>
  </div>
  <div class="page">
    <p>Scheduling Goals</p>
    <p>Support - Reservation, Limit (in IOPS), Shares (no units)</p>
    <p>An example:</p>
    <p>VM Reservation Shares Limit</p>
    <p>A 250 100 Unlimited</p>
    <p>B 250 200 Unlimited</p>
    <p>C 0 300 1000</p>
    <p>T h ro</p>
    <p>u g h p u t A</p>
    <p>ll o c a ti o n</p>
    <p>Total Throughput T (IOPS)</p>
    <p>RD OLTP DM</p>
  </div>
</Presentation>
