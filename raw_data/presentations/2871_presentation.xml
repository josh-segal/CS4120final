<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Forest-to-String SMT for Asian Language Translation: NAIST at WAT 2014</p>
    <p>Graham Neubig Nara Institute of Science and Technology (NAIST)</p>
  </div>
  <div class="page">
    <p>Features of ASPEC</p>
    <p>Translation between languages with different grammatical structures</p>
    <p>an image was reconstituted in order to measure flowing plasma correctly .</p>
    <p>We all know: Phrase-based MT is not enough</p>
    <p>for the accurate measurement of plasma flow image was reconstructed .</p>
  </div>
  <div class="page">
    <p>Solution?: 2-step Translation Process</p>
    <p>Pre-ordering [Weblio, SAS_MT, NII, TMU, NICT]</p>
    <p>RBMT+Statistical Post Editing [TOSHIBA, EIWA]</p>
    <p>we translate scientific papers</p>
    <p>we translate science thesis</p>
    <p>we translate scientific papers</p>
  </div>
  <div class="page">
    <p>This is a lot of work... :( How do I make good</p>
    <p>Japanese-English preordering rules?!</p>
    <p>How do I make good Japanese-Chinese</p>
    <p>preorderering rules?!</p>
    <p>What about error propagation?</p>
    <p>What if better preordering accuracy doesn't equal better</p>
    <p>translation accuracy?</p>
  </div>
  <div class="page">
    <p>Evidence</p>
  </div>
  <div class="page">
    <p>Our Solution: Tree-to-String Translation [Liu+ 06]</p>
    <p>SUF 5</p>
    <p>VP 0-5</p>
    <p>PP 0-1</p>
    <p>VP 2-5</p>
    <p>PP 2-3</p>
    <p>N 2</p>
    <p>P 3</p>
    <p>V 4</p>
    <p>N 0</p>
    <p>P 1</p>
    <p>VP 4-5</p>
    <p>a meal</p>
    <p>a meal</p>
    <p>x1 x0</p>
    <p>x1 x0</p>
    <p>my friend</p>
    <p>my friend</p>
    <p>x1 with x0</p>
    <p>x1 x0</p>
    <p>with</p>
    <p>ate</p>
    <p>ate</p>
  </div>
  <div class="page">
    <p>Requirements for a Tree-to-String Model</p>
    <p>This is a test . It uses data .</p>
    <p>Parallel Corpus</p>
    <p>Source Sentence Parser</p>
    <p>Alignments</p>
    <p>Rule Extraction Rule Scoring Optimization</p>
    <p>Tree-to-String Model</p>
  </div>
  <div class="page">
    <p>Reducing our work load. How do I make good</p>
    <p>Japanese-English preordering rules?!</p>
    <p>How do I make good Japanese-Chinese</p>
    <p>preorderering rules?!</p>
    <p>What about error propagation?</p>
    <p>What if better preordering accuracy doesn't equal better</p>
    <p>translation accuracy?</p>
    <p>X X</p>
    <p>X</p>
  </div>
  <div class="page">
    <p>Forest-to-string Translation [Mi+ 08]</p>
    <p>I saw a girl with a telescope</p>
    <p>PRP 0,1</p>
    <p>VBD 1,2</p>
    <p>DT 2,3</p>
    <p>NN 3,4</p>
    <p>IN 4,5</p>
    <p>DT 5,6</p>
    <p>NN 6,7</p>
    <p>NP 5,7</p>
    <p>NP 2,4</p>
    <p>PP 4,7</p>
    <p>VP 1,7</p>
    <p>S 0,7</p>
    <p>NP 2,7</p>
    <p>NP 0,1</p>
  </div>
  <div class="page">
    <p>Travatar Toolkit</p>
    <p>Forest-to-string translation toolkit</p>
    <p>Supports training, decoding</p>
    <p>Includes preprocessing scripts for parsing, etc.</p>
    <p>Many other features (optimization, Hiero, etc...)</p>
    <p>Available open source! http://phontron.com/travatar</p>
  </div>
  <div class="page">
    <p>NAIST WAT System</p>
  </div>
  <div class="page">
    <p>WAT Results</p>
    <p>en-ja ja-en zh-ja ja-zh 0</p>
    <p>BLEU</p>
    <p>en-ja ja-en zh-ja ja-zh 0</p>
    <p>HUMAN</p>
    <p>Other NAIST</p>
    <p>First place in all tasks!</p>
  </div>
  <div class="page">
    <p>System Elements</p>
    <p>Travatar! Same as [Neubig &amp; Duh, ACL2014]</p>
    <p>Recurrent Neural Net Language Model</p>
    <p>Pre/post Processing (UNK splitting, transliteration)</p>
    <p>Dictionaries</p>
  </div>
  <div class="page">
    <p>Recurrent Neural Network LM</p>
    <p>Vector representation  robustness</p>
    <p>Recurrent architecture  longer context</p>
    <p>I can eat an apple &lt;/s&gt;</p>
  </div>
  <div class="page">
    <p>Pre/post processing UNK segmentation (ja-en)</p>
    <p>Kanji Normalization (ja-zh, zh-ja)</p>
    <p>Transliteration (ja-en)</p>
    <p>Japan</p>
    <p>Japan Intekku</p>
    <p>Dictionary addition (ja-en)</p>
    <p>apostema</p>
    <p>archetype</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
  </div>
  <div class="page">
    <p>Future Work</p>
    <p>LOSE at next year's WAT. (Make Travatar so easy to use that others can use it to make really good MT systems for Asian languages.)</p>
    <p>Starting soon! Training scripts to be available: http://phontron.com/project/wat2014</p>
  </div>
</Presentation>
