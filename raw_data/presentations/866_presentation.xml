<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting</p>
    <p>Historical Information</p>
    <p>Min Fu, Dan Feng, Yu Hua, Xubin He, Zuoning Chen*, Wen Xia, Fangting Huang, Qing Liu</p>
    <p>Huazhong University of Science and Technology Virginia Commonwealth University,</p>
    <p>*National Engineering Center for Parallel Computer</p>
    <p>June 19, 2014</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 1 / 25</p>
  </div>
  <div class="page">
    <p>Background</p>
    <p>Whats data deduplication?</p>
    <p>Data deduplication is a scalable compression technique used in large-scale backup systems.</p>
    <p>Traditional compression compresses a piece of data (e.g., a small file) at byte granularity.</p>
    <p>Data deduplication compresses the entire storage system at chunk granularity.</p>
    <p>The fragmentation problem caused by data deduplication:</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 2 / 25</p>
  </div>
  <div class="page">
    <p>Background</p>
    <p>Whats data deduplication?</p>
    <p>Data deduplication is a scalable compression technique used in large-scale backup systems.</p>
    <p>Traditional compression compresses a piece of data (e.g., a small file) at byte granularity.</p>
    <p>Data deduplication compresses the entire storage system at chunk granularity.</p>
    <p>The fragmentation problem caused by data deduplication:</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 2 / 25</p>
  </div>
  <div class="page">
    <p>How the fragmentation arises</p>
    <p>The first backup:</p>
    <p>We have 13 chunks, most of which are UNIQUE.</p>
    <p>Restoring this backup with 3-container-sized LRU cache requires 5 container reads.</p>
    <p>Restoring this backup with an unlimited cache requires 4 container reads.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 3 / 25</p>
  </div>
  <div class="page">
    <p>How the fragmentation arises</p>
    <p>The second backup:</p>
    <p>We also have 13 chunks, 9 of which are DUPLICATE.</p>
    <p>Restoring this backup with 3-container-sized LRU cache requires 9 container reads.</p>
    <p>Restoring this backup with an unlimited cache requires 6 container reads.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 4 / 25</p>
  </div>
  <div class="page">
    <p>How the fragmentation arises</p>
    <p>If we delete the first backup:</p>
    <p>We can NOT reclaim their space without additional mechanisms.</p>
    <p>Container merge operation: migrate valid chunks into new containers. The most time-consuming phase in garbage collection.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 5 / 25</p>
  </div>
  <div class="page">
    <p>Our observations and motivations</p>
    <p>The fragmentation taxonomy</p>
    <p>Sparse container: a container with a utilization smaller than utilization threshold (e.g., 50%), such as Container IV for backup 2.</p>
    <p>Out-of-order container: its chunks are intermittently referenced by a backup, such as Container V for backup 2.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 6 / 25</p>
  </div>
  <div class="page">
    <p>Our observations and motivations</p>
    <p>The negative impacts and potential solutions:</p>
    <p>Sparse containers directly amplify read operations, hence hurt both restore and garbage collection.</p>
    <p>Solution: rewriting referenced chunks in them to new compact containers, i.e., rewriting algorithm.</p>
    <p>Out-of-order containers hurt restore if the restore cache is small.</p>
    <p>Solution: Increasing the cache size, or developing more intelligent replacement algorithm than LRU.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 7 / 25</p>
  </div>
  <div class="page">
    <p>Our observations and motivations</p>
    <p>How existing rewriting algorithms work?</p>
    <p>Deduplication is delayed to identify fragmented duplicate chunks.</p>
    <p>They use a rewriting buffer and identify duplicate but fragmented chunks in the buffer.</p>
    <p>I The chunk M is supposed to be in a sparse container, since it has no physical neighbor in the buffer.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 8 / 25</p>
  </div>
  <div class="page">
    <p>Our observations and motivations</p>
    <p>Existing rewriting algorithms:</p>
    <p>If we extend the rewriting buffer, more physical neighbors of M would be found. M is in an out-of-order container rather than a sparse container!</p>
    <p>I NOT scalable since memory is limited.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 9 / 25</p>
  </div>
  <div class="page">
    <p>Our observations and motivations</p>
    <p>The problems of existing rewriting algorithms:</p>
    <p>They CANNOT accurately differentiate sparse containers from out-of-order containers due to the limited size of the rewriting buffer. As a result, they</p>
    <p>lose too much storage efficiency, and</p>
    <p>gain limited restore speed.</p>
    <p>The challenge:</p>
    <p>Due to the existence of out-of-order containers, accurately identifying sparse containers requires the complete knowledge of the on-going backup.</p>
    <p>How can we obtain such knowledge on the fly?</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 10 / 25</p>
  </div>
  <div class="page">
    <p>Our observations and motivations</p>
    <p>The problems of existing rewriting algorithms:</p>
    <p>They CANNOT accurately differentiate sparse containers from out-of-order containers due to the limited size of the rewriting buffer. As a result, they</p>
    <p>lose too much storage efficiency, and</p>
    <p>gain limited restore speed.</p>
    <p>The challenge:</p>
    <p>Due to the existence of out-of-order containers, accurately identifying sparse containers requires the complete knowledge of the on-going backup.</p>
    <p>How can we obtain such knowledge on the fly?</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 10 / 25</p>
  </div>
  <div class="page">
    <p>Our observations and motivations</p>
    <p>Rationale</p>
    <p>Due to the incremental nature of backup, consecutive backups share similar characteristics, including fragmentation.</p>
    <p>Our key observations:</p>
    <p>I Only a limited number of emerging sparse containers in each backup.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 11 / 25</p>
  </div>
  <div class="page">
    <p>Design and implementation</p>
    <p>Figure : The system architecture. Colored modules are our contributions.</p>
    <p>Three contributions: History-Aware Rewriting Algorithm (HAR) in backup (tackling sparse containers);</p>
    <p>Beladys optimal replacement algorithm (OPT) in restore (tackling out-of-order containers);</p>
    <p>Container-Marker Algorithm (CMA) in garbage collection (a new reference management).</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 12 / 25</p>
  </div>
  <div class="page">
    <p>Design and implementation History-Aware Rewriting</p>
    <p>History-Aware Rewriting (HAR)</p>
    <p>HAR records sparse containers during the backup, and rewrite referenced chunks in them during next backup.</p>
    <p>The emerging sparse containers of a backup become the inherited sparse containers of the next backup.</p>
    <p>Advantages:</p>
    <p>NOT rewriting emerging sparse containers does NOT hurt restore performance due to the limited number of emerging sparse containers (observation 2);</p>
    <p>Rewriting inherited sparse containers does NOT hurt backup performance due to the limited number of inherited sparse containers (observation 2);</p>
    <p>Identify sparse containers accurately due to Observation 3.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 13 / 25</p>
  </div>
  <div class="page">
    <p>Design and implementation History-Aware Rewriting</p>
    <p>History-Aware Rewriting (HAR)</p>
    <p>HAR records sparse containers during the backup, and rewrite referenced chunks in them during next backup.</p>
    <p>The emerging sparse containers of a backup become the inherited sparse containers of the next backup.</p>
    <p>Advantages:</p>
    <p>NOT rewriting emerging sparse containers does NOT hurt restore performance due to the limited number of emerging sparse containers (observation 2);</p>
    <p>Rewriting inherited sparse containers does NOT hurt backup performance due to the limited number of inherited sparse containers (observation 2);</p>
    <p>Identify sparse containers accurately due to Observation 3.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 13 / 25</p>
  </div>
  <div class="page">
    <p>Design and implementation Optimal cache</p>
    <p>The problem of out-of-order containers</p>
    <p>Out-of-order containers hurt restore performance if the restore cache is small.</p>
    <p>Our observations:</p>
    <p>We restore a backup stream according to the fingerprint sequence preserved in the recipe. As a result,</p>
    <p>We exactly know the future access pattern of containers during the restore.</p>
    <p>I more intelligent cache replacement algorithms than LRU are possible.</p>
    <p>Beladys optimal replacement algorithm:</p>
    <p>When the restore cache is full, the container that will not be accessed for the longest time in the future is evicted.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 14 / 25</p>
  </div>
  <div class="page">
    <p>Design and implementation Optimal cache</p>
    <p>The problem of out-of-order containers</p>
    <p>Out-of-order containers hurt restore performance if the restore cache is small.</p>
    <p>Our observations:</p>
    <p>We restore a backup stream according to the fingerprint sequence preserved in the recipe. As a result,</p>
    <p>We exactly know the future access pattern of containers during the restore.</p>
    <p>I more intelligent cache replacement algorithms than LRU are possible.</p>
    <p>Beladys optimal replacement algorithm:</p>
    <p>When the restore cache is full, the container that will not be accessed for the longest time in the future is evicted.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 14 / 25</p>
  </div>
  <div class="page">
    <p>Design and implementation Optimal cache</p>
    <p>The problem of out-of-order containers</p>
    <p>Out-of-order containers hurt restore performance if the restore cache is small.</p>
    <p>Our observations:</p>
    <p>We restore a backup stream according to the fingerprint sequence preserved in the recipe. As a result,</p>
    <p>We exactly know the future access pattern of containers during the restore.</p>
    <p>I more intelligent cache replacement algorithms than LRU are possible.</p>
    <p>Beladys optimal replacement algorithm:</p>
    <p>When the restore cache is full, the container that will not be accessed for the longest time in the future is evicted.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 14 / 25</p>
  </div>
  <div class="page">
    <p>Design and implementation Container-Marker Algorithm</p>
    <p>Two-phased garbage collection:</p>
    <p>I its overhead is proportional to the number of chunks.</p>
    <p>I it competes with regular backup and urgent restore for I/O bandwidth.</p>
    <p>Our observation:</p>
    <p>After the latest backup referring to the sparse container is deleted, we can directly reclaim the container rather than merging it. Simplified reference management is possible!</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 15 / 25</p>
  </div>
  <div class="page">
    <p>Design and implementation Container-Marker Algorithm</p>
    <p>Two-phased garbage collection:</p>
    <p>I its overhead is proportional to the number of chunks.</p>
    <p>I it competes with regular backup and urgent restore for I/O bandwidth.</p>
    <p>Our observation:</p>
    <p>After the latest backup referring to the sparse container is deleted, we can directly reclaim the container rather than merging it. Simplified reference management is possible!</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 15 / 25</p>
  </div>
  <div class="page">
    <p>Design and implementation Container-Marker Algorithm</p>
    <p>Container-Marker Algorithm (CMA)</p>
    <p>Maintains a container manifest for each dataset. I The manifest records IDs of all containers related to the dataset. I Each container ID is paired with a backup time that indicates the most</p>
    <p>recent backup referring to the container.</p>
    <p>Suppose we delete all backups before time T. I All containers with a backup time smaller than T can be reclaimed.</p>
    <p>The overhead is proportional to the number of containers rather than chunks.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 16 / 25</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Evaluation Methodology</p>
    <p>We implement the baseline (no rewriting) and two existing rewriting algorithms (CBR @ SYSTOR12 and CAP @ FAST13) for comparisons.</p>
    <p>Deduplication ratio: the size of the non-deduplicated data divided by that of the deduplicated data.</p>
    <p>Speed factor (@ FAST13): a metric to measure restore performance. Its defined as the size of restored data (MB) per container read.</p>
    <p>The number of valid containers (the actual storage cost after GC).</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 17 / 25</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Table : Characteristics of datasets.</p>
    <p>dataset name VMDK Linux Synthetic total size 1.44TB 104GB 4.5TB</p>
    <p># of versions 102 258 400 deduplication ratio 25.44 45.24 37.26 avg. chunk size 10.33KB 5.29KB 12.44KB</p>
    <p>sparse medium severe severe out-of-order severe medium medium</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 18 / 25</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Table : Default settings.</p>
    <p>fingerprint index in-memory container size 4MB</p>
    <p>utilization threshold 50% caching scheme OPT</p>
    <p>backup retention time 20 days container merge N/A</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 19 / 25</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>VMDK Linux Synthetic</p>
    <p>d e d u p li</p>
    <p>c a ti</p>
    <p>o n r</p>
    <p>a ti</p>
    <p>o baseline</p>
    <p>CBR CAP HAR</p>
    <p>Figure : The comparisons between HAR and other rewriting algorithms in terms of deduplication ratio.</p>
    <p>Conclusion (1)</p>
    <p>HAR rewrites less data than CBR and CAP.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 20 / 25</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>sp e e d</p>
    <p>f a c to</p>
    <p>r</p>
    <p>version number</p>
    <p>baseline(LRU) baseline(OPT)</p>
    <p>CBR</p>
    <p>CAP HAR</p>
    <p>(a) VMDK</p>
    <p>sp e e d</p>
    <p>f a c to</p>
    <p>r</p>
    <p>version number</p>
    <p>baseline(LRU) baseline(OPT)</p>
    <p>CBR</p>
    <p>CAP HAR</p>
    <p>(b) Linux</p>
    <p>Figure : The comparisons of rewriting algorithms in terms of restore performance. The cache is 512- and 32-container-sized in VMDK and Linux respectively.</p>
    <p>Conclusion (2)</p>
    <p>HAR achieves better restore performane, while rewrites less data than CBR and CAP.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 21 / 25</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>sp e e d</p>
    <p>f a c to</p>
    <p>r</p>
    <p>cache size</p>
    <p>baseline CBR</p>
    <p>CAP HAR</p>
    <p>(a) VMDK</p>
    <p>sp e e d</p>
    <p>f a c to</p>
    <p>r</p>
    <p>cache size</p>
    <p>baseline CBR</p>
    <p>CAP HAR</p>
    <p>(b) Linux</p>
    <p>Figure : The comparisons of rewriting algorithms under various cache size. Speed factor is the average value of last 20 backups. The cache size is in terms of # of containers.</p>
    <p>Conclusion (3)</p>
    <p>HAR works significantly better when the restore cache is large.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 22 / 25</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p># o</p>
    <p>f v</p>
    <p>a li</p>
    <p>d c</p>
    <p>o n</p>
    <p>ta in</p>
    <p>e r s</p>
    <p>version number</p>
    <p>baseline</p>
    <p>CBR</p>
    <p>CAP</p>
    <p>HAR</p>
    <p>(a) VMDK</p>
    <p># o</p>
    <p>f v</p>
    <p>a li</p>
    <p>d c</p>
    <p>o n</p>
    <p>ta in</p>
    <p>e r s</p>
    <p>version number</p>
    <p>baseline</p>
    <p>CBR</p>
    <p>CAP</p>
    <p>HAR</p>
    <p>(b) Linux</p>
    <p>Figure : The comparisons of rewriting algorithms in terms of the storage cost after garbage collection.</p>
    <p>Conclusion (4)</p>
    <p>After GC, HAR has lowest storage cost since it reduces sparse containers.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 23 / 25</p>
  </div>
  <div class="page">
    <p>More in the paper</p>
    <p>A hybrid rewriting scheme: I HAR+CBR; I HAR+CAP.</p>
    <p>More experimental results: I For Synthetic dataset. I Metadata overhead of garbage collection. I Varying the utilization threshold in HAR.</p>
    <p>Related work.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 24 / 25</p>
  </div>
  <div class="page">
    <p>Summary</p>
    <p>The fragmentation taxonomy:</p>
    <p>Sparse containers hurt both restore and garbage collection. Out-of-order containers hurt restore if the cache is small.</p>
    <p>History-Aware Rewriting: rewrites less data but gains more restore speed than existing work.</p>
    <p>I Solve the sparse container problem.</p>
    <p>Optimal cache: reduces the cache size we require. I Alleviate the out-of-order container problem.</p>
    <p>Container-Marker Algorithm: simpler and lower metadata overhead. I A new reference management.</p>
    <p>Min Fu  , Dan Feng</p>
    <p>, Yu Hua</p>
    <p>, Xubin He</p>
    <p>, Zuoning Chen</p>
    <p>* , Wen Xia</p>
    <p>, Fangting Huang</p>
    <p>, Qing Liu</p>
    <p>Virginia Commonwealth University,</p>
    <p>* National Engineering Center for Parallel Computer)Accelerating Restore and Garbage Collection in Deduplication-based Backup Systems via Exploiting Historical InformationJune 19, 2014 25 / 25</p>
  </div>
</Presentation>
