<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Enhancing Privacy through an Interactive On-demand Incremental Information</p>
    <p>Disclosure Interface: Applying Privacy-by-Design to Record Linkage</p>
    <p>Hye-Chung Kum (kum@tamu.edu); Cason Schmit (schmit@sph.tamu.edu)</p>
    <p>Gurudev Ilangovan; Mahin Ramezani; Qinbo Li</p>
    <p>Population Informatics Lab (https://pinformatics.org/), Texas A&amp;M University</p>
    <p>Eric D. Ragan (ergan@ufl.edu)</p>
    <p>INDIE Lab, University of Florida</p>
  </div>
  <div class="page">
    <p>Data Wrangling is a term that is applied to activities that make data more usable by changing their</p>
    <p>form but not their meaning</p>
    <p>o reformatting data: MDY vs YMD</p>
    <p>o mapping data from one data model to another: ICD9 vs CPT code</p>
    <p>o and/or converting data into more consumable forms: to graphs</p>
    <p>30-80% of the work in using big data</p>
    <p>Once raw data is wrangled into the correct analytic data</p>
    <p>o Running statistics models are fairly simple and similar to what you do traditionally</p>
    <p>o There are new methods but, usually requires a LOT of data</p>
    <p>Legitimate access to PII</p>
    <p>Data Wrangling (cleaning &amp; curation) is essential to data analytics</p>
  </div>
  <div class="page">
    <p>Legitimate access to PII</p>
    <p>Tuning parameters &amp; building training data in ML</p>
    <p>Most all data analytics</p>
    <p>o Must tune parameters: Requires manual interaction with the data (even PII)</p>
    <p>Machine learning algorithms</p>
    <p>o Requires building training data</p>
  </div>
  <div class="page">
    <p>Personal Data and Privacy</p>
    <p>Not legitimate without explicit permission</p>
    <p>o Advertising tracking location</p>
    <p>Legitimate without informed consent</p>
    <p>o Track how many emergency department a patient visited</p>
    <p>For better clinical care</p>
    <p>To improve policies for reimbursement</p>
    <p>o Track use of opioid to assess relationship between addiction and treatment</p>
    <p>o Analyze relationship between cancer and HIV</p>
    <p>o Track outcomes to evaluate and improve public programs such as child welfare</p>
    <p>Educational outcomes for children in foster care</p>
    <p>Income outcomes</p>
    <p>Incarceration outcomes 5</p>
  </div>
  <div class="page">
    <p>Restrict access</p>
    <p>Algorithms and automation</p>
    <p>Encryption</p>
    <p>Aggregation</p>
    <p>Synthetic data</p>
    <p>Partial Solutions</p>
    <p>Sorry, data scientists cant do magic</p>
  </div>
  <div class="page">
    <p>Uncertainty + Human Judgement</p>
    <p>Garbage in &amp; Garbage out: Requires human in the loop</p>
    <p>Data cleaning, data wrangling</p>
    <p>Deduplication</p>
    <p>Record linkage</p>
    <p>Parameter tuning</p>
    <p>Building training datasets</p>
    <p>Anomaly investigation</p>
  </div>
  <div class="page">
    <p>NO FREE LUNCH!! Privacy vs. Utility</p>
    <p>Related background from literature on Differential Privacy</p>
    <p>o Research has demonstrated that information privacy is a budget-constrained problem that requires reasoning about the tradeoff between privacy and utility for a given context</p>
    <p>o Consequently, there is no one-size-fits-all solution, and there is no way to benefit from using data</p>
    <p>without taking some privacy risks.</p>
  </div>
  <div class="page">
    <p>We have Hope</p>
    <p>Garbage in &amp; Garbage out: Requires human in the loop</p>
    <p>Data cleaning, data wrangling</p>
    <p>Deduplication</p>
    <p>Record linkage</p>
    <p>Parameter tuning</p>
    <p>Building training datasets</p>
    <p>Anomaly investigation</p>
    <p>Key Insights</p>
    <p>scientist need dig into for high quality results?</p>
  </div>
  <div class="page">
    <p>Insight: How do you enhance privacy while maintaining effectiveness</p>
    <p>What are key design elements for privacy enhanced systems?</p>
    <p>Current approaches: All or Nothing</p>
    <p>o Either have approval to access EVERYTHING</p>
    <p>o OR access NOTHING</p>
    <p>Need better ability to balance tradeoffs between privacy and utility</p>
    <p>o Partial Access: only when needed, and only what is needed for good decisions (e.g., parameter tuning, data cleaning, validation etc)</p>
    <p>Example: last four digits of SSN,</p>
    <p>o Make just-in-time decision on what needs to be accessed</p>
    <p>o Monitoring on level of access: (e.g. security cameras)</p>
    <p>Quantifying access level: ability to compare, detect anomalies etc</p>
    <p>o Be accountable for what was accessed: audits (e.g., logs)</p>
  </div>
  <div class="page">
    <p>Problem Statement</p>
  </div>
  <div class="page">
    <p>Record Linkage for Person-Level Data</p>
    <p>Privacy Enhanced System using Privacy-by-Design</p>
    <p>Same person?</p>
    <p>(How many emergency department visits last year?)</p>
    <p>Data source 2Data source 1</p>
  </div>
  <div class="page">
    <p>Research Overview</p>
    <p>Goals:</p>
    <p>o Privacy goal: Limiting disclosure of personal information</p>
    <p>o Utility goal: But not reduce human effectiveness</p>
  </div>
  <div class="page">
    <p>Real Question &amp; Spoiler</p>
    <p>Can we find the sweet spot between accessing PII for legitimate use while providing the maximum</p>
    <p>privacy protection as possible through the privacy by design approach by</p>
    <p>YES!!</p>
    <p>Privacy by Design Works</p>
    <p>Significantly improved privacy</p>
    <p>for same quality of results</p>
    <p>FULL ACCESS STATIC DESIGN ON-DEMAND</p>
    <p>DESIGN</p>
    <p>PPIVACY RISK</p>
  </div>
  <div class="page">
    <p>Background &amp; Previous Work</p>
  </div>
  <div class="page">
    <p>75%-80% automatics</p>
    <p>15%-25% manual resolution</p>
    <p>Hybrid Human Computer Process</p>
  </div>
  <div class="page">
    <p>Application</p>
    <p>Uncertainty in data</p>
    <p>Requires Human Judgement</p>
    <p>Human Interaction With Data</p>
    <p>Standardize Data</p>
    <p>Clean Data</p>
    <p>Build Training Data</p>
    <p>Tune Model Parameters</p>
    <p>Common Issues</p>
    <p>Typos</p>
    <p>Nicknames</p>
    <p>Switched characters</p>
    <p>Name changes</p>
    <p>Missing values</p>
    <p>Family members</p>
  </div>
  <div class="page">
    <p>PATIENT MATCHING: SAME OR DIFFERENT PEOPLE?</p>
    <p>Given multiple databases, determine if records refer to the same real world people or not</p>
    <p>Your job in this study is to:</p>
    <p>Maybe</p>
    <p>Father/Son</p>
    <p>Maybe</p>
    <p>Twins</p>
    <p>Probably</p>
    <p>data error</p>
  </div>
  <div class="page">
    <p>Maybe</p>
    <p>Father/Son</p>
    <p>Maybe</p>
    <p>Twins</p>
    <p>Probably</p>
    <p>data error</p>
    <p>Status Quo: Access to ALL for approved personnel</p>
  </div>
  <div class="page">
    <p>One Privacy Preserving Approach: Show NOTHING</p>
    <p>Encrypted disclosure</p>
    <p>Are there ways to</p>
    <p>o Improve quality of linkage: Standardize Data, Tune</p>
    <p>Parameters, Build training data</p>
    <p>o Validate results</p>
    <p>o Monitor for drifts in linkage</p>
  </div>
  <div class="page">
    <p>Previous work: What Works Best for Static Interface</p>
    <p>Markup Design</p>
    <p>Ragan, E., Kum, H.-C., Ilangovan, G.*, and Wang, H.* (2018). Balancing Privacy and Information Disclosure in Interactive Record Linkage with Visual Masking. Proceedings of the SIGCHI conference on Human factors in computing systems. ACM. CHI2018 Honourable Mention Best Paper Award (top 5% of all submissions). Also presented at the 14th Symposium on Usable Privacy and Security (SOUPS) Aug 2018 as invited poster.</p>
  </div>
  <div class="page">
    <p>Previous work: Our approach (static design)</p>
    <p>Help people by highlighting differences: Add markup</p>
    <p>Ragan, E., Kum, H.-C., Ilangovan, G.*, and Wang, H.* (2018). Balancing Privacy and Information Disclosure in Interactive Record Linkage with Visual Masking. Proceedings of the SIGCHI conference on Human factors in computing systems. ACM. CHI2018 Honourable Mention Best Paper Award (top 5% of all submissions). Also presented at the 14th Symposium on Usable Privacy and Security (SOUPS) Aug 2018 as invited poster.</p>
    <p>KEY FINDINGS</p>
    <p>High decision quality with only 30%</p>
    <p>disclosure with appropriate masks</p>
    <p>Legally deidentified data?</p>
    <p>o Fully masked (0% disclosure) had 75%</p>
    <p>accuracy</p>
    <p>The quality of human decisions will suffer</p>
    <p>with low disclosure limits</p>
  </div>
  <div class="page">
    <p>Proposed Design Elements</p>
  </div>
  <div class="page">
    <p>Our Proposed Key Design Elements</p>
    <p>Interactive Just-in-Time</p>
    <p>Interface</p>
    <p>Hide data values (when possible)</p>
    <p>Add visual meta-data to help</p>
    <p>decision making without seeing</p>
    <p>raw data</p>
    <p>Privacy Risk</p>
    <p>Budget</p>
  </div>
  <div class="page">
    <p>Our Proposed Key Design Elements</p>
    <p>Interactive Just-in-Time</p>
    <p>Interface</p>
    <p>Hide data values (when possible)</p>
    <p>Add visual meta-data to help</p>
    <p>decision making without seeing</p>
    <p>raw data</p>
    <p>Privacy Risk</p>
    <p>Budget</p>
  </div>
  <div class="page">
    <p>Our proposed approach 1: Interactive Interfaces</p>
    <p>Dynamic On-demand Incremental Disclosure</p>
    <p>Dynamic: Click to see more</p>
    <p>On-demand: When needed</p>
    <p>o Just-in-time decision</p>
    <p>Incremental: As needed</p>
    <p>o Not all at once</p>
    <p>Allow for easy</p>
    <p>accountability in</p>
    <p>information Use</p>
  </div>
  <div class="page">
    <p>Our proposed approach 1: Interactive Interfaces</p>
    <p>Dynamic On-demand Incremental Disclosure</p>
    <p>Dynamic: Click to see more</p>
    <p>On-demand: When needed</p>
    <p>o Just-in-time decision</p>
    <p>Incremental: As needed</p>
    <p>o Not all at once</p>
    <p>Allow for easy</p>
    <p>accountability in</p>
    <p>information Use</p>
  </div>
  <div class="page">
    <p>Our proposed approach 1: Interactive Interfaces</p>
    <p>Dynamic On-demand Incremental Disclosure</p>
    <p>Dynamic: Click to see more</p>
    <p>On-demand: When needed</p>
    <p>o Just-in-time decision</p>
    <p>Incremental: As needed</p>
    <p>o Not all at once</p>
    <p>Allow for easy</p>
    <p>accountability in</p>
    <p>information Use</p>
  </div>
  <div class="page">
    <p>Status quo: Access to ALL</p>
  </div>
  <div class="page">
    <p>Our proposed approach 1: Interactive Interfaces</p>
    <p>Dynamic On-demand Incremental Disclosure</p>
    <p>Incremental disclosure: No Access</p>
    <p>o Start with nothing opened, click to see more</p>
  </div>
  <div class="page">
    <p>Our proposed approach 1: Interactive Interfaces</p>
    <p>Dynamic On-demand Incremental Disclosure</p>
    <p>Incremental disclosure: Partial Information</p>
    <p>o Start with nothing opened, click to see more</p>
  </div>
  <div class="page">
    <p>Our proposed approach 1: Interactive Interfaces</p>
    <p>Dynamic On-demand Incremental Disclosure</p>
    <p>Incremental disclosure: Full Access</p>
    <p>o Start with nothing opened, click to see more</p>
  </div>
  <div class="page">
    <p>Our Proposed Key Design Elements</p>
    <p>Interactive Just-in-Time</p>
    <p>Interface</p>
    <p>Hide data values (when possible)</p>
    <p>Add visual meta-data to help</p>
    <p>decision making without seeing</p>
    <p>raw data</p>
    <p>Privacy Risk</p>
    <p>Budget</p>
  </div>
  <div class="page">
    <p>Our approach 2: Accountability &amp; Transparency</p>
    <p>Quantify the Risk: Add privacy risk meter</p>
    <p>Behavior Triggers, Nudges</p>
    <p>Proactive</p>
  </div>
  <div class="page">
    <p>KAPR (k-anonymity privacy risk) score</p>
    <p>where X(N,M) represents a given state of disclosure for N records and M attributes; {ki} resents the anonymity set size of record i; and Pij represents the percentage of characters disclosed for attribute j of record i.</p>
    <p>We introduce a user-specified parameter, K, which represents the minimum anonymity set size for a record. When a disclosure action will make the anonymity set under K this action is prohibited.</p>
    <p>The KAPR score is 0 when no information is disclosed and 1 when all records are disclosed to anonymity set size of K.</p>
    <p>In our demo, the default value for K is set to 1. This means that when all records are disclosed and each record is unique, the KAPR score would be 1.</p>
  </div>
  <div class="page">
    <p>KAPR (k-anonymity privacy risk) score properties</p>
    <p>Work in progress</p>
    <p>Risk of identity disclosure</p>
    <p>The privacy risk should be regularized to 0-100</p>
    <p>Revealing information should always lead to a privacy risk increment</p>
    <p>Privacy risk increment should be higher when disclosing information that leads to a lower anonymity set (disclosing unique names vs. disclosing common names).</p>
    <p>For any given state of disclosure, the KAPR score should always be the same. That is the order of disclosure should not matter.</p>
    <p>Qinbo Li, Adam DSouza, Cason Schmit, and Hye-Chung Kum. Increasing Transparent and Accountable Use of Data by Quantifying the Actual Privacy Risk in Interactive Record Linkage. Poster presentation at Proceedings of the AMIA Symposium 2019, Full technical report available on [arXiv:1906.03345 cs.DB] http://arxiv.org/abs/1906.03345</p>
  </div>
  <div class="page">
    <p>Our Proposed Key Design Elements</p>
    <p>Interactive Just-in-Time</p>
    <p>Interface</p>
    <p>Hide data values (when possible)</p>
    <p>Add visual meta-data to help</p>
    <p>decision making without seeing</p>
    <p>raw data</p>
    <p>Privacy Risk</p>
    <p>Budget</p>
  </div>
  <div class="page">
    <p>Our approach 3: Accountability &amp; Transparency</p>
    <p>Limiting Privacy Risk via Budget: Add limit on meter</p>
    <p>Forced</p>
  </div>
  <div class="page">
    <p>Evaluation: Hypothesis &amp; Experimental Design</p>
  </div>
  <div class="page">
    <p>Controlled Experiment</p>
    <p>Basics</p>
    <p>o Record linkage task</p>
    <p>o Data: Perturbed from real voter registration data with known ground truth</p>
    <p>o Between-subjects design (5 conditions)</p>
    <p>o Lab study with group sessions</p>
    <p>122 participants</p>
    <p>90 minutes</p>
    <p>o Tutorial</p>
    <p>o Practice trial (36 linkage pairs)</p>
    <p>o Main trials (36 linkage pairs)</p>
    <p>o Additional practice and questionnaires</p>
    <p>Bonferonni-adjusted  = 0.0125</p>
    <p>o 4 hypothesis tests</p>
  </div>
  <div class="page">
    <p>Experimental Design: Five Conditions</p>
  </div>
  <div class="page">
    <p>H1: Effects of On-demand Interface</p>
    <p>H1: We hypothesize that an appropriate on-demand and incremental disclosure interface can significantly</p>
    <p>reduce disclosure without compromising decision quality</p>
  </div>
  <div class="page">
    <p>H2: Effects of Privacy Risk Meter</p>
    <p>H2: The second hypothesis is that the addition of the feedback mechanism, which quantifies and provides a real-time display of consequences of the click, can better inform the decision</p>
    <p>to access information, and hence encourage only the most needed disclosure</p>
  </div>
  <div class="page">
    <p>H3: Effects of Pre-specified Budget</p>
    <p>When providing feedback on disclosure, enforcing a limit on privacy disclosure through a pre-specified budget</p>
    <p>will change disclosing behavior to tend toward the given limit</p>
  </div>
  <div class="page">
    <p>H3: Effects of Pre-specified Budget</p>
    <p>H3.1: Effects of High Pre-specified Budget</p>
    <p>If the limit is set high, then higher levels of disclosure will occur</p>
  </div>
  <div class="page">
    <p>H3: Effects of Pre-specified Budget</p>
    <p>H3.2: Effects of Low Pre-specified Budget</p>
    <p>On the other hand, if the limit is set too low, disclosure levels will be</p>
    <p>forced to be lower, but decision quality will be negatively affected</p>
  </div>
  <div class="page">
    <p>Expert Study</p>
    <p>Six experts who regularly conduct record linkage and work with PII (5-10 years of experience)</p>
    <p>All experts completed an abbreviated version of the high limit condition  The experts then answered questions about the potential utility and limitations of</p>
    <p>the approach and system</p>
  </div>
  <div class="page">
    <p>Results</p>
  </div>
  <div class="page">
    <p>H1: Effects of On-demand Interface</p>
    <p>p &lt; 0.001No difference</p>
  </div>
  <div class="page">
    <p>H3: Effects of Privacy Risk Pre-specified Budget</p>
    <p>H3.2: Effects of Low Pre-specified Budget</p>
    <p>p &lt; 0.012 p &lt; 0.001</p>
  </div>
  <div class="page">
    <p>Time to complete the task: 36 pairs</p>
    <p>No significant difference</p>
    <p>Needs further work</p>
    <p>No difference 54</p>
  </div>
  <div class="page">
    <p>Expert Study Results Compared to Full access to PII</p>
    <p>Five of the experts normally conducted record linkage with full access to PII</p>
    <p>They perceived that this system</p>
    <p>o offered more privacy protection</p>
    <p>o with little to no impact on accuracy in the linkage</p>
    <p>o but may take more time</p>
    <p>Evidence for improving linkage (i.e., more consistent linkage decisions) by providing better processed</p>
    <p>information for decision making in place of raw data</p>
    <p>Once I got used to the coding, allowing partial disclosure helped in</p>
    <p>decision making</p>
  </div>
  <div class="page">
    <p>Expert Study Results</p>
    <p>Compared to Encryption Based No Access to PII</p>
    <p>One expert had prior experience using encryption-based methods of data hiding for private record linkage with no access to PII.</p>
    <p>Compared to the encryption-based method, this participant perceived our system</p>
    <p>o to have less protection</p>
    <p>o and require more time</p>
    <p>o but to also allow for much better accuracy</p>
    <p>This seems to agree with our goal of providing a level of access between the all or nothing that provides better accuracy than no access, but more protection than full access.</p>
    <p>I never know how well the hashing worked, or how accurate it is. It would</p>
    <p>be helpful to use this method to spot check a random sample (e.g., 5%)</p>
  </div>
  <div class="page">
    <p>Highlights on On-Demand &amp; Just-in-Time Interface Model</p>
    <p>User Study</p>
    <p>o On-demand model to satisfy minimum-necessary legal requirement (e.g., GDPR, HIPAA)</p>
    <p>o On-demand interface reduced privacy risk to 7.85% compared to 100% when all data is disclosed with little impact on decision quality or completion time</p>
    <p>o To have high quality results, you must have sufficient budget: The error results indicate that the quality of human decisions will suffer if low disclosure limits are enforced</p>
    <p>Expert Study: Positive reactions from experts in intended user population</p>
    <p>o Evidence for improving linkage (i.e., more consistent linkage decisions) by providing better processed information for decision making in place of raw data</p>
    <p>o Potential to validate results when used in conjunction with encryption based no access methods</p>
    <p>Future Works</p>
    <p>o Need to refine privacy risk score</p>
    <p>o Need to refine design considerations for possible time costs</p>
  </div>
  <div class="page">
    <p>Closing Thoughts</p>
  </div>
  <div class="page">
    <p>Closing thoughts and discussion on Information Privacy</p>
    <p>Threat model: Insider threat</p>
    <p>Insider Threat</p>
    <p>o system goals are to minimize any incidental knowledge from legitimate access</p>
    <p>o discourage against access for unauthorized purposes by authorized users</p>
    <p>Incidental</p>
    <p>o MUCH less information disclosed to significantly reduce incidental inferences (e.g. co-workers)</p>
    <p>Negligent (curious but honest)</p>
    <p>o What is the effect of a surveillance camera in discouraging bad behavior?</p>
    <p>o KEY: people must know that their behavior is being recorded AND audited</p>
    <p>Malicious</p>
    <p>o Limitation: Not full guarantees like encryption</p>
    <p>o Some guarantees on total level of disclosure</p>
  </div>
  <div class="page">
    <p>Key Technology Used in Physical Security Systems</p>
    <p>Locks: Control Access  Surveillance Camera: monitoring &amp; information</p>
    <p>accountability/transparency</p>
  </div>
  <div class="page">
    <p>Tools for information privacy: virtual secure systems</p>
    <p>More research needed in CHI</p>
    <p>Locks: Control Access (=Encryption)  Surveillance Camera (monitoring) (=CHI)</p>
    <p>o LOGS: How ???</p>
    <p>Interactive Interface: Just-in-time incremental access</p>
  </div>
  <div class="page">
    <p>Team</p>
    <p>Hye-Chung Kum: Population Informatics Lab, Texas A&amp;M University</p>
    <p>Eric D. Ragan: INDIE Lab, University of Florida</p>
    <p>Cason Schmit, JD: Population Informatics Lab, Texas A&amp;M University</p>
    <p>Students: Population Informatics Lab, Texas A&amp;M University</p>
    <p>o Gurudev Ilangovan</p>
    <p>o Mahin Ramezani</p>
    <p>o Qinbo Li</p>
    <p>Research supported</p>
    <p>by the Patient</p>
    <p>Centered Outcomes</p>
    <p>Research Institute</p>
    <p>ME-1602-34486.</p>
  </div>
  <div class="page">
    <p>Thank You!!</p>
    <p>Hye-Chung Kum (kum@tamu.edu)</p>
    <p>Population Informatics Lab (https://pinformatics.org/)</p>
    <p>Privacy is a BUDGET constrained problem</p>
    <p>The goal is to achieve the maximum utility under a fixed privacy budget</p>
    <p>Utility Privacy</p>
  </div>
</Presentation>
