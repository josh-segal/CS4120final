<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>HPCA-8: 1 February 5, 2002</p>
    <p>A New Cache Monitoring Scheme for Memory-Aware Scheduling and Partitioning</p>
    <p>G. Edward Suh Srinivas Devadas</p>
    <p>Larry Rudolph</p>
    <p>Massachusetts Institute of Technology</p>
  </div>
  <div class="page">
    <p>HPCA-8: 2 February 5, 2002</p>
    <p>Problem</p>
    <p>Memory system performance is critical  Everyone thinks about their own application</p>
    <p>Tuning replacement policies  Software/hardware prefetching</p>
    <p>But modern computer systems execute multiple applications concurrently/simultaneously  Time-shared systems</p>
    <p>Context switches cause cold misses  Multiprocessors systems sharing memory hierarchy</p>
    <p>(SMP, SMT, CMP)  Simultaneous applications compete for cache space</p>
  </div>
  <div class="page">
    <p>HPCA-8: 3 February 5, 2002</p>
    <p>Solutions: Cache Partitioning &amp; Memory-Aware Scheduling</p>
    <p>Cache Partitioning  Explicitly manage cache space allocation amongst concurrent/</p>
    <p>simultaneous processes  Each process gets different benefit from more cache space  Similar to main memory partition (e.g.. Stone 1992) in the old days</p>
    <p>Memory-Aware Scheduling  Choose a set of simultaneous processes to minimize</p>
    <p>memory/cache contention  Schedule for SMT systems (Snavely 2000)</p>
    <p>Threads interact in various ways (RUU, functional units, caches, etc)  Based on executing various schedules and profiling them</p>
    <p>Admission control for gang scheduling (Batat 2000)  Based on the footprint of a job (total memory usage)</p>
  </div>
  <div class="page">
    <p>HPCA-8: 4 February 5, 2002</p>
    <p>BUT</p>
    <p>Testing many possible schedules not viable  The number of possible schedules increase exponentially as the</p>
    <p>number of processes increase  Need to decide a good schedule from individual process</p>
    <p>characteristics complexity increases linearly</p>
    <p>Footprint-based scheduling not enough information  Footprint of a process is often larger than the cache  Processes may not need the entire working set in the cache</p>
    <p>Can we find a good schedule for cache performance?  What information do we need for each process?</p>
  </div>
  <div class="page">
    <p>HPCA-8: 5 February 5, 2002</p>
    <p>Information a Scheduler/Partitioner Needs</p>
    <p>Characterizing a process  For scheduling and partitioning, need to know the effect of</p>
    <p>varying cache size  Multiple performance numbers for different cache sizes  Ignore other effects than cache size</p>
    <p>Miss-rate curves; m(c)  Cache miss-rates as a function of cache</p>
    <p>size (cache blocks)  Assume a process is isolated  Assume the cache is FULLY-ASSOCIATIVE</p>
    <p>Provides essential information for scheduling and partitioning</p>
    <p>Cache Space (%)</p>
    <p>M is</p>
    <p>sra</p>
    <p>te</p>
  </div>
  <div class="page">
    <p>HPCA-8: 6 February 5, 2002</p>
    <p>Using Miss-Rate Curves for Partitioning</p>
    <p>What do miss-rate curves tell about cache allocation?</p>
    <p>Cache Space (%)</p>
    <p>M is</p>
    <p>sra</p>
    <p>te</p>
    <p>Cache Space (%)</p>
    <p>M is</p>
    <p>sra</p>
    <p>te</p>
    <p>Process A Process B</p>
    <p>cA cB</p>
    <p>Cache misses</p>
    <p>mA(cA)refA+ mB(cB)refB</p>
    <p>Cache Allocation</p>
    <p>A B</p>
  </div>
  <div class="page">
    <p>HPCA-8: 7 February 5, 2002</p>
    <p>Finding the best allocation</p>
    <p>Use marginal gain; g(c) = m(c) ref - m(c+1)ref  Gain in the number of misses by increasing the cache space</p>
    <p>Allocate cache blocks to each process in a greedy manner  Guaranteed to result in the optimal partition if m(c) are convex</p>
    <p>Cache Space (Blocks)</p>
    <p>M ar</p>
    <p>gi na</p>
    <p>l G ai</p>
    <p>n (H</p>
    <p>its )</p>
    <p>Process A</p>
    <p>Process B</p>
    <p>Cache Allocation</p>
    <p>Initially no cache block is allocated</p>
    <p>Compare Marginal Gains 987 &lt; 2111</p>
    <p>B</p>
    <p>Allocate a block to Process B</p>
    <p>Compare Marginal Gains 987 &gt; 1568</p>
    <p>Allocate a block to Process B</p>
    <p>B</p>
    <p>Compare Marginal Gains 987 &gt; 746</p>
    <p>A</p>
    <p>Allocate a block to Process A</p>
    <p>Compare Marginal Gains 409 &lt; 746</p>
    <p>B</p>
    <p>Allocate a block to Process B</p>
  </div>
  <div class="page">
    <p>HPCA-8: 8 February 5, 2002</p>
    <p>Partitioning Results</p>
    <p>L2 Size (MB)</p>
    <p>IP C LRU</p>
    <p>Partition</p>
    <p>Partition the L2 cache amongst two simultaneous processes (spec2000 benchmarks: art and mcf )</p>
  </div>
  <div class="page">
    <p>HPCA-8: 9 February 5, 2002</p>
    <p>Intuition for Memory-Aware Scheduling</p>
    <p>How to schedule 4 processes on 2 processor system using individual miss-rate curves?</p>
    <p>Cache Space (%)</p>
    <p>M is</p>
    <p>sra</p>
    <p>te</p>
    <p>Cache Space (%)</p>
    <p>M is</p>
    <p>sra</p>
    <p>te</p>
    <p>Cache Space (%)</p>
    <p>M is</p>
    <p>sra</p>
    <p>te</p>
    <p>Cache Space (%)</p>
    <p>M is</p>
    <p>sra</p>
    <p>te</p>
    <p>Curves tend to have a knee The amount of cache</p>
    <p>space where the marginal gain diminishes a lot</p>
    <p>Group processes based on the knees</p>
    <p>Process A Process B</p>
    <p>Process DProcess C</p>
    <p>Working set size is larger than the cache for all processes</p>
    <p>All processes result in similar miss-rate if they have the entire cache</p>
    <p>Schedule A and C, and B and D together</p>
  </div>
  <div class="page">
    <p>HPCA-8: 10 February 5, 2002</p>
    <p>Determining the Knee of the Curve</p>
    <p>Use partitioning technique</p>
    <p>Cache Space (Blocks)</p>
    <p>M ar</p>
    <p>gi na</p>
    <p>l G ai</p>
    <p>n (H</p>
    <p>its )</p>
    <p>Process A</p>
    <p>Process B</p>
    <p>Cache Allocation</p>
    <p>However, now we may need multiple time slices to schedule processes (2 time slices in our example)</p>
    <p>Available cache resource should be doubled</p>
    <p>Cache Allocation</p>
  </div>
  <div class="page">
    <p>HPCA-8: 11 February 5, 2002</p>
    <p>Scheduling Results</p>
    <p>Schedule 6 SPEC CPU benchmarks for 2 Processors</p>
    <p>Memory Size (MB)</p>
    <p>N or</p>
    <p>m al</p>
    <p>iz ed</p>
    <p>M is</p>
    <p>sra</p>
    <p>te</p>
    <p>Worst Best Scheduling Algorithm</p>
  </div>
  <div class="page">
    <p>HPCA-8: 12 February 5, 2002</p>
    <p>Analytical Model (ICS`01)</p>
    <p>Time Quantum (# of cache accesses)</p>
    <p>M is</p>
    <p>sra</p>
    <p>te</p>
    <p>LRU Partition</p>
    <p>Miss-rate curves (or marginal gains) alone may not be enough for optimizing time-shared systems  Partitioning amongst concurrent processes  Scheduling considering the effects of context switches</p>
    <p>Use analytical model to predict cache-sharing effects</p>
    <p>(bzip2+gcc+swim+ mesa+vortex+vpr+t</p>
    <p>wolf+iu)</p>
  </div>
  <div class="page">
    <p>HPCA-8: 13 February 5, 2002</p>
    <p>BUT</p>
    <p>Processes to execute are only known at run-time  Users decide what applications to run  Scheduling/Partitioning decisions should be made at run-time</p>
    <p>The behavior of a process changes over time  Applications have different phases  Miss-rates curves (and marginal gains) may change over an</p>
    <p>execution</p>
    <p>Cache configurations are different for systems  Miss-rate curves (and marginal gains) are different for systems</p>
    <p>Need an on-line estimation of miss-rate curves (and marginal gains)</p>
  </div>
  <div class="page">
    <p>HPCA-8: 14 February 5, 2002</p>
    <p>On-Line Estimation of Marginal Gains: Fully-Associative Caches</p>
    <p>Marginal gains can be directly counted based on the temporal ordering of cache blocks (LRU information)  Use one counter per each cache block (or a group of cache</p>
    <p>blocks) and one for counting all accesses  Hit on the ith MRU Increment ith counter</p>
    <p>Example: a FA cache with 4 blocks</p>
    <p>Block</p>
    <p>Increment the 3th</p>
    <p>Counter</p>
    <p>Access Counter</p>
    <p>Increment the 1st</p>
    <p>Counter 2433</p>
    <p>the MRU Cache Block</p>
    <p>Cache Space (Blocks)</p>
    <p>M ar</p>
    <p>gi na</p>
    <p>l G ai</p>
    <p>n</p>
    <p>Marginal-Gain Counters</p>
    <p>Cache Blocks</p>
  </div>
  <div class="page">
    <p>HPCA-8: 15 February 5, 2002</p>
    <p>BUT</p>
    <p>Most caches are SET-ASSOCIATIVE  Except main memory  Usually up to 8-way associative</p>
    <p>Set-associative caches only maintain temporal ordering within a set  No global temporal ordering</p>
    <p>Cannot use block-by-block temporal ordering to obtain marginal gains for fully-associative caches</p>
  </div>
  <div class="page">
    <p>HPCA-8: 16 February 5, 2002</p>
    <p>Way-Counters</p>
    <p>Way-Counters  Use the existing LRU information within a set  One counter per way (D-way cacehs D counters)  Hit on the ith MRU Increment ith counter</p>
    <p>Each way-counter represents the gain of having S more blocks (S is the number of sets)</p>
    <p>Associative Cache</p>
    <p>S sets</p>
    <p>Way Counters 4384 376 121 31</p>
    <p>Access Counter 5012</p>
    <p>Hit on the MRU</p>
    <p>Cache Block</p>
    <p>Increment the 1st</p>
    <p>Counter</p>
    <p>Hit on the 2nd MRU Cache Block</p>
    <p>Increment the 2nd Counter</p>
    <p>Cache Size (Blocks)</p>
    <p>M is</p>
    <p>sR</p>
    <p>at e</p>
    <p>Way-Counter</p>
    <p>Fully-Ass ociative</p>
  </div>
  <div class="page">
    <p>HPCA-8: 17 February 5, 2002</p>
    <p>Way+Set Counters</p>
    <p>Use more counters for more detailed information  Maintain the LRU information of sets  Hit on the ith MRU way and jth MRU set Increment counter(i,j)</p>
    <p>Cache</p>
    <p>Counters</p>
    <p>Access Counter</p>
    <p>Group 0</p>
    <p>Group 1</p>
    <p>Group S</p>
    <p>Increment the Counter</p>
    <p>(0,1)</p>
    <p>Hit on the MRU way</p>
    <p>the 2nd MRU group</p>
    <p>Temporal Ordering Of</p>
    <p>Set Groups</p>
    <p>Cache Size (Blocks)</p>
    <p>M is</p>
    <p>sR</p>
    <p>at e</p>
    <p>Way-Counter (2-way) Way+Set (8 Groups) Way+Set (16 Groups) Fully-Associative</p>
  </div>
  <div class="page">
    <p>HPCA-8: 18 February 5, 2002</p>
    <p>Summary</p>
    <p>Caches should be managed more carefully considering the effect of space/time-sharing  Cache Partitioning  Memory-Aware Scheduling</p>
    <p>Miss-rate curves provide very relevant information for scheduling and partitioning  Enables us to predict the effect of varying the cache space  Useful for any tradeoff between performance and space (power)</p>
    <p>On-line counters can estimate miss-rate curves at runtime  Use the temporal ordering of blocks to predict miss-rates for</p>
    <p>smaller caches  Works for both fully-associative and set-associative caches</p>
  </div>
</Presentation>
