<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Guessing Preferences: A New Approach to Multi-Attribute Ranking &amp; Selection</p>
    <p>Peter I. Frazier* and Aleksandr M. Kazachov** * Cornell University, Operations Research and Information Engineering ** Carnegie Mellon University, PhD program in Algorithms Combinatorics and Optimization</p>
  </div>
  <div class="page">
    <p>Contributions of this Work</p>
    <p>We consider multi-objective (or multi-attribute) optimization, where each objective can only be evaluated through simulation.</p>
    <p>We contribute:</p>
    <p>(1) A new measure of the quality of an estimate of the Pareto frontier.</p>
    <p>(2) A new algorithm for allocating samples to optimize this quality measure.</p>
    <p>Objective 1</p>
    <p>O b</p>
    <p>jective 2</p>
  </div>
  <div class="page">
    <p>Related Work</p>
    <p>Multi-objective optimization via simulation:</p>
    <p>Multi-objective OCBA: Lee, Teng, Chew, Lye, Lendermann, Karimi, Chen, &amp; Koh 2005; Lee, Chew, &amp; Teng 2007; Chen &amp; Lee 2009; Lee, Chew, Teng, &amp; Goldsman 2010; R&amp;S with stochastic constraints: Andradottir, Goldsman, &amp; Kim 2005; Andradottir &amp; Kim 2010; Luo &amp; Lim 2011; and others; Sample average approximation: Kim &amp; Ryu 2011; MO-COMPASS: Lee, Chew, Li 2011.</p>
    <p>Multi-objective global optimization of expensive functions (usually noise free): Keane 2006; Bautista 2009; Knowles 2006; Forrester, Sobester, &amp; Keane 2008.</p>
    <p>Measures of the quality of an estimate of the Pareto frontier: Faulkenberg &amp; Wiecek 2010; Sayin 2000; Zitzler, Knowles, &amp; Thiele; Leung &amp; Wang 2003; Meng, Zhang &amp; Liu 2005; Zitzler, Brockhoff, &amp; Thiele 2007; Zitzler, Thiele, Laumanns, Foneseca, &amp; V. Fonseca 2003.</p>
    <p>Putting a Bayesian prior on DMs utility function to allow efficient utility elicitation: Chajewska, Koller, &amp; Parr 2000; Boutilier 2002; Abbas 2004.</p>
  </div>
  <div class="page">
    <p>We Begin with an Example</p>
    <p>A scientist has just been awarded a research grant, which includes a fixed budget of $25K to build a parallel high-performance computing system.</p>
    <p>How should she allocate this money across different types of hardware?</p>
    <p>How many compute nodes? What type of CPUs? How much storage and what type? What type of interconnect?</p>
    <p>?</p>
  </div>
  <div class="page">
    <p>Choice of hardware depends on the compute job</p>
    <p>The appropriate choice of hardware depends on the type of compute job.</p>
    <p>The scientist DM needs to run 2 types of compute jobs.</p>
    <p>Job type A is CPU intensive. It will be faster if the system has fast CPUs.</p>
    <p>Job type B is I/O intensive. It will run faster if the system has fast disk and interconnect.</p>
    <p>Job A Performance</p>
    <p>Job B Performance</p>
    <p>System 3 $$$ I/O, $ CPU</p>
    <p>System 1 $ I/O, $$$ CPU</p>
    <p>System 2 $$ I/O, $$ CPU</p>
  </div>
  <div class="page">
    <p>The scientist decision-maker (DM) asks for advice</p>
    <p>The DM asks her contact in the universitys research IT department for advice:</p>
    <p>Please help me choose the design of my new computing system.</p>
    <p>I need it to run the following types of compute jobs....</p>
    <p>Analyst from IT department</p>
  </div>
  <div class="page">
    <p>One approach: Elicit the DMs preferences before optimizing</p>
    <p>Which of these hypothetical systems</p>
    <p>would you prefer?</p>
    <p>A</p>
    <p>B</p>
  </div>
  <div class="page">
    <p>Now which of these of hypothetical systems?</p>
    <p>A</p>
    <p>B</p>
    <p>One approach: Elicit the DMs preferences before optimizing</p>
  </div>
  <div class="page">
    <p>Now which of these hypothetical systems?</p>
    <p>A</p>
    <p>B</p>
    <p>One approach: Elicit the DMs preferences before optimizing</p>
  </div>
  <div class="page">
    <p>I now know your utility function!! It is</p>
    <p>where the vector c is</p>
    <p>A</p>
    <p>B</p>
    <p>Excuse me while I go find a real system that</p>
    <p>optimizes that.</p>
    <p>One approach: Elicit the DMs preferences before optimizing</p>
    <p>c = [cA, cB]</p>
    <p>U(x) = c  v(x)</p>
  </div>
  <div class="page">
    <p>In some situations, we cannot elicit the DMs preferences before optimizing.</p>
    <p>I am busy.</p>
    <p>I do not have time to have my preferences elicited.</p>
    <p>Give me an estimate of the Pareto frontier &amp; I will use that to make my decision.</p>
  </div>
  <div class="page">
    <p>The IT analyst uses simulation to estimate the Pareto frontier.</p>
    <p>Job A Performance</p>
    <p>Job B Performance</p>
    <p>Samples for system 1</p>
    <p>The IT department has a stochastic simulator. Given a system configuration, this simulator can sample the systems response time for each job type.</p>
    <p>For simplicity, suppose we care only about a single expected performance measure for each job type, e.g., expected number of jobs of each type that can be finished in 1 hour.</p>
  </div>
  <div class="page">
    <p>Let be the expected performance vector for system x.</p>
    <p>Let be our estimate of this vector.</p>
    <p>We estimate performance from simulation samples.</p>
    <p>Job A Performance</p>
    <p>Job B Performance</p>
    <p>Samples for system 1</p>
    <p>Estimator of expected</p>
    <p>performance for system 1</p>
    <p>v(x) = [vA(x), vB(x)]</p>
    <p>v(x) = [vA(x), vB(x)]</p>
    <p>Expected performance for system 1</p>
  </div>
  <div class="page">
    <p>Because of sampling noise, estimates are imperfect</p>
    <p>Job A Performance</p>
    <p>Job B Performance</p>
    <p>v(x) != v(x)</p>
  </div>
  <div class="page">
    <p>If we could take an infinite number of samples from each system, estimates would be perfect.</p>
    <p>Job A Performance</p>
    <p>Job B Performance</p>
    <p>v(x) = v(x)</p>
  </div>
  <div class="page">
    <p>Given perfect estimates, the DM would choose among points on the Pareto frontier.</p>
    <p>Job A Performance</p>
    <p>Job B Performance</p>
  </div>
  <div class="page">
    <p>I choose this one!</p>
    <p>Given perfect estimates, the DM would choose among points on the Pareto frontier.</p>
    <p>Job A Performance</p>
    <p>Job B Performance</p>
  </div>
  <div class="page">
    <p>Had I known, I</p>
    <p>would have chosen this</p>
    <p>system.</p>
    <p>The DM suffers some loss from imperfect estimates.</p>
    <p>Job A Performance</p>
    <p>Job B Performance</p>
  </div>
  <div class="page">
    <p>Central Questions</p>
  </div>
  <div class="page">
    <p>Recap: The analyst shows estimates to the DM; Then the DM chooses, suffering some loss.</p>
    <p>Here are my estimates .</p>
    <p>This one seems best, but I might have some loss because</p>
    <p>v(x) != v(x)</p>
    <p>A</p>
    <p>B</p>
    <p>A</p>
    <p>B</p>
    <p>v(x)</p>
  </div>
  <div class="page">
    <p>What is the DMs loss?</p>
    <p>We suppose the DMs utility is for some vector . The analyst does not know and does not try to elicit it. Note: this linear form disallows non-convex Pareto sets.</p>
    <p>Given systems with estimated performances, the DM can determine which would provide her with the most utility, if the estimates were correct. Based on the estimates provided, she chooses</p>
    <p>U(x) = c  v(x) c c</p>
    <p>x(c) = arg max x</p>
    <p>c  v(x)</p>
    <p>L(v, v, c) = c  v(x!(c)) ! c  v(x(c))  Her loss is the difference in utility between the two choices</p>
    <p>x!(c) = arg max x</p>
    <p>c  v(x)  Had the estimates been perfect, she would have chosen</p>
  </div>
  <div class="page">
    <p>The DMs loss is unknown to the analyst.</p>
    <p>The DMs loss is</p>
    <p>L(v, v, c) = c  v(x!(c)) ! c  v(x(c))</p>
    <p>This depends on the DMs preferences through the vector , which is unknown to the analyst.</p>
    <p>How can the analyst minimize the loss without knowing ?</p>
    <p>c</p>
    <p>c</p>
  </div>
  <div class="page">
    <p>The analyst has intuition about the DMs utility.</p>
    <p>Based on my past experience, and my conversation with the DM,</p>
    <p>its most likely her preference is this:</p>
    <p>Also, theres a 90% chance her preference falls in this range:</p>
    <p>A</p>
    <p>B</p>
    <p>A</p>
    <p>B</p>
  </div>
  <div class="page">
    <p>where are fixed values and .</p>
    <p>Recall: where the vector c is unknown.</p>
    <p>We suppose that the simulation analyst has a Bayesian prior distribution on the vector c. This prior distribution can be continuous or discrete.</p>
    <p>Our algorithm is nicer if this prior is discrete,</p>
    <p>We model the analysts intuition with a Bayesian prior distribution on the DMs utility.</p>
    <p>! = 1, . . . , L</p>
    <p>A</p>
    <p>B</p>
    <p>U(x) = c  v(x)</p>
    <p>c P(c = c!) = p!</p>
    <p>c!, p!</p>
  </div>
  <div class="page">
    <p>We measure the quality of our estimate with the expected loss suffered by the DM.</p>
    <p>Given c, the DMs loss from estimation error is</p>
    <p>L(v, v, c) = c  v(x!(c)) ! c  v(x(c))  With our prior on c, the loss from estimation error is</p>
    <p>L(v, v) = E[L(v, v, c)|v, v]  When our prior is discrete, this can be written,</p>
    <p>L(v, v) = L!</p>
    <p>!=1</p>
    <p>p!L(v, v, c!)</p>
    <p>This is a general measure of the quality of an estimated Pareto frontier.</p>
  </div>
  <div class="page">
    <p>We use a standard Bayesian framework to model uncertainty about the sampling means.</p>
    <p>We assume that samples are independent and normally distributed.</p>
    <p>We suppose an independent Bayesian prior distribution on the sampling means and variances,</p>
    <p>We obtain a Bayesian posterior distribution after sampling.</p>
    <p>vj(x)|!j(x) ! Normal(0jx, !j(x)/&quot;0jx) 1/!j(x) ! Gamma(a0jx, b0jx)</p>
    <p>vj(x)|!j(x) ! Normal(njx, !j(x)/&quot;njx) 1/!j(x) ! Gamma(anjx, bnjx)</p>
    <p>yj(x) ! Normal(vj(x), !j(x))</p>
  </div>
  <div class="page">
    <p>The Bayesian posterior distribution implies a Bayesian expected loss</p>
    <p>Our Bayesian posterior distribution after sampling is</p>
    <p>The Bayes-optimal estimate is the posterior mean</p>
    <p>Our Bayesian expected loss at time n is</p>
    <p>vj(x)|!j(x) ! Normal(njx, !j(x)/&quot;njx) 1/!j(x) ! Gamma(anjx, bnjx)</p>
    <p>where is the expectation with respect to the posterior distribution.En</p>
    <p>v(x) = En[v(x)] = !nx</p>
    <p>En[L(v, v)] = En[max x</p>
    <p>c  v(x)] ! max x</p>
    <p>c  !nx</p>
  </div>
  <div class="page">
    <p>We derive a knowledge-gradient allocation method for this loss function.</p>
    <p>We define the knowledge-gradient (KG) factor to be the expected one-step reduction in loss,</p>
    <p>The knowledge-gradient policy allocates the next sample to the one that maximizes this one-step benefit,</p>
    <p>The KG factor can be computed analytically if the sampling variance is known. We use an adaptively updated point estimate of the variance as an approximation when the variance is unknown.</p>
    <p>xn+1 ! arg max x</p>
    <p>KGnx</p>
    <p>KGnx = En !&quot;</p>
    <p>max x!</p>
    <p>c  !n+1,x! # !</p>
    <p>&quot; max x!</p>
    <p>c  !n,x! # |xn+1 = x</p>
    <p>$</p>
  </div>
  <div class="page">
    <p>Details of the knowledge-gradient policy</p>
    <p>When the sampling variances are known and the prior on c is discrete, the KG factor is</p>
    <p>We then obtain a vector of point estimates and choose to sample next,!n</p>
    <p>xn+1 ! arg max x</p>
    <p>KGnx(!n)</p>
    <p>KGnx(!) = L!</p>
    <p>!=1</p>
    <p>p!&quot;nx(c, !)f</p>
    <p>&quot; !!nx(c) &quot;nx(c, !)</p>
    <p>#</p>
    <p>(!nx(c, &quot;)) 2 =</p>
    <p>m!</p>
    <p>j=1</p>
    <p>c2j &quot;xj</p>
    <p>#nxj(#nxj + 1) ,</p>
    <p>f(d) = d!(d) + $(d),</p>
    <p>&quot;nx(c) =</p>
    <p>&quot;&quot;&quot;&quot;c  %nx ! maxx! !=x c  %nx!</p>
    <p>&quot;&quot;&quot;&quot; .</p>
    <p>where</p>
  </div>
  <div class="page">
    <p>Numerical Results</p>
    <p>1 0.5 0 0.5 1 1.5 1</p>
    <p>0.5</p>
    <p>Theta 1</p>
    <p>Th et</p>
    <p>a 2</p>
    <p>True mean Estimate by KG policy</p>
    <p>1 0.5 0 0.5 1 1.5 1</p>
    <p>0.5</p>
    <p>Theta 1</p>
    <p>Th et</p>
    <p>a 2</p>
    <p>True mean Estimate by KG policy</p>
    <p>Prior says horizontal objective is likely to be more important. More samples are allocated to</p>
    <p>alternatives with good horizontal values, giving better estimates.</p>
    <p>Prior says vertical objective is likely to be more important.</p>
    <p>More samples are allocated to alternatives with good vertical values, giving better estimates.</p>
  </div>
  <div class="page">
    <p>Numerical Results</p>
    <p>Iteration</p>
    <p>A ve</p>
    <p>ra ge</p>
    <p>V al</p>
    <p>ue</p>
    <p>KG Policy Equal Allocation</p>
    <p>Expected reward vs the number of samples taken (after an initial stage of 5 samples per alternative completes). Parameters: 20 systems, sampling variance of 1, homogeneous prior means, 5 equi-probable values of c. Maximum standard error is 0.011.</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>We presented a new way to think about Pareto frontier estimation, and the quality of a Pareto frontier.</p>
    <p>We presented a new KG algorithm based on this measure. Other algorithmic approaches can also use this measure.</p>
    <p>Future work:  Compare this measure of the Pareto frontier to other measures.  Compare the KG algorithm to other multi-objective algorithms.  Incorporate correlated prior distributions.  Incorporate noisy information from DM about preferences.</p>
  </div>
  <div class="page">
    <p>Thank You!</p>
  </div>
</Presentation>
