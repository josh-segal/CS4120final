<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Correlation Clustering: Maximizing Agreements via Semidefinite Programming</p>
    <p>Chaitanya Swamy Cornell University</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Correlation Clustering</p>
    <p>Graph G=(V,E)</p>
    <p>Partition V into clusters s.t.</p>
    <p>+ edges are within clusters</p>
    <p>edges are across clusters.</p>
    <p>No bound on # of clusters.</p>
    <p>Edges are labeled + or . +</p>
    <p>+</p>
    <p>+</p>
    <p>+</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Agreements and Disagreements</p>
    <p>+</p>
    <p>+</p>
    <p>+</p>
    <p>+</p>
    <p>Agreements + edges inside clusters AND  edges outside clusters.</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Agreements and Disagreements</p>
    <p>Agreements + edges inside clusters AND  edges outside clusters.</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Agreements and Disagreements</p>
    <p>+</p>
    <p>+</p>
    <p>+</p>
    <p>+</p>
    <p>Agreements + edges inside clusters AND  edges outside clusters. Disagreements (mistakes) + edges outside clusters AND  edges inside clusters.</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Can either Maximize Agreements</p>
    <p>OR Minimize</p>
    <p>Disagreements</p>
    <p>Disagreements (mistakes) + edges outside clusters AND  edges inside clusters.</p>
    <p>Agreements and Disagreements</p>
    <p>Agreements + edges inside clusters AND  edges outside clusters.</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Previous Work Bansal, Blum &amp; Chawla (BBC02): Introduced the problem and showed it is NP-Hard even on complete graphs.</p>
    <p>a) Minimizing Disagreements</p>
    <p>Bansal et al. gave a constant-approximation for complete graphs.</p>
    <p>Demaine &amp; Immorlica Emanuel &amp; Fiat Charikar, Guruswami &amp; Wirth (CGW03)</p>
    <p>Charikar et al. give a 4-approx. for the problem on complete graphs and show it is MAXSNPHard.</p>
    <p>Independently showed that min. disagreements on general graphs is multicut-hard.</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Previous Work (contd.)</p>
    <p>b) Maximizing Agreements</p>
    <p>Bansal et al. gave a (1-)-approximation for any &gt;0 when |E|=(|V|2).</p>
    <p>Charikar et al. showed that max. agreements in general graphs is MAXSNP-Hard, i.e., there exists &gt;0 s.t. cannot get better than (1-)-approx. unless P=NP.</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Our Results</p>
    <p>Give a 0.7666-approx. algorithm for maximizing agreements.</p>
    <p>Works even if we have a multigraph with edge weights.</p>
    <p>Extends to the k-clustering variant where at most k clusters may be created.</p>
    <p>Independently, CGW03 have also given a const.- approx. for maximizing agreements.</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>A Few Applications</p>
    <p>Document clustering (BBC02): Nodes are documents, + edges  similar documents,  edges  dissimilar documents.</p>
    <p>Learning edge labels (BBC02): Represent target function f : VxV  {+, } using a hypothesis class of vertex clusters.</p>
    <p>See also Emanuel &amp; Fiat.</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Trivial 0.5-approximation</p>
    <p>G=(V,E), m = |E| = (# of + edges) + (# of  edges).</p>
    <p>If (# of + edges)  m/2, all nodes in one big cluster.</p>
    <p>If (# of  edges) &gt; m/2, each node in separate cluster.</p>
    <p>Get # of agreements  m/2  OPT/2. Hence, a 0.5-approximation algorithm.</p>
    <p>Observed by Bansal et al.</p>
    <p>There are graphs such that OPT  m/2, so need a better upper bound.</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>A Semidefinite Relaxation Let n=|V|, E+ = set of + edges, E = set of  edges. e1,  ,en : mutually orthogonal unit vectors in n.</p>
    <p>Each ei represents a possible cluster. Setting xu = ei u is assigned to cluster i.</p>
    <p>Maximize (u,v)E+xu .xv + (u,v)E(1</p>
    <p>xu.xv)</p>
    <p>subject to xu  {e1,  ,en} for every uV.</p>
    <p>xu.xu = 1 for every uV,</p>
    <p>xu.xv  0 for every u,vV, u  v.</p>
    <p>Can solve (SP) in polynomial time. Optimal solution value is an upper bound on OPT.</p>
    <p>(SP)</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Semidefinite Programming Matrix Y is (symmetric) positive semidefinite  Y=XTX for some matrix X. SDP is a quadratic program of the form:</p>
    <p>minimize cijYij s.t. A (k)</p>
    <p>Yij = bk, k=1,, m, Y 0</p>
    <p>ij ij ij</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Semidefinite Program (SP)</p>
    <p>Let n=|V|, E+ = set of + edges, E = set of  edges.</p>
    <p>Maximize (u,v)E+xu .xv + (u,v)E</p>
    <p>(1-xu.xv) (SP)</p>
    <p>subject to xu.xu = 1 for every uV,</p>
    <p>xu.xv  0 for every u,vV, u  v.</p>
    <p>Can solve (SP) in polynomial time. Optimal solution value is an upper bound on OPT.</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Semidefinite Programming</p>
    <p>Goemans &amp; Williamson first applied SDP in approximation algorithms. Gave a 0.878-approx. for MAXCUT by using a random hyperplane method for rounding SDPs.</p>
    <p>Karger, Motwani &amp; Sudan (KMS94) used multiple hyperplanes for graph coloring. Introduced random spoke rounding.</p>
    <p>Frieze &amp; Jerrum (FJ95) used random spoke method for MAX-k-CUT.</p>
    <p>Matrix Y is (symmetric) positive semidefinite  Y=XTX for some matrix X. SDP is a quadratic program of the form:</p>
    <p>minimize cijYij s.t. A (k)</p>
    <p>Yij = bk, k=1,, m, Y 0</p>
    <p>ij ij ij</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Rounding (SP) Let (xu)uV be an optimal solution to (SP)</p>
    <p>O*  OPT be the optimal solution value. If xu, xv are</p>
    <p>close want u, v to be in same cluster.</p>
    <p>If xu, xv are far apart want u, v to be in separate clusters.</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Rounding (SP) contd.</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Rounding (SP) contd.</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Rounding (SP) contd.</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Rounding (SP) contd.</p>
    <p>Always form at most 4 clusters.</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Analysis</p>
    <p>Consider vertices u, v.</p>
    <p>Let xu.xv = cos .</p>
    <p>Basic Fact</p>
    <p>Pr[u, v are in same cluster] = Pr[no hyperplane separates xu, xv]</p>
    <p>= (1-/)2 = pin().</p>
    <p>Let pout() = 1-pin()</p>
    <p>= Pr[u, v are in separate clusters]</p>
    <p>xu xv</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Analysis (contd.)</p>
    <p>Lemma: pin()  0.75(cos ), pout()  0.75(1-cos ) for  [0,/2].</p>
    <p>This will show algorithm is a 0.75-approx. algorithm since,</p>
    <p>E[agreements] = (u,v)E+Pr[u, v are in same</p>
    <p>cluster] +</p>
    <p>(u,v)EPr[u, v are in separate</p>
    <p>clusters]</p>
    <p>(u,v)E+0.75(xu .xv) + (u,v)E0.75(1</p>
    <p>xu.xv)</p>
    <p>= 0.75.O*  0.75.OPT.</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Proof of Lemma By picture.</p>
    <p>pin() (cos ) pout()</p>
    <p>(1  cos ) 0.75</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Improvements  Choose r random hyperplanes instead of just 2.</p>
    <p>r=1, Pr[u, v not separated]/xu.xv is large, but Pr[u, v separated]/(1-xu.xv) is only  0.5.</p>
    <p>r3, Pr[u, v separated]/(1-xu.xv) is large, but Pr[u, v not separated]/xu.xv decreases rapidly. Can take best r for the instance OR randomly choose r. Choosing the better of r=2 or 3, gives 0.7664-approx.</p>
    <p>Pick r random spokes (KMS94, FJ95), v1,,vr .</p>
    <p>Each vi creates a cluster {u : xu.vi = maxj xu.vj}. Taking r=6, better of this and earlier rounding gives a 0.7666-approx. Analysis is fairly involved and probably not tight.</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Open Questions</p>
    <p>Integrality gap of (SP) with added triangle inequalities. Can we get a better approx. ratio? Might help in improving ratio for MAXCUT.</p>
    <p>Maximizing agreements  disagreements. This is what corresponds to correlation.</p>
    <p>Minimizing disagreements: quality of semidefinite relaxations? Natural LP has a log n integrality gap.</p>
    <p>Equations in 2 vars. mod k: Constraints yuyv  a (mod k), yuyv  b (mod k). Want to maximize number of satisfied constraints. Is MAXSNP-Hard, only know of a (1/k+)-approx. algorithm.</p>
  </div>
  <div class="page">
    <p>SODA Talk, 01/200 4</p>
    <p>Thanks.</p>
  </div>
</Presentation>
