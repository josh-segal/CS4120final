<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>PRETZEL: Opening the Black Box of ML Prediction Serving Systems</p>
    <p>Yunseong Lees, Alberto Scolarip, Byung-Gon Chuns, Marco Domenico Santambrogiop, Markus Weimerm, Matteo Interlandim</p>
    <p>fi</p>
    <p>fi</p>
    <p>fi   A</p>
    <p>fi   B</p>
    <p>BS06  -</p>
    <p>'    `     ,    , ` '</p>
    <p>' .     ,</p>
    <p>,  ,'  fl .   FullColor</p>
    <p>.CD-Rom</p>
  </div>
  <div class="page">
    <p>Machine Learning Prediction Serving 1. Models are learned from data 2. Models are deployed and served together</p>
    <p>Prediction serving</p>
    <p>UsersServerData</p>
    <p>Training</p>
    <p>ModelLearn Deploy</p>
    <p>Performance goal: 1) Low latency 2) High throughput 3) Minimal resource usage</p>
  </div>
  <div class="page">
    <p>ML.Net</p>
    <p>ML Prediction Serving Systems: State-of-the-art</p>
    <p>Assumption: models are black box  Re-use the same code in training phase</p>
    <p>Encapsulate all operations into a function call (e.g., predict())</p>
    <p>Apply external optimizations</p>
    <p>TF ServingClipper</p>
    <p>Prediction Serving System</p>
    <p>Pretzel is tasty</p>
    <p>cat</p>
    <p>car</p>
    <p>Text Analysis</p>
    <p>Image Recognition</p>
    <p>Result caching</p>
    <p>Replication</p>
    <p>ensemble Request Batching</p>
  </div>
  <div class="page">
    <p>How do Models Look inside Boxes?</p>
    <p>&lt;Example: Sentiment Analysis&gt;</p>
    <p>Pretzel is tasty Model J vs. L (text) (positive vs. negative)</p>
  </div>
  <div class="page">
    <p>Tokenizer</p>
    <p>How do Models Look inside Boxes?</p>
    <p>&lt;Example: Sentiment Analysis&gt;</p>
    <p>Pretzel is tasty</p>
    <p>Char Ngram</p>
    <p>Word Ngram</p>
    <p>Concat Logistic Regression</p>
    <p>DAG of Operators</p>
    <p>J vs. L</p>
    <p>Featurizers Predictor</p>
  </div>
  <div class="page">
    <p>Tokenizer</p>
    <p>How do Models Look inside Boxes?</p>
    <p>&lt;Example: Sentiment Analysis&gt;</p>
    <p>Pretzel is tasty</p>
    <p>Char Ngram</p>
    <p>Word Ngram</p>
    <p>Concat Logistic Regression</p>
    <p>DAG of Operators</p>
    <p>J vs. L</p>
    <p>Split text into tokens</p>
    <p>Extract N-grams</p>
    <p>Merge two vectors</p>
    <p>Compute final score</p>
  </div>
  <div class="page">
    <p>Many Models Have Similar Structures</p>
    <p>Many part of a model can be re-used in other models</p>
    <p>Customer personalization, Templates, Transfer Learning</p>
    <p>Identical set of operators with different parameters</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Prediction Serving Systems  Limitations of Black Box Approaches  PRETZEL: White-box Prediction Serving System  Evaluation  Conclusion</p>
  </div>
  <div class="page">
    <p>Limitation 1: Resource Waste</p>
    <p>Resources are isolated across Black boxes</p>
    <p>(despite similarities between models)</p>
    <p>machine 9</p>
  </div>
  <div class="page">
    <p>Tokenizer</p>
    <p>Char Ngram</p>
    <p>Word Ngram</p>
    <p>Concat Log Reg</p>
    <p>Limitation 2: Inconsideration for Ops Characteristics</p>
    <p>CharNgram WordNgram Concat LogReg Others</p>
  </div>
  <div class="page">
    <p>Limitation 3: Lazy Initialization  ML.Net initializes code and memory lazily (efficient in training phase)  Run 250 Sentiment Analysis models 100 times  cold: first execution / hot: average of the rest 99  Long-tail latency in the cold case  Code analysis, Justin-time (JIT) compilation, memory allocation, etc  Difficult to provide strong Service-Level-Agreement (SLA)</p>
    <p>Tokenizer</p>
    <p>Char Ngram</p>
    <p>Word Ngram</p>
    <p>Concat Log Reg 13x</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>(Black-box) Prediction Serving Systems  Limitations of Black Box Approaches  PRETZEL: White-box Prediction Serving System  Evaluation  Conclusion</p>
  </div>
  <div class="page">
    <p>PRETZEL: White-box Prediction Serving We analyze models to optimize the internal execution</p>
    <p>We let models co-exist on the same runtime, sharing computation and memory resources</p>
    <p>We optimize models in two directions: 1. End-to-end optimizations 2. Multi-model optimizations</p>
  </div>
  <div class="page">
    <p>End-to-End Optimizations</p>
    <p>Optimize the execution of individual models from start to end 1. [Ahead-of-time Compilation]</p>
    <p>Compile operators code in advance  No JIT overhead</p>
  </div>
  <div class="page">
    <p>Multi-model Optimizations</p>
    <p>Share computation and memory across models 1. [Object Store]</p>
    <p>Share Operators parameters/weights  Maintain only one copy</p>
  </div>
  <div class="page">
    <p>System Components</p>
    <p>var fContext = ...; var Tokenizer = ...; return fPrgm.Plan();</p>
    <p>Logical Stages S1 S2 S3</p>
    <p>int[100] float[200]</p>
    <p>Params Stats</p>
    <p>Physical Stages S1 S2 S3</p>
    <p>ML.NET Model</p>
    <p>Stats</p>
    <p>Params Logical Stages Physical Stages</p>
    <p>Model Plan</p>
    <p>Runtime</p>
    <p>Object Store</p>
    <p>Scheduler</p>
    <p>FrontEnd</p>
  </div>
  <div class="page">
    <p>Prediction Serving with PRETZEL</p>
    <p>RuntimeFrontEnd</p>
    <p>Model</p>
    <p>Model Plan</p>
    <p>RuntimeRegister</p>
    <p>Analyze</p>
  </div>
  <div class="page">
    <p>System Design: Offline Phase</p>
    <p>Tokenizer</p>
    <p>Char Ngram</p>
    <p>Word Ngram</p>
    <p>Concat LogReg</p>
    <p>&lt;Model&gt; var fContext = new FlourContext(...) var tTokenizer = fContext.CSV</p>
    <p>.FromText(fields, fieldsType, sep)</p>
    <p>.Tokenize();</p>
    <p>var tCNgram = tTokenizer.CharNgram(numCNgrms, ...); var tWNgram = tTokenizer.WordNgram(numWNgrms, ...); var fPrgrm = tCNgram</p>
    <p>.Concat(tWNgram)</p>
    <p>.ClassifierBinaryLinear(cParams);</p>
    <p>return fPrgrm.Plan();</p>
    <p>&lt;Flour Program&gt;</p>
  </div>
  <div class="page">
    <p>System Design: Offline Phase</p>
    <p>var fContext = new FlourContext(...) var tTokenizer = fContext.CSV</p>
    <p>.FromText(fields, fieldsType, sep)</p>
    <p>.Tokenize();</p>
    <p>var tCNgram = tTokenizer.CharNgram(numCNgrms, ...); var tWNgram = tTokenizer.WordNgram(numWNgrms, ...); var fPrgrm = tCNgram</p>
    <p>.Concat(tWNgram)</p>
    <p>.ClassifierBinaryLinear(cParams);</p>
    <p>return fPrgrm.Plan();</p>
    <p>&lt;Flour Program&gt;</p>
    <p>Push linear predictor &amp; Remove Concat</p>
    <p>Stage 1</p>
    <p>Stage 2</p>
    <p>Group ops into stages</p>
    <p>Rule-based optimizer</p>
    <p>S1</p>
    <p>S2</p>
    <p>&lt;Model Plan&gt;</p>
    <p>Logical DAG</p>
  </div>
  <div class="page">
    <p>System Design: Offline Phase</p>
    <p>var fContext = new FlourContext(...) var tTokenizer = fContext.CSV</p>
    <p>.FromText(fields, fieldsType, sep)</p>
    <p>.Tokenize();</p>
    <p>var tCNgram = tTokenizer.CharNgram(numCNgrms, ...); var tWNgram = tTokenizer.WordNgram(numWNgrms, ...); var fPrgrm = tCNgram</p>
    <p>.Concat(tWNgram)</p>
    <p>.ClassifierBinaryLinear(cParams);</p>
    <p>return fPrgrm.Plan();</p>
    <p>&lt;Flour Program&gt;</p>
    <p>Push linear predictor &amp; Remove Concat</p>
    <p>Stage 1</p>
    <p>Stage 2</p>
    <p>Group ops into stages</p>
    <p>Rule-based optimizer</p>
    <p>S1</p>
    <p>S2</p>
    <p>&lt;Model Plan&gt;</p>
    <p>Logical DAG</p>
    <p>var fContext = new FlourContext(...) var tTokenizer = fContext.CSV</p>
    <p>.FromText(fields, fieldsType, sep)</p>
    <p>.Tokenize();</p>
    <p>var tCNgram = tTokenizer.CharNgram(numCNgrms, ...); var tWNgram = tTokenizer.WordNgram(numWNgrms, ...); var fPrgrm = tCNgram</p>
    <p>.Concat(tWNgram)</p>
    <p>.ClassifierBinaryLinear(cParams);</p>
    <p>return fPrgrm.Plan();</p>
    <p>var fContext = new FlourContext(...) var tTokenizer = fContext.CSV</p>
    <p>.FromText(fields, fieldsType, sep)</p>
    <p>.Tokenize();</p>
    <p>var tCNgram = tTokenizer.CharNgram(numCNgrms, ...); var tWNgram = tTokenizer.WordNgram(numWNgrms, ...); var fPrgrm = tCNgram</p>
    <p>.Concat(tWNgram)</p>
    <p>.ClassifierBinaryLinear(cParams);</p>
    <p>return fPrgrm.Plan(); Parameters</p>
    <p>e.g., Dictionary, N-gram Length</p>
    <p>Statisticse.g., dense vs. sparse, maximum vector size 20</p>
  </div>
  <div class="page">
    <p>System Design: Offline Phase</p>
    <p>&lt;Model Plan&gt;</p>
    <p>Logical DAG</p>
    <p>Parameters</p>
    <p>Statistics</p>
    <p>Physical Stages</p>
    <p>S1 S2</p>
    <p>Logical Stages Model1</p>
    <p>S1</p>
    <p>S2</p>
    <p>Object Store</p>
    <p>logical stages 21</p>
  </div>
  <div class="page">
    <p>System Design: Offline Phase</p>
    <p>&lt;Model Plan&gt;</p>
    <p>Logical DAG</p>
    <p>Parameters</p>
    <p>Statistics</p>
    <p>Physical Stages</p>
    <p>S1 S2 Catalog</p>
    <p>Catalog</p>
    <p>Logical Stages Model1</p>
    <p>S1</p>
    <p>S2</p>
    <p>Object Store</p>
    <p>logical stages</p>
    <p>N-gram length 1 vs. 3 Sparse vs. Dense</p>
  </div>
  <div class="page">
    <p>System Design: Online Phase</p>
    <p>Runtime</p>
    <p>Logical Stages Model1 Model2</p>
    <p>S1</p>
    <p>S2</p>
    <p>S1</p>
    <p>S2</p>
    <p>&lt;Model1, Pretzel is tasty&gt;</p>
    <p>managed by Scheduler</p>
    <p>Physical Stages</p>
    <p>along with parameters</p>
    <p>Object Store</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>(Black-box) Prediction Serving Systems  Limitations of Black box approaches  PRETZEL: White-box Prediction Serving System Evaluation  Conclusion</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Q. How PRETZEL improves performance over black-box approaches?  in terms of latency, memory and throughput</p>
    <p>500 Models from Microsoft Machine Learning Team  250 Sentiment Analysis (Memory-bound)  250 Attendee Count (Compute-bound)</p>
    <p>System configuration  16 Cores CPU, 32GB RAM  Windows 10, .Net core 2.0</p>
  </div>
  <div class="page">
    <p>Evaluation: Latency</p>
    <p>Micro-benchmark (No server-client communication)  Score 250 Sentiment Analysis models 100 times for each  Compare ML.Net vs. PRETZEL</p>
    <p>CD F</p>
    <p>(% )</p>
    <p>ML.Net (hot)</p>
    <p>ML.Net (cold)</p>
    <p>P99 (hot) P99 (cold) Worst (cold)</p>
    <p>ML.Net PRETZEL P99 (hot) 0.6 P99 (cold) 8.1 Worst (cold)</p>
    <p>ML.Net PRETZEL P99 (hot) 0.6 0.2 P99 (cold) 8.1 0.8 Worst (cold)</p>
    <p>ML.Net PRETZEL P99 (hot) 0.6 0.2 P99 (cold) 8.1 0.8 Worst (cold) 280.2 6.2</p>
    <p>CD F</p>
    <p>(% )</p>
    <p>PR ET</p>
    <p>ZE L</p>
    <p>(h ot</p>
    <p>)</p>
    <p>PR ET</p>
    <p>ZE L</p>
    <p>(c ol</p>
    <p>d) 0.6 8.1 0.2 0.8</p>
  </div>
  <div class="page">
    <p>Measure Cumulative Memory Usage after loading 250 models  Attendee Count models (smaller size than Sentiment Analysis)  4 settings for Comparison</p>
    <p>Evaluation: Memory</p>
    <p>better 0 50 100 150 200 250</p>
    <p>Number of pipelines 10MB</p>
    <p>Cu m</p>
    <p>ul at</p>
    <p>iv e</p>
    <p>M em</p>
    <p>or y</p>
    <p>Us ag</p>
    <p>e (</p>
    <p>lo g</p>
    <p>sc al</p>
    <p>ed )</p>
    <p>Shared Runtime</p>
    <p>ML.Net + Clipper</p>
    <p>ML.Net  PRETZEL without ObjectStore  PRETZEL</p>
    <p>Cu m</p>
    <p>ul at</p>
    <p>iv e</p>
    <p>M em</p>
    <p>or y</p>
    <p>Us ag</p>
    <p>e (</p>
    <p>lo g</p>
    <p>sc al</p>
    <p>ed )</p>
    <p>Cu m</p>
    <p>ul at</p>
    <p>iv e</p>
    <p>M em</p>
    <p>or y</p>
    <p>Us ag</p>
    <p>e (</p>
    <p>lo g</p>
    <p>sc al</p>
    <p>ed )</p>
    <p>PRETZEL</p>
    <p>(w.o . Obj</p>
    <p>Store )ML.</p>
    <p>Net</p>
    <p>ML.Net + Clipper</p>
  </div>
  <div class="page">
    <p>Evaluation: Throughput</p>
    <p>(SA)</p>
    <p>Th ro</p>
    <p>ug hp</p>
    <p>ut (K</p>
    <p>Q PS</p>
    <p>)</p>
    <p>(ideal)</p>
    <p>(ideal)</p>
    <p>Pretzel ML.Net</p>
    <p>(AC)</p>
    <p>(ideal)</p>
    <p>(SA)</p>
    <p>Th ro</p>
    <p>ug hp</p>
    <p>ut (K</p>
    <p>Q PS</p>
    <p>)</p>
    <p>(ideal)</p>
    <p>(ideal)</p>
    <p>Pretzel ML.Net</p>
    <p>(AC)</p>
    <p>(ideal)</p>
    <p>better</p>
    <p>Micro-benchmark  Score 250 Attendee Count models 1000 times for each  Request 1000 queries in a batch  Compare ML.Net vs. PRETZEL</p>
    <p>Close to ideal scalability</p>
    <p>More results in the paper!</p>
  </div>
  <div class="page">
    <p>Conclusion  PRETZEL is the first white-box prediction serving system for ML pipelines</p>
    <p>By using models structural info, we enable two types of optimizations:  End-to-end optimizations generate efficient execution plans for a model  Multi-model optimizations let models share computation and memory resources</p>
    <p>Our evaluation shows that PRETZEL can improve performance compared to Black-box systems (e.g., ML.Net)  Decrease latency and memory footprint  Increase resource utilization and throughput</p>
  </div>
  <div class="page">
    <p>PRETZEL: a White-Box ML Prediction Serving System</p>
    <p>Thank you! Questions?</p>
    <p>fi</p>
    <p>fi</p>
    <p>fi   A</p>
    <p>fi   B</p>
    <p>BS06  -</p>
    <p>'    `     ,    , ` '</p>
    <p>' .     ,</p>
    <p>,  ,'  fl .   FullColor</p>
    <p>.CD-Rom</p>
  </div>
</Presentation>
