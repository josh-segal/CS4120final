<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Model-Switching: Dealing with Fluctuating Workloads in MLaaS* Systems</p>
    <p>jeffjunzhang@nyu.edu</p>
    <p>USENIX HotCloud 2020 [*] Machine Learning-as-a-Service</p>
    <p>Jeff Zhang1, Sameh Elnikety2, Shuayb Zarar2, Atul Gupta2, Siddharth Garg1</p>
  </div>
  <div class="page">
    <p>Deep-Learning Models are Pervasive</p>
  </div>
  <div class="page">
    <p>Computations in Deep Learning</p>
    <p>Activation Tensor</p>
    <p>Convolution</p>
    <p>Convolution Filters Output Tensor</p>
    <p>=</p>
    <p>Output Tensor</p>
    <p>...</p>
    <p>[Ref.] Sze, V., et al., Efficient Processing of Deep Neural Networks: A Tutorial and Survey, IEEE Proceedings 2017.</p>
    <p>Convolutions account for more than 90% computation  dominate both run-time and energy.*</p>
    <p>Execution time factors: depth, activation/filter size in each layer</p>
  </div>
  <div class="page">
    <p>Offline Training</p>
    <p>Data</p>
    <p>Data Collection</p>
    <p>Cleaning &amp; Visualization</p>
    <p>Feature Eng. &amp; Model Design</p>
    <p>Training &amp; Validation</p>
    <p>Model Development</p>
    <p>Trained ModelsTraining Pipelines</p>
    <p>Live Data</p>
    <p>Training</p>
    <p>Validation</p>
    <p>End User Application</p>
    <p>Query</p>
    <p>Prediction</p>
    <p>Prediction Service</p>
    <p>Inference</p>
    <p>Feedback</p>
    <p>Logic</p>
    <p>Data Scientist</p>
    <p>Data Engineer</p>
    <p>Data Engineer</p>
    <p>Machine Learning Lifecycle (Typical)</p>
    <p>Online</p>
    <p>Model Development  Prescribes model design, architecture and data processing</p>
    <p>Training  At scale on live data  Retraining on new data and manage model versioning</p>
    <p>Serving or Online Inference  Deploys trained model into device, edge, or cloud</p>
    <p>MLaaS</p>
  </div>
  <div class="page">
    <p>MLaaS: Challenges and Limitations</p>
    <p>Existing Solution - Static model versioning</p>
    <p>- Tie each application to one specific model at run-time - In the event of load spikes:</p>
    <p>Prune requests (new, low priority, near deadline etc.) - QoS violations, customer L</p>
    <p>Add significant new capacity&quot; (autoscaling) - Not economically viable, provider L</p>
    <p>Maintain QoS under dynamic workloads.</p>
    <p>- Service success rates dropped below 99.99% - Teams suffered 2-hour outage in Europe - Free offers and new subscriptions were limited</p>
    <p>March 28, 2020</p>
  </div>
  <div class="page">
    <p>A cc</p>
    <p>ur ac</p>
    <p>y Single Image Inference with ResNet-x</p>
    <p>ResNet-18</p>
    <p>ResNet-34</p>
    <p>ResNet-50</p>
    <p>ResNet-101</p>
    <p>ResNet-152</p>
    <p>Opportunity: DNN Model Diversity</p>
    <p>For the same application, many models can be trained with tradeoffs among: Accuracy, Inference Time and Computation Cost (Parallelism)</p>
    <p>[Ref.] He, K., et al., Deep Residual Learning for Image Recognition, IEEE CVPR 2016; 5</p>
    <p>R es</p>
    <p>id ua</p>
    <p>l B lo</p>
    <p>ck</p>
    <p>Model</p>
  </div>
  <div class="page">
    <p>Assumption: fluctuating workloads fixed hardware capacity</p>
    <p>Which DNN model to use?</p>
    <p>How to allocate resources?</p>
    <p>MLaaS Provider</p>
    <p>ML App End Users</p>
    <p>What is the QoS?</p>
    <p>sending requests</p>
    <p>rende ring p</p>
    <p>redict ions</p>
    <p>SLAs</p>
    <p>Typical SLA Objectives: latency, throughput, cost,</p>
    <p>Make all decisions online!</p>
    <p>Questions in this Study</p>
  </div>
  <div class="page">
    <p>MLaaS Provider</p>
    <p>Application End Users</p>
    <p>What Do Users Care About?</p>
    <p>From the users perspective, deadline misses and incorrect predictions are equally bad:</p>
    <p>User can always meet deadline by guessing randomly Quick and correct predictions!</p>
  </div>
  <div class="page">
    <p>E ff</p>
    <p>ec tiv</p>
    <p>e A</p>
    <p>cc ur</p>
    <p>ac y</p>
    <p>ResNet152 ResNet101 ResNet50 ResNet34 ResNet18</p>
    <p>A New Metric for MLaaS</p>
    <p>No single DNN works best at all load levels</p>
    <p>(: load, : baseline accuracy)</p>
    <p>Effective Accuracy (!&quot;&quot;) : the fraction of correct predictions within deadline (D)</p>
    <p>Likelihood of meeting deadline</p>
    <p>#$$ = %,'</p>
  </div>
  <div class="page">
    <p>th p</p>
    <p>er ce</p>
    <p>nt ile</p>
    <p>ta il</p>
    <p>la te</p>
    <p>nc y</p>
    <p>(m s)</p>
    <p>ResNet-152 Tail Latency Vs Job arrival rate</p>
    <p>R:16 T:1 R:8 T:2 R:4 T:4 R:2 T:8 R:1 T:16</p>
    <p>Characterizing DNN Parallelism</p>
    <p>As load increases, additional replicas help more than threads. 9</p>
    <p>Fixed Capacity: 16 threads</p>
    <p>End to End Query Latency</p>
    <p>R: Replicas T: Threads</p>
  </div>
  <div class="page">
    <p>Online Model Switching Framework</p>
    <p>Load Change Detection</p>
    <p>Offline policy training</p>
    <p>Model Switching</p>
    <p>Load Best Model Parallelism</p>
    <p>&gt; 20 ResNet-18</p>
    <p>Model that exhibits best effective accuracy is a function of load</p>
    <p>Front-End Queries</p>
    <p>Predictions</p>
    <p>Dynamically select best model (effective accuracy) based on load</p>
    <p>Model Switching Controller</p>
    <p>Online Serving</p>
    <p>SLA deadline</p>
  </div>
  <div class="page">
    <p>Experimental Setup</p>
    <p>Built on top of Clipper, an open-source containerized model-serving</p>
    <p>framework (caching, adaptive batching disabled)</p>
    <p>Deployed PyTorch pretrained ResNet models on ImageNet (R: 4 T: 4)</p>
    <p>Two dedicated Azure VMs:</p>
    <p>Server: 32 vCPUs + 128GB RAM</p>
    <p>Client: 8vCPUs + 32GB RAM</p>
    <p>Markov Model based load generator</p>
    <p>Open system model</p>
    <p>Poisson inter-arrivals</p>
    <p>Model Switching</p>
    <p>[Ref.] D. Crankshaw et al., Clipper: A low-latency online prediction serving system, USENIX NDSI 2017.</p>
    <p>sampling period 1 sec</p>
  </div>
  <div class="page">
    <p>Evaluation: Automatic Model-Switching</p>
    <p>ad (Q</p>
    <p>ue ri</p>
    <p>es P</p>
    <p>er S</p>
    <p>ec on</p>
    <p>d)</p>
    <p>ResNet-18</p>
    <p>ResNet-34</p>
    <p>ResNet-50</p>
    <p>ResNet-101</p>
    <p>ResNet-152</p>
    <p>Model-Switching can quickly adapt to load spikes.</p>
  </div>
  <div class="page">
    <p>E ff</p>
    <p>ec tiv</p>
    <p>e A</p>
    <p>cc ur</p>
    <p>ac y</p>
    <p>Model Switch ResNet-18 ResNet-34 ResNet-50 ResNet-101 ResNet-152</p>
    <p>(s)</p>
    <p>Evaluation: Effective Accuracy</p>
    <p>Model-Switching achieves pareto-optimal effective accuracy.</p>
  </div>
  <div class="page">
    <p>Evaluation: Tail Latency</p>
    <p>Model-Switching tradeoffs deadline slack for accuracy.</p>
    <p>SLA deadline: 750 ms</p>
    <p>P er</p>
    <p>ce nt</p>
    <p>ag e</p>
    <p>Empirical CDF</p>
    <p>Model Switch ResNet-18 ResNet-34 ResNet-50 ResNet-101 ResNet-152</p>
  </div>
  <div class="page">
    <p>Model-Switching: Manage Fluctuating Workloads in MLaaS Systems</p>
    <p>Thank You and Questions</p>
    <p>Jeff Zhang jeffjunzhang@nyu.edu</p>
  </div>
  <div class="page">
    <p>How to prepare a pool of models for each application?  Neural Architecture Search, Multi-level Quantization</p>
    <p>Current approach pre-deploys all (20) candidate models  Cold start time (ML): tens of seconds  RAM overheads: currently 11.8% of the total 128 GB RAM</p>
    <p>Reinforcement learning based controller for model switching  Account for job queue status, system load, current latency  Offline training free</p>
    <p>Integrate with existing MLaaS techniques  Batching, caching, autoscaling etc.</p>
    <p>Exploit availability of heterogenous computing resources  CPU, GPU, TPU, FPGA</p>
    <p>Discussion and Future Work</p>
  </div>
</Presentation>
