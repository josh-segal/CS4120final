<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Random Walk Inference and Learning in A Large Scale Knowledge Basein A Large Scale Knowledge Base</p>
    <p>Ni Lao Tom Mitchell William W CohenNi Lao, Tom Mitchell, William W. Cohen Carnegie Mellon University</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 1</p>
  </div>
  <div class="page">
    <p>OutlineOutline  Motivation</p>
    <p>Inference in KnowledgeBases  The NELL project  Random Walk Inference</p>
    <p>Approach  Path Ranking Algorithm (Recap)</p>
    <p>Data Driven Path Finding DataDriven Path Finding  Efficient Random Walk (Recap)  LowVariance Sampling</p>
    <p>Results  Cross Validation  Mechanical Turk Evaluation</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 2</p>
    <p>Mechanical Turk Evaluation</p>
  </div>
  <div class="page">
    <p>Large Scale KnowledgeBasesLarge Scale Knowledge Bases  Human knowledge is being transformed into structured data at a fast</p>
    <p>speed e gspeed, e.g.</p>
    <p>KnowItAll (Univ. Washington)  0.5B facts extracted from 0.1B web pages</p>
    <p>DBpedia (Univ. Leipzig)  3.5M entities 0.7B facts extracted from wikipedia</p>
    <p>YAGO (MaxPlanck Institute)  2M entities 20M facts extracted from Wikipedia and wordNet</p>
    <p>FreeBase  20M entities 0.3B links, integrated from different data sources and human judgments</p>
    <p>NELL (Carnegie Mellon Univ.)  0.85M facts extracted from 0.5B webpages</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 3</p>
  </div>
  <div class="page">
    <p>The Need for Robust and Efficient fInference</p>
    <p>Knowledge is potentially useful in many tasks  Support information retrieval/recommendation  Bootstrap information extraction/integration</p>
    <p>Challenges  Robustness: extracted knowledge is incomplete and noisy  Scalability: the size of knowledge base can be very largeScalability: the size of knowledge base can be very large</p>
    <p>AthletePlaysInLeague</p>
    <p>SteelersAthletePlays ForTeam</p>
    <p>TeamPlays InLeague</p>
    <p>American</p>
    <p>IsA</p>
    <p>PlaysIn</p>
    <p>AthletePlaysInLeague HinesWard NFL</p>
    <p>?</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 4</p>
    <p>American isa-1</p>
  </div>
  <div class="page">
    <p>The NELL Case StudyThe NELL Case Study  NeverEnding Language Learning:</p>
    <p>a neverending learning system that operates 24 hours per day, for years, to continuously improve its ability to read (extract structured facts from) the web (Carlson et al., 2010)</p>
    <p>Closed domain, semisupervised extraction  Combines multiple strategies: morphological patterns, textual</p>
    <p>context, html patterns, logical inference</p>
    <p>Example beliefs</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 5</p>
  </div>
  <div class="page">
    <p>A Link Prediction TaskA Link Prediction Task</p>
    <p>We consider 48 relations for which NELL database has more than 100 instances</p>
    <p>W li k di i k f h l i We create two link prediction tasks for each relation  AthletePlaysInLeague(HinesWard,?)  AthletePlaysInLeague(? NFL)AthletePlaysInLeague(?, NFL)</p>
    <p>The actual nodes y known to satisfy R(x; ?) are treated as labeled positive examples, and all other nodes are treated as negative examples</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 6</p>
  </div>
  <div class="page">
    <p>First Order Inductive LearnerFirst Order Inductive Learner</p>
    <p>FOIL (Quinlan and CameronJones 1993) is a learning algorithmFOIL (Quinlan and Cameron Jones, 1993) is a learning algorithm similar to decision trees, but in relational domains</p>
    <p>NELL implements two assumptions for efficient learning (NFOIL)</p>
    <p>The predicates are functional e.g. an athlete plays in at most one league</p>
    <p>Only find clauses that correspond to boundedlength paths of binary relations  relational pathfinding (Richards &amp; Mooney, 1992)</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 7</p>
  </div>
  <div class="page">
    <p>First Order Inductive LearnerFirst Order Inductive Learner  Efficiency</p>
    <p>Horn clauses can be very costly to evaluate  E.g. it take days to train NFOIL on the NELL data</p>
    <p>Robustness  FOIL can only combine rules with disjunctions, therefore cannot</p>
    <p>leverage low accuracy rulesg y  E.g. rules for teamPlaysSports</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 8</p>
  </div>
  <div class="page">
    <p>Random Walk InferenceRandom Walk Inference  Consider a low precision/high recall Horn clause</p>
    <p>isa(x, c) ^ isa(x,c)^ AthletePlaysInLeague(x, y) AthletePlaysInLeague(x; y)</p>
    <p>A Path Constrained Random Walk following the above edge type A Path Constrained Random Walk following the above edge type sequence generates a distribution over all leagues</p>
    <p>AthletePlays InLeagueisa-1</p>
    <p>i</p>
    <p>HinesWard athlete (concept) all leagues</p>
    <p>isa</p>
    <p>Prob(HinesWard y) can be treated as a relational feature for di i A hl Pl I L (Hi W d )</p>
    <p>(concept) all athletes</p>
    <p>all leagues</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK</p>
    <p>predicting AthletePlaysInLeague(HinesWard; y)</p>
  </div>
  <div class="page">
    <p>ComparisonComparison  Inductive logic programming (e.g. FOIL)</p>
    <p>Brittle facing uncertainty</p>
    <p>Statistical relational learning (e.g. Markov logic networks, Relational Bayesian Networks)</p>
    <p>Inference is costly when the domain contains many nodes Inference is costly when the domain contains many nodes  Inference is needed at each iteration of optimization</p>
    <p>Random walk inference  Decouples feature generation and learning (propositionalization)</p>
    <p>No inference needed during optimization</p>
    <p>S li h f ffi i d lk Sampling schemes for efficient random walks  Trains in minutes as opposed to days for NFOIL</p>
    <p>Low precision/high recall rules as features with fractional values</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK</p>
    <p>p / g  Doubles precision at rank 100 compared with NFOIL</p>
  </div>
  <div class="page">
    <p>OutlineOutline  Motivation</p>
    <p>Inference in KnowledgeBases  The NELL project  Random Walk Inference</p>
    <p>Approach  Path Ranking Algorithm (Recap)</p>
    <p>Data Driven Path Finding DataDriven Path Finding  Efficient Random Walk (Recap)  LowVariance Sampling</p>
    <p>Results  Cross Validation  Mechanical Turk Evaluation</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 11</p>
    <p>Mechanical Turk Evaluation</p>
  </div>
  <div class="page">
    <p>Path Ranking Algorithm (PRA)Path Ranking Algorithm (PRA)  A relation path P=(R1, ,Rn) is a sequence of relations</p>
    <p>A PRA d l t t d i b li f ti</p>
    <p>(Lao &amp; Cohen, ECML 2010)</p>
    <p>A PRA model scores a sourcetarget node pair by a linear function of their path features</p>
    <p>( , ) ( , )P Pscore s t f s t =   P is the set of all relation paths with length  L</p>
    <p>( , ) ( , )P P P</p>
    <p>f</p>
    <p>P</p>
    <p>( , ) Prob( ; )Pf s t s t P=</p>
    <p>Training  For a relation R and a set of node pairs {(si, ti)},</p>
    <p>( , ) Prob( ; )Pf s t s t P</p>
    <p>i i  we construct a training dataset D ={(xi, yi)}, where  xi is a vector of all the path features for (si, ti), and  yi indicates whether R(si, ti) is true or not</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK</p>
    <p>is estimated using L1,L2regularized logistic regression</p>
  </div>
  <div class="page">
    <p>DataDriven Path FindingData Driven Path Finding  Impractical to enumerate all possible paths even for small length l</p>
    <p>Require any path to instantiat e in at least  portion of the training queries, i.e. fP(s,t)  0 for any t</p>
    <p>Require any path to reach at least one target node in the training set</p>
    <p>Discover paths by a depth first search  Starts from a set of training queries, expand a node if the</p>
    <p>instantiation constraint is satisfied</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 13</p>
  </div>
  <div class="page">
    <p>DataDriven Path FindingData Driven Path Finding</p>
    <p>Dramatically reduce the number of pathsy p</p>
    <p>l</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 14</p>
  </div>
  <div class="page">
    <p>Efficient InferenceEfficient Inference</p>
    <p>Exact calculation of random walk distributions results in</p>
    <p>(Lao &amp; Cohen, KDD 2010)</p>
    <p>Exact calculation of random walk distributions results in nonzero probabilities for many internal nodes in the graph</p>
    <p>but computation should be focused on the few target but computation should be focused on the few target nodes which we care about</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 15</p>
  </div>
  <div class="page">
    <p>Efficient InferenceEfficient Inference</p>
    <p>Sampling approach (Lao &amp; Cohen, KDD 2010)</p>
    <p>p g pp  A few random walkers (or particles) are enough to distinguish good target nodes from bad ones</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 16</p>
  </div>
  <div class="page">
    <p>LowVariance SamplingLow Variance Sampling  Sampling walkers/particles independently introduces</p>
    <p>variances to the result distributions</p>
    <p>LowVariance Sampling (LVS)(Thrun et al., 2005) p g ( )( , ) generates M correlated samples, by drawing a single number r from (0,M1)</p>
    <p>samples correspond to M1+kr, k=0..M1</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 17</p>
  </div>
  <div class="page">
    <p>Low Variance SamplingLow Variance Sampling Averaged over 96 tasks</p>
    <p>In our evaluation  LVS can slightly</p>
    <p>improve prediction for both finger printing and particle filtering M</p>
    <p>R R</p>
    <p>and particle filtering M Exact Independent Fingerprinting Low Variance Fingerprinting</p>
    <p>Low Variance Fingerprinting Independent Filtering Low Variance Filtering</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 18</p>
  </div>
  <div class="page">
    <p>OutlineOutline  Motivation</p>
    <p>Inference in KnowledgeBases  The NELL project  Random Walk Inference</p>
    <p>Approach  Path Ranking Algorithm (Recap)</p>
    <p>Data Driven Path Finding DataDriven Path Finding  Efficient Random Walk (Recap)  LowVariance Sampling</p>
    <p>Results  Cross Validation  Mechanical Turk Evaluation</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 19</p>
    <p>Mechanical Turk Evaluation</p>
  </div>
  <div class="page">
    <p>Parameter TuningParameter Tuning  Cross Validation on Training Queries</p>
    <p>Supervised training can improve retrieval quality (RWR)  Path structure can produce further improvement (PRA)</p>
    <p>RWR: Random Walk with Restart (personalized page rank)</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 20</p>
    <p>Paired ttest give pvalues 7x103, 9x104, 9x108, 4x104</p>
  </div>
  <div class="page">
    <p>Example PathsExample Paths</p>
    <p>Synonyms ofSynonyms of the query team</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 21</p>
  </div>
  <div class="page">
    <p>Evaluation by Mechanical TurkEvaluation by Mechanical Turk  There are many test queries per predicate</p>
    <p>ll f d  d / All entities of a predicates domain/range, e.g.  WorksFor(person, organization)</p>
    <p>On average 7,000 test queries for each functional predicate, and 13,000 for each nonfunctional predicate</p>
    <p>Sampled evaluation  We only evaluate the top ranked result for each queryWe only evaluate the top ranked result for each query</p>
    <p>We sort the queries for each predicate according to the scores of their top ranked results, and then evaluate precisions at top 10, 100 and 1000 queries</p>
    <p>Each belief is voted by 5 workers  Workers are given assertions like Hines Ward plays for the team Steelers, as</p>
    <p>well as Google search links for each entity</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 22</p>
  </div>
  <div class="page">
    <p>Evaluation by Mechanical TurkEvaluation by Mechanical Turk  On 8 functional predicates where NFOIL can successfully learn</p>
    <p>bl f b h f l b PRA is comparable to NFOIL for p@10, but has significantly better p@100</p>
    <p>On randomly sampled 8 nonfunctional (one to many mapping) predicates  Slightly lower accuracy than functional predicatesSlightly lower accuracy than functional predicates</p>
    <p>NFOIL PRA Task #Rules p@10 p@100 #Paths p@10 p@100</p>
    <p>Functional Predicates 2.1(+37) 0.76 0.380 43 0.79 0.668 Nonfunctional Predicates    92 0.65 0.620</p>
    <p>PRA: Path Ranking Algorithm</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 23</p>
  </div>
  <div class="page">
    <p>ConclusionConclusion  Random walk inference</p>
    <p>h f f l k d k Generate path features for link prediction tasks  Use sampling schemes for efficient inference  User low precision rules as fractional valued features</p>
    <p>Future work (in model expressiveness)  Efficiently discover long paths</p>
    <p>Di l i li d h ( i d ) Discover lexicalized paths (contains constant nodes)  Generalize relation paths to trees/networks</p>
    <p>Thank you! Questions?</p>
    <p>EMNLP 2011, Edinburgh, Scotland, UK 7/28/2011 24</p>
  </div>
</Presentation>
