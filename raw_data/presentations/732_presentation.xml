<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Wayne State University Cluster and Internet Computing Laboratory</p>
    <p>A Scheduling Framework that Makes any Disk Schedulers Non-work-conserving</p>
    <p>solely based on Request Characteristics</p>
    <p>Yuehai Xu and Song Jiang</p>
    <p>Department of Electrical and Computer Engineering Wayne State University</p>
  </div>
  <div class="page">
    <p>Disk Performance and Workload Spatial Locality</p>
    <p>The disk is cost effective with its ever increasing capacity and peak throughput.</p>
    <p>The performance with non-sequential access is critical for the disk to be competitive.  Virtual machine environment  Consolidated storage system</p>
    <p>The effective performance depends on exploitation of spatial locality.  This locality is usually exploited statically in the request</p>
    <p>scheduling.  In this work, we exploit it in both space and time dimensions.</p>
  </div>
  <div class="page">
    <p>Quantifying Request Service Time</p>
    <p>Logical Block</p>
    <p>Address (LBA)</p>
  </div>
  <div class="page">
    <p>From 1-D Locality to 2-D Locality</p>
    <p>LB A</p>
    <p>LB A</p>
    <p>TimeTimeCurrent Time</p>
    <p>D is</p>
    <p>k H</p>
    <p>ea d</p>
    <p>T1 = service_time(pending_request)</p>
    <p>To exploit the locality, usually select minimal T1 among pending requests.</p>
    <p>T1</p>
  </div>
  <div class="page">
    <p>From 1-D Locality to 2-D Locality</p>
    <p>TimeTime 5</p>
    <p>LB A</p>
    <p>LB A</p>
    <p>T1</p>
    <p>T3</p>
    <p>T2</p>
    <p>T1 = service_time(pending_request)</p>
    <p>T2 = wait_time (future_request)</p>
    <p>T3 = service_time (future_request)</p>
    <p>To exploit 1-D locality, select min(T1) among pending requests.</p>
    <p>To exploit 2-D locality, select min(T1, T2+T3) among pending and future requests with non-workconserving scheduling.D</p>
    <p>is k</p>
    <p>H ea</p>
    <p>d</p>
    <p>Current Time</p>
  </div>
  <div class="page">
    <p>Challenges of Exploiting 2-D Locality</p>
    <p>TimeTime 6</p>
    <p>LB A</p>
    <p>LB A</p>
    <p>T1</p>
    <p>T3</p>
    <p>T2</p>
    <p>T2+T3 &lt; T1</p>
    <p>Predicting arrival times and locations of future requests whose T2+T3 &lt; T1;</p>
    <p>Determining what request history should be used for the prediction.</p>
    <p>T1 = service_time(pending_request)</p>
    <p>T2 = wait_time (future_request)</p>
    <p>T3 = service_time (future_request)</p>
    <p>D is</p>
    <p>k H</p>
    <p>ea d</p>
    <p>Current Time</p>
  </div>
  <div class="page">
    <p>How does anticipatory handle them?</p>
    <p>LB A</p>
    <p>LB A</p>
    <p>TimeTimeCurrent Time</p>
    <p>D is</p>
    <p>k H</p>
    <p>ea d</p>
    <p>The anticipatory scheduling (AS) groups requests according to their issuing processes. AS explicitly tracks request arrival times and locations for each process to make a prediction for the next request.</p>
  </div>
  <div class="page">
    <p>Anticipatorys Limitations</p>
    <p>LB A</p>
    <p>LB A</p>
    <p>TimeTime</p>
    <p>D is</p>
    <p>k H</p>
    <p>ea d</p>
    <p>Requests in a local disk region may be issued by different processes. Maintaining/analyzing long history access statistics can be expensive. The process information may be unavailable ! (VM, SAN, NFS, and PVFS etc.)</p>
  </div>
  <div class="page">
    <p>Related Approaches Antfarm infers process information in the virtual machine monitor by tracking activities of processes in VMs [USENIX ATC06].  Applicable only to VM.  Guest OS needs to be open for instrumentation.</p>
    <p>Hints, such as accessed files directory or owner, are used for grouping requests in the NFS servers. [Cluster08].  Hints may not be always relevant.</p>
    <p>The Linux prefetching policy exploits spatial locality by tracking file access for every processes opened file. [Linux Symposium04]  File abstraction may not be available to the disk schedulers.  Its efficient tracking and decision making mechanisms can be leveraged.</p>
  </div>
  <div class="page">
    <p>Design Goals of Stream Scheduling</p>
    <p>Use only request characteristics, i.e., request arrival times and locations  Process information is not required in any way.</p>
    <p>Introduce minimal overhead  Remember minimal history access information  Conduct minimal computation in its locality analysis</p>
    <p>Integrate seamlessly with any work-conserving schedulers  Designed as a framework to make them non-work-conserving</p>
  </div>
  <div class="page">
    <p>Design of Stream Scheduling</p>
    <p>Group requests into streams so that the intra-stream locality is stronger than the inter-stream locality.</p>
    <p>Track judicious scheduling decisions rather than locality metrics  Wait or not wait? (future request vs. pending request)  A stream is a sequence of requests for which judicious decisions</p>
    <p>are wait.</p>
    <p>A stream is maintained as Linux prefetching does.  A stream is built up or torn down depending on next judicious</p>
    <p>decision.</p>
  </div>
  <div class="page">
    <p>Arrival of a request</p>
    <p>Completion of a request</p>
    <p>Time period serving other requests</p>
    <p>Time period serving this request</p>
    <p>Link showing relationship between parent request and child request</p>
    <p>TimeTime</p>
    <p>LB A</p>
    <p>LB A</p>
    <p>Stream Scheduling Illustration</p>
    <p>a</p>
    <p>b</p>
    <p>b</p>
    <p>c</p>
    <p>c d</p>
    <p>Req 1 has its child (Req 2).</p>
    <p>The stream length increases to two.</p>
    <p>T2+T3 &lt; T1</p>
  </div>
  <div class="page">
    <p>Maintenance of Streams A stream grows when a completed request sees its child.  Determining existence of a child is independent of actual</p>
    <p>scheduling.  A stream is established when its length exceeds a threshold.  An established stream leads to non-work-conserving</p>
    <p>scheduling. The scheduler stops serving a stream when  the stream is broken; or  the time slice allocated to the stream runs out; or  an urgent request appears. To maintain a stream, only current stream lengths need to be remembered.  The cost is trivial ! We have design of stream scheduling for the disk array.  It is described in the paper.</p>
  </div>
  <div class="page">
    <p>Experiment Settings</p>
    <p>Software settings  Stream Scheduling (SS) is prototyped in Linux kernel 2.6.31.3 using</p>
    <p>Deadline as its work-conserving component.  The default stream length threshold is 4.  The default stream time slice is 124ms. Hardware settings  Intel Core2 Duo with 2GB DRAM memory.  7200RPM, 500GB Western Digital Caviar Blue SATA II with a 16MB</p>
    <p>built-in cache. Adaptation for NCQ  Disk head position is indicated by the last request sent to the disk.</p>
  </div>
  <div class="page">
    <p>Storage without Process Information</p>
    <p>parpar--readread: four independent processes, each reading a 1GB file using 4KB requests in parallel. GrepGrep: two grep instances, each searching in a Linux directory tree. TPCTPC--HH: three TPC-H instances, each using PostgreSQL as its database server and DBT3 to create its tables. PostMarkPostMark: four PostMark instances, each creating a data set of 10,000 files.</p>
    <p>par-read grep TPC-H PostMark</p>
  </div>
  <div class="page">
    <p>Storage without Process Information</p>
    <p>parpar--readread: four independent processes, each reading a 1GB file using 4KB requests in parallel.</p>
    <p>Execution Time (s)</p>
    <p>P en</p>
    <p>di ng</p>
    <p>T im</p>
    <p>e (m</p>
    <p>s)</p>
    <p>S er</p>
    <p>vi ce</p>
    <p>T im</p>
    <p>e (m</p>
    <p>s)</p>
    <p>Execution Time (s)</p>
  </div>
  <div class="page">
    <p>Storage with Inadequate Process Information</p>
    <p>multimulti--threads:threads: four processes, each forking two threads for reading files with periodic synchronization between them. mpimpi--ioio--testtest:: four mpi-io-test program instances running on PVFS2 where files are striped over eight data servers. ProFTPDProFTPD:: a ProFTPD FTP server on each Xen VM supporting four clients to simultaneously download four 300MB files. TPCTPC--H:H: three TPC-H instances on each Xen VM.</p>
  </div>
  <div class="page">
    <p>Conclusions</p>
    <p>The stream scheduling framework turns any disk scheduler into a non-work-conserving one.  Process information is not required in the scheduling.  Both time and space overheads are low.</p>
    <p>The framework can be extended to disk arrays to recover and exploit the locality weakened by file striping.</p>
    <p>Experiments on its Linux prototype show significantly improved performance for representative benchmarks.</p>
  </div>
</Presentation>
