<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Copyright(C) 2020 KDDI Research, Inc. All Rights Reserved.</p>
    <p>Resource Efficient Stream Processing Platform with Latency-Aware Scheduling Algorithms</p>
    <p>Yuta Morisawa, Masaki Suzuki, Takeshi Kitahara</p>
    <p>KDDI Research, Inc.</p>
  </div>
  <div class="page">
    <p>Copyright(C) 2020 KDDI Research, Inc. All Rights Reserved. 2</p>
    <p>Background</p>
    <p>Stream processing has become a major region  By 2025, nearly 30 percent of the data will be real-time [1]</p>
    <p>One organization will have many stream applications for their business</p>
    <p>Resource Inefficiency of the traditional big data stream processing  Users must allocate resources according to traffic peak</p>
    <p>Once users creates a cluster, the total amount of resources</p>
    <p>(e.g., CPU cores) cannot be modified</p>
    <p>C P</p>
    <p>U</p>
    <p>Timeline of the CPU usage. Gray area shows unused</p>
    <p>CPU resources.</p>
    <p>[1] David Reinsel  John Gantz  John Rydning, &quot;The Digitization of the World From Edge to Core&quot;, Nov. 2018,</p>
    <p>Goal: Improvement of resource efficiency in an environment</p>
    <p>where multiple applications with different latency</p>
    <p>requirements exist</p>
  </div>
  <div class="page">
    <p>Copyright(C) 2020 KDDI Research, Inc. All Rights Reserved. 3</p>
    <p>Challenges</p>
    <p>Improving resource efficiency of the stream platform is difficult because</p>
    <p>Different latency requirements  Stream applications have various latency SLAs that must be observed</p>
    <p>Unexpected traffic patterns  Input data rate often varies suddenly</p>
    <p>Sometimes, users must allocate extra resources to cope with it</p>
    <p>Optimization for multi-applications environment  Improving the resource efficiency of every cluster is needed to minimize the platform cost</p>
    <p>Prior studies did not address the problem</p>
  </div>
  <div class="page">
    <p>Copyright(C) 2020 KDDI Research, Inc. All Rights Reserved. 4</p>
    <p>Proposal: Multi-application platform</p>
    <p>Accommodate multiple applications in one Spark cluster  This design enables finest granularity resource management</p>
    <p>Resource reallocation can be completed with lower latency</p>
    <p>Latency-aware task scheduler  Determine the priority of each application to observe applications' latency SLAs</p>
    <p>App App App App</p>
    <p>Infra</p>
    <p>App App App App</p>
    <p>Infra</p>
  </div>
  <div class="page">
    <p>Copyright(C) 2020 KDDI Research, Inc. All Rights Reserved. 5</p>
    <p>Proposal: Architecture Overview</p>
    <p>Scheduling pools  Applications are assigned to dedicated scheduling pools</p>
    <p>Scheduled in the task level granularity</p>
    <p>Executors  Just runs assigned tasks (do not care what applications are)</p>
    <p>API  Fully compatible with Apache Spark</p>
    <p>Spark Driver</p>
    <p>Scheduling Pools</p>
    <p>Allocating</p>
    <p>A1</p>
    <p>B1</p>
    <p>C1</p>
    <p>A2</p>
    <p>B2</p>
    <p>C2</p>
    <p>Task</p>
    <p>scheduler</p>
    <p>TaskSet Executor</p>
    <p>Executor</p>
    <p>Executor</p>
    <p>A1</p>
    <p>B1</p>
    <p>A2 C1</p>
    <p>Executor B2 C2</p>
  </div>
  <div class="page">
    <p>Copyright(C) 2020 KDDI Research, Inc. All Rights Reserved. 6</p>
    <p>Proposal: Latency-aware task scheduler</p>
    <p>Scheduler designs  White box: Estimating the necessary resources</p>
    <p>Difficult to apply to stream applications because data rate varies in time</p>
    <p>Black box: Using only metrics (we chose this design)</p>
    <p>Monitor the latency and manipulate resource allocation</p>
    <p>How Black box design works  Utilized existing Spark task-level scheduler</p>
    <p>has available resources</p>
    <p>each task in each application</p>
    <p>to the priorities</p>
    <p>Spark Driver</p>
    <p>Scheduling Pools</p>
    <p>A1</p>
    <p>B1</p>
    <p>C1</p>
    <p>A2</p>
    <p>B2</p>
    <p>C2</p>
    <p>Task</p>
    <p>scheduler</p>
    <p>Executor</p>
    <p>Executor</p>
    <p>Executor</p>
    <p>Executor</p>
    <p>(1) send resourceOffer</p>
    <p>(2) determine</p>
    <p>priority</p>
    <p>(3) Allocate</p>
    <p>resources</p>
  </div>
  <div class="page">
    <p>Copyright(C) 2020 KDDI Research, Inc. All Rights Reserved. 7</p>
    <p>Proposal: Latency-aware task scheduler</p>
    <p>Ps Priority of Jobs</p>
    <p>Tc Current Time</p>
    <p>Ts Submission time of Jobs</p>
    <p>Ls Latency SLA of Jobs</p>
    <p>Implemented 3 algorithms  Earliest Deadline First (EDF), Priority based EDF, Process time Estimation</p>
    <p>Goal: Determine the priority of the tasks of each application to observe SLAs</p>
    <p>EDF 1, Scheduler calculates  for each Job of each application</p>
    <p>=       Equal to the negation of the remaining time</p>
    <p>Larger value has higher priority</p>
    <p>A resource allocation unit is TaskSet, which is a group of tasks and is a component of the Job</p>
    <p>Submission Deadline</p>
    <p>Ts Ts + LsTc</p>
    <p>Remaining Time</p>
    <p>Current Time</p>
    <p>Job</p>
    <p>TaskSet TaskSet</p>
    <p>Task</p>
  </div>
  <div class="page">
    <p>Copyright(C) 2020 KDDI Research, Inc. All Rights Reserved. 8</p>
    <p>Proposal: Latency-aware task scheduler</p>
    <p>Ps Priority of Jobs</p>
    <p>Tc Current Time</p>
    <p>Ts Submission time of Jobs</p>
    <p>Ls Latency SLA of Jobs</p>
    <p>Priority based EDF (PT)  Added potential priority  of the application</p>
    <p>e.g., anomaly detection may have higher priority than aggregation for visualization</p>
    <p>The equation is modified as follows</p>
    <p>=</p>
    <p>Processing time estimation (EST)</p>
    <p>Added estimated job execution time   ,</p>
    <p>F() is an estimation function, and  , is the input data rate</p>
    <p>In this paper, F() is defined through the measurement of the actual latency</p>
    <p>The equation is modified as follows</p>
    <p>=  +  ,</p>
    <p>Submission Deadline</p>
    <p>Ts Ts + LsTc</p>
    <p>Remaining Time</p>
    <p>Current Time</p>
  </div>
  <div class="page">
    <p>Copyright(C) 2020 KDDI Research, Inc. All Rights Reserved. 9</p>
    <p>Evaluation</p>
    <p>Testbed Environment  5 servers Hadoop cluster with YARN (Specifications are shown in the table)</p>
    <p>Kafka as the data source and sink</p>
    <p>Applications  3 types of connected car applications (Parsing, Searching, and Windowing)</p>
    <p>3 copies of each type application (total 9 applications)</p>
    <p>Comparison with  Compared EDF</p>
    <p>Priority based EDF</p>
    <p>Process time estimation (EST)</p>
    <p>Default Spark (run applications separately)</p>
    <p>CPU Xeon E5-2620v4 (8Core) x 2</p>
    <p>Memory 128 GB DDR4</p>
    <p>Storage 15 TB of HDD, 128 GB of SSD</p>
    <p>Network 10 Gb</p>
    <p>OS CentOS 6.9</p>
  </div>
  <div class="page">
    <p>Copyright(C) 2020 KDDI Research, Inc. All Rights Reserved. 10</p>
    <p>Evaluation</p>
    <p>Required minimum number of CPU cores to</p>
    <p>fulfil applications SLAs</p>
    <p>Same performance with 64%</p>
    <p>(25/39) CPU cores</p>
    <p>Parsing Searching Windowing all</p>
    <p>Separating Proposal</p>
    <p>Separating EDF FAIR FIFO EST PT</p>
    <p>C P</p>
    <p>U T</p>
    <p>im e p</p>
    <p>e r c</p>
    <p>o r e</p>
    <p>(1 0</p>
    <p>n s )</p>
    <p>CPU time per core during experiment</p>
  </div>
  <div class="page">
    <p>Copyright(C) 2020 KDDI Research, Inc. All Rights Reserved. 11</p>
    <p>Evaluation</p>
    <p>mean max mean max mean max</p>
    <p>Parsing Searching Windowing</p>
    <p>N o r m</p>
    <p>a li</p>
    <p>z e d</p>
    <p>L a</p>
    <p>te n</p>
    <p>c y</p>
    <p>EDF FAIR FIFO EST PT</p>
    <p>The latency normalized by the latency of the</p>
    <p>default Spark</p>
    <p>Achieved smaller latency</p>
    <p>EDF FIFO PT EST FAIR</p>
    <p>R e c o r d</p>
    <p>s (</p>
    <p>The number of records violated latency SLAs</p>
    <p>when the platform was overloaded</p>
  </div>
  <div class="page">
    <p>Copyright(C) 2020 KDDI Research, Inc. All Rights Reserved. 12</p>
    <p>Conclusion</p>
    <p>Summary</p>
    <p>Goal: resource efficient stream processing</p>
    <p>Accommodating multiple applications</p>
    <p>Scheduling in the same cluster enables quick reallocation and fine-grained control</p>
    <p>Latency-aware schedulers</p>
    <p>Task-level granularity schedulers</p>
    <p>Future Work</p>
    <p>Tradeoff between resource efficiency and isolation</p>
    <p>Consideration on other resources (e.g., memory)</p>
  </div>
  <div class="page">
    <p>Copyright(C) 2020 KDDI Research, Inc. All Rights Reserved. 13</p>
    <p>Thank you!</p>
    <p>Contact : yu-morisawa@kddi-research.jp</p>
    <p>masaki-suzuki@kddi-research.jp</p>
    <p>kitahara@kddi-research.jp</p>
  </div>
</Presentation>
