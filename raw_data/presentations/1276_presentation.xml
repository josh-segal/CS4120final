<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>HDDse: Enabling High-Dimensional Disk State Embedding for Generic Failure Detection System of Heterogeneous Disks in Large Data Centers</p>
    <p>Ji Zhang1,4, Ping Huang1,2, Ke Zhou1, Ming Xie3, Sebastian Schelter4 1Huazhong University of Science and Technology, 2Temple University</p>
  </div>
  <div class="page">
    <p>Ji Zhang</p>
    <p>jizhang@hust.edu.cn</p>
    <p>http://www.jizhang.pro</p>
    <p>AI for System</p>
    <p>Disk Failure Prediction (ATC, ICPP, TPDS)</p>
    <p>Sector Error Prediction (DAC, FAST)</p>
    <p>Database Tuning (SIGMOD, VLDB, VLDBJ, NEDB)</p>
    <p>Chief Engineer, Huawei</p>
    <p>Postdoc, University of Amsterdam</p>
  </div>
  <div class="page">
    <p>Disk Failure</p>
    <p>Data Protection Scheme</p>
    <p>Disk Failure Prediction</p>
    <p>eg., replication and erasure codes</p>
    <p>eg., Machine Learning-based Disk Failure Prediction</p>
  </div>
  <div class="page">
    <p>S.M.A.R.T Technology</p>
    <p>( ID, Normalized, Raw, Threshold, Worst )</p>
    <p>Self-Monitoring Analysis and Reporting Technology</p>
    <p>SMART technology contains up to 30 attributes, reporting various disk operating conditions.</p>
    <p>Threshold Method</p>
    <p>Failure detection rate (FDR) of 3%-10% with 0.1% false alarm rate (FAR)</p>
  </div>
  <div class="page">
    <p>Threshold-Based approaches</p>
    <p>TB</p>
    <p>Distance-based Anomaly Detection</p>
    <p>approaches DAD</p>
    <p>Shallow Machine Learning-based</p>
    <p>approaches SML</p>
    <p>Deep Neural Network-based</p>
    <p>approaches (DNN)</p>
    <p>One-Class Classification -based</p>
    <p>approaches (OCC)</p>
    <p>Transfer Learning-based</p>
    <p>approaches (TL)</p>
    <p>Six classes of approaches</p>
  </div>
  <div class="page">
    <p>Limitations</p>
    <p>TB DAD SML DNN OCC TL</p>
    <p>Applicability       Adaptability      (*) Imbalance Datasets</p>
    <p>Minority Disk      (*)</p>
    <p>Performance FDR:3%10% FDR:56%70% FDR:75%96% FDR:87%98% FDR:70%92% FDR:80%97% FAR:0.1%2% FAR:0%0.8% FAR:0.8%4% FAR:0.6%1.9% FAR:0%10% FAR:0.5%6%</p>
    <p>(*) refers to certain conditions that are required, e.g., finding a suitable source domain (i.e., another disk model) for knowledge transfer.</p>
  </div>
  <div class="page">
    <p>Limitation</p>
    <p>Applicability and Adaptability SML</p>
    <p>DNN OCCOCC</p>
  </div>
  <div class="page">
    <p>DAD Limitation</p>
    <p>Applicability and Adaptability</p>
  </div>
  <div class="page">
    <p>Data Center KLD(01) KLD(12) KLD(23) KLD(&gt;4)</p>
    <p>Tencent 35% 25% 23% 17%</p>
    <p>Backblaze 32% 18% 31% 19%</p>
    <p>Limitation</p>
    <p>Minority Disk</p>
  </div>
  <div class="page">
    <p>Motivation</p>
    <p>l Why the DAD approaches have good applicability and high adaptability while DNN does not?</p>
    <p>A commonality and not sensitive to the disk models.</p>
    <p>l Why the overall detective performance of the DAD method is not as good as other approaches?</p>
    <p>Transformation and computation in low-dimensional space.</p>
    <p>l Why the DNN approach achieves the best performance among other candidates</p>
    <p>Good expression and fitting ability.</p>
  </div>
  <div class="page">
    <p>Overview of HDDse</p>
  </div>
  <div class="page">
    <p>LSTM-based Siamese Network in HDDse</p>
  </div>
  <div class="page">
    <p>The relationship between instances, samples and the input pairs in HDDse</p>
  </div>
  <div class="page">
    <p>Benefits</p>
    <p>l Better with imbalanced datasets</p>
    <p>Imbalance degree (IDe).</p>
    <p>For an imbalanced dataset containing a minority class sample with size A and the IDe is  , the majority class sample size is  A.</p>
    <p>The new imbalance degre , which effectively alleviates the original</p>
    <p>data imbalance by a factor of two.</p>
    <p>l Better with minority disk models The number of training pairs with the minority disk models in existing methods is</p>
    <p>In our method the number of training pairs is</p>
  </div>
  <div class="page">
    <p>A voting-based sliding window (VSW)</p>
    <p>Define a length-W time sliding window and move it forward everyday.</p>
    <p>Decision Maker in HDDse</p>
  </div>
  <div class="page">
    <p>Datasets:</p>
    <p>Evaluation Metrics:</p>
    <p>From Backblaze, which spans a period of 58 months consisting of 146,203 healthy disks and 8,256 failed disks.</p>
    <p>Tencent and spans 29 months consisting of 70,192 healthy disks and 2,971 failed disks.</p>
    <p>TPR. True Positive Rate (also called recall) is the proportion of failed disks that are correctly predicted.</p>
    <p>FPR. False Positive Rate (also called false alarm rate) is the proportion of healthy disks that are falsely predicted as failed.</p>
    <p>AUC. Area under the receiver operating characteristic curve value under the ROC curve (receiver operating characteristic) to evaluate the binary classification performance of our detection model in imbalanced datasets.</p>
    <p>F-Measure. A balance between the two metrics TPR and Prediction Precision.</p>
    <p>Experimental Evaluation</p>
    <p>C-MTTDL. Cost-based MTTDL.</p>
  </div>
  <div class="page">
    <p>Cost-based Mean Time To Data Loss (C-MTTDL)</p>
    <p>approximate the mean time to data loss with failure detection model</p>
    <p>Neglect the cost of misclassification by the approach</p>
    <p>An end-to-end economic analysis metric called C-MTTDL</p>
  </div>
  <div class="page">
    <p>The t-SNE of the S.M.A.R.T data before and after embedding using HDDse</p>
    <p>Before After</p>
  </div>
  <div class="page">
    <p>HHDse only Trained on Minority Disk Datasets</p>
  </div>
  <div class="page">
    <p>The Applicability of HHDse</p>
  </div>
  <div class="page">
    <p>The Adaptability of HHDse</p>
  </div>
  <div class="page">
    <p>Improvement of Storage System Reliability</p>
  </div>
  <div class="page">
    <p>Training and Detecting Time</p>
  </div>
  <div class="page">
    <p>Evaluating Practical Long-Term Availability</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>HDDse: an LSTM-based siamese network that can learn the dynamically changed long-term behavior of</p>
    <p>disk healthy statues and generate a unified and efficient high dimensional disk state embeddings from low</p>
    <p>dimensional S.M.A.R.T attributes for disk failure detection.</p>
    <p>Applicability Adaptability Imbalance datasets Minority Disk Performance TPR: 92%-97% FPR: 0.2%-0.4% F-Measure: 91%-97%</p>
  </div>
  <div class="page">
    <p>Thanks</p>
  </div>
</Presentation>
