<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Prototype-Driven Learning for Sequence Models</p>
    <p>Aria Haghighi and Dan Klein</p>
    <p>Computer Science Division</p>
    <p>University of California Berkeley</p>
  </div>
  <div class="page">
    <p>Overview</p>
    <p>+</p>
    <p>PrototypesTarget Label</p>
    <p>PrototypesTarget Label</p>
    <p>Unlabeled Data</p>
    <p>Prototype List</p>
    <p>Annotated Data</p>
  </div>
  <div class="page">
    <p>Sequence Modeling Tasks</p>
    <p>Newly remodeled 2 Bdrms/1 Bath, spacious upper unit, located in Hilltop Mall area. Walking distance to shopping, public transportation, schools and park. Paid water and garbage. No dogs allowed.</p>
    <p>FEATURE kitchen, laundry</p>
    <p>LOCATION near, close</p>
    <p>TERMS paid, utilities</p>
    <p>SIZE large, feet</p>
    <p>RESTRICT cat, smoking</p>
    <p>Information Extraction: Classified Ads</p>
    <p>FeaturesLocationTermsRestrictSize</p>
    <p>Prototype List</p>
    <p>Newly remodeled 2 Bdrms/1 Bath, spacious upper unit, located in Hilltop Mall area. Walking distance to shopping, public transportation, schools and park. Paid water and garbage. No dogs allowed.</p>
  </div>
  <div class="page">
    <p>Newly remodeled 2 Bdrms/1 Bath, spacious upper unit, located in Hilltop Mall area. Walking distance to shopping, public transportation, schools and park. Paid water and garbage. No dogs allowed.</p>
    <p>Sequence Modeling Tasks</p>
    <p>Newly remodeled 2 Bdrms/1 Bath, spacious upper unit, located in Hilltop Mall area. Walking distance to shopping, public transportation, schools and park. Paid water and garbage. No dogs allowed.</p>
    <p>Prototype List</p>
    <p>NN VBN CC JJ CD PUNC</p>
    <p>IN NNS IN NNP RB DET</p>
    <p>NN president IN of</p>
    <p>VBD said NNS shares</p>
    <p>CC and TO to</p>
    <p>NNP Mr. PUNC .</p>
    <p>JJ new CD million</p>
    <p>DET the VBP are</p>
    <p>English POS</p>
  </div>
  <div class="page">
    <p>Generalizing Prototypes</p>
    <p>NN president</p>
    <p>DET the</p>
    <p>VBD said</p>
    <p>the</p>
    <p>president</p>
    <p>said</p>
    <p>a witness reported a witness reported</p>
    <p>Tie each word to its most similar prototype</p>
  </div>
  <div class="page">
    <p>Generalizing Prototypes</p>
    <p>DET NN VBD</p>
    <p>a witness reported</p>
    <p>y:</p>
    <p>x:</p>
    <p>reported  VBD</p>
    <p>suffix-2=ed  VBD</p>
    <p>sim=said  VBD</p>
  </div>
  <div class="page">
    <p>Markov Random Fields</p>
    <p>for</p>
    <p>Unlabeled Data</p>
  </div>
  <div class="page">
    <p>Markov Random Fields</p>
    <p>DET NN VBD</p>
    <p>a witness reported</p>
    <p>y:</p>
    <p>x:</p>
    <p>x: input sentence y: hidden labels</p>
  </div>
  <div class="page">
    <p>Markov Random Fields</p>
    <p>a  DET</p>
    <p>suffix-1=a  DET</p>
    <p>sim=the  DET</p>
    <p>DET NN VBD</p>
    <p>a witness reported</p>
    <p>y:</p>
    <p>x:</p>
  </div>
  <div class="page">
    <p>Markov Random Fields</p>
    <p>witness  NN</p>
    <p>suffix-2=ss  NN</p>
    <p>sim=president  NN</p>
    <p>DET NN VBD</p>
    <p>a witness reported</p>
    <p>y:</p>
    <p>x:</p>
  </div>
  <div class="page">
    <p>Markov Random Fields</p>
    <p>reported  VBD</p>
    <p>suffix-2=ed  VBD</p>
    <p>sim=said  VBD</p>
    <p>DET NN VBD</p>
    <p>a witness reported</p>
    <p>y:</p>
    <p>x:</p>
  </div>
  <div class="page">
    <p>Markov Random Fields</p>
    <p>DET  NN  VBD</p>
    <p>DET NN VBD</p>
    <p>a witness reported</p>
    <p>y:</p>
    <p>x:</p>
  </div>
  <div class="page">
    <p>Markov Random Fields</p>
    <p>score(x,y) = exp( T )</p>
    <p>DET  NN  VBD witness  NN suffix-2=ed  VBD suffix-1=s  NN suffix-1=a  DET a  DET</p>
    <p>DET NN VBD</p>
    <p>a witness reported</p>
    <p>y:</p>
    <p>x:</p>
  </div>
  <div class="page">
    <p>Markov Random Fields</p>
    <p>Joint Probability Model p(x,y) = score(x,y) / Z()</p>
    <p>Partition Function Z() = x,y score(x,y)</p>
    <p>Sum over infinite inputs!</p>
  </div>
  <div class="page">
    <p>Given unlabeled sentences {x1,,xn}</p>
    <p>choose  to maximize</p>
    <p>Objective Function</p>
  </div>
  <div class="page">
    <p>Optimization</p>
    <p>? ? ?</p>
    <p>a witness reported</p>
    <p>First Expectation  Forward Backward Algorithm</p>
    <p>Second Expectation ? ? ?</p>
    <p>the of in</p>
    <p>the of in</p>
    <p>the of in</p>
    <p>For fixed input length, Forward Backward Algorithm for Lattices</p>
  </div>
  <div class="page">
    <p>Partition Function</p>
    <p>+ +</p>
    <p>? ? ?</p>
    <p>the In</p>
    <p>the In</p>
    <p>the In</p>
    <p>? ?</p>
    <p>the In</p>
    <p>the In</p>
    <p>?</p>
    <p>the In</p>
    <p>Length Lattice  Compute sum for fixed length  Lattice Forward Backward</p>
    <p>[Smith &amp; Eisner 05]</p>
    <p>Approximation  Truncate to finite length</p>
    <p>? ? ?</p>
    <p>the of In</p>
    <p>the of In</p>
    <p>the of In</p>
  </div>
  <div class="page">
    <p>Experiments</p>
  </div>
  <div class="page">
    <p>English POS Experiments</p>
    <p>Data  193K tokens (about 8K sentences)</p>
    <p>of WSJ portion of Penn Treebank  Features [Smith &amp; Eisner 05]</p>
    <p>Trigram tagger  Word type, suffixes up to length 3,</p>
    <p>contains hyphen, contains digit,</p>
    <p>initial capitalization</p>
  </div>
  <div class="page">
    <p>English POS Experiments</p>
    <p>Fully Unsupervised  Random initialization  Greedy label remapping</p>
    <p>BASE</p>
    <p>BASE</p>
    <p>Accuracy</p>
  </div>
  <div class="page">
    <p>English POS Experiments</p>
    <p>Prototype List</p>
    <p>3 prototypes per tag</p>
    <p>Automatically extracted by frequency</p>
  </div>
  <div class="page">
    <p>English POS Distributional Similarity</p>
    <p>Judge a word by the company it keeps</p>
    <p>&lt;s&gt; the president said a downturn is near &lt;/s&gt;</p>
    <p>Collect context counts from 40M words of WSJ</p>
    <p>Similarity [Schuetze 93]  SVD dimensionality reduction  cos() similarity measure</p>
    <p>-1 +1</p>
    <p>president the ___ said :0.6 a ___ reported:0.3</p>
  </div>
  <div class="page">
    <p>English POS Experiments</p>
    <p>Add similarity features  Top five most similar prototypes</p>
    <p>that exceed threshold</p>
    <p>PROTO+SIM</p>
    <p>accuracy</p>
    <p>BASE</p>
    <p>PROTO+SIM</p>
    <p>Accuracy</p>
  </div>
  <div class="page">
    <p>English POS Transition Counts</p>
    <p>Target Structure Learned Structure</p>
  </div>
  <div class="page">
    <p>Classified Ads Experiments</p>
    <p>Data  100 ads (about 119K tokens) from [Grenager et. al. 05]</p>
    <p>Features  Trigram tagger  Word type</p>
  </div>
  <div class="page">
    <p>Classified Ads Experiments</p>
    <p>Fully Unsupervised  Random initialization  Greedy label remapping</p>
    <p>BASE</p>
    <p>BASE</p>
    <p>Accuracy</p>
  </div>
  <div class="page">
    <p>Classified Ads Experiments</p>
    <p>Prototype List  3 prototypes per tag</p>
    <p>33 words in total</p>
    <p>Automatically extracted by frequency</p>
  </div>
  <div class="page">
    <p>Different from English POS</p>
    <p>Similar to topic model</p>
    <p>Classified Ads Distributional Similarity</p>
    <p>&lt;s&gt; the president said a downturn is near &lt;/s&gt;</p>
    <p>-1 +1</p>
    <p>walking distance to shopping , public transportation</p>
  </div>
  <div class="page">
    <p>Classified Ads Experiments</p>
    <p>Add similarity features PROTO + SIM</p>
    <p>BASE</p>
    <p>PROTO+SIM</p>
    <p>Accuracy</p>
  </div>
  <div class="page">
    <p>Reacting to observed errors</p>
    <p>Boundary Model</p>
    <p>Augment Prototype List</p>
    <p>TermsLocation</p>
    <p>Boundary , ; .</p>
    <p>schools and park . Paid water andschools and park . Paid water andschools and park . Paid water and</p>
  </div>
  <div class="page">
    <p>Classified Ads Experiments</p>
    <p>Add Boundary field BOUND</p>
    <p>BASE</p>
    <p>PROTO+SIM</p>
    <p>BOUND</p>
    <p>Accuracy</p>
  </div>
  <div class="page">
    <p>Information Extraction Transition Counts</p>
    <p>Learned StructureTarget Structure</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Prototype-Driven learning  Novel flexible weakly-supervised learning framework</p>
    <p>Merged distributional clustering techniques with supervised structured models</p>
  </div>
  <div class="page">
    <p>Thanks!</p>
    <p>Questions?</p>
  </div>
  <div class="page">
    <p>English POS Experiments</p>
    <p>Fix Prototypes to their tag  No random initialization  No remapping</p>
    <p>accuracy</p>
    <p>Accuracy 40 50 60 70</p>
    <p>BASE 41.3</p>
    <p>PROTO 68.8</p>
    <p>PROTO</p>
  </div>
  <div class="page">
    <p>Classified Ads Experiments</p>
    <p>Fix Prototypes to their tag  No random initialization  No remapping</p>
    <p>Accuracy 40 50 60 70 80</p>
    <p>BASE 46.4</p>
    <p>PROTO 53.7</p>
    <p>PROTO</p>
  </div>
  <div class="page">
    <p>Objective Function</p>
    <p>? ? ?</p>
    <p>a witness reported</p>
    <p>Forward-Backward Algorithm</p>
    <p>Sum over hidden labels</p>
  </div>
  <div class="page">
    <p>Objective Function</p>
    <p>Can be computed exactly under certain conditions</p>
    <p>? ?</p>
    <p>? ?</p>
    <p>?</p>
    <p>?</p>
    <p>? ? ?</p>
    <p>? ? ? + +</p>
    <p>Infinite sum over all lengths of input</p>
  </div>
  <div class="page">
    <p>English POS Distributional Similarity</p>
    <p>president the ___ said : 0.6 a ___ reported: 0.3</p>
    <p>downturn a ___ was: 0.8 a ___ is: 0.2</p>
    <p>the &lt;s&gt; ___ president: 0.8 said ___ downturn: 0.2</p>
    <p>a &lt;a&gt; ___ witness: 0.6 said ___ downturn: 0.3</p>
    <p>Collect context counts form BLIPP corpus</p>
    <p>Similarity [Schuetze 93]  SVD dimensionality reduction  cos() between context vectors</p>
  </div>
</Presentation>
