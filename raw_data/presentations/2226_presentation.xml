<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Extending MPI to Accelerators*</p>
    <p>Jeff A. Stuart, John D. Owens University of California, Davis</p>
    <p>cpunerd@gmail.com, jowens@ece.ucdavis.edu</p>
    <p>Pavan Balaji Argonne National Laboratories</p>
    <p>balaji@mcs.anl.gov</p>
    <p>* For this presentation, we mean GPUs</p>
  </div>
  <div class="page">
    <p>Outline  Motivation</p>
    <p>Previous Work</p>
    <p>Proposal</p>
    <p>Challenges</p>
  </div>
  <div class="page">
    <p>Motivation  HPC no longer (just) CPU</p>
    <p>GPUs Have Problems</p>
    <p>Slave Device</p>
    <p>No system calls</p>
  </div>
  <div class="page">
    <p>Previous Work  Three Main Works</p>
    <p>cudaMPI</p>
    <p>GAMPI</p>
    <p>DCGN</p>
  </div>
  <div class="page">
    <p>Previous Work  cudaMPI</p>
    <p>Handles buffer movement</p>
    <p>No ranks for GPUs</p>
  </div>
  <div class="page">
    <p>Previous Work  GAMPI</p>
    <p>GPUs have ranks*</p>
    <p>More communicators</p>
    <p>Handles buffer movement</p>
  </div>
  <div class="page">
    <p>Previous Work  DCGN</p>
    <p>GPUs have ranks</p>
    <p>GPUs source/sink communication*</p>
    <p>Doesn't implement standard MPI</p>
  </div>
  <div class="page">
    <p>Proposal  Several Ideas</p>
    <p>No Ranks for GPUs</p>
    <p>Multiple Ranks per GPU Context</p>
    <p>One Rank per GPU Context</p>
    <p>New MPI Function(s) to Spawn Kernels</p>
  </div>
  <div class="page">
    <p>Proposal  No Ranks for GPUs</p>
    <p>The way things work right now</p>
    <p>No changes necessary to MPI</p>
  </div>
  <div class="page">
    <p>Proposal  Multiple Ranks Per Accelerator Context</p>
    <p>Ranks exist for lifetime of application  # of ranks chosen at runtime by user</p>
    <p>Modifications to MPI  Bind GPU threads to rank/MPI functions take source rank  Host must listen for requests</p>
    <p>Extra threads on CPU (one for each GPU)</p>
  </div>
  <div class="page">
    <p>Proposal  One Rank per Accelerator Context</p>
    <p>Ranks exist for lifetime of Application</p>
    <p>Mapping of Processes:Contexts?</p>
    <p>Can CPU Processes use MPI communication?</p>
  </div>
  <div class="page">
    <p>Proposal  New MPI Function(s) to Spawn Kernels</p>
    <p>New communicators and ranks after every spawn  Cleaned up after all kernels finish</p>
    <p>Intercommunicator(s) available upon request</p>
  </div>
  <div class="page">
    <p>Challenges  Threads vs Processes</p>
    <p>Extra Communicators?</p>
    <p>Collectives</p>
    <p>Source/Sink Communication</p>
  </div>
  <div class="page">
    <p>Looking Forward  GPU-Direct is good</p>
    <p>GPU-Direct 2 is great</p>
    <p>We want GPU-Direct 3 to  Let GPU source/sink  Use GPU-Direct 2 to interface with NIC  Administer MPI ranks without CPU interference</p>
  </div>
  <div class="page">
    <p>One Last Note  Graduating with Ph.D. In June 2012</p>
    <p>Resume at http://jeff.bleugris.com/resume.pdf</p>
  </div>
</Presentation>
