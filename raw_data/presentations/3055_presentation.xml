<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Splinter: Bare-Metal Extensions for Multi-Tenant Low-Latency Storage</p>
    <p>Chinmay Kulkarni, Sara Moore, Mazhar Naqvi, Tian Zhang, Robert Ricci, and Ryan Stutsman</p>
    <p>University of Utah</p>
  </div>
  <div class="page">
    <p>Introduction  Kernel-bypass key-value stores offer &lt; 10s latency, &gt; Mops/s throughput</p>
    <p>Fast because theyre just dumb?</p>
    <p>Problem: Leverage performance  share between tenants  Problem: Apps require rich data models. Ex: Facebooks TAO</p>
    <p>Implement using gets &amp; puts?  Data movement, client stalls</p>
    <p>Push code to key-value store?  Isolation costs limit density</p>
    <p>Splinter: Multi-tenant key-value store that code can be pushed to</p>
    <p>Tenants push type- &amp; memory-safe code written in Rust at runtime</p>
    <p>&gt; 1000 tenants/server, 3.5 Million ops/s, 9s median latency</p>
  </div>
  <div class="page">
    <p>Richer Data Models Come At A Price</p>
    <p>Apps require rich data models in addition to performance</p>
    <p>Ex: Social graphs, Decision trees etc.</p>
    <p>Key-value stores trade-off data model for performance</p>
    <p>Simple get()s &amp; put()s over key-value pairs</p>
    <p>Key-value store</p>
    <p>get_friends(user)</p>
    <p>Client</p>
    <p>get()/put()</p>
    <p>Hash Table Records</p>
    <p>Thinner data model  Better performance But do applications benefit?</p>
  </div>
  <div class="page">
    <p>Richer Data Models Come At A Price</p>
    <p>Apps require rich data models in addition to performance</p>
    <p>Ex: Social graphs, Decision trees etc.</p>
    <p>Key-value stores trade-off data model for performance</p>
    <p>Simple get()s &amp; put()s over key-value pairs</p>
    <p>Key-value store</p>
    <p>get_friends(user)</p>
    <p>Client</p>
    <p>get()/put()</p>
    <p>Hash Table Records</p>
    <p>Thinner data model  Better performance But do applications benefit?</p>
  </div>
  <div class="page">
    <p>Extra Round-Trips (RTTs) Hurt Latency &amp; Utilization</p>
    <p>Example: Traverse tree with N nodes using gets</p>
    <p>One get() at each level of the tree  O(log N) RTTs</p>
    <p>Control flow depends on data  Client stalls during get()</p>
    <p>Key-value store</p>
    <p>Client</p>
    <p>get()/put()</p>
    <p>Hash Table Records</p>
    <p>Network RTTs, dispatch are the main bottleneck ~10s</p>
    <p>1.5s inside the server</p>
    <p>So push code to storage?</p>
  </div>
  <div class="page">
    <p>Extra Round-Trips (RTTs) Hurt Latency &amp; Utilization</p>
    <p>Example: Traverse tree with N nodes using gets</p>
    <p>One get() at each level of the tree  O(log N) RTTs</p>
    <p>Control flow depends on data  Client stalls during get()</p>
    <p>Key-value store</p>
    <p>Client</p>
    <p>get()/put()</p>
    <p>Hash Table Records</p>
    <p>Network RTTs, dispatch are the main bottleneck ~10s</p>
    <p>1.5s inside the server</p>
    <p>So push code to storage?</p>
  </div>
  <div class="page">
    <p>Why Not Push Compute To Storage?</p>
    <p>ISOLATION?</p>
    <p>Key-value store</p>
    <p>fn get_friends() { . . . }</p>
    <p>fn get_friends() { . . . }</p>
    <p>fn get_friends() { . . . }</p>
    <p>fn get_friends() { . . . }</p>
    <p>fn get_friends() { . . . }</p>
    <p>fn get_friends() { . . . }</p>
    <p>fn get_friends() { . . . }</p>
    <p>fn get_friends() { . . . }</p>
    <p>fn get_friends() { . . . }</p>
    <p>fn get_friends() { . . . }</p>
    <p>fn get_friends() { . . . }</p>
    <p>fn get_friends() { . . . }</p>
    <p>fn get_friends() { . . . }</p>
    <p>fn get_friends() { . . . }</p>
    <p>fn get_friends() { . . . }</p>
    <p>fn classify() { . . . }</p>
    <p>Context Switches ~1.5s Multi-tenancy  Need hardware isolation</p>
    <p>RPC Processing Time ~1.5s Only native code will do</p>
  </div>
  <div class="page">
    <p>What Do We Want From The Storage Layer?</p>
    <p>Extremely high tenant density</p>
    <p>Fine-grained resource allocation; 100s of CPU cycles, Kilobytes of memory</p>
    <p>Allow tenants to extend data model at runtime</p>
    <p>Low overhead isolation between tenants &amp; storage layer</p>
    <p>Granularity of compute is steadily decreasing</p>
    <p>Virtual machines  Containers  Lambdas</p>
  </div>
  <div class="page">
    <p>Splinter: A Multi-Tenant Key-Value Store</p>
    <p>Tenants can install and invoke extensions at runtime</p>
    <p>Extensions written in Rust</p>
    <p>Rely on type and memory safety for isolation, avoids context switch</p>
    <p>Implemented in ~9000 lines of Rust</p>
    <p>Supports two RPCs  install(ext_name) &amp; invoke(ext_name)</p>
    <p>Also supports regular get() &amp; put() RPCs  Native operations</p>
  </div>
  <div class="page">
    <p>rustc rustcrustc</p>
    <p>SplinterSplinter</p>
    <p>Tenants</p>
    <p>Tenant Hash Tables</p>
  </div>
  <div class="page">
    <p>SplinterSplinter</p>
    <p>Tenants</p>
    <p>Tenant Hash Tables</p>
    <p>Tenants push extensions written in Rust</p>
    <p>rustc rustcrustc</p>
    <p>Splinter compiles, loads extensions</p>
    <p>Into address-space</p>
  </div>
  <div class="page">
    <p>rustc rustcrustc</p>
    <p>SplinterSplinter</p>
    <p>Tenants</p>
    <p>Tenant Hash Tables</p>
    <p>Rust provides memory-safety</p>
    <p>Extensions do not share state</p>
    <p>Rust provides memory-safety</p>
    <p>Extensions do not share state</p>
    <p>Trust Boundary</p>
  </div>
  <div class="page">
    <p>rustc rustcrustc</p>
    <p>SplinterSplinter</p>
    <p>Tenants</p>
    <p>Tenant Hash Tables</p>
    <p>Trust Boundary</p>
    <p>Extensions receive references to records</p>
    <p>Each tenant sees a custom key-value store</p>
  </div>
  <div class="page">
    <p>invoke(aggregate, K) sum: 64 bits</p>
    <p>Simple Aggregation With Splinter</p>
    <p>V1[0] + V2[0] + V3[0]</p>
    <p>Client</p>
    <p>Splinter Server</p>
    <p>Native mode</p>
    <p>Splinter Server</p>
    <p>V1[0] + V2[0] + V3[0]</p>
    <p>Client</p>
    <p>Extension mode</p>
    <p>get(K) K1 K2 K3K1 K2 K3</p>
  </div>
  <div class="page">
    <p>invoke(aggregate, K) sum: 64 bitsK1 K2 K3</p>
    <p>Simple Aggregation With Splinter</p>
    <p>Splinter Server</p>
    <p>V1[0] + V2[0] + V3[0]</p>
    <p>Client</p>
    <p>get(K) K1 K2 K3</p>
    <p>Native mode</p>
    <p>Splinter Server</p>
    <p>V1[0] + V2[0] + V3[0]</p>
    <p>Client</p>
    <p>Extension mode</p>
  </div>
  <div class="page">
    <p>invoke(aggregate, K) sum: 64 bits</p>
    <p>Simple Aggregation With Splinter</p>
    <p>Splinter Server</p>
    <p>V1[0] + V2[0] + V3[0]</p>
    <p>Client</p>
    <p>multiget( )K1 K2 K3 V1 V2 V3</p>
    <p>Native mode</p>
    <p>Splinter Server</p>
    <p>V1[0] + V2[0] + V3[0]</p>
    <p>Client</p>
    <p>Extension mode</p>
  </div>
  <div class="page">
    <p>Simple Aggregation With Splinter</p>
    <p>Splinter Server</p>
    <p>V1[0] + V2[0] + V3[0]</p>
    <p>Client</p>
    <p>Native mode</p>
    <p>Splinter Server</p>
    <p>V1[0] + V2[0] + V3[0]</p>
    <p>Client</p>
    <p>Extension mode</p>
    <p>multiget( ) V1 V2 V3K1 K2 K3 invoke(aggregate, K) sum: 64 bits</p>
  </div>
  <div class="page">
    <p>Simple Aggregation With Splinter</p>
    <p>Splinter Server</p>
    <p>V1[0] + V2[0] + V3[0]</p>
    <p>Client</p>
    <p>Splinter Server</p>
    <p>V1[0] + V2[0] + V3[0]</p>
    <p>Client</p>
    <p>invoke(aggregate, K)</p>
    <p>Native mode Extension mode</p>
    <p>sum: 64 bits</p>
  </div>
  <div class="page">
    <p>Simple Aggregation With Splinter</p>
    <p>Native Extension</p>
    <p>Number of Records Aggregated</p>
    <p>Million Aggregations/s</p>
    <p>Extension Mode  Few RPCs, Less Data movement  Better Throughput</p>
  </div>
  <div class="page">
    <p>Splinter: Design</p>
    <p>Tenant Locality And Work Stealing</p>
    <p>Avoid cross-core coordination while avoiding hotspots</p>
    <p>Lightweight Cooperative Scheduling</p>
    <p>Prevent long running extensions from starving short running ones</p>
    <p>Low cost isolation</p>
    <p>No forced data copies across trust boundary</p>
  </div>
  <div class="page">
    <p>Splinter: Design</p>
    <p>Tenant Locality And Work Stealing</p>
    <p>Avoid cross-core coordination while avoiding hotspots</p>
    <p>Lightweight Cooperative Scheduling</p>
    <p>Prevent long running extensions from starving short running ones</p>
    <p>Low cost isolation</p>
    <p>No forced data copies across trust boundary</p>
  </div>
  <div class="page">
    <p>Flow Director</p>
    <p>Splinter: Tenant Locality And Work Stealing</p>
    <p>Problem: Quickly dispatch requests to cores, avoid hotspots</p>
    <p>Solution: NIC routes tenants to cores, cores steal work</p>
    <p>ServerServer</p>
    <p>Tenants</p>
    <p>NICNIC</p>
    <p>One Rx queue per core</p>
  </div>
  <div class="page">
    <p>Flow Director</p>
    <p>Splinter: Tenant Locality And Work Stealing</p>
    <p>Problem: Quickly dispatch requests to cores, avoid hotspots</p>
    <p>Solution: NIC routes tenants to cores, cores steal work</p>
    <p>ServerServer</p>
    <p>Tenants</p>
    <p>NIC Rx Queue</p>
    <p>NICNIC</p>
    <p>One Rx queue per core</p>
  </div>
  <div class="page">
    <p>Splinter: Tenant Locality And Work Stealing</p>
    <p>Problem: Quickly dispatch requests to cores, avoid hotspots</p>
    <p>Solution: NIC routes tenants to cores, cores steal work</p>
    <p>ServerServer</p>
    <p>Tenants</p>
    <p>Maintain Locality route tenant to queue</p>
    <p>NICNICFlow Director</p>
    <p>NIC Rx Queue</p>
  </div>
  <div class="page">
    <p>Splinter: Tenant Locality And Work Stealing</p>
    <p>Problem: Quickly dispatch requests to cores, avoid hotspots</p>
    <p>Solution: NIC routes tenants to cores, cores steal work</p>
    <p>ServerServer</p>
    <p>Tenants</p>
    <p>NICNIC</p>
    <p>Few active tenants Many idle tenants</p>
    <p>Hotspot</p>
  </div>
  <div class="page">
    <p>Splinter: Tenant Locality And Work Stealing</p>
    <p>Problem: Quickly dispatch requests to cores, avoid hotspots</p>
    <p>Solution: NIC routes tenants to cores, cores steal work</p>
    <p>ServerServer</p>
    <p>Tenants</p>
    <p>Cores steal from neighboring queue</p>
    <p>NICNIC</p>
  </div>
  <div class="page">
    <p>What are the benefits of tenant locality &amp; work stealing?</p>
    <p>Setup:</p>
    <p>1024 tenants</p>
    <p>Invoke small extension that reads one object</p>
  </div>
  <div class="page">
    <p>Performance With Tenant Locality &amp; Work Stealing</p>
    <p>Splinter No Work Stealing No Locality</p>
    <p>Tenant Skew</p>
    <p>Median Latency (s)</p>
    <p>Offered load = 4 Mop/s Approaching saturation</p>
    <p>Lower is better</p>
    <p>Higher tenant skew  Fewer active tenants</p>
    <p>No Tenant Locality  Poor median Latency</p>
  </div>
  <div class="page">
    <p>Performance With Tenant Locality &amp; Work Stealing</p>
    <p>Splinter No Work Stealing No Locality</p>
    <p>Tenant Skew</p>
    <p>Higher tenant skew  Fewer active tenants</p>
    <p>No work stealing  Poor tail Latency under high skew</p>
    <p>Offered load = 4 Mop/s Approaching saturation</p>
    <p>Lower is better</p>
  </div>
  <div class="page">
    <p>Splinter: Design</p>
    <p>Tenant Locality And Work Stealing</p>
    <p>Avoid cross-core coordination while avoiding hotspots</p>
    <p>Lightweight Cooperative Scheduling</p>
    <p>Prevent long running extensions from starving short running ones</p>
    <p>Low cost isolation</p>
    <p>No forced data copies across trust boundary</p>
  </div>
  <div class="page">
    <p>Splinter: Lightweight Cooperative Scheduling</p>
    <p>Problem: Minimize trust boundary crossing cost</p>
    <p>Solution: Run extensions in stackless coroutines</p>
    <p>NIC Rx Queue</p>
    <p>Worker Thread</p>
    <p>Coroutine</p>
    <p>Task Queue</p>
    <p>Dedicated Dispatch task to construct coroutines</p>
  </div>
  <div class="page">
    <p>Splinter: Lightweight Cooperative Scheduling</p>
    <p>Problem: Minimize trust boundary crossing cost</p>
    <p>Solution: Run extensions in stackless coroutines</p>
    <p>NIC Rx Queue</p>
    <p>Coroutine</p>
    <p>Task Queue Worker Thread</p>
  </div>
  <div class="page">
    <p>Splinter: Lightweight Cooperative Scheduling</p>
    <p>Problem: Minimize trust boundary crossing cost</p>
    <p>Solution: Run extensions in stackless coroutines</p>
    <p>NIC Rx Queue</p>
    <p>Coroutine</p>
    <p>Task Queue</p>
    <p>Dedicated Dispatch task to construct coroutinesWorker Thread</p>
  </div>
  <div class="page">
    <p>Splinter: Lightweight Cooperative Scheduling</p>
    <p>Problem: Minimize trust boundary crossing cost</p>
    <p>Solution: Run extensions in stackless coroutines</p>
    <p>NIC Rx Queue</p>
    <p>Coroutine</p>
    <p>Task Queue</p>
    <p>Dedicated Dispatch task to construct coroutines</p>
    <p>Task switch cost ~10ns</p>
    <p>Worker Thread</p>
  </div>
  <div class="page">
    <p>Splinter: Lightweight Cooperative Scheduling</p>
    <p>Problem: Minimize trust boundary crossing cost</p>
    <p>Solution: Run extensions in stackless coroutines</p>
    <p>NIC Rx Queue</p>
    <p>Coroutine</p>
    <p>Task Queue</p>
    <p>Task switch cost ~10ns</p>
    <p>Run extension until it returnsWorker Thread</p>
  </div>
  <div class="page">
    <p>Task switch cost ~10ns</p>
    <p>Splinter: Lightweight Cooperative Scheduling</p>
    <p>Problem: Long running tasks starve shorter tasks, hurt latency</p>
    <p>Solution: Extensions are cooperative, must yield frequently</p>
    <p>Running Task Preemption is too</p>
    <p>expensive!</p>
    <p>aggregate()  u64 {  yield;</p>
    <p>... }</p>
    <p>Task Queue</p>
  </div>
  <div class="page">
    <p>Splinter: Lightweight Cooperative Scheduling</p>
    <p>Problem: Long running tasks starve shorter tasks, hurt latency</p>
    <p>Solution: Extensions are cooperative, must yield frequently</p>
    <p>Running Task</p>
    <p>aggregate()  u64 {  yield;</p>
    <p>... }</p>
    <p>Compiler generates code to save &amp; restore state</p>
    <p>Task Queue</p>
  </div>
  <div class="page">
    <p>What are the benefits of cooperative scheduling?</p>
    <p>Setup:</p>
    <p>1024 tenants</p>
    <p>85% requests invoke small extension that reads one object</p>
    <p>15% requests invoke extension that reads 128 objects</p>
  </div>
  <div class="page">
    <p>Performance With And Without Yields</p>
    <p>Yields No Yields 0</p>
    <p>Median Latency (s)</p>
    <p>Offered load = 1 Mop/s</p>
    <p>Lower is better</p>
    <p>Yield frequently  Better Qos, Less interference</p>
  </div>
  <div class="page">
    <p>Splinter: Lightweight Cooperative Scheduling</p>
    <p>Problem: Uncooperative extensions</p>
    <p>Solution: Trusted watchdog core</p>
    <p>Running Task</p>
    <p>Task Queue</p>
    <p>aggregate()  u64 {  loop {};</p>
    <p>... }</p>
  </div>
  <div class="page">
    <p>aggregate()  u64 {  loop {};</p>
    <p>... }</p>
    <p>Splinter: Lightweight Cooperative Scheduling</p>
    <p>Problem: Uncooperative extensions</p>
    <p>Solution: Trusted watchdog core</p>
    <p>Uncooperative Task</p>
    <p>Task Queue</p>
    <p>Watchdog Poor Qos</p>
  </div>
  <div class="page">
    <p>aggregate()  u64 {  loop {};</p>
    <p>... }</p>
    <p>Splinter: Lightweight Cooperative Scheduling</p>
    <p>Problem: Uncooperative extensions</p>
    <p>Solution: Trusted watchdog core</p>
    <p>Watchdog</p>
    <p>Migrate worker thread</p>
  </div>
  <div class="page">
    <p>aggregate()  u64 {  loop {};</p>
    <p>... }</p>
    <p>Splinter: Lightweight Cooperative Scheduling</p>
    <p>Problem: Uncooperative extensions</p>
    <p>Solution: Trusted watchdog core</p>
    <p>Watchdog Delete Rx queue</p>
    <p>Spawn new worker thread Extension cannot send/recv packets</p>
  </div>
  <div class="page">
    <p>aggregate()  u64 {  loop {};</p>
    <p>... }</p>
    <p>Splinter: Lightweight Cooperative Scheduling</p>
    <p>Problem: Uncooperative extensions</p>
    <p>Solution: Trusted watchdog core</p>
    <p>Watchdog</p>
    <p>Steal enqueued tasks</p>
    <p>Kill worker thread when task yields</p>
    <p>Poor Qos</p>
  </div>
  <div class="page">
    <p>What are the benefits of the watchdog?</p>
    <p>Setup:</p>
    <p>1024 tenants</p>
    <p>Invoke small extension that reads one object</p>
  </div>
  <div class="page">
    <p>Performance With Misbehavior</p>
    <p>Fraction of Misbehaving Extensions</p>
    <p>Throughput (Mop/s)</p>
    <p>Offered load = 3 Mop/s</p>
    <p>Watchdog  Maintain performance during misbehavior</p>
  </div>
  <div class="page">
    <p>Performance With Misbehavior</p>
    <p>Fraction of Misbehaving Extensions</p>
    <p>Offered load = 3 Mop/s</p>
  </div>
  <div class="page">
    <p>Performance With Misbehavior</p>
    <p>Fraction of Misbehaving Extensions</p>
    <p>Offered load = 3 Mop/s</p>
    <p>Will need tight admission control</p>
    <p>Every 1/3 seconds</p>
  </div>
  <div class="page">
    <p>Splinter: Design</p>
    <p>Tenant Locality And Work Stealing</p>
    <p>Avoid cross-core coordination while avoiding hotspots</p>
    <p>Lightweight Cooperative Scheduling</p>
    <p>Prevent long running extensions from starving short running ones</p>
    <p>Low cost isolation</p>
    <p>No forced data copies across trust boundary</p>
  </div>
  <div class="page">
    <p>Splinter: Low Cost Isolation</p>
    <p>Problem: No forced data copies across trust boundary</p>
    <p>Solution: Ensure buffers outlast reference lifetime</p>
    <p>aggregate()  u64 {  ...</p>
    <p>... }</p>
    <p>Request Buffer</p>
    <p>Response Buffer</p>
    <p>Refs</p>
    <p>Send references to extension</p>
  </div>
  <div class="page">
    <p>Splinter: Low Cost Isolation</p>
    <p>Problem: No forced data copies across trust boundary</p>
    <p>Solution: Ensure buffers outlast reference lifetime</p>
    <p>Request Buffer</p>
    <p>Response Buffer</p>
    <p>aggregate()  u64 {  ...</p>
    <p>... }</p>
    <p>Refs</p>
    <p>Send references to extension</p>
  </div>
  <div class="page">
    <p>Splinter: Low Cost Isolation</p>
    <p>Problem: No forced data copies across trust boundary</p>
    <p>Solution: Ensure buffers outlast reference lifetime</p>
    <p>Request Buffer</p>
    <p>Response Buffer</p>
    <p>aggregate()  u64 {  ...</p>
    <p>... }</p>
    <p>Refs</p>
    <p>Statically ensure RPC buffers</p>
    <p>outlast lifetime</p>
    <p>Lifetime</p>
    <p>Statically ensure record stays</p>
    <p>stable across yields</p>
  </div>
  <div class="page">
    <p>Splinter: Low Cost Isolation</p>
    <p>Problem: No forced data copies across trust boundary</p>
    <p>Solution: Ensure buffers outlast reference lifetime</p>
    <p>Record</p>
    <p>aggregate()  u64 {  yield;</p>
    <p>... }</p>
    <p>Ref</p>
    <p>Statically ensure record stays</p>
    <p>stable across yields</p>
    <p>Lifetime</p>
    <p>Refer to paper</p>
  </div>
  <div class="page">
    <p>Pushing Facebooks TAO To Splinter</p>
    <p>Native Extension Hybrid 0</p>
    <p>Throughput (Mop/s)</p>
    <p>Hybrid  get() for point ops, extension for dependencies</p>
    <p>Best of both worlds!</p>
  </div>
  <div class="page">
    <p>Related Work  Language isolation for kernels  SPIN, Singularity</p>
    <p>Low runtime overheads, zero-copy interface</p>
    <p>Using Rust for memory safety  NetBricks, Tock</p>
    <p>Small set of static functions; does not target massive tenant densities</p>
    <p>Software fault isolation</p>
    <p>Requires data copies, page table manipulation</p>
    <p>Pushing extensions/compute to storage  Malacology, Redis etc</p>
    <p>Extensions are usually trusted, SQL not very good for ADTs</p>
  </div>
  <div class="page">
    <p>Conclusion  Kernel-bypass key-value stores offer &lt; 10s latency, &gt; Mops/s throughput</p>
    <p>Fast because theyre just dumb?</p>
    <p>Problem: Leverage performance  share between tenants  Problem: Apps require rich data models. Ex: Facebooks TAO</p>
    <p>Implement using gets &amp; puts?  Data movement, client stalls</p>
    <p>Push code to key-value store?  Isolation costs limit density</p>
    <p>Splinter: Multi-tenant key-value store that code can be pushed to</p>
    <p>Tenants push type- &amp; memory-safe code written in Rust at runtime</p>
    <p>&gt; 1000 tenants/server, 3.5 Million ops/s, 9s median latency</p>
  </div>
</Presentation>
