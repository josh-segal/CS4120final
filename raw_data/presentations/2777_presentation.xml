<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>G-NET: Effective GPU Sharing In NFV Systems</p>
    <p>Kai Zhang*, Bingsheng He^, Jiayu Hu#, Zeke Wang^, Bei Hua#, Jiayi Meng#, Lishan Yang#</p>
    <p>*Fudan University ^National University of Singapore</p>
    <p>#University of Science and Technology of China</p>
  </div>
  <div class="page">
    <p>Network Function Virtualization (NFV)</p>
    <p>VirtualizationVirtualization</p>
    <p>IPsec Router</p>
    <p>Virtualization</p>
    <p>IPS LB</p>
    <p>Firewall NIDS</p>
    <p>Easier to manage/deploy, higher flexibility, higher scalability, easier to validate, etc.</p>
    <p>Network Functions: nodes on the data path between a source host and a destination host  Firewall, NIDS, IPS, Gateway, VPNs, Load Balancers, etc.</p>
    <p>NFV is a network architecture concept: hardware =&gt; software  Based on virtualization techniques</p>
    <p>Construct service chains to provide specific services to meet different demands</p>
  </div>
  <div class="page">
    <p>GPUs in Accelerating Network Functions</p>
    <p>GPUs are proven to be a good candidate for accelerating network functions</p>
    <p>Router - PacketShader [Sigcomm10]  SSL reverse proxy - SSLShader [NSDI11]  NIDS - Kargus [CCS12], MIDeA [CCS11]  NDN Router - [NSDI13]</p>
    <p>Virtualization</p>
    <p>IPsec Router</p>
    <p>CPU GPU</p>
    <p>thread scheduling (a GPU hardware support)</p>
    <p>Nvidia Titan X: 3840 Cores 550 GB/s memory bandwidth</p>
    <p>price: $1999</p>
    <p>Intel Xeon E5-2697 v4: 18 Cores 76.8 GB/s memory bandwidth</p>
    <p>price: $2702</p>
  </div>
  <div class="page">
    <p>GPU-Accelerated Network Functions</p>
    <p>RX TXGPU Processing</p>
    <p>GPU</p>
    <p>PreProcessing</p>
    <p>PostProcessing</p>
  </div>
  <div class="page">
    <p>PostProcessing</p>
    <p>GPU-Accelerated Network Functions</p>
    <p>PreProcessing</p>
    <p>Parallel Processing in GPUs</p>
    <p>5</p>
    <p>RX</p>
    <p>Compute/memoryintensive tasks</p>
    <p>TX Construct/filter packet, etc.</p>
    <p>Packet parsing, batching, etc.</p>
  </div>
  <div class="page">
    <p>GPU</p>
    <p>Aho-Corasick algorithm</p>
    <p>Current GPU-based NFs - Exclusive Access to GPU  The GPU is only accessed by one network function</p>
    <p>NIDS</p>
    <p>Virtualization</p>
    <p>Why GPUs Have not Been Utilized in NFV Systems?</p>
  </div>
  <div class="page">
    <p>Bit vector linear search</p>
    <p>Aho-Corasick algorithm</p>
    <p>AES and SHA1 DIR-24-8-BASIC</p>
    <p>Temporal GPU Sharing - Only kernels from one VM can run on the GPU at a time</p>
    <p>Firewall NIDS IPsec Router</p>
    <p>GPU</p>
    <p>Virtualization</p>
    <p>Why GPUs Have not Been Utilized in NFV Systems?</p>
    <p>Inefficient</p>
  </div>
  <div class="page">
    <p>GPU capability: 70 Mpps</p>
    <p>Input: 20 Mpps</p>
    <p>Aho-Corasick algorithm</p>
    <p>Firewall NIDS IPsec Router</p>
    <p>GPUIdle</p>
    <p>Virtualization</p>
    <p>GPU underutilization</p>
    <p>Current Way of GPU Virtualization is Inefficient</p>
    <p>Temporal GPU Sharing - Only kernels from one VM can run on the GPU at a time</p>
  </div>
  <div class="page">
    <p>A B C A(2) Temporal sharing GPU Timeline</p>
    <p>Kernel</p>
    <p>AA A A AA GPU Timeline</p>
    <p>(1) Exclusive access KernelA</p>
    <p>Current Way of GPU Virtualization is Inefficient</p>
    <p>Temporal GPU Sharing - Only kernels from one VM can run on the GPU at a time</p>
    <p>GPU underutilization  Higher latency</p>
    <p>A</p>
  </div>
  <div class="page">
    <p>Spatial GPU Sharing</p>
    <p>Spatial GPU sharing  multiple kernels run on the GPU simultaneously  Minimize the interference of kernel executions from other NFs (Latency)</p>
    <p>Enhance utilization - Kernels from VMs can run on the GPU simultaneously (Throughput)</p>
    <p>(3) Spatial sharing</p>
    <p>GPU Timeline</p>
    <p>A B</p>
    <p>C</p>
    <p>A A A B B B B B</p>
    <p>C C C Kernel</p>
    <p>AA A A AA GPU Timeline</p>
    <p>(1) Exclusive access Kernel</p>
    <p>A B C A(2) Temporal sharing GPU Timeline</p>
    <p>Kernel</p>
  </div>
  <div class="page">
    <p>GPU</p>
    <p>Firewall NIDS IPsec Router</p>
    <p>Hyper-Q for Spatial GPU Sharing</p>
    <p>Hyper-Q for spatial GPU sharing  A technique that enables GPU kernels from the same GPU context to execute on the GPU</p>
    <p>simultaneously</p>
    <p>Challenges 1. VMs have different GPU context =&gt; Cannot utilize Hyper-Q directly</p>
    <p>Hyper-Q</p>
    <p>Virtualization</p>
  </div>
  <div class="page">
    <p>The Goal of G-NET</p>
    <p>Network Function Virtualization</p>
    <p>Flexibility Easy to manage</p>
    <p>/deploy Scalability</p>
    <p>AgilityEasy validation</p>
    <p>Development</p>
    <p>Security</p>
    <p>Scheduling</p>
    <p>Resource Allocation</p>
    <p>Spatial GPU Sharing</p>
    <p>GPU</p>
    <p>G-NET: NF-Hypervisor Co-Design</p>
  </div>
  <div class="page">
    <p>G-NET: GPU Virtualization</p>
    <p>GPU</p>
    <p>Manager Common Context</p>
    <p>Hypervisor</p>
    <p>A proxy creates a common context in the hypervisor for spatial GPU sharing</p>
    <p>Use API remoting to launch GPU operations</p>
    <p>Receive requests Perform GPU ops Send response</p>
    <p>NF1 NFn</p>
    <p>Framework Framework</p>
    <p>VMs</p>
  </div>
  <div class="page">
    <p>G-NET: System Workflow</p>
    <p>GPU</p>
    <p>Manager Common Context</p>
    <p>Hypervisor</p>
    <p>Switch</p>
    <p>NF1</p>
    <p>Framework</p>
    <p>NFn</p>
    <p>Framework</p>
    <p>NIC</p>
    <p>VMs</p>
    <p>Shared Memory</p>
    <p>Req.</p>
    <p>Resp.</p>
    <p>Zero-copy principle applied in system implementation</p>
  </div>
  <div class="page">
    <p>Achieve Predictable Performance</p>
    <p>Latency</p>
    <p>Throughput GPU Kernel</p>
    <p>Performance</p>
    <p>Quantity of Work</p>
    <p>Compute Resource</p>
    <p>NF Perf.</p>
    <p>Batch Size</p>
    <p>How to allocate GPU resources  GPUs utilize fast thread switching to enhance hardware utilization</p>
    <p>GPUs have massive hardware threads (#thread &gt;&gt; #core)</p>
    <p>Unlike CPUs, a GPU thread is unable to be bond to a specific core</p>
    <p>How to guarantee the performance of a service chain?</p>
    <p>Firewall NIDS IPsec Router</p>
    <p>Virtualization</p>
    <p>GPU</p>
    <p>?</p>
    <p>How to control the performance of an NF?</p>
  </div>
  <div class="page">
    <p>Achieve Predictable Performance</p>
    <p>Thread block</p>
    <p>Our Approach  Streaming Multiprocessor (SM) as the basic</p>
    <p>unit for resource allocation  One thread block can only run on one SM;</p>
    <p>A thread block would be scheduled to run on an idle SM when there are available ones</p>
    <p>A thread block is allocated with one SM when Total #thread blocks &lt;= Total #SMs</p>
    <p>Core SM</p>
    <p>GPU Kernel Performance</p>
    <p>Quantity of Work</p>
    <p>Compute Resource ?</p>
    <p>How to guarantee the performance of a service chain?</p>
    <p>Latency</p>
    <p>Throughput NF</p>
    <p>Perf. Firewall NIDS IPsec Router</p>
    <p>Virtualization</p>
    <p>GPU</p>
    <p>Batch Size How to control the</p>
    <p>performance of an NF?</p>
  </div>
  <div class="page">
    <p>Service Chain Based Scheduling</p>
    <p>Service chain based scheduling and resource allocation  Locate the bottleneck NF (the NF with the lowest throughput T)  Allocate resources for all NFs in the service chain to achieve throughput T * (1+P) (0&lt;P&lt;1)</p>
    <p>Firewall NIDS IPsec Router</p>
    <p>Firewall NIDS IPsec Router</p>
    <p>How to optimize the performance of a service chain with limited compute resources  NFs have different processing tasks</p>
    <p>SMs</p>
    <p>Throughput improves by P in each round</p>
  </div>
  <div class="page">
    <p>NF2</p>
    <p>Framework</p>
    <p>NF1</p>
    <p>Framework</p>
    <p>NFn</p>
    <p>Framework</p>
    <p>Service Chain Based Scheduling</p>
    <p>GPU</p>
    <p>Manager</p>
    <p>Common Context Hypervisor</p>
    <p>Switch</p>
    <p>NIC</p>
    <p>Scheduler</p>
    <p>Streaming Multiprocessor</p>
    <p>Traffic Speed 1. Batch size</p>
    <p>B1 B2</p>
    <p>NF1:5 NF2:4 NF3:7</p>
    <p>Bn VMs</p>
  </div>
  <div class="page">
    <p>NF1 NFn</p>
    <p>NF2</p>
    <p>Framework Framework Framework</p>
    <p>IsoPointer for GPU Memory Isolation</p>
    <p>GPU</p>
    <p>Manager</p>
    <p>Common Context</p>
    <p>Switch</p>
    <p>NIC</p>
    <p>Scheduler</p>
    <p>IsoPointer: guarantee GPU memory isolationMa</p>
    <p>*Pa</p>
    <p>Mb</p>
    <p>*Pb *P &gt; Memory Region  Base Address (B)  Memory Size (S)</p>
    <p>Pointer access checking: B &lt;= P &lt; B+S</p>
  </div>
  <div class="page">
    <p>NF Development</p>
    <p>GPU</p>
    <p>Manager</p>
    <p>Common Context</p>
    <p>Switch</p>
    <p>NIC</p>
    <p>Scheduler</p>
    <p>NF1 NFnNF2</p>
    <p>Framework Framework Framework</p>
    <p>Framework handles all common operations</p>
    <p>Repetitive development efforts  CPU-GPU pipeline  Manage CPU threads  Communicate with Manager  Packet I/O with Switch</p>
  </div>
  <div class="page">
    <p>NF Development</p>
    <p>GPU</p>
    <p>Manager Common Context</p>
    <p>Switch</p>
    <p>NIC</p>
    <p>NF1 NFnNF2</p>
    <p>Scheduler</p>
    <p>Framework Framework Framework</p>
    <p>Abstraction</p>
    <p>NF Spec.</p>
    <p>Abstraction</p>
    <p>NF Spec.</p>
    <p>Abstraction</p>
    <p>NF Spec.</p>
    <p>Framework handles all common operations</p>
    <p>Abstraction to simplify NF development</p>
    <p>Repetitive development efforts  CPU-GPU pipeline  Manage CPU threads  Communicate with Manager  Packet I/O with Switch</p>
  </div>
  <div class="page">
    <p>NF Development</p>
    <p>NF1</p>
    <p>Framework</p>
    <p>Abstraction</p>
    <p>NF Spec.</p>
    <p>GPU Processing</p>
    <p>PreProcessing</p>
    <p>PostProcessing</p>
    <p>pre_pkt_handler  post_pkt_handler  memcpy_htod  set_kernel_args  memcpy_dtoh</p>
    <p>+ GPU</p>
    <p>Kernel</p>
    <p>Core functions</p>
    <p>CPU code (Router)</p>
    <p>Implementation = Significantly reduces development efforts</p>
    <p>called for each pktcalled for each kernelcalled for each pkt</p>
  </div>
  <div class="page">
    <p>Evaluation</p>
    <p>Hardware</p>
    <p>CPU: Intel Xeon</p>
    <p>E5-2650 v4</p>
    <p>GPU: NVIDIA GTX</p>
    <p>TITAN X</p>
    <p>NIC: Intel XL710</p>
    <p>Software  Virtualization: Docker 17.03.0-ce  NIC Driver &amp; Library: DPDK 17.02.1  OS: CentOS 7.3.1611, Linux kernel 3.8.0-30</p>
    <p>Service Chains  2 NFs:</p>
    <p>3 NFs:</p>
    <p>4 NFs:</p>
    <p>NIDSIPsec</p>
    <p>Firewall NIDSIPsec</p>
    <p>NIDSIPsec Router</p>
    <p>Firewall NIDSIPsec Router</p>
    <p>{</p>
  </div>
  <div class="page">
    <p>Throughput</p>
    <p>Comparison with Temporal GPU Sharing</p>
    <p>N or</p>
    <p>m al</p>
    <p>iz ed</p>
    <p>Th</p>
    <p>ro ug</p>
    <p>hp ut</p>
    <p>Packet Size (Byte) 64 128 256 512 1024 1518</p>
    <p>Temporal Share G-NET (a) IPSec+NIDS</p>
    <p>up to 23.8%</p>
    <p>Packet Size (Byte) 64 128 256 512 1024 1518</p>
    <p>(b) Firewall+IPSec+NIDS</p>
    <p>up to 25.9%</p>
    <p>N or</p>
    <p>m al</p>
    <p>iz ed</p>
    <p>Th</p>
    <p>ro ug</p>
    <p>hp ut</p>
    <p>Packet Size (Byte) 64 128 256 512 1024 1518</p>
    <p>(c) IPSec+NIDS+Router</p>
    <p>up to 21.5%</p>
    <p>Packet Size (Byte) 64 128 256 512 1024 1518</p>
    <p>(d) Firewall+IPSec+NIDS+Router</p>
    <p>up to 70.8% More Resource</p>
    <p>Competition with four NFs</p>
  </div>
  <div class="page">
    <p>Scheduling</p>
    <p>Service chain scheduling scheme comparison  G-NET: optimize the performance of the service chain  FairShare: Evenly partition compute resources among NFs  UncoShare: Each NF tries to maximize its resource allocation</p>
    <p>Th ro</p>
    <p>ug hp</p>
    <p>ut</p>
    <p>Im pr</p>
    <p>ov em</p>
    <p>en t</p>
    <p>Packet Size (Byte) 64 128 256 512 1024 1518</p>
    <p>FairShare UncoShare G-NET</p>
    <p>Firewall + IPSec + NIDS + Router</p>
  </div>
  <div class="page">
    <p>Latency</p>
    <p>C D</p>
    <p>F</p>
    <p>Round Trip Time (microsecond) 0 1,000 2,000 3,000 4,000 5,000 6,000 7,000</p>
    <p>NIDS IPSec+NIDS Firewall+IPSec+NIDS Firewall+IPSec+NIDS+Router</p>
    <p>(b) 95th percentile latency</p>
    <p>IPSec+NIDS Firewall+ IPSec+NIDS</p>
    <p>Firewall+IPSec+ NIDS+Router</p>
    <p>G-NET Temporal GPU Sharing</p>
    <p>N or</p>
    <p>m al</p>
    <p>iz ed</p>
    <p>L at</p>
    <p>en cy</p>
    <p>IPSec+NIDS Firewall+ IPSec+NIDS</p>
    <p>Firewall+IPSec+ NIDS+Router</p>
    <p>(a) 50th percentile latency</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>G-NET:  An NFV system that efficiently utilizes GPUs with spatial GPU sharing  Service chain based scheduling and resource allocation scheme  Memory isolation with IsoPointer  Abstraction that simplifies building GPU-accelerated NFs</p>
    <p>Experimental Results Compare with temporal GPU sharing  Enhances throughput by up to 70.8%  Reduces latency by up to 44.3%</p>
    <p>G-NET High-efficient platform for building GPU-based NFV systems</p>
  </div>
</Presentation>
