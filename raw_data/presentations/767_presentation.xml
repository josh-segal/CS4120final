<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Generating Realistic Impressions for File-System Benchmarking</p>
    <p>Nitin Agrawal Andrea C. Arpaci-Dusseau, Remzi H. Arpaci-Dusseau</p>
  </div>
  <div class="page">
    <p>For better or for worse,&quot; benchmarks shape a field&quot;</p>
    <p>David Patterson</p>
  </div>
  <div class="page">
    <p>Inputs to file-system benchmarking</p>
    <p>Application Input: Benchmark workload</p>
    <p>Input: File-System Image</p>
    <p>FS logical organization</p>
    <p>Disk layout</p>
    <p>File System</p>
    <p>Input: In-memory state</p>
    <p>Storage device</p>
    <p>Postmark, FileBench, Fstress, Bonnie, IOZone, TPCC, etc etc</p>
    <p>Cold cache/warm cache</p>
    <p>Anything goes!</p>
  </div>
  <div class="page">
    <p>FS images in past: use what is convenient</p>
    <p>Randomly generated files of several MB (FAST 08)</p>
    <p>Typical desktop file system w/ no description (SOSP 05)</p>
  </div>
  <div class="page">
    <p>Performance of find operation</p>
    <p>R e</p>
    <p>la ti</p>
    <p>v e</p>
    <p>T</p>
    <p>im e</p>
    <p>T a k</p>
    <p>e n</p>
    <p>Disk layout</p>
    <p>&amp; cache state File-system logical</p>
    <p>organization</p>
  </div>
  <div class="page">
    <p>Problem scope</p>
    <p>Characteristics of file-system images have strong impact on performance</p>
    <p>We need to incorporate representative file-system images in benchmarking &amp; design</p>
    <p>How to create representative file-system images?</p>
  </div>
  <div class="page">
    <p>Requirements for creating FS images</p>
    <p>Access to data on file systems and disk layout  Properties of file-system metadata [Satyanarayan81,</p>
    <p>Mullender84, Irlam93, Sienknecht94, Douceur99, Agrawal07]  Disk fragmentation [Smith97]  More such studies in future?  A technique to create file-system images that</p>
    <p>is  Representative: given a set of input distributions  Controllable: supply additional user constraints  Reproducible: control &amp; report internal parameters  Easy to use: for widespread adoption and consensus</p>
  </div>
  <div class="page">
    <p>Introducing Impressions</p>
    <p>Powerful statistical framework to generate file-system images  Takes properties of file-system attributes as input  Works out underlying statistical details of the image  Mounted on a disk partition for real benchmarking  Satisfies the four design goals</p>
    <p>Applying Impressions gives useful insights  What is the impact on performance and storage size?  How does an application behave on a real FS image?</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction  Generating realistic file-system images  Applying Impressions: Desktop search  Conclusion</p>
  </div>
  <div class="page">
    <p>Overview of Impressions</p>
    <p>Impressions</p>
  </div>
  <div class="page">
    <p>Properties of file-system metadata Five-year study of file-system metadata [FAST07]</p>
    <p>(Agrawal, Bolosky, Douceur, Lorch)</p>
    <p>Used as exemplar for metadata properties in Impressions</p>
  </div>
  <div class="page">
    <p>Features of Impressions  Modes of operation for different usages</p>
    <p>Basic mode: choose default settings for parameters  Advanced mode: several individually tunable knobs</p>
    <p>Thorough statistical machinery ensures accuracy  Uses parameterized curve fits  Allows arbitrary user constraints  Built-in statistical tests for goodness-of-fit</p>
    <p>Generates namespace, metadata, file content, and disk fragmentation using above techniques</p>
  </div>
  <div class="page">
    <p>Creating valid metadata  Creating file-system namespace</p>
    <p>Uses Generative Model proposed earlier [FAST 07]  Explains the process of directory tree creation  Accurately regenerates distribution of directory</p>
    <p>size and of directory depth</p>
  </div>
  <div class="page">
    <p>Creating namespace</p>
    <p>Directory tree Monte Carlo run</p>
    <p>Incorporates dirs by depth and dirs by subdir count</p>
    <p>i Probability of parent selection</p>
    <p>Count(subdirs)+2</p>
    <p>C u m</p>
    <p>u la</p>
    <p>ti v e %</p>
    <p>o f d ir e c to</p>
    <p>ri e s</p>
    <p>Count of subdirectories</p>
    <p>Directories by Subdirectory Count</p>
    <p>D G</p>
    <p>Dirs by subdir count</p>
    <p>F ra</p>
    <p>c ti o n o</p>
    <p>f d ir e c to</p>
    <p>ri e s</p>
    <p>Namespace depth (bin size 1)</p>
    <p>Directories by Namespace Depth</p>
    <p>D G</p>
    <p>Dirs by namespace depth</p>
    <p>Dataset</p>
    <p>Generated</p>
  </div>
  <div class="page">
    <p>Creating valid metadata  Creating file-system namespace  Creating files: stepwise process</p>
    <p>File size, file extension, file depth, parent directory  Uses statistical models &amp; analytical approximations</p>
  </div>
  <div class="page">
    <p>Example: creating realistic file sizes</p>
    <p>Pure lognormal distribution no longer good fit  Hybrid model: lognormal body, Pareto tail</p>
    <p>Fits observed data more accurately, used to recreate file sizes in Impressions</p>
    <p>C o</p>
    <p>n tr</p>
    <p>ib u</p>
    <p>ti o</p>
    <p>n</p>
    <p>to u</p>
    <p>se d</p>
    <p>s p</p>
    <p>a ce</p>
    <p>Containing file size (bytes, log scale)</p>
    <p>Lognormal</p>
    <p>Hybrid</p>
    <p>File Sizes</p>
  </div>
  <div class="page">
    <p>Creating files</p>
    <p>File Size Model Lognormal body,</p>
    <p>Pareto tail Captures bimodal curve</p>
    <p>i S2 S4 S6 S8 S9 S1 S3 S5 S7 0</p>
    <p>F ra</p>
    <p>c ti o n o</p>
    <p>f b y te</p>
    <p>s</p>
    <p>File Size (bytes, log scale)</p>
    <p>Files by Containing Bytes</p>
    <p>D G</p>
    <p>Files by containing bytes</p>
  </div>
  <div class="page">
    <p>Creating files</p>
    <p>File Extensions Percentile values</p>
    <p>Top 20 extensions account for 50% of files and bytes</p>
    <p>i S2 S4 S6 S8 S9 S1 S3 S5 S7 E2 E4 E6 E8 E9 E3 E5 E7 E1</p>
    <p>Desired Generated</p>
    <p>F ra</p>
    <p>c ti o n o</p>
    <p>f fi le</p>
    <p>s</p>
    <p>Top Extensions by Count</p>
    <p>cpp dll exe gif h htm jpg null txt</p>
    <p>others</p>
    <p>cpp dll exe gif h htm jpg null txt</p>
    <p>others</p>
    <p>Top extensions by count</p>
  </div>
  <div class="page">
    <p>Creating files</p>
    <p>File Depth Poisson</p>
    <p>Multiplicative model along with bytes by depth</p>
    <p>F ra</p>
    <p>c ti o n o</p>
    <p>f fi le</p>
    <p>s</p>
    <p>Namespace depth (bin size 1)</p>
    <p>Files by Namespace Depth</p>
    <p>D G</p>
    <p>Files by namespace depth</p>
    <p>M e a n b</p>
    <p>y te</p>
    <p>s p</p>
    <p>e r</p>
    <p>fi le</p>
    <p>(l o g s</p>
    <p>c a le</p>
    <p>)</p>
    <p>Namespace depth (bin size 1)</p>
    <p>Bytes by Namespace Depth</p>
    <p>D G</p>
    <p>Bytes by namespace depth</p>
    <p>i S2 S4 S6 S8 S9 S1 S3 S5 S7 E2 E4 E6 E8 E9 E3 E5 E7 E1 D2 D4 D6 D8 D9 D3 D5 D7 D1</p>
  </div>
  <div class="page">
    <p>Creating files</p>
    <p>Parent Dir Inverse Polynomial</p>
    <p>Satisfies distribution of dirs with file count</p>
    <p>F ra</p>
    <p>c ti o n o</p>
    <p>f fi le</p>
    <p>s</p>
    <p>Namespace depth (bin size 1)</p>
    <p>Files by Namespace Depth (with Special Directories)</p>
    <p>D G</p>
    <p>Files by namespace depth w/ special dirs</p>
    <p>i</p>
  </div>
  <div class="page">
    <p>Resolving arbitrary constraints</p>
  </div>
  <div class="page">
    <p>F ra</p>
    <p>c ti o</p>
    <p>n o</p>
    <p>f fi le</p>
    <p>s</p>
    <p>File Size (bytes, log scale)</p>
    <p>C</p>
    <p>F ra</p>
    <p>c ti o</p>
    <p>n o</p>
    <p>f fi le</p>
    <p>s</p>
    <p>File Size (bytes, log scale)</p>
    <p>O</p>
    <p>Resolving arbitrary constraints</p>
    <p>Accurate both for the sum and the distribution 22</p>
    <p>Original Constrained</p>
    <p>Contrived for sum</p>
    <p>Constraint: Given count of files &amp; size distribution, ensure sum of file sizes matches a desired total file system size</p>
  </div>
  <div class="page">
    <p>Resolving arbitrary constraints</p>
    <p>Arbitrarily specified on file system parameters  Variant of NP-complete Subset Sum Problem</p>
    <p>Approximation algorithm based solution (in paper)  Oversampling to get additional sample values  Local improvement to iteratively converge to the</p>
    <p>desired sum by identifying best-fit in current sample</p>
    <p>While constraints are satisfied, constrained distribution also retains original characteristics</p>
  </div>
  <div class="page">
    <p>Interpolation and extrapolation</p>
    <p>Why dont we just use available data values?  Limited to empirical data in input dataset  What-if analysis beyond available dataset  Efficient to maintain compact curve fits and use</p>
    <p>interpolation/extrapolation instead of all data</p>
    <p>Technique: Piecewise interpolation</p>
  </div>
  <div class="page">
    <p>F ra</p>
    <p>c ti</p>
    <p>o n</p>
    <p>o f</p>
    <p>b y te</p>
    <p>s</p>
    <p>File Size</p>
    <p>Piecewise Interpolation</p>
    <p>Segment 19 Segment 19 Segment 19 Segment 19</p>
    <p>Se gm</p>
    <p>en t V al u e</p>
    <p>File System Size (GB)</p>
    <p>Interpola9on: Seg 19</p>
    <p>Interpolation technique &amp; accuracy Piecewise Interpolation</p>
    <p>Each distribution broken down into segments  Data points within a segment used for curve fit  Combine segment interpolations for new curve</p>
    <p>F ra</p>
    <p>ct io</p>
    <p>n o</p>
    <p>f b yt</p>
    <p>e s</p>
    <p>File Size</p>
    <p>Extrapolation (125 GB)</p>
    <p>R E</p>
    <p>File Size extrapolation 125GB</p>
    <p>F ra</p>
    <p>c ti o</p>
    <p>n o</p>
    <p>f b</p>
    <p>y te</p>
    <p>s</p>
    <p>File Size</p>
    <p>Interpolation (75 GB)</p>
    <p>R I</p>
    <p>File Size interpolation 75GB</p>
    <p>Real</p>
    <p>Interpolated</p>
    <p>Extrapolated</p>
    <p>Real</p>
  </div>
  <div class="page">
    <p>File content</p>
    <p>Files having natural language content  Word-popularity model (heavy tailed)  Word-length frequency model (for the long tail)</p>
    <p>Content for other files (mp3, gif, mpeg etc)  Impressions generates valid header/footer  Uses third-party libraries and software</p>
  </div>
  <div class="page">
    <p>Disk layout and fragmentation</p>
  </div>
  <div class="page">
    <p>Disk layout and fragmentation</p>
    <p>Simplistic technique  Layout Score for degree of fragmentation [Smith97]  Pairs of file create/delete operations till desired</p>
    <p>layout score is achieved</p>
    <p>In future more nuanced ways are possible  Out-of-order file writes, writes with long delays  Access to file-system specific interfaces</p>
    <p>FIPMAP in Linux, XFS_IOC_GETBMAP for XFS  Perhaps a tool complementary to Impressions</p>
    <p>File 1 File 2</p>
    <p>All blocks contiguous File Layout Score = 1 (6/6)</p>
  </div>
  <div class="page">
    <p>Outline</p>
    <p>Introduction  Generating realistic file-system images  Applying Impressions: Desktop search  Conclusion</p>
  </div>
  <div class="page">
    <p>Applying Impressions</p>
    <p>Case study: desktop search  Google desktop for linux (GDL) and Beagle  Metrics of interest:</p>
    <p>Size of index, time to build initial search index  Identifying application bugs and policies</p>
    <p>GDL doesnt index content beyond 10-deep</p>
    <p>Computing realistic rules of thumb  Overhead of metadata replication?</p>
  </div>
  <div class="page">
    <p>Impact of file content</p>
    <p>File content has significant affect: around 300% increase in index size for both GDL &amp; Beagle</p>
    <p>Understanding design: GDL index smaller than Beagle for text files, larger for binary files</p>
    <p>Beagle GDL</p>
    <p>In d</p>
    <p>e x S</p>
    <p>iz e</p>
    <p>/F S</p>
    <p>s iz</p>
    <p>e Index Size Comparison</p>
    <p>Text (1 Word) Text (Model)</p>
    <p>Binary</p>
  </div>
  <div class="page">
    <p>Impact of metadata and content</p>
    <p>Developer aid: understanding impact of different file system content &amp; different index schemes</p>
    <p>O rig</p>
    <p>in al</p>
    <p>T ex</p>
    <p>tC ac</p>
    <p>he</p>
    <p>D is D ir</p>
    <p>D is F ilt er</p>
    <p>R e la</p>
    <p>ti v e I n d e x S</p>
    <p>iz e</p>
    <p>Beagle: Index Size</p>
    <p>Default Text</p>
    <p>Image Binary</p>
  </div>
  <div class="page">
    <p>Impact of metadata and content</p>
    <p>Reproducing identical file-system image to compare other apps or ones developed later</p>
    <p>O ri g in a l</p>
    <p>T e xt C a ch</p>
    <p>e</p>
    <p>D is D ir</p>
    <p>D is F ilt e r</p>
    <p>R e la</p>
    <p>ti v e I n d e x S</p>
    <p>iz e</p>
    <p>Beagle: Index Size</p>
    <p>Default Text</p>
    <p>Image Binary</p>
    <p>Future App Beagle</p>
  </div>
  <div class="page">
    <p>Conclusion</p>
    <p>Impressions framework for realistic FS images  Representative, controllable, reproducible, easy to use  Includes almost all file system params of interest</p>
    <p>Extensible architecture  Plug in new statistical constructs, new models for</p>
    <p>metadata and content generation</p>
    <p>Powerful utility for file-system benchmarking  To be contributed publicly (coming soon) http://www.cs.wisc.edu/adsl/Software/Impressions</p>
  </div>
  <div class="page">
    <p>Nitin Agrawal http://www.cs.wisc.edu/~nitina</p>
    <p>Impressions download (coming soon) http://www.cs.wisc.edu/adsl/Software/Impressions</p>
    <p>Questions?</p>
    <p>i</p>
  </div>
</Presentation>
