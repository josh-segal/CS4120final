<?xml version="1.0" ?>
<Presentation>
  <div class="page">
    <p>Approximate Initialization of Camera Sensor Networks</p>
    <p>Purushottam Kulkarni K.R. School of Information Technology Indian Institute of Technology, Bombay</p>
    <p>Deepak Ganesan, Prashant Shenoy Department of Computer Science</p>
    <p>University of Massachusetts, Amherst</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 2</p>
    <p>Camera Sensor Networks</p>
    <p>Wireless network of tetherless imaging sensors  Directional camera sensors</p>
    <p>Applications  Ad-hoc Surveillance  Environmental and habitat monitoring</p>
    <p>Tasks  Object detection, recognition, tracking</p>
    <p>Field-of -view</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 3</p>
    <p>Camera Initialization</p>
    <p>Pre-requisite for applications tasks  Localization, requires camera coordinates  Duty-cycling, requires set/overlap of neighbors  Tracking, requires overlap location with neighbors</p>
    <p>Initialization parameters:  Extrinsic: location, orientation</p>
    <p>Intrinsic: focal length, skew, principal point</p>
    <p>Set of neighbors</p>
    <p>Degree of overlap</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 4</p>
    <p>Factors Effecting Initialization</p>
    <p>Computation Capability  Infrastructure Support</p>
    <p>Range Estimation  Landmarks</p>
    <p>sync</p>
    <p>range estimation pulse</p>
    <p>Cricket Mote</p>
    <p>Camera Sensor Networks  Landmarks hard to find  Resource-constraints</p>
    <p>Estimation of accurate parameters not possible</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 5</p>
    <p>Problem Statement</p>
    <p>Given a CSN with,  Limited computation capability  No/minimal infrastructure support</p>
    <p>is it possible to initialize cameras to enable applications?</p>
    <p>Proposed solution: Approximate Initialization  Estimate relative relationships between cameras  Use only picture taking capability and local</p>
    <p>processing of camera</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 6</p>
    <p>Outline</p>
    <p>Introduction &amp; Problem Statement</p>
    <p>Approximate Initialization Parameters</p>
    <p>Estimation Techniques</p>
    <p>Experimental Evaluation</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 7</p>
    <p>Approximate Initialization</p>
    <p>Degree of Overlap  Fraction of viewing region that overlaps with</p>
    <p>neighboring cameras</p>
    <p>k-overlap: fraction of viewing region overlapping by k cameras</p>
    <p>Approximates level of sensing redundancy with neighboring cameras</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 8</p>
    <p>Approximate Initialization</p>
    <p>Region of Overlap  spatial volume within viewing region that</p>
    <p>overlaps with another camera</p>
    <p>Degree of overlap does not estimate which portion overlaps with neighbors</p>
    <p>Approximates location of neighbors and spatial region of overlap</p>
    <p>Approximate estimates can support application requirements</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 9</p>
    <p>Duty-Cycling</p>
    <p>Operate in ON-OFF cycles  d:duty-cycling parameter (ON fraction)</p>
    <p>Oik: k-overlap of camera</p>
    <p>Parameter in proportion to degree of overlap (extent of redundant coverage)</p>
    <p>k</p>
    <p>d o k</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 10</p>
    <p>Triggered Wakeup</p>
    <p>Wakeup scenarios  Object tracking  Reliable detection</p>
    <p>Region of overlap can determine potential cameras</p>
    <p>C1</p>
    <p>C2 C3</p>
    <p>Object</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 11</p>
    <p>Estimating k-overlap</p>
    <p>k-overlap: ratio of randomly placed reference objects viewed simultaneously by k cameras</p>
    <p>cameras take pictures  determine if object can be viewed simultaneously by</p>
    <p>other cameras</p>
    <p>Camera 3</p>
    <p>Camera 2</p>
    <p>Camera 1</p>
    <p>k k i i</p>
    <p>i</p>
    <p>r O</p>
    <p>r</p>
    <p>reference points viewed at camera i</p>
    <p>ir</p>
    <p>k ir reference points</p>
    <p>viewed by k cameras</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 12</p>
    <p>Skewed Distributions</p>
    <p>Fraction of points does not represent fraction of overlap  Points in sparse region actually represent larger region  Error in estimation due to non-uniform distribution</p>
    <p>Camera 3</p>
    <p>Camera 2</p>
    <p>Camera 1 1 1O</p>
    <p>: 2/3</p>
    <p>: 1/9</p>
    <p>: 2/9</p>
    <p>: 1/2</p>
    <p>: 1/4</p>
    <p>: 1/4</p>
    <p>Estimated Exact</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 13</p>
    <p>Handling Skewed Distributions</p>
    <p>Assign area of each polygon as weight to corresponding reference point  Weight in proportion to density of neighbors</p>
    <p>k k i i</p>
    <p>i</p>
    <p>w O</p>
    <p>w</p>
    <p>Total weight of reference points viewed at camera i</p>
    <p>iw</p>
    <p>k iw Total weight of reference points</p>
    <p>viewed by k cameras</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 14</p>
    <p>Approximate 3D Voronoi Tessellation</p>
    <p>Accurate 3D tessellation  Compute intensive</p>
    <p>Approximation  Discretize volume into cubes  Calculate closest reference point</p>
    <p>Add volume to closest  Points in spare regions will have higher weights</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 15</p>
    <p>Determining Region of Overlap</p>
    <p>where the overlap exists between cameras</p>
    <p>region of overlap is the union of cells containing all simultaneously visible points</p>
    <p>C1 C2</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 16</p>
    <p>Estimate dr using object size, image size, focal length</p>
    <p>&amp; have same orientation</p>
    <p>Use unit vector along and dr to estimate location</p>
    <p>Estimating Reference Point Location</p>
    <p>f</p>
    <p>rd</p>
    <p>s</p>
    <p>s</p>
    <p>Lens</p>
    <p>P(-x,-y,-f) O</p>
    <p>R rd</p>
    <p>rv (unknown location)Image</p>
    <p>plane'</p>
    <p>r</p>
    <p>s s tan</p>
    <p>d f</p>
    <p>uuur PO</p>
    <p>uur rv</p>
    <p>uuur PO</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 17</p>
    <p>Outline</p>
    <p>Introduction &amp; Problem Statement</p>
    <p>Approximate Initialization Parameters</p>
    <p>Estimation Techniques</p>
    <p>Experimental Evaluation</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 18</p>
    <p>Experimental Evaluation</p>
    <p>Simulation  150 x 150 x 150  Two scenarios</p>
    <p>4 cameras  12 cameras</p>
    <p>Non-uniform distribution  Fraction of objects restricted area</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 19</p>
    <p>Experimental Evaluation</p>
    <p>Implementation  8 Cyclops camera sensors  Crossbow Micaz nodes  8ft x 6ft x 17ft</p>
    <p>Image Grabber Object Detection</p>
    <p>Bounding Box</p>
    <p>Cyclops View Table</p>
    <p>Initialization procedure</p>
    <p>HostMote trigger</p>
    <p>view information</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 20</p>
    <p>Weighted Approximation</p>
    <p>Demonstrates non-weighted scheme shortcoming  Performs 4-6 times worse than weighted</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 21</p>
    <p>Effect of Skew</p>
    <p>Weighted scheme can correct for skew better  Non-weighted scheme worse by a factor of 6</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 22</p>
    <p>Region of overlap</p>
    <p>Error decreases with #reference points  ~22% with 12 pts/camera  10% with 37 pts/camera</p>
    <p>Error ~10% in region of overlap estimation</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 23</p>
    <p>Applications</p>
    <p>Duty-cycling  Weighted scheme outperforms non-weighted</p>
    <p>Triggered wakeup  80% positive wakeups with 10 pts/camera with 2 triggers</p>
    <p>Duty-Cycling Triggered Wakeup</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 24</p>
    <p>Implementation Results</p>
    <p>k-overlap estimation error: 2-9%</p>
    <p>Region of overlap error: 1-11%</p>
    <p>Approximate techniques feasible in real deployments (~10% error)</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 25</p>
    <p>Related Work</p>
    <p>Camera calibration  Accurate Extrinsic and Intrinsic parameters [Tsai 86], [Tsai</p>
    <p>Multimedia Sensor Networks  Panoptes: A vision sensor [Feng 03]  Audio sensors [Raykar 03]</p>
    <p>Localization  Sensor Localization [He 03], [Savvides 01], [Whitehouse 02]  Active Badge [Harter 94], RADAR [Bahl 00], Cricket</p>
    <p>[Priyantha 00], Active Bat [Ward 97], GPS  Relative Locationing [Rao 03]</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 26</p>
    <p>Conclusions</p>
    <p>Proposed approximate techniques to estimate associations between cameras  Degree and region of overlap</p>
    <p>Demonstrated use of estimates to enable applications  Error in estimations tolerable</p>
    <p>http://sensors.cs.umass.edu</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 27</p>
    <p>Technology Trends</p>
    <p>Sensors/platforms span a large spectrum  Enable heterogeneous camera networks</p>
    <p>Stargate</p>
    <p>Fu n</p>
    <p>c ti</p>
    <p>o n a li ty</p>
    <p>Cyclops</p>
    <p>CMUcam</p>
    <p>Webcam</p>
    <p>Mote</p>
    <p>Telos</p>
    <p>XYZ</p>
    <p>Image Sensors Sensor platforms</p>
    <p>PTZ</p>
    <p>Energy</p>
    <p>Fu n</p>
    <p>c ti</p>
    <p>o n</p>
    <p>a li ty</p>
    <p>Energy</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 28</p>
    <p>Approximate Initialization</p>
    <p>Degree of overlap  Extent of overlapping coverage  k-overlap: fraction of viewing area covered by k cameras</p>
    <p>Region of overlap  where is the overlapping coverage  spatial region of overlap with neighboring</p>
    <p>cameras</p>
    <p>Above estimates can support application requirements</p>
  </div>
  <div class="page">
    <p>UNIVERSITY OF MASSACHUSETTS, AMHERST 29</p>
    <p>Triggered Wakeup</p>
    <p>Wakeup scenarios  Object tracking  Reliable detection</p>
    <p>Determine best camera  Projection line</p>
    <p>Object along this line  Reference points within</p>
    <p>distance threshold  Extent of overlap</p>
    <p>determines best camera</p>
    <p>Image</p>
    <p>Projection line</p>
    <p>Object</p>
    <p>Distance threshold</p>
  </div>
</Presentation>
