{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/joshuasegal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import utils as utils\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import os\n",
    "from datasets import Dataset\n",
    "from transformers.keras_callbacks import KerasMetricCallback, PushToHubCallback\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import create_optimizer, AutoTokenizer, TFAutoModelForSequenceClassification, DataCollatorWithPadding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# dataset_path = 'dataset'\n",
    "# papers_path = 'papers'\n",
    "# presentations_path = 'presentations'\n",
    "#\n",
    "# utils.move_xml_files(dataset_path, papers_path, presentations_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<TEI xmlns=\"http://www.tei-c.org/ns/1.0\" \\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \\nxsi:schemaLocation=\"http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd\"\\n xmlns:xlink=\"http://www.w3.org/1999/xlink\">\\n\\t<teiHeader xml:lang=\"en\">\\n\\t\\t<encodingDesc>\\n\\t\\t\\t<appInfo>\\n\\t\\t\\t\\t<application version=\"0.5.3\" ident=\"GROBID\" when=\"2019-03-26T16:26+0000\">\\n\\t\\t\\t\\t\\t<ref target=\"https://github.com/kermitt2/grobid\">GROBID - A machine learning software for extracting information from scholarly documents</ref>\\n\\t\\t\\t\\t</application>\\n\\t\\t\\t</appInfo>\\n\\t\\t</encodingDesc>\\n\\t\\t<fileDesc>\\n\\t\\t\\t<titleStmt>\\n\\t\\t\\t\\t<title level=\"a\" type=\"main\">Best-Response Mechanisms</title>\\n\\t\\t\\t</titleStmt>\\n\\t\\t\\t<publicationStmt>\\n\\t\\t\\t\\t<publisher/>\\n\\t\\t\\t\\t<availability status=\"unknown\"><licence/></availability>\\n\\t\\t\\t</publicationStmt>\\n\\t\\t\\t<sourceDesc>\\n\\t\\t\\t\\t<biblStruct>\\n\\t\\t\\t\\t\\t<analytic>\\n\\t\\t\\t\\t\\t\\t<author>\\n\\t\\t\\t\\t\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Noam</forename><surname>Nisan</surname></persName>\\n\\t\\t\\t\\t\\t\\t\\t<affiliation key=\"aff0\">\\n\\t\\t\\t\\t\\t\\t\\t\\t<orgName type=\"department\">School of Eng. and Computer Science</orgName>\\n\\t\\t\\t\\t\\t\\t\\t\\t<orgName type=\"institution\">The Hebrew University of Jerusalem</orgName>\\n\\t\\t\\t\\t\\t\\t\\t</affiliation>\\n\\t\\t\\t\\t\\t\\t</author>\\n\\t\\t\\t\\t\\t\\t<author>\\n\\t\\t\\t\\t\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Michael</forename><surname>Schapira</surname></persName>\\n\\t\\t\\t\\t\\t\\t\\t<affiliation key=\"aff1\">\\n\\t\\t\\t\\t\\t\\t\\t\\t<orgName type=\"department\">Computer Science Dept</orgName>\\n\\t\\t\\t\\t\\t\\t\\t\\t<orgName type=\"institution\">Princeton University</orgName>\\n\\t\\t\\t\\t\\t\\t\\t</affiliation>\\n\\t\\t\\t\\t\\t\\t</author>\\n\\t\\t\\t\\t\\t\\t<author>\\n\\t\\t\\t\\t\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Gregory</forename><surname>Valiant</surname></persName>\\n\\t\\t\\t\\t\\t\\t\\t<email>gvaliant@eecs.berkeley.edu</email>\\n\\t\\t\\t\\t\\t\\t\\t<affiliation key=\"aff2\">\\n\\t\\t\\t\\t\\t\\t\\t\\t<orgName type=\"department\">Dept. of Computer Science</orgName>\\n\\t\\t\\t\\t\\t\\t\\t\\t<orgName type=\"institution\">UC Berkeley</orgName>\\n\\t\\t\\t\\t\\t\\t\\t</affiliation>\\n\\t\\t\\t\\t\\t\\t</author>\\n\\t\\t\\t\\t\\t\\t<author>\\n\\t\\t\\t\\t\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Aviv</forename><surname>Zohar</surname></persName>\\n\\t\\t\\t\\t\\t\\t\\t<email>avivz@microsoft.com</email>\\n\\t\\t\\t\\t\\t\\t\\t<affiliation key=\"aff3\">\\n\\t\\t\\t\\t\\t\\t\\t\\t<orgName type=\"institution\" key=\"instit1\">Microsoft Research</orgName>\\n\\t\\t\\t\\t\\t\\t\\t\\t<orgName type=\"institution\" key=\"instit2\">Silicon Valley</orgName>\\n\\t\\t\\t\\t\\t\\t\\t</affiliation>\\n\\t\\t\\t\\t\\t\\t</author>\\n\\t\\t\\t\\t\\t\\t<title level=\"a\" type=\"main\">Best-Response Mechanisms</title>\\n\\t\\t\\t\\t\\t</analytic>\\n\\t\\t\\t\\t\\t<monogr>\\n\\t\\t\\t\\t\\t\\t<imprint>\\n\\t\\t\\t\\t\\t\\t\\t<date/>\\n\\t\\t\\t\\t\\t\\t</imprint>\\n\\t\\t\\t\\t\\t</monogr>\\n\\t\\t\\t\\t</biblStruct>\\n\\t\\t\\t</sourceDesc>\\n\\t\\t</fileDesc>\\n\\t\\t<profileDesc>\\n\\t\\t\\t<textClass>\\n\\t\\t\\t\\t<keywords>\\n\\t\\t\\t\\t\\t<term>Best Response</term>\\n\\t\\t\\t\\t\\t<term>Mechanism Design</term>\\n\\t\\t\\t\\t\\t<term>Incentive Compatible Dynamics</term>\\n\\t\\t\\t\\t</keywords>\\n\\t\\t\\t</textClass>\\n\\t\\t\\t<abstract>\\n\\t\\t\\t\\t<p>Under many protocols-in computerized settings and in economics settings-participants repeatedly &quot;best respond&quot; to each others&apos; actions until the system &quot;converges&quot; to an equilibrium point. We ask when does such myopic &quot;local rationality&quot; imply &quot;global rationality&quot;, i.e., when is it best for a player, given that the others are repeatedly best-responding, to also repeatedly best-respond? We exhibit a class of games where this is indeed the case. We identify several environments of interest that fall within our class: models of the Border Gateway Protocol (BGP) [7], that handles routing on the Internet, and of the Transmission Control Protocol (TCP) [5], and also stable-roommates [3] and cost-sharing [9, 10], that have been extensively studied in economic theory.</p>\\n\\t\\t\\t</abstract>\\n\\t\\t</profileDesc>\\n\\t</teiHeader>\\n\\t<text xml:lang=\"en\">\\n\\t\\t<body>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"1\">Introduction</head></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"1.1\">Motivation: When is it Best to BestRespond?</head><p>The basic object of study in game theory and in economics is the equilibrium: a \"stable\" state from which none of the players wish to deviate. Equilibrium is a static concept that often abstracts away the question of how it is reached. Once we start looking at dynamics, or at algorithms for finding equilibria, we cannot escape questions of the form \"How is an equilibrium reached?\". While there can be different formalizations of this question, in most cases, a truly satisfactory answer would have each player performing only simple \"locally rational\" actions and yet, mysteriously, the system would reach a global equilibrium. The simplest example of such phenomena is repeated best-response dynamics: each player selects the best (locally optimal) response to what others are currently doing, and this process goes on \"for a while\" until it \"converges\" to what must be a (pure Nash) equilibrium. Convergence of repeated bestresponse is, unfortunately, not guaranteed in general, and is the subject of much research, as is the convergence of more sophisticated \"locallyrational\" dynamics, e.g., fictitious play or regret minimization.</p><p>Our focus in this paper is on a different question that has received little attention so far: \"Is such locally rational behavior really rational?\". Specifically, we consider games in which repeated best-response dynamics do converge to an equilibrium and study the incentive properties of this process: Is it rational for players to repeatedly bestrespond? Can a long-sighted player improve, in the long run, over this repeated myopic optimization?</p><p>These questions about incentives are best explored in the context of games with incomplete information. Switching our attention from games with complete information to games with uncoupled incomplete information, we see that repeated best-response exhibits another attractive trait: to best-respond each player need only know his own utility function (\"type\"), as his best response does not depend on other players\\' utility functions, but only on their actions. Thus, we can view bestresponse dynamics as a natural protocol for gradual and limited sharing of information in an effort to reach an equilibrium. Indeed, in many real-life contexts the interaction between decision makers with incomplete information takes the form of best-response dynamics (e.g., Internet routing <ref type=\"bibr\" target=\"#b6\">[7]</ref>). When regarding best-response dynamics from this perspective, it is an indirect mechanism in the private-information mechanism-design sense. We wish to understand when such a mechanism, that dictates that all players repeatedly best-respond, is incentive compatible.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"1.2\">The Setting</head><p>Let us begin by laying out our setting for studying and formalizing incentives for repeated bestresponse. In our framework, each player holds a private utility function, and all players\\' utility functions, when put together, determine a fullinformation base game with some commonlyknown strategy spaces. We desire that the outcome of the dynamics be an equilibrium of this base game.</p><p>Base game: We are given an n-player (one-shot) base game G, with players 1, . . . , n, in which each player i has strategy space S i , and S = S 1 × ... × S n . Each player i has a utility function u i such that (u 1 , . . . , u n ) ∈ U ⊆ U 1 × · · · × U n , where U i ⊆ ℜ |S| is player i\\'s utility space. Each player knows only his own utility function, i.e., we view u i itself as player i\\'s type.</p><p>Best-response mechanisms: We study a class of indirect mechanisms, that we term \"repeatedresponse mechanisms\": players take turns selecting strategies; at each (discrete) time step t, some player i t selects and announces strategy s t i ∈ S it . Observe that one course of action available to each player in a repeated-response mechanism is to always choose a best-response to the most recently announced strategies of the others, that is, repeated-best-response. We call a repeated-response mechanism in which the prescribed behavior for each player is to repeatedly best-respond a \"best-response mechanism\". To fully-specify a best-response mechanism we must specify (1) the starting state; (2) the order of player activations (which player is \"active\" when); and (3) for each player, a rule for breaking ties among multiple best responses. All of our results hold regardless of the initial state and of the order of players\\' activations (so long as it is \"long enough\"), and, in fact, even in more general settings. <ref type=\"bibr\" target=\"#b0\">1</ref> We discuss tie-breaking rules below.</p><p>Goal: Our general aim is to identify interesting classes of (base) games for which best-response mechanisms are incentive-compatible.</p><p>Intuitively, a best-response mechanism is incentivecompatible if, when all other players are repeatedly best-responding, then a player is incentivized to do the same. Defining incentive compatibility in our setting involves many intricacies. We opt to focus here on a very general notion of incentive compatibility that, we believe, captures essentially any variant that the reader may desire; in a companion paper <ref type=\"bibr\" target=\"#b10\">[11]</ref>, we present several more games (auctions) where only strictly weaker notions of incentive compatibility can be obtained. Our notion of incentive compatibility here captures the two following distinct but complementary points of view: a mechanism design perspective and a learning equilibrium <ref type=\"bibr\" target=\"#b0\">[1,</ref><ref type=\"bibr\" target=\"#b1\">2]</ref> perspective.</p><p>Mechanism design perspective (in a prior-free non-Bayesian setting): This point of view is natural when analyzing finite-time protocols in computerized and economic settings. We are given a game with incomplete information G, where each player\\'s utility function is private, and we wish to implement a pure Nash equilibrium (PNE) of G. We point out that this uncommon objectiveimplementing an equilibrium-proves to be a natural implementation goal in many contexts (see Section 3, where we show that desirable outcomes can be regarded as \"stable states\"). Best-response mechanisms are incentive compatible, from this perspective, if the desired outcomes are implemented in the ex-post Nash sense 2 . Importantly, from this point of view, no actual play happens during the process of best-response dynamics and players merely announce strategies as their communication with the mechanism; each player only cares about maximizing his benefit from the final outcome of the mechanism, that is expected to ter-1 Our results actually hold even for (1) asynchronous player activation orders in which multiple players can best-respond simultaneously or based on outdated information (as studied in <ref type=\"bibr\" target=\"#b11\">[12]</ref>); (2) adaptive player activation orders that can change based on the history of play; and also when (3) the mechanism terminates as soon as all players \"pass\", that is, each player repeats his last strategy. <ref type=\"bibr\" target=\"#b1\">2</ref> The Revelation Principle then implies that the direct revelation mechanism is truthful (in the ex-post-nash sense). minate after some finite predetermined number of time steps.</p><p>Learning equilibrium perspective: This point of view is natural when analyzing environments such as Internet protocols and global financial transactions, where players repeatedly interact with each other and there is no \"final turn\". Now, the players are actually involved in infinite repeated play of the incomplete-information game G and each player has a rule for selecting his next strategy based on the history of play. We are interested in the natural rule that dictates that a player simply always best-respond to others\\' most-recent strategies. In this context, each player wishes to maximize his long-term payoff, that we model to be the lim sup of his stage utilities in this infinitely-played game 3 . Best-response mechanisms are incentive compatible, from this perspective, if the \"best-response\" rules are themselves in equilibrium in this infinite game regardless of the realization of (u 1 , . . . , u n ). Using the terminology of <ref type=\"bibr\" target=\"#b0\">[1,</ref><ref type=\"bibr\" target=\"#b1\">2]</ref>, this means that best-response dynamics are in \"learning equilibrium\". We stress that this would not follow from the folk theorem since our players do not, in any way, punish other players for deviation. To the contrary, our incentive compatibility results establish that the natural best-response dynamics are in equilibrium without requiring players to be able to detect and penalize other players\\' deviations.</p><p>Tie-breaking rules.</p><p>When multiple bestresponses exist we must specify, for each player, a tie-breaking rule. Importantly, this tie-breaking rule must be \"uncoupled\", i.e., depend solely on the player\\'s private information (utility function) and not on information that is unavailable to him 4 . Our tie-breaking rules always have the following simple form: fix, for each player i, an a-priori full order ≺ i on S i (that can depend on u i ), and instruct player i to break ties between multiple best-responses according to ≺ i . While this might seem innocent enough, we do get significant milage from delicate choices of these tie-breaking rules, to the point that one may desire an intuitive justification for these choices. Roughly speaking, there are two main, conflicting, intuitions: in some cases we simply ask players to break ties so as to be \"nice\" to others; in other cases we break ties according to some \"iterated-trembling-hand\" logic.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"1.3\">Games with Incentive-Compatible BestResponse Mechanisms</head><p>Our main results are identifying a class of games for which best-response mechanisms are incentive compatible, and exhibiting several interesting games that fall within this class (and thus have incentive-compatible best-response mechanisms). While at first glance, it might seem that the existence of a unique PNE to which best-response dynamics are guaranteed to converge implies the incentive-compatibility of best-response mechanisms, this intuition is false. Observe that in this game, (B, D) is the unique PNE and every sequence of best responses converges to it. Yet, consider the scenario that the starting point is the strategy profile (A, C), and the column player repeatedly best-responds. Clearly, the row player\\'s local improvement from (A, C) to (B, C) will lead to the column player moving to <ref type=\"bibr\">(B, D)</ref>. Hence, the row player can do better by looking ahead, not moving from (A, C), and thus \"getting stuck\" at (A, C), that he strictly prefers to the unique pure Nash (B, D). Hence, repeated best-responding is not incentive compatible in this game which is strictly-dominance-solvable, is a potential game, and has a unique and Paretooptimal PNE.</p><p>What traits must a game have for best-response dynamics to be incentive compatible?</p><p>We now present an intuitive exposition of a class of games for which this is achieved, which we term \"Never-Best-Response-Solvable (NBRsolvable) games with clear outcomes\". In an NBRsolvable game, strategies are iteratively eliminated if a best-response never leads to them (this is slightly different from dominance-solvability and shall be defined in the following section). Intuitively, an NBR-solvable game has a clear outcome if when each player i considers the game after the other players have already eliminated strategies that can be eliminated regardless of what i does, he can already tell that he will not be able to do better than the outcome that is reached via repeated best-response.</p><p>Our main, and quite easy to prove, general theorem is the following. (We now state the theorem for the case that the strategy spaces are finite, though our result also holds for infinite strategy spaces.)</p><p>Theorem (informal): Let G be an NBR-solvable game with a clear outcome. Then, for every starting point and every (finite or infinite) order of player activations with at least T = Σ i |S i | − n \"rounds\" (a round is a sequence of consecutive time steps in which each player is \"active\" at least once) it holds that:</p><p>1. Repeated best-response dynamics converges to a pure Nash equilibrium s * of G. 2. Repeated best-response dynamics is incentive compatible. We prove that each of the four environments below can be formulated as a game that falls within our class of games, and that the desired outcome in each environment translates to a PNE in this formulation. Thus, the above result implies the existence of incentive-compatible best-response mechanisms that implement the desired outcome in all the contexts below.</p><p>• Stable-roommates. In this classic setting <ref type=\"bibr\" target=\"#b2\">[3]</ref>, students must be paired for the purpose of sharing dorm rooms, and each student has a private full order over possible roommates.</p><p>The objective is to find a \"stable matching\" where no two students prefer each other to their assigned roommates. We show that a natural mechanism, in which a student repeatedly proposes to his most preferred roommate among those that would not immediately reject him, and immediately rejects all proposers except for his most preferred proposer, is incentive compatible in well-studied environments (interns-hospitals, correlated markets).</p><p>• Cost-sharing. Cost-sharing arises in situations in which the cost of some public service (e.g., building a bridge) must be distributed between self-interested users that can benefit from this service to different extents. We present a distributed mechanism that achieves this goal in an incentive-compatible manner.</p><p>Our mechanism implements the outcome of the famous Moulin mechanism <ref type=\"bibr\" target=\"#b8\">[9,</ref><ref type=\"bibr\" target=\"#b9\">10]</ref> (this result can be extended to the more general class of \"acyclic mechanisms\" <ref type=\"bibr\" target=\"#b7\">[8]</ref>).</p><p>• Internet routing. The Border Gateway Protocol (BGP) establishes routes between the smaller networks that make up the Internet.</p><p>We abstract the results in <ref type=\"bibr\" target=\"#b6\">[7]</ref> and prove that BGP is incentive compatible in realistic environments.</p><p>• Congestion control. The Transmission Control Protocol (TCP) handles congestion on the Internet. Building upon <ref type=\"bibr\" target=\"#b4\">[5]</ref>, that models key aspects of TCP, we consider behavior that is somewhat similar to TCP: increase your attempted transmission rate until encountering congestion, and then decrease the transmission rate. We show that such behavior is in equilibrium. Our results above establish incentive compatibility of best-response mechanisms. We also consider the stronger \"collusion-proofness\" desideratum, that even a coalition of players not be able to deviate from repeated best-response and all strictly gain from doing so. We prove that in some of the above environments best-response mechanisms even achieve this stronger requirement.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"1.4\">Research Agenda</head><p>We view this work as a first step towards a more general research agenda. While convergence to equilibrium of \"locally-rational\" dynamics, e.g., repeated best-response, fictitious play and regret minimization, has been extensively studied, little attention has been given to the question of when such locally-rational dynamics are also \"globally rational\". Here, we tackle this question in the context of repeated best-response and the implementation of PNE. However, we believe that the examination of other dynamics (e.g., fictitious play, regret minimization) and other kinds of equilibria (e.g., mixed Nash equilibrium, correlated equilibrium) is an interesting direction for future research.</p><p>Positive and negative results along these lines can help shed new light on the incentive structure of existing protocols/mechanisms (see our results for BGP and TCP and the results in <ref type=\"bibr\" target=\"#b4\">[5,</ref><ref type=\"bibr\" target=\"#b6\">7]</ref>), and provide new insights into the design of new protocols/mechanisms.</p><p>Our results for repeated best-response dynamics establish sufficient conditions for repeated bestresponse to be incentive compatible. We still lack characterizations of conditions that imply incentive compatibility both for general games and for specific classes of games (dominance-solvable games, potential games, etc.). We have thus far considered a very strong notion of incentive compatibility. We believe that considering more restrictive notions (e.g., incentive compatibility in expectation) is of interest. Indeed, in a companion paper <ref type=\"bibr\" target=\"#b10\">[11]</ref> we present several such results for commerce environments.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"1.5\">Organization</head><p>In the next section we formalize our model and present our general theorem. In section 3 we present our results for the four specific environments listed above. We discuss collusionproofness in Section 4.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"2\">Incentive-Compatible</head><p>Best-Response Dynamics Definition 2.1 (tie-breaking rules) A tiebreaking rule (or tie-breaking order) for player i is a full order ≺ i on S i .</p><p>When faced with a choice between multiple best-responses, player i should choose the highest (under ≺ i ) best-response. We now present the following definitions for full-information games.</p><p>Definition 2.2 (never-best-response strategies)</p><formula xml:id=\"formula_0\">s i ∈ S i is a never-best-response (NBR) under tie-breaking order ≺ i on S i if for all s −i , there exists s ′ i so that u i (s i , s −i ) &lt; u i (s ′ i , s −i ) OR both u i (s i , s −i ) = u i (s ′ i , s −i ) and s i ≺ i s ′ i .</formula><p>Definition 2.3 (NBR-solvable games) A game G is never-best-response-solvable (NBR-solvable) under tie-breaking rules ≺ 1 , . . . , ≺ n if there exists a sequence of eliminations of NBR strategies (under these tie breaking rules) that results in a single strategy profile.</p><p>Observe that every weakly-dominance-solvable game has a tie-breaking order under which it is NBR-solvable and every strongly-dominancesolvable game is NBR-solvable for all tie-breaking orders. Observe also that in every game that is NBR-solvable under tie-breaking rules ≺ 1 , . . . , ≺ n the elimination of NBR strategies (under these tie-breaking rules) has a unique orderindependent outcome, that is a pure Nash equilibrium of the game. We call this outcome \"the unique PNE under tie-breaking\".</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Definition 2.4 (shortest-elimination parameters)</head><p>Let G be an NBR-solvable game (under tiebreaking). Then, there exists a sequence of games G 0 , . . . , G r such that G = G 0 , in G r each player has only a single strategy, and ∀i ∈ {0, . . . , r −1}, G i+1 is obtained from G i via the removal of sets of NBR strategies (under tie-breaking). The shortest-elimination parameter e G for G is the length of the shortest such sequence of games for G.</p><p>Observe that if, in an NBR-solvable game G, each strategy space S i is finite, then e G ≤ Σ i |S i |− n. NBR solvability on its own is insufficient to guarantee incentive compatibility, and so we further restrict it.</p><p>Definition 2.5 (globally-optimal profiles) s ∈ S is globally optimal for i if ∀t ∈ S, u i (t) ≤ u i (s). Definition 2.6 (clear outcomes) Let G be an NBR-solvable game under tie breaking rules ≺ 1 , . . . , ≺ n . Let s * be the unique PNE under tiebreaking of G. We say that G has a clear outcome if for every player i there exists a (player-specific) order of elimination of NBR strategies (under the given tie-breaking rules) such that s * is globally optimal for i at the first step in the elimination sequence in which a strategy in S i is eliminated (that is, in the game obtained after the removal of all previously-eliminated strategies from G).</p><p>We say that an incomplete-information game G is NBR-solvable with a clear outcome (under tiebreaking rules) if every realization of (u 1 , . . . , u n ) induces a full-information game that is NBRsolvable with a clear outcome (under tie-breaking, when each player i uses the tie-breaking rule &lt; i for the realized u i ).</p><p>Consider a best-response mechanism M for a base game G. Let s t ∈ S be the players\\' strategies at time step t. We call u i (s t ) player i\\'s stage utility at time t. If M terminates after some finite number of time steps T &gt; 0 we say that player i\\'s total utility is Γ i = u i (s T ) (his stage utility at the last time step of M \\'s execution). If M does not terminate after finite time then i\\'s total utility is Γ i = lim sup t→∞ u i (s t ). M is incentive compatible if repeated best-response is a pure Nash equilibrium in this repeated game with overall utilities Γ 1 , . . . , Γ n for every realization of (u 1 , . . . , u n ). We say that M is collusion-proof if no coalition can deviate from repeated best-response and all strictly gain from doing so in this repeated game. We show that best-response mechanisms are incentive compatible for NBR-solvable games with clear outcomes.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Theorem 2.7 (incentive-compatible mechanisms)</head><p>Let G be NBR-solvable with a clear outcome s * ∈ S under tie-breaking rules ≺ 1 , . . . , ≺ n . Let M be a best-response mechanism for G that breaks ties as in ≺ 1 , . . . , ≺ n . Then, for every starting point and every (finite or infinite) order of player activations with at least T = e G \"rounds\", where a round is a sequence of consecutive time steps in which each player is \"active\" at least once,</p><p>1. M converges to s * . 2. M is incentive compatible. This holds even for (1) asynchronous player activations orders in which multiple players can bestrespond simultaneously or based on outdated information (as studied in <ref type=\"bibr\" target=\"#b11\">[12]</ref>); (2) adaptive player activations orders that can change based on the history of play; and also when (3) the mechanism terminates as soon as all players \"pass\", that is, each player repeats his last strategy.</p><p>Proof sketch: Let G be an NBR-solvable game with a clear outcome (under tie-breaking). Then, there exists a sequence of games G 0 , . . . , G r with length r = e G , such that G = G 0 , in G r each player has only a single strategy, and ∀i ∈ {0, . . . , r − 1}, G i+1 is obtained from G i via the removal of sets of NBR strategies (under tiebreaking).</p><p>Convergence: We first show that if all players repeatedly best-respond then convergence to a PNE is guaranteed within e G rounds. Consider the first round of a best-response mechanism, and consider some j ∈ [n] such that there exists s j ∈ S j that is NBR in G = G 0 . Observe that once j is activated for the first time, s j will never be selected thereafter. Thus, after the first round, no NBR strategy in G 0 will be played ever again and hence the game is effectively equivalent to G 1 . We can now use the same argument to show that after the second round the game is effectively equivalent to G 2 . Thus, we mimic the elimination sequence in each strategy until we end up at G r , whose unique strategy tuple s * is the unique PNE under tie-breaking of G.</p><p>Incentive compatibility: this property follows from the fact that when each player i considers the game after the other players have already eliminated dominated strategies that can be eliminated regardless of what i does, he can already tell that he will not be able to do better than the outcome that is reached via repeated best-response.</p><p>We give the precise argument (by contradiction). Let i be a player that deviates from repeated best-response and strictly gains from doing so. The fact that G is NBR-solvable with a clear outcome (under tie-breaking) implies that there exists a (player-specific) order of elimination of NBR strategies (under the given tie-breaking rules) such that s * is globally optimal for i at the first step in the elimination sequence in which a strategy in S i is eliminated (that is, in the game obtained after the removal of all previously-eliminated strategies from G). Consider this order of elimination; it induces some sequence of games G 0 , . . . , G l such that G = G 0 , in G l each player has only a single strategy, and ∀i ∈ {0, . . . , l − 1}, G i+1 is obtained from G i via the removal of sets of NBR strategies (under tie-breaking) as in the (i + 1)\\'th step in that order. Now, let t i be the index of the first game in the sequence in which i\\'s strategies are eliminated in that order. All players but i are repeatedly bestresponding and in the t i − 1 first steps of the elimination sequence no strategy in S i is eliminated. We can use the same arguments that we used to show convergence, to show that after t i − 1 rounds the game is effectively equivalent to G ti , regardless of the actions of player i. However, in that game, i can do no better than s * -a contradiction.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3\">Four Best-Response Mechanisms</head><p>We present four examples of environments that can be formulated as games that are NBRsolvable with clear outcomes (sometimes under tie-breaking): stable-roommates games, costsharing games, BGP games and TCP games. This implies the existence of incentive-compatible bestresponse mechanisms for all these environments.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.1\">Stable-Roommates</head><p>This following classic setting has been extensively studied in economics, game theory and computer science. n students 1, . . . , n must be paired for the purpose of sharing dorm rooms. Each student has a private strict ranking of the others, and prefers being matched to not being matched. The goal is to find a stable matching, i.e., a matching where no two students prefer each other to their matched roommates. Unfortunately, a stable matching is not guaranteed to exist in general and, furthermore, even if a stable matching does exist (e.g., in bipartite graphs), existing algorithms for reaching it are not incentive compatible <ref type=\"bibr\" target=\"#b2\">[3]</ref>. We seek environments where a stable matching is guaranteed to exist and can be reached in an incentive compatible manner. We focus on two wellknown special cases of stable roommates:</p><p>• Intern-hospital matchings: The \"students\" are divided into two disjoint sets, called interns and hospitals, and all hospitals have the same ranking of interns (e.g., GPA-based).</p><p>• Correlated markets: The \"students\" are vertices in a complete graph in which every edge has a unique \"weight\". The \"heavier\" the edge connecting a student to another student the higher that student ranks the other student. We now show how the framework in Section 2 can be used to design natural incentive compatible mechanisms for stable-roommates. We first formulate this environment as a game and prove that this game is NBR-solvable with a clear outcome.</p><p>Stable-roommates games: The students are the players and each student i\\'s strategy space S i is the set of all students j ̸ = i. α i (j) denotes student j\\'s rank in student i\\'s ranking (the least desired roommate\\'s rank is 1). ∀s = (s 1 , . . . , s n ) ∈ S (that is, choices of roommates), u i (s) = α i (j) iff s i = j and k ̸ = i such that s k = j and α j (k) &gt; α j (i); otherwise, u i (s) = 0. 5 (Observe that players\\' utilities are correlated.)</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Theorem 3.1 For every stable-roommates game G it holds that in both hospital-intern matchings and correlated markets</head><p>• G is NBR-solvable.</p><p>• G\\'s unique PNE is a stable matchings.</p><p>• e G ≤ n.</p><p>Proof sketch: We say that a stable-roommates game is cycle-free if there is no sequence of roomates r 1 , r 2 , . . . r k of length k &gt; 2 such that each student r i ranks student r i+1 higher than student r i−1 (where student indices are considered mod k to induce a cycle). Any matching game that is cycle-free has an elimination sequence that can be constructed as follows: At any stage in the elimination start with some arbitrary student r 1 (that has more than one strategy in the current subgame) and construct a sequence r 1 , r 2 , . . . of students in which r i+1 is the student r i prefers the most out of the students that still have more than one possible strategy remaining (other strategies were eliminated). The number of students is finite and so the sequence must repeat. Since the game is cycle free, the cycle must be of length 2. We have thus located 2 students that desire each other the most. We can eliminate for each of the two the strategies of proposing to any other student since they are guaranteed to gain the maximal utility by proposing to each other.</p><p>All that remains is to notice that both the hospital-intern game and the correlated markets game are cycle-free. In the case of hospitals and interns, the hospitals agree about the ranking of interns and so any cycle of players will have to include a hospital that is placed after a desired intern and before a less desired one. In the case of correlated markets, any cycle of nodes in the graph must include an edge with a lower weight that appears after an edge with a higher one and therefore the preferences do not induce a cycle in the matching graph in either case.</p><p>We observe that the following simple and computationally-efficient mechanism is a bestresponse mechanism for stable-roommate games, and so Theorem 2.7 implies that it implements a stable matching in an incentive-compatible manner.</p><p>Mechanism for Stable-Roommates:</p><p>• Go over the students in some cyclic (roundrobin) order and, at each time step, allow a single student to announce another student.</p><p>• We say that a student i makes a \"better offer\" to another student j at time t if (1) i announces j at time t; and (2) j prefers i to all students from whom he has \"offers\", that is, all students whose last announcement was j.</p><p>The mechanism prescribes that each student repeatedly check which students he can make a better offer to, and announce his most preferred student to whom he can make a better offer.</p><p>• The mechanism terminates after n 2 steps and outputs all student pairs (i, j) such that i\\'s last announcement was j and j\\'s last announcement was i.</p><formula xml:id=\"formula_1\">Theorem 3.2</formula><p>The mechanism is incentivecompatible in ex-post Nash and implements a stable matching in both intern-hospital matchings and correlated markets.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.2\">Cost-Sharing</head><p>Cost-sharing arises in situations in which the cost of some public service (e.g., building a bridge) must be distributed between self-interested users that can benefit from this service to different extents, and is modeled as follows. n users 1, . . . , n aim to share the cost of building some common infrastructure. Some cost-sharing rule specifies, for every subset of users S, and every user i ∈ S, i\\'s \"cost share\" c i (S) for building an infrastructure that only serves members of S. c i (S) is nonnegative, monotonically non-increasing in S, and also cross-monotonic, that is, ∀i ∈ S ⊆ T , c i (S) ≥ c i (T ). User i gets positive (private) value v i ∈ ℜ ≥0 if the infrastructure serves him and 0 otherwise. The goal is to split the cost of the infrastructure between a group of users so that each user\\'s payment is at least his cost-share, yet does not exceed his private value, that is, to find \"reasonable\" cost shares. Moulin <ref type=\"bibr\" target=\"#b8\">[9]</ref> exhibits a centralized mechanism that achieves this (see also <ref type=\"bibr\" target=\"#b9\">[10]</ref>).</p><p>We now use the framework in Section 2 to design simple and natural distributed incentivecompatible mechanisms that implement the same outcome as the Moulin mechanism. We present \"1 st -price cost-sharing games\" and specific tiebreaking rules.</p><p>1 st -price cost-sharing games: The users are the players and, for each user i, S i = ℜ ≥0 . Given a vector of users\\' bids (strategies) − → b = (b 1 , . . . , b n ), the \"serviced set\" for − → b is the maximum-cardinality subset of users S such that ∀j ∈ S, b j ≥ c j (S) (breaking ties between such sets lexicographically).</p><formula xml:id=\"formula_2\">∀ − → b = (b 1 , . . . , b n ), u i ( − → b ) = v i − b i if i is in the serviced set for − → b ; u i ( − → b ) = 0 otherwise.</formula><p>Tie-breaking rules: Prefer bids closer to v i , i.e.,</p><formula xml:id=\"formula_3\">∀s, t ∈ S i , if |s − v i | ≤ |t − v i | then t ≺ i s.</formula></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Theorem 3.3 For every 1 st -price cost-sharing game G it holds that</head><p>• G is NBR-solvable under these tie-breaking rules.</p><p>• G\\'s unique PNE under these tie-breaking rules induces reasonable cost shares as in the outcome of the Moulin mechanism.</p><p>• e G ≤ n.</p><p>Proof sketch: Let us show an elimination sequence for every cost sharing game. First, notice that each player can only get a non-positive utility from a bid that is above his valuation. We therefore start by eliminating these bids for all players. Next, let R v be the set of serviced users for bids that are exactly the valuations of the players. Any player i / ∈ R v will not get serviced for any set of bids that are in the remaining subgame (costs only increase as players drop out and he does not win when they all pay the maximal amount). We can therefore eliminate all strategies below v i for any such player. For every player j ∈ R v , we can eliminate all bids below c j (R v ), as he will only get 0 utility with those bids, and non-negative utility with higher bids. Once these are eliminated, then in the remaining subgame R v will always be the serviced set of players and we can eliminate all bids above c j (R v ) as well.</p><p>Note that it is also possible to perform the eliminations using a different order. Specifically, for each player i we can let all other players eliminate bids above v, then determine a set of serviced agents R i for the case in which every agent j bids v j except for agent i that bids ∞. Then, eliminate all bids for non-serviced agents (except their valuation), and check if c i (R i ) is greater than v i . If it is, we can eliminate bids below c i (R i ) for agent i. Otherwise, agent i will not gain a positive utility from the service in any case and we can eliminate all his strategies except his valuation. We can then continue along the same lines as before and eliminate strategies for all other players. Either way, the elimination done by agent i leads to a subgame in which s * is the optimal outcome for him, and so the game has a clear outcome as required.</p><p>We observe that the following natural distributed mechanism is a best-response mechanism for 1 st -price cost-sharing games (under these tiebreaking rules), and so Theorem 2.7 implies that it implements the outcome of the Moulin mechanism in an incentive-compatible manner.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Mechanism for Cost-Sharing:</head><p>• Go over the users in some cyclic (roundrobin) order and, at each time step, allow a single user to submit a bid in ℜ ≥0 .</p><p>• The mechanism prescribes that each bidder i repeatedly bid as follows: submit the minimal bid b i ≤ v i such that i is in the serviced set for the most-recently submitted bids; in the event that no such bid exists submit the bid b i = v i .</p><p>• The mechanism terminates after n 2 time steps, outputs the serviced set S for the lastsubmitted bids and charges each bidder i ∈ S his last bid b i .</p><formula xml:id=\"formula_4\">Theorem 3.4</formula><p>The mechanism is incentive compatible and implements reasonable cost-shares.</p><p>This result can be extended to the class of acyclic mechanisms studied in <ref type=\"bibr\" target=\"#b7\">[8]</ref>).</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.3\">Internet Routing</head><p>The Border Gateway Protocol (BGP) establishes routes between the smaller networks that make up the Internet. Griffin et al. <ref type=\"bibr\" target=\"#b5\">[6]</ref> put forth the following model for analyzing BGP dynamics. The network is an undirected graph G = (V, E) where the vertex set V consists of n source nodes and 1, . . . , n a unique destination node d. Each source node has a private strict ranking of all simple (loop-free) routes between itself and the destination node d. Under BGP, each source node repeatedly examines its neighboring nodes\\' most recent route-announcements, selects to forward traffic through the neighbor whose route it likes the most, and announces its newly chosen route to all neighbors via update messages. The network is asynchronous and so nodes can select routes simultaneously and based on outdated information (update messages between nodes can be arbitrarily delayed).</p><p>BGP\\'s convergence to a \"stable\" routing tree is the subject of extensive networking research. <ref type=\"bibr\">Levin et al. [7]</ref> observe that BGP can be regarded as best-response dynamics in a specific class of \"routing games\", and prove that BGP is incentivecompatible in networks for which the No Dispute Wheel <ref type=\"bibr\" target=\"#b5\">[6]</ref> condition holds.</p><p>Each pivot node u i would rather route clockwise through pivot node u i+1 than through the direct route Q i . No Dispute Wheel is a generalization of the Gao-Rexford <ref type=\"bibr\" target=\"#b3\">[4]</ref> conditions, that capture common Internet routing practices. A Dispute Wheel (see <ref type=\"figure\" target=\"#fig_1\">Figure 2)</ref> is a 3-tuple (U, R, Q), where U = (u 0 , u 1 , . . . , u k−1 ) is a sequence of k vertices in V , called the \"pivot nodes\" and R = (R 0 , R 1 , . . . , R k−1 ), Q = (Q 0 , Q 1 , . . . , Q k−1 ) are two sequences of k routes, such that (indices are considered modulo k):</p><p>• ∀i, Q i is a simple route from i to d.</p><p>• ∀i, R i is a simple route from u i to u i+1 .</p><p>• ∀i, u i ranks the route R i Q i+1 more highly than the route Q i . \"No Dispute Wheel\" is the condition that no Dispute Wheel exist in the network.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Theorem 3.5 [7] BGP is incentive-compatible in ex-post Nash in networks for which No Dispute Wheel holds.</head><p>We now show that the class of \"BGP games\" presented in <ref type=\"bibr\" target=\"#b6\">[7]</ref> falls within the category of NBRsolvable games with clear outcomes. Thus, the essence of the incentive compatibility result for BGP in <ref type=\"bibr\" target=\"#b6\">[7]</ref> follows from Theorem 2.7.</p><p>BGP games: The source nodes are the players and, for each source node i, S i is the set of i\\'s outgoing edges in E. Given a vector of source nodes\\' traffic forwarding decisions (strategies </p><formula xml:id=\"formula_5\">) − → f = (f 1 , . . . , f n ), u i ( − → f = (f 1 , . . . , f n )) is i\\'</formula></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Theorem 3.6 For a BGP game G it holds that</head><p>• G is NBR-solvable.</p><p>• G\\'s unique PNE is a stable routing tree.</p><p>• e G ≤ n.</p><p>Proof sketch: Let us show an elimination order in the game. At every stage in the elimination, we locate a node that can guarantee its most preferred route (in the current subgame) and eliminate all other routing actions for it. To show that such a node always exists, we begin with an arbitrary node a 0 with at least 2 actions. Let R 0 be a 0 \\'s most preferred existing route to d (a route is said to exist if all nodes along it can route accordingly in the current subgame). Let a 1 be the vertex closest to d on R 0 , with two available actions in the current subgame, such that a 1 prefers some other route R 1 to the suffix of R 0 that leads from a 1 to d (if no such node exists a 0 can guarantee its most preferred route). Then we choose a 2 to be the vertex closest to d on R 1 such that a 2 \\'s most preferred route R 2 is preferred over the suffix of R 1 that leads from a 2 to d. Once again if there is no such a 2 we are done. We can continue to choose a 3 , a 4 , . . . in the same manner. Since there is a finite number of vertices, at some point some vertex will appear twice in this sequence (a 0 , a 1 , . . .). This would result in the formation of a Dispute Wheel (in which the a i s are the pivot nodes and the R i s are the routes) which we assumed is not contained in the graph. We will therefore always be able to find a node that can guarantee its most preferred route and continue with the elimination, until there are no more nodes with several possible actions.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.4\">Congestion Control</head><p>Congestion control is a crucial task in communication networks. Congestion is handled via the combination of transmission-rate-adjustment protocols at the sender-receiver level (e.g., TCP), and queueing management policies at the router level, that dictate how excess traffic is discarded (e.g., RED). TCP is notoriously not incentive compatible. <ref type=\"bibr\" target=\"#b4\">[5]</ref> analyzes incentives in the following TCPinspired environment. The network is an undirected graph G = (V, E) with a given a capacity function c that specifies the capacity c(e) for each edge e ∈ E. The network consists of n sourcetarget pairs of vertices (α i , β i ). Every such sourcetarget pair (α i , β i ) aims to send traffic along a fixed route R i in G. Each source α i can select transmission rates that lie in the interval <ref type=\"bibr\">[0, M i ]</ref>, where M i is α i \\'s private information, and wishes to maximize its achieved throughput. When an edge encounters congestion, that is, the sum of incoming flows traversing it exceeds its capacity, excess traffic must be discarded. <ref type=\"bibr\" target=\"#b4\">[5]</ref> considers two capacityallocation schemes:</p><p>• Strict-Priority-Queueing (SPQ). ∀e ∈ E there is an edge-specific order over source nodes. Capacity is shared as follows: the most highly ranked source whose route traverses the edge gets its entire flow sent along the edge (up to c(e)); unused capacity is allocated to the second most highly ranked source whose route traverses the edge in a similar fashion, etc.</p><p>• Weighted-Fair-Queueing (WFQ). ∀e ∈ E, each source node α i has weight w i (e) at e. Every source α i is then allocated capacity wi Σj wj c(e). Unused capacity is allocated in a recursive manner. The special case that ∀e ∈ E, ∀i ∈ [n], w i (e) = 1 is called \"fair queueing\" (FQ).</p><p>[5] considers a TCP-like protocol called Probing-Increase-Educate-Decrease (PIED) in which each source is instructed to gradually increase its transmission rate until encountering congestion and, at that point, decrease its transmission rate to its achieved throughput. <ref type=\"bibr\" target=\"#b4\">[5]</ref> analyzes PIED in settings in which all edges use SPQ or all edges use WFQ, and sources priorities/weights are identical on all edges. PIED is shown to be incentive compatible in both these environments (also under asynchronous timings of rate-transmission adjustments). It is interesting to notice that PIED can be considered a form of better-response in a setting in which the exact available capacity is unknown. We unify the two results above for an abstracted setting by formulating the environment in <ref type=\"bibr\" target=\"#b4\">[5]</ref> as a game and showing that this game is NBR-solvable with a clear outcome (under specific tie-breaking rules). Our main difference from <ref type=\"bibr\" target=\"#b4\">[5]</ref> is that we allow players more knowledge about the network, while <ref type=\"bibr\" target=\"#b4\">[5]</ref> uses the probing nature of PIED to learn the needed information (all that is needed is for players to be able to tell the amount of available bandwidth on their path). Thus, Theorem 2.7 implies a result that is similar in spirit to the two theorems in <ref type=\"bibr\" target=\"#b4\">[5]</ref>.</p><p>TCP games: The source nodes are the players and each source node i\\'s strategy space is S i = [0, M i ]. Given a vector of source nodes\\' transmission rates (strategies) − → r = (r 1 , . . . , r n ), u i ( − → r ) is α i \\'s achieved throughput in the unique trafficflow equilibrium point of the network for − → r ( <ref type=\"bibr\" target=\"#b4\">[5]</ref> shows that such a unique equilibrium point exists for the SPQ and WFQ settings with coordinated priorities/weights).</p><p>Tie-breaking rules: ∀s, t ∈ S i , s ≺ i t iff s &gt; t. • e G ≤ n.</p><p>For clarity of presentation we show only the proof for the case of Weighted-Fair-Queueing, with equal weights. The proof for non-equal weights and for Strict-Priority-Queueing follow similar lines. Proof sketch: Let us define for each edge e, the share of each flow as β e = c e /k e where k e is the number of flows that traverse the edge. We construct an elimination sequence for the game as follows: Let e * be the edge with the minimal β. Each flow on this edge is guaranteed β e * traffic through that edge, and at least that amount on all other edges. It is therefore possible to eliminate all actions of transmitting less than β e * for each player that goes through e * . Now, if all flows through e * claim their fair share, no flow can send more (no bandwidth is unclaimed). We can therefore eliminate all actions of transmitting above β e * for these flows. Now, we are left with a subgame with a smaller number of active players where some of the bandwidth on each edge is already used up. We can now repeat the elimination steps for the residual network graph with the remaining players.</p><p>Notice that for each bottleneck edge e * that is found along the process there are several orders of elimination (according to ordering among players). If player i eliminates actions below β e * last among players that go through e * , then he does so in a game in which the final profile is optimal for him, and so the game has a clear outcome.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4\">Collusion-Proof Best-Response Mechanisms</head><p>In Section 3, we establish incentive compatibility results for four environments. We are able to strengthen our results for stable-roommates (Theorem 3.1), BGP games (Theorem 3.6), and TCP games where all edges use SPQ with coordinated priorities (see Theorem 3.9). We prove that, in all these settings, best-response mechanisms are actually also collusion-proof. We observe, though, that NBR-solvability with a clear outcome does not imply collusion-proofness of best-response mechanisms in general. To see this, consider the game depicted in <ref type=\"figure\" target=\"#fig_3\">Figure 3</ref> (which is simply the prisoner\\'s dilemma).</p><p>Observe that this game is indeed an NBRsolvable game with a clear outcome, yet both players prefer (C, C) to the unique equilibrium (D, D). Thus, the two players can jointly deviate from repeated best-response and both strictly gain from doing so.</p></div><figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_0\"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A game for which best-response mechanisms are not incentive compatible.</figDesc></figure>\\n<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_1\"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A Dispute Wheel</figDesc></figure>\\n<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_2\"><head></head><label></label><figDesc>s rank for the simple route from i to d under − → f (the least desired route has rank 1) if such a route exists; u i ( − → f ) = 0 otherwise.</figDesc></figure>\\n<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_3\"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: An NBR-solvable game with a clear outcome for which best-response mechanisms are not collusion proof.</figDesc></figure>\\n\\n\\t\\t\\t<note place=\"foot\" n=\"3\"> In all our results, at equilibrium the lim sup is actually the limit, and thus choosing lim sup gives us the strongest and most robust results -the definition is in fact adversarial to our proofs, it potentially allows manipulators to gain utility by avoiding convergence. 4 We note that it is also permissible for the tie-breaking rules to depend on the players&apos; actions, though for our purposes this was not needed.</note>\\n\\n\\t\\t\\t<note place=\"foot\" n=\"5\"> We note that the more natural definition of utilities that only awards utility to players that are selected by the partner they themselves choose implies a game in which all matchings are stable, and is thus not useful to us.</note>\\n\\t\\t</body>\\n\\t\\t<back>\\n\\t\\t\\t<div type=\"references\">\\n\\n\\t\\t\\t\\t<listBibl>\\n\\n<biblStruct xml:id=\"b0\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Efficient learning equilibrium</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Ronen</forename><forename type=\"middle\">I</forename><surname>Brafman</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Moshe</forename><surname>Tennenholtz</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">Artif. Intell</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"volume\">159</biblScope>\\n\\t\\t\\t<biblScope unit=\"issue\">1-2</biblScope>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"27\" to=\"47\" />\\n\\t\\t\\t<date type=\"published\" when=\"2004\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b1\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Optimal efficient learning equilibrium: Imperfect monitoring in symmetric games</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Ronen</forename><forename type=\"middle\">I</forename><surname>Brafman</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Moshe</forename><surname>Tennenholtz</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the National Conference on Artificial Intelligence (AAAI</title>\\n\\t\\t<meeting>the National Conference on Artificial Intelligence (AAAI</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<publisher>Press</publisher>\\n\\t\\t\\t<date type=\"published\" when=\"2005\" />\\n\\t\\t\\t<biblScope unit=\"page\" from=\"726\" to=\"731\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b2\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">College admissions and stability of marriage</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">D</forename><surname>Gale</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">L</forename><forename type=\"middle\">S</forename><surname>Shapley</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">Amer. Math. Monthly</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"issue\">69</biblScope>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"9\" to=\"15\" />\\n\\t\\t\\t<date type=\"published\" when=\"1962\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b3\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Stable Internet routing without global coordination</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Lixin</forename><surname>Gao</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Jennifer</forename><surname>Rexford</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">IEEE/ACM Transactions on Networking</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"volume\">9</biblScope>\\n\\t\\t\\t<biblScope unit=\"issue\">6</biblScope>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"681\" to=\"692\" />\\n\\t\\t\\t<date type=\"published\" when=\"2001\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b4\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Aviv Zohar, and Scott Shenker. Incentive compatibility and dynamics of congestion control. SIGMET-RICS Perform</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">P</forename><forename type=\"middle\">Brighten</forename><surname>Godfrey</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Michael</forename><surname>Schapira</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">Eval. Rev</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"volume\">38</biblScope>\\n\\t\\t\\t<biblScope unit=\"issue\">1</biblScope>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"95\" to=\"106\" />\\n\\t\\t\\t<date type=\"published\" when=\"2010\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b5\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">The stable paths problem and interdomain routing</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Timothy</forename><forename type=\"middle\">G</forename><surname>Griffin</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">F</forename><forename type=\"middle\">Bruce</forename><surname>Shepherd</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Gordon</forename><surname>Wilfong</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">IEEE/ACM Transactions on Networking</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"volume\">10</biblScope>\\n\\t\\t\\t<biblScope unit=\"issue\">2</biblScope>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"232\" to=\"243\" />\\n\\t\\t\\t<date type=\"published\" when=\"2002-04\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b6\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Interdomain routing and games</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Hagay</forename><surname>Levin</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Michael</forename><surname>Schapira</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Aviv</forename><surname>Zohar</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">STOC</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2008\" />\\n\\t\\t\\t<biblScope unit=\"page\" from=\"57\" to=\"66\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b7\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Beyond moulin mechanisms</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Aranyak</forename><surname>Mehta</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Tim</forename><surname>Roughgarden</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Mukund</forename><surname>Sundararajan</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">EC &apos;07: Proceedings of the 8th ACM conference on Electronic commerce</title>\\n\\t\\t<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<publisher>ACM</publisher>\\n\\t\\t\\t<date type=\"published\" when=\"2007\" />\\n\\t\\t\\t<biblScope unit=\"page\" from=\"1\" to=\"10\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b8\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Incremental cost sharing: Characterization by coalition strategy-proofness</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Herve</forename><surname>Moulin</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">Social Choice and Welfare</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"volume\">16</biblScope>\\n\\t\\t\\t<biblScope unit=\"issue\">2</biblScope>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"279\" to=\"320\" />\\n\\t\\t\\t<date type=\"published\" when=\"1999\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b9\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Strategyproof sharing of submodular costs: budget balance versus efficiency</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Herve</forename><surname>Moulin</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Scott</forename><surname>Shenker</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">Economic Theory</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"volume\">18</biblScope>\\n\\t\\t\\t<biblScope unit=\"issue\">3</biblScope>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"511\" to=\"533\" />\\n\\t\\t\\t<date type=\"published\" when=\"2001\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b10\">\\n\\t<monogr>\\n\\t\\t<title level=\"m\" type=\"main\">Best-response auctions. Working paper</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">N</forename><surname>Nisan</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">M</forename><surname>Schapira</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">G</forename><surname>Valiant</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">A</forename><surname>Zohar</surname></persName>\\n\\t\\t</author>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2010\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b11\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Asynchronous best-reply dynamics</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Noam</forename><surname>Nisan</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Michael</forename><surname>Schapira</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Aviv</forename><surname>Zohar</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of WINE</title>\\n\\t\\t<meeting>WINE</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2008\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n\\t\\t\\t\\t</listBibl>\\n\\t\\t\\t</div>\\n\\t\\t</back>\\n\\t</text>\\n</TEI>\\n'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_xml_pres_path = \"dataset/sample_data/presentations/slide.clean_tika.xml\"\n",
    "sample_xml_pres = utils.read_file(sample_xml_pres_path)\n",
    "sample_xml_pres\n",
    "\n",
    "sample_xml_paper_path = \"dataset/sample_data/papers/Paper_BRM.tei.xml\"\n",
    "sample_xml_paper = utils.read_file(sample_xml_paper_path)\n",
    "sample_xml_paper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'Noam Nisan, Michael Schapira, Gregory Valiant, and Aviv Zohar'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_pres_text = utils.parse_presentation_xml(sample_xml_pres)\n",
    "sample_pres_text[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'The basic object of study in game theory and in economics is the equilibrium: a \"stable\" state from which none of the players wish to deviate. Equilibrium is a static concept that often abstracts away the question of how it is reached. Once we start looking at dynamics, or at algorithms for finding equilibria, we cannot escape questions of the form \"How is an equilibrium reached?\". While there can be different formalizations of this question, in most cases, a truly satisfactory answer would have each player performing only simple \"locally rational\" actions and yet, mysteriously, the system would reach a global equilibrium. The simplest example of such phenomena is repeated best-response dynamics: each player selects the best (locally optimal) response to what others are currently doing, and this process goes on \"for a while\" until it \"converges\" to what must be a (pure Nash) equilibrium. Convergence of repeated bestresponse is, unfortunately, not guaranteed in general, and is the subject of much research, as is the convergence of more sophisticated \"locallyrational\" dynamics, e.g., fictitious play or regret minimization.Our focus in this paper is on a different question that has received little attention so far: \"Is such locally rational behavior really rational?\". Specifically, we consider games in which repeated best-response dynamics do converge to an equilibrium and study the incentive properties of this process: Is it rational for players to repeatedly bestrespond? Can a long-sighted player improve, in the long run, over this repeated myopic optimization?These questions about incentives are best explored in the context of games with incomplete information. Switching our attention from games with complete information to games with uncoupled incomplete information, we see that repeated best-response exhibits another attractive trait: to best-respond each player need only know his own utility function (\"type\"), as his best response does not depend on other players\\' utility functions, but only on their actions. Thus, we can view bestresponse dynamics as a natural protocol for gradual and limited sharing of information in an effort to reach an equilibrium. Indeed, in many real-life contexts the interaction between decision makers with incomplete information takes the form of best-response dynamics (e.g., Internet routing [7]). When regarding best-response dynamics from this perspective, it is an indirect mechanism in the private-information mechanism-design sense. We wish to understand when such a mechanism, that dictates that all players repeatedly best-respond, is incentive compatible.'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_paper_text = utils.parse_paper_xml(sample_xml_paper)\n",
    "sample_paper_text[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best-Response Mechanisms\n"
     ]
    }
   ],
   "source": [
    "sample_paper_title = utils.parse_title(sample_xml_paper)\n",
    "print(sample_paper_title)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "sample_pres_preprocessed = utils.preprocess_text(sample_pres_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "sample_paper_preprocessed = utils.preprocess_text(sample_paper_text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['noam', 'nisan', 'michael', 'schapira', 'gregori', 'valiant', 'aviv', 'zohar']\n",
      "['basic', 'object', 'studi', 'game', 'theori', 'econom', 'equilibrium', 'stabl', 'state', 'none', 'player', 'wish', 'deviat', 'equilibrium', 'static', 'concept', 'often', 'abstract', 'away', 'question', 'reach', 'start', 'look', 'dynam', 'algorithm', 'find', 'equilibria', 'escap', 'question', 'form', 'equilibrium', 'reach', 'differ', 'formal', 'question', 'case', 'truli', 'satisfactori', 'answer', 'would', 'player', 'perform', 'simpl', 'local', 'ration', 'action', 'yet', 'mysteri', 'system', 'would', 'reach', 'global', 'equilibrium', 'simplest', 'exampl', 'phenomena', 'repeat', 'bestrespons', 'dynam', 'player', 'select', 'best', 'local', 'optim', 'respons', 'other', 'current', 'process', 'goe', 'converg', 'must', 'pure', 'nash', 'equilibrium', 'converg', 'repeat', 'bestrespons', 'unfortun', 'guarante', 'gener', 'subject', 'much', 'research', 'converg', 'sophist', 'locallyr', 'dynam', 'eg', 'fictiti', 'play', 'regret', 'minimizationour', 'focu', 'paper', 'differ', 'question', 'receiv', 'littl', 'attent', 'far', 'local', 'ration', 'behavior', 'realli', 'ration', 'specif', 'consid', 'game', 'repeat', 'bestrespons', 'dynam', 'converg', 'equilibrium', 'studi', 'incent', 'properti', 'process', 'ration', 'player', 'repeatedli', 'bestrespond', 'longsight', 'player', 'improv', 'long', 'run', 'repeat', 'myopic', 'optimizationthes', 'question', 'incent', 'best', 'explor', 'context', 'game', 'incomplet', 'inform', 'switch', 'attent', 'game', 'complet', 'inform', 'game', 'uncoupl', 'incomplet', 'inform', 'see', 'repeat', 'bestrespons', 'exhibit', 'anoth', 'attract', 'trait', 'bestrespond', 'player', 'need', 'know', 'util', 'function', 'type', 'best', 'respons', 'depend', 'player', 'util', 'function', 'action', 'thu', 'view', 'bestrespons', 'dynam', 'natur', 'protocol', 'gradual', 'limit', 'share', 'inform', 'effort', 'reach', 'equilibrium', 'inde', 'mani', 'reallif', 'context', 'interact', 'decis', 'maker', 'incomplet', 'inform', 'take', 'form', 'bestrespons', 'dynam', 'eg', 'internet', 'rout', '7', 'regard', 'bestrespons', 'dynam', 'perspect', 'indirect', 'mechan', 'privateinform', 'mechanismdesign', 'sens', 'wish', 'understand', 'mechan', 'dictat', 'player', 'repeatedli', 'bestrespond', 'incent', 'compat']\n"
     ]
    }
   ],
   "source": [
    "print(sample_pres_preprocessed[0])\n",
    "print(sample_paper_preprocessed[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "presentation_word_model = Word2Vec(sentences = sample_pres_preprocessed, vector_size = 50, window = 5, min_count = 1, workers = 3, sg = 1)\n",
    "paper_word_model = Word2Vec(sentences = sample_paper_preprocessed, vector_size = 50, window = 5, min_count = 1, workers = 3, sg = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=187, vector_size=50, alpha=0.025>\n",
      "Word2Vec<vocab=829, vector_size=50, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "print(presentation_word_model)\n",
    "print(paper_word_model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "EMBEDDING_PRES_MODEL_FILE = \"pres_word_model.txt\"\n",
    "EMBEDDING_PAPER_MODEL_FILE = \"paper_word_model.txt\"\n",
    "\n",
    "presentation_word_model.wv.save_word2vec_format(EMBEDDING_PRES_MODEL_FILE, binary=False)\n",
    "paper_word_model.wv.save_word2vec_format(EMBEDDING_PAPER_MODEL_FILE, binary=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "presentation_folder = \"dataset/presentations\"\n",
    "paper_folder = \"dataset/papers\"\n",
    "\n",
    "papers_data = []\n",
    "presentations_data = []\n",
    "id2label = {}\n",
    "label2id = {}\n",
    "unknowns = 0\n",
    "\n",
    "# Loop through presentation XML files\n",
    "for presentation_file in os.listdir(presentation_folder):\n",
    "    file_path = os.path.join(presentation_folder, presentation_file)\n",
    "    file_content = utils.read_file(file_path)\n",
    "    if file_content:\n",
    "        # Parse presentation XML\n",
    "        presentation_data = utils.parse_presentation_xml(file_content)\n",
    "        # Preprocess presentation data\n",
    "        # preprocessed_presentation_data = utils.preprocess_text(presentation_data)\n",
    "        # presentations_data.append(preprocessed_presentation_data)\n",
    "        presentations_data.append(presentation_data)\n",
    "\n",
    "# Loop through paper XML files\n",
    "for idx, paper_file in enumerate(os.listdir(paper_folder)):\n",
    "    file_path = os.path.join(paper_folder, paper_file)\n",
    "    file_content = utils.read_file(file_path)\n",
    "    if file_content:\n",
    "        # Parse paper XML\n",
    "        paper_data = utils.parse_paper_xml(file_content)\n",
    "        # Preprocess paper data\n",
    "        # preprocessed_paper_data = utils.preprocess_text(paper_data)\n",
    "        title = utils.parse_title(file_content)\n",
    "        if title is not None:\n",
    "            # Check if title is already in label2id\n",
    "            if title not in label2id:\n",
    "                # If title is not in label2id, add it directly\n",
    "                id2label[idx] = title\n",
    "                label2id[title] = idx\n",
    "            else:\n",
    "                # If title is already in label2id, generate a unique title\n",
    "                unique_title = f\"{title}_{idx}\"\n",
    "                id2label[idx] = unique_title\n",
    "                label2id[unique_title] = idx\n",
    "            # Append paper data\n",
    "        else:\n",
    "            unknowns += 1  # Increment unknowns counter\n",
    "            unique_title = f\"unknown_{idx}\"\n",
    "            id2label[idx] = unique_title\n",
    "            label2id[unique_title] = idx\n",
    "        # papers_data.append(preprocessed_paper_data)\n",
    "        papers_data.append(paper_data)\n",
    "data = {\n",
    "    \"papers\": papers_data,\n",
    "    \"presentations\": presentations_data\n",
    "}\n",
    "# presentation_to_paper = utils.create_presentation_to_paper_mapping(presentation_folder, paper_folder)\n",
    "#\n",
    "# presentations_data = utils.process_presentation_folder(presentation_folder)\n",
    "# papers_data = utils.process_papers_folder(paper_folder)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair 1:\n",
      "Paper: We analyze in this paper the performance of TCP (Transmission Control Protocol), the widely-used transport protocol of the Internet [15,30]. TCP is a reliable window-based flow control protocol where the window is increased until a packet loss is detected. Here, the source assumes that the network is congested and reduces its window. Once the lost packets are recovered, the source resumes its window increase. As a performance measure, we consider the throughput of a long time TCP connection having an infinite amount of data to send. A mathematical model is presented to find a closed form expression for the throughput of the connection. We assume that the reader is familiar with basic mechanisms of TCP such as Slow Start and Congestion Avoidance algorithms, the two methods for loss detection: Duplicate ACKs and TimeOut, the Delay ACK mechanism, the limitation on the congestion window due to receiver buffer, etc. (see [5] for a survey on TCP issues). * The work of this author was financed by a grant of CNET France-Telecom on flow control in High Speed Networks.† The work of this author was financed by an RNRT (French National Research Network in Telecommunications) \"Constellations\" project on satellite communications.A remarkable attention has been given to TCP modeling within the research community [1,10,17,18,21,22,23,27,29]. This is not surprising since 95% of today Internet traffic is carried over TCP. Closed form expressions for the throughput have been obtained. These expressions have helped to understand the impact of different network and TCP parameters on the throughput of the connection and on the efficiency of network resource utilization (e.g. Fairness). Recently, these expressions have been also used to adapt the rate of UDP flows (e.g. audio and video) in a way to be friendly with TCP flows [11,12].The mathematical analysis of TCP requires two steps. First, we need to construct a model for the window size evolution. Most of the existing models ignore the Slow Start phase and make the assumption that the source stays always in Congestion Avoidance mode. A fluid model has often been used. The window of the connection is assumed to increase linearly as a function of time until a loss occurs; then it is divided by two. An initialization to one packet has been proposed in [23] in case of losses detected via TimeOut. The phase of recovery from losses is assumed to be negligible and the source resumes its linear increase directly after the reduction. In [27], a packet-level model has been proposed to account for the discrete nature of TCP. Indeed, the volume of data in the network at any moment is in multiple of packets. It increases by one once the increase in the window exceeds the packet size. Later in our paper, we will show how a fluid model can be corrected to account for this discreteness of TCP.Second, TCP analysis requires a characterization of time between congestion events (i.e. between moments at which the congestion window is reduced). Namely, one needs to model the impact of the path between the source and the destination on the connection. Particular models are considered in the literature. The fixed point approach used in [18,21] gives a deterministic time between congestion events. The assumptions made in [27] can also be shown to imply a deterministic time between congestion events. An exponentially distributed time with a constant intensity has been considered in [23] between congestion events. In [29], the intensity of the exponentially distributed time between congestion events is assumed to increase with the window size. Instead of working in real time, the authors in [22,26] chose to work in a virtual time. This time is obtained by sampling the congestion window at the moments of ACK arrivals. Again, they consider the case where times between congestion events in this virtual time are identically and exponentially distributed. The distribution as well as the moments of the congestion window are found in this virtual time and a method is suggested to go back to the real time.An expression of TCP throughput is provided for each of these models. Our experimentations over the Internet show however that the times between congestion events can have general distribution. They can vary from an approximately deterministic case to a considerably bursty case. Moreover, some correlation may exist between these times. We note, in particular, that if packets are dropped independently with a constant probability then the times between drops are not independent (since the instantaneous transmission rate is variable). We believe that the Internet is so heterogenous that different types of distributions of times between congestion events will always exist. We also believe that making simple assumptions on the process of congestion events will lead to a wrong estimation of TCP throughput. In particular, we have shown in [1] that the throughput of TCP increases when the moments at which the congestion window is reduced tend to appear in bursts. This results in performance problems in applications based on explicit expressions for TCP throughput. Consider for example the case of TCP-friendly applications using explicit expressions for TCP throughput to adapt their rate (see [11,12] and references therein). These are typically real time applications designed to compete fairly for the available bandwidth with TCP transfers. Suppose that these applications use an expression for TCP throughput that makes a simple assumption on the process of congestion events (e.g. deterministic or Poisson). These applications will suffer when the process of congestion events is highly bursty. They can perform better and transmit at a higher rate by basing their throughput calculation on a more precise model for congestion events.In this paper, we investigate the case of a general sequence of times between congestion events. In the sequel, we call a congestion event a loss event. A loss (event) is a moment where the congestion window is reduced by a given constant factor. It can be the result of multiple packet losses. Ideally, a TCP connection must divide its window by two whatever is the number of packet losses within a Round Trip Time (RTT) [27]. All we assume is that this process of loss moments is stationary ergodic. With this minimal assumption, we are able to obtain explicit expressions for the throughput of TCP. Our loss model is general enough to allow us to capture any correlation or any distribution of inter-loss times.For the dynamics of TCP, we decided to focus on the transmission rate which is the number of packets in the network (or the volume of data) divided by the RTT of the connection. The source is assumed to have always data to send. The number of packets in the network is thus equal to the number of packets that can be fit within the window. Denote by X(t) the transmission rate of the connection at time t. At any moment, we can multiply X(t) by RTT to get the window size in terms of packets. We assume that X(t) increases linearly with time at a rate α. If we denote by b the number of data packets covered by one ACK, then α = 1/(bRT T 2 ). Let ν denote the decrease in the transmission rate when a loss event occurs. Usually ν is equal to one half but we consider a more general scenario to account for other possible flow control mechanisms (see e.g. [6]). The moments of losses are modeled by a general stationary ergodic point process [4] with non-null and finite intensity λ.Let {Tn} +∞ n=−∞ be a particular realization of the point process. Consider for the moment the case where losses are quickly detected without the need for a long TimeOut period (e.g. via Duplicate ACK mechanism or via an efficient fine-granularity TimeOut mechanism). Then, the evolution of the transmission rate can be described by the following equationwhere X n is the value of X(t) just prior to the arrival of the loss at T n and S n := T n+1 − T n . The pair {T n , X n } can be considered as a marked point process [4].In the next section, we use the machinery of stochastic processes to study this model of the rate evolution. We compute the throughput, that is the time average of process X(t). We also compute the first two moments of the transmission rate at loss arrivals for the stationary regime. Then different examples of loss processes are studied: deterministic, Poisson, i.i.d. and Markovian arrival processes. The expression of the throughput is provided for each of these particular cases. In Section 2.3, we extend our model to account for the case where there is a limitation on the evolution of the transmission rate caused by the receiver advertised window; we provide bounds on the throughput for that model. In Section 2.4, we explain how to extend our model to the case when some losses are detected via a conservative coarsegranularity TimeOut mechanism which is used in most TCP implementations. In section 3, we present the testbed as well as the results of our experimentations. In particular, our results demonstrate that different types of loss processes exist in the Internet and that often the distribution of inter-loss times cannot be approximated by a constant or by an exponential distribution. Our experimentations show also the common problem of linear rate increase models. When the transmission rate of TCP indeed exhibits a linear increase, our model gives excellent results. The linear rate increase is known to hold for TCP connections in which the propagation delay is large in comparison with queuing delays, since in that case, RTT is almost constant (see [2]). However, in the case where queueing delays are non negligible as in Local Area Networks, TCP window growth exhibits some sub-linearity due to the increase of the RTT with the window size. In this case, we find that linear rate models overestimate the real throughput. We conclude Section 3 with a method to correct the error caused by the fluid assumption. With this method, the deterministic case of our fluid model has given the same results as the packet level approach described in [27]. Finally, we conclude the work in Section 4.\n",
      "Presentation: Twizzler: A Data-Centric OS for Persistent Memory Daniel Bittman Peter Alvaro Pankaj Mehra Darrell Long Ethan Miller Center for Research in Storage Systems University of California, Santa Cruz\n",
      "\n",
      "Pair 2:\n",
      "Paper: Text Simplification (TS) is generally defined as the conversion of a sentence into one or more simpler sentences. It has been shown useful both as a preprocessing step for tasks such as Machine Translation (MT; Mishra et al., 2014;ˇ Stajner and Popovi´cPopovi´c, 2016) and relation extraction ( Niklaus et al., 2016), as well as for developing reading aids, e.g. for people with dyslexia ( Rello et al., 2013) or non-native speakers (Siddharthan, 2002).TS includes both structural and lexical operations. The main structural simplification operation is sentence splitting, namely rewriting a single sentence into multiple sentences while preserving its meaning. While recent improvement in TS has been achieved by the use of neural MT (NMT) approaches ( Nisioi et al., 2017;Zhang and Lapata, 2017), where TS is considered a case of monolingual translation, the sentence splitting operation has not been addressed by these systems, potentially due to the rareness of this operation in the training corpora (Narayan and Gardent, 2014;Xu et al., 2015).We show that the explicit integration of sentence splitting in the simplification system could also reduce conservatism, which is a grave limitation of NMT-based TS systems (Alva-Manchego et al., 2017). Indeed, experimenting with a stateof-the-art neural system ( Nisioi et al., 2017), we find that 66% of the input sentences remain unchanged, while none of the corresponding references is identical to the source. Human and automatic evaluation of the references (against other references), confirm that the references are indeed simpler than the source, indicating that the observed conservatism is excessive. Our methods for performing sentence splitting as pre-processing allows the TS system to perform other structural (e.g. deletions) and lexical (e.g. word substitutions) operations, thus increasing both structural and lexical simplicity.For combining linguistically informed sentence splitting with data-driven TS, two main methods have been proposed. The first involves handcrafted syntactic rules, whose compilation and validation are laborious (Shardlow, 2014). For example, Siddharthan and Angrosh (2014) used 111 rules for relative clauses, appositions, subordination and coordination. Moreover, syntactic splitting rules, which form a substantial part of the rules, are usually language specific, requiring the development of new rules when ported to other languages (Aluísio and Gasperin, 2010;Seretan, 2012;Hung et al., 2012;Barlacchi and Tonelli, 2013, for Portuguese, French, Vietnamese, and Italian respectively). The second method uses linguistic information for detecting potential splitting points, while splitting probabilities are learned us-ing a parallel corpus. For example, in the system of Narayan and Gardent (2014) (henceforth, HYBRID), the state-of-the-art for joint structural and lexical TS, potential splitting points are determined by event boundaries.In this work, which is the first to combine structural semantics and neural methods for TS, we propose an intermediate way for performing sentence splitting, presenting Direct Semantic Splitting (DSS), a simple and efficient algorithm based on a semantic parser which supports the direct decomposition of the sentence into its main semantic constituents. After splitting, NMT-based simplification is performed, using the NTS system. We show that the resulting system outperforms HY-BRID in both automatic and human evaluation.We use the UCCA scheme for semantic representation ( Abend and Rappoport, 2013), where the semantic units are anchored in the text, which simplifies the splitting operation. We further leverage the explicit distinction in UCCA between types of Scenes (events), applying a specific rule for each of the cases. Nevertheless, the DSS approach can be adapted to other semantic schemes, like AMR ( Banarescu et al., 2013).We collect human judgments for multiple variants of our system, its sub-components, HYBRID and similar systems that use phrase-based MT. This results in a sizable human evaluation benchmark, which includes 28 systems, totaling at 1960 complex-simple sentence pairs, each annotated by three annotators using four criteria. 1 This benchmark will support the future analysis of TS systems, and evaluation practices.Previous work is discussed in §2, the semantic and NMT components we use in §3 and §4 respectively. The experimental setup is detailed in §5. Our main results are presented in §6, while §7 presents a more detailed analysis of the system's sub-components and related settings.\n",
      "Presentation: DryadInc: Reusing work in large scale computations *Lucian Popa*+, Mihai Budiu+, Yuan Yu+, Michael Isard+ + Microsoft Research Silicon Valley * UC Berkeley\n",
      "\n",
      "Pair 3:\n",
      "Paper: The largest systems in the world today already scale to hundreds of thousands of cores. With plans under way for exascale systems to emerge within the next decade, we are likely soon to have systems comprising more than a million processing elements. As researchers work toward architecting these enormous systems, it is becoming increasingly clear that at such scales, resilience to hardware faults is going to be a prominent issue that needs to be addressed. Driven by the needs of large-scale scientific computing applications, a variety of programming models have beenn introduced over the past two decades. While the Message Passing Interface (MPI) [1], [2] has become the de facto standard for writing parallel programs, PGAS models have recently gained popularity as well [3], [4], [5], [6]. Together with these programming models, different communication runtime systems to serve these programming models have also become available [7], [8].Fault tolerance in MPI has been an area of significant research [9], [10], [11], [12], [13], [14]. Most of this research, however, has focused on allowing the computational processes to survive fault, through either checkpointing or applicationlevel resilience to faults. While a process-driven model for fault tolerance has its benefits, it has the disadvantage that each process manages its data; thus, a failed node implies that the processes residing on those nodes as well as their data are lost and must be recreated or restored. Recently, we have started investigating fault resilience techniques for datacentric programming models such as the partitioned global address space (PGAS) models. The primary difference in data-centric models is the decoupling of computation and data locality. That is, data placement is decoupled from the executing processes, allowing one to view process failure (a physical node hosting a process is dead) separately from data failure (a physical node hosting data is dead).However, the first obstruction in providing such data-centric fault resilience is that there is a lack of basic fault resiliency in the underlying communication runtime infrastructure for PGAS models and other associated components such as the process manager. Even for the hard faults, there is no lowoverhead fault detection framework and no support for even a minimal set of fault-resilient collective communication primitives.In this paper, we take a first step toward data-centric fault resilience by designing and implementing a fault-resilient, onesided communication runtime framework. Emphasizing the properties of PGAS models for fault resiliency, we present data redundancy models for continued execution during failure and a design for a remote node fault detection module that uses a combination of modern network primitives such as remote direct memory access (RDMA) [15], send/receive, and data delivery notification semantics for high-accuracy fault detection. Leveraging this fundamental infrastructure, we design and implement non-data-moving collective communication primitives and provide the foundation for fault-resilient data-moving collectives. We discuss the need for various semantic changes to write-based operations for recovery with data redundancy, and we provide a framework for error notification with one-sided communication primitives. Using Global Arrays (GA) [3] as an example PGAS model, we implement our design with Aggregate Remote Memory Copy Interface (ARMCI) [7], the communication runtime system of Global Arrays [3], and refer to our solution as fault-tolerant ARMCI, or FT-ARMCI. Our performance evaluation shows that FT-ARMCI can provide fault resiliency with low overhead. We are currently designing and implementing a fault-resilient, high-order computational chemistry method using Global Arrays. We plan to present the results in the final version of the paper.The rest of the article is organized as follows. In Section II, we discuss related work. In Section III, we present the background of our work. In Section IV, we describe the overall design for FT-ARMCI. In Section V, we present a performance evaluation of FT-ARMCI. In section VI, we conclude with a brief summary and discussion of future directions for research.\n",
      "Presentation: Cyber Physical System Challenges for Human-in-the Loop Control Sirajum Munir, John A. Stankovic, Chieh-Jan Mike Liang, Shan Lin University of Virginia, Microsoft Research Asia, Temple University\n",
      "\n",
      "Pair 4:\n",
      "Paper: Efficient graph-parallel systems require careful task partitioning. It plays a pivotal role because the load balancing and communication cost are largely determined by the partitioning strategy. All existing partitioning algorithms in current systems assume that the property of each vertex/edge is indivisible. Therefore, task partitioning is equivalent to graph partitioning. But, in reality, the property associated with a(n) vertex/edge for many Machine Learning and Data Mining (MLDM) problems is a vector of data elements, which is not indivisible.This new feature can be illustrated by a popular machine learning problem, Collaborative Filtering (CF), which estimates the missing ratings based on a given incomplete set of (user, item) ratings. The original problem is defined in a matrix-centric view: given a sparse rating matrix R with size N×M, the goal is to find two dense matrices P (with size N×D) and Q (with size M×D) that are R's non-negative factors (i.e., R ≈ P×Q T ). Here, N and M are the number of users and items, respectively. D is the size of feature vector. When formulated in a graph-centric view, the rows of P and Q correspond to  vertices of a bipartite graph. Each vertex is associated with a property vector with D features. In contrast, the rating matrix R corresponds to edges. For every non-zero element (u, v) in matrix R, there is an edge connects vertex p u and vertex q v , and the weight of this edge is R uv . An illustration of these two views is given in Figure 1. One distinct nature of the graph in Figure 1 (b) is that each vertex is associated with a divisible element vector, which is a common pattern when modelling MLDM algorithms as graph computing problems. Another good example is Sparse Matrix to Matrix Multiplication (SpMM), a prevalently used computation kernel that multiplies a dense feature matrix with a sparse parameter matrix (see Section 5.2.1 for more details). SpMM dominates the execution time of most minibatchbased neural network training algorithms.In essence, when formulating matrix-based applications as graph problems, the property of vertex or edge is usually a vector of elements, instead of a single value. More importantly, during computation, these property vectors are mostly manipulated by element-wise operators, where the computations can be perfectly parallelized without any additional communication when disjoint ranges of vector elements are assigned to different nodes.Due to the common pattern of vector property and its amenability to parallelism, this paper considers a new dimension of task partitioning, which is assigning disjoint elements of the same property to different nodes. It is considered to be a hidden dimension in existing 1D/2D partitioners used in previous systems [10,15,16,24] because all of them treat the property as an indivisible component. According to our investigation, the 3D partitioning principle could significantly reduce network traffic and improve performance.The key intuition is that: since each node only processes a subset of elements in property vectors, it can be assigned with more edges and vertices that otherwise need to be assigned to different nodes. Therefore, on the bright side, certain communications previously happened between nodes are converted to local value exchanges. But, on the other side, 3D partitioning may incur extra synchronizations between sub-vertices/edges. In either case, with 3D partitioning, programmers are given the option to carefully choose the partition strategy of this third dimension. This ability enables them to explore a new tradeoff that may lead to better performance, which is prohibited by traditional 1D/2D partitioners. Importantly, 3D partitioning does not require long property vector to be effective. Our results show that a network traffic reduction up to 90.6% can be achieved by partitioning this dimension into just 64 layers. In other words, our algorithm works very well on property vectors with modest and reasonable size.Based on a novel 3D partitioning algorithm, we build a distributed graph processing engine CUBE, which introduces significantly fewer communication than existing systems in many real-world cases. To achieve better performance, CUBE internally uses a matrix-based data structure for storing and processing graphs while providing a set of vertex-centric APIs for the users. The matrixbased design is inspired by a recent graph-processing system [34], which only works on a single machine. The design of CUBE achieves both the programming productivity of vertex programming and the high performance of a matrix-based backend.This paper makes the following contributions. i) We propose the first 3D graph partitioning algorithm (Section 3.2) for graph-parallel systems. It considers a hidden dimension that is ignored by all previous systems. Unlike traditional 1D and 2D partitioning, the new dimension allows dividing the elements of property vectors to different nodes. Our 3D partitioning offers unprecedented performance that is not achievable by traditional graph partitioning strategies in existing systems.ii) We propose a new programming model UPPS (Update, Push, Pull, Sink) (Section 3.3) designed for 3D partitioning. The existing graph-oriented programming models are insufficient because they implicitly assume that the entire property of a single vertex is accessed as an indivisible component.iii) We build CUBE, a graph processing engine that adopts 3D partitioning and implements the proposed vertex-centric programming model UPPS. The system significantly reduces communication cost and memory consumption. We use matrix-based data structures in the backend which reduces the COST metric [25] of our system to as low as four (Section 4).iv) We systematically study the effectiveness of 3D partitioning with both micro-benchmarks (Section 5.2) and real-world MLDM algorithms (Section 5.3.3). The results show that it only trades a negligible growth of graph partitioning time for a notable reduction of both communication cost and memory consumption. Overall, CUBE outperforms state-of-the-art graph-parallel system PowerLyra by up to 4.7× (up to 7.3× speedup against PowerGraph).\n",
      "Presentation: An Analysis of Long Lines in Richland County, South Carolina Duncan A. Buell University of South Carolina USENIX EVT/WOTE 2013, Washington DC\n",
      "\n",
      "Pair 5:\n",
      "Paper: Web applications must serve many users at low latency. They respond to each user request using data queried from backend stores, usually relational databases. The vast majority of such store accesses are reads, and evaluating them as repeated queries over the normalized schema of a relational database is inefficient [54,57]. Hence, many applications explicitly include precomputed query results in their database schemas, or cache such results in separate key-value stores [8,54]. For example, the Lobsters news aggregator [43] stores stories' computed vote counts and \"hotness\" in separate * equal contribution table columns to avoid re-computing them on every page load [42]. As each vote is reflected in several places, application logic must explicitly update computed columns every time a value changes. Hence, pre-computation complicates both application reads and writes. In general, developers must choose between convenient, but slow, \"natural\" relational queries (e.g., with inline aggregations), and increased performance at the cost of application and deployment complexity (e.g., due to caching).Noria applications do not need to choose. Noria exposes a high-level query interface (SQL), but unlike in conventional systems, Noria accelerates the execution of even complex natural queries by answering with pre-computed results where possible. At its core, Noria runs a continuous, but dynamically changing, dataflow computation that combines the persistent store, the cache, and elements of application logic. Each write to Noria streams through a joint data-flow graph for the current queries and incrementally updates the cached, eventually-consistent internal state and query results.Making this approach work for web applications is challenging. A na¨ıvena¨ıve implementation might maintain unbounded pre-computed state, causing unacceptable space and time overhead, so Noria must limit its state size. Writes can update many pre-computed results, so Noria must ensure that writes are fast and avoid unnecessary work. Finally, since many web applications frequently change their queries [20,61], Noria must accommodate changes without iterating over all data.Existing data-flow systems either cannot perform finegrained incremental updates to state [36,52,75], or limit the growth of operator state using \"windowed\" state (e.g., this week's stories). This bounds their memory footprint but prohibits reading older data [11,39,46,51]. Noria's data-flow operator state is partial instead of windowed, retaining only the subset of records that the application has queried. This is possible thanks to a new, partially-stateful data-flow model: when in need of missing state, operators request an upquery that derives the missing records from upstream state. Ensuring correctness with this model requires careful attention to invariants, as ordinary updates and upqueries can race. With- out care, such races could produce permanently incorrect state, and therefore incorrect cached query results.The state that Noria keeps is similar to a materialized view, and its data-flow processing is akin to view maintenance [2,37]. Noria demonstrates that, contrary to conventional wisdom, maintaining materialized views for all application queries is feasible. This is possible because partially-stateful operators can evict rarely-used state, and discard writes for that state, which reduces state size and write load. Noria further avoids redundant computation and state by jointly optimizing its queries to merge overlapping data-flow subgraphs.Few existing streaming data-flow systems can change their queries and input schemas without downtime. For example, Naiad must re-start to accommodate changes, and Spark's Structured Streaming must restart from a checkpoint [18]. Noria, by contrast, adapts its data-flow to new queries without interrupting existing clients. It applies changes while retaining existing state and while remaining live for reads throughout. Writes from current clients see sub-second interruptions in the common case.Noria's techniques remain compatible with traditional parallel and distributed data-flow, and allow Noria to parallelize and scale fine-grained, partially materialized view maintenance over multiple cores and machines.In summary, Noria makes four principal contributions:1. the partially-stateful data-flow model, its correctness invariants, and a conforming system design; 2. automatic merge-and-reuse techniques for dataflow subgraphs in joint data-flows over many queries, which reduce processing cost and state size; 3. near-instantaneous, dynamic transitions for dataflow graphs in response to changes to queries or schema without loss of existing state; and 4. a prototype implementation and an evaluation that demonstrates that practical web applications benefit from Noria's approach. Our Noria prototype exposes a backwards-compatible MySQL protocol interface and can serve real web applications with minimal changes, although its benefits increase for Noria-optimized applications. When serving the Lobsters web application on a single Amazon EC2 VM, our prototype outperforms the default MySQLbased backend by 5× while simultaneously simplifying the application ( §8.1). For a representative query, our prototype outperforms the widely-used MySQL/memcached stack and the materialized views of a commercial database by 2-10× ( §8.2). It also scales the query to millions of writes and tens of millions of reads per second on a cluster of EC2 VMs, outperforming a stateof-the-art data-flow system, differential dataflow [46,51] ( §8.3). Finally, our prototype adapts the data-flow without any perceptible downtime for reads or writes when transitioning the same query to a modified version ( §8.5).Nevertheless, our current prototype has some limitations. It only guarantees eventual consistency; its eviction from partial state is randomized; it is inefficient for sharded queries that require shuffles in the data-flow; and it lacks support for some SQL keywords. We plan to address these limitations in future work.\n",
      "Presentation: Direct Synthesis of Hardware Designs Using a SAT Solver Dr David Greaves University of Cambridge Computer Laboratory http://www.cl.cam.ac.uk/users/djg RSP 2004 Geneva (C) 2004 IEEE Computer Society\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(presentations_data[0])\n",
    "# print(papers_data[3])\n",
    "# print(data)\n",
    "for idx in range(5):\n",
    "    paper = data[\"papers\"][idx][0] if idx < len(data[\"papers\"]) and data[\"papers\"][idx] else \"N/A\"\n",
    "    presentation = data[\"presentations\"][idx][0] if idx < len(data[\"presentations\"]) and data[\"presentations\"][idx] else \"N/A\"\n",
    "    print(f\"Pair {idx+1}:\")\n",
    "    print(\"Paper:\", paper)\n",
    "    print(\"Presentation:\", presentation)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "labels = []\n",
    "for key, value in label2id.items():\n",
    "    labels.append(value)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4984\n",
      "4984\n",
      "4984\n",
      "4984\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "# print(label2id)\n",
    "# print(labels)\n",
    "print(len(presentations_data))\n",
    "print(len(papers_data))\n",
    "print(len(label2id))\n",
    "print(len(labels))\n",
    "print(unknowns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "## distilBERT tokenizer to preprocess\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "## split into train and test sets with labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"presentations\"], labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_text = []\n",
    "test_text = []\n",
    "train_label = []\n",
    "test_label = []\n",
    "\n",
    "for text, label in zip(X_train, y_train):\n",
    "    train_text.append(text)\n",
    "    train_label.append(label)\n",
    "\n",
    "for text, label in zip(X_test, y_test):\n",
    "    test_text.append(text)\n",
    "    test_label.append(label)\n",
    "\n",
    "train_dict = {\n",
    "    \"label\": train_label,\n",
    "    \"text\": train_text\n",
    "}\n",
    "\n",
    "test_dict = {\n",
    "    \"label\": test_label,\n",
    "    \"text\": test_text\n",
    "}\n",
    "\n",
    "train_data = Dataset.from_dict(train_dict)\n",
    "test_data = Dataset.from_dict(test_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "## preprocessing function to apply tokenizer over whole dataset\n",
    "def preprocess_function(data):\n",
    "    return tokenizer(data[\"text\"], truncation=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/3987 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1550b3a24bdf4aa4a6a0e5e07f343deb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m## batch to process multiple at once for faster compute\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m tokenized_train_data \u001B[38;5;241m=\u001B[39m train_data\u001B[38;5;241m.\u001B[39mmap(preprocess_function, batched\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      3\u001B[0m tokenized_test_data \u001B[38;5;241m=\u001B[39m test_data\u001B[38;5;241m.\u001B[39mmap(preprocess_function, batched\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/datasets/arrow_dataset.py:578\u001B[0m, in \u001B[0;36mtransmit_tasks.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    576\u001B[0m     \u001B[38;5;28mself\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    577\u001B[0m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[0;32m--> 578\u001B[0m out: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetDict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    579\u001B[0m datasets: List[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(out\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[1;32m    580\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dataset \u001B[38;5;129;01min\u001B[39;00m datasets:\n\u001B[1;32m    581\u001B[0m     \u001B[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/datasets/arrow_dataset.py:543\u001B[0m, in \u001B[0;36mtransmit_format.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    536\u001B[0m self_format \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    537\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_type,\n\u001B[1;32m    538\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mformat_kwargs\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_kwargs,\n\u001B[1;32m    539\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_columns,\n\u001B[1;32m    540\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_all_columns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_all_columns,\n\u001B[1;32m    541\u001B[0m }\n\u001B[1;32m    542\u001B[0m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[0;32m--> 543\u001B[0m out: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetDict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    544\u001B[0m datasets: List[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(out\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[1;32m    545\u001B[0m \u001B[38;5;66;03m# re-apply format to the output\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/datasets/arrow_dataset.py:3073\u001B[0m, in \u001B[0;36mDataset.map\u001B[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001B[0m\n\u001B[1;32m   3065\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transformed_dataset \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3066\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m logging\u001B[38;5;241m.\u001B[39mtqdm(\n\u001B[1;32m   3067\u001B[0m         disable\u001B[38;5;241m=\u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m logging\u001B[38;5;241m.\u001B[39mis_progress_bar_enabled(),\n\u001B[1;32m   3068\u001B[0m         unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m examples\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3071\u001B[0m         desc\u001B[38;5;241m=\u001B[39mdesc \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMap\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   3072\u001B[0m     ) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[0;32m-> 3073\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m rank, done, content \u001B[38;5;129;01min\u001B[39;00m Dataset\u001B[38;5;241m.\u001B[39m_map_single(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdataset_kwargs):\n\u001B[1;32m   3074\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m done:\n\u001B[1;32m   3075\u001B[0m                 shards_done \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/datasets/arrow_dataset.py:3449\u001B[0m, in \u001B[0;36mDataset._map_single\u001B[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001B[0m\n\u001B[1;32m   3445\u001B[0m indices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\n\u001B[1;32m   3446\u001B[0m     \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m*\u001B[39m(\u001B[38;5;28mslice\u001B[39m(i, i \u001B[38;5;241m+\u001B[39m batch_size)\u001B[38;5;241m.\u001B[39mindices(shard\u001B[38;5;241m.\u001B[39mnum_rows)))\n\u001B[1;32m   3447\u001B[0m )  \u001B[38;5;66;03m# Something simpler?\u001B[39;00m\n\u001B[1;32m   3448\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3449\u001B[0m     batch \u001B[38;5;241m=\u001B[39m apply_function_on_filtered_inputs(\n\u001B[1;32m   3450\u001B[0m         batch,\n\u001B[1;32m   3451\u001B[0m         indices,\n\u001B[1;32m   3452\u001B[0m         check_same_num_examples\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(shard\u001B[38;5;241m.\u001B[39mlist_indexes()) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m   3453\u001B[0m         offset\u001B[38;5;241m=\u001B[39moffset,\n\u001B[1;32m   3454\u001B[0m     )\n\u001B[1;32m   3455\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m NumExamplesMismatchError:\n\u001B[1;32m   3456\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m DatasetTransformationNotAllowedError(\n\u001B[1;32m   3457\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3458\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/datasets/arrow_dataset.py:3330\u001B[0m, in \u001B[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001B[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001B[0m\n\u001B[1;32m   3328\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m with_rank:\n\u001B[1;32m   3329\u001B[0m     additional_args \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (rank,)\n\u001B[0;32m-> 3330\u001B[0m processed_inputs \u001B[38;5;241m=\u001B[39m function(\u001B[38;5;241m*\u001B[39mfn_args, \u001B[38;5;241m*\u001B[39madditional_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfn_kwargs)\n\u001B[1;32m   3331\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(processed_inputs, LazyDict):\n\u001B[1;32m   3332\u001B[0m     processed_inputs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m   3333\u001B[0m         k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m processed_inputs\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m processed_inputs\u001B[38;5;241m.\u001B[39mkeys_to_format\n\u001B[1;32m   3334\u001B[0m     }\n",
      "Cell \u001B[0;32mIn[19], line 3\u001B[0m, in \u001B[0;36mpreprocess_function\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpreprocess_function\u001B[39m(data):\n\u001B[0;32m----> 3\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tokenizer(data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m], truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2602\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.__call__\u001B[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m   2600\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_in_target_context_manager:\n\u001B[1;32m   2601\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_input_mode()\n\u001B[0;32m-> 2602\u001B[0m     encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_one(text\u001B[38;5;241m=\u001B[39mtext, text_pair\u001B[38;5;241m=\u001B[39mtext_pair, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mall_kwargs)\n\u001B[1;32m   2603\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text_target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2604\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_target_mode()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2688\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase._call_one\u001B[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m   2683\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   2684\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch length of `text`: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(text)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not match batch length of `text_pair`:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2685\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(text_pair)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2686\u001B[0m         )\n\u001B[1;32m   2687\u001B[0m     batch_text_or_text_pairs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(text, text_pair)) \u001B[38;5;28;01mif\u001B[39;00m text_pair \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m text\n\u001B[0;32m-> 2688\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_encode_plus(\n\u001B[1;32m   2689\u001B[0m         batch_text_or_text_pairs\u001B[38;5;241m=\u001B[39mbatch_text_or_text_pairs,\n\u001B[1;32m   2690\u001B[0m         add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[1;32m   2691\u001B[0m         padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[1;32m   2692\u001B[0m         truncation\u001B[38;5;241m=\u001B[39mtruncation,\n\u001B[1;32m   2693\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[1;32m   2694\u001B[0m         stride\u001B[38;5;241m=\u001B[39mstride,\n\u001B[1;32m   2695\u001B[0m         is_split_into_words\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[1;32m   2696\u001B[0m         pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[1;32m   2697\u001B[0m         return_tensors\u001B[38;5;241m=\u001B[39mreturn_tensors,\n\u001B[1;32m   2698\u001B[0m         return_token_type_ids\u001B[38;5;241m=\u001B[39mreturn_token_type_ids,\n\u001B[1;32m   2699\u001B[0m         return_attention_mask\u001B[38;5;241m=\u001B[39mreturn_attention_mask,\n\u001B[1;32m   2700\u001B[0m         return_overflowing_tokens\u001B[38;5;241m=\u001B[39mreturn_overflowing_tokens,\n\u001B[1;32m   2701\u001B[0m         return_special_tokens_mask\u001B[38;5;241m=\u001B[39mreturn_special_tokens_mask,\n\u001B[1;32m   2702\u001B[0m         return_offsets_mapping\u001B[38;5;241m=\u001B[39mreturn_offsets_mapping,\n\u001B[1;32m   2703\u001B[0m         return_length\u001B[38;5;241m=\u001B[39mreturn_length,\n\u001B[1;32m   2704\u001B[0m         verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[1;32m   2705\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   2706\u001B[0m     )\n\u001B[1;32m   2707\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2708\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode_plus(\n\u001B[1;32m   2709\u001B[0m         text\u001B[38;5;241m=\u001B[39mtext,\n\u001B[1;32m   2710\u001B[0m         text_pair\u001B[38;5;241m=\u001B[39mtext_pair,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2726\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   2727\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2879\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001B[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[1;32m   2869\u001B[0m \u001B[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001B[39;00m\n\u001B[1;32m   2870\u001B[0m padding_strategy, truncation_strategy, max_length, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_padding_truncation_strategies(\n\u001B[1;32m   2871\u001B[0m     padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[1;32m   2872\u001B[0m     truncation\u001B[38;5;241m=\u001B[39mtruncation,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2876\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   2877\u001B[0m )\n\u001B[0;32m-> 2879\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_encode_plus(\n\u001B[1;32m   2880\u001B[0m     batch_text_or_text_pairs\u001B[38;5;241m=\u001B[39mbatch_text_or_text_pairs,\n\u001B[1;32m   2881\u001B[0m     add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[1;32m   2882\u001B[0m     padding_strategy\u001B[38;5;241m=\u001B[39mpadding_strategy,\n\u001B[1;32m   2883\u001B[0m     truncation_strategy\u001B[38;5;241m=\u001B[39mtruncation_strategy,\n\u001B[1;32m   2884\u001B[0m     max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[1;32m   2885\u001B[0m     stride\u001B[38;5;241m=\u001B[39mstride,\n\u001B[1;32m   2886\u001B[0m     is_split_into_words\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[1;32m   2887\u001B[0m     pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[1;32m   2888\u001B[0m     return_tensors\u001B[38;5;241m=\u001B[39mreturn_tensors,\n\u001B[1;32m   2889\u001B[0m     return_token_type_ids\u001B[38;5;241m=\u001B[39mreturn_token_type_ids,\n\u001B[1;32m   2890\u001B[0m     return_attention_mask\u001B[38;5;241m=\u001B[39mreturn_attention_mask,\n\u001B[1;32m   2891\u001B[0m     return_overflowing_tokens\u001B[38;5;241m=\u001B[39mreturn_overflowing_tokens,\n\u001B[1;32m   2892\u001B[0m     return_special_tokens_mask\u001B[38;5;241m=\u001B[39mreturn_special_tokens_mask,\n\u001B[1;32m   2893\u001B[0m     return_offsets_mapping\u001B[38;5;241m=\u001B[39mreturn_offsets_mapping,\n\u001B[1;32m   2894\u001B[0m     return_length\u001B[38;5;241m=\u001B[39mreturn_length,\n\u001B[1;32m   2895\u001B[0m     verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[1;32m   2896\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   2897\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py:445\u001B[0m, in \u001B[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001B[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001B[0m\n\u001B[1;32m    436\u001B[0m \u001B[38;5;66;03m# Set the truncation and padding strategy and restore the initial configuration\u001B[39;00m\n\u001B[1;32m    437\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_truncation_and_padding(\n\u001B[1;32m    438\u001B[0m     padding_strategy\u001B[38;5;241m=\u001B[39mpadding_strategy,\n\u001B[1;32m    439\u001B[0m     truncation_strategy\u001B[38;5;241m=\u001B[39mtruncation_strategy,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    442\u001B[0m     pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[1;32m    443\u001B[0m )\n\u001B[0;32m--> 445\u001B[0m encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tokenizer\u001B[38;5;241m.\u001B[39mencode_batch(\n\u001B[1;32m    446\u001B[0m     batch_text_or_text_pairs,\n\u001B[1;32m    447\u001B[0m     add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[1;32m    448\u001B[0m     is_pretokenized\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[1;32m    449\u001B[0m )\n\u001B[1;32m    451\u001B[0m \u001B[38;5;66;03m# Convert encoding to dict\u001B[39;00m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;66;03m# `Tokens` has type: Tuple[\u001B[39;00m\n\u001B[1;32m    453\u001B[0m \u001B[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001B[39;00m\n\u001B[1;32m    454\u001B[0m \u001B[38;5;66;03m#                       List[EncodingFast]\u001B[39;00m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;66;03m#                    ]\u001B[39;00m\n\u001B[1;32m    456\u001B[0m \u001B[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001B[39;00m\n\u001B[1;32m    457\u001B[0m tokens_and_encodings \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    458\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_encoding(\n\u001B[1;32m    459\u001B[0m         encoding\u001B[38;5;241m=\u001B[39mencoding,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    468\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m encoding \u001B[38;5;129;01min\u001B[39;00m encodings\n\u001B[1;32m    469\u001B[0m ]\n",
      "\u001B[0;31mTypeError\u001B[0m: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]"
     ]
    }
   ],
   "source": [
    "## batch to process multiple at once for faster compute\n",
    "tokenized_train_data = train_data.map(preprocess_function, batched=True)\n",
    "tokenized_test_data = test_data.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## padding dynamically\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## metrics function that passes preds and labels to compute metrics\n",
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels = eval_preds\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 5\n",
    "batches_per_epoch = len(train_data) // batch_size\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "# try 3e-5\n",
    "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=len(labels), id2label=id2label, label2id=label2id)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    train_data,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_test_set = model.prepare_tf_dataset(\n",
    "    test_data,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer) #Transformer has default task-relevant loss function\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_test_set)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "push_to_hub_callback = PushToHubCallback(\n",
    "    output_dir=\"CS4120final\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "callbacks = [metric_callback, push_to_hub_callback]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(x=tf_train_set, validation_data=tf_test_set, epochs=3, callbacks=callbacks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ## check if works\n",
    "#\n",
    "# word_tokenizer = Tokenizer()\n",
    "# word_tokenizer.fit_on_texts(presentations_data)\n",
    "# encoded = word_tokenizer.texts_to_sequences(presentations_data)\n",
    "#\n",
    "# char_tokenizer = Tokenizer()\n",
    "# char_tokenizer.fit_on_texts(papers_data)\n",
    "# encoded = char_tokenizer.texts_to_sequences(papers_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ## correct implementation for LR ?\n",
    "#\n",
    "# word_map, index_map = utils.read_embeddings(\"spooky_embedding_word.txt\", word_tokenizer)\n",
    "# char_map, char_index_map = utils.read_embeddings(\"spooky_embedding_char.txt\", char_tokenizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "# X = tfidf_vectorizer.fit_transform(presentations_data)\n",
    "#\n",
    "# y = list(range(len(presentations_data)))\n",
    "#\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#\n",
    "# logreg_model = LogisticRegression(max_iter=1000)\n",
    "# logreg_model.fit(X_train, y_train)\n",
    "#\n",
    "# y_pred = logreg_model.predict(X_test)\n",
    "#\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # print(y_pred[0])\n",
    "# # print(y_test[0])\n",
    "# # print(presentations_data)\n",
    "# print(X_train)\n",
    "# print(X_test)\n",
    "# # print(len(y))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
