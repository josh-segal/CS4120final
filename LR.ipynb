{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install datasets\n",
    "!pip install evaluate\n",
    "!pip install tokenizers\n",
    "!pip install transformers\n",
    "!pip install bs4\n",
    "!pip install lxml"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E5eWlFMrgojZ",
    "outputId": "3c4706a2-652c-4d64-9a0a-a94f8ed55712",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:06:19.113507Z",
     "start_time": "2024-04-09T23:06:06.985549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (1.25.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.22.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: evaluate in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (2.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (1.25.2)\n",
      "Requirement already satisfied: dill in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (2.1.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (4.66.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (0.22.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (23.1)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tokenizers) (0.22.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub<1.0,>=0.16.4->tokenizers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.7.22)\n",
      "Requirement already satisfied: transformers in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.39.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: bs4 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bs4) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Requirement already satisfied: lxml in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.2.1)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import utils as utils\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import os\n",
    "from datasets import Dataset\n",
    "from transformers.keras_callbacks import KerasMetricCallback, PushToHubCallback\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import create_optimizer, AutoTokenizer, TFAutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67eu0djHdb4N",
    "outputId": "fd234abb-2c3f-45c2-bfc0-14b5970b2495",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:06:32.587465Z",
     "start_time": "2024-04-09T23:06:19.114896Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "# dataset_path = 'dataset'\n",
    "# papers_path = 'papers'\n",
    "# presentations_path = 'presentations'\n",
    "#\n",
    "# utils.move_xml_files(dataset_path, papers_path, presentations_path)"
   ],
   "metadata": {
    "id": "S2bstsijdb4O",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:06:32.592005Z",
     "start_time": "2024-04-09T23:06:32.589016Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "sample_xml_pres_path = \"sample_data/presentations/slide.clean_tika.xml\"\n",
    "sample_xml_pres = utils.read_file(sample_xml_pres_path)\n",
    "sample_xml_pres\n",
    "\n",
    "sample_xml_paper_path = \"sample_data/papers/Paper_BRM.tei.xml\"\n",
    "sample_xml_paper = utils.read_file(sample_xml_paper_path)\n",
    "sample_xml_paper"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vvKeerpSdb4P",
    "outputId": "c5566859-b849-49c0-a03f-53012d93c89c",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:06:32.620303Z",
     "start_time": "2024-04-09T23:06:32.593157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<TEI xmlns=\"http://www.tei-c.org/ns/1.0\" \\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \\nxsi:schemaLocation=\"http://www.tei-c.org/ns/1.0 /Users/atharsefid/Desktop/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd\"\\n xmlns:xlink=\"http://www.w3.org/1999/xlink\">\\n\\t<teiHeader xml:lang=\"en\">\\n\\t\\t<encodingDesc>\\n\\t\\t\\t<appInfo>\\n\\t\\t\\t\\t<application version=\"0.5.3\" ident=\"GROBID\" when=\"2019-03-26T16:26+0000\">\\n\\t\\t\\t\\t\\t<ref target=\"https://github.com/kermitt2/grobid\">GROBID - A machine learning software for extracting information from scholarly documents</ref>\\n\\t\\t\\t\\t</application>\\n\\t\\t\\t</appInfo>\\n\\t\\t</encodingDesc>\\n\\t\\t<fileDesc>\\n\\t\\t\\t<titleStmt>\\n\\t\\t\\t\\t<title level=\"a\" type=\"main\">Best-Response Mechanisms</title>\\n\\t\\t\\t</titleStmt>\\n\\t\\t\\t<publicationStmt>\\n\\t\\t\\t\\t<publisher/>\\n\\t\\t\\t\\t<availability status=\"unknown\"><licence/></availability>\\n\\t\\t\\t</publicationStmt>\\n\\t\\t\\t<sourceDesc>\\n\\t\\t\\t\\t<biblStruct>\\n\\t\\t\\t\\t\\t<analytic>\\n\\t\\t\\t\\t\\t\\t<author>\\n\\t\\t\\t\\t\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Noam</forename><surname>Nisan</surname></persName>\\n\\t\\t\\t\\t\\t\\t\\t<affiliation key=\"aff0\">\\n\\t\\t\\t\\t\\t\\t\\t\\t<orgName type=\"department\">School of Eng. and Computer Science</orgName>\\n\\t\\t\\t\\t\\t\\t\\t\\t<orgName type=\"institution\">The Hebrew University of Jerusalem</orgName>\\n\\t\\t\\t\\t\\t\\t\\t</affiliation>\\n\\t\\t\\t\\t\\t\\t</author>\\n\\t\\t\\t\\t\\t\\t<author>\\n\\t\\t\\t\\t\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Michael</forename><surname>Schapira</surname></persName>\\n\\t\\t\\t\\t\\t\\t\\t<affiliation key=\"aff1\">\\n\\t\\t\\t\\t\\t\\t\\t\\t<orgName type=\"department\">Computer Science Dept</orgName>\\n\\t\\t\\t\\t\\t\\t\\t\\t<orgName type=\"institution\">Princeton University</orgName>\\n\\t\\t\\t\\t\\t\\t\\t</affiliation>\\n\\t\\t\\t\\t\\t\\t</author>\\n\\t\\t\\t\\t\\t\\t<author>\\n\\t\\t\\t\\t\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Gregory</forename><surname>Valiant</surname></persName>\\n\\t\\t\\t\\t\\t\\t\\t<email>gvaliant@eecs.berkeley.edu</email>\\n\\t\\t\\t\\t\\t\\t\\t<affiliation key=\"aff2\">\\n\\t\\t\\t\\t\\t\\t\\t\\t<orgName type=\"department\">Dept. of Computer Science</orgName>\\n\\t\\t\\t\\t\\t\\t\\t\\t<orgName type=\"institution\">UC Berkeley</orgName>\\n\\t\\t\\t\\t\\t\\t\\t</affiliation>\\n\\t\\t\\t\\t\\t\\t</author>\\n\\t\\t\\t\\t\\t\\t<author>\\n\\t\\t\\t\\t\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Aviv</forename><surname>Zohar</surname></persName>\\n\\t\\t\\t\\t\\t\\t\\t<email>avivz@microsoft.com</email>\\n\\t\\t\\t\\t\\t\\t\\t<affiliation key=\"aff3\">\\n\\t\\t\\t\\t\\t\\t\\t\\t<orgName type=\"institution\" key=\"instit1\">Microsoft Research</orgName>\\n\\t\\t\\t\\t\\t\\t\\t\\t<orgName type=\"institution\" key=\"instit2\">Silicon Valley</orgName>\\n\\t\\t\\t\\t\\t\\t\\t</affiliation>\\n\\t\\t\\t\\t\\t\\t</author>\\n\\t\\t\\t\\t\\t\\t<title level=\"a\" type=\"main\">Best-Response Mechanisms</title>\\n\\t\\t\\t\\t\\t</analytic>\\n\\t\\t\\t\\t\\t<monogr>\\n\\t\\t\\t\\t\\t\\t<imprint>\\n\\t\\t\\t\\t\\t\\t\\t<date/>\\n\\t\\t\\t\\t\\t\\t</imprint>\\n\\t\\t\\t\\t\\t</monogr>\\n\\t\\t\\t\\t</biblStruct>\\n\\t\\t\\t</sourceDesc>\\n\\t\\t</fileDesc>\\n\\t\\t<profileDesc>\\n\\t\\t\\t<textClass>\\n\\t\\t\\t\\t<keywords>\\n\\t\\t\\t\\t\\t<term>Best Response</term>\\n\\t\\t\\t\\t\\t<term>Mechanism Design</term>\\n\\t\\t\\t\\t\\t<term>Incentive Compatible Dynamics</term>\\n\\t\\t\\t\\t</keywords>\\n\\t\\t\\t</textClass>\\n\\t\\t\\t<abstract>\\n\\t\\t\\t\\t<p>Under many protocols-in computerized settings and in economics settings-participants repeatedly &quot;best respond&quot; to each others&apos; actions until the system &quot;converges&quot; to an equilibrium point. We ask when does such myopic &quot;local rationality&quot; imply &quot;global rationality&quot;, i.e., when is it best for a player, given that the others are repeatedly best-responding, to also repeatedly best-respond? We exhibit a class of games where this is indeed the case. We identify several environments of interest that fall within our class: models of the Border Gateway Protocol (BGP) [7], that handles routing on the Internet, and of the Transmission Control Protocol (TCP) [5], and also stable-roommates [3] and cost-sharing [9, 10], that have been extensively studied in economic theory.</p>\\n\\t\\t\\t</abstract>\\n\\t\\t</profileDesc>\\n\\t</teiHeader>\\n\\t<text xml:lang=\"en\">\\n\\t\\t<body>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"1\">Introduction</head></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"1.1\">Motivation: When is it Best to BestRespond?</head><p>The basic object of study in game theory and in economics is the equilibrium: a \"stable\" state from which none of the players wish to deviate. Equilibrium is a static concept that often abstracts away the question of how it is reached. Once we start looking at dynamics, or at algorithms for finding equilibria, we cannot escape questions of the form \"How is an equilibrium reached?\". While there can be different formalizations of this question, in most cases, a truly satisfactory answer would have each player performing only simple \"locally rational\" actions and yet, mysteriously, the system would reach a global equilibrium. The simplest example of such phenomena is repeated best-response dynamics: each player selects the best (locally optimal) response to what others are currently doing, and this process goes on \"for a while\" until it \"converges\" to what must be a (pure Nash) equilibrium. Convergence of repeated bestresponse is, unfortunately, not guaranteed in general, and is the subject of much research, as is the convergence of more sophisticated \"locallyrational\" dynamics, e.g., fictitious play or regret minimization.</p><p>Our focus in this paper is on a different question that has received little attention so far: \"Is such locally rational behavior really rational?\". Specifically, we consider games in which repeated best-response dynamics do converge to an equilibrium and study the incentive properties of this process: Is it rational for players to repeatedly bestrespond? Can a long-sighted player improve, in the long run, over this repeated myopic optimization?</p><p>These questions about incentives are best explored in the context of games with incomplete information. Switching our attention from games with complete information to games with uncoupled incomplete information, we see that repeated best-response exhibits another attractive trait: to best-respond each player need only know his own utility function (\"type\"), as his best response does not depend on other players\\' utility functions, but only on their actions. Thus, we can view bestresponse dynamics as a natural protocol for gradual and limited sharing of information in an effort to reach an equilibrium. Indeed, in many real-life contexts the interaction between decision makers with incomplete information takes the form of best-response dynamics (e.g., Internet routing <ref type=\"bibr\" target=\"#b6\">[7]</ref>). When regarding best-response dynamics from this perspective, it is an indirect mechanism in the private-information mechanism-design sense. We wish to understand when such a mechanism, that dictates that all players repeatedly best-respond, is incentive compatible.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"1.2\">The Setting</head><p>Let us begin by laying out our setting for studying and formalizing incentives for repeated bestresponse. In our framework, each player holds a private utility function, and all players\\' utility functions, when put together, determine a fullinformation base game with some commonlyknown strategy spaces. We desire that the outcome of the dynamics be an equilibrium of this base game.</p><p>Base game: We are given an n-player (one-shot) base game G, with players 1, . . . , n, in which each player i has strategy space S i , and S = S 1 × ... × S n . Each player i has a utility function u i such that (u 1 , . . . , u n ) ∈ U ⊆ U 1 × · · · × U n , where U i ⊆ ℜ |S| is player i\\'s utility space. Each player knows only his own utility function, i.e., we view u i itself as player i\\'s type.</p><p>Best-response mechanisms: We study a class of indirect mechanisms, that we term \"repeatedresponse mechanisms\": players take turns selecting strategies; at each (discrete) time step t, some player i t selects and announces strategy s t i ∈ S it . Observe that one course of action available to each player in a repeated-response mechanism is to always choose a best-response to the most recently announced strategies of the others, that is, repeated-best-response. We call a repeated-response mechanism in which the prescribed behavior for each player is to repeatedly best-respond a \"best-response mechanism\". To fully-specify a best-response mechanism we must specify (1) the starting state; (2) the order of player activations (which player is \"active\" when); and (3) for each player, a rule for breaking ties among multiple best responses. All of our results hold regardless of the initial state and of the order of players\\' activations (so long as it is \"long enough\"), and, in fact, even in more general settings. <ref type=\"bibr\" target=\"#b0\">1</ref> We discuss tie-breaking rules below.</p><p>Goal: Our general aim is to identify interesting classes of (base) games for which best-response mechanisms are incentive-compatible.</p><p>Intuitively, a best-response mechanism is incentivecompatible if, when all other players are repeatedly best-responding, then a player is incentivized to do the same. Defining incentive compatibility in our setting involves many intricacies. We opt to focus here on a very general notion of incentive compatibility that, we believe, captures essentially any variant that the reader may desire; in a companion paper <ref type=\"bibr\" target=\"#b10\">[11]</ref>, we present several more games (auctions) where only strictly weaker notions of incentive compatibility can be obtained. Our notion of incentive compatibility here captures the two following distinct but complementary points of view: a mechanism design perspective and a learning equilibrium <ref type=\"bibr\" target=\"#b0\">[1,</ref><ref type=\"bibr\" target=\"#b1\">2]</ref> perspective.</p><p>Mechanism design perspective (in a prior-free non-Bayesian setting): This point of view is natural when analyzing finite-time protocols in computerized and economic settings. We are given a game with incomplete information G, where each player\\'s utility function is private, and we wish to implement a pure Nash equilibrium (PNE) of G. We point out that this uncommon objectiveimplementing an equilibrium-proves to be a natural implementation goal in many contexts (see Section 3, where we show that desirable outcomes can be regarded as \"stable states\"). Best-response mechanisms are incentive compatible, from this perspective, if the desired outcomes are implemented in the ex-post Nash sense 2 . Importantly, from this point of view, no actual play happens during the process of best-response dynamics and players merely announce strategies as their communication with the mechanism; each player only cares about maximizing his benefit from the final outcome of the mechanism, that is expected to ter-1 Our results actually hold even for (1) asynchronous player activation orders in which multiple players can best-respond simultaneously or based on outdated information (as studied in <ref type=\"bibr\" target=\"#b11\">[12]</ref>); (2) adaptive player activation orders that can change based on the history of play; and also when (3) the mechanism terminates as soon as all players \"pass\", that is, each player repeats his last strategy. <ref type=\"bibr\" target=\"#b1\">2</ref> The Revelation Principle then implies that the direct revelation mechanism is truthful (in the ex-post-nash sense). minate after some finite predetermined number of time steps.</p><p>Learning equilibrium perspective: This point of view is natural when analyzing environments such as Internet protocols and global financial transactions, where players repeatedly interact with each other and there is no \"final turn\". Now, the players are actually involved in infinite repeated play of the incomplete-information game G and each player has a rule for selecting his next strategy based on the history of play. We are interested in the natural rule that dictates that a player simply always best-respond to others\\' most-recent strategies. In this context, each player wishes to maximize his long-term payoff, that we model to be the lim sup of his stage utilities in this infinitely-played game 3 . Best-response mechanisms are incentive compatible, from this perspective, if the \"best-response\" rules are themselves in equilibrium in this infinite game regardless of the realization of (u 1 , . . . , u n ). Using the terminology of <ref type=\"bibr\" target=\"#b0\">[1,</ref><ref type=\"bibr\" target=\"#b1\">2]</ref>, this means that best-response dynamics are in \"learning equilibrium\". We stress that this would not follow from the folk theorem since our players do not, in any way, punish other players for deviation. To the contrary, our incentive compatibility results establish that the natural best-response dynamics are in equilibrium without requiring players to be able to detect and penalize other players\\' deviations.</p><p>Tie-breaking rules.</p><p>When multiple bestresponses exist we must specify, for each player, a tie-breaking rule. Importantly, this tie-breaking rule must be \"uncoupled\", i.e., depend solely on the player\\'s private information (utility function) and not on information that is unavailable to him 4 . Our tie-breaking rules always have the following simple form: fix, for each player i, an a-priori full order ≺ i on S i (that can depend on u i ), and instruct player i to break ties between multiple best-responses according to ≺ i . While this might seem innocent enough, we do get significant milage from delicate choices of these tie-breaking rules, to the point that one may desire an intuitive justification for these choices. Roughly speaking, there are two main, conflicting, intuitions: in some cases we simply ask players to break ties so as to be \"nice\" to others; in other cases we break ties according to some \"iterated-trembling-hand\" logic.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"1.3\">Games with Incentive-Compatible BestResponse Mechanisms</head><p>Our main results are identifying a class of games for which best-response mechanisms are incentive compatible, and exhibiting several interesting games that fall within this class (and thus have incentive-compatible best-response mechanisms). While at first glance, it might seem that the existence of a unique PNE to which best-response dynamics are guaranteed to converge implies the incentive-compatibility of best-response mechanisms, this intuition is false. Observe that in this game, (B, D) is the unique PNE and every sequence of best responses converges to it. Yet, consider the scenario that the starting point is the strategy profile (A, C), and the column player repeatedly best-responds. Clearly, the row player\\'s local improvement from (A, C) to (B, C) will lead to the column player moving to <ref type=\"bibr\">(B, D)</ref>. Hence, the row player can do better by looking ahead, not moving from (A, C), and thus \"getting stuck\" at (A, C), that he strictly prefers to the unique pure Nash (B, D). Hence, repeated best-responding is not incentive compatible in this game which is strictly-dominance-solvable, is a potential game, and has a unique and Paretooptimal PNE.</p><p>What traits must a game have for best-response dynamics to be incentive compatible?</p><p>We now present an intuitive exposition of a class of games for which this is achieved, which we term \"Never-Best-Response-Solvable (NBRsolvable) games with clear outcomes\". In an NBRsolvable game, strategies are iteratively eliminated if a best-response never leads to them (this is slightly different from dominance-solvability and shall be defined in the following section). Intuitively, an NBR-solvable game has a clear outcome if when each player i considers the game after the other players have already eliminated strategies that can be eliminated regardless of what i does, he can already tell that he will not be able to do better than the outcome that is reached via repeated best-response.</p><p>Our main, and quite easy to prove, general theorem is the following. (We now state the theorem for the case that the strategy spaces are finite, though our result also holds for infinite strategy spaces.)</p><p>Theorem (informal): Let G be an NBR-solvable game with a clear outcome. Then, for every starting point and every (finite or infinite) order of player activations with at least T = Σ i |S i | − n \"rounds\" (a round is a sequence of consecutive time steps in which each player is \"active\" at least once) it holds that:</p><p>1. Repeated best-response dynamics converges to a pure Nash equilibrium s * of G. 2. Repeated best-response dynamics is incentive compatible. We prove that each of the four environments below can be formulated as a game that falls within our class of games, and that the desired outcome in each environment translates to a PNE in this formulation. Thus, the above result implies the existence of incentive-compatible best-response mechanisms that implement the desired outcome in all the contexts below.</p><p>• Stable-roommates. In this classic setting <ref type=\"bibr\" target=\"#b2\">[3]</ref>, students must be paired for the purpose of sharing dorm rooms, and each student has a private full order over possible roommates.</p><p>The objective is to find a \"stable matching\" where no two students prefer each other to their assigned roommates. We show that a natural mechanism, in which a student repeatedly proposes to his most preferred roommate among those that would not immediately reject him, and immediately rejects all proposers except for his most preferred proposer, is incentive compatible in well-studied environments (interns-hospitals, correlated markets).</p><p>• Cost-sharing. Cost-sharing arises in situations in which the cost of some public service (e.g., building a bridge) must be distributed between self-interested users that can benefit from this service to different extents. We present a distributed mechanism that achieves this goal in an incentive-compatible manner.</p><p>Our mechanism implements the outcome of the famous Moulin mechanism <ref type=\"bibr\" target=\"#b8\">[9,</ref><ref type=\"bibr\" target=\"#b9\">10]</ref> (this result can be extended to the more general class of \"acyclic mechanisms\" <ref type=\"bibr\" target=\"#b7\">[8]</ref>).</p><p>• Internet routing. The Border Gateway Protocol (BGP) establishes routes between the smaller networks that make up the Internet.</p><p>We abstract the results in <ref type=\"bibr\" target=\"#b6\">[7]</ref> and prove that BGP is incentive compatible in realistic environments.</p><p>• Congestion control. The Transmission Control Protocol (TCP) handles congestion on the Internet. Building upon <ref type=\"bibr\" target=\"#b4\">[5]</ref>, that models key aspects of TCP, we consider behavior that is somewhat similar to TCP: increase your attempted transmission rate until encountering congestion, and then decrease the transmission rate. We show that such behavior is in equilibrium. Our results above establish incentive compatibility of best-response mechanisms. We also consider the stronger \"collusion-proofness\" desideratum, that even a coalition of players not be able to deviate from repeated best-response and all strictly gain from doing so. We prove that in some of the above environments best-response mechanisms even achieve this stronger requirement.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"1.4\">Research Agenda</head><p>We view this work as a first step towards a more general research agenda. While convergence to equilibrium of \"locally-rational\" dynamics, e.g., repeated best-response, fictitious play and regret minimization, has been extensively studied, little attention has been given to the question of when such locally-rational dynamics are also \"globally rational\". Here, we tackle this question in the context of repeated best-response and the implementation of PNE. However, we believe that the examination of other dynamics (e.g., fictitious play, regret minimization) and other kinds of equilibria (e.g., mixed Nash equilibrium, correlated equilibrium) is an interesting direction for future research.</p><p>Positive and negative results along these lines can help shed new light on the incentive structure of existing protocols/mechanisms (see our results for BGP and TCP and the results in <ref type=\"bibr\" target=\"#b4\">[5,</ref><ref type=\"bibr\" target=\"#b6\">7]</ref>), and provide new insights into the design of new protocols/mechanisms.</p><p>Our results for repeated best-response dynamics establish sufficient conditions for repeated bestresponse to be incentive compatible. We still lack characterizations of conditions that imply incentive compatibility both for general games and for specific classes of games (dominance-solvable games, potential games, etc.). We have thus far considered a very strong notion of incentive compatibility. We believe that considering more restrictive notions (e.g., incentive compatibility in expectation) is of interest. Indeed, in a companion paper <ref type=\"bibr\" target=\"#b10\">[11]</ref> we present several such results for commerce environments.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"1.5\">Organization</head><p>In the next section we formalize our model and present our general theorem. In section 3 we present our results for the four specific environments listed above. We discuss collusionproofness in Section 4.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"2\">Incentive-Compatible</head><p>Best-Response Dynamics Definition 2.1 (tie-breaking rules) A tiebreaking rule (or tie-breaking order) for player i is a full order ≺ i on S i .</p><p>When faced with a choice between multiple best-responses, player i should choose the highest (under ≺ i ) best-response. We now present the following definitions for full-information games.</p><p>Definition 2.2 (never-best-response strategies)</p><formula xml:id=\"formula_0\">s i ∈ S i is a never-best-response (NBR) under tie-breaking order ≺ i on S i if for all s −i , there exists s ′ i so that u i (s i , s −i ) &lt; u i (s ′ i , s −i ) OR both u i (s i , s −i ) = u i (s ′ i , s −i ) and s i ≺ i s ′ i .</formula><p>Definition 2.3 (NBR-solvable games) A game G is never-best-response-solvable (NBR-solvable) under tie-breaking rules ≺ 1 , . . . , ≺ n if there exists a sequence of eliminations of NBR strategies (under these tie breaking rules) that results in a single strategy profile.</p><p>Observe that every weakly-dominance-solvable game has a tie-breaking order under which it is NBR-solvable and every strongly-dominancesolvable game is NBR-solvable for all tie-breaking orders. Observe also that in every game that is NBR-solvable under tie-breaking rules ≺ 1 , . . . , ≺ n the elimination of NBR strategies (under these tie-breaking rules) has a unique orderindependent outcome, that is a pure Nash equilibrium of the game. We call this outcome \"the unique PNE under tie-breaking\".</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Definition 2.4 (shortest-elimination parameters)</head><p>Let G be an NBR-solvable game (under tiebreaking). Then, there exists a sequence of games G 0 , . . . , G r such that G = G 0 , in G r each player has only a single strategy, and ∀i ∈ {0, . . . , r −1}, G i+1 is obtained from G i via the removal of sets of NBR strategies (under tie-breaking). The shortest-elimination parameter e G for G is the length of the shortest such sequence of games for G.</p><p>Observe that if, in an NBR-solvable game G, each strategy space S i is finite, then e G ≤ Σ i |S i |− n. NBR solvability on its own is insufficient to guarantee incentive compatibility, and so we further restrict it.</p><p>Definition 2.5 (globally-optimal profiles) s ∈ S is globally optimal for i if ∀t ∈ S, u i (t) ≤ u i (s). Definition 2.6 (clear outcomes) Let G be an NBR-solvable game under tie breaking rules ≺ 1 , . . . , ≺ n . Let s * be the unique PNE under tiebreaking of G. We say that G has a clear outcome if for every player i there exists a (player-specific) order of elimination of NBR strategies (under the given tie-breaking rules) such that s * is globally optimal for i at the first step in the elimination sequence in which a strategy in S i is eliminated (that is, in the game obtained after the removal of all previously-eliminated strategies from G).</p><p>We say that an incomplete-information game G is NBR-solvable with a clear outcome (under tiebreaking rules) if every realization of (u 1 , . . . , u n ) induces a full-information game that is NBRsolvable with a clear outcome (under tie-breaking, when each player i uses the tie-breaking rule &lt; i for the realized u i ).</p><p>Consider a best-response mechanism M for a base game G. Let s t ∈ S be the players\\' strategies at time step t. We call u i (s t ) player i\\'s stage utility at time t. If M terminates after some finite number of time steps T &gt; 0 we say that player i\\'s total utility is Γ i = u i (s T ) (his stage utility at the last time step of M \\'s execution). If M does not terminate after finite time then i\\'s total utility is Γ i = lim sup t→∞ u i (s t ). M is incentive compatible if repeated best-response is a pure Nash equilibrium in this repeated game with overall utilities Γ 1 , . . . , Γ n for every realization of (u 1 , . . . , u n ). We say that M is collusion-proof if no coalition can deviate from repeated best-response and all strictly gain from doing so in this repeated game. We show that best-response mechanisms are incentive compatible for NBR-solvable games with clear outcomes.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Theorem 2.7 (incentive-compatible mechanisms)</head><p>Let G be NBR-solvable with a clear outcome s * ∈ S under tie-breaking rules ≺ 1 , . . . , ≺ n . Let M be a best-response mechanism for G that breaks ties as in ≺ 1 , . . . , ≺ n . Then, for every starting point and every (finite or infinite) order of player activations with at least T = e G \"rounds\", where a round is a sequence of consecutive time steps in which each player is \"active\" at least once,</p><p>1. M converges to s * . 2. M is incentive compatible. This holds even for (1) asynchronous player activations orders in which multiple players can bestrespond simultaneously or based on outdated information (as studied in <ref type=\"bibr\" target=\"#b11\">[12]</ref>); (2) adaptive player activations orders that can change based on the history of play; and also when (3) the mechanism terminates as soon as all players \"pass\", that is, each player repeats his last strategy.</p><p>Proof sketch: Let G be an NBR-solvable game with a clear outcome (under tie-breaking). Then, there exists a sequence of games G 0 , . . . , G r with length r = e G , such that G = G 0 , in G r each player has only a single strategy, and ∀i ∈ {0, . . . , r − 1}, G i+1 is obtained from G i via the removal of sets of NBR strategies (under tiebreaking).</p><p>Convergence: We first show that if all players repeatedly best-respond then convergence to a PNE is guaranteed within e G rounds. Consider the first round of a best-response mechanism, and consider some j ∈ [n] such that there exists s j ∈ S j that is NBR in G = G 0 . Observe that once j is activated for the first time, s j will never be selected thereafter. Thus, after the first round, no NBR strategy in G 0 will be played ever again and hence the game is effectively equivalent to G 1 . We can now use the same argument to show that after the second round the game is effectively equivalent to G 2 . Thus, we mimic the elimination sequence in each strategy until we end up at G r , whose unique strategy tuple s * is the unique PNE under tie-breaking of G.</p><p>Incentive compatibility: this property follows from the fact that when each player i considers the game after the other players have already eliminated dominated strategies that can be eliminated regardless of what i does, he can already tell that he will not be able to do better than the outcome that is reached via repeated best-response.</p><p>We give the precise argument (by contradiction). Let i be a player that deviates from repeated best-response and strictly gains from doing so. The fact that G is NBR-solvable with a clear outcome (under tie-breaking) implies that there exists a (player-specific) order of elimination of NBR strategies (under the given tie-breaking rules) such that s * is globally optimal for i at the first step in the elimination sequence in which a strategy in S i is eliminated (that is, in the game obtained after the removal of all previously-eliminated strategies from G). Consider this order of elimination; it induces some sequence of games G 0 , . . . , G l such that G = G 0 , in G l each player has only a single strategy, and ∀i ∈ {0, . . . , l − 1}, G i+1 is obtained from G i via the removal of sets of NBR strategies (under tie-breaking) as in the (i + 1)\\'th step in that order. Now, let t i be the index of the first game in the sequence in which i\\'s strategies are eliminated in that order. All players but i are repeatedly bestresponding and in the t i − 1 first steps of the elimination sequence no strategy in S i is eliminated. We can use the same arguments that we used to show convergence, to show that after t i − 1 rounds the game is effectively equivalent to G ti , regardless of the actions of player i. However, in that game, i can do no better than s * -a contradiction.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3\">Four Best-Response Mechanisms</head><p>We present four examples of environments that can be formulated as games that are NBRsolvable with clear outcomes (sometimes under tie-breaking): stable-roommates games, costsharing games, BGP games and TCP games. This implies the existence of incentive-compatible bestresponse mechanisms for all these environments.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.1\">Stable-Roommates</head><p>This following classic setting has been extensively studied in economics, game theory and computer science. n students 1, . . . , n must be paired for the purpose of sharing dorm rooms. Each student has a private strict ranking of the others, and prefers being matched to not being matched. The goal is to find a stable matching, i.e., a matching where no two students prefer each other to their matched roommates. Unfortunately, a stable matching is not guaranteed to exist in general and, furthermore, even if a stable matching does exist (e.g., in bipartite graphs), existing algorithms for reaching it are not incentive compatible <ref type=\"bibr\" target=\"#b2\">[3]</ref>. We seek environments where a stable matching is guaranteed to exist and can be reached in an incentive compatible manner. We focus on two wellknown special cases of stable roommates:</p><p>• Intern-hospital matchings: The \"students\" are divided into two disjoint sets, called interns and hospitals, and all hospitals have the same ranking of interns (e.g., GPA-based).</p><p>• Correlated markets: The \"students\" are vertices in a complete graph in which every edge has a unique \"weight\". The \"heavier\" the edge connecting a student to another student the higher that student ranks the other student. We now show how the framework in Section 2 can be used to design natural incentive compatible mechanisms for stable-roommates. We first formulate this environment as a game and prove that this game is NBR-solvable with a clear outcome.</p><p>Stable-roommates games: The students are the players and each student i\\'s strategy space S i is the set of all students j ̸ = i. α i (j) denotes student j\\'s rank in student i\\'s ranking (the least desired roommate\\'s rank is 1). ∀s = (s 1 , . . . , s n ) ∈ S (that is, choices of roommates), u i (s) = α i (j) iff s i = j and k ̸ = i such that s k = j and α j (k) &gt; α j (i); otherwise, u i (s) = 0. 5 (Observe that players\\' utilities are correlated.)</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Theorem 3.1 For every stable-roommates game G it holds that in both hospital-intern matchings and correlated markets</head><p>• G is NBR-solvable.</p><p>• G\\'s unique PNE is a stable matchings.</p><p>• e G ≤ n.</p><p>Proof sketch: We say that a stable-roommates game is cycle-free if there is no sequence of roomates r 1 , r 2 , . . . r k of length k &gt; 2 such that each student r i ranks student r i+1 higher than student r i−1 (where student indices are considered mod k to induce a cycle). Any matching game that is cycle-free has an elimination sequence that can be constructed as follows: At any stage in the elimination start with some arbitrary student r 1 (that has more than one strategy in the current subgame) and construct a sequence r 1 , r 2 , . . . of students in which r i+1 is the student r i prefers the most out of the students that still have more than one possible strategy remaining (other strategies were eliminated). The number of students is finite and so the sequence must repeat. Since the game is cycle free, the cycle must be of length 2. We have thus located 2 students that desire each other the most. We can eliminate for each of the two the strategies of proposing to any other student since they are guaranteed to gain the maximal utility by proposing to each other.</p><p>All that remains is to notice that both the hospital-intern game and the correlated markets game are cycle-free. In the case of hospitals and interns, the hospitals agree about the ranking of interns and so any cycle of players will have to include a hospital that is placed after a desired intern and before a less desired one. In the case of correlated markets, any cycle of nodes in the graph must include an edge with a lower weight that appears after an edge with a higher one and therefore the preferences do not induce a cycle in the matching graph in either case.</p><p>We observe that the following simple and computationally-efficient mechanism is a bestresponse mechanism for stable-roommate games, and so Theorem 2.7 implies that it implements a stable matching in an incentive-compatible manner.</p><p>Mechanism for Stable-Roommates:</p><p>• Go over the students in some cyclic (roundrobin) order and, at each time step, allow a single student to announce another student.</p><p>• We say that a student i makes a \"better offer\" to another student j at time t if (1) i announces j at time t; and (2) j prefers i to all students from whom he has \"offers\", that is, all students whose last announcement was j.</p><p>The mechanism prescribes that each student repeatedly check which students he can make a better offer to, and announce his most preferred student to whom he can make a better offer.</p><p>• The mechanism terminates after n 2 steps and outputs all student pairs (i, j) such that i\\'s last announcement was j and j\\'s last announcement was i.</p><formula xml:id=\"formula_1\">Theorem 3.2</formula><p>The mechanism is incentivecompatible in ex-post Nash and implements a stable matching in both intern-hospital matchings and correlated markets.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.2\">Cost-Sharing</head><p>Cost-sharing arises in situations in which the cost of some public service (e.g., building a bridge) must be distributed between self-interested users that can benefit from this service to different extents, and is modeled as follows. n users 1, . . . , n aim to share the cost of building some common infrastructure. Some cost-sharing rule specifies, for every subset of users S, and every user i ∈ S, i\\'s \"cost share\" c i (S) for building an infrastructure that only serves members of S. c i (S) is nonnegative, monotonically non-increasing in S, and also cross-monotonic, that is, ∀i ∈ S ⊆ T , c i (S) ≥ c i (T ). User i gets positive (private) value v i ∈ ℜ ≥0 if the infrastructure serves him and 0 otherwise. The goal is to split the cost of the infrastructure between a group of users so that each user\\'s payment is at least his cost-share, yet does not exceed his private value, that is, to find \"reasonable\" cost shares. Moulin <ref type=\"bibr\" target=\"#b8\">[9]</ref> exhibits a centralized mechanism that achieves this (see also <ref type=\"bibr\" target=\"#b9\">[10]</ref>).</p><p>We now use the framework in Section 2 to design simple and natural distributed incentivecompatible mechanisms that implement the same outcome as the Moulin mechanism. We present \"1 st -price cost-sharing games\" and specific tiebreaking rules.</p><p>1 st -price cost-sharing games: The users are the players and, for each user i, S i = ℜ ≥0 . Given a vector of users\\' bids (strategies) − → b = (b 1 , . . . , b n ), the \"serviced set\" for − → b is the maximum-cardinality subset of users S such that ∀j ∈ S, b j ≥ c j (S) (breaking ties between such sets lexicographically).</p><formula xml:id=\"formula_2\">∀ − → b = (b 1 , . . . , b n ), u i ( − → b ) = v i − b i if i is in the serviced set for − → b ; u i ( − → b ) = 0 otherwise.</formula><p>Tie-breaking rules: Prefer bids closer to v i , i.e.,</p><formula xml:id=\"formula_3\">∀s, t ∈ S i , if |s − v i | ≤ |t − v i | then t ≺ i s.</formula></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Theorem 3.3 For every 1 st -price cost-sharing game G it holds that</head><p>• G is NBR-solvable under these tie-breaking rules.</p><p>• G\\'s unique PNE under these tie-breaking rules induces reasonable cost shares as in the outcome of the Moulin mechanism.</p><p>• e G ≤ n.</p><p>Proof sketch: Let us show an elimination sequence for every cost sharing game. First, notice that each player can only get a non-positive utility from a bid that is above his valuation. We therefore start by eliminating these bids for all players. Next, let R v be the set of serviced users for bids that are exactly the valuations of the players. Any player i / ∈ R v will not get serviced for any set of bids that are in the remaining subgame (costs only increase as players drop out and he does not win when they all pay the maximal amount). We can therefore eliminate all strategies below v i for any such player. For every player j ∈ R v , we can eliminate all bids below c j (R v ), as he will only get 0 utility with those bids, and non-negative utility with higher bids. Once these are eliminated, then in the remaining subgame R v will always be the serviced set of players and we can eliminate all bids above c j (R v ) as well.</p><p>Note that it is also possible to perform the eliminations using a different order. Specifically, for each player i we can let all other players eliminate bids above v, then determine a set of serviced agents R i for the case in which every agent j bids v j except for agent i that bids ∞. Then, eliminate all bids for non-serviced agents (except their valuation), and check if c i (R i ) is greater than v i . If it is, we can eliminate bids below c i (R i ) for agent i. Otherwise, agent i will not gain a positive utility from the service in any case and we can eliminate all his strategies except his valuation. We can then continue along the same lines as before and eliminate strategies for all other players. Either way, the elimination done by agent i leads to a subgame in which s * is the optimal outcome for him, and so the game has a clear outcome as required.</p><p>We observe that the following natural distributed mechanism is a best-response mechanism for 1 st -price cost-sharing games (under these tiebreaking rules), and so Theorem 2.7 implies that it implements the outcome of the Moulin mechanism in an incentive-compatible manner.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Mechanism for Cost-Sharing:</head><p>• Go over the users in some cyclic (roundrobin) order and, at each time step, allow a single user to submit a bid in ℜ ≥0 .</p><p>• The mechanism prescribes that each bidder i repeatedly bid as follows: submit the minimal bid b i ≤ v i such that i is in the serviced set for the most-recently submitted bids; in the event that no such bid exists submit the bid b i = v i .</p><p>• The mechanism terminates after n 2 time steps, outputs the serviced set S for the lastsubmitted bids and charges each bidder i ∈ S his last bid b i .</p><formula xml:id=\"formula_4\">Theorem 3.4</formula><p>The mechanism is incentive compatible and implements reasonable cost-shares.</p><p>This result can be extended to the class of acyclic mechanisms studied in <ref type=\"bibr\" target=\"#b7\">[8]</ref>).</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.3\">Internet Routing</head><p>The Border Gateway Protocol (BGP) establishes routes between the smaller networks that make up the Internet. Griffin et al. <ref type=\"bibr\" target=\"#b5\">[6]</ref> put forth the following model for analyzing BGP dynamics. The network is an undirected graph G = (V, E) where the vertex set V consists of n source nodes and 1, . . . , n a unique destination node d. Each source node has a private strict ranking of all simple (loop-free) routes between itself and the destination node d. Under BGP, each source node repeatedly examines its neighboring nodes\\' most recent route-announcements, selects to forward traffic through the neighbor whose route it likes the most, and announces its newly chosen route to all neighbors via update messages. The network is asynchronous and so nodes can select routes simultaneously and based on outdated information (update messages between nodes can be arbitrarily delayed).</p><p>BGP\\'s convergence to a \"stable\" routing tree is the subject of extensive networking research. <ref type=\"bibr\">Levin et al. [7]</ref> observe that BGP can be regarded as best-response dynamics in a specific class of \"routing games\", and prove that BGP is incentivecompatible in networks for which the No Dispute Wheel <ref type=\"bibr\" target=\"#b5\">[6]</ref> condition holds.</p><p>Each pivot node u i would rather route clockwise through pivot node u i+1 than through the direct route Q i . No Dispute Wheel is a generalization of the Gao-Rexford <ref type=\"bibr\" target=\"#b3\">[4]</ref> conditions, that capture common Internet routing practices. A Dispute Wheel (see <ref type=\"figure\" target=\"#fig_1\">Figure 2)</ref> is a 3-tuple (U, R, Q), where U = (u 0 , u 1 , . . . , u k−1 ) is a sequence of k vertices in V , called the \"pivot nodes\" and R = (R 0 , R 1 , . . . , R k−1 ), Q = (Q 0 , Q 1 , . . . , Q k−1 ) are two sequences of k routes, such that (indices are considered modulo k):</p><p>• ∀i, Q i is a simple route from i to d.</p><p>• ∀i, R i is a simple route from u i to u i+1 .</p><p>• ∀i, u i ranks the route R i Q i+1 more highly than the route Q i . \"No Dispute Wheel\" is the condition that no Dispute Wheel exist in the network.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Theorem 3.5 [7] BGP is incentive-compatible in ex-post Nash in networks for which No Dispute Wheel holds.</head><p>We now show that the class of \"BGP games\" presented in <ref type=\"bibr\" target=\"#b6\">[7]</ref> falls within the category of NBRsolvable games with clear outcomes. Thus, the essence of the incentive compatibility result for BGP in <ref type=\"bibr\" target=\"#b6\">[7]</ref> follows from Theorem 2.7.</p><p>BGP games: The source nodes are the players and, for each source node i, S i is the set of i\\'s outgoing edges in E. Given a vector of source nodes\\' traffic forwarding decisions (strategies </p><formula xml:id=\"formula_5\">) − → f = (f 1 , . . . , f n ), u i ( − → f = (f 1 , . . . , f n )) is i\\'</formula></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head>Theorem 3.6 For a BGP game G it holds that</head><p>• G is NBR-solvable.</p><p>• G\\'s unique PNE is a stable routing tree.</p><p>• e G ≤ n.</p><p>Proof sketch: Let us show an elimination order in the game. At every stage in the elimination, we locate a node that can guarantee its most preferred route (in the current subgame) and eliminate all other routing actions for it. To show that such a node always exists, we begin with an arbitrary node a 0 with at least 2 actions. Let R 0 be a 0 \\'s most preferred existing route to d (a route is said to exist if all nodes along it can route accordingly in the current subgame). Let a 1 be the vertex closest to d on R 0 , with two available actions in the current subgame, such that a 1 prefers some other route R 1 to the suffix of R 0 that leads from a 1 to d (if no such node exists a 0 can guarantee its most preferred route). Then we choose a 2 to be the vertex closest to d on R 1 such that a 2 \\'s most preferred route R 2 is preferred over the suffix of R 1 that leads from a 2 to d. Once again if there is no such a 2 we are done. We can continue to choose a 3 , a 4 , . . . in the same manner. Since there is a finite number of vertices, at some point some vertex will appear twice in this sequence (a 0 , a 1 , . . .). This would result in the formation of a Dispute Wheel (in which the a i s are the pivot nodes and the R i s are the routes) which we assumed is not contained in the graph. We will therefore always be able to find a node that can guarantee its most preferred route and continue with the elimination, until there are no more nodes with several possible actions.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"3.4\">Congestion Control</head><p>Congestion control is a crucial task in communication networks. Congestion is handled via the combination of transmission-rate-adjustment protocols at the sender-receiver level (e.g., TCP), and queueing management policies at the router level, that dictate how excess traffic is discarded (e.g., RED). TCP is notoriously not incentive compatible. <ref type=\"bibr\" target=\"#b4\">[5]</ref> analyzes incentives in the following TCPinspired environment. The network is an undirected graph G = (V, E) with a given a capacity function c that specifies the capacity c(e) for each edge e ∈ E. The network consists of n sourcetarget pairs of vertices (α i , β i ). Every such sourcetarget pair (α i , β i ) aims to send traffic along a fixed route R i in G. Each source α i can select transmission rates that lie in the interval <ref type=\"bibr\">[0, M i ]</ref>, where M i is α i \\'s private information, and wishes to maximize its achieved throughput. When an edge encounters congestion, that is, the sum of incoming flows traversing it exceeds its capacity, excess traffic must be discarded. <ref type=\"bibr\" target=\"#b4\">[5]</ref> considers two capacityallocation schemes:</p><p>• Strict-Priority-Queueing (SPQ). ∀e ∈ E there is an edge-specific order over source nodes. Capacity is shared as follows: the most highly ranked source whose route traverses the edge gets its entire flow sent along the edge (up to c(e)); unused capacity is allocated to the second most highly ranked source whose route traverses the edge in a similar fashion, etc.</p><p>• Weighted-Fair-Queueing (WFQ). ∀e ∈ E, each source node α i has weight w i (e) at e. Every source α i is then allocated capacity wi Σj wj c(e). Unused capacity is allocated in a recursive manner. The special case that ∀e ∈ E, ∀i ∈ [n], w i (e) = 1 is called \"fair queueing\" (FQ).</p><p>[5] considers a TCP-like protocol called Probing-Increase-Educate-Decrease (PIED) in which each source is instructed to gradually increase its transmission rate until encountering congestion and, at that point, decrease its transmission rate to its achieved throughput. <ref type=\"bibr\" target=\"#b4\">[5]</ref> analyzes PIED in settings in which all edges use SPQ or all edges use WFQ, and sources priorities/weights are identical on all edges. PIED is shown to be incentive compatible in both these environments (also under asynchronous timings of rate-transmission adjustments). It is interesting to notice that PIED can be considered a form of better-response in a setting in which the exact available capacity is unknown. We unify the two results above for an abstracted setting by formulating the environment in <ref type=\"bibr\" target=\"#b4\">[5]</ref> as a game and showing that this game is NBR-solvable with a clear outcome (under specific tie-breaking rules). Our main difference from <ref type=\"bibr\" target=\"#b4\">[5]</ref> is that we allow players more knowledge about the network, while <ref type=\"bibr\" target=\"#b4\">[5]</ref> uses the probing nature of PIED to learn the needed information (all that is needed is for players to be able to tell the amount of available bandwidth on their path). Thus, Theorem 2.7 implies a result that is similar in spirit to the two theorems in <ref type=\"bibr\" target=\"#b4\">[5]</ref>.</p><p>TCP games: The source nodes are the players and each source node i\\'s strategy space is S i = [0, M i ]. Given a vector of source nodes\\' transmission rates (strategies) − → r = (r 1 , . . . , r n ), u i ( − → r ) is α i \\'s achieved throughput in the unique trafficflow equilibrium point of the network for − → r ( <ref type=\"bibr\" target=\"#b4\">[5]</ref> shows that such a unique equilibrium point exists for the SPQ and WFQ settings with coordinated priorities/weights).</p><p>Tie-breaking rules: ∀s, t ∈ S i , s ≺ i t iff s &gt; t. • e G ≤ n.</p><p>For clarity of presentation we show only the proof for the case of Weighted-Fair-Queueing, with equal weights. The proof for non-equal weights and for Strict-Priority-Queueing follow similar lines. Proof sketch: Let us define for each edge e, the share of each flow as β e = c e /k e where k e is the number of flows that traverse the edge. We construct an elimination sequence for the game as follows: Let e * be the edge with the minimal β. Each flow on this edge is guaranteed β e * traffic through that edge, and at least that amount on all other edges. It is therefore possible to eliminate all actions of transmitting less than β e * for each player that goes through e * . Now, if all flows through e * claim their fair share, no flow can send more (no bandwidth is unclaimed). We can therefore eliminate all actions of transmitting above β e * for these flows. Now, we are left with a subgame with a smaller number of active players where some of the bandwidth on each edge is already used up. We can now repeat the elimination steps for the residual network graph with the remaining players.</p><p>Notice that for each bottleneck edge e * that is found along the process there are several orders of elimination (according to ordering among players). If player i eliminates actions below β e * last among players that go through e * , then he does so in a game in which the final profile is optimal for him, and so the game has a clear outcome.</p></div>\\n<div xmlns=\"http://www.tei-c.org/ns/1.0\"><head n=\"4\">Collusion-Proof Best-Response Mechanisms</head><p>In Section 3, we establish incentive compatibility results for four environments. We are able to strengthen our results for stable-roommates (Theorem 3.1), BGP games (Theorem 3.6), and TCP games where all edges use SPQ with coordinated priorities (see Theorem 3.9). We prove that, in all these settings, best-response mechanisms are actually also collusion-proof. We observe, though, that NBR-solvability with a clear outcome does not imply collusion-proofness of best-response mechanisms in general. To see this, consider the game depicted in <ref type=\"figure\" target=\"#fig_3\">Figure 3</ref> (which is simply the prisoner\\'s dilemma).</p><p>Observe that this game is indeed an NBRsolvable game with a clear outcome, yet both players prefer (C, C) to the unique equilibrium (D, D). Thus, the two players can jointly deviate from repeated best-response and both strictly gain from doing so.</p></div><figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_0\"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A game for which best-response mechanisms are not incentive compatible.</figDesc></figure>\\n<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_1\"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: A Dispute Wheel</figDesc></figure>\\n<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_2\"><head></head><label></label><figDesc>s rank for the simple route from i to d under − → f (the least desired route has rank 1) if such a route exists; u i ( − → f ) = 0 otherwise.</figDesc></figure>\\n<figure xmlns=\"http://www.tei-c.org/ns/1.0\" xml:id=\"fig_3\"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: An NBR-solvable game with a clear outcome for which best-response mechanisms are not collusion proof.</figDesc></figure>\\n\\n\\t\\t\\t<note place=\"foot\" n=\"3\"> In all our results, at equilibrium the lim sup is actually the limit, and thus choosing lim sup gives us the strongest and most robust results -the definition is in fact adversarial to our proofs, it potentially allows manipulators to gain utility by avoiding convergence. 4 We note that it is also permissible for the tie-breaking rules to depend on the players&apos; actions, though for our purposes this was not needed.</note>\\n\\n\\t\\t\\t<note place=\"foot\" n=\"5\"> We note that the more natural definition of utilities that only awards utility to players that are selected by the partner they themselves choose implies a game in which all matchings are stable, and is thus not useful to us.</note>\\n\\t\\t</body>\\n\\t\\t<back>\\n\\t\\t\\t<div type=\"references\">\\n\\n\\t\\t\\t\\t<listBibl>\\n\\n<biblStruct xml:id=\"b0\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Efficient learning equilibrium</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Ronen</forename><forename type=\"middle\">I</forename><surname>Brafman</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Moshe</forename><surname>Tennenholtz</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">Artif. Intell</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"volume\">159</biblScope>\\n\\t\\t\\t<biblScope unit=\"issue\">1-2</biblScope>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"27\" to=\"47\" />\\n\\t\\t\\t<date type=\"published\" when=\"2004\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b1\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Optimal efficient learning equilibrium: Imperfect monitoring in symmetric games</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Ronen</forename><forename type=\"middle\">I</forename><surname>Brafman</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Moshe</forename><surname>Tennenholtz</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of the National Conference on Artificial Intelligence (AAAI</title>\\n\\t\\t<meeting>the National Conference on Artificial Intelligence (AAAI</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<publisher>Press</publisher>\\n\\t\\t\\t<date type=\"published\" when=\"2005\" />\\n\\t\\t\\t<biblScope unit=\"page\" from=\"726\" to=\"731\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b2\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">College admissions and stability of marriage</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">D</forename><surname>Gale</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">L</forename><forename type=\"middle\">S</forename><surname>Shapley</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">Amer. Math. Monthly</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"issue\">69</biblScope>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"9\" to=\"15\" />\\n\\t\\t\\t<date type=\"published\" when=\"1962\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b3\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Stable Internet routing without global coordination</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Lixin</forename><surname>Gao</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Jennifer</forename><surname>Rexford</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">IEEE/ACM Transactions on Networking</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"volume\">9</biblScope>\\n\\t\\t\\t<biblScope unit=\"issue\">6</biblScope>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"681\" to=\"692\" />\\n\\t\\t\\t<date type=\"published\" when=\"2001\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b4\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Aviv Zohar, and Scott Shenker. Incentive compatibility and dynamics of congestion control. SIGMET-RICS Perform</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">P</forename><forename type=\"middle\">Brighten</forename><surname>Godfrey</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Michael</forename><surname>Schapira</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">Eval. Rev</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"volume\">38</biblScope>\\n\\t\\t\\t<biblScope unit=\"issue\">1</biblScope>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"95\" to=\"106\" />\\n\\t\\t\\t<date type=\"published\" when=\"2010\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b5\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">The stable paths problem and interdomain routing</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Timothy</forename><forename type=\"middle\">G</forename><surname>Griffin</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">F</forename><forename type=\"middle\">Bruce</forename><surname>Shepherd</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Gordon</forename><surname>Wilfong</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">IEEE/ACM Transactions on Networking</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"volume\">10</biblScope>\\n\\t\\t\\t<biblScope unit=\"issue\">2</biblScope>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"232\" to=\"243\" />\\n\\t\\t\\t<date type=\"published\" when=\"2002-04\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b6\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Interdomain routing and games</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Hagay</forename><surname>Levin</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Michael</forename><surname>Schapira</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Aviv</forename><surname>Zohar</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">STOC</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2008\" />\\n\\t\\t\\t<biblScope unit=\"page\" from=\"57\" to=\"66\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b7\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Beyond moulin mechanisms</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Aranyak</forename><surname>Mehta</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Tim</forename><surname>Roughgarden</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Mukund</forename><surname>Sundararajan</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">EC &apos;07: Proceedings of the 8th ACM conference on Electronic commerce</title>\\n\\t\\t<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<publisher>ACM</publisher>\\n\\t\\t\\t<date type=\"published\" when=\"2007\" />\\n\\t\\t\\t<biblScope unit=\"page\" from=\"1\" to=\"10\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b8\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Incremental cost sharing: Characterization by coalition strategy-proofness</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Herve</forename><surname>Moulin</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">Social Choice and Welfare</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"volume\">16</biblScope>\\n\\t\\t\\t<biblScope unit=\"issue\">2</biblScope>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"279\" to=\"320\" />\\n\\t\\t\\t<date type=\"published\" when=\"1999\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b9\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Strategyproof sharing of submodular costs: budget balance versus efficiency</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Herve</forename><surname>Moulin</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Scott</forename><surname>Shenker</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"j\">Economic Theory</title>\\n\\t\\t<imprint>\\n\\t\\t\\t<biblScope unit=\"volume\">18</biblScope>\\n\\t\\t\\t<biblScope unit=\"issue\">3</biblScope>\\n\\t\\t\\t<biblScope unit=\"page\" from=\"511\" to=\"533\" />\\n\\t\\t\\t<date type=\"published\" when=\"2001\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b10\">\\n\\t<monogr>\\n\\t\\t<title level=\"m\" type=\"main\">Best-response auctions. Working paper</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">N</forename><surname>Nisan</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">M</forename><surname>Schapira</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">G</forename><surname>Valiant</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">A</forename><surname>Zohar</surname></persName>\\n\\t\\t</author>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2010\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n<biblStruct xml:id=\"b11\">\\n\\t<analytic>\\n\\t\\t<title level=\"a\" type=\"main\">Asynchronous best-reply dynamics</title>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Noam</forename><surname>Nisan</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Michael</forename><surname>Schapira</surname></persName>\\n\\t\\t</author>\\n\\t\\t<author>\\n\\t\\t\\t<persName xmlns=\"http://www.tei-c.org/ns/1.0\"><forename type=\"first\">Aviv</forename><surname>Zohar</surname></persName>\\n\\t\\t</author>\\n\\t</analytic>\\n\\t<monogr>\\n\\t\\t<title level=\"m\">Proceedings of WINE</title>\\n\\t\\t<meeting>WINE</meeting>\\n\\t\\t<imprint>\\n\\t\\t\\t<date type=\"published\" when=\"2008\" />\\n\\t\\t</imprint>\\n\\t</monogr>\\n</biblStruct>\\n\\n\\t\\t\\t\\t</listBibl>\\n\\t\\t\\t</div>\\n\\t\\t</back>\\n\\t</text>\\n</TEI>\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "sample_pres_text = utils.parse_presentation_xml(sample_xml_pres)\n",
    "sample_pres_text[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "0ANc_UhWdb4P",
    "outputId": "8c40584a-da10-4fdc-d5f5-0e7a2d55c4cc",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:06:32.641260Z",
     "start_time": "2024-04-09T23:06:32.620303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Noam Nisan, Michael Schapira, Gregory Valiant, and Aviv Zohar'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "sample_paper_text = utils.parse_paper_xml(sample_xml_paper)\n",
    "sample_paper_text[0]"
   ],
   "metadata": {
    "id": "A2NuAWphdb4P",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:06:32.661421Z",
     "start_time": "2024-04-09T23:06:32.641896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The basic object of study in game theory and in economics is the equilibrium: a \"stable\" state from which none of the players wish to deviate. Equilibrium is a static concept that often abstracts away the question of how it is reached. Once we start looking at dynamics, or at algorithms for finding equilibria, we cannot escape questions of the form \"How is an equilibrium reached?\". While there can be different formalizations of this question, in most cases, a truly satisfactory answer would have each player performing only simple \"locally rational\" actions and yet, mysteriously, the system would reach a global equilibrium. The simplest example of such phenomena is repeated best-response dynamics: each player selects the best (locally optimal) response to what others are currently doing, and this process goes on \"for a while\" until it \"converges\" to what must be a (pure Nash) equilibrium. Convergence of repeated bestresponse is, unfortunately, not guaranteed in general, and is the subject of much research, as is the convergence of more sophisticated \"locallyrational\" dynamics, e.g., fictitious play or regret minimization.Our focus in this paper is on a different question that has received little attention so far: \"Is such locally rational behavior really rational?\". Specifically, we consider games in which repeated best-response dynamics do converge to an equilibrium and study the incentive properties of this process: Is it rational for players to repeatedly bestrespond? Can a long-sighted player improve, in the long run, over this repeated myopic optimization?These questions about incentives are best explored in the context of games with incomplete information. Switching our attention from games with complete information to games with uncoupled incomplete information, we see that repeated best-response exhibits another attractive trait: to best-respond each player need only know his own utility function (\"type\"), as his best response does not depend on other players\\' utility functions, but only on their actions. Thus, we can view bestresponse dynamics as a natural protocol for gradual and limited sharing of information in an effort to reach an equilibrium. Indeed, in many real-life contexts the interaction between decision makers with incomplete information takes the form of best-response dynamics (e.g., Internet routing [7]). When regarding best-response dynamics from this perspective, it is an indirect mechanism in the private-information mechanism-design sense. We wish to understand when such a mechanism, that dictates that all players repeatedly best-respond, is incentive compatible.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "sample_paper_title = utils.parse_title(sample_xml_paper)\n",
    "print(sample_paper_title)"
   ],
   "metadata": {
    "id": "q1RE2aBldb4P",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:06:32.667785Z",
     "start_time": "2024-04-09T23:06:32.662681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best-Response Mechanisms\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "sample_pres_preprocessed = utils.preprocess_text(sample_pres_text)"
   ],
   "metadata": {
    "id": "7S4Gkn9Sdb4P",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:06:32.693655Z",
     "start_time": "2024-04-09T23:06:32.668948Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "sample_paper_preprocessed = utils.preprocess_text(sample_paper_text)"
   ],
   "metadata": {
    "id": "IfPoEVgfdb4P",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:06:32.759723Z",
     "start_time": "2024-04-09T23:06:32.694865Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "print(sample_pres_preprocessed[0])\n",
    "print(sample_paper_preprocessed[0])"
   ],
   "metadata": {
    "id": "qnzkDNmEdb4P",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:06:32.765831Z",
     "start_time": "2024-04-09T23:06:32.762038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['noam', 'nisan', 'michael', 'schapira', 'gregori', 'valiant', 'aviv', 'zohar']\n",
      "['basic', 'object', 'studi', 'game', 'theori', 'econom', 'equilibrium', 'stabl', 'state', 'none', 'player', 'wish', 'deviat', 'equilibrium', 'static', 'concept', 'often', 'abstract', 'away', 'question', 'reach', 'start', 'look', 'dynam', 'algorithm', 'find', 'equilibria', 'escap', 'question', 'form', 'equilibrium', 'reach', 'differ', 'formal', 'question', 'case', 'truli', 'satisfactori', 'answer', 'would', 'player', 'perform', 'simpl', 'local', 'ration', 'action', 'yet', 'mysteri', 'system', 'would', 'reach', 'global', 'equilibrium', 'simplest', 'exampl', 'phenomena', 'repeat', 'bestrespons', 'dynam', 'player', 'select', 'best', 'local', 'optim', 'respons', 'other', 'current', 'process', 'goe', 'converg', 'must', 'pure', 'nash', 'equilibrium', 'converg', 'repeat', 'bestrespons', 'unfortun', 'guarante', 'gener', 'subject', 'much', 'research', 'converg', 'sophist', 'locallyr', 'dynam', 'eg', 'fictiti', 'play', 'regret', 'minimizationour', 'focu', 'paper', 'differ', 'question', 'receiv', 'littl', 'attent', 'far', 'local', 'ration', 'behavior', 'realli', 'ration', 'specif', 'consid', 'game', 'repeat', 'bestrespons', 'dynam', 'converg', 'equilibrium', 'studi', 'incent', 'properti', 'process', 'ration', 'player', 'repeatedli', 'bestrespond', 'longsight', 'player', 'improv', 'long', 'run', 'repeat', 'myopic', 'optimizationthes', 'question', 'incent', 'best', 'explor', 'context', 'game', 'incomplet', 'inform', 'switch', 'attent', 'game', 'complet', 'inform', 'game', 'uncoupl', 'incomplet', 'inform', 'see', 'repeat', 'bestrespons', 'exhibit', 'anoth', 'attract', 'trait', 'bestrespond', 'player', 'need', 'know', 'util', 'function', 'type', 'best', 'respons', 'depend', 'player', 'util', 'function', 'action', 'thu', 'view', 'bestrespons', 'dynam', 'natur', 'protocol', 'gradual', 'limit', 'share', 'inform', 'effort', 'reach', 'equilibrium', 'inde', 'mani', 'reallif', 'context', 'interact', 'decis', 'maker', 'incomplet', 'inform', 'take', 'form', 'bestrespons', 'dynam', 'eg', 'internet', 'rout', '7', 'regard', 'bestrespons', 'dynam', 'perspect', 'indirect', 'mechan', 'privateinform', 'mechanismdesign', 'sens', 'wish', 'understand', 'mechan', 'dictat', 'player', 'repeatedli', 'bestrespond', 'incent', 'compat']\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "presentation_word_model = Word2Vec(sentences = sample_pres_preprocessed, vector_size = 50, window = 5, min_count = 1, workers = 3, sg = 1)\n",
    "paper_word_model = Word2Vec(sentences = sample_paper_preprocessed, vector_size = 50, window = 5, min_count = 1, workers = 3, sg = 1)"
   ],
   "metadata": {
    "id": "OLL6deywdb4P",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:06:32.866686Z",
     "start_time": "2024-04-09T23:06:32.767064Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "print(presentation_word_model)\n",
    "print(paper_word_model)"
   ],
   "metadata": {
    "id": "Ju1zL57idb4Q",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:06:32.871049Z",
     "start_time": "2024-04-09T23:06:32.866686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=187, vector_size=50, alpha=0.025>\n",
      "Word2Vec<vocab=829, vector_size=50, alpha=0.025>\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "EMBEDDING_PRES_MODEL_FILE = \"pres_word_model.txt\"\n",
    "EMBEDDING_PAPER_MODEL_FILE = \"paper_word_model.txt\"\n",
    "\n",
    "presentation_word_model.wv.save_word2vec_format(EMBEDDING_PRES_MODEL_FILE, binary=False)\n",
    "paper_word_model.wv.save_word2vec_format(EMBEDDING_PAPER_MODEL_FILE, binary=False)"
   ],
   "metadata": {
    "id": "QtVBBA73db4Q",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:06:32.903204Z",
     "start_time": "2024-04-09T23:06:32.872261Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "presentation_folder = \"sample_data/presentations\"   #Original: \"dataset/presentations\"\n",
    "paper_folder = \"sample_data/papers\"                 #Original: \"dataset/papers\"\n",
    "\n",
    "papers_data = []\n",
    "presentations_data = []\n",
    "id2label = {}\n",
    "label2id = {}\n",
    "unknowns = 0\n",
    "\n",
    "# Loop through presentation XML files\n",
    "for presentation_file in os.listdir(presentation_folder):\n",
    "    file_path = os.path.join(presentation_folder, presentation_file)\n",
    "    if os.path.isfile(file_path):\n",
    "      file_content = utils.read_file(file_path)\n",
    "      if file_content:\n",
    "          # Parse presentation XML\n",
    "          presentation_data = utils.parse_presentation_xml(file_content)\n",
    "          # Preprocess presentation data\n",
    "          # preprocessed_presentation_data = utils.preprocess_text(presentation_data)\n",
    "          # presentations_data.append(preprocessed_presentation_data)\n",
    "          presentations_data.append(presentation_data)\n",
    "\n",
    "# Loop through paper XML files\n",
    "for idx, paper_file in enumerate(os.listdir(paper_folder)):\n",
    "    file_path = os.path.join(paper_folder, paper_file)\n",
    "    file_content = utils.read_file(file_path)\n",
    "    if file_content:\n",
    "        # Parse paper XML\n",
    "        paper_data = utils.parse_paper_xml(file_content)\n",
    "        # Preprocess paper data\n",
    "        # preprocessed_paper_data = utils.preprocess_text(paper_data)\n",
    "        title = utils.parse_title(file_content)\n",
    "        if title is not None:\n",
    "            # Check if title is already in label2id\n",
    "            if title not in label2id:\n",
    "                # If title is not in label2id, add it directly\n",
    "                id2label[idx] = title\n",
    "                label2id[title] = idx\n",
    "            else:\n",
    "                # If title is already in label2id, generate a unique title\n",
    "                unique_title = f\"{title}_{idx}\"\n",
    "                id2label[idx] = unique_title\n",
    "                label2id[unique_title] = idx\n",
    "            # Append paper data\n",
    "        else:\n",
    "            unknowns += 1  # Increment unknowns counter\n",
    "            unique_title = f\"unknown_{idx}\"\n",
    "            id2label[idx] = unique_title\n",
    "            label2id[unique_title] = idx\n",
    "        # papers_data.append(preprocessed_paper_data)\n",
    "        papers_data.append(paper_data)\n",
    "data = {\n",
    "    \"papers\": papers_data,\n",
    "    \"presentations\": presentations_data\n",
    "}\n",
    "# presentation_to_paper = utils.create_presentation_to_paper_mapping(presentation_folder, paper_folder)\n",
    "#\n",
    "# presentations_data = utils.process_presentation_folder(presentation_folder)\n",
    "# papers_data = utils.process_papers_folder(paper_folder)\n",
    "\n"
   ],
   "metadata": {
    "id": "j8AdV2bqdb4Q",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:06:33.008867Z",
     "start_time": "2024-04-09T23:06:32.904392Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "# print(presentations_data[0])\n",
    "# print(papers_data[3])\n",
    "# print(data)\n",
    "for idx in range(5):\n",
    "    paper = data[\"papers\"][idx][0] if idx < len(data[\"papers\"]) and data[\"papers\"][idx] else \"N/A\"\n",
    "    presentation = data[\"presentations\"][idx][0] if idx < len(data[\"presentations\"]) and data[\"presentations\"][idx] else \"N/A\"\n",
    "    print(f\"Pair {idx+1}:\")\n",
    "    print(\"Paper:\", paper)\n",
    "    print(\"Presentation:\", presentation)\n",
    "    print()"
   ],
   "metadata": {
    "id": "f6Ik2bemdb4Q",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:06:33.014148Z",
     "start_time": "2024-04-09T23:06:33.009068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair 1:\n",
      "Paper: Text simplification (TS) is the task of modifying an original text into a simpler version of it. One of the main parameters for defining a suitable simplification is the target audience. Examples include elderly, children, cognitively impaired users, nonnative speakers and low-literacy readers.Traditionally, work on TS has been divided in lexical simplification (LS) and syntactic simplification (SS). LS (Paetzold, 2016) deals with the identification and replacement of complex words or phrases. SS (Siddharthan, 2011) performs structural transformations such as changing a sentence from passive to active voice. However, most recent approaches learn transformations from corpora, addressing simplification at lexical and syntactic levels altogether. These include either learning tree-based transformations (Woodsend and La- pata, 2011;Paetzold and Specia, 2013) or using machine translation (MT)-based techniques ( Zhu et al., 2010;Coster and Kauchak, 2011a;Wubben et al., 2012;Narayan and Gardent, 2014;Nisioi et al., 2017;Zhang and Lapata, 2017). This paper uses the latter type of technique, which treats TS as a monolingual MT task, where an original text is \"translated\" into its simplified version.In order to build MT-based models, a parallel corpus of original texts with their simplified counterparts is needed. For English, two main such corpora are available: Wikipedia-Simple Wikipedia (W-SW) ( Zhu et al., 2010) and the Newsela Article Corpus. 1 The former is a collection of original Wikipedia articles and their simplified versions created by volunteers. The latter consists of news articles professionally simplified for various specific audiences following the US school grade system. To build simplification models, the pairs of articles in these corpora have been aligned at the level of smaller units using standard algorithms (Coster and Kauchak, 2011b;Paetzold and Specia, 2016;ˇ Stajner et al., 2017). Based on the number of sentences involved in these alignments, one can categorise alignments into four types of coarse-grained simplification operations:• Identical: an original sentence is aligned to itself, i.e. no simplification is performed.• Elaboration: an original sentence is aligned to a single, rewritten simplified sentence.• One-to-many: splitting -an original sentence is aligned to 2+ simplified sentences.• Many-to-one: joining -2+ original sentences are aligned to a single simplified sentence.We hereafter refer to the unit of simplification, i.e. one or more original or simplified sentences, as instances.The Newsela corpus is seen as having higher quality than W-SW because its simplifications are created by professionals, following well defined guidelines ( Xu et al., 2015). It is also larger which is preferable for training corpus-based models. More interestingly, the Newsela corpus has a feature that has been ignored thus far: Each instance in the corpus was created for readers with a certain school grade level. Each original article has a label indicating its corresponding grade level (from 12 to 2), and may have various simplified versions, each for a different grade level. For example, a level 12 article may have simplified counterparts for levels 8 and 4. In other words, the corpus contains instances where the same input leads to different outputs. Disregarding this factor may lead to suboptimal models. To avoid this problem, previous work (Alva- Manchego et al., 2017;Zhang and Lapata, 2017;Scarton et al., 2018b) has used subsets of the corpus with only certain combinations of complex-simplified article pairs, e.g. adjacent or non-adjacent pairs. This however reduces the amount of data available for training.We propose a way of making use of this information to build more informed TS models that are aware of different types of target audiences, while still making use of the full dataset for learning. Inspired by the work of Johnson et al. (2017) for MT, we add to each original instance an artificial token that represents the target grade level of that instance in order to guide a sequence-to-sequence attentional encoder-decoder neural approach (Bahdanau et al., 2015) ( §2). In a similar vein, we also annotate the coarse-grained type of operation that should be performed to simplify the original instance, under the hypothesis that certain operations are more often used to simplify into certain grade levels. Deciding on the operation is an easier problem than performing the actual operation. We rely on both gold and predicted operation types.Experiments with models built with these artificial tokens outperform state-of-the-art neural models for TS, with the best approach combining grade level and type of operation ( §3). Interestingly, such an approach also enables zero-shot TS, where a simplification for a grade level pair unseen at training time can still be generated during testing. We show that our zero-shot learning models perform virtually as well as our grade/operationinformed models ( §4). To the best of our knowledge, this is the first work to build TS models for specific target audiences and to explore zero-shot learning for this application.\n",
      "Presentation: Learning Simplifications for Specific Target Audiences Carolina Scarton and Lucia Specia {c.scarton, l.specia}@sheffield.ac.uk ACL 2018, Melbourne, Australia\n",
      "\n",
      "Pair 2:\n",
      "Paper: Contextual, or 'data-to-text' natural language generation is one of the core tasks in natural language processing and has a considerable impact on various fields (Gatt and Krahmer, 2017). Within the field of recommender systems, a promising application is to estimate (or generate) personalized reviews that a user would write about a product, i.e., to discover their nuanced opinions about each of its individual aspects. A successful model could work (for instance) as (a) a highly-nuanced recommender system that tells users their likely reaction to a product in the form of text fragments; (b) a writing tool that helps users 'brainstorm' the review-writing process; or (c) a querying system that facilitates personalized natural language queries (i.e., to find items about which a user would be most likely to write a particular phrase). Some recent works have explored the review generation task and shown success in generating cohesive reviews ( Dong et al., 2017;Ni et al., 2017;Zang and Wan, 2017). Most of these works treat the user and item identity as input; we seek a system with more nuance and more precision by allowing users to 'guide' the model via short phrases, or auxiliary data such as item specifications. For example, a review writing assistant might allow users to write short phrases and expand these key points into a plausible review.Review text has been widely studied in traditional tasks such as aspect extraction (Mukherjee and Liu, 2012;He et al., 2017), extraction of sentiment lexicons ( Zhang et al., 2014), and aspectaware sentiment analysis ( Wang et al., 2016;McAuley et al., 2012). These works are related to review generation since they can provide prior knowledge to supervise the generative process. We are interested in exploring how such knowledge (e.g. extracted aspects) can be used in the review generation task.In this paper, we focus on designing a review generation model that is able to leverage both user and item information as well as auxiliary, textual input and aspect-aware knowledge. Specifically, we study the task of expanding short phrases into complete, coherent reviews that accurately reflect the opinions and knowledge learned from those phrases.These short phrases could include snippets provided by the user, or manifest aspects about the items themselves (e.g. brand words, technical specifications, etc.). We propose an encoderdecoder framework that takes into consideration three encoders (a sequence encoder, an attribute encoder, and an aspect encoder), and one decoder. The sequence encoder uses a gated recurrent unit   (GRU) network to encode text information; the attribute encoder learns a latent representation of user and item identity; finally, the aspect encoder finds an aspect-aware representation of users and items, which reflects user-aspect preferences and item-aspect relationships. The aspect-aware representation is helpful to discover what each user is likely to discuss about each item. Finally, the output of these encoders is passed to the sequence decoder with an attention fusion layer. The decoder attends on the encoded information and biases the model to generate words that are consistent with the input phrases and words belonging to the most relevant aspects.\n",
      "Presentation: Personalized Review Generation by Expanding Phrases and Attending on Aspect-Aware Representations Jianmo Ni and Julian McAuley UC San Diego July 2018\n",
      "\n",
      "Pair 3:\n",
      "Paper: Query auto-completion (QAC) is a feature used by search engines that provides a list of suggested queries for the user as they are typing. For instance, if the user types the prefix \"mete\" then the system might suggest \"meters\" or \"meteorite\" as completions. This feature can save the user time and reduce cognitive load (Cai et al., 2016).Most approaches to QAC are extensions of the Most Popular Completion (MPC) algorithm (Bar- Yossef and Kraus, 2011). MPC suggests completions based on the most popular queries in the training data that match the specified prefix. One way to improve MPC is to consider additional signals such as temporal information (Shokouhi and Radinsky, 2012;Whiting and Jose, 2014) or information gleaned from a users' past queries (Shok- ouhi, 2013). This paper deals with the latter of those two signals, i.e. personalization. Personalization relies on the fact that query likelihoods are drastically different among different people depending on their needs and interests.Recently, Park and Chiba (2017) suggested a significantly different approach to QAC. In their\n",
      "Presentation: Personalized Language Model for Query Auto-Completion Aaron Jaech and Mari Ostendorf University of Washington\n",
      "\n",
      "Pair 4:\n",
      "Paper: Language, and therefore data derived from language, changes over time (Ullmann, 1962). Word senses can shift over long periods of time (Wilkins, 1993;Wijaya and Yeniterzi, 2011;Hamilton et al., 2016), and written language can change rapidly in online platforms ( Eisenstein et al., 2014;Goel et al., 2016). However, little is known about how shifts in text over time affect the performance of language processing systems.This paper focuses on a standard text processing task, document classification, to provide insight into how classification performance varies with time. We consider both long-term variations in text over time and seasonal variations which change throughout a year but repeat across years. Our empirical study considers corpora containing formal text spanning decades as well as usergenerated content spanning only a few years.After describing the datasets and experiment design, this paper has two main sections, respectively addressing the following research questions:1. In what ways does document classification depend on the timestamps of the documents?2. Can document classifiers be adapted to perform better in time-varying corpora?To address question 1, we train and test on data from different time periods, to understand how performance varies with time. To address question 2, we apply a domain adaptation approach, treating time intervals as domains. We show that in most cases this approach can lead to improvements in classification performance, even on future time intervals.\n",
      "Presentation: Examining Temporality in Document Classification Xiaolei Huang Michael J. Paul University of Colorado Boulder\n",
      "\n",
      "Pair 5:\n",
      "Paper: Problem. Schumacher convinced to win on Sunday. When this news headline is fed into modern tools for Named Entity Disambiguation (NED), virtually all of them would map the mention Schumacher onto the former Formula One champion Michael Schumacher, as the best-fitting entity from a Wikipedia-centric knowledge base (KB). However, knowing that Sunday refers to August 14, 1949, i.e., ignoring the surface form but exploiting normalized information, it becomes clear that the text actually refers to the German politician Kurt Schumacher. State-of-the-art NED methods (see surveys by Hachey et al. (2013), Ling et al. (2015), Shen et al. (2015)) tend to miss this because they are designed and trained for temporally focused input corpora such as current news, and do not cope well with longitudinal archives and other diachronic corpora that span decades. Standard NED benchmarks from CoNLL and TAC do not reflect this difficulty either. 1 The diaNED corpus and the temporal signatures of entities are publicly available: https://www.mpi-inf. mpg.de/yago-naga/dianed/. What is needed here is a better way of capturing temporal context, for both the mention Schumacher and each of the candidate entities. Figure 1 illustrates \"time profiles\" for sample entities with highly ambiguous names. Normalized temporal information from the input context, such as Sunday (1949-08-14), can provide additional cues for proper disambiguation. The problem addressed in this paper is how to model and capture temporal contexts and how to enhance NED with this novel asset. Contribution. Our approach to this problem is to compute temporal signatures for entities in the KB, and to use these as expressive features when comparing candidate entities against the context of an input mention. Temporal signatures are embeddings that reflect the importance of different years for entities. They are automatically constructed by extracting and normalizing temporal expressions in entity descriptions such as Wikipedia articles. Analogously, temporal signals are captured in the contexts of textual mentions and represented by embeddings.The time-aware NED method that we devise with these features can robustly cope with inputs from diachronic corpora. We propose a new evaluation benchmark, based on the New York Times Archive, spanning more than 20 years, and the history collection historynet.com, spanning several centuries. Our experiments demonstrate that timeaware NED substantially outperforms some of the best standard NED tools.\n",
      "Presentation: diaNED: Time-Aware Named Entity Disambiguation for Diachronic Corpora Prabal Agarwal1, Jannik Strotgen1,2, Luciano del Corro3, Johannes Hoffart3, Ger hard Weikum1 July 18, 2018\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "labels = []\n",
    "for key, value in label2id.items():\n",
    "    labels.append(value)"
   ],
   "metadata": {
    "id": "8yKx3uvqdb4Q",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:06:33.023403Z",
     "start_time": "2024-04-09T23:06:33.015536Z"
    }
   },
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "# print(label2id)\n",
    "# print(labels)\n",
    "print(len(presentations_data))\n",
    "print(len(papers_data))\n",
    "print(len(label2id))\n",
    "print(len(labels))\n",
    "print(unknowns)"
   ],
   "metadata": {
    "id": "QTuhu7Ordb4Q",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:06:33.033036Z",
     "start_time": "2024-04-09T23:06:33.024796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "0\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "## distilBERT tokenizer to preprocess\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ],
   "metadata": {
    "id": "BVLIYEZ7db4Q",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:06:33.432887Z",
     "start_time": "2024-04-09T23:06:33.033937Z"
    }
   },
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "-p0GWz-uBhbU",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:06:33.436421Z",
     "start_time": "2024-04-09T23:06:33.433025Z"
    }
   },
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "## split into train and test sets with labels\n",
    "presentation_data = utils.stringify(data[\"presentations\"])\n",
    "#print(data[\"presentations\"])\n",
    "#print(presentation_data)\n",
    "#print(len(presentation_data))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"presentations\"], labels, test_size=0.2, train_size=0.8, random_state=42)\n",
    "\n",
    "train_text = []\n",
    "test_text = []\n",
    "train_label = []\n",
    "test_label = []\n",
    "\n",
    "for text, label in zip(X_train, y_train):\n",
    "    train_text.append(text)\n",
    "    train_label.append(label)\n",
    "\n",
    "for text, label in zip(X_test, y_test):\n",
    "    test_text.append(text)\n",
    "    test_label.append(label)\n",
    "    \n",
    "#print(train_text)\n",
    "\n",
    "#train_text = utils.stringify(train_data[\"text\"])\n",
    "#print(train_text[0])\n",
    "\n",
    "#test_text = utils.stringify(test_data[\"text\"])\n",
    "#print(test_text)\n",
    "#print(len(test_text))\n",
    "#print(len(test_label))\n",
    "\n",
    "train_dict = {\n",
    "    \"label\": train_label,\n",
    "    \"text\": train_text\n",
    "}\n",
    "\n",
    "test_dict = {\n",
    "    \"label\": test_label,\n",
    "    \"text\": test_text\n",
    "}\n",
    "\n",
    "train_data = Dataset.from_dict(train_dict)\n",
    "test_data = Dataset.from_dict(test_dict)\n",
    "\n",
    "print(test_data[1])\n",
    "print(train_data[1])\n"
   ],
   "metadata": {
    "id": "KCKFdzUjdb4R",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:13:32.762965Z",
     "start_time": "2024-04-10T00:13:32.293173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 1, 'text': ['Personalized Review Generation by Expanding Phrases and Attending on Aspect-Aware Representations Jianmo Ni and Julian McAuley UC San Diego July 2018', 'Reviews in recommender system', 'Help user write reviews in an easier way? Expand and rewrite phrases  Estimate reactions and provide suggestions', 'Incorporate information & knowledge User and item attribute  Dong et al. EACL 2017. Learning to Generate Product Reviews from Attributes.  Tang et al. Arxiv 2016. Context-aware Natural Language Generation with Recurrent Neural Networks. Rich auxiliary information!  Short phrases (user input)  Product title  Aspect preference', 'Incorporate information & knowledge Aspect preference  User-aspect preference  Item-aspect relation Aspects Representative words Service vendor seller supplier reply refund Price price value overall dependable reliable Screen screen touchscreen browse display scrolling Case case cover briefcase portfolio padded Drive drive disk copying copied fat32 Table 1 Representative words of aspects A1  AK U1 A1  AK I1 Interaction Aspect Preference Score', 'Proposed method Attribute latent factor Aspect-aware factor Embedding layers Attribute attention Aspect attentionSequence attention 1 2 3 4 easy useto ! user item Sequence Encoder Attribute Encoder Aspect Encoder', 'Proposed method Attribute latent factor Aspect-aware factor Embedding layers 1 2 4 53 5 5 5 the is beautifuldisplay and easy to use the is beautifuldisplay and easy to<str> Attribute attention Aspect attentionSequence attention 1 2 3 4 easy useto ! 2 Projection layer user item Sequence Encoder Attribute Encoder Aspect Encoder Pv(display) = Pw(display)', 'Proposed method Attribute latent factor Aspect-aware factor Embedding layers 1 2 4 53 5 5 5 the is beautifuldisplay and easy to use Pv(display) + Pdisplay in Ak(Ak) = Pw(display) the is beautifuldisplay and easy to<str> Attribute attention Aspect attentionSequence attention 1 2 3 4 easy useto ! 2 Projection layer A1 AkA2 Aspect bias user item Sequence Encoder Attribute Encoder Aspect Encoder Aspect preference score', 'Experiment setting Dataset: Amazon Electronics  Vocabulary of 30,000 tokens  182,850 users, 59,043 items, and 992,172 reviews  Much sparser than previous work Training  Use teacher-forcing and masked cross-entropy loss Testing  Greedy decoding', 'Automatic evaluation metrics Model PPL BLEU-1(%) BLEU-4(%) ROUGE-L Distinct-1(%) Distinct-2(%) Rand / 20.24 0.45 0.390 1.311 13.681 GRU-LM 35.35 30.79 1.20 / / / Att2Seq 34.21 26.16 1.23 0.403 0.014 0.051 +aspect 34.26 26.87 1.51 0.397 0.018 0.069 ExpansionNet 34.18 26.05 2.21 0.404 0.096 0.789 +title 30.70 27.90 2.50 0.415 0.099 0.911 +attribute & aspect Table 2 Comparison of different algorithms', 'Examples of generated review User/Item Review Item user A3G831BTCLWGVQ and item B007M50PTM Summary easy to use and nice standard apps Title samsung galaxy tab 2 (10.1-Inch, wi-fi) 2012 model Real review the display is beautiful and the tablet is very easy to use. it comes with some really nice standard apps . Attr2Seq i bought this for my wife s new ipad air . it fits perfectly and looks great . the only thing i do nt like is that the cover is a little too small for the ipad air . ExpansionNet i love this tablet . it is fast and easy to use . i have no complaints . i would recommend this tablet to anyone . +title i love this tablet . it is fast and easy to use . i have a galaxy tab 2 and i love it . +attribute & aspect i love this tablet . it is easy to use and the screen is very responsive . i love the fact that it has a micro sd slot . i have not tried the tablet app yet but i do nt have any problems with it . i am very happy with this tablet .', 'Examples of generated review User/Item Review Item user A3G831BTCLWGVQ and item B007M50PTM Summary easy to use and nice standard apps Title samsung galaxy tab 2 (10.1-Inch, wi-fi) 2012 model Real review the display is beautiful and the tablet is very easy to use. it comes with some really nice standard apps . Attr2Seq i bought this for my wife s new ipad air . it fits perfectly and looks great . the only thing i do nt like is that the cover is a little too small for the ipad air . ExpansionNet i love this tablet . it is fast and easy to use . i have no complaints . i would recommend this tablet to anyone . +title i love this tablet . it is fast and easy to use . i have a galaxy tab 2 and i love it . +attribute & aspect i love this tablet . it is easy to use and the screen is very responsive . i love the fact that it has a micro sd slot . i have not tried the tablet app yet but i do nt have any problems with it . i am very happy with this tablet .', 'Examples of generated review User/Item Review Item user A3G831BTCLWGVQ and item B007M50PTM Summary easy to use and nice standard apps Title samsung galaxy tab 2 (10.1-Inch, wi-fi) 2012 model Real review the display is beautiful and the tablet is very easy to use. it comes with some really nice standard apps . Attr2Seq i bought this for my wife s new ipad air . it fits perfectly and looks great . the only thing i do nt like is that the cover is a little too small for the ipad air . ExpansionNet i love this tablet . it is fast and easy to use . i have no complaints . i would recommend this tablet to anyone . +title i love this tablet . it is fast and easy to use . i have a galaxy tab 2 and i love it . +attribute & aspect i love this tablet . it is easy to use and the screen is very responsive . i love the fact that it has a micro sd slot . i have not tried the tablet app yet but i do nt have any problems with it . i am very happy with this tablet .', 'Examples of generated review User/Item Review Item user A3G831BTCLWGVQ and item B007M50PTM Summary easy to use and nice standard apps Title samsung galaxy tab 2 (10.1-Inch, wi-fi) 2012 model Real review the display is beautiful and the tablet is very easy to use. it comes with some really nice standard apps . Attr2Seq i bought this for my wife s new ipad air . it fits perfectly and looks great . the only thing i do nt like is that the cover is a little too small for the ipad air . ExpansionNet i love this tablet . it is fast and easy to use . i have no complaints . i would recommend this tablet to anyone . +title i love this tablet . it is fast and easy to use . i have a galaxy tab 2 and i love it . +attribute & aspect i love this tablet . it is easy to use and the screen is very responsive . i love the fact that it has a micro sd slot . i have not tried the tablet app yet but i do nt have any problems with it . i am very happy with this tablet .', 'Broader aspect coverage in generation # aspect plus one, if the review covers the representative words from that aspect Our model covers more real reviews aspects Model # aspects (real) # aspects (generated) # aspects in generated review also covered in real review Attr2Seq 2.875 2.744 0.686 ExpansionNet 2.875 1.804 0.807 +title 2.875 1.721 0.894 +attribute & aspect 2.875 1.834 0.931', 'Conclusion and future work Conclusion  Build ExpansionNet to incorporate short phrases, product title and aspect preference in review generation  Show aspect embedding and aspect extraction can be used in personalized text generation Future work  Combine text expansion task with text rewriting techniques  Generate longer text such as product recommendation articles', 'Q & A Thank you! Code and data available: https://github.com/nijianmo/textExpansion']}\n",
      "{'label': 2, 'text': ['Personalized Language Model for Query Auto-Completion Aaron Jaech and Mari Ostendorf University of Washington', 'Query Auto-Completion  Search engine suggests queries as the user types Idea from Park & Chiba (2017): Use an LSTM to generate completions  Memory savings over most popular completion  Handles previously unseen prefixes Can we do better by adapting the LM to provide personalized suggestions?', 'RNN Language Model Adaptation Learn an embedding, c, for each user and use it to adapt the predictions Method #1: Concatenate the user embedding with the input at each step*  Same as applying a constant linear shift to the bias vector (in recurrent & output layers)  Leaves most of the recurrent model parameters unchanged  Method #2: Low-rank adaptation of recurrent weight matrix (FactorCell model) Concatenating the user embedding is the same as shifting the bias. \" = \\' =  \" \\')*,\\',  +  =   \\')*,\\' +  + user embedding word embedding Adjust b and W! 0 * Referred to here as ConcatCell (Mikolov& Zweig, 2012)', 'W0 +WA = c LLLL cR Low-rank adaptationGeneric weightsAdapted weights (e + h) x h (e + h) x h k x (e + h) x r r x h x k1 x k k x 1 FactorCell Model The adaptation matrix is formed from a product of the context embedding with left and right bases. The two bases tensors (L and R) hold k different rank r matrices, each the same size as W. Context vectors give a weighted combination.', 'Learning User embeddings, recurrent layer weights and {L, R} tensor learned jointly Need online learning to adapt to users that were not previously seen  In joint training, learn a cold-start embedding for set of infrequent users  During evaluation Initialize each users embedding with learned cold-start vector  Make query suggestions  After user selects a query, back-propagate and only update the user embedding', 'Data & Experiments  Using AOL 2006 Query Log data, 173K users and 12 million queries for training User embedding size = 32, LSTM size = 600 Evaluate on 500K queries with disjoint user population Mean reciprocal rank (MRR) as a metric', 'Experimental Results M ea n Re ci pr oc al R an k Performance for users with > 50 queries Benefit improves over time!', 'Qualitative Comparison What queries are boosted the most after searching for high school softball and math homework help? FactorCell ConcatCell high school musical horoscope chris brown high school musical funnyjunk.com homes for sale funbrain.com modular homes chat room hair styles Queries that most decrease in likelihood with the FactorCell include travel agencies and plane tickets.', 'Recent Related Work: Florini & Lu, NAACL 2018 Also personalized LSTM for query prediction  ConcatCell adaptation framework  User embedding learned separately  No online learning  Assessed on two datasets, but different split of AOL data  Confirms benefit of adapted LM', 'Conclusions Personalization helps and the benefit increases as more queries are seen  Stronger adaptation of the recurrent layer (FactorCell) gives better results than concatenating a user vector  No extra latency/computation due to caching of adapted weight matrix Try out the FactorCell on your data  http://github.com/ajaech/query_completion', 'THANKS!', 'Qualitative Comparison What queries are boosted the most after searching for prada handbags and versace eyewear? FactorCell ConcatCell neiman marcus craigslist nyc pottery barn myspace layours jc penny verizon wireless verizon wireless jensen ackles bed bath and beyond webster dictionary', 'Backup Slides', \"FactorCell Model W0 +WA = Low-rank adaptationGeneric weightsAdapted weights c LLLL cR The adapted weight matrix is a drop-in replacement for W h1 h2 h3 h4 <START> THE YELLOW FOX THE YELLOW FOX JUMPED Much larger change in recurrent layer than what ConcatCell does '1* = ( W4 + W0 ',' + )\", 'Prefix and query length Longer queries are more difficult  Suggestion quality improves as prefix length increases']}\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "source": [
    "## preprocessing function to apply tokenizer over whole dataset\n",
    "def preprocess_function(data):\n",
    "    return tokenizer(data[\"text\"],padding=\"max_length\", truncation=True)"
   ],
   "metadata": {
    "id": "FkGXWNA0db4R",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:13:40.198882Z",
     "start_time": "2024-04-10T00:13:40.192998Z"
    }
   },
   "outputs": [],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "source": [
    "## batch to process multiple at once for faster compute\n",
    "#print(train_data)\n",
    "#print(test_data)\n",
    "\n",
    "#print(len(train_data[\"text\"][0]))\n",
    "#print(len(test_data[\"text\"][0]))\n",
    "#preprocessed_data = [preprocess_function(item) for item in train_data[\"text\"][0]]\n",
    "#tokenized_train_data = train_data.map(preprocess_function, batched=True)\n",
    "#print(tokenized_train_data)\n",
    "\n",
    "#tokenized_test_data = test_data.map(preprocess_function, batched=True)\n",
    "#print(tokenized_test_data)"
   ],
   "metadata": {
    "id": "q-ellueudb4R",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:13:42.661602Z",
     "start_time": "2024-04-10T00:13:41.951195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c564c025eb7f4dabb98b1e46cb09bc2e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[76], line 8\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m## batch to process multiple at once for faster compute\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#print(train_data)\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m#print(test_data)\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m#print(len(test_data[\"text\"][0]))\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m#preprocessed_data = [preprocess_function(item) for item in train_data[\"text\"][0]]\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m tokenized_train_data \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpreprocess_function\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m#print(tokenized_train_data)\u001B[39;00m\n\u001B[0;32m     11\u001B[0m tokenized_test_data \u001B[38;5;241m=\u001B[39m test_data\u001B[38;5;241m.\u001B[39mmap(preprocess_function, batched\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:593\u001B[0m, in \u001B[0;36mtransmit_tasks.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    591\u001B[0m     \u001B[38;5;28mself\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    592\u001B[0m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[1;32m--> 593\u001B[0m out: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetDict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    594\u001B[0m datasets: List[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(out\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[0;32m    595\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dataset \u001B[38;5;129;01min\u001B[39;00m datasets:\n\u001B[0;32m    596\u001B[0m     \u001B[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:558\u001B[0m, in \u001B[0;36mtransmit_format.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    551\u001B[0m self_format \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    552\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_type,\n\u001B[0;32m    553\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mformat_kwargs\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_kwargs,\n\u001B[0;32m    554\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_columns,\n\u001B[0;32m    555\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_all_columns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_all_columns,\n\u001B[0;32m    556\u001B[0m }\n\u001B[0;32m    557\u001B[0m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[1;32m--> 558\u001B[0m out: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetDict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    559\u001B[0m datasets: List[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(out\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[0;32m    560\u001B[0m \u001B[38;5;66;03m# re-apply format to the output\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3105\u001B[0m, in \u001B[0;36mDataset.map\u001B[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001B[0m\n\u001B[0;32m   3099\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transformed_dataset \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3100\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m hf_tqdm(\n\u001B[0;32m   3101\u001B[0m         unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m examples\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   3102\u001B[0m         total\u001B[38;5;241m=\u001B[39mpbar_total,\n\u001B[0;32m   3103\u001B[0m         desc\u001B[38;5;241m=\u001B[39mdesc \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMap\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   3104\u001B[0m     ) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[1;32m-> 3105\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m rank, done, content \u001B[38;5;129;01min\u001B[39;00m Dataset\u001B[38;5;241m.\u001B[39m_map_single(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdataset_kwargs):\n\u001B[0;32m   3106\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m done:\n\u001B[0;32m   3107\u001B[0m                 shards_done \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3482\u001B[0m, in \u001B[0;36mDataset._map_single\u001B[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001B[0m\n\u001B[0;32m   3478\u001B[0m indices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\n\u001B[0;32m   3479\u001B[0m     \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m*\u001B[39m(\u001B[38;5;28mslice\u001B[39m(i, i \u001B[38;5;241m+\u001B[39m batch_size)\u001B[38;5;241m.\u001B[39mindices(shard\u001B[38;5;241m.\u001B[39mnum_rows)))\n\u001B[0;32m   3480\u001B[0m )  \u001B[38;5;66;03m# Something simpler?\u001B[39;00m\n\u001B[0;32m   3481\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3482\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[43mapply_function_on_filtered_inputs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3483\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3484\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3485\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_same_num_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mshard\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlist_indexes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3486\u001B[0m \u001B[43m        \u001B[49m\u001B[43moffset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3487\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3488\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m NumExamplesMismatchError:\n\u001B[0;32m   3489\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m DatasetTransformationNotAllowedError(\n\u001B[0;32m   3490\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3491\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3361\u001B[0m, in \u001B[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001B[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001B[0m\n\u001B[0;32m   3359\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m with_rank:\n\u001B[0;32m   3360\u001B[0m     additional_args \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (rank,)\n\u001B[1;32m-> 3361\u001B[0m processed_inputs \u001B[38;5;241m=\u001B[39m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfn_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43madditional_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfn_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3362\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(processed_inputs, LazyDict):\n\u001B[0;32m   3363\u001B[0m     processed_inputs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m   3364\u001B[0m         k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m processed_inputs\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m processed_inputs\u001B[38;5;241m.\u001B[39mkeys_to_format\n\u001B[0;32m   3365\u001B[0m     }\n",
      "Cell \u001B[1;32mIn[75], line 3\u001B[0m, in \u001B[0;36mpreprocess_function\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpreprocess_function\u001B[39m(data):\n\u001B[1;32m----> 3\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtext\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_length\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2872\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.__call__\u001B[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   2870\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_in_target_context_manager:\n\u001B[0;32m   2871\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_input_mode()\n\u001B[1;32m-> 2872\u001B[0m     encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_pair\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtext_pair\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mall_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2873\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text_target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2874\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_target_mode()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2958\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase._call_one\u001B[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   2953\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   2954\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch length of `text`: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(text)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not match batch length of `text_pair`:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2955\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(text_pair)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2956\u001B[0m         )\n\u001B[0;32m   2957\u001B[0m     batch_text_or_text_pairs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(text, text_pair)) \u001B[38;5;28;01mif\u001B[39;00m text_pair \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m text\n\u001B[1;32m-> 2958\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_encode_plus\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2959\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_text_or_text_pairs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_text_or_text_pairs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2960\u001B[0m \u001B[43m        \u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2961\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2962\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtruncation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2963\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2964\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstride\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2965\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_split_into_words\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_split_into_words\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2966\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2967\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2968\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2969\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2970\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2971\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2972\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2973\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2974\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2975\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2976\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2977\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2978\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode_plus(\n\u001B[0;32m   2979\u001B[0m         text\u001B[38;5;241m=\u001B[39mtext,\n\u001B[0;32m   2980\u001B[0m         text_pair\u001B[38;5;241m=\u001B[39mtext_pair,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2996\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2997\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3149\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001B[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   3139\u001B[0m \u001B[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001B[39;00m\n\u001B[0;32m   3140\u001B[0m padding_strategy, truncation_strategy, max_length, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_padding_truncation_strategies(\n\u001B[0;32m   3141\u001B[0m     padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[0;32m   3142\u001B[0m     truncation\u001B[38;5;241m=\u001B[39mtruncation,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3146\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3147\u001B[0m )\n\u001B[1;32m-> 3149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_batch_encode_plus\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3150\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_text_or_text_pairs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_text_or_text_pairs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3151\u001B[0m \u001B[43m    \u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3152\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpadding_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpadding_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3153\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtruncation_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtruncation_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3154\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3155\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstride\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3156\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_split_into_words\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_split_into_words\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3157\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad_to_multiple_of\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3158\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3159\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_token_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3160\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3161\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_overflowing_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3162\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_special_tokens_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3163\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3164\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3165\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3166\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3167\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_fast.py:504\u001B[0m, in \u001B[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001B[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001B[0m\n\u001B[0;32m    495\u001B[0m \u001B[38;5;66;03m# Set the truncation and padding strategy and restore the initial configuration\u001B[39;00m\n\u001B[0;32m    496\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_truncation_and_padding(\n\u001B[0;32m    497\u001B[0m     padding_strategy\u001B[38;5;241m=\u001B[39mpadding_strategy,\n\u001B[0;32m    498\u001B[0m     truncation_strategy\u001B[38;5;241m=\u001B[39mtruncation_strategy,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    501\u001B[0m     pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[0;32m    502\u001B[0m )\n\u001B[1;32m--> 504\u001B[0m encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode_batch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    505\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_text_or_text_pairs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    506\u001B[0m \u001B[43m    \u001B[49m\u001B[43madd_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madd_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    507\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_pretokenized\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_split_into_words\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    508\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    510\u001B[0m \u001B[38;5;66;03m# Convert encoding to dict\u001B[39;00m\n\u001B[0;32m    511\u001B[0m \u001B[38;5;66;03m# `Tokens` has type: Tuple[\u001B[39;00m\n\u001B[0;32m    512\u001B[0m \u001B[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001B[39;00m\n\u001B[0;32m    513\u001B[0m \u001B[38;5;66;03m#                       List[EncodingFast]\u001B[39;00m\n\u001B[0;32m    514\u001B[0m \u001B[38;5;66;03m#                    ]\u001B[39;00m\n\u001B[0;32m    515\u001B[0m \u001B[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001B[39;00m\n\u001B[0;32m    516\u001B[0m tokens_and_encodings \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    517\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_encoding(\n\u001B[0;32m    518\u001B[0m         encoding\u001B[38;5;241m=\u001B[39mencoding,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    527\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m encoding \u001B[38;5;129;01min\u001B[39;00m encodings\n\u001B[0;32m    528\u001B[0m ]\n",
      "\u001B[1;31mTypeError\u001B[0m: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "source": [
    "## padding dynamically\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")"
   ],
   "metadata": {
    "id": "xLLuOr9Bdb4R",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:13:56.862130Z",
     "start_time": "2024-04-10T00:13:56.856373Z"
    }
   },
   "outputs": [],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ],
   "metadata": {
    "id": "3g4T_czqdb4R",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:13:59.779967Z",
     "start_time": "2024-04-10T00:13:58.380281Z"
    }
   },
   "outputs": [],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "source": [
    "## metrics function that passes preds and labels to compute metrics\n",
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels = eval_preds\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ],
   "metadata": {
    "id": "NB6U2954db4R",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:14:00.745322Z",
     "start_time": "2024-04-10T00:14:00.739926Z"
    }
   },
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 16\n",
    "num_epochs = 5\n",
    "batches_per_epoch = len(train_data) // batch_size\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "# try 3e-5\n",
    "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
   ],
   "metadata": {
    "id": "Gxnyj9LLdb4R",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:14:02.119616Z",
     "start_time": "2024-04-10T00:14:02.033581Z"
    }
   },
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=len(labels), id2label=id2label, label2id=label2id)\n"
   ],
   "metadata": {
    "id": "8aLtnJEGdb4R",
    "ExecuteTime": {
     "end_time": "2024-04-09T23:57:25.819436Z",
     "start_time": "2024-04-09T23:57:23.305316Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "source": [
    "print(train_data)\n",
    "print(tokenized_train_data[\"label\"])\n",
    "print(tokenized_train_data[\"text\"])\n",
    "print(tokenized_train_data[\"input_ids\"])\n",
    "#print(tokenized_train_data[\"attention-mask\"])\n",
    "#print(train_data[\"attention-mask\"])\n",
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    tokenized_train_data,\n",
    "    shuffle=True,\n",
    "    batch_size=1,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_test_set = model.prepare_tf_dataset(\n",
    "    tokenized_test_data,\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "#print(tf_train_set)"
   ],
   "metadata": {
    "id": "yzs4SvIfdb4R",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:14:54.461948Z",
     "start_time": "2024-04-10T00:14:54.233711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['label', 'text'],\n",
      "    num_rows: 4\n",
      "})\n",
      "[5, 2, 4, 3]\n",
      "['Noam Nisan, Michael Schapira, Gregory Valiant, and Aviv Zohar Motivation Equilibrium is the basic object of study in game theory. Question: How is an equilibrium reached? In a truly satisfactory answer each players rule of behavior is simple and locally rational repeated best-response repeated better-response regret-minimization Motivation Repeated best-response is often employed in practice e.g., Internet routing We ask: When is such locallyrational behavior really rational? Repeated best-response is not always best. *the game is solvable through elimination of dominated strategies. Overview of Results We identify a small class of games for which: 1. Repeated best-response converges (quickly) from any initial point. While small, this class covers several important examples: Internet Routing, Cost Sharing, Stable Roommates, Congestion Control. The Setting The repeated best-response strategy: When a players turn arrives, it announces the best response to the latest announcements of others. Tie Breaking Rules Never Best Response (NBR) Strategies -10 -15 3 -3 3 -1 NBR-Solvability Def: A game G is NBR-solvable (under some tiebreaking rule) if there exists a sequence of eliminations of NBR strategies from the game that leaves each player with only a single strategy. There must be such a sequence for every type configuration of the players. Clear Outcomes Example: Congestion Control  A crude model of TCP congestion control. [Godfrey, Schapira, Zohar, Shenker  SIGMETRICS 2010] A protocol responsible for scaling back transmission rate in cases of congestion. The network is represented by a graph with capacities on the edges. Each player is a pair of source & target nodes, connected by a simple path, and has some maximal rate of transmission. Actions of players: selecting transmission rate (up to limit). Utility: amount of flow that reaches destination. Flow is handled as if routers use Fair Queuing: Capacity on each link is equally divided between players that use the link. Unused capacity by some player is divided equally among others Ce =9 Adjusting rate to fit bottleneck capacity: equivalent to best reply (with certain tie breaking rules) Results for Congestion Control Thm: The Congestion Control Game with routers that follow Fair-Queueing is NBRSolvable with a clear outcome. Ce Eliminate all transmission rates below e* for them. If they all transmit at least e*, none will manage to get more through. Eliminate all rates above e*. Repeat with the residual graph and remaining players. Ce Results for Congestion Control Thm: The Congestion Control Game with routers that follow Fair-Queueing is NBR-Solvable with a clear outcome. Corollaries:  Best-response is incentive compatible  Converges fast regardless of topology TCPs actual behavior in this setting can be seen as probing for the best-response. Other Games Matching Uncorrelated markets, interns and hospitals Cost-sharing games BGP  interdomain routing in the internet. See the paper for more details and references! d Open Questions: Explore other dynamics (e.g., regret minimization) and other equilibria (e.g., mixed Nash, correlated). Find an exact characterization of games where repeated best-response is rational.', 'Personalized Language Model for Query Auto-Completion Aaron Jaech and Mari Ostendorf University of Washington Query Auto-Completion  Search engine suggests queries as the user types Idea from Park & Chiba (2017): Use an LSTM to generate completions  Memory savings over most popular completion  Handles previously unseen prefixes Can we do better by adapting the LM to provide personalized suggestions? RNN Language Model Adaptation Learn an embedding, c, for each user and use it to adapt the predictions Method #1: Concatenate the user embedding with the input at each step*  Same as applying a constant linear shift to the bias vector (in recurrent & output layers)  Leaves most of the recurrent model parameters unchanged  Method #2: Low-rank adaptation of recurrent weight matrix (FactorCell model) Concatenating the user embedding is the same as shifting the bias. \" = \\' =  \" \\')*,\\',  +  =   \\')*,\\' +  + user embedding word embedding Adjust b and W! 0 * Referred to here as ConcatCell (Mikolov& Zweig, 2012) W0 +WA = c LLLL cR Low-rank adaptationGeneric weightsAdapted weights (e + h) x h (e + h) x h k x (e + h) x r r x h x k1 x k k x 1 FactorCell Model The adaptation matrix is formed from a product of the context embedding with left and right bases. The two bases tensors (L and R) hold k different rank r matrices, each the same size as W. Context vectors give a weighted combination. Learning User embeddings, recurrent layer weights and {L, R} tensor learned jointly Need online learning to adapt to users that were not previously seen  In joint training, learn a cold-start embedding for set of infrequent users  During evaluation Initialize each users embedding with learned cold-start vector  Make query suggestions  After user selects a query, back-propagate and only update the user embedding Data & Experiments  Using AOL 2006 Query Log data, 173K users and 12 million queries for training User embedding size = 32, LSTM size = 600 Evaluate on 500K queries with disjoint user population Mean reciprocal rank (MRR) as a metric Experimental Results M ea n Re ci pr oc al R an k Performance for users with > 50 queries Benefit improves over time! Qualitative Comparison What queries are boosted the most after searching for high school softball and math homework help? FactorCell ConcatCell high school musical horoscope chris brown high school musical funnyjunk.com homes for sale funbrain.com modular homes chat room hair styles Queries that most decrease in likelihood with the FactorCell include travel agencies and plane tickets. Recent Related Work: Florini & Lu, NAACL 2018 Also personalized LSTM for query prediction  ConcatCell adaptation framework  User embedding learned separately  No online learning  Assessed on two datasets, but different split of AOL data  Confirms benefit of adapted LM Conclusions Personalization helps and the benefit increases as more queries are seen  Stronger adaptation of the recurrent layer (FactorCell) gives better results than concatenating a user vector  No extra latency/computation due to caching of adapted weight matrix Try out the FactorCell on your data  http://github.com/ajaech/query_completion THANKS! Qualitative Comparison What queries are boosted the most after searching for prada handbags and versace eyewear? FactorCell ConcatCell neiman marcus craigslist nyc pottery barn myspace layours jc penny verizon wireless verizon wireless jensen ackles bed bath and beyond webster dictionary Backup Slides FactorCell Model W0 +WA = Low-rank adaptationGeneric weightsAdapted weights c LLLL cR The adapted weight matrix is a drop-in replacement for W h1 h2 h3 h4 <START> THE YELLOW FOX THE YELLOW FOX JUMPED Much larger change in recurrent layer than what ConcatCell does \\'1* = ( W4 + W0 \\',\\' + ) Prefix and query length Longer queries are more difficult  Suggestion quality improves as prefix length increases', 'diaNED: Time-Aware Named Entity Disambiguation for Diachronic Corpora Prabal Agarwal1, Jannik Strotgen1,2, Luciano del Corro3, Johannes Hoffart3, Ger hard Weikum1 July 18, 2018 Bush to Stress Domestic Issues in Speech. (Year 1989) George W. Bush George H. W. Bush Bush to Stress Domestic Issues in Speech. (Year 1989) George W. Bush George H. W. Bush Bush to Stress Domestic Issues in Speech. (Year 1989) George W. Bush George H. W. Bush Bush to Stress Domestic Issues in Speech. (Year 1989) George W. Bush George H. W. Bush Table of contents Introduction Problem Description Given: Set of entity mentions M in a document.  Entities: entries in a Knowledge Base (KB). Task: Link each m, where m M, to its correct entry in KB, if available.  Predict as an OOKBE, otherwise. Named Entity Disambiguation In 1959, David Pearson exhibited as part of the Young Contemporaries exhibition in London. (en.wikipedia.org/wiki/Dave Pearson (painter)) In 1981, with a small number of BNR colleagues, David Pearson left to found Orcatech Inc. (en.wikipedia.org/wiki/David Pearson (computer scientist)) David Pearson raced for Hoss Ellington during the 1980 season. (en.wikipedia.org/wiki/David Pearson (racing driver)) Named Entity Disambiguation In 1959, David Pearson exhibited as part of the Young Contemporaries exhibition in London. (en.wikipedia.org/wiki/Dave Pearson (painter)) In 1981, with a small number of BNR colleagues, David Pearson left to found Orcatech Inc. (en.wikipedia.org/wiki/David Pearson (computer scientist)) David Pearson raced for Hoss Ellington during the 1980 season. (en.wikipedia.org/wiki/David Pearson (racing driver)) Context Evolution Popularity-based Models Mihalcea and Csomai, 2007 [7] Entity popularity and mention-entity prior probabilities. Leverages anchor links structure. David Pearson Dave Pearson (painter) 0.1 David Pearson David Pearson (computer scientist) 0.03 Local Models Bunescu and Pasca, 2006[2]; Cucerzan, 2007[3]; Milne and Witten, 2008[8] Similarity with immediate context words. Independent disambiguation. David Pearson Dave Pearson (painter) 1959, exhibited, young, exhibition, london David Pearson David Pearson (computer scientist) orcatech Context Evolution Popularity-based Models Mihalcea and Csomai, 2007 [7] Entity popularity and mention-entity prior probabilities. Leverages anchor links structure. David Pearson Dave Pearson (painter) 0.1 David Pearson David Pearson (computer scientist) 0.03 Local Models Bunescu and Pasca, 2006[2]; Cucerzan, 2007[3]; Milne and Witten, 2008[8] Similarity with immediate context words. Independent disambiguation. David Pearson Dave Pearson (painter) 1959, exhibited, young, exhibition, london David Pearson David Pearson (computer scientist) orcatech Context Evolution Global Models Kulkarni et al., 2007[6], Hoffart et al., 2011[4] Entities mentioned in a document are related. Collectively disambiguate entities. David Pearson Dave Pearson (painter) London David Pearson David Pearson (computer scientist) BNR, Orcatech Inc. Representation Learning and Context Attention Blanco et al., 2015[1], Hu et al.[5], 2015, Yamada et al, 2016[10] Use of distributed vector representations. Trained using the anchor links structure of KB. Remove noisy words from the context. David Pearson Dave Pearson (painter) VLondon, Vexhibition David Pearson David Pearson (computer scientist) VBNR, VOrcatech Context Evolution Global Models Kulkarni et al., 2007[6], Hoffart et al., 2011[4] Entities mentioned in a document are related. Collectively disambiguate entities. David Pearson Dave Pearson (painter) London David Pearson David Pearson (computer scientist) BNR, Orcatech Inc. Representation Learning and Context Attention Blanco et al., 2015[1], Hu et al.[5], 2015, Yamada et al, 2016[10] Use of distributed vector representations. Trained using the anchor links structure of KB. Remove noisy words from the context. David Pearson Dave Pearson (painter) VLondon, Vexhibition David Pearson David Pearson (computer scientist) VBNR, VOrcatech Context Evolution Temporal Context Motivation for Temporal Modeling Deductions Previous works fail to factor-in temporal semantics.  Single value for entity popularity.  Bias towards frequently occurring entities in KB and recent news. Year 1989 Bush to Stress Domestic Issues in Speech. Year 1521 Martin Luther confronts the emperor Charles V, refusing to retract the views which led to his excommunication. (4.85105) (1.28104) (2.67105) (5.21105) (3.70105)(4.21106) Figure 1: Entity Annotated Sample Texts1. (Image source: Wikipedia) Motivation for Temporal Modeling Deductions Previous works fail to factor-in temporal semantics.  Single value for entity popularity.  Bias towards frequently occurring entities in KB and recent news. Year 1989 Bush to Stress Domestic Issues in Speech. Year 1521 Martin Luther confronts the emperor Charles V, refusing to retract the views which led to his excommunication. (4.85105) (1.28104) (2.67105) (5.21105) (3.70105)(4.21106) Figure 1: Entity Annotated Sample Texts1. (Image source: Wikipedia) Motivation for Temporal Modeling Deductions Previous works fail to factor-in temporal semantics.  Single value for entity popularity.  Bias towards frequently occurring entities in KB and recent news. Year 1989 Bush to Stress Domestic Issues in Speech. Year 1521 Martin Luther confronts the emperor Charles V, refusing to retract the views which led to his excommunication. (4.85105) (1.28104) (2.67105) (5.21105) (3.70105)(4.21106) Figure 1: Entity Annotated Sample Texts1. (Image source: Wikipedia) Context Evolution Temporal Context Factor-in temporal semantics. Distributed popularity. Independent of anchor link structure. Unbiased towards document creation time. Temporal NED Model Vector Space Modeling C A P C A 3 <George_W._Bush> <George_H._W._Bush> (Bush, 1989) Figure 2: Temporal Vector Space Modeling2. Temporal Signatures of KB Entities Martin Luther Martin Luther (10 November 1483 professor .. Luther proposed .. Ninety-five Theses of 1517 .. Leo X in 1520 and .. Diet of Worms one year later .. family moved to Mansfeld in 1484, .. town councilor in 1492 .. Magdeburg in 1497 .. and Eisenach in 1498 .. In 1501, at .. received his masters degree in 1505. HeidelTime (multi-set of temporal expressions) Fix granularity Exp. Smoothing T em po ra l a ct iv it y Martin Luther (signature) Figure 3: Extraction of Temporal Signatures from Wikipedia Article Content. Temporal Context for Entity Mentions corresponding to DCT. values T (m) extracted by the temporal tagger. The context similarity scores can also be aggregated.  tm = .tdctm + (1 ).tcontentm Disambiguation Example T e m p o ra l a c ti v it y George H. W. Bush Barbara Bush Alan Bush Lawrence Bush George W. Bush Lynn J. Bush Kate Bush T e m p o ra l a c ti v it y Martin Luther King Jr. Martin Luther (diplomat) Martin Luther McCoy Martin Luther Figure 4: Temporal signatures of entity candidates for mentions (Bush, 1989) and (Martin Luther, 1521). Time-Aware Start-of-the-Arts Making NEDs Time-aware diaNED-1, extension of [Hoffart et al.: Robust Disambiguation of Named Entities in Text, EMNLP 2011] Document as a graph with mentions and entities as nodes. Mention-entity priors, mention entity similarity, and entity coherence used as edge weights. Disambiguation: A one-one mapping between each mention and entity node.. diaNED-2, extension of [Yamada et al.: Joint Learning of the Embedding of Words and Entities for Named Entity Disambiguation, SIGNLL 2016] Representation of context words and entities in a single vector space using skip gram model. Disambiguation: A learning-to-rank model using prior stats, string similarity, mention-entity, and coherence similarity as features. Evaluation Standard NED Datasets CoNLL-AIDA 1996 TAC 2010 2004-2007 Microposts 2014 2011 Shortcomings Minimal improvements with Time-aware models.  Not suitable to demonstrate/evaluate power of time-awareness. A Diachronic Dataset: diaNED HistoryNet Historynet.com: online resource of major historical events.  Manually annotated 865 mentions in 350 randomly selected documents3. NewYorkTimes NYT headlines published between 1987 and 2007.  Manually annotated 368 mentions in 300 randomly selected headlines. Results: diaNED-1 HistoryNet NewYorkTimes Feature set w/o time w/ time w/o time w/ time Prior 72.26 80.48* 38.14 54.24* Context 63.63 66.10* 48.31 62.71* Table 1: Micro-accuracy of diaNED-1 with and without time-awareness feature. * significant over w/o time (Welchs t-test at level of 0.01). Results: diaNED-2 HistoryNet NewYorkTimes Feature set w/o time w/ time w/o time w/ time Base 89.44 90.23* 85.81 87.36* String 89.40 90.00* 86.28 87.07* Context 91.10 91.81* 87.07 88.34* Coherence 91.16 91.98* 86.83 88.69* Table 2: Micro-accuracy of diaNED-2 with and without time-awareness feature. * significant over w/o time (Welchs t-test at level of 0.01). Results: diaNED system HistoryNet NewYorkTimes xLisa-NGRAM [Zhang and Rettinger, 2014] 87.07 66.30 xLisa-NER [Zhang and Rettinger, 2014] 83.32 60.25 WAT [Ferragina and Scaiella, 2012] 82.26 70.95 PBOH [Ganea et al., 2016] 90.26 71.75 FREME NER [Dojchinovski and Kliegr, 2013] 48.50 45.27 FRED [Consoli and Recupero, 2015] 23.18 15.44 FOX [Speck and Ngomo, 2014] 77.85 54.25 Dexter [Ceccarelli et al., 2013] 69.88 49.12 DBpedia Spotlight [Mendes et al., 2011] 56.92 61.91 AIDA [Hoffart et al, 2011] 82.68 70.14 AGDISTIS [usbeck et al, 2014] 70.77 50.14 Gupta et al., 2017 62.82 43.33 re-impl. of [Yamada et al., 2016] 90.87 72.55 diaNED-2 91.68 76.09 Table 3: Micro-f1 scores on the HistoryNet and NewYorkTimes datasets of diaNED-2 (trained on CoNLL-AIDA [4]) and other tools available on GERBIL [9]. 19 Summary Summary EED TES EER m 7 e KB Entity Repository Lookup Dictionary m 7 e (Mention-Entity Mapping) EER (Entity-Entity Relations) EED (Entity Encyclopedic Descriptions) Wikipedia Input Texts Texts with Time aware Disambiguated Entity Mentions diaNED CoNLL-AIDA TAC 2010 Named Entity Tagger Time-aware NED Temporal Tagger TES: Temporal Entity Signatures Temporal Contexts Note The annotated diaNED Corpora and Entity Temporal Signatures are available at: https://www.mpi-inf.mpg.de/yago-naga/dianed/ Future Work Study how temporal affinity can be used for identifying out-of-KB entities. Large scale experiments using data-sets generarted using semi-supervised methods. Adding multilingual support for the temporal signatures. Thank you! Questions? References i R. Blanco, G. Ottaviano, and E. Meij. Fast and space-efficient entity linking for queries. In Proceedings of the 8th ACM International Conference on Web Search and Data Mining, WSDM 15, pages 179188. ACM, 2015. R. C. Bunescu and M. Pasca. Using encyclopedic knowledge for named entity disambiguation. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, EACL 06, pages References ii S. Cucerzan. Large-scale named entity disambiguation based on Wikipedia data. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL 07, pages 708716. Association for Computational Linguistics, June 2007. J. Hoffart, M. A. Yosef, I. Bordino, H. Furstenau, M. Pinkal, M. Spaniol, B. Taneva, S. Thater, and G. Weikum. Robust disambiguation of named entities in text. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP 11, pages 782792. Association for Computational Linguistics, 2011. References iii Z. Hu, P. Huang, Y. Deng, Y. Gao, and E. Xing. Entity hierarchy embedding. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 12921300, Beijing, China, July 2015. Association for Computational Linguistics. S. Kulkarni, A. Singh, G. Ramakrishnan, and S. Chakrabarti. Collective annotation of wikipedia entities in web text. In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD 09, pages References iv R. Mihalcea and A. Csomai. Wikify!: Linking documents to encyclopedic knowledge. In Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management, CIKM 07, pages D. Milne and I. H. Witten. Learning to link with wikipedia. In Proceedings of the 17th ACM Conference on Information and Knowledge Management, CIKM 08, pages 509518. ACM, 2008. References v R. Usbeck, M. Roder, A.-C. Ngonga Ngomo, C. Baron, A. Both, M. Brummer, D. Ceccarelli, M. Cornolti, D. Cherix, B. Eickmann, P. Ferragina, C. Lemke, A. Moro, R. Navigli, F. Piccinno, G. Rizzo, H. Sack, R. Speck, R. Troncy, J. Waitelonis, and L. Wesemann. Gerbil: General entity annotator benchmarking framework. In Proceedings of the 24th International Conference on World Wide Web, WWW 15, pages 11331143. International World Wide Web Conferences Steering Committee, 2015. I. Yamada, H. Shindo, H. Takeda, and Y. Takefuji. Joint learning of the embedding of words and entities for named entity disambiguation. In Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning, CoNLL 15, pages 250259. Association for Computational Linguistics, August 2016.', 'Examining Temporality in Document Classification Xiaolei Huang Michael J. Paul University of Colorado Boulder Examining Temporality in Document Classification or Why is my classifier getting worse over time? Why is my classifier getting worse? The data distribution has changed Is there anything systematic about how it changes? Is there anything we can do to adapt to temporal changes? Subtle shifts in topic distribution Declining performance Experiments Two types of time periods: Seasonal Repeat across years (e.g., time of year) Non-seasonal  No repetition (e.g., spans of years) Experiments Binary classification  Logistic regression, n-gram features Six datasets, each grouped into 4-6 time periods Why is my classifier getting worse? The data distribution has changed Is there anything systematic about how it changes? Is there anything we can do to adapt to temporal changes? RQ1: How does performance vary? Analysis:  Train and test on each time period Measure how performance drops when the test period is different Balanced so each time period has same # of documents RQ1: How does performance vary? RQ1: How does performance vary? RQ1: How does performance vary? Yelp reviews are getting more informative over time? RQ1: How does performance vary? Takeaways: This type of analysis can reveal characteristics of corpus Unanswered: why does performance vary? Why is my classifier getting worse? The data distribution has changed Is there anything systematic about how it changes? Is there anything we can do to adapt to temporal changes? RQ2: Can we adapt to temporal variations? Idea: Address this as a domain adaptation problem Treat explicitly-defined time periods as domains RQ2: Can we adapt to temporal variations? Approach: Feature augmentation method from Daum III (2007) RQ2: Can we adapt to temporal variations? Approach: Feature augmentation method from Daum III (2007) Photo via @ChrisVVarren RQ2: Can we adapt to temporal variations? General Jan-Mar Apr-Jun Jul-Sep Oct-Dec Domain-specific copies of the feature set: RQ2: Can we adapt to temporal variations? General Jan-Mar Apr-Jun Jul-Sep Oct-Dec Apr-Jun RQ2: Can we adapt to temporal variations? Straightforward to apply to seasonal features: RQ2: Can we adapt to temporal variations? How to use in non-seasonal settings? General 2012 2013 2014 2015 RQ2: Can we adapt to temporal variations? How to use in non-seasonal settings?  Separately weigh domain-specific features General 2012 2013 2014 2015 RQ2: Can we adapt to temporal variations? How to use in non-seasonal settings?  During training: weigh domain-specific features differently  Can also combine with seasonal domains 3 copies of each feature (general, year-specific, season-specific) Simulating performance on future data:  Train in initial time periods  Tune on second-to-last period  Test on final time period RQ2: Can we adapt to temporal variations? How to use in non-seasonal settings? RQ2: Can we adapt to temporal variations? Takeaways: Simple-to-implement adaptation can make classifiers more robust across time Suggestion: tune hyperparameters on heldout data from the chronological end of your corpus (cf. cross-validation)  Can lead to better performance on future data Thank you! Questions? Code: https://github.com/xiaoleihuang/Domain_Adaptation_ACL2018']\n",
      "[[101, 2053, 3286, 9152, 8791, 1010, 2745, 8040, 3270, 8197, 2527, 1010, 7296, 24329, 1010, 1998, 12724, 1062, 11631, 2906, 14354, 14442, 2003, 1996, 3937, 4874, 1997, 2817, 1999, 2208, 3399, 1012, 3160, 1024, 2129, 2003, 2019, 14442, 2584, 1029, 1999, 1037, 5621, 23045, 3437, 2169, 2867, 3627, 1997, 5248, 2003, 3722, 1998, 7246, 11581, 5567, 2190, 1011, 3433, 5567, 2488, 1011, 3433, 9038, 1011, 7163, 4328, 9276, 14354, 5567, 2190, 1011, 3433, 2003, 2411, 4846, 1999, 3218, 1041, 1012, 1043, 1012, 1010, 4274, 16972, 2057, 3198, 1024, 2043, 2003, 2107, 7246, 8156, 2389, 5248, 2428, 11581, 1029, 5567, 2190, 1011, 3433, 2003, 2025, 2467, 2190, 1012, 1008, 1996, 2208, 2003, 14017, 12423, 2083, 9614, 1997, 6817, 9942, 1012, 19184, 1997, 3463, 2057, 6709, 1037, 2235, 2465, 1997, 2399, 2005, 2029, 1024, 1015, 1012, 5567, 2190, 1011, 3433, 28314, 2015, 1006, 2855, 1007, 2013, 2151, 3988, 2391, 1012, 2096, 2235, 1010, 2023, 2465, 4472, 2195, 2590, 4973, 1024, 4274, 16972, 1010, 3465, 6631, 1010, 6540, 18328, 2015, 1010, 20176, 2491, 1012, 1996, 4292, 1996, 5567, 2190, 1011, 3433, 5656, 1024, 2043, 1037, 2867, 2735, 8480, 1010, 2009, 17472, 1996, 2190, 3433, 2000, 1996, 6745, 25674, 1997, 2500, 1012, 5495, 4911, 3513, 2196, 2190, 3433, 1006, 1050, 19892, 1007, 9942, 1011, 2184, 1011, 2321, 1017, 1011, 1017, 1017, 1011, 1015, 1050, 19892, 1011, 14017, 3567, 8553, 13366, 1024, 1037, 2208, 1043, 2003, 1050, 19892, 1011, 14017, 12423, 1006, 2104, 2070, 5495, 23890, 2075, 3627, 1007, 2065, 2045, 6526, 1037, 5537, 1997, 9614, 2015, 1997, 1050, 19892, 9942, 2013, 1996, 2208, 2008, 3727, 2169, 2447, 2007, 2069, 1037, 2309, 5656, 1012, 2045, 2442, 2022, 2107, 1037, 5537, 2005, 2296, 2828, 9563, 1997, 1996, 2867, 1012, 3154, 13105, 2742, 1024, 20176, 2491, 1037, 13587, 2944, 1997, 22975, 2361, 20176, 2491, 1012, 1031, 18238, 1010, 8040, 3270, 8197, 2527, 1010, 1062, 11631, 2906, 1010, 21882, 5484, 9033, 21693, 3388, 7277, 2015, 2230, 1033, 1037, 8778, 3625, 2005, 25169, 2067, 6726, 3446, 1999, 3572, 1997, 20176, 1012, 1996, 2897, 2003, 3421, 2011, 1037, 10629, 2007, 21157, 2006, 1996, 7926, 1012, 2169, 2447, 2003, 1037, 3940, 1997, 3120, 1004, 4539, 14164, 1010, 4198, 2011, 1037, 3722, 4130, 1010, 1998, 2038, 2070, 29160, 3446, 1997, 6726, 1012, 4506, 1997, 2867, 1024, 17739, 6726, 3446, 1006, 2039, 2000, 5787, 1007, 1012, 9710, 1024, 3815, 1997, 4834, 2008, 6561, 7688, 1012, 4834, 2003, 8971, 2004, 2065, 2799, 2869, 2224, 4189, 10861, 25165, 1024, 3977, 2006, 2169, 4957, 2003, 8053, 4055, 2090, 2867, 2008, 2224, 1996, 4957, 1012, 15171, 3977, 2011, 2070, 2447, 2003, 4055, 8053, 2426, 2500, 8292, 1027, 1023, 19158, 3446, 2000, 4906, 5835, 18278, 3977, 1024, 5662, 2000, 2190, 7514, 1006, 2007, 3056, 5495, 4911, 3513, 1007, 3463, 2005, 20176, 2491, 16215, 2213, 1024, 1996, 20176, 2491, 2208, 2007, 2799, 2869, 2008, 3582, 4189, 1011, 24240, 2075, 2003, 1050, 19892, 19454, 12423, 2007, 1037, 3154, 9560, 1012, 8292, 11027, 2035, 6726, 6165, 2917, 1041, 1008, 2005, 2068, 1012, 2065, 2027, 2035, 19818, 2012, 2560, 1041, 1008, 1010, 3904, 2097, 6133, 2000, 2131, 2062, 2083, 1012, 11027, 2035, 6165, 2682, 1041, 1008, 1012, 9377, 2007, 1996, 21961, 10629, 1998, 3588, 2867, 1012, 8292, 3463, 2005, 20176, 2491, 16215, 2213, 1024, 1996, 20176, 2491, 2208, 2007, 2799, 2869, 2008, 3582, 4189, 1011, 24240, 2075, 2003, 1050, 19892, 1011, 14017, 12423, 2007, 1037, 3154, 9560, 1012, 2522, 28402, 12086, 1024, 2190, 1011, 3433, 2003, 20438, 11892, 28314, 2015, 3435, 7539, 1997, 19587, 22975, 4523, 5025, 5248, 1999, 2023, 4292, 2064, 2022, 2464, 2004, 28664, 2005, 1996, 2190, 1011, 3433, 1012, 2060, 2399, 9844, 4895, 27108, 16570, 4383, 6089, 1010, 25204, 2015, 1998, 8323, 3465, 1011, 6631, 2399, 1038, 21600, 6970, 9527, 8113, 16972, 1999, 1996, 4274, 1012, 2156, 1996, 3259, 2005, 2062, 4751, 1998, 7604, 999, 1040, 2330, 3980, 1024, 8849, 2060, 10949, 1006, 1041, 1012, 1043, 1012, 1010, 9038, 7163, 4328, 9276, 1007, 1998, 2060, 1041, 26147, 12322, 4360, 1006, 1041, 1012, 1043, 1012, 1010, 3816, 10594, 1010, 23900, 1007, 1012, 2424, 2019, 6635, 23191, 1997, 2399, 2073, 5567, 2190, 1011, 3433, 2003, 11581, 1012, 102], [101, 3167, 3550, 2653, 2944, 2005, 23032, 8285, 1011, 6503, 7158, 22770, 2818, 1998, 16266, 9808, 6528, 11592, 2118, 1997, 2899, 23032, 8285, 1011, 6503, 3945, 3194, 6083, 10861, 5134, 2004, 1996, 5310, 4127, 2801, 2013, 2380, 1004, 27368, 1006, 2418, 1007, 1024, 2224, 2019, 1048, 3367, 2213, 2000, 9699, 6503, 2015, 3638, 10995, 2058, 2087, 2759, 6503, 16024, 3130, 16100, 17576, 2229, 2064, 2057, 2079, 2488, 2011, 25357, 1996, 1048, 2213, 2000, 3073, 3167, 3550, 15690, 1029, 29300, 2078, 2653, 2944, 6789, 4553, 2019, 7861, 8270, 4667, 1010, 1039, 1010, 2005, 2169, 5310, 1998, 2224, 2009, 2000, 15581, 1996, 20932, 4118, 1001, 1015, 1024, 9530, 16280, 12556, 1996, 5310, 7861, 8270, 4667, 2007, 1996, 7953, 2012, 2169, 3357, 1008, 2168, 2004, 11243, 1037, 5377, 7399, 5670, 2000, 1996, 13827, 9207, 1006, 1999, 28667, 29264, 1004, 6434, 9014, 1007, 3727, 2087, 1997, 1996, 28667, 29264, 2944, 11709, 15704, 4118, 1001, 1016, 1024, 2659, 1011, 4635, 6789, 1997, 28667, 29264, 3635, 8185, 1006, 5387, 29109, 2140, 2944, 1007, 9530, 16280, 19833, 2075, 1996, 5310, 7861, 8270, 4667, 2003, 1996, 2168, 2004, 9564, 1996, 13827, 1012, 1000, 1027, 1005, 1027, 1000, 1005, 1007, 1008, 1010, 1005, 1010, 1009, 1027, 1005, 1007, 1008, 1010, 1005, 1009, 1009, 5310, 7861, 8270, 4667, 2773, 7861, 8270, 4667, 14171, 1038, 1998, 1059, 999, 1014, 1008, 3615, 2000, 2182, 2004, 9530, 11266, 29109, 2140, 1006, 2771, 3683, 14301, 1004, 1062, 27204, 1010, 2262, 1007, 1059, 2692, 1009, 11333, 1027, 1039, 2222, 3363, 13675, 2659, 1011, 4635, 6789, 6914, 22420, 15871, 8447, 13876, 2098, 15871, 1006, 1041, 1009, 1044, 1007, 1060, 1044, 1006, 1041, 1009, 1044, 1007, 1060, 1044, 1047, 1060, 1006, 1041, 1009, 1044, 1007, 1060, 1054, 1054, 1060, 1044, 1060, 1047, 2487, 1060, 1047, 1047, 1060, 1015, 5387, 29109, 2140, 2944, 1996, 6789, 8185, 2003, 2719, 2013, 1037, 4031, 1997, 1996, 6123, 7861, 8270, 4667, 2007, 2187, 1998, 2157, 7888, 1012, 1996, 2048, 7888, 23435, 2015, 1006, 1048, 1998, 1054, 1007, 2907, 1047, 2367, 4635, 1054, 21520, 1010, 2169, 1996, 2168, 2946, 2004, 1059, 1012, 6123, 19019, 2507, 1037, 18215, 5257, 1012, 4083, 5310, 7861, 8270, 4667, 2015, 1010, 28667, 29264, 6741, 15871, 1998, 1063, 1048, 1010, 1054, 1065, 23435, 4342, 10776, 2342, 3784, 4083, 2000, 15581, 2000, 5198, 2008, 2020, 2025, 3130, 2464, 1999, 4101, 2731, 1010, 4553, 1037, 3147, 1011, 2707, 7861, 8270, 4667, 2005, 2275, 1997, 1999, 19699, 2063, 15417, 5198, 2076, 9312, 3988, 4697, 2169, 5198, 7861, 8270, 4667, 2007, 4342, 3147, 1011, 2707, 9207, 2191, 23032, 15690, 2044, 5310, 27034, 1037, 23032, 1010, 2067, 1011, 17678, 16098, 2618, 1998, 2069, 10651, 1996, 5310, 7861, 8270, 4667, 2951, 1004, 7885, 2478, 20118, 2140, 2294, 23032, 8833, 2951, 1010, 19410, 2243, 5198, 1998, 2260, 2454, 10861, 5134, 2005, 2731, 5310, 7861, 8270, 4667, 2946, 1027, 3590, 1010, 1048, 3367, 2213, 2946, 1027, 5174, 16157, 2006, 3156, 2243, 10861, 5134, 2007, 4487, 2015, 5558, 18447, 5310, 2313, 2812, 28309, 4635, 1006, 2720, 2099, 1007, 2004, 1037, 12046, 6388, 3463, 1049, 19413, 1050, 2128, 25022, 10975, 1051, 2278, 2632, 1054, 2019, 1047, 2836, 2005, 5198, 2007, 1028, 2753, 10861, 5134, 5770, 24840, 2058, 2051, 999, 24209, 11475, 27453, 7831, 2054, 10861, 5134, 2024, 28043, 1996, 2087, 2044, 6575, 2005, 2152, 2082, 12585, 1998, 8785, 19453, 2393, 1029, 5387, 29109, 2140, 9530, 11266, 29109, 2140, 2152, 2082, 3315, 7570, 7352, 16186, 3782, 2829, 2152, 2082, 3315, 6057, 19792, 2243, 1012, 4012, 5014, 2005, 5096, 4569, 10024, 2378, 1012, 4012, 19160, 5014, 11834, 2282, 2606, 6782, 10861, 5134, 2008, 2087, 9885, 1999, 16593, 2007, 1996, 5387, 29109, 2140, 2421, 3604, 6736, 1998, 4946, 9735, 1012, 3522, 3141, 2147, 1024, 13109, 28741, 2072, 1004, 11320, 1010, 6583, 6305, 2140, 2760, 2036, 3167, 3550, 1048, 3367, 2213, 2005, 23032, 17547, 9530, 11266, 29109, 2140, 6789, 7705, 5310, 7861, 8270, 4667, 4342, 10329, 2053, 3784, 4083, 14155, 2006, 2048, 2951, 13462, 2015, 1010, 2021, 2367, 3975, 1997, 20118, 2140, 2951, 23283, 5770, 1997, 5967, 1048, 2213, 15306, 3167, 3989, 7126, 1998, 1996, 5770, 7457, 2004, 2062, 10861, 5134, 2024, 2464, 6428, 6789, 1997, 1996, 28667, 29264, 6741, 1006, 5387, 29109, 2140, 1007, 3957, 2488, 3463, 2084, 9530, 16280, 19833, 2075, 1037, 5310, 9207, 2053, 4469, 2397, 9407, 1013, 22334, 2349, 2000, 6187, 8450, 1997, 5967, 3635, 8185, 3046, 2041, 1996, 5387, 29109, 2140, 2006, 2115, 2951, 8299, 1024, 1013, 1013, 21025, 2705, 12083, 1012, 4012, 1013, 19128, 6679, 2818, 1013, 23032, 1035, 6503, 4283, 999, 24209, 11475, 27453, 7831, 2054, 10861, 5134, 2024, 28043, 1996, 2087, 2044, 6575, 2005, 10975, 8447, 2192, 26813, 1998, 18601, 3401, 3239, 16689, 1029, 5387, 29109, 2140, 9530, 11266, 29109, 2140, 11265, 18505, 6647, 7010, 14540, 2923, 16392, 11378, 8659, 24927, 3913, 22957, 29175, 10647, 2310, 21885, 2239, 9949, 2310, 21885, 2239, 9949, 14857, 9353, 19099, 2015, 2793, 7198, 1998, 3458, 11635, 9206, 10200, 14816, 5387, 29109, 2140, 2944, 1059, 2692, 1009, 11333, 1027, 2659, 1011, 4635, 6789, 6914, 22420, 15871, 8447, 13876, 2098, 15871, 1039, 2222, 3363, 13675, 1996, 5967, 3635, 8185, 2003, 1037, 4530, 1011, 1999, 6110, 2005, 1059, 1044, 2487, 1044, 2475, 1044, 2509, 1044, 2549, 1026, 2707, 1028, 1996, 3756, 4419, 1996, 3756, 4419, 5598, 2172, 3469, 2689, 1999, 28667, 29264, 6741, 2084, 2054, 9530, 11266, 29109, 2140, 2515, 1005, 1015, 1008, 1027, 1006, 1059, 2549, 1009, 1059, 2692, 1005, 1010, 1005, 1009, 1007, 17576, 1998, 23032, 3091, 2936, 10861, 5134, 2024, 2062, 3697, 10293, 3737, 24840, 2004, 17576, 3091, 7457, 102], [101, 12082, 2094, 1024, 2051, 1011, 5204, 2315, 9178, 4487, 21559, 5638, 19696, 3508, 2005, 22939, 2818, 4948, 2594, 13058, 6525, 10975, 19736, 2140, 12943, 2906, 13476, 2487, 1010, 5553, 8238, 2358, 21709, 6914, 2487, 1010, 1016, 1010, 24512, 3972, 2522, 18933, 2509, 1010, 12470, 7570, 20961, 5339, 2509, 1010, 16216, 2099, 2524, 11417, 5283, 2213, 2487, 2251, 2324, 1010, 2760, 5747, 2000, 6911, 4968, 3314, 1999, 4613, 1012, 1006, 2095, 2960, 1007, 2577, 1059, 1012, 5747, 2577, 1044, 1012, 1059, 1012, 5747, 5747, 2000, 6911, 4968, 3314, 1999, 4613, 1012, 1006, 2095, 2960, 1007, 2577, 1059, 1012, 5747, 2577, 1044, 1012, 1059, 1012, 5747, 5747, 2000, 6911, 4968, 3314, 1999, 4613, 1012, 1006, 2095, 2960, 1007, 2577, 1059, 1012, 5747, 2577, 1044, 1012, 1059, 1012, 5747, 5747, 2000, 6911, 4968, 3314, 1999, 4613, 1012, 1006, 2095, 2960, 1007, 2577, 1059, 1012, 5747, 2577, 1044, 1012, 1059, 1012, 5747, 2795, 1997, 8417, 4955, 3291, 6412, 2445, 1024, 2275, 1997, 9178, 9704, 1049, 1999, 1037, 6254, 1012, 11422, 1024, 10445, 1999, 1037, 3716, 2918, 1006, 21677, 1007, 1012, 4708, 1024, 4957, 2169, 1049, 1010, 2073, 1049, 1049, 1010, 2000, 2049, 6149, 4443, 1999, 21677, 1010, 2065, 2800, 1012, 16014, 2004, 2019, 1051, 6559, 4783, 1010, 4728, 1012, 2315, 9178, 4487, 21559, 5638, 19696, 3508, 1999, 3851, 1010, 2585, 12874, 8176, 2004, 2112, 1997, 1996, 2402, 16682, 4538, 1999, 2414, 1012, 1006, 4372, 1012, 16948, 1012, 8917, 1013, 15536, 3211, 1013, 4913, 12874, 1006, 5276, 1007, 1007, 1999, 3261, 1010, 2007, 1037, 2235, 2193, 1997, 24869, 2099, 8628, 1010, 2585, 12874, 2187, 2000, 2179, 2030, 16280, 2818, 4297, 1012, 1006, 4372, 1012, 16948, 1012, 8917, 1013, 15536, 3211, 1013, 2585, 12874, 1006, 3274, 7155, 1007, 1007, 2585, 12874, 8255, 2005, 7570, 4757, 21630, 2076, 1996, 3150, 2161, 1012, 1006, 4372, 1012, 16948, 1012, 8917, 1013, 15536, 3211, 1013, 2585, 12874, 1006, 3868, 4062, 1007, 1007, 2315, 9178, 4487, 21559, 5638, 19696, 3508, 1999, 3851, 1010, 2585, 12874, 8176, 2004, 2112, 1997, 1996, 2402, 16682, 4538, 1999, 2414, 1012, 1006, 4372, 1012, 16948, 1012, 8917, 1013, 15536, 3211, 1013, 4913, 12874, 1006, 5276, 1007, 1007, 1999, 3261, 1010, 2007, 1037, 2235, 2193, 1997, 24869, 2099, 8628, 1010, 2585, 12874, 2187, 2000, 2179, 2030, 16280, 2818, 4297, 1012, 1006, 4372, 1012, 16948, 1012, 8917, 1013, 15536, 3211, 1013, 2585, 12874, 1006, 3274, 7155, 1007, 1007, 2585, 12874, 8255, 2005, 7570, 4757, 21630, 2076, 1996, 3150, 2161, 1012, 1006, 4372, 1012, 16948, 1012, 8917, 1013, 15536, 3211, 1013, 2585, 12874, 1006, 3868, 4062, 1007, 1007, 6123, 6622, 6217, 1011, 2241, 4275, 2771, 8865, 21456, 1998, 20116, 9626, 2072, 1010, 2289, 1031, 1021, 1033, 9178, 6217, 1998, 5254, 1011, 9178, 3188, 4013, 3676, 14680, 1012, 21155, 2015, 8133, 6971, 3252, 1012, 2585, 12874, 4913, 12874, 1006, 5276, 1007, 1014, 1012, 1015, 2585, 12874, 2585, 12874, 1006, 3274, 7155, 1007, 1014, 1012, 6021, 2334, 4275, 21122, 19434, 1998, 14674, 3540, 1010, 2294, 1031, 1016, 1033, 1025, 12731, 17119, 13471, 1010, 2289, 1031, 1017, 1033, 1025, 24377, 1998, 15966, 6528, 1010, 2263, 1031, 1022, 1033, 14402, 2007, 6234, 6123, 2616, 1012, 2981, 4487, 21559, 5638, 19696, 3508, 1012, 2585, 12874, 4913, 12874, 1006, 5276, 1007, 3851, 1010, 8176, 1010, 2402, 1010, 4538, 1010, 2414, 2585, 12874, 2585, 12874, 1006, 3274, 7155, 1007, 2030, 16280, 2818, 6123, 6622, 6217, 1011, 2241, 4275, 2771, 8865, 21456, 1998, 20116, 9626, 2072, 1010, 2289, 1031, 1021, 1033, 9178, 6217, 1998, 5254, 1011, 9178, 3188, 4013, 3676, 14680, 1012, 21155, 2015, 8133, 6971, 3252, 1012, 2585, 12874, 4913, 12874, 1006, 5276, 1007, 1014, 1012, 1015, 2585, 12874, 2585, 12874, 1006, 3274, 7155, 1007, 1014, 1012, 6021, 2334, 4275, 21122, 19434, 1998, 14674, 3540, 1010, 2294, 1031, 1016, 1033, 1025, 12731, 17119, 13471, 1010, 2289, 1031, 1017, 1033, 1025, 24377, 1998, 15966, 6528, 1010, 2263, 1031, 1022, 1033, 14402, 2007, 6234, 6123, 2616, 1012, 2981, 4487, 21559, 5638, 19696, 3508, 1012, 2585, 12874, 4913, 12874, 1006, 5276, 1007, 3851, 1010, 8176, 1010, 2402, 1010, 4538, 1010, 2414, 2585, 12874, 2585, 12874, 1006, 3274, 7155, 1007, 2030, 16280, 2818, 6123, 6622, 3795, 4275, 13970, 26518, 6826, 2072, 3802, 2632, 1012, 1010, 2289, 1031, 1020, 1033, 1010, 7570, 20961, 5339, 3802, 2632, 1012, 1010, 2249, 1031, 1018, 1033, 11422, 3855, 1999, 1037, 6254, 2024, 3141, 1012, 13643, 4487, 21559, 5638, 19696, 2618, 11422, 1012, 2585, 12874, 4913, 12874, 1006, 5276, 1007, 2414, 2585, 12874, 2585, 12874, 1006, 3274, 7155, 1007, 24869, 2099, 1010, 2030, 16280, 2818, 4297, 1012, 6630, 4083, 1998, 6123, 3086, 20036, 3802, 2632, 1012, 1010, 2325, 1031, 1015, 1033, 1010, 15876, 3802, 2632, 1012, 1031, 1019, 1033, 1010, 2325, 1010, 8038, 23574, 3802, 2632, 1010, 2355, 1031, 2184, 1033, 2224, 1997, 5500, 9207, 15066, 1012, 4738, 2478, 1996, 8133, 6971, 3252, 1997, 21677, 1012, 6366, 20810, 2616, 2013, 1996, 6123, 1012, 2585, 12874, 4913, 12874, 1006, 5276, 1007, 1058, 7811, 5280, 1010, 2310, 2595, 4048, 16313, 3258, 2585, 12874, 2585, 12874, 1006, 3274, 7155, 1007, 1058, 24700, 2099, 1010, 29536, 18992, 15007, 6123, 6622, 3795, 4275, 13970, 26518, 6826, 2072, 3802, 2632, 1012, 1010, 2289, 1031, 1020, 1033, 1010, 7570, 20961, 5339, 3802, 2632, 1012, 1010, 2249, 1031, 1018, 1033, 11422, 3855, 1999, 1037, 6254, 2024, 3141, 1012, 13643, 4487, 21559, 5638, 19696, 2618, 11422, 1012, 2585, 12874, 4913, 12874, 1006, 5276, 1007, 2414, 2585, 12874, 2585, 12874, 1006, 3274, 7155, 1007, 24869, 2099, 1010, 2030, 16280, 2818, 4297, 1012, 6630, 4083, 1998, 6123, 3086, 20036, 3802, 2632, 1012, 1010, 2325, 1031, 1015, 1033, 1010, 15876, 3802, 2632, 1012, 1031, 1019, 1033, 1010, 2325, 1010, 8038, 23574, 3802, 2632, 1010, 2355, 1031, 2184, 1033, 2224, 1997, 5500, 9207, 15066, 1012, 4738, 2478, 1996, 8133, 6971, 3252, 1997, 21677, 1012, 6366, 20810, 2616, 2013, 1996, 6123, 1012, 2585, 12874, 4913, 12874, 1006, 5276, 1007, 1058, 7811, 5280, 1010, 2310, 2595, 4048, 16313, 3258, 2585, 12874, 2585, 12874, 1006, 3274, 7155, 1007, 1058, 24700, 2099, 1010, 29536, 18992, 15007, 6123, 6622, 15850, 6123, 14354, 2005, 15850, 11643, 2139, 16256, 2015, 3025, 2573, 8246, 2000, 5387, 1011, 1999, 15850, 28081, 1012, 2309, 3643, 2005, 9178, 6217, 1012, 13827, 2875, 4703, 10066, 11422, 1999, 21677, 1998, 3522, 2739, 1012, 2095, 2960, 5747, 2000, 6911, 4968, 3314, 1999, 4613, 1012, 2095, 15017, 2487, 3235, 9678, 17628, 1996, 3750, 2798, 1058, 1010, 11193, 2000, 2128, 6494, 6593, 1996, 5328, 2029, 2419, 2000, 2010, 4654, 9006, 23041, 21261, 1012, 1006, 1018, 1012, 5594, 10790, 2629, 1007, 1006, 1015, 1012, 22955, 2692, 2549, 1007, 1006, 1016, 1012, 6163, 10790, 2629, 1007, 1006, 1019, 1012, 19235, 2692, 2629, 1007, 1006, 1017, 1012, 3963, 10790, 2629, 1007, 1006, 1018, 1012, 19235, 2692, 2575, 1007, 3275, 1015, 1024, 9178, 5754, 17287, 3064, 7099, 6981, 2487, 1012, 1006, 3746, 3120, 1024, 16948, 1007, 14354, 2005, 15850, 11643, 2139, 16256, 2015, 3025, 2573, 8246, 2000, 5387, 1011, 1999, 15850, 28081, 1012, 2309, 3643, 2005, 9178, 6217, 1012, 13827, 2875, 4703, 10066, 11422, 1999, 21677, 1998, 3522, 2739, 1012, 2095, 2960, 5747, 2000, 6911, 4968, 3314, 1999, 4613, 1012, 2095, 15017, 2487, 3235, 9678, 17628, 1996, 3750, 2798, 1058, 1010, 11193, 2000, 2128, 6494, 6593, 1996, 5328, 2029, 2419, 2000, 2010, 4654, 9006, 23041, 21261, 1012, 1006, 1018, 1012, 5594, 10790, 2629, 1007, 1006, 1015, 1012, 22955, 2692, 2549, 1007, 1006, 1016, 1012, 6163, 10790, 2629, 1007, 1006, 1019, 1012, 19235, 2692, 2629, 1007, 1006, 1017, 1012, 3963, 10790, 2629, 1007, 1006, 1018, 1012, 19235, 2692, 2575, 1007, 3275, 1015, 1024, 9178, 5754, 17287, 3064, 7099, 6981, 2487, 1012, 1006, 3746, 3120, 1024, 16948, 1007, 14354, 2005, 15850, 11643, 2139, 16256, 2015, 3025, 2573, 8246, 2000, 5387, 1011, 1999, 15850, 28081, 1012, 2309, 3643, 2005, 9178, 6217, 1012, 13827, 2875, 4703, 10066, 11422, 1999, 21677, 1998, 3522, 2739, 1012, 2095, 2960, 5747, 2000, 6911, 4968, 3314, 1999, 4613, 1012, 2095, 15017, 2487, 3235, 9678, 17628, 1996, 3750, 2798, 1058, 1010, 11193, 2000, 2128, 6494, 6593, 1996, 5328, 2029, 2419, 2000, 2010, 4654, 9006, 23041, 21261, 1012, 1006, 1018, 1012, 5594, 10790, 2629, 1007, 1006, 1015, 1012, 22955, 2692, 2549, 1007, 1006, 1016, 1012, 6163, 10790, 2629, 1007, 1006, 1019, 1012, 19235, 2692, 2629, 1007, 1006, 1017, 1012, 3963, 10790, 2629, 1007, 1006, 1018, 1012, 19235, 2692, 2575, 1007, 3275, 1015, 1024, 9178, 5754, 17287, 3064, 7099, 6981, 2487, 1012, 1006, 3746, 3120, 1024, 16948, 1007, 6123, 6622, 15850, 6123, 5387, 1011, 1999, 15850, 28081, 1012, 5500, 6217, 1012, 2981, 1997, 8133, 4957, 3252, 1012, 4895, 11607, 6924, 2875, 6254, 4325, 2051, 1012, 15850, 12311, 2944, 9207, 2686, 11643, 1039, 1037, 1052, 1039, 1037, 1017, 1026, 2577, 1035, 1059, 1012, 1035, 5747, 1028, 1026, 2577, 1035, 1044, 1012, 1035, 1059, 1012, 1035, 5747, 1028, 1006, 5747, 1010, 2960, 1007, 3275, 1016, 1024, 15850, 9207, 2686, 11643, 2475, 1012, 15850, 16442, 1997, 21677, 11422, 3235, 9678, 3235, 9678, 1006, 2184, 2281, 16459, 2509, 2934, 1012, 1012, 9678, 3818, 1012, 1012, 13568, 1011, 2274, 2122, 2015, 1997, 16528, 2581, 1012, 1012, 6688, 1060, 1999, 15017, 2692, 1998, 1012, 1012, 8738, 1997, 16253, 2028, 2095, 2101, 1012, 1012, 2155, 2333, 2000, 16042, 8151, 1999, 16459, 2549, 1010, 1012, 1012, 2237, 2473, 2953, 1999, 17332, 2475, 1012, 1012, 23848, 3207, 4645, 1999, 17332, 2581, 1012, 1012, 1998, 1041, 28992, 6776, 1999, 17332, 2620, 1012, 1012, 1999, 5018, 2487, 1010, 2012, 1012, 1012, 2363, 2010, 5972, 3014, 1999, 5018, 2629, 1012, 2002, 5178, 7096, 14428, 1006, 4800, 1011, 2275, 1997, 15850, 11423, 1007, 8081, 12604, 7934, 3012, 4654, 2361, 1012, 27045, 1056, 7861, 13433, 10958, 1048, 1037, 14931, 4921, 2009, 1061, 3235, 9678, 1006, 8085, 1007, 3275, 1017, 1024, 14676, 1997, 15850, 16442, 2013, 16948, 3720, 4180, 1012, 15850, 6123, 2005, 9178, 9704, 7978, 2000, 5887, 2102, 1012, 5300, 1056, 1006, 1049, 1007, 15901, 2011, 1996, 15850, 6415, 4590, 1012, 1996, 6123, 14402, 7644, 2064, 2036, 2022, 9572, 2094, 1012, 1056, 2213, 1027, 1012, 14595, 6593, 2213, 1009, 1006, 1015, 1007, 1012, 22975, 28040, 3372, 2213, 4487, 21559, 5638, 19696, 3508, 2742, 1056, 1041, 1049, 1052, 1051, 10958, 1048, 1037, 1039, 14841, 1058, 2009, 1061, 2577, 1044, 1012, 1059, 1012, 5747, 6437, 5747, 5070, 5747, 5623, 5747, 2577, 1059, 1012, 5747, 9399, 1046, 1012, 5747, 5736, 5747, 1056, 1041, 1049, 1052, 1051, 10958, 1048, 1037, 1039, 14841, 1058, 2009, 1061, 3235, 9678, 2332, 3781, 1012, 3235, 9678, 1006, 11125, 1007, 3235, 9678, 16075, 3235, 9678, 3275, 1018, 1024, 15850, 16442, 1997, 9178, 5347, 2005, 9704, 1006, 5747, 1010, 2960, 1007, 1998, 1006, 3235, 9678, 1010, 15017, 2487, 1007, 1012, 2051, 1011, 5204, 2707, 1011, 1997, 1011, 1996, 1011, 2840, 2437, 12311, 2015, 2051, 1011, 5204, 12082, 2094, 1011, 1015, 1010, 5331, 1997, 1031, 7570, 20961, 5339, 3802, 2632, 1012, 1024, 15873, 4487, 21559, 5638, 19696, 3508, 1997, 2315, 11422, 1999, 3793, 1010, 7861, 20554, 2361, 2249, 1033, 6254, 2004, 1037, 10629, 2007, 9704, 1998, 11422, 2004, 14164, 1012, 5254, 1011, 9178, 3188, 2015, 1010, 5254, 9178, 14402, 1010, 1998, 9178, 2522, 5886, 10127, 2109, 2004, 3341, 15871, 1012, 4487, 21559, 5638, 19696, 3508, 1024, 1037, 2028, 1011, 2028, 12375, 2090, 2169, 5254, 1998, 9178, 13045, 1012, 1012, 12082, 2094, 1011, 1016, 1010, 5331, 1997, 1031, 8038, 23574, 3802, 2632, 1012, 1024, 4101, 4083, 1997, 1996, 7861, 8270, 4667, 1997, 2616, 1998, 11422, 2005, 2315, 9178, 4487, 21559, 5638, 19696, 3508, 1010, 3696, 3363, 2355, 1033, 6630, 1997, 6123, 2616, 1998, 11422, 1999, 1037, 2309, 9207, 2686, 2478, 13558, 13250, 2944, 1012, 4487, 21559, 5638, 19696, 3508, 1024, 1037, 4083, 1011, 2000, 1011, 4635, 2944, 2478, 3188, 26319, 1010, 5164, 14402, 1010, 5254, 1011, 9178, 1010, 1998, 2522, 5886, 10127, 14402, 2004, 2838, 1012, 9312, 3115, 12311, 2951, 13462, 2015, 9530, 3363, 1011, 4681, 2050, 2727, 11937, 2278, 2230, 2432, 1011, 2289, 12702, 19894, 2015, 2297, 2249, 2460, 18935, 2015, 10124, 8377, 2007, 2051, 1011, 5204, 4275, 1012, 2025, 7218, 2000, 10580, 1013, 16157, 2373, 1997, 2051, 1011, 7073, 1012, 1037, 22939, 2818, 4948, 2594, 2951, 13462, 1024, 12082, 2094, 2381, 7159, 2381, 7159, 1012, 4012, 1024, 3784, 7692, 1997, 2350, 3439, 2824, 1012, 21118, 5754, 17287, 3064, 6564, 2629, 9704, 1999, 8698, 18154, 3479, 5491, 2509, 1012, 2047, 7677, 8024, 7292, 2015, 6396, 2102, 19377, 2405, 2090, 3055, 1998, 2289, 1012, 21118, 5754, 17287, 3064, 4029, 2620, 9704, 1999, 3998, 18154, 3479, 19377, 1012, 3463, 1024, 12082, 2094, 1011, 1015, 2381, 7159, 2047, 7677, 8024, 7292, 2015, 3444, 2275, 1059, 1013, 1051, 2051, 1059, 1013, 2051, 1059, 1013, 1051, 2051, 1059, 1013, 2051, 3188, 5824, 1012, 2656, 3770, 1012, 4466, 1008, 4229, 1012, 2403, 5139, 1012, 2484, 1008, 6123, 6191, 1012, 6191, 5764, 1012, 2184, 1008, 4466, 1012, 2861, 5786, 1012, 6390, 1008, 2795, 1015, 1024, 12702, 1011, 10640, 1997, 12082, 2094, 1011, 1015, 2007, 1998, 2302, 2051, 1011, 7073, 3444, 1012, 1008, 3278, 2058, 1059, 1013, 1051, 2051, 1006, 17939, 2015, 1056, 1011, 3231, 2012, 2504, 1997, 1014, 1012, 5890, 1007, 1012, 3463, 1024, 12082, 2094, 1011, 1016, 2381, 7159, 2047, 7677, 8024, 7292, 2015, 3444, 2275, 1059, 1013, 1051, 2051, 1059, 1013, 2051, 1059, 1013, 1051, 2051, 1059, 1013, 2051, 2918, 6486, 1012, 4008, 3938, 1012, 2603, 1008, 5594, 1012, 6282, 6584, 1012, 4029, 1008, 5164, 6486, 1012, 2871, 3938, 1012, 4002, 1008, 6564, 1012, 2654, 6584, 1012, 5718, 1008, 6123, 6205, 1012, 2184, 6205, 1012, 6282, 1008, 6584, 1012, 5718, 6070, 1012, 4090, 1008, 2522, 5886, 10127, 6205, 1012, 2385, 6205, 1012, 5818, 1008, 6564, 1012, 6640, 6070, 1012, 6353, 1008, 2795, 1016, 1024, 12702, 1011, 10640, 1997, 12082, 2094, 1011, 1016, 2007, 1998, 2302, 2051, 1011, 7073, 3444, 1012, 1008, 3278, 2058, 1059, 1013, 1051, 2051, 1006, 17939, 2015, 1056, 1011, 3231, 2012, 2504, 1997, 1014, 1012, 5890, 1007, 1012, 3463, 1024, 12082, 2094, 2291, 2381, 7159, 2047, 7677, 8024, 7292, 2015, 28712, 14268, 1011, 12835, 6444, 1031, 9327, 1998, 2128, 13027, 2121, 1010, 2297, 1033, 6584, 1012, 5718, 5764, 1012, 2382, 28712, 14268, 1011, 11265, 2099, 1031, 9327, 1998, 2128, 13027, 2121, 1010, 2297, 1033, 6640, 1012, 3590, 3438, 1012, 2423, 28194, 1031, 10768, 11335, 20876, 1998, 8040, 4886, 8411, 1010, 2262, 1033, 6445, 1012, 2656, 3963, 1012, 5345, 1052, 5092, 2232, 1031, 25957, 5243, 3802, 2632, 1012, 1010, 2355, 1033, 3938, 1012, 2656, 6390, 1012, 4293, 10424, 21382, 11265, 2099, 1031, 2079, 3501, 17231, 4492, 5488, 1998, 1047, 8751, 16523, 1010, 2286, 1033, 4466, 1012, 2753, 3429, 1012, 2676, 5965, 1031, 9530, 19454, 2072, 1998, 28667, 6279, 10624, 1010, 2325, 1033, 2603, 1012, 2324, 2321, 1012, 4008, 4419, 1031, 28699, 2243, 1998, 17895, 5302, 1010, 2297, 1033, 6255, 1012, 5594, 5139, 1012, 2423, 14375, 1031, 8292, 16665, 22948, 3802, 2632, 1012, 1010, 2286, 1033, 6353, 1012, 6070, 4749, 1012, 2260, 16962, 5669, 2401, 17763, 1031, 27916, 3802, 2632, 1012, 1010, 2249, 1033, 5179, 1012, 6227, 6079, 1012, 6205, 4681, 2050, 1031, 7570, 20961, 5339, 3802, 2632, 1010, 2249, 1033, 6445, 1012, 6273, 3963, 1012, 2403, 12943, 10521, 7315, 1031, 18833, 11012, 3802, 2632, 1010, 2297, 1033, 3963, 1012, 6255, 2753, 1012, 2403, 20512, 3802, 2632, 1012, 1010, 2418, 5786, 1012, 6445, 4724, 1012, 3943, 2128, 1011, 17727, 2140, 1012, 1997, 1031, 8038, 23574, 3802, 2632, 1012, 1010, 2355, 1033, 3938, 1012, 6584, 5824, 1012, 4583, 12082, 2094, 1011, 1016, 6205, 1012, 6273, 6146, 1012, 5641, 2795, 1017, 1024, 12702, 1011, 20069, 7644, 2006, 1996, 2381, 7159, 1998, 2047, 7677, 8024, 7292, 2015, 2951, 13462, 2015, 1997, 12082, 2094, 1011, 1016, 1006, 4738, 2006, 9530, 3363, 1011, 4681, 2050, 1031, 1018, 1033, 1007, 1998, 2060, 5906, 2800, 2006, 16216, 15185, 4014, 1031, 1023, 1033, 1012, 2539, 12654, 12654, 25212, 2094, 8915, 2015, 25212, 2099, 1049, 1021, 1041, 21677, 9178, 22409, 2298, 6279, 9206, 1049, 1021, 1041, 1006, 5254, 1011, 9178, 12375, 1007, 25212, 2099, 1006, 9178, 1011, 9178, 4262, 1007, 25212, 2094, 1006, 9178, 4372, 5666, 20464, 24174, 2594, 13271, 1007, 16948, 7953, 6981, 6981, 2007, 2051, 5204, 4487, 21559, 5638, 19696, 3064, 9178, 9704, 12082, 2094, 9530, 3363, 1011, 4681, 2050, 11937, 2278, 2230, 2315, 9178, 6415, 4590, 2051, 1011, 5204, 12311, 15850, 6415, 4590, 8915, 2015, 1024, 15850, 9178, 16442, 15850, 18046, 3602, 1996, 5754, 17287, 3064, 12082, 2094, 13058, 6525, 1998, 9178, 15850, 16442, 2024, 2800, 2012, 1024, 16770, 1024, 1013, 1013, 7479, 1012, 6131, 2072, 1011, 1999, 2546, 1012, 6131, 2290, 1012, 2139, 1013, 8038, 3995, 1011, 26539, 1013, 12082, 2094, 1013, 2925, 2147, 2817, 2129, 15850, 16730, 2064, 2022, 2109, 2005, 12151, 2041, 1011, 1997, 1011, 21677, 11422, 1012, 2312, 4094, 7885, 2478, 2951, 1011, 4520, 11416, 17724, 2478, 4100, 1011, 13588, 4725, 1012, 5815, 4800, 2989, 8787, 2490, 2005, 1996, 15850, 16442, 1012, 4067, 2017, 999, 3980, 1029, 7604, 1045, 1054, 1012, 20036, 1010, 1043, 1012, 27178, 2696, 18073, 2080, 1010, 1998, 1041, 1012, 19734, 3501, 1012, 3435, 1998, 2686, 1011, 8114, 9178, 11383, 2005, 10861, 5134, 1012, 1999, 8931, 1997, 1996, 5893, 9353, 2213, 2248, 3034, 2006, 4773, 3945, 1998, 2951, 5471, 1010, 1059, 16150, 2213, 2321, 1010, 5530, 14362, 2620, 2620, 1012, 9353, 2213, 1010, 2325, 1012, 1054, 1012, 1039, 1012, 21122, 19434, 1998, 1049, 1012, 14674, 3540, 1012, 2478, 4372, 5666, 20464, 24174, 2594, 3716, 2005, 2315, 9178, 4487, 21559, 5638, 19696, 3508, 1012, 1999, 8931, 1997, 1996, 6252, 3034, 1997, 1996, 2647, 3127, 1997, 1996, 2523, 2005, 15078, 15397, 1010, 19413, 20464, 5757, 1010, 5530, 7604, 2462, 1055, 1012, 12731, 17119, 13471, 1012, 2312, 1011, 4094, 2315, 9178, 4487, 21559, 5638, 19696, 3508, 2241, 2006, 16948, 2951, 1012, 1999, 8931, 1997, 1996, 2289, 4101, 3034, 2006, 17537, 4725, 1999, 3019, 2653, 6364, 1998, 15078, 3019, 2653, 4083, 1010, 7861, 20554, 2361, 1011, 9530, 3363, 5718, 1010, 5530, 3963, 2620, 2581, 16048, 1012, 2523, 2005, 15078, 15397, 1010, 2238, 2289, 1012, 1046, 1012, 7570, 20961, 5339, 1010, 1049, 1012, 1037, 1012, 10930, 20106, 1010, 1045, 1012, 8945, 17080, 3630, 1010, 1044, 1012, 6519, 16173, 4887, 1010, 1049, 1012, 5061, 2389, 1010, 1049, 1012, 8487, 20282, 1010, 1038, 1012, 9092, 13331, 1010, 1055, 1012, 2008, 2121, 1010, 1998, 1043, 1012, 11417, 5283, 2213, 1012, 15873, 4487, 21559, 5638, 19696, 3508, 1997, 2315, 11422, 1999, 3793, 1012, 1999, 8931, 1997, 1996, 3034, 2006, 17537, 4725, 1999, 3019, 2653, 6364, 1010, 7861, 20554, 2361, 2340, 1010, 5530, 6275, 22907, 2683, 2475, 1012, 2523, 2005, 15078, 15397, 1010, 2249, 1012, 7604, 3523, 1062, 1012, 15876, 1010, 1052, 1012, 15469, 1010, 1061, 1012, 26957, 1010, 1061, 1012, 17377, 1010, 1998, 1041, 1012, 8418, 3070, 1012, 9178, 12571, 7861, 8270, 4667, 1012, 1999, 8931, 1997, 1996, 5187, 4103, 3296, 3116, 1997, 1996, 2523, 2005, 15078, 15397, 1998, 1996, 5504, 2248, 4101, 3034, 2006, 3019, 2653, 6364, 1006, 3872, 1015, 1024, 2146, 4981, 1007, 1010, 5530, 14378, 17465, 14142, 2692, 1010, 7211, 1010, 2859, 1010, 2251, 2325, 1012, 2523, 2005, 15078, 15397, 1012, 1055, 1012, 13970, 26518, 6826, 2072, 1010, 1037, 1012, 5960, 1010, 1043, 1012, 14115, 23017, 2078, 1010, 1998, 1055, 1012, 15775, 22272, 8237, 3775, 1012, 7268, 5754, 17287, 3508, 1997, 16948, 11422, 1999, 4773, 3793, 1012, 1999, 8931, 1997, 1996, 6286, 9353, 2213, 9033, 2290, 2243, 14141, 2248, 3034, 2006, 3716, 5456, 1998, 2951, 5471, 1010, 1047, 14141, 5641, 1010, 5530, 7604, 4921, 1054, 1012, 2771, 8865, 21456, 1998, 1037, 1012, 20116, 9626, 2072, 1012, 15536, 3211, 12031, 999, 1024, 11383, 5491, 2000, 4372, 5666, 20464, 24174, 2594, 3716, 1012, 1999, 8931, 1997, 1996, 14683, 9353, 2213, 3034, 2006, 3034, 2006, 2592, 1998, 3716, 2968, 1010, 25022, 22287, 5718, 1010, 5530, 1040, 1012, 24377, 1998, 1045, 1012, 1044, 1012, 15966, 6528, 1012, 4083, 2000, 4957, 2007, 16948, 1012, 1999, 8931, 1997, 1996, 5550, 9353, 2213, 3034, 2006, 2592, 1998, 3716, 2968, 1010, 25022, 22287, 5511, 1010, 5530, 2753, 2683, 22203, 2620, 1012, 9353, 2213, 1010, 2263, 1012, 7604, 1058, 1054, 1012, 18833, 11012, 1010, 1049, 1012, 8469, 2099, 1010, 1037, 1012, 1011, 1039, 1012, 17895, 13807, 17895, 5302, 1010, 1039, 1012, 5797, 1010, 1037, 1012, 2119, 1010, 1049, 1012, 7987, 2819, 5017, 1010, 1040, 1012, 8292, 16665, 22948, 1010, 1049, 1012, 9781, 27914, 2072, 1010, 1040, 1012, 24188, 7646, 1010, 1038, 1012, 1041, 6799, 5804, 1010, 1052, 1012, 10768, 11335, 20876, 1010, 1039, 1012, 3393, 2213, 3489, 1010, 1037, 1012, 22822, 2080, 1010, 1054, 1012, 6583, 5737, 25394, 1010, 1042, 1012, 27263, 15459, 3630, 1010, 1043, 1012, 15544, 12036, 1010, 1044, 1012, 12803, 1010, 1054, 1012, 28699, 2243, 1010, 1054, 1012, 19817, 2239, 5666, 1010, 1046, 1012, 3524, 18349, 8977, 1010, 1998, 1048, 1012, 14008, 17545, 1012, 16216, 15185, 4014, 1024, 2236, 9178, 5754, 17287, 4263, 6847, 10665, 2075, 7705, 1012, 1999, 8931, 1997, 1996, 13386, 2248, 3034, 2006, 2088, 2898, 4773, 1010, 7479, 2321, 1010, 5530, 12104, 21486, 16932, 2509, 1012, 2248, 2088, 2898, 4773, 9281, 9602, 2837, 1010, 2325, 1012, 1045, 1012, 8038, 23574, 1010, 1044, 1012, 12277, 3527, 1010, 1044, 1012, 2202, 2850, 1010, 1998, 1061, 1012, 2202, 11263, 4478, 1012, 4101, 4083, 1997, 1996, 7861, 8270, 4667, 1997, 2616, 1998, 11422, 2005, 2315, 9178, 4487, 21559, 5638, 19696, 3508, 1012, 1999, 8931, 1997, 1996, 3983, 3696, 3363, 3034, 2006, 15078, 3019, 2653, 4083, 1010, 9530, 3363, 2321, 1010, 5530, 5539, 17788, 2683, 1012, 2523, 2005, 15078, 15397, 1010, 2257, 2355, 1012, 102], [101, 12843, 15850, 3012, 1999, 6254, 5579, 19523, 23057, 15469, 2745, 1046, 1012, 2703, 2118, 1997, 5169, 13264, 12843, 15850, 3012, 1999, 6254, 5579, 2030, 2339, 2003, 2026, 2465, 18095, 2893, 4788, 2058, 2051, 1029, 2339, 2003, 2026, 2465, 18095, 2893, 4788, 1029, 1996, 2951, 4353, 2038, 2904, 2003, 2045, 2505, 11778, 2055, 2129, 2009, 3431, 1029, 2003, 2045, 2505, 2057, 2064, 2079, 2000, 15581, 2000, 15850, 3431, 1029, 11259, 12363, 1999, 8476, 4353, 13993, 2836, 7885, 2048, 4127, 1997, 2051, 6993, 1024, 12348, 9377, 2408, 2086, 1006, 1041, 1012, 1043, 1012, 1010, 2051, 1997, 2095, 1007, 2512, 1011, 12348, 2053, 23318, 1006, 1041, 1012, 1043, 1012, 1010, 14798, 1997, 2086, 1007, 7885, 12441, 5579, 8833, 6553, 26237, 1010, 1050, 1011, 13250, 2838, 2416, 2951, 13462, 2015, 1010, 2169, 15131, 2046, 1018, 1011, 1020, 2051, 6993, 2339, 2003, 2026, 2465, 18095, 2893, 4788, 1029, 1996, 2951, 4353, 2038, 2904, 2003, 2045, 2505, 11778, 2055, 2129, 2009, 3431, 1029, 2003, 2045, 2505, 2057, 2064, 2079, 2000, 15581, 2000, 15850, 3431, 1029, 28134, 2487, 1024, 2129, 2515, 2836, 8137, 1029, 4106, 1024, 3345, 1998, 3231, 2006, 2169, 2051, 2558, 5468, 2129, 2836, 9010, 2043, 1996, 3231, 2558, 2003, 2367, 12042, 2061, 2169, 2051, 2558, 2038, 2168, 1001, 1997, 5491, 28134, 2487, 1024, 2129, 2515, 2836, 8137, 1029, 28134, 2487, 1024, 2129, 2515, 2836, 8137, 1029, 28134, 2487, 1024, 2129, 2515, 2836, 8137, 1029, 6300, 14277, 4391, 2024, 2893, 2062, 12367, 8082, 2058, 2051, 1029, 28134, 2487, 1024, 2129, 2515, 2836, 8137, 1029, 2202, 9497, 2015, 1024, 2023, 2828, 1997, 4106, 2064, 7487, 6459, 1997, 13931, 14477, 3619, 13777, 2098, 1024, 2339, 2515, 2836, 8137, 1029, 2339, 2003, 2026, 2465, 18095, 2893, 4788, 1029, 1996, 2951, 4353, 2038, 2904, 2003, 2045, 2505, 11778, 2055, 2129, 2009, 3431, 1029, 2003, 2045, 2505, 2057, 2064, 2079, 2000, 15581, 2000, 15850, 3431, 1029, 28134, 2475, 1024, 2064, 2057, 15581, 2000, 15850, 8358, 1029, 2801, 1024, 4769, 2023, 2004, 1037, 5884, 6789, 3291, 7438, 12045, 1011, 4225, 2051, 6993, 2004, 13100, 28134, 2475, 1024, 2064, 2057, 15581, 2000, 15850, 8358, 1029, 3921, 1024, 3444, 15476, 3672, 3370, 4118, 2013, 4830, 2819, 3523, 1006, 2289, 1007, 28134, 2475, 1024, 2064, 2057, 15581, 2000, 15850, 8358, 1029, 3921, 1024, 3444, 15476, 3672, 3370, 4118, 2013, 4830, 2819, 3523, 1006, 2289, 1007, 6302, 3081, 1030, 3782, 2615, 10755, 7389, 28134, 2475, 1024, 2064, 2057, 15581, 2000, 15850, 8358, 1029, 2236, 5553, 1011, 9388, 19804, 1011, 12022, 21650, 1011, 19802, 13323, 1011, 11703, 5884, 1011, 3563, 4809, 1997, 1996, 3444, 2275, 1024, 28134, 2475, 1024, 2064, 2057, 15581, 2000, 15850, 8358, 1029, 2236, 5553, 1011, 9388, 19804, 1011, 12022, 21650, 1011, 19802, 13323, 1011, 11703, 19804, 1011, 12022, 28134, 2475, 1024, 2064, 2057, 15581, 2000, 15850, 8358, 1029, 19647, 2000, 6611, 2000, 12348, 2838, 1024, 28134, 2475, 1024, 2064, 2057, 15581, 2000, 15850, 8358, 1029, 2129, 2000, 2224, 1999, 2512, 1011, 12348, 10906, 1029, 2236, 2262, 2286, 2297, 2325, 28134, 2475, 1024, 2064, 2057, 15581, 2000, 15850, 8358, 1029, 2129, 2000, 2224, 1999, 2512, 1011, 12348, 10906, 1029, 10329, 17042, 5884, 1011, 3563, 2838, 2236, 2262, 2286, 2297, 2325, 28134, 2475, 1024, 2064, 2057, 15581, 2000, 15850, 8358, 1029, 2129, 2000, 2224, 1999, 2512, 1011, 12348, 10906, 1029, 2076, 2731, 1024, 17042, 5884, 1011, 3563, 2838, 11543, 2064, 2036, 11506, 2007, 12348, 13100, 1017, 4809, 1997, 2169, 3444, 1006, 2236, 1010, 2095, 1011, 3563, 1010, 2161, 1011, 3563, 1007, 21934, 10924, 2836, 2006, 2925, 2951, 1024, 3345, 1999, 3988, 2051, 6993, 8694, 2006, 2117, 1011, 2000, 1011, 2197, 2558, 3231, 2006, 2345, 2051, 2558, 28134, 2475, 1024, 2064, 2057, 15581, 2000, 15850, 8358, 1029, 2129, 2000, 2224, 1999, 2512, 1011, 12348, 10906, 1029, 28134, 2475, 1024, 2064, 2057, 15581, 2000, 15850, 8358, 1029, 2202, 9497, 2015, 1024, 3722, 1011, 2000, 1011, 10408, 6789, 2064, 2191, 2465, 28295, 2062, 15873, 2408, 2051, 10293, 1024, 8694, 23760, 28689, 22828, 2015, 2006, 2218, 5833, 2951, 2013, 1996, 23472, 2203, 1997, 2115, 13931, 1006, 12935, 1012, 2892, 1011, 27354, 1007, 2064, 2599, 2000, 2488, 2836, 2006, 2925, 2951, 4067, 2017, 999, 3980, 1029, 3642, 1024, 16770, 1024, 1013, 1013, 21025, 2705, 12083, 1012, 4012, 1013, 19523, 23057, 14691, 3070, 1013, 5884, 1035, 6789, 1035, 9353, 2140, 11387, 15136, 102]]\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "source": [
    "model.compile(optimizer=optimizer) #Transformer has default task-relevant loss function\n"
   ],
   "metadata": {
    "id": "8ofKM1CHdb4R",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:14:59.378546Z",
     "start_time": "2024-04-10T00:14:59.308736Z"
    }
   },
   "outputs": [],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "source": [
    "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_test_set)"
   ],
   "metadata": {
    "id": "DaVIOc5tdb4R",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:15:00.029184Z",
     "start_time": "2024-04-10T00:15:00.023971Z"
    }
   },
   "outputs": [],
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install huggingface_hub\n",
    "import huggingface_hub\n",
    "#huggingface_hub.login()\n",
    "\n",
    "push_to_hub_callback = PushToHubCallback(\n",
    "    output_dir=\"CS4120final\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "id": "JJrRMAcbdb4R",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:15:05.387974Z",
     "start_time": "2024-04-10T00:15:00.459158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.22.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chris\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\CS4120final\\CS4120final is already a clone of https://huggingface.co/crisis101/CS4120final. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "source": [
    "callbacks = [metric_callback, push_to_hub_callback]"
   ],
   "metadata": {
    "id": "oeJ7SiOhdb4S",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:15:05.405830Z",
     "start_time": "2024-04-10T00:15:05.390165Z"
    }
   },
   "outputs": [],
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(tokenized_train_data[\"text\"][3]))"
   ],
   "metadata": {
    "id": "Qe6qMh68Do97",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:15:05.412664Z",
     "start_time": "2024-04-10T00:15:05.407871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3306\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "source": [
    "print(tf_train_set)\n",
    "model.fit(tf_train_set)\n",
    "#model.fit(x=tf_train_set, validation_data=tf_test_set, epochs=3, callbacks=callbacks)"
   ],
   "metadata": {
    "id": "upHF-Ro5db4S",
    "ExecuteTime": {
     "end_time": "2024-04-10T00:15:17.804853Z",
     "start_time": "2024-04-10T00:15:05.638559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec=({'input_ids': TensorSpec(shape=(1, None), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(1, None), dtype=tf.int64, name=None)}, TensorSpec(shape=(1,), dtype=tf.int64, name=None))>\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node tf_distil_bert_for_sequence_classification_1/distilbert/embeddings/Gather_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_56308\\3536526835.py\", line 2, in <module>\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1170, in fit\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1613, in train_step\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 590, in __call__\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 812, in run_call_with_unpacked_inputs\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 820, in call\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 812, in run_call_with_unpacked_inputs\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 465, in call\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 128, in call\n\nindices[0,512] = 512 is not in [0, 512)\n\t [[{{node tf_distil_bert_for_sequence_classification_1/distilbert/embeddings/Gather_1}}]] [Op:__inference_train_function_52446]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[88], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(tf_train_set)\n\u001B[1;32m----> 2\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtf_train_set\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m#model.fit(x=tf_train_set, validation_data=tf_test_set, epochs=3, callbacks=callbacks)\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:1170\u001B[0m, in \u001B[0;36mTFPreTrainedModel.fit\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1167\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(keras\u001B[38;5;241m.\u001B[39mModel\u001B[38;5;241m.\u001B[39mfit)\n\u001B[0;32m   1168\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1169\u001B[0m     args, kwargs \u001B[38;5;241m=\u001B[39m convert_batch_encoding(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1170\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     54\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Graph execution error:\n\nDetected at node tf_distil_bert_for_sequence_classification_1/distilbert/embeddings/Gather_1 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_56308\\3536526835.py\", line 2, in <module>\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1170, in fit\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1807, in fit\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1613, in train_step\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 590, in __call__\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 812, in run_call_with_unpacked_inputs\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 820, in call\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 812, in run_call_with_unpacked_inputs\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 465, in call\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 128, in call\n\nindices[0,512] = 512 is not in [0, 512)\n\t [[{{node tf_distil_bert_for_sequence_classification_1/distilbert/embeddings/Gather_1}}]] [Op:__inference_train_function_52446]"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "source": [
    "# ## check if works\n",
    "#\n",
    "# word_tokenizer = Tokenizer()\n",
    "# word_tokenizer.fit_on_texts(presentations_data)\n",
    "# encoded = word_tokenizer.texts_to_sequences(presentations_data)\n",
    "#\n",
    "# char_tokenizer = Tokenizer()\n",
    "# char_tokenizer.fit_on_texts(papers_data)\n",
    "# encoded = char_tokenizer.texts_to_sequences(papers_data)"
   ],
   "metadata": {
    "id": "f_BF_zXydb4S"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "xxefv_YKdb4S"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# ## correct implementation for LR ?\n",
    "#\n",
    "# word_map, index_map = utils.read_embeddings(\"spooky_embedding_word.txt\", word_tokenizer)\n",
    "# char_map, char_index_map = utils.read_embeddings(\"spooky_embedding_char.txt\", char_tokenizer)"
   ],
   "metadata": {
    "id": "MlU-XB1_db4S"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "# X = tfidf_vectorizer.fit_transform(presentations_data)\n",
    "#\n",
    "# y = list(range(len(presentations_data)))\n",
    "#\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#\n",
    "# logreg_model = LogisticRegression(max_iter=1000)\n",
    "# logreg_model.fit(X_train, y_train)\n",
    "#\n",
    "# y_pred = logreg_model.predict(X_test)\n",
    "#\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ],
   "metadata": {
    "id": "UzxHaeU9db4S"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# # print(y_pred[0])\n",
    "# # print(y_test[0])\n",
    "# # print(presentations_data)\n",
    "# print(X_train)\n",
    "# print(X_test)\n",
    "# # print(len(y))"
   ],
   "metadata": {
    "id": "RfGGs18Zdb4S"
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
